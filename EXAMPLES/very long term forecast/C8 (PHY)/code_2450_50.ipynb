{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "2495    55.336073\n",
       "2496    55.327055\n",
       "2497    55.318036\n",
       "2498    55.309018\n",
       "2499    55.300000\n",
       "Name: C8, Length: 2500, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c8_interpolated_2450_50.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "2445     0.000000\n",
       "2446     0.157439\n",
       "2447     0.000000\n",
       "2448     0.000000\n",
       "2449     0.104578\n",
       "Name: C8, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(50)\n",
    "test\n",
    "training_set = training_set.head(2450)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.987115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.774230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87.561345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.348459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.200000  0.000298\n",
       "1     87.987115  0.000298\n",
       "2     87.774230  0.000297\n",
       "3     87.561345  0.000297\n",
       "4     87.348459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 85.7336  # Value for C0\n",
    "K0 = -0.0020  # Value for K0\n",
    "K1 = 0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0125    # Value for b\n",
    "c = 2.3008    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-175)  var1(t-174)  var1(t-173)  var1(t-172)  var1(t-171)  \\\n",
      "175    88.200000    87.987115    87.774230    87.561345    87.348459   \n",
      "176    87.987115    87.774230    87.561345    87.348459    87.135574   \n",
      "177    87.774230    87.561345    87.348459    87.135574    86.922689   \n",
      "178    87.561345    87.348459    87.135574    86.922689    86.709804   \n",
      "179    87.348459    87.135574    86.922689    86.709804    86.496919   \n",
      "\n",
      "     var1(t-170)  var1(t-169)  var1(t-168)  var1(t-167)  var1(t-166)  ...  \\\n",
      "175    87.135574    86.922689    86.709804    86.496919    86.294538  ...   \n",
      "176    86.922689    86.709804    86.496919    86.294538    86.221709  ...   \n",
      "177    86.709804    86.496919    86.294538    86.221709    86.148880  ...   \n",
      "178    86.496919    86.294538    86.221709    86.148880    86.076050  ...   \n",
      "179    86.294538    86.221709    86.148880    86.076050    86.003221  ...   \n",
      "\n",
      "     var1(t+45)  var2(t+45)  var1(t+46)  var2(t+46)  var1(t+47)  var2(t+47)  \\\n",
      "175   79.697526    0.000280   79.676984    0.000280   79.656443    0.000280   \n",
      "176   79.676984    0.000280   79.656443    0.000280   79.635901    0.000280   \n",
      "177   79.656443    0.000280   79.635901    0.000280   79.615359    0.000279   \n",
      "178   79.635901    0.000280   79.615359    0.000279   79.594818    0.000279   \n",
      "179   79.615359    0.000279   79.594818    0.000279   79.574276    0.000279   \n",
      "\n",
      "     var1(t+48)  var2(t+48)  var1(t+49)  var2(t+49)  \n",
      "175   79.635901    0.000280   79.615359    0.000279  \n",
      "176   79.615359    0.000279   79.594818    0.000279  \n",
      "177   79.594818    0.000279   79.574276    0.000279  \n",
      "178   79.574276    0.000279   79.553735    0.000279  \n",
      "179   79.553735    0.000279   79.533193    0.000279  \n",
      "\n",
      "[5 rows x 276 columns]\n",
      "Index(['var1(t-175)', 'var1(t-174)', 'var1(t-173)', 'var1(t-172)',\n",
      "       'var1(t-171)', 'var1(t-170)', 'var1(t-169)', 'var1(t-168)',\n",
      "       'var1(t-167)', 'var1(t-166)',\n",
      "       ...\n",
      "       'var1(t+45)', 'var2(t+45)', 'var1(t+46)', 'var2(t+46)', 'var1(t+47)',\n",
      "       'var2(t+47)', 'var1(t+48)', 'var2(t+48)', 'var1(t+49)', 'var2(t+49)'],\n",
      "      dtype='object', length=276)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 175, n_out = 50)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 176):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-150:]\n",
    "trainX = train[:,:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-150:]\n",
    "forecastX = forecast[:,:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 1, 126) (2225, 150) (1, 1, 126)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28/28 [==============================] - 3s 24ms/step - loss: 4400.3086 - val_loss: 2046.7390\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 4066.7661 - val_loss: 1912.1753\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3893.7820 - val_loss: 1822.0918\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3707.5879 - val_loss: 1739.9128\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3526.8967 - val_loss: 1659.2871\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3351.1506 - val_loss: 1586.4135\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3186.4092 - val_loss: 1522.0293\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3038.7573 - val_loss: 1461.9825\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2890.7625 - val_loss: 1408.7698\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 2753.6802 - val_loss: 1360.2942\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 2623.5891 - val_loss: 1314.1216\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 2502.5896 - val_loss: 1273.5432\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 2387.9839 - val_loss: 1236.1359\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2279.6987 - val_loss: 1204.9093\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2175.1121 - val_loss: 1171.6497\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 2074.4773 - val_loss: 1138.1854\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1979.8263 - val_loss: 1113.1232\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1890.8280 - val_loss: 1094.1965\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1804.1650 - val_loss: 1069.0209\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1721.6730 - val_loss: 1047.3375\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1642.7064 - val_loss: 1030.6038\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1560.8060 - val_loss: 1011.1213\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1482.2549 - val_loss: 996.7925\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1410.5631 - val_loss: 989.2142\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1344.5593 - val_loss: 980.2510\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1282.4794 - val_loss: 975.1470\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1226.5851 - val_loss: 974.5012\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1167.0304 - val_loss: 976.6068\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1114.5532 - val_loss: 976.1733\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1062.9509 - val_loss: 965.7155\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1016.3951 - val_loss: 963.1339\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1042.7932 - val_loss: 983.7658\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 927.9119 - val_loss: 986.6836\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 890.4209 - val_loss: 973.7412\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 932.8250 - val_loss: 1041.4929\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 827.7333 - val_loss: 1050.6080\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 783.2876 - val_loss: 1058.8801\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 748.2940 - val_loss: 1056.9229\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 718.0639 - val_loss: 1052.3528\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 768.1356 - val_loss: 1057.5679\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 755.1064 - val_loss: 1119.5598\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 652.1235 - val_loss: 1158.5684\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 621.9729 - val_loss: 1161.2688\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 611.5593 - val_loss: 1159.0286\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 601.1932 - val_loss: 1143.5980\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 574.2885 - val_loss: 1144.1758\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 550.7158 - val_loss: 1136.6886\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 555.1484 - val_loss: 1178.3605\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 522.4147 - val_loss: 1186.2224\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 515.5472 - val_loss: 1228.4513\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 519.9227 - val_loss: 1226.5128\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 503.5116 - val_loss: 1226.6688\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 530.1720 - val_loss: 1231.2130\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 469.5247 - val_loss: 1217.9260\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 477.7243 - val_loss: 1214.5671\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 465.1379 - val_loss: 1226.3124\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 460.3765 - val_loss: 1265.9022\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 446.3574 - val_loss: 1254.4899\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 456.3020 - val_loss: 1260.8580\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 445.3419 - val_loss: 1269.4136\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 435.6401 - val_loss: 1268.9227\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 419.6087 - val_loss: 1276.5035\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 455.9196 - val_loss: 1291.6848\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 405.3202 - val_loss: 1305.6519\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 398.8671 - val_loss: 1314.5814\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 391.3657 - val_loss: 1331.2583\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 382.9884 - val_loss: 1336.3982\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 395.3035 - val_loss: 1393.2771\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 381.7469 - val_loss: 1373.3754\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 412.1075 - val_loss: 1377.6104\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 384.1777 - val_loss: 1356.0292\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 383.9947 - val_loss: 1339.0790\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 384.8423 - val_loss: 1359.8252\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 373.9705 - val_loss: 1346.6541\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 369.0022 - val_loss: 1369.3705\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 362.3457 - val_loss: 1385.8594\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 332.1656 - val_loss: 1375.5897\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 339.1712 - val_loss: 1435.0894\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 335.4677 - val_loss: 1438.6250\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 333.5420 - val_loss: 1441.3032\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 331.1590 - val_loss: 1444.8645\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 328.1048 - val_loss: 1449.1219\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 326.1294 - val_loss: 1432.1813\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 314.5077 - val_loss: 1395.4905\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 339.2970 - val_loss: 1400.1121\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 336.6613 - val_loss: 1406.5363\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 333.9436 - val_loss: 1413.1322\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 331.6399 - val_loss: 1420.7144\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 329.6179 - val_loss: 1426.8455\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 327.6541 - val_loss: 1434.3665\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 325.9408 - val_loss: 1439.4700\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 324.1621 - val_loss: 1444.2167\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 322.4474 - val_loss: 1448.1466\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 321.1106 - val_loss: 1452.2954\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 319.5780 - val_loss: 1450.7772\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 320.3690 - val_loss: 1466.7456\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 318.0318 - val_loss: 1469.8551\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 317.1132 - val_loss: 1472.9202\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 315.5987 - val_loss: 1471.5352\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 315.1263 - val_loss: 1477.9824\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 313.9368 - val_loss: 1473.4095\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 323.4198 - val_loss: 1520.6144\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 346.0069 - val_loss: 1604.6400\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 334.7157 - val_loss: 1556.9805\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 338.8164 - val_loss: 1539.7889\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 333.1294 - val_loss: 1531.6360\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 331.4505 - val_loss: 1526.0072\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 330.2127 - val_loss: 1525.3292\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 333.1765 - val_loss: 1545.2548\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 336.7045 - val_loss: 1560.1034\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 328.1950 - val_loss: 1532.7224\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 333.8439 - val_loss: 1570.5562\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 332.6664 - val_loss: 1570.4796\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 330.1666 - val_loss: 1553.8767\n",
      "Epoch 115/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 325.0590 - val_loss: 1540.9059\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 323.0472 - val_loss: 1535.2264\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 322.4201 - val_loss: 1532.8315\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 322.6503 - val_loss: 1542.8645\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 320.9455 - val_loss: 1538.7571\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 320.2663 - val_loss: 1538.3406\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 319.6228 - val_loss: 1537.8954\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 318.9434 - val_loss: 1537.6469\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 318.2978 - val_loss: 1537.0479\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 317.6495 - val_loss: 1535.8815\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 317.0092 - val_loss: 1534.6691\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 316.1602 - val_loss: 1528.3156\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 311.5125 - val_loss: 1513.9131\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 308.4989 - val_loss: 1503.5753\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 306.0634 - val_loss: 1495.0291\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 305.0482 - val_loss: 1487.6837\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 304.3671 - val_loss: 1488.3851\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 303.2960 - val_loss: 1484.7827\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 302.9941 - val_loss: 1490.6500\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 302.2971 - val_loss: 1490.4689\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 301.6543 - val_loss: 1487.7802\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 300.9792 - val_loss: 1487.2314\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 300.3319 - val_loss: 1485.2737\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 299.6745 - val_loss: 1478.0988\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 312.7961 - val_loss: 1472.5935\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 311.6303 - val_loss: 1472.6281\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 310.7078 - val_loss: 1474.6770\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 309.7069 - val_loss: 1478.2227\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 308.8165 - val_loss: 1480.7122\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 307.8789 - val_loss: 1480.2782\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 319.2750 - val_loss: 1534.3909\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 318.0081 - val_loss: 1535.9266\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 317.3107 - val_loss: 1536.5945\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 316.6089 - val_loss: 1536.1569\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 317.5907 - val_loss: 1545.3938\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 315.3892 - val_loss: 1541.9198\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 314.7448 - val_loss: 1541.7462\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 314.1097 - val_loss: 1541.0334\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 313.5520 - val_loss: 1535.1884\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 329.0394 - val_loss: 1533.8370\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 321.0407 - val_loss: 1478.8058\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 340.7038 - val_loss: 1484.8636\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 331.9332 - val_loss: 1541.2932\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 324.3672 - val_loss: 1524.4802\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 346.2189 - val_loss: 1622.4731\n",
      "Epoch 160/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 344.1845 - val_loss: 1614.1351\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 339.5415 - val_loss: 1593.5118\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 333.4876 - val_loss: 1575.9607\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 324.8911 - val_loss: 1548.1857\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 322.7257 - val_loss: 1540.8215\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 320.9385 - val_loss: 1537.4867\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 319.9374 - val_loss: 1530.1873\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 326.9330 - val_loss: 1565.3837\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 318.0229 - val_loss: 1548.2949\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 313.5472 - val_loss: 1524.4308\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 326.4897 - val_loss: 1514.2865\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 325.3083 - val_loss: 1512.6998\n",
      "Epoch 172/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 320.3234 - val_loss: 1502.4247\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 318.3214 - val_loss: 1497.3544\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 314.9316 - val_loss: 1495.9596\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 313.7950 - val_loss: 1497.6344\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 312.4723 - val_loss: 1502.7788\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 311.9363 - val_loss: 1509.5300\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 310.8171 - val_loss: 1518.4446\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 310.4480 - val_loss: 1514.7500\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 307.7039 - val_loss: 1487.1052\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 369.9865 - val_loss: 1491.4718\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 379.5536 - val_loss: 1625.3544\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 358.0880 - val_loss: 1621.4569\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 363.2901 - val_loss: 1703.9655\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 325.1466 - val_loss: 1646.2675\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 326.2207 - val_loss: 1690.6681\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 334.4035 - val_loss: 1655.5524\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 325.0117 - val_loss: 1604.2423\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 326.4305 - val_loss: 1591.0785\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 315.9704 - val_loss: 1546.2974\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 376.6068 - val_loss: 1553.1495\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 373.0573 - val_loss: 1572.7125\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 369.8242 - val_loss: 1589.7657\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 367.4037 - val_loss: 1602.7815\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 365.1945 - val_loss: 1615.5605\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 363.5420 - val_loss: 1624.9545\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 362.0401 - val_loss: 1632.1465\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 360.3319 - val_loss: 1635.5168\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 357.6352 - val_loss: 1637.2297\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 356.5989 - val_loss: 1644.5808\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 355.4272 - val_loss: 1646.6368\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 344.5312 - val_loss: 1590.2241\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 357.8381 - val_loss: 1598.7109\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 356.1287 - val_loss: 1602.5857\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 354.5757 - val_loss: 1611.5946\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 352.4742 - val_loss: 1598.0260\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 360.1957 - val_loss: 1645.5879\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 357.1207 - val_loss: 1650.3875\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 352.0708 - val_loss: 1638.6499\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 349.8873 - val_loss: 1625.0601\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 348.7091 - val_loss: 1574.8937\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 349.1055 - val_loss: 1580.2303\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 346.8517 - val_loss: 1585.2773\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 345.6150 - val_loss: 1592.0034\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 344.6223 - val_loss: 1594.3542\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 343.4546 - val_loss: 1598.8146\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 363.4968 - val_loss: 1590.9888\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 360.0702 - val_loss: 1587.7051\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 355.1742 - val_loss: 1603.9905\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 338.6173 - val_loss: 1576.0878\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 341.1980 - val_loss: 1564.5914\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 338.2082 - val_loss: 1546.0558\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 337.6021 - val_loss: 1560.9907\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 330.6787 - val_loss: 1553.4152\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 327.5092 - val_loss: 1539.7965\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 322.3108 - val_loss: 1514.0967\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 321.0353 - val_loss: 1517.9020\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 320.3784 - val_loss: 1526.2386\n",
      "Epoch 229/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 318.8226 - val_loss: 1519.0562\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 316.9934 - val_loss: 1516.1200\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 316.2263 - val_loss: 1517.1532\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 315.5026 - val_loss: 1520.0948\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 314.6023 - val_loss: 1522.4778\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 314.0728 - val_loss: 1517.7369\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 313.4035 - val_loss: 1526.3706\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 312.6718 - val_loss: 1525.2332\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 311.9186 - val_loss: 1514.2952\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 292.6864 - val_loss: 1409.1014\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 317.5155 - val_loss: 1414.2037\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 315.9341 - val_loss: 1422.7896\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 313.7192 - val_loss: 1434.2042\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 312.2320 - val_loss: 1440.7317\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 311.5769 - val_loss: 1440.4695\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 310.3853 - val_loss: 1448.4198\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 309.1252 - val_loss: 1452.2673\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 308.0608 - val_loss: 1456.9242\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 306.2013 - val_loss: 1462.3286\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 301.1617 - val_loss: 1466.0088\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 299.2279 - val_loss: 1465.1444\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 298.2745 - val_loss: 1467.2222\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 297.5849 - val_loss: 1465.3474\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 296.7607 - val_loss: 1467.6855\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 296.1003 - val_loss: 1473.4347\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 295.6714 - val_loss: 1473.0996\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 294.6446 - val_loss: 1467.7705\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 293.9441 - val_loss: 1469.0983\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 293.3045 - val_loss: 1470.5409\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 292.7045 - val_loss: 1470.9990\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 292.5863 - val_loss: 1475.8553\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 292.5128 - val_loss: 1477.7483\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 292.1136 - val_loss: 1468.2241\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 343.5172 - val_loss: 1481.5427\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 341.5508 - val_loss: 1493.2992\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 338.5890 - val_loss: 1499.1224\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 336.8972 - val_loss: 1507.2745\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 319.0720 - val_loss: 1419.4161\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 327.6548 - val_loss: 1427.9028\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 322.9288 - val_loss: 1430.8621\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 317.9180 - val_loss: 1434.6034\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 316.1224 - val_loss: 1445.9877\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 314.8885 - val_loss: 1451.9872\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 313.5118 - val_loss: 1460.9673\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 312.4951 - val_loss: 1472.3583\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 310.3117 - val_loss: 1478.7429\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 298.4289 - val_loss: 1480.6906\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 301.0795 - val_loss: 1508.1942\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 298.5283 - val_loss: 1494.1110\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 297.2654 - val_loss: 1483.1179\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 294.2233 - val_loss: 1473.8600\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 292.2199 - val_loss: 1468.2758\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 308.0297 - val_loss: 1466.4907\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 307.3282 - val_loss: 1473.3907\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 306.5417 - val_loss: 1479.1156\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 305.7973 - val_loss: 1482.1337\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 305.1578 - val_loss: 1485.0378\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 304.5501 - val_loss: 1487.9337\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 304.0095 - val_loss: 1489.3121\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 303.4631 - val_loss: 1491.4973\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 303.0128 - val_loss: 1491.7020\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 302.5499 - val_loss: 1493.0134\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 302.0087 - val_loss: 1484.6411\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 341.5368 - val_loss: 1490.3463\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 340.0084 - val_loss: 1493.5796\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 338.3016 - val_loss: 1518.1138\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 336.0018 - val_loss: 1545.1902\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 299.8799 - val_loss: 1529.6586\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 301.2411 - val_loss: 1521.7194\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 301.8216 - val_loss: 1514.5280\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 324.2741 - val_loss: 1624.5049\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 317.2792 - val_loss: 1578.7429\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 311.3695 - val_loss: 1528.7192\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 311.0818 - val_loss: 1503.7196\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 310.1120 - val_loss: 1492.4908\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 307.0445 - val_loss: 1476.9598\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 302.0864 - val_loss: 1461.5591\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 300.2075 - val_loss: 1455.4365\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 298.6282 - val_loss: 1455.4611\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 295.8457 - val_loss: 1443.0640\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 295.6599 - val_loss: 1455.7628\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 294.7576 - val_loss: 1458.5715\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 294.2727 - val_loss: 1459.8263\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 293.7897 - val_loss: 1461.5524\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 293.3451 - val_loss: 1461.1903\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 292.9229 - val_loss: 1462.1461\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 292.4688 - val_loss: 1462.7758\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 292.0228 - val_loss: 1462.8435\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 291.5912 - val_loss: 1462.6984\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 291.1615 - val_loss: 1462.4905\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 290.7377 - val_loss: 1462.2621\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 290.3245 - val_loss: 1461.7761\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.9212 - val_loss: 1461.1332\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.5224 - val_loss: 1460.3972\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.1200 - val_loss: 1459.5330\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 288.7230 - val_loss: 1458.6931\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 288.3290 - val_loss: 1457.9629\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 287.9288 - val_loss: 1457.6943\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 287.6937 - val_loss: 1448.0040\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 285.2422 - val_loss: 1439.1198\n",
      "Epoch 329/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 282.0428 - val_loss: 1431.8815\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 307.1225 - val_loss: 1438.9281\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 305.9785 - val_loss: 1441.8771\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 303.3394 - val_loss: 1443.6757\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 302.6585 - val_loss: 1444.5067\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 298.3357 - val_loss: 1434.1344\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 297.2460 - val_loss: 1432.1819\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 296.2530 - val_loss: 1415.0671\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 294.8045 - val_loss: 1410.2079\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 293.7755 - val_loss: 1415.6342\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 292.9498 - val_loss: 1420.0054\n",
      "Epoch 340/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 292.1964 - val_loss: 1423.9614\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 291.6612 - val_loss: 1425.9857\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 291.0727 - val_loss: 1426.7465\n",
      "Epoch 343/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 290.5173 - val_loss: 1425.8118\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.9150 - val_loss: 1431.9496\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.4005 - val_loss: 1433.3372\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 288.7996 - val_loss: 1428.3628\n",
      "Epoch 347/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 279.0812 - val_loss: 1373.5463\n",
      "Epoch 348/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 290.5115 - val_loss: 1379.6523\n",
      "Epoch 349/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.6782 - val_loss: 1384.2372\n",
      "Epoch 350/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 288.9800 - val_loss: 1388.4326\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 288.1622 - val_loss: 1393.9471\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 287.3928 - val_loss: 1398.3553\n",
      "Epoch 353/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 286.6705 - val_loss: 1401.8357\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 286.0311 - val_loss: 1404.9143\n",
      "Epoch 355/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 285.4558 - val_loss: 1407.8042\n",
      "Epoch 356/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 285.0026 - val_loss: 1409.3486\n",
      "Epoch 357/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 284.5272 - val_loss: 1410.2911\n",
      "Epoch 358/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 284.0675 - val_loss: 1411.6847\n",
      "Epoch 359/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 283.5898 - val_loss: 1413.0804\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 283.1417 - val_loss: 1413.8263\n",
      "Epoch 361/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 282.6855 - val_loss: 1414.7843\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 282.4150 - val_loss: 1413.8350\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 282.0557 - val_loss: 1409.7954\n",
      "Epoch 364/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 281.6878 - val_loss: 1410.5989\n",
      "Epoch 365/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 281.2597 - val_loss: 1411.2258\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 280.8473 - val_loss: 1411.5011\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 280.4474 - val_loss: 1411.4686\n",
      "Epoch 368/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 280.0566 - val_loss: 1411.2433\n",
      "Epoch 369/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 279.6726 - val_loss: 1410.9769\n",
      "Epoch 370/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 279.2910 - val_loss: 1410.5796\n",
      "Epoch 371/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 278.9142 - val_loss: 1410.1019\n",
      "Epoch 372/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 278.5389 - val_loss: 1409.4983\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 278.1678 - val_loss: 1408.8163\n",
      "Epoch 374/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 277.7986 - val_loss: 1408.0582\n",
      "Epoch 375/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 277.4325 - val_loss: 1407.2236\n",
      "Epoch 376/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 277.0683 - val_loss: 1406.3265\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.7060 - val_loss: 1405.3601\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.3453 - val_loss: 1404.3452\n",
      "Epoch 379/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 275.9857 - val_loss: 1403.2695\n",
      "Epoch 380/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 275.6274 - val_loss: 1402.1464\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 275.2694 - val_loss: 1400.9658\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 274.9102 - val_loss: 1399.7697\n",
      "Epoch 383/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 274.5529 - val_loss: 1398.1462\n",
      "Epoch 384/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 274.2105 - val_loss: 1399.0720\n",
      "Epoch 385/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 273.1718 - val_loss: 1371.9698\n",
      "Epoch 386/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 308.9884 - val_loss: 1360.1724\n",
      "Epoch 387/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 301.1108 - val_loss: 1325.6271\n",
      "Epoch 388/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 489.3771 - val_loss: 1327.9443\n",
      "Epoch 389/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 452.3068 - val_loss: 1351.9244\n",
      "Epoch 390/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 428.6893 - val_loss: 1428.6035\n",
      "Epoch 391/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 420.7532 - val_loss: 1760.1545\n",
      "Epoch 392/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 359.2403 - val_loss: 1772.2904\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 352.7791 - val_loss: 1734.8105\n",
      "Epoch 394/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 331.4655 - val_loss: 1633.8417\n",
      "Epoch 395/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 317.6374 - val_loss: 1560.7395\n",
      "Epoch 396/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 315.7131 - val_loss: 1552.6875\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 310.1329 - val_loss: 1545.8402\n",
      "Epoch 398/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 298.2239 - val_loss: 1478.9159\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 288.6272 - val_loss: 1415.3984\n",
      "Epoch 400/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 288.6795 - val_loss: 1416.4550\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 288.0596 - val_loss: 1418.4022\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 287.7963 - val_loss: 1416.4681\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 287.9841 - val_loss: 1418.6198\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 290.6654 - val_loss: 1426.2166\n",
      "Epoch 405/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 290.4384 - val_loss: 1430.9121\n",
      "Epoch 406/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 290.0236 - val_loss: 1429.2501\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.5231 - val_loss: 1427.6321\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.1682 - val_loss: 1426.1978\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 288.6260 - val_loss: 1429.7461\n",
      "Epoch 410/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 288.7558 - val_loss: 1419.1007\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 284.4539 - val_loss: 1398.4675\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 284.1002 - val_loss: 1398.3080\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 283.7397 - val_loss: 1401.2373\n",
      "Epoch 414/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 283.3049 - val_loss: 1403.1335\n",
      "Epoch 415/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 282.9735 - val_loss: 1401.8516\n",
      "Epoch 416/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 282.7645 - val_loss: 1391.4449\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 281.9102 - val_loss: 1390.7610\n",
      "Epoch 418/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 283.7853 - val_loss: 1410.1332\n",
      "Epoch 419/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 285.2124 - val_loss: 1412.2173\n",
      "Epoch 420/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 284.8212 - val_loss: 1409.8340\n",
      "Epoch 421/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 284.2707 - val_loss: 1407.0363\n",
      "Epoch 422/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 279.4216 - val_loss: 1377.8566\n",
      "Epoch 423/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 281.6274 - val_loss: 1388.5319\n",
      "Epoch 424/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 277.3344 - val_loss: 1377.4878\n",
      "Epoch 425/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.9193 - val_loss: 1376.5510\n",
      "Epoch 426/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.5912 - val_loss: 1374.9014\n",
      "Epoch 427/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 277.3794 - val_loss: 1379.9335\n",
      "Epoch 428/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 275.8683 - val_loss: 1378.6863\n",
      "Epoch 429/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 275.7128 - val_loss: 1377.6622\n",
      "Epoch 430/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 275.3654 - val_loss: 1376.2538\n",
      "Epoch 431/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 275.0074 - val_loss: 1374.7490\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 274.6537 - val_loss: 1372.8687\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 274.5857 - val_loss: 1370.6174\n",
      "Epoch 434/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 326.7100 - val_loss: 1669.2906\n",
      "Epoch 435/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 329.2009 - val_loss: 1682.3992\n",
      "Epoch 436/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 328.9100 - val_loss: 1676.6652\n",
      "Epoch 437/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 328.4627 - val_loss: 1668.2126\n",
      "Epoch 438/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 328.5288 - val_loss: 1664.0367\n",
      "Epoch 439/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 328.3033 - val_loss: 1659.7063\n",
      "Epoch 440/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 328.1137 - val_loss: 1655.1382\n",
      "Epoch 441/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 327.9404 - val_loss: 1652.4056\n",
      "Epoch 442/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 327.7675 - val_loss: 1648.3458\n",
      "Epoch 443/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 327.6047 - val_loss: 1645.9481\n",
      "Epoch 444/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 327.4319 - val_loss: 1643.9916\n",
      "Epoch 445/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 327.2531 - val_loss: 1634.7196\n",
      "Epoch 446/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 315.3138 - val_loss: 1563.4796\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 328.6435 - val_loss: 1564.6882\n",
      "Epoch 448/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 327.9021 - val_loss: 1571.6056\n",
      "Epoch 449/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 327.4517 - val_loss: 1573.5480\n",
      "Epoch 450/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 327.2547 - val_loss: 1573.4672\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 323.0663 - val_loss: 1546.1288\n",
      "Epoch 452/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 313.1969 - val_loss: 1507.3356\n",
      "Epoch 453/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 310.7421 - val_loss: 1477.1304\n",
      "Epoch 454/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 302.7003 - val_loss: 1441.6714\n",
      "Epoch 455/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 302.1659 - val_loss: 1428.3971\n",
      "Epoch 456/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 297.5373 - val_loss: 1429.0026\n",
      "Epoch 457/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 292.9734 - val_loss: 1417.4204\n",
      "Epoch 458/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 284.8456 - val_loss: 1375.3407\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 277.1454 - val_loss: 1324.4481\n",
      "Epoch 460/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 273.3186 - val_loss: 1318.0422\n",
      "Epoch 461/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 270.5032 - val_loss: 1307.6674\n",
      "Epoch 462/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 270.1343 - val_loss: 1306.5862\n",
      "Epoch 463/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 269.6031 - val_loss: 1306.0913\n",
      "Epoch 464/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 265.0012 - val_loss: 1303.1305\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 322.1703 - val_loss: 1528.4849\n",
      "Epoch 466/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 304.5103 - val_loss: 1506.6938\n",
      "Epoch 467/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 297.9341 - val_loss: 1464.7556\n",
      "Epoch 468/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 297.1770 - val_loss: 1461.7649\n",
      "Epoch 469/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 293.6115 - val_loss: 1451.5778\n",
      "Epoch 470/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 286.8445 - val_loss: 1402.9441\n",
      "Epoch 471/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 277.2912 - val_loss: 1382.6782\n",
      "Epoch 472/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.9425 - val_loss: 1377.8645\n",
      "Epoch 473/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.6356 - val_loss: 1377.9194\n",
      "Epoch 474/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.3118 - val_loss: 1378.2769\n",
      "Epoch 475/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 275.9966 - val_loss: 1376.5092\n",
      "Epoch 476/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 275.6943 - val_loss: 1376.5399\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 275.3886 - val_loss: 1375.7286\n",
      "Epoch 478/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 275.0872 - val_loss: 1374.9150\n",
      "Epoch 479/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 274.7855 - val_loss: 1374.1737\n",
      "Epoch 480/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 274.4734 - val_loss: 1371.7866\n",
      "Epoch 481/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 273.9299 - val_loss: 1371.3239\n",
      "Epoch 482/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 273.6385 - val_loss: 1370.2902\n",
      "Epoch 483/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 273.3437 - val_loss: 1369.9637\n",
      "Epoch 484/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 273.0542 - val_loss: 1368.6010\n",
      "Epoch 485/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 272.7678 - val_loss: 1368.1089\n",
      "Epoch 486/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 272.4832 - val_loss: 1368.3145\n",
      "Epoch 487/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 272.1797 - val_loss: 1365.9691\n",
      "Epoch 488/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 271.9038 - val_loss: 1366.3467\n",
      "Epoch 489/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 271.6045 - val_loss: 1363.8625\n",
      "Epoch 490/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 271.3198 - val_loss: 1363.0819\n",
      "Epoch 491/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 271.0357 - val_loss: 1361.7693\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 270.7491 - val_loss: 1360.7795\n",
      "Epoch 493/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 270.4667 - val_loss: 1359.5981\n",
      "Epoch 494/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 270.1866 - val_loss: 1358.7255\n",
      "Epoch 495/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 269.9128 - val_loss: 1358.5328\n",
      "Epoch 496/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 269.6068 - val_loss: 1356.1116\n",
      "Epoch 497/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 269.3433 - val_loss: 1357.2089\n",
      "Epoch 498/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 269.0411 - val_loss: 1354.2600\n",
      "Epoch 499/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 268.7658 - val_loss: 1353.1080\n",
      "Epoch 500/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 268.4800 - val_loss: 1352.9730\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(85.7336, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0020, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0125, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3008, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 402ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 126)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 126)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 186)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:150:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 6.62273226e+01, 8.07057600e-02, 6.65643908e+01,\n",
       "        6.58459034e+01, 6.51628151e+01, 6.61829715e+01, 6.54821429e+01,\n",
       "        6.88478058e+01, 0.00000000e+00, 0.00000000e+00, 7.07138500e-02,\n",
       "        6.54401261e+01, 0.00000000e+00, 6.57594538e+01, 7.01633987e+01,\n",
       "        0.00000000e+00, 6.53981092e+01, 6.73996149e+01, 6.84295051e+01,\n",
       "        3.74972600e-01, 3.20638180e-01, 1.39785171e-01, 6.08381004e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.74103492e-01,\n",
       "        1.57439277e-01, 1.04578055e-01, 4.99242020e+01, 0.00000000e+00,\n",
       "        4.56996202e-01, 0.00000000e+00, 0.00000000e+00, 3.30871165e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.93447495e-01,\n",
       "        0.00000000e+00, 7.96321630e-02, 0.00000000e+00, 6.90334260e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.24377243e-02, 1.17385745e+00,\n",
       "        0.00000000e+00, 4.93547827e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55.74189383, 55.73287559, 55.72385735, 55.71483911, 55.70582086,\n",
       "       55.69680262, 55.68778438, 55.67876614, 55.6697479 , 55.66072966,\n",
       "       55.65171142, 55.64269317, 55.63367493, 55.62465669, 55.61563845,\n",
       "       55.60662021, 55.59760197, 55.58858373, 55.57956548, 55.57054724,\n",
       "       55.561529  , 55.55251076, 55.54349252, 55.53447428, 55.52545604,\n",
       "       55.51643779, 55.50741955, 55.49840131, 55.48938307, 55.48036483,\n",
       "       55.47134659, 55.46232835, 55.4533101 , 55.44429186, 55.43527362,\n",
       "       55.42625538, 55.41723714, 55.4082189 , 55.39920066, 55.39018241,\n",
       "       55.38116417, 55.37214593, 55.36312769, 55.35410945, 55.34509121,\n",
       "       55.33607297, 55.32705472, 55.31803648, 55.30901824, 55.3       ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.63875976936617\n",
      "41.80458523145139\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
