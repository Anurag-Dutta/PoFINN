{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "2445    55.786985\n",
       "2446    55.777967\n",
       "2447    55.768949\n",
       "2448    55.759930\n",
       "2449    55.750912\n",
       "Name: C8, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c8_interpolated_2350_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "2345     0.157439\n",
       "2346     0.000000\n",
       "2347     0.000000\n",
       "2348     0.104578\n",
       "2349     0.061171\n",
       "Name: C8, Length: 2350, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2350)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.987115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.774230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87.561345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.348459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.200000  0.000298\n",
       "1     87.987115  0.000298\n",
       "2     87.774230  0.000297\n",
       "3     87.561345  0.000297\n",
       "4     87.348459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 85.7336  # Value for C0\n",
    "K0 = -0.0020  # Value for K0\n",
    "K1 = 0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0125    # Value for b\n",
    "c = 2.3008    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.200000    87.987115    87.774230    87.561345    87.348459   \n",
      "351    87.987115    87.774230    87.561345    87.348459    87.135574   \n",
      "352    87.774230    87.561345    87.348459    87.135574    86.922689   \n",
      "353    87.561345    87.348459    87.135574    86.922689    86.709804   \n",
      "354    87.348459    87.135574    86.922689    86.709804    86.496919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.135574    86.922689    86.709804    86.496919    86.294538  ...   \n",
      "351    86.922689    86.709804    86.496919    86.294538    86.221709  ...   \n",
      "352    86.709804    86.496919    86.294538    86.221709    86.148880  ...   \n",
      "353    86.496919    86.294538    86.221709    86.148880    86.076050  ...   \n",
      "354    86.294538    86.221709    86.148880    86.076050    86.003221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   76.094351    0.000263   76.058870    0.000263   76.023389    0.000263   \n",
      "351   76.058870    0.000263   76.023389    0.000263   75.987909    0.000262   \n",
      "352   76.023389    0.000263   75.987909    0.000262   75.952428    0.000262   \n",
      "353   75.987909    0.000262   75.952428    0.000262   75.916947    0.000262   \n",
      "354   75.952428    0.000262   75.916947    0.000262   75.881466    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   75.987909    0.000262   75.952428    0.000262  \n",
      "351   75.952428    0.000262   75.916947    0.000262  \n",
      "352   75.916947    0.000262   75.881466    0.000262  \n",
      "353   75.881466    0.000262   75.845985    0.000262  \n",
      "354   75.845985    0.000262   75.810504    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 1, 251) (1900, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 3s 23ms/step - loss: 4411.1514 - val_loss: 2372.0181\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4166.4766 - val_loss: 2274.2390\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4063.5818 - val_loss: 2211.4885\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3961.9099 - val_loss: 2157.5955\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3859.8843 - val_loss: 2108.4897\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 3771.4548 - val_loss: 2061.2136\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 3685.9136 - val_loss: 2016.4824\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3602.8230 - val_loss: 1973.4175\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3521.8728 - val_loss: 1931.8665\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3442.8513 - val_loss: 1891.7278\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3365.6167 - val_loss: 1852.9286\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3290.0718 - val_loss: 1815.4143\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3216.1399 - val_loss: 1779.1393\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3143.7615 - val_loss: 1744.0667\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3072.8892 - val_loss: 1710.1632\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3003.4792 - val_loss: 1677.3995\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2935.4954 - val_loss: 1645.7490\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2868.9055 - val_loss: 1615.1870\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2803.6802 - val_loss: 1585.6899\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2739.7915 - val_loss: 1557.2354\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2677.2139 - val_loss: 1529.7977\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2615.9236 - val_loss: 1503.1353\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2548.5576 - val_loss: 1472.9025\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2483.0798 - val_loss: 1446.3428\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2420.9099 - val_loss: 1421.3348\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2360.9897 - val_loss: 1397.6390\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2302.9175 - val_loss: 1375.1176\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2246.4712 - val_loss: 1353.6876\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2191.5178 - val_loss: 1333.2913\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2137.9692 - val_loss: 1313.8868\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2085.7542 - val_loss: 1295.0513\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2039.6857 - val_loss: 1278.4111\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1984.3560 - val_loss: 1259.9956\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1931.1851 - val_loss: 1242.9608\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1880.2220 - val_loss: 1227.1034\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1831.0641 - val_loss: 1212.3031\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1783.4915 - val_loss: 1198.4835\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1737.3665 - val_loss: 1185.5905\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1692.5948 - val_loss: 1173.5800\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1649.1055 - val_loss: 1162.4163\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1606.8409 - val_loss: 1152.0679\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1565.7542 - val_loss: 1142.5062\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1525.8040 - val_loss: 1133.7054\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1486.9541 - val_loss: 1125.6410\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1449.1727 - val_loss: 1118.2906\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1412.4296 - val_loss: 1111.6323\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1376.6978 - val_loss: 1105.6453\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1341.9509 - val_loss: 1100.3099\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1308.1652 - val_loss: 1095.6067\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1275.3179 - val_loss: 1091.5170\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1243.3867 - val_loss: 1088.0225\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1212.3508 - val_loss: 1085.1055\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1182.1901 - val_loss: 1082.7487\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1152.8853 - val_loss: 1080.9351\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1124.4165 - val_loss: 1079.6478\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1096.7657 - val_loss: 1078.8707\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1069.9158 - val_loss: 1078.5875\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1043.8484 - val_loss: 1078.7823\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1018.5468 - val_loss: 1079.4398\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 993.9941 - val_loss: 1080.5443\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 970.1743 - val_loss: 1082.0808\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 947.0710 - val_loss: 1084.0344\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 924.6683 - val_loss: 1086.3903\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 902.9512 - val_loss: 1089.1339\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 881.9043 - val_loss: 1092.2510\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 861.5125 - val_loss: 1095.7277\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 841.7613 - val_loss: 1099.5494\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 822.6359 - val_loss: 1103.7028\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 804.1223 - val_loss: 1108.1741\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 786.2062 - val_loss: 1112.9500\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 768.8742 - val_loss: 1118.0170\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 752.1118 - val_loss: 1123.3622\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 735.9061 - val_loss: 1128.9727\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 720.2438 - val_loss: 1134.8358\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 705.1117 - val_loss: 1140.9388\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 690.4967 - val_loss: 1147.2695\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 676.3863 - val_loss: 1153.8158\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 662.7676 - val_loss: 1160.5653\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 649.6287 - val_loss: 1167.5063\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 636.9568 - val_loss: 1174.6273\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 624.7401 - val_loss: 1181.9167\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 612.9667 - val_loss: 1189.3632\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 601.6249 - val_loss: 1196.9556\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 590.7028 - val_loss: 1204.6830\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 580.1895 - val_loss: 1212.5342\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 570.0735 - val_loss: 1220.4963\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 560.3436 - val_loss: 1228.5155\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 550.9537 - val_loss: 1236.3225\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 538.5010 - val_loss: 1249.0475\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 527.8882 - val_loss: 1258.7048\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 518.4087 - val_loss: 1268.1495\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 509.6500 - val_loss: 1277.4866\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 501.4542 - val_loss: 1286.7577\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 493.7383 - val_loss: 1295.9805\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 486.4500 - val_loss: 1305.1616\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 479.5521 - val_loss: 1314.3031\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 473.0156 - val_loss: 1323.4036\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 466.8169 - val_loss: 1332.4591\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 460.9360 - val_loss: 1341.4669\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 455.3553 - val_loss: 1350.4222\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 450.0586 - val_loss: 1359.3192\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 445.0320 - val_loss: 1368.1539\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 440.2618 - val_loss: 1376.9208\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 435.7359 - val_loss: 1385.6145\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 431.4424 - val_loss: 1394.2305\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 427.3708 - val_loss: 1402.7637\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 423.5104 - val_loss: 1411.2094\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 419.8517 - val_loss: 1419.5625\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 416.3851 - val_loss: 1427.8197\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.1020 - val_loss: 1435.9764\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 409.9936 - val_loss: 1444.0288\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 407.0519 - val_loss: 1451.9725\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 404.2690 - val_loss: 1459.8046\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 401.6376 - val_loss: 1467.5216\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 399.1504 - val_loss: 1475.1212\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 396.8008 - val_loss: 1482.5990\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 394.5817 - val_loss: 1489.9536\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 392.4872 - val_loss: 1497.1829\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 390.5110 - val_loss: 1504.2837\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 388.6474 - val_loss: 1511.2546\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 386.8907 - val_loss: 1518.0946\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 385.2357 - val_loss: 1524.8015\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 383.6769 - val_loss: 1531.3741\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 382.2098 - val_loss: 1537.8114\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 380.8294 - val_loss: 1544.1128\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 379.5312 - val_loss: 1550.2766\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 378.3110 - val_loss: 1556.3036\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 377.1644 - val_loss: 1562.1931\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 376.0879 - val_loss: 1567.9451\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 375.0772 - val_loss: 1573.5597\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 374.1289 - val_loss: 1579.0372\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 373.2395 - val_loss: 1584.3778\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 372.4059 - val_loss: 1589.5814\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 371.6245 - val_loss: 1594.6503\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 370.8929 - val_loss: 1599.5851\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 370.2078 - val_loss: 1604.3857\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 369.5668 - val_loss: 1609.0540\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 368.9671 - val_loss: 1613.5914\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 368.4063 - val_loss: 1617.9984\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 367.8821 - val_loss: 1622.2773\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 367.3924 - val_loss: 1626.4298\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 366.9349 - val_loss: 1630.4570\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 366.5078 - val_loss: 1634.3616\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 366.1090 - val_loss: 1638.1448\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 365.7371 - val_loss: 1641.8076\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 365.3900 - val_loss: 1645.3540\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 365.0664 - val_loss: 1648.7844\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 364.7648 - val_loss: 1652.1019\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 364.4836 - val_loss: 1655.3083\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 364.2217 - val_loss: 1658.4062\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 363.9777 - val_loss: 1661.3973\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 363.7505 - val_loss: 1664.2845\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 363.5390 - val_loss: 1667.0696\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 363.3420 - val_loss: 1669.7554\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 363.1587 - val_loss: 1672.3434\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 362.9882 - val_loss: 1674.8375\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 362.8295 - val_loss: 1677.2388\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 362.6818 - val_loss: 1679.5497\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 362.5445 - val_loss: 1681.7737\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 362.4168 - val_loss: 1683.9120\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 362.2980 - val_loss: 1685.9673\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 362.1875 - val_loss: 1687.9421\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 362.0848 - val_loss: 1689.8391\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 361.9893 - val_loss: 1691.6609\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 361.9004 - val_loss: 1693.4073\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 361.8179 - val_loss: 1695.0835\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 361.7411 - val_loss: 1696.6903\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 361.6697 - val_loss: 1698.2306\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 361.6034 - val_loss: 1699.7068\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 361.5415 - val_loss: 1701.1189\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 361.4841 - val_loss: 1702.4717\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 361.4308 - val_loss: 1703.7665\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 361.3811 - val_loss: 1705.0043\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 361.3349 - val_loss: 1706.1884\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 361.2919 - val_loss: 1707.3199\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 361.2520 - val_loss: 1708.4009\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 361.2148 - val_loss: 1709.4336\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 361.1802 - val_loss: 1710.4194\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 361.1480 - val_loss: 1711.3607\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 361.1180 - val_loss: 1712.2587\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 361.0901 - val_loss: 1713.1145\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 361.0641 - val_loss: 1713.9305\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 361.0400 - val_loss: 1714.7091\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 361.0174 - val_loss: 1715.4498\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.9965 - val_loss: 1716.1561\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 360.9770 - val_loss: 1716.8280\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 360.9588 - val_loss: 1717.4681\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.9419 - val_loss: 1718.0768\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 360.9261 - val_loss: 1718.6553\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 360.9113 - val_loss: 1719.2061\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.8977 - val_loss: 1719.7291\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 360.8850 - val_loss: 1720.2267\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.8731 - val_loss: 1720.6997\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 360.8621 - val_loss: 1721.1482\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.8518 - val_loss: 1721.5740\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 360.8423 - val_loss: 1721.9784\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 360.8334 - val_loss: 1722.3625\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 360.8251 - val_loss: 1722.7268\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 360.8174 - val_loss: 1723.0719\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 360.8102 - val_loss: 1723.3990\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 360.8035 - val_loss: 1723.7096\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.7973 - val_loss: 1724.0033\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.7915 - val_loss: 1724.2819\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.7863 - val_loss: 1724.5460\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7812 - val_loss: 1724.7964\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.7766 - val_loss: 1725.0322\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.7723 - val_loss: 1725.2567\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7683 - val_loss: 1725.4678\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7646 - val_loss: 1725.6681\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 360.7613 - val_loss: 1725.8578\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.7581 - val_loss: 1726.0365\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 360.7552 - val_loss: 1726.2056\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 360.7526 - val_loss: 1726.3661\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 360.7500 - val_loss: 1726.5171\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.7478 - val_loss: 1726.6600\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7456 - val_loss: 1726.7947\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.7437 - val_loss: 1726.9215\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7420 - val_loss: 1727.0425\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 360.7403 - val_loss: 1727.1553\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.7389 - val_loss: 1727.2623\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7376 - val_loss: 1727.3638\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.7363 - val_loss: 1727.4594\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7351 - val_loss: 1727.5485\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7342 - val_loss: 1727.6331\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7333 - val_loss: 1727.7131\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7325 - val_loss: 1727.7888\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7317 - val_loss: 1727.8595\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7311 - val_loss: 1727.9266\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7305 - val_loss: 1727.9896\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 360.7300 - val_loss: 1728.0487\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 360.7295 - val_loss: 1728.1052\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.7291 - val_loss: 1728.1576\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7289 - val_loss: 1728.2070\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7285 - val_loss: 1728.2537\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7283 - val_loss: 1728.2970\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7281 - val_loss: 1728.3378\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7280 - val_loss: 1728.3773\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.7278 - val_loss: 1728.4128\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 360.7279 - val_loss: 1728.4475\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7278 - val_loss: 1728.4800\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7278 - val_loss: 1728.5104\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7278 - val_loss: 1728.5385\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7278 - val_loss: 1728.5654\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7280 - val_loss: 1728.5909\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7281 - val_loss: 1728.6145\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7281 - val_loss: 1728.6365\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7284 - val_loss: 1728.6581\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7285 - val_loss: 1728.6780\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7287 - val_loss: 1728.6956\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7289 - val_loss: 1728.7128\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7290 - val_loss: 1728.7288\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7293 - val_loss: 1728.7448\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7294 - val_loss: 1728.7594\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7297 - val_loss: 1728.7721\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7299 - val_loss: 1728.7855\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7301 - val_loss: 1728.7963\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7303 - val_loss: 1728.8081\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7307 - val_loss: 1728.8187\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7308 - val_loss: 1728.8281\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7311 - val_loss: 1728.8376\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7314 - val_loss: 1728.8457\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7317 - val_loss: 1728.8536\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7320 - val_loss: 1728.8612\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7322 - val_loss: 1728.8685\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7325 - val_loss: 1728.8749\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7328 - val_loss: 1728.8811\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7330 - val_loss: 1728.8864\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 360.7333 - val_loss: 1728.8921\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7335 - val_loss: 1728.8967\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7338 - val_loss: 1728.9023\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7341 - val_loss: 1728.9059\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7344 - val_loss: 1728.9104\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7346 - val_loss: 1728.9142\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7349 - val_loss: 1728.9180\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7352 - val_loss: 1728.9213\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7354 - val_loss: 1728.9246\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7357 - val_loss: 1728.9279\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7359 - val_loss: 1728.9305\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7361 - val_loss: 1728.9324\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7365 - val_loss: 1728.9352\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7368 - val_loss: 1728.9376\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7370 - val_loss: 1728.9407\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7372 - val_loss: 1728.9423\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7374 - val_loss: 1728.9447\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7376 - val_loss: 1728.9457\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7379 - val_loss: 1728.9479\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7381 - val_loss: 1728.9490\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7383 - val_loss: 1728.9507\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7385 - val_loss: 1728.9523\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7387 - val_loss: 1728.9532\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7390 - val_loss: 1728.9540\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7391 - val_loss: 1728.9546\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7394 - val_loss: 1728.9565\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7395 - val_loss: 1728.9575\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7398 - val_loss: 1728.9585\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7399 - val_loss: 1728.9592\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 360.7402 - val_loss: 1728.9601\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7403 - val_loss: 1728.9611\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7404 - val_loss: 1728.9615\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7408 - val_loss: 1728.9625\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7408 - val_loss: 1728.9628\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7410 - val_loss: 1728.9640\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7411 - val_loss: 1728.9646\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7414 - val_loss: 1728.9653\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7415 - val_loss: 1728.9663\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7417 - val_loss: 1728.9668\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7419 - val_loss: 1728.9673\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7421 - val_loss: 1728.9681\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7421 - val_loss: 1728.9689\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7423 - val_loss: 1728.9702\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7424 - val_loss: 1728.9714\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7425 - val_loss: 1728.9730\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7427 - val_loss: 1728.9755\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7429 - val_loss: 1728.9801\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7430 - val_loss: 1728.9769\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7464 - val_loss: 1727.8352\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 361.1567 - val_loss: 1735.1758\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.6657 - val_loss: 1734.2845\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.6849 - val_loss: 1734.5074\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.6777 - val_loss: 1734.1403\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.6791 - val_loss: 1733.7947\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.6823 - val_loss: 1733.4734\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.6858 - val_loss: 1733.1741\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.6895 - val_loss: 1732.8954\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.6933 - val_loss: 1732.6355\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 360.6970 - val_loss: 1732.3950\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7006 - val_loss: 1732.1703\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7041 - val_loss: 1731.9603\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7074 - val_loss: 1731.7655\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7105 - val_loss: 1731.5833\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7136 - val_loss: 1731.4135\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7166 - val_loss: 1731.2560\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7192 - val_loss: 1731.1085\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7218 - val_loss: 1730.9711\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7242 - val_loss: 1730.8429\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7265 - val_loss: 1730.7234\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7286 - val_loss: 1730.6122\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7306 - val_loss: 1730.5079\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7326 - val_loss: 1730.4111\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7344 - val_loss: 1730.3209\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7361 - val_loss: 1730.2371\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7375 - val_loss: 1730.1576\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7391 - val_loss: 1730.0846\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7405 - val_loss: 1730.0161\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7417 - val_loss: 1729.9520\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7429 - val_loss: 1729.8925\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7440 - val_loss: 1729.8365\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7451 - val_loss: 1729.7845\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7461 - val_loss: 1729.7358\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7471 - val_loss: 1729.6909\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7479 - val_loss: 1729.6482\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7488 - val_loss: 1729.6090\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7495 - val_loss: 1729.5720\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7502 - val_loss: 1729.5378\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 360.7509 - val_loss: 1729.5054\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.7515 - val_loss: 1729.4760\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7520 - val_loss: 1729.4478\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7526 - val_loss: 1729.4215\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7532 - val_loss: 1729.3977\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7537 - val_loss: 1729.3750\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7539 - val_loss: 1729.3536\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7544 - val_loss: 1729.3335\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7549 - val_loss: 1729.3152\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7552 - val_loss: 1729.2977\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7555 - val_loss: 1729.2809\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7558 - val_loss: 1729.2662\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7561 - val_loss: 1729.2522\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7564 - val_loss: 1729.2390\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7567 - val_loss: 1729.2272\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7569 - val_loss: 1729.2161\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7571 - val_loss: 1729.2056\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7573 - val_loss: 1729.1957\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7575 - val_loss: 1729.1865\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7577 - val_loss: 1729.1776\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7578 - val_loss: 1729.1694\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7580 - val_loss: 1729.1616\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7581 - val_loss: 1729.1547\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7583 - val_loss: 1729.1483\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7585 - val_loss: 1729.1431\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7585 - val_loss: 1729.1370\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7587 - val_loss: 1729.1321\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7587 - val_loss: 1729.1273\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7589 - val_loss: 1729.1230\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 360.7589 - val_loss: 1729.1188\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7590 - val_loss: 1729.1147\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7590 - val_loss: 1729.1104\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7591 - val_loss: 1729.1069\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7591 - val_loss: 1729.1031\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7593 - val_loss: 1729.1002\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7593 - val_loss: 1729.0964\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7594 - val_loss: 1729.0934\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7595 - val_loss: 1729.0914\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7595 - val_loss: 1729.0889\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7596 - val_loss: 1729.0865\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7596 - val_loss: 1729.0846\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7596 - val_loss: 1729.0833\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7597 - val_loss: 1729.0814\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7597 - val_loss: 1729.0800\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7597 - val_loss: 1729.0787\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7598 - val_loss: 1729.0776\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7597 - val_loss: 1729.0767\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7598 - val_loss: 1729.0748\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7598 - val_loss: 1729.0735\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7599 - val_loss: 1729.0728\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7599 - val_loss: 1729.0714\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 360.7598 - val_loss: 1729.0704\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7599 - val_loss: 1729.0697\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7599 - val_loss: 1729.0695\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7599 - val_loss: 1729.0687\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7599 - val_loss: 1729.0674\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 360.7599 - val_loss: 1729.0669\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0658\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7600 - val_loss: 1729.0657\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7600 - val_loss: 1729.0658\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0654\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0652\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0649\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7599 - val_loss: 1729.0645\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7599 - val_loss: 1729.0643\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0638\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0645\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0638\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0638\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0635\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0635\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0635\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0626\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0624\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0621\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0619\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0621\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0621\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0625\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0619\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 360.7601 - val_loss: 1729.0619\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7600 - val_loss: 1729.0619\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0619\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0620\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7600 - val_loss: 1729.0620\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0619\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0619\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0619\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7600 - val_loss: 1729.0615\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7600 - val_loss: 1729.0615\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0612\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0609\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0605\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0602\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0602\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0602\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0610\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0609\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0605\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0605\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0605\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0609\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0607\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0607\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 360.7600 - val_loss: 1729.0605\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7600 - val_loss: 1729.0598\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7600 - val_loss: 1729.0596\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7600 - val_loss: 1729.0592\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7601 - val_loss: 1729.0588\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0583\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0582\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7601 - val_loss: 1729.0581\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7601 - val_loss: 1729.0577\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7601 - val_loss: 1729.0577\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7600 - val_loss: 1729.0574\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7601 - val_loss: 1729.0573\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0568\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0565\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0565\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0565\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0565\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0565\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0565\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0565\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0565\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0571\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0569\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0569\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 360.7602 - val_loss: 1729.0573\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7601 - val_loss: 1729.0574\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7601 - val_loss: 1729.0573\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7601 - val_loss: 1729.0574\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7601 - val_loss: 1729.0574\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0576\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0579\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0582\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0583\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7601 - val_loss: 1729.0582\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7601 - val_loss: 1729.0582\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 360.7602 - val_loss: 1729.0582\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0583\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0586\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.7602 - val_loss: 1729.0588\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0586\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0582\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 360.7602 - val_loss: 1729.0582\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(85.7336, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0020, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0125, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3008, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 410ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.51796219e+01, 6.96545285e+01, 6.84444444e+01, 6.71979342e+01,\n",
       "        6.35367088e+01, 0.00000000e+00, 0.00000000e+00, 4.61061150e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.45991400e-01,\n",
       "        6.67689680e-01, 6.55913865e+01, 6.53644958e+01, 6.51376050e+01,\n",
       "        5.73102950e-01, 0.00000000e+00, 6.61563609e+01, 6.59168651e+01,\n",
       "        6.56838235e+01, 6.54556933e+01, 6.52300420e+01, 6.99234360e+01,\n",
       "        6.87133520e+01, 6.74752451e+01, 0.00000000e+00, 4.26903900e-01,\n",
       "        1.72087370e-01, 6.53224790e+01, 7.02082166e+01, 6.82063492e+01,\n",
       "        6.69843685e+01, 6.57834080e+01, 1.77785600e-01, 6.80144608e+01,\n",
       "        6.67665616e+01, 6.60410481e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.06198692e+01, 0.00000000e+00, 5.15083492e-01, 1.45723358e-01,\n",
       "        1.05602193e+00, 0.00000000e+00, 1.13051116e-01, 6.77525560e+01,\n",
       "        2.82885670e-01, 3.54694840e-01, 0.00000000e+00, 6.53728992e+01,\n",
       "        6.51460084e+01, 6.84752568e+01, 6.72649594e+01, 6.60496337e+01,\n",
       "        0.00000000e+00, 6.82917717e+01, 6.70438726e+01, 6.62007119e+01,\n",
       "        2.59407600e-01, 4.76310400e-01, 6.75214636e+01, 0.00000000e+00,\n",
       "        6.82455532e+01, 6.69976541e+01, 6.61741013e+01, 0.00000000e+00,\n",
       "        6.65111695e+01, 6.57930672e+01, 7.22844544e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.84504166e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.13289070e+00, 6.20516658e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.41262894e+01, 5.85166156e-01, 1.26371264e+00, 0.00000000e+00,\n",
       "        2.62031943e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.38526142e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.11877668e-01, 3.39882106e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.15224496e-02, 1.12400830e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56.64371797, 56.63469973, 56.62568149, 56.61666325, 56.60764501,\n",
       "       56.59862677, 56.58960853, 56.58059028, 56.57157204, 56.5625538 ,\n",
       "       56.55353556, 56.54451732, 56.53549908, 56.52648084, 56.51746259,\n",
       "       56.50844435, 56.49942611, 56.49040787, 56.48138963, 56.47237139,\n",
       "       56.46335315, 56.4543349 , 56.44531666, 56.43629842, 56.42728018,\n",
       "       56.41826194, 56.4092437 , 56.40022546, 56.39120721, 56.38218897,\n",
       "       56.37317073, 56.36415249, 56.35513425, 56.34611601, 56.33709777,\n",
       "       56.32807952, 56.31906128, 56.31004304, 56.3010248 , 56.29200656,\n",
       "       56.28298832, 56.27397008, 56.26495183, 56.25593359, 56.24691535,\n",
       "       56.23789711, 56.22887887, 56.21986063, 56.21084239, 56.20182414,\n",
       "       56.1928059 , 56.18378766, 56.17476942, 56.16575118, 56.15673294,\n",
       "       56.1477147 , 56.13869645, 56.12967821, 56.12065997, 56.11164173,\n",
       "       56.10262349, 56.09360525, 56.08458701, 56.07556876, 56.06655052,\n",
       "       56.05753228, 56.04851404, 56.0394958 , 56.03047756, 56.02145932,\n",
       "       56.01244107, 56.00342283, 55.99440459, 55.98538635, 55.97636811,\n",
       "       55.96734987, 55.95833163, 55.94931338, 55.94029514, 55.9312769 ,\n",
       "       55.92225866, 55.91324042, 55.90422218, 55.89520394, 55.88618569,\n",
       "       55.87716745, 55.86814921, 55.85913097, 55.85011273, 55.84109449,\n",
       "       55.83207625, 55.823058  , 55.81403976, 55.80502152, 55.79600328,\n",
       "       55.78698504, 55.7779668 , 55.76894856, 55.75993031, 55.75091207])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.78553880017365\n",
      "36.36263431357591\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
