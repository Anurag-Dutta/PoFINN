{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "1845    60.734664\n",
       "1846    60.720658\n",
       "1847    60.706653\n",
       "1848    60.692647\n",
       "1849    60.678641\n",
       "Name: C8, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c8_interpolated_1750_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "1745     0.000000\n",
       "1746     0.144706\n",
       "1747     0.288644\n",
       "1748     0.229632\n",
       "1749     0.000000\n",
       "Name: C8, Length: 1750, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1750)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.987115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.774230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87.561345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.348459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.200000  0.000298\n",
       "1     87.987115  0.000298\n",
       "2     87.774230  0.000297\n",
       "3     87.561345  0.000297\n",
       "4     87.348459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 85.7336  # Value for C0\n",
    "K0 = -0.0020  # Value for K0\n",
    "K1 = 0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0125    # Value for b\n",
    "c = 2.3008    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.200000    87.987115    87.774230    87.561345    87.348459   \n",
      "351    87.987115    87.774230    87.561345    87.348459    87.135574   \n",
      "352    87.774230    87.561345    87.348459    87.135574    86.922689   \n",
      "353    87.561345    87.348459    87.135574    86.922689    86.709804   \n",
      "354    87.348459    87.135574    86.922689    86.709804    86.496919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.135574    86.922689    86.709804    86.496919    86.294538  ...   \n",
      "351    86.922689    86.709804    86.496919    86.294538    86.221709  ...   \n",
      "352    86.709804    86.496919    86.294538    86.221709    86.148880  ...   \n",
      "353    86.496919    86.294538    86.221709    86.148880    86.076050  ...   \n",
      "354    86.294538    86.221709    86.148880    86.076050    86.003221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   76.094351    0.000263   76.058870    0.000263   76.023389    0.000263   \n",
      "351   76.058870    0.000263   76.023389    0.000263   75.987909    0.000262   \n",
      "352   76.023389    0.000263   75.987909    0.000262   75.952428    0.000262   \n",
      "353   75.987909    0.000262   75.952428    0.000262   75.916947    0.000262   \n",
      "354   75.952428    0.000262   75.916947    0.000262   75.881466    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   75.987909    0.000262   75.952428    0.000262  \n",
      "351   75.952428    0.000262   75.916947    0.000262  \n",
      "352   75.916947    0.000262   75.881466    0.000262  \n",
      "353   75.881466    0.000262   75.845985    0.000262  \n",
      "354   75.845985    0.000262   75.810504    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 1, 251) (1300, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 2s 37ms/step - loss: 4972.5469 - val_loss: 3395.1309\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4906.0947 - val_loss: 3361.0605\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4846.0732 - val_loss: 3326.6890\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4800.9331 - val_loss: 3299.5127\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4759.6162 - val_loss: 3272.7671\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4718.9419 - val_loss: 3246.4731\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4678.8354 - val_loss: 3220.5413\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4639.1855 - val_loss: 3194.9109\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4599.9253 - val_loss: 3169.5466\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4561.0107 - val_loss: 3144.4250\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4522.4146 - val_loss: 3119.5310\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4484.1177 - val_loss: 3094.8555\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4446.1079 - val_loss: 3070.4141\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4401.5322 - val_loss: 3036.9680\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4352.3247 - val_loss: 3010.0496\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4310.4922 - val_loss: 2983.7908\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4269.6880 - val_loss: 2958.1057\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4229.6890 - val_loss: 2932.8665\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4190.3120 - val_loss: 2907.9956\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4151.4487 - val_loss: 2883.5430\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4104.3384 - val_loss: 2854.1638\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4059.0981 - val_loss: 2828.2134\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4016.5183 - val_loss: 2802.8713\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3975.1187 - val_loss: 2778.0256\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3934.6226 - val_loss: 2753.5857\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3894.8394 - val_loss: 2729.4939\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3855.6514 - val_loss: 2705.7141\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3816.9829 - val_loss: 2682.2212\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3778.7834 - val_loss: 2658.9976\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3741.0144 - val_loss: 2636.0288\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3703.6482 - val_loss: 2613.3044\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3666.6609 - val_loss: 2590.8154\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3630.0359 - val_loss: 2568.5542\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3593.7583 - val_loss: 2546.5151\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3557.8147 - val_loss: 2524.6924\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3522.1953 - val_loss: 2503.0813\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3486.8911 - val_loss: 2481.6777\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3451.8936 - val_loss: 2460.4778\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3417.1963 - val_loss: 2439.4783\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3382.7927 - val_loss: 2418.6755\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3348.6772 - val_loss: 2398.0674\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3314.8447 - val_loss: 2377.6494\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3281.2910 - val_loss: 2357.4202\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3248.0107 - val_loss: 2337.3752\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3215.0007 - val_loss: 2317.5081\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3182.2571 - val_loss: 2297.7952\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3146.0393 - val_loss: 2267.5500\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3098.0342 - val_loss: 2243.6345\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3059.7693 - val_loss: 2220.6187\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3022.9053 - val_loss: 2198.5112\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2987.1824 - val_loss: 2177.0757\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2952.3135 - val_loss: 2156.1614\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2918.1250 - val_loss: 2135.6777\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2884.5090 - val_loss: 2115.5671\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2851.3965 - val_loss: 2095.7908\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2818.7375 - val_loss: 2076.3203\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2786.4968 - val_loss: 2057.1343\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2754.6462 - val_loss: 2038.2156\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2723.1641 - val_loss: 2019.5524\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2692.0344 - val_loss: 2001.1323\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2661.2412 - val_loss: 1982.9470\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2630.7727 - val_loss: 1964.9883\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2600.6179 - val_loss: 1947.2501\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2570.7683 - val_loss: 1929.7257\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2541.2156 - val_loss: 1912.4104\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2511.9536 - val_loss: 1895.3000\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2482.9749 - val_loss: 1878.3894\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2454.2739 - val_loss: 1861.6753\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2425.8464 - val_loss: 1845.1543\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2397.6873 - val_loss: 1828.8232\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2369.7913 - val_loss: 1812.6791\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2342.1550 - val_loss: 1796.7189\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2314.7747 - val_loss: 1780.9403\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2287.6475 - val_loss: 1765.3406\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2260.7690 - val_loss: 1749.9178\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2234.1360 - val_loss: 1734.6699\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2207.7468 - val_loss: 1719.5945\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2181.5974 - val_loss: 1704.6898\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2155.6858 - val_loss: 1689.9532\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2130.0093 - val_loss: 1675.3837\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 2104.5657 - val_loss: 1660.9784\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2079.3518 - val_loss: 1646.7361\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2054.3665 - val_loss: 1632.6527\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2029.6064 - val_loss: 1618.7250\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2005.0710 - val_loss: 1604.9393\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1980.6866 - val_loss: 1588.5275\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1949.2444 - val_loss: 1571.4034\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1919.3976 - val_loss: 1554.7318\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1890.7255 - val_loss: 1538.8718\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1863.1814 - val_loss: 1523.6227\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1836.4796 - val_loss: 1508.8455\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1810.4376 - val_loss: 1494.4543\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1784.9446 - val_loss: 1480.3973\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1759.9281 - val_loss: 1466.6378\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1735.3385 - val_loss: 1453.1498\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1711.1382 - val_loss: 1439.9133\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1687.3013 - val_loss: 1426.9142\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1663.8055 - val_loss: 1414.1398\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1640.6329 - val_loss: 1401.5803\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1617.7694 - val_loss: 1389.2272\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1595.2025 - val_loss: 1377.0731\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1572.9220 - val_loss: 1365.1122\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1550.9189 - val_loss: 1353.3392\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1529.1859 - val_loss: 1341.7488\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1507.7148 - val_loss: 1330.3370\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1486.5001 - val_loss: 1319.1001\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1465.5359 - val_loss: 1308.0343\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1444.8173 - val_loss: 1297.1360\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1424.3389 - val_loss: 1286.4027\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1404.0972 - val_loss: 1275.8314\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 1384.0876 - val_loss: 1265.4193\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1364.3065 - val_loss: 1255.1641\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1344.7504 - val_loss: 1245.0637\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1325.4160 - val_loss: 1235.1157\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1306.3008 - val_loss: 1225.3182\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1287.4008 - val_loss: 1215.6691\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1268.7137 - val_loss: 1206.1664\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1250.2368 - val_loss: 1196.8085\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1231.9678 - val_loss: 1187.5933\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1213.9041 - val_loss: 1178.5194\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1196.0432 - val_loss: 1169.5854\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1178.3837 - val_loss: 1160.7896\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1160.9222 - val_loss: 1152.1298\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1143.6572 - val_loss: 1143.6057\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1126.5868 - val_loss: 1135.2152\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1109.7091 - val_loss: 1126.9568\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1093.0219 - val_loss: 1118.8295\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1076.5237 - val_loss: 1110.8317\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1060.2123 - val_loss: 1102.9620\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1044.0859 - val_loss: 1095.2197\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1028.1437 - val_loss: 1087.6033\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1012.3832 - val_loss: 1080.1115\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 996.8030 - val_loss: 1072.7429\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 981.4016 - val_loss: 1065.4967\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 966.1774 - val_loss: 1058.3716\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 951.1285 - val_loss: 1051.3663\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 936.2540 - val_loss: 1044.4802\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 921.5521 - val_loss: 1037.7115\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 907.0214 - val_loss: 1031.0593\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 892.6608 - val_loss: 1024.5232\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 878.4686 - val_loss: 1018.1014\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 864.4434 - val_loss: 1011.7935\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 850.5842 - val_loss: 1005.5976\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 836.8892 - val_loss: 999.5134\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 823.3574 - val_loss: 993.5396\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 809.9874 - val_loss: 987.6749\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 796.7775 - val_loss: 981.9189\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 783.7271 - val_loss: 976.2704\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 770.8345 - val_loss: 970.7281\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 758.0986 - val_loss: 965.2916\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 745.5183 - val_loss: 959.9593\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 733.0920 - val_loss: 954.7307\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 720.8187 - val_loss: 949.6047\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 708.6976 - val_loss: 944.5806\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 696.7272 - val_loss: 939.6572\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 684.9059 - val_loss: 934.8334\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 673.2327 - val_loss: 930.1085\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 661.7070 - val_loss: 925.4817\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 650.3273 - val_loss: 920.9522\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 639.0928 - val_loss: 916.5187\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 628.0020 - val_loss: 912.1807\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 617.0537 - val_loss: 907.9366\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 606.2472 - val_loss: 903.7863\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 595.5807 - val_loss: 899.7286\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 585.0539 - val_loss: 895.7625\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 574.6651 - val_loss: 891.8871\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 564.4136 - val_loss: 888.1019\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 554.2980 - val_loss: 884.4055\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 544.3174 - val_loss: 880.7972\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 534.4707 - val_loss: 877.2764\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 524.7570 - val_loss: 873.8419\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 515.1749 - val_loss: 870.4931\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 505.7236 - val_loss: 867.2291\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 496.4020 - val_loss: 864.0486\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 487.2089 - val_loss: 860.9510\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 478.1434 - val_loss: 857.9359\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 469.2046 - val_loss: 855.0018\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 460.3911 - val_loss: 852.1483\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 451.7023 - val_loss: 849.3741\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 443.1369 - val_loss: 846.6785\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 434.6935 - val_loss: 844.0609\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 426.3719 - val_loss: 841.5204\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 418.1706 - val_loss: 839.0560\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 410.0886 - val_loss: 836.6668\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 402.1250 - val_loss: 834.3522\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 394.2789 - val_loss: 832.1110\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 386.5490 - val_loss: 829.9426\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 378.9344 - val_loss: 827.8463\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 371.4343 - val_loss: 825.8209\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 364.0473 - val_loss: 823.8657\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 356.7728 - val_loss: 821.9802\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 349.6096 - val_loss: 820.1631\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 342.5566 - val_loss: 818.4136\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 335.6130 - val_loss: 816.7312\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 328.7780 - val_loss: 815.1147\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 322.0502 - val_loss: 813.5635\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 315.4288 - val_loss: 812.0765\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 308.9127 - val_loss: 810.6533\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 302.5012 - val_loss: 809.2927\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 296.1928 - val_loss: 807.9940\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 289.9872 - val_loss: 806.7564\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 283.8831 - val_loss: 805.5790\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 277.8794 - val_loss: 804.4611\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 271.9752 - val_loss: 803.4016\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 266.1695 - val_loss: 802.4000\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 260.4616 - val_loss: 801.4552\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 254.8503 - val_loss: 800.5665\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 249.3345 - val_loss: 799.7330\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 243.9134 - val_loss: 798.9541\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 238.5864 - val_loss: 798.2288\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 233.3518 - val_loss: 797.5562\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 228.2092 - val_loss: 796.9356\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 223.1573 - val_loss: 796.3661\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 218.1953 - val_loss: 795.8470\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 213.3220 - val_loss: 795.3773\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 208.5369 - val_loss: 794.9564\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 203.8389 - val_loss: 794.5834\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 199.2267 - val_loss: 794.2573\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 194.6998 - val_loss: 793.9777\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 190.2570 - val_loss: 793.7433\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 185.8974 - val_loss: 793.5536\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 181.6201 - val_loss: 793.4077\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 177.4241 - val_loss: 793.3047\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 173.3084 - val_loss: 793.2440\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 169.2723 - val_loss: 793.2246\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 165.3146 - val_loss: 793.2458\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 161.4345 - val_loss: 793.3066\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 157.6311 - val_loss: 793.4066\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 153.9032 - val_loss: 793.5447\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 150.2500 - val_loss: 793.7202\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 146.6708 - val_loss: 793.9321\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 143.1644 - val_loss: 794.1799\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 139.7299 - val_loss: 794.4626\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 136.3665 - val_loss: 794.7795\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 133.0732 - val_loss: 795.1300\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 129.8492 - val_loss: 795.5129\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 126.6934 - val_loss: 795.9277\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 123.6049 - val_loss: 796.3734\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 120.5830 - val_loss: 796.8496\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 117.6265 - val_loss: 797.3550\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 114.7346 - val_loss: 797.8895\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 111.9065 - val_loss: 798.4517\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 109.1412 - val_loss: 799.0411\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 106.4378 - val_loss: 799.6572\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 103.7953 - val_loss: 800.2988\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 101.2131 - val_loss: 800.9652\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 98.6902 - val_loss: 801.6558\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 96.2255 - val_loss: 802.3699\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 93.8184 - val_loss: 803.1068\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 91.4678 - val_loss: 803.8655\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 89.1730 - val_loss: 804.6454\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 86.9330 - val_loss: 805.4458\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 84.7471 - val_loss: 806.2658\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 82.6143 - val_loss: 807.1050\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 80.5336 - val_loss: 807.9625\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 78.5044 - val_loss: 808.8375\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 76.5259 - val_loss: 809.7293\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 74.5971 - val_loss: 810.6375\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 72.7172 - val_loss: 811.5609\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 70.8852 - val_loss: 812.4993\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 69.1006 - val_loss: 813.4517\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 67.3623 - val_loss: 814.4177\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 65.6694 - val_loss: 815.3962\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 64.0213 - val_loss: 816.3869\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 62.4171 - val_loss: 817.3890\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 60.8561 - val_loss: 818.4020\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 59.3374 - val_loss: 819.4249\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 57.8602 - val_loss: 820.4575\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 56.4237 - val_loss: 821.4988\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 55.0272 - val_loss: 822.5485\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 53.6698 - val_loss: 823.6055\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 52.3508 - val_loss: 824.6698\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 51.0695 - val_loss: 825.7402\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 49.8250 - val_loss: 826.8165\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 48.6166 - val_loss: 827.8981\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 47.4436 - val_loss: 828.9843\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 46.3051 - val_loss: 830.0745\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 45.2006 - val_loss: 831.1682\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 44.1293 - val_loss: 832.2646\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 43.0905 - val_loss: 833.3636\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 42.0833 - val_loss: 834.4643\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 41.1072 - val_loss: 835.5664\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 40.1614 - val_loss: 836.6693\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 39.2454 - val_loss: 837.7722\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 38.3583 - val_loss: 838.8749\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 37.4995 - val_loss: 839.9769\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 36.6683 - val_loss: 841.0778\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 35.8641 - val_loss: 842.1768\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 35.0863 - val_loss: 843.2737\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 34.3341 - val_loss: 844.3680\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 33.6070 - val_loss: 845.4590\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 32.9043 - val_loss: 846.5469\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 32.2253 - val_loss: 847.6308\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 31.5696 - val_loss: 848.7101\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 30.9364 - val_loss: 849.7849\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 30.3253 - val_loss: 850.8542\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 29.7356 - val_loss: 851.9182\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 29.1668 - val_loss: 852.9761\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 28.6183 - val_loss: 854.0279\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 28.0895 - val_loss: 855.0730\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 27.5799 - val_loss: 856.1112\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 27.0889 - val_loss: 857.1418\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 26.6161 - val_loss: 858.1650\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 26.1609 - val_loss: 859.1801\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.7228 - val_loss: 860.1868\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3012 - val_loss: 861.1854\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 24.8957 - val_loss: 862.1749\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 24.5058 - val_loss: 863.1553\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 24.1311 - val_loss: 864.1264\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 23.7711 - val_loss: 865.0878\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 23.4253 - val_loss: 866.0397\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 23.0932 - val_loss: 866.9812\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.7744 - val_loss: 867.9127\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.4686 - val_loss: 868.8334\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.1752 - val_loss: 869.7437\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.8939 - val_loss: 870.6431\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.6243 - val_loss: 871.5314\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.3660 - val_loss: 872.4087\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.1185 - val_loss: 873.2744\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.8816 - val_loss: 874.1287\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.6548 - val_loss: 874.9713\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.4379 - val_loss: 875.8024\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.2304 - val_loss: 876.6213\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.0319 - val_loss: 877.4286\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 19.8423 - val_loss: 878.2238\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.6611 - val_loss: 879.0070\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.4881 - val_loss: 879.7779\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.3229 - val_loss: 880.5365\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.1652 - val_loss: 881.2829\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.0148 - val_loss: 882.0169\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.8713 - val_loss: 882.7385\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.7346 - val_loss: 883.4478\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.6043 - val_loss: 884.1445\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.4802 - val_loss: 884.8289\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.3620 - val_loss: 885.5010\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.2495 - val_loss: 886.1606\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.1425 - val_loss: 886.8077\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.0406 - val_loss: 887.4426\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.9438 - val_loss: 888.0651\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.8518 - val_loss: 888.6753\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.7643 - val_loss: 889.2729\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.6813 - val_loss: 889.8585\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.6025 - val_loss: 890.4322\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.5277 - val_loss: 890.9938\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.4567 - val_loss: 891.5431\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 17.3894 - val_loss: 892.0805\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.3256 - val_loss: 892.6061\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.2651 - val_loss: 893.1201\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.2078 - val_loss: 893.6223\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.1535 - val_loss: 894.1131\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.1022 - val_loss: 894.5924\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.0536 - val_loss: 895.0604\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.0076 - val_loss: 895.5169\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.9641 - val_loss: 895.9625\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.9230 - val_loss: 896.3975\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8841 - val_loss: 896.8212\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.8474 - val_loss: 897.2344\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.8127 - val_loss: 897.6370\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.7800 - val_loss: 898.0293\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.7491 - val_loss: 898.4110\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.7200 - val_loss: 898.7829\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.6925 - val_loss: 899.1445\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.6666 - val_loss: 899.4966\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6421 - val_loss: 899.8385\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.6191 - val_loss: 900.1709\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.5975 - val_loss: 900.4944\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.5770 - val_loss: 900.8085\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.5578 - val_loss: 901.1135\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.5396 - val_loss: 901.4094\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 16.5226 - val_loss: 901.6968\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.5066 - val_loss: 901.9752\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.4915 - val_loss: 902.2458\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.4773 - val_loss: 902.5080\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.4640 - val_loss: 902.7618\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.4515 - val_loss: 903.0081\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.4397 - val_loss: 903.2465\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.4287 - val_loss: 903.4771\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.4183 - val_loss: 903.7005\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.4086 - val_loss: 903.9164\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.3994 - val_loss: 904.1257\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.3908 - val_loss: 904.3277\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.3828 - val_loss: 904.5229\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.3752 - val_loss: 904.7117\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.3681 - val_loss: 904.8939\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3615 - val_loss: 905.0698\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 16.3553 - val_loss: 905.2397\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3494 - val_loss: 905.4034\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3439 - val_loss: 905.5615\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3388 - val_loss: 905.7137\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3340 - val_loss: 905.8606\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.3295 - val_loss: 906.0021\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.3253 - val_loss: 906.1387\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3213 - val_loss: 906.2695\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3177 - val_loss: 906.3961\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3142 - val_loss: 906.5176\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3110 - val_loss: 906.6344\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3080 - val_loss: 906.7467\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3051 - val_loss: 906.8547\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3025 - val_loss: 906.9586\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3000 - val_loss: 907.0580\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2977 - val_loss: 907.1536\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2956 - val_loss: 907.2452\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2936 - val_loss: 907.3331\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2917 - val_loss: 907.4175\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2900 - val_loss: 907.4985\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2883 - val_loss: 907.5761\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2868 - val_loss: 907.6503\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2854 - val_loss: 907.7211\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2841 - val_loss: 907.7892\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2829 - val_loss: 907.8542\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 16.2818 - val_loss: 907.9167\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2807 - val_loss: 907.9763\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2798 - val_loss: 908.0334\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2788 - val_loss: 908.0877\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2780 - val_loss: 908.1397\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2772 - val_loss: 908.1892\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2765 - val_loss: 908.2365\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2759 - val_loss: 908.2815\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2753 - val_loss: 908.3246\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2747 - val_loss: 908.3655\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2742 - val_loss: 908.4047\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2738 - val_loss: 908.4419\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2733 - val_loss: 908.4773\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2730 - val_loss: 908.5110\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2726 - val_loss: 908.5429\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2724 - val_loss: 908.5734\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2720 - val_loss: 908.6023\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2718 - val_loss: 908.6297\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2716 - val_loss: 908.6558\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2715 - val_loss: 908.6808\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2713 - val_loss: 908.7045\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2711 - val_loss: 908.7267\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 16.2710 - val_loss: 908.7478\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2709 - val_loss: 908.7678\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2709 - val_loss: 908.7865\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2708 - val_loss: 908.8043\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2708 - val_loss: 908.8214\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2708 - val_loss: 908.8375\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2708 - val_loss: 908.8524\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2708 - val_loss: 908.8669\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2709 - val_loss: 908.8805\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2709 - val_loss: 908.8932\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2710 - val_loss: 908.9053\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2710 - val_loss: 908.9166\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2711 - val_loss: 908.9272\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2712 - val_loss: 908.9371\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2713 - val_loss: 908.9467\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2715 - val_loss: 908.9557\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2716 - val_loss: 908.9638\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2717 - val_loss: 908.9717\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2719 - val_loss: 908.9790\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 16.2720 - val_loss: 908.9860\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2722 - val_loss: 908.9924\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2723 - val_loss: 908.9984\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2725 - val_loss: 909.0041\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2727 - val_loss: 909.0093\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2728 - val_loss: 909.0145\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2730 - val_loss: 909.0189\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2732 - val_loss: 909.0233\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2734 - val_loss: 909.0272\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2736 - val_loss: 909.0309\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2738 - val_loss: 909.0345\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2740 - val_loss: 909.0376\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2742 - val_loss: 909.0404\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2744 - val_loss: 909.0434\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2746 - val_loss: 909.0457\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2748 - val_loss: 909.0482\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2750 - val_loss: 909.0502\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2752 - val_loss: 909.0523\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2754 - val_loss: 909.0540\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2756 - val_loss: 909.0557\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2758 - val_loss: 909.0569\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2761 - val_loss: 909.0583\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2763 - val_loss: 909.0594\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2765 - val_loss: 909.0606\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2767 - val_loss: 909.0616\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 16.2769 - val_loss: 909.0625\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2771 - val_loss: 909.0631\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2774 - val_loss: 909.0637\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2776 - val_loss: 909.0646\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2778 - val_loss: 909.0648\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2780 - val_loss: 909.0651\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2783 - val_loss: 909.0652\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2785 - val_loss: 909.0657\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2787 - val_loss: 909.0659\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2789 - val_loss: 909.0660\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2792 - val_loss: 909.0662\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2794 - val_loss: 909.0662\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2796 - val_loss: 909.0662\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2798 - val_loss: 909.0662\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2800 - val_loss: 909.0661\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2802 - val_loss: 909.0659\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2804 - val_loss: 909.0659\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2807 - val_loss: 909.0657\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2809 - val_loss: 909.0655\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2811 - val_loss: 909.0652\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2813 - val_loss: 909.0651\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2815 - val_loss: 909.0648\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 16.2817 - val_loss: 909.0646\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2819 - val_loss: 909.0641\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(85.7336, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0020, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0125, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3008, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 425ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.77987745e+01, 6.76601191e+01, 6.75214636e+01, 6.73828081e+01,\n",
       "        6.72441527e+01, 6.71054972e+01, 6.69668417e+01, 0.00000000e+00,\n",
       "        2.61160940e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.51549834e-01, 6.90569561e+01, 6.89225023e+01, 6.87880485e+01,\n",
       "        6.86535948e+01, 6.85191410e+01, 6.83842087e+01, 6.82455532e+01,\n",
       "        6.81068978e+01, 6.79682423e+01, 6.78295868e+01, 6.76909314e+01,\n",
       "        6.75522759e+01, 6.74136204e+01, 6.72749650e+01, 6.71363095e+01,\n",
       "        6.69976541e+01, 6.68589986e+01, 6.67329248e+01, 6.66530929e+01,\n",
       "        6.65732610e+01, 6.64934290e+01, 6.64135971e+01, 6.63337652e+01,\n",
       "        6.62539332e+01, 6.61741013e+01, 6.60942694e+01, 6.60144374e+01,\n",
       "        0.00000000e+00, 6.57682478e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.75791919e-01, 0.00000000e+00, 6.74444328e+01,\n",
       "        6.73057773e+01, 6.71671219e+01, 6.70284664e+01, 6.68898109e+01,\n",
       "        6.67511555e+01, 6.66708333e+01, 6.65910014e+01, 6.65111695e+01,\n",
       "        6.64313375e+01, 6.63515056e+01, 6.62716737e+01, 6.61918417e+01,\n",
       "        6.61120098e+01, 6.60321779e+01, 6.59523459e+01, 6.58725140e+01,\n",
       "        6.57930672e+01, 6.57174370e+01, 6.56418067e+01, 6.55661765e+01,\n",
       "        6.54905462e+01, 6.54149160e+01, 6.53392857e+01, 6.52636555e+01,\n",
       "        6.51880252e+01, 7.22844544e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.20709970e-01, 0.00000000e+00,\n",
       "        4.72012482e+01, 2.56794453e-01, 0.00000000e+00, 3.52068007e-01,\n",
       "        2.82769017e-02, 0.00000000e+00, 5.54408073e-01, 4.86232877e-01,\n",
       "        2.54633904e-01, 5.40280938e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.18361354e+00,\n",
       "        7.08772302e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61.77679739, 61.76746032, 61.75812325, 61.74878618, 61.73944911,\n",
       "       61.73011204, 61.72077498, 61.71143791, 61.70210084, 61.69276377,\n",
       "       61.6834267 , 61.67408964, 61.66475257, 61.6554155 , 61.64607843,\n",
       "       61.63674136, 61.6274043 , 61.61806723, 61.60873016, 61.59939309,\n",
       "       61.59005602, 61.58071895, 61.57138189, 61.56204482, 61.55270775,\n",
       "       61.54337068, 61.53403361, 61.52469655, 61.51535948, 61.50602241,\n",
       "       61.49668534, 61.48734827, 61.4780112 , 61.46867414, 61.45933707,\n",
       "       61.45      , 61.44066293, 61.43132586, 61.4219888 , 61.41265173,\n",
       "       61.40331466, 61.39397759, 61.38464052, 61.37530345, 61.36596639,\n",
       "       61.35662932, 61.34729225, 61.33795518, 61.32861811, 61.31928105,\n",
       "       61.30994398, 61.30060691, 61.29126984, 61.28193277, 61.2725957 ,\n",
       "       61.26325864, 61.25392157, 61.2445845 , 61.23524743, 61.22591036,\n",
       "       61.2165733 , 61.20723623, 61.19684874, 61.18284314, 61.16883754,\n",
       "       61.15483193, 61.14082633, 61.12682073, 61.11281513, 61.09880952,\n",
       "       61.08480392, 61.07079832, 61.05679272, 61.04278711, 61.02878151,\n",
       "       61.01477591, 61.00077031, 60.98676471, 60.9727591 , 60.9587535 ,\n",
       "       60.9447479 , 60.9307423 , 60.91673669, 60.90273109, 60.88872549,\n",
       "       60.87471989, 60.86071429, 60.84670868, 60.83270308, 60.81869748,\n",
       "       60.80469188, 60.79068627, 60.77668067, 60.76267507, 60.74866947,\n",
       "       60.73466387, 60.72065826, 60.70665266, 60.69264706, 60.67864146])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.81868482954097\n",
      "26.654223083464327\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
