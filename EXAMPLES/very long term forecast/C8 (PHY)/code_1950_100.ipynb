{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "2045    59.052299\n",
       "2046    59.047164\n",
       "2047    59.042028\n",
       "2048    59.036893\n",
       "2049    59.031758\n",
       "Name: C8, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c8_interpolated_1950_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "1945     0.289124\n",
       "1946     0.102327\n",
       "1947     0.667690\n",
       "1948     0.000000\n",
       "1949     0.000000\n",
       "Name: C8, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1950)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.987115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.774230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87.561345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.348459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.200000  0.000298\n",
       "1     87.987115  0.000298\n",
       "2     87.774230  0.000297\n",
       "3     87.561345  0.000297\n",
       "4     87.348459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAo90lEQVR4nO3df5xcdX3v8ddnZ39lfyTZTZb83PyChJIgEFh+KWBtAYNVQluVoF7x1pa2V9r6sL0WrxVbvH206vVarVwVH/IotSpWe3tNKz4QFUVFIAkkQAJJ1iRkE0J+b5L9/et7/5izk5nJzM6ZmTNzzuy8n4/HPmbmzDlzvnN29/v5nu9Pc84hIiLVpybsBIiISDgUAEREqpQCgIhIlVIAEBGpUgoAIiJVqjbsBKSbO3euW7ZsWdjJEBGpKFu2bDnmnOvI55jIBYBly5axefPmsJMhIlJRzOyVfI9RFZCISJVSABARqVIKACIiVUoBQESkSikAiIhUKQUAEZEqpQAgIlKlFABEpOp99ed7+f4Lh8JORtkpAIhME845RsYm6B8eo3dghEpZ68M5x9DouK99R8YmGBufSNn20qHT/Ok3n2PP0b6UzxwZm0g/nP7hsYyf+9CT+/jBjsN5pPrseQrZzznHK8f7+erP9+Z9ziBFbiSwSCVyzjEwMk7/8BiDo+MMjo4zMDLO0Mh44vXgyDhD3vPh0QlGxuM/o2OO0fEJRsYm4o/jE0mvXdprb9vY2f1Gk/ZL9r7XL+Ovb13jK+2HTw/TPzLG+R0tU+47PDbOvmMD7Dnax5Ezw5zoH0n8vOGCubzr6iWJzzzWN0LPyQF6Tgxw6NQQJwdG6O0fjT8OxB9PDozSOzDC2ITji+++nFtet4Andh3lBzteo3dgNLFfr7df/8g4r1s0i//4k+uAeEDYc7Sfjdte5c7XL+P00Chv+8ef03NigNqaGh770A0sndPMc/tP8rWnXuGRFw7x3Q9cx4XzW+kdGOE/nz/Ey6+d5tXeQa5Y2gZA3/AYLx86TdeydgD2Hevn0e2v8czeE9z7ttXsPtzHz7uPseWVk3Qf6eOB917B9Ss7cM7xrU09bO3p5Z1XdlJjxo9fOsyz+3vZ2tPL2iWz6Whp4LmeXk4OjDAwPM7I+ARf+PFuvvieK7hmxZy8/+6KpQAgVS1e+pzgzNAoZ4bH6Bsa48zQGH3Do97jWMrjmaFR+lL2O7ttIs8CtxnUx2qor62hPlZDXayGulqjLlaT2F4Xq6EuZrQ21lEfM+91/Cd+nLetNvkY46EnX2Hvsf5zvuvRM8PsPHyGXYf72H34DDsPn6H7cB9nvJLxzz78JjrbmxgYGWP34T66j/TRfdR7PNLH/hMDjKd90dlNdQyPTtB9pI93Xb2Eh5/Zz9/8xw4G00r19bEaZjfV0dZUz+ymOs7vaKGtuY6ZjXV8+Yk97D0eT+8//HAXLx48zeK2GcxqqmPezEYunN/K7Bn1bDvQy45XTzMyNsG3t/Tw0X9/MeUcR88M88rxAS5dPIttB07xL0+9wvMHTvH03hO0NtTyO5cv5vTQKH/7vR184+n99I+kpvEbT+/n77//EgAP/d5VPPiLfXzv+VeZcPHv+cZP/wSAGXUxVi+cyeDoONt6erliaRtN9bV86ae/Yt/xAR7e1ANAjcGvzZ9JrMb42e5jALxu0ayU383JgVHfd0BBUwCQSHPOMTw2kSg5D3ol6qFRb1tSCXs4sc+Et894huPGz8nY0zO0TBrramhpqKO1sZbWxlpaGmpZOqeJ1sa6xOsW77GpPsaMuhiN3uOMuhhN9TEa62LM8LY11NZQGytdDexPdx1l3/F+/vFHu+k5OcDeY/3sOtzHqcHRxD7tzfWsPK+F3758EaPjE3zzmR5O9I8wf1Yj13/ycY73jwBQW2Msm9vMr81v5a2XLOCC81o4v6OFeTMbaWuqozZWw589/Bxbe3oBWDmvhXddvYTOthl0tjexpL2JBbNn0Fwfw8zOSatzji8/sYeh0fgdzISDa8+fw0O/d9U5+37+R7vZ8spJbvjU47x2eijr979u5Vy2HTjFV362l7ktDXzsravZcGUnjXUxLv/EY/QNj3HrpQu546olvPPLv0wc19JYy7Xnz+Gq5XP47f/zJM31Me664Xze9/plzJ/VyN898hJXLW/nhlUdjI5PsPreR/lfP9jFrsN9fP6OtXznj1/PGz/1OP0j41yzop0H3tvFzMY61t//C7b19NJYV8P/eMtF3PGVpwr6vQZNAUDKamBkLFFlcLx/hBN9I5wcOPv8eH/89Yn+EY73DXNmeIxCqrLrYzU01tUwYzLjrTv72NneRKuXYccz7zpaGmuZOZmRN9SmZOzNDbXU11ZWc9n8mTP4RfdxPvPYLjpaG1ja3sRvXbKAVee1sGpeK6vmtzK3pSGx/y+6j/HNZ3oYHB1nZGyC4/0j3N7VyR/csIKlc5qoyxGsZtTFEqXYK5a2c8XSdt9pNTMa62p8lYIXt80A4LyZDfz9776Ona+d4e++//I5+yV/tyc+/Os01cezupGxCU4NjvLBG1fywRtXndNOcOulC7n10oU84jUIf+MPruHSztmJ9z/ylosSz2MZgtncloZEkJs3s5GZjXXn7LNgVmPO71kuCgByjsGRcXpODjA4Eq+jHB6dYHgsnjEMj6U/P7ttsl47ef/B0fF4XW//KMf7hxOlvHS1NUZ7c33iZ83CmcxprmfWjLqUkvSM+hgNtWdL0vGMvSaldN1YFyNWc+4/ZzX5xG1r+ONfP5/FbTNorIvl3H9yn+RM+PzzmrngvKnbBJKPHxwpvBqjMSmATGX9ZYu47oK5nDcznom+cnwg437tzfX87MNvYk5LfSLzTzYZ0OpiRqzGGJ9wZPqLmera1dQYDbU1DGdobJ7KsrnN/PIjv8G1f/fjxLawmusVAKqYc46DvYO8fOgML792mpcOneGl106z71h/3vXZ9bU1NNTW0FAb8x7j9dENdTHmtjSwal4rc5rraWuuZ05zPe3NDbR7z9ua65nZWJuxekAK01Rf6zvzhngVF5A1QOc+PnZOI3Q+amtqGPP+6Kb604vVWCLzh/idxyQzUu4WO9ubcp7XzGisrTmnLcCvdRfP57tbX837uAWzZhR0vqApAFSRI6eH2NrTy/MHTrHtQC/beno5PXS2W9yS9iYuWtDK2y5ZyPnntdDslbYb6uINjA118Qy+PjmD9xoflXlXto7WBt577dJEFUu+/vubL+Qv110YcKpyC+JO79l7b+I3P/PTgo793Ia1PH/gVErQqqT/BAWAaerM0CgvHDjFtgOn2NbTy7YDvRw6FW80i9UYF85r5bcuWcCahbO4aEErF86fSUuD/hyq1Xmtjdy3/mIg3g0yX0FXuRVbnshWIHEZ7i8aamPnnC+fdic/SbXEY7TCg/7jI8g5x2mvh0rf5GPi+Sh9w+Opz4fH6Jvsnjg8zunBUV49NZj4I142p4krl7VzaedsLuucxeoFs5hRn7teWKRaZMvwiwlE0crqM1MACMnAyBg9JwbZf2KA/Sfig2V6Jp+fHPBVFzujLkZzQ21Sb5UYi2bP4MJ5Lazo6OTSztlcsmgWbc31ZfhGMt2Uu7Ra7MDlolMbZo4dUiuwAkCJjE84Xjs9xP7jXuZ+ciAlsz/WN5Kyf3N9vHvi8rnNvHFVB/NnNdLaGO+C2NJwtrtic0OMVu+xlP3IRcoppaRdVCSojOkvokIBoAinBkfPltpPpGbwB3sHGR0/+8dYY7Bw9gyWtDdx40Xz6GxvSgySWdLeRFtTnRpSRfJUqn+ZTG0FU+6fHLQypCmq/9oKADkcPj3ErsNnUjL3+ONgyqhKiA8VX9LexJqFs1h38YJE5t7ZPoOFs2fkHEwjEgVRmESu2Pwy2/HZvlpRXzmPxEYtECgAZNA7MML3XjjEd597lWf2nUhsr4sZi9viJffLOmcnMvjJbbNmnDvqT6RSRS2zClKm75apzaOYS1AJd/QKAMTr61/tHeT5A6f47taDPL7zCKPjjvM7mvmLm1fRtaydJe1NzJvZWPUjTEVKJ/dAsKlUQoabTb5VTkGpugDQNzzGz3YdZfurp9lzrI89R/vZe6w/MZy7o7WBO69dxm1rF7Fm4cyK/qMSqRRB/ZdFoPaqIrp/TqqKAHDk9BCPvXSYx3Yc5snu44yMT1Bj8ZGvKzpauH7lXFZ0tLDyvBbWLmlTKV8kZH4LXtl2K7bclm8gybW7pT1GxbQNABMTjm9v6eHhTT08t78XiGf47712KTetnsdlS2bTUKvBUCLpIlCIjgw/gSTbLlHL7DOZlgHgxYOn+Kv/9yJbe3q5aMFM/vymVdy8Zj6r5rWoSkckospZfZOxwTfErCGsqqtpFwC++vO9/O33dtDeXM9nb7+U2y5bpExfJOKS/0ULzQyNaNy9VFJ+M60CwOHTQ3z60Ze5fmUHn79jrbplikxzkZlcLQqRpwDTamTSF37czdi44771a5T5i1Sw4geCFfcJ+eTnfkr8k/tE7e5g2gSAnhMDPLxpP7df2cnSOc1hJ0ekYkWhK2WpZB8JnO1LT+/pQKdNFdC8mY18/G1ruPGieWEnRWRaKHdptejZQIuckiHUyUDVCFyc+toa3nPN0rCTISIFSK6yKWZUbBTuXiJWyzMlX1VAZrbOzHaaWbeZ3ZPh/Q+Z2Q4ze97MfmRmS5Peu9PMdns/dwaZeBGpbiWbDTTPSJIraEU1JuQMAGYWA+4HbgFWA3eY2eq03Z4DupxzlwDfAT7lHdsOfBy4GrgK+LiZtQWXfBEJ3DQoRWc7vhRz7uST1KgFAj93AFcB3c65Pc65EeBhYH3yDs65x51zA97Lp4DF3vM3A4855044504CjwHrgkm6iEwnYU2IFj93ZsUtCRm17P5cfgLAIqAn6fUBb1s27we+X+CxIhIR5cy+ghkI5j/FmfYMqjqpkI8JK/QF2ghsZu8BuoA35nncXcBdAEuWLAkySSJSRcK8i6hEfu4ADgKdSa8Xe9tSmNmNwEeBW51zw/kc65x7wDnX5Zzr6ujo8Jt2EZm2ol99kizXXUvi7iJiX8tPANgErDSz5WZWD2wANibvYGZrgS8Tz/yPJL31KHCzmbV5jb83e9tEJKKmQyk63yUh8/2clH0ilqnnI2cVkHNuzMzuJp5xx4AHnXPbzew+YLNzbiPwaaAF+LY3eGS/c+5W59wJM/sE8SACcJ9z7kSG04hIlQuzD38pzp1PYAhrHWZfbQDOuUeAR9K23Zv0/MYpjn0QeLDQBIpIOMpZsk0+VcGNwEWPBA7mC0dtvp+pTJu5gESk+qRntkEVpKMworgcFABEJHJKNRCsVHI2Ant3F1G7N1AAEJEUYZV+y3HafM/ha6rnyGXr/ikAiEjokjPacgSC9Ew7yJ5PhfT4DKvGSQFARDKq3HJtYSqo7TYwCgAiUrHS8+zAGoHzLJPn3N9LaNR6CCkAiEjkFJ9NBtSl088+0crT86IAICIpwqqPLkfjc7YBV9XS7TOdAoCIZBRWdUWho2KLHggW1GyglvroR1gBSAFARCpWeiYbVG+earkjUAAQkciptHr13APBvMeIfS8FABGJhED74gdcnTNdKQCISIowZqYsV0ab7ZsF+40np32IfvRQABCRjCqt9Ft8hhvmFw6n0UEBQEQq1jlTOkR0NtCoBlMFABGJnKhUn/hNh994EY1vdZYCgIhEQ4Cl7nJmtFGb3iEfCgAikiKM2ujkPLSUK4Jl++wgq3w0EExEKl4llGsLLXxnKrVXcEG+YAoAIiJpgi6QJ1YEi1iUUQAQkcgpfknIoBZ497dfpU4doQAgIinCXhIyyBHBWU8SoPQYEa0y/tQUAEQkdEF0+yyu0B98ZMirETjws/ujACAimUWsvjqTQlOY6bjkbWFMhxEGBQARiZxCY094+fbUJ050DS1DSvKhACAikRBkqbu8A8HKeLKAKQCISIqSNsJmEcRAMD/K8d0qKSAoAIjItFBMQ3Jpgo7/9GgksIhESiUUZAtdEjLXmsCBDwSL6MVUABCRyInMbKABDwSLWiBQABCRSAiy1F3OjDb9XFEJXn4oAIhIqhDqo1P64Bf6GcXMBlrgOYMSRsM7KACISEUrrLSdeSBYsI0AUavuyUQBQEQyqoQMLF1UB/CeDS7Ruqi+AoCZrTOznWbWbWb3ZHj/BjN71szGzOztae+Nm9lW72djUAkXkeklJfOOSD7pd1bRiMadnGpz7WBmMeB+4CbgALDJzDY653Yk7bYfeB/wFxk+YtA5d1nxSRWR6So5ow1iRHBZG4HTolUl3TnlDADAVUC3c24PgJk9DKwHEgHAObfPe2+iBGkUkTKq1NKsn3w323crxeRv+cSBKA8EWwT0JL0+4G3zq9HMNpvZU2Z2W6YdzOwub5/NR48ezeOjRaRUKqE7Y6mWhAyrV065laMReKlzrgt4F/APZnZ++g7OuQecc13Oua6Ojo4yJElEoqzQ0BP8Uo4BfU4BC8WXg58AcBDoTHq92Nvmi3PuoPe4B/gJsDaP9IlIlQh0IFiZ716Sq5AilsdPyU8A2ASsNLPlZlYPbAB89eYxszYza/CezwXeQFLbgYgIBDMQLCxRK9XnI2cAcM6NAXcDjwIvAf/qnNtuZveZ2a0AZnalmR0A3gF82cy2e4dfBGw2s23A48Dfp/UeEpGIiWpf+kyS815/I4Ezf7n0rUFcg0pYEtJPLyCcc48Aj6Rtuzfp+SbiVUPpxz0JvK7INIpICCq5ZJtLxtlAy5+M0GkksIhEQko9eoHRJ+junL5nA/X7eQWnpDQUAEQkfEE3ApR1IFja6wq6dVIAEJFponIy3nSlGIjmhwKAiKSopEFQ+Za2s48E9rdfPiphIJ0CgIhkFP3sq3AZp4PONDo4oKsw+dlRqx1SABCRSAhiMtCw7l0qqetsMgUAEQldBbcBR69YnwcFABGZFio4Hw6NAoCIpKik6ox88/ysawKnvRH0SOCoxiYFABHJKMwSdaHn9p1x+zxB0Ncgaj2DFABEJBq8zDusPvHFSGnAjlYePyUFABEJXdCjZ8s5GreC8vtzKACISIpKKn/nW8/ud5BbuQfDRXlJSBGRaS1b/ltM6T7fqarDoAAgIhmVfVWtpGy48DP7K0pnHglc8El9f07UAoECgIiErqIHglGZDdegACAi00RY0zAHcdqwJuBTABCRFJVUms078806HWjay8q5BEVRABCRqpN5Schg1omc/JzkOxJLe4wKBQARyazMuVVyqbvwJSEDSkyVUAAQkdAl5/dBz8Mj2SkAiMi0EGSen08MCuK8GggmIpFQSdUo+Y5V8NkGHLioLhSvACAiGZW/L335zp0pcPhuGM712VMOBItWIFAAEJHQJWe0xfSJ15KQ+VEAEJFpp5zTWEStVJ8PBQARqVzJs4EG2gqs2UBFRKYVv0tCTiokqCQGfWlJSBGpVOWu2kip+y/xkpCZG3yrjwKAiIQu6IFg5RbWZG7FUgAQkWkhueG32JuXcg8EC4sCgIhUrErOfJOFdf+gACAiKcKqginHebNV1QS5JORk20mmO5Ko9Rj1FQDMbJ2Z7TSzbjO7J8P7N5jZs2Y2ZmZvT3vvTjPb7f3cGVTCRaS0wsqrnCu8H7/ftQxKuSRkJckZAMwsBtwP3AKsBu4ws9Vpu+0H3gd8I+3YduDjwNXAVcDHzayt+GSLiGQX5jQWlcTPHcBVQLdzbo9zbgR4GFifvINzbp9z7nlgIu3YNwOPOedOOOdOAo8B6wJIt4hI6qIrAeb6+WTogSwJGVIE8RMAFgE9Sa8PeNv88HWsmd1lZpvNbPPRo0d9frSISGkVMhYi8xHRrF+KRCOwc+4B51yXc66ro6Mj7OSIVLWw+rQnn7VU9fHZRwIHf66Mg80iFgf8BICDQGfS68XeNj+KOVZEQlTOzCqoUcd+8/HMmXPEcucy8BMANgErzWy5mdUDG4CNPj//UeBmM2vzGn9v9raJiJROiOsZV5KcAcA5NwbcTTzjfgn4V+fcdjO7z8xuBTCzK83sAPAO4Mtmtt079gTwCeJBZBNwn7dNRKRopcrn82mUDWLq6bDiR62fnZxzjwCPpG27N+n5JuLVO5mOfRB4sIg0ikgZTe+BYNm2Z5kNtJCTTFH3X851CvyIRCOwiFS35GzRORdKNhn0OaOV1WemACAiGVVim6jv6aADzp41G6iISIhSF2ApLoPPKzuvwEA5SQFARCpWqe9SilkRLNe2FFoSUkSiILzKjNKfOVvvnnI1fEetWk0BQERCl7IiGGXIKAsqpud5iohl9pkoAIhIRlHrsuhHaNNYVGYbsAKAiFSu1EVXAlwSMp/ZQIs7Vfx8IQUuBQARkSwKuQvKNKdQVKuDFABEJEVYc9Mnn7ZU1U9ZZwMtwbkyBoISnKcYCgAiklF5ZwM9+7yo+ON7IFimbVHLnktPAUBEJE2+MahC24AVAESkcqWO/s38vJxpKPTcYfUiUgAQkUiIZCk6oEgyWb0UtUVnFABEJEUYGXFy/bvDlb/XTCmWhAz+IwOnACAi04b/JSErp6tmKSkAiEjFSqn3T24PKDI3z7srbCTrr3JTABARycJPHEnvPpp5wfmpPyOs+KEAICKRENYAtHKKWi2TAoCIpAgjH04fCFaq+vjsI4GrsxVYAUBEMopal0U//C8J6W+b7/NWaCOAAoCIVK4sy0CGNY1Fejr80kAwEalqUSxDBxVHonozpQAgIqFLzh/dOVumkYh9LQUAEUkTxbJ4MLLV1ZeiCqYSZhdVABCRjKKffZ3Lb2Nsrr76eY8Dq9CYqQAgIhUrW8NvcHX3uT/pnEbgAk6uJSFFpKpVainaj8RsoCGnI50CgIiEL6nYXMqBYNlM49gzJQUAEUlRySXxXGmf6v2gG22j2vUzmQKAiGRUCRlYofX+uSdnyy8KVmrMVAAQkUgIMhMNKnj5+Rhfdw65Ao5GAotItUrNHyu1PJ1b1OZX8hUAzGydme00s24zuyfD+w1m9i3v/afNbJm3fZmZDZrZVu/nSwGnX0QCFoXst1TZZLbvVg1TUWdSm2sHM4sB9wM3AQeATWa20Tm3I2m39wMnnXMXmNkG4JPA7d57v3LOXRZsskWk1CphJGs630tCZvhuxQwEy3yO6PNzB3AV0O2c2+OcGwEeBtan7bMeeMh7/h3gNy1q9zoiMu2YvxeFf77Pj0m+gygk64vyimCLgJ6k1we8bRn3cc6NAaeAOd57y83sOTP7qZldn+kEZnaXmW02s81Hjx7N6wuIyPRQqdUw/paNjKZSNwIfApY459YCHwK+YWYz03dyzj3gnOtyznV1dHSUOEkiEjXlWhEsbFH7Wn4CwEGgM+n1Ym9bxn3MrBaYBRx3zg07544DOOe2AL8CVhWbaBEpnQotiPuS7S6jFF+5EoKYnwCwCVhpZsvNrB7YAGxM22cjcKf3/O3Aj51zzsw6vEZkzGwFsBLYE0zSRaSUKiEDS69v91uNlHE20OTPyTMdyftXwGVLyNkLyDk3ZmZ3A48CMeBB59x2M7sP2Oyc2wh8FfiamXUDJ4gHCYAbgPvMbBSYAP7IOXeiFF9ERKpbKZaEDKonVM6G4ZBuu3IGAADn3CPAI2nb7k16PgS8I8Nx/wb8W5FpFJFprpJKzcWI2l2VRgKLSKQ4KnMMQiVSABCRFGEtTlIO2UcCT/26EJUQxBQARCSj6GdfabOBWpG9eTLUz/gfCJb/MVGgACAikRBkO2g582Bfy0bmeD/KI4FFRErKUlYEm75VUFGrFlIAEJHIqaRqlEqmACAiKSq6AF7EkpCpH1P4RZgMXpUQxBQARCSjSsjALMvznMdlavAtIh3FxkytCCYiVS3I7qflnI3e17KREQ2mCgAiErr0eXgiml8WLWqBQAFARKpa0L2OotbTZyoKACKSopIagdNL1LmrkbK/ryUhRUQSypuFFZvpJtf750q532/mu8omR+JzDgQLKeoqAIhI6IIufZdT1Or186EAICKRU85ePNXM13oAIiLTVVB3HI9uf43HXz5SUXcEugMQkRSVNR10ar1/rsx8qvcz9d7x26PHATtePc3Dm3rOnqMCIoECgIhkVO78K9DZQHOkPcjvNvlR9bXx7HR0fCLD+aY+oWYDFZGqNVnSds5lzEArQV0s/h2mSn/U2jYUAEQkMv7mP3YwMDIeyrl/uutIUcfXxeLZ6dhE5VShKQCISIowu2E21OWXJeVboM701Sa3Pbu/9+y2Ai7CZAAYHaucOxgFABHJqNyVFQ5HY20s/ryADNjMf/Dy27ibz5KQ9V4AGBl33jmiTwFARAL11J7jnBocze8gL7dsrIsHgJEi2wHKOR/PZL1+XW32NoDcI4Hh+QO9PLv/ZNDJm5ICgIgE5szQKBseeIr/9vUtBR3f6FUBDY1WTjXKpOVzW3jX1Uv48LoLs+7z0qHTWd/79KM7+cR/7ihF0rJSABCRFA/+Yi8A+473533s4Gi8AXfna30FnXtuSwMA4yE1pE5WPeVTA+Wc44WDp/jOlh7+5tY1vPvqpQWde3zCUVtT3oojBQARSfHYjsMAvNo7lPexY179d6EZ2dsuXUhrYy1zWup97T95lndfvYSm+twTG/zh1869M0lub3h674mMnz9lGrwqoH95aj/DYxOJz0tpP/DxQWMTjliZA4CmghCRFMNeL5aG2vzLhyPesbWx/DKyu990QVGDs9YuaeOff7kv536TdzXZzvWBrz/Llo/dVHA6sl2zBq9xOxtH/A6gvm7q/YKmACAiQLzxdnBkPJGJFxIAJoNHvncAN6zqSDz/2FtXs2Juc17Hv3jwFP/05D5+Z+0iIHsGn6lq59Cps3c6k1VY+egbGks8z/a9Z3gZ+40XnZfx/S/+pJtjfSO8Mek6lIMCgIgA8JUn9vDa6aRqnwKK5JN197lKvJmOOzkwwszGOt7Z1Zn3ef/pyX0ADI3ln4EnZ/qFBIBn9p2tNjKzjF1YJ3sIXb60LeNnHOsbAeCJ3UfzPn8x1AYgIgDsOdbP9lfP9lIZn8i/J87qhTMBOHByIK/jfrLzCF3/84dT9pLJ5KIF8fNdvCj+OFxA76HZTXWJ587B5364m5vXzOdzGy6jpoAgmOkuo7UhXtb+g+tXJLZ94raLfR1bSroDEBEA9h5L7fVTTFf8/jync2hrjjf6nhgYyeu4xroYf/IbF9DR2sCLB7djBovbZiRG5frR3pTa4PzZH+7iz25cyYXzW/NKS7rksQjXr+ygpSE1u+3wejyFSXcAIgLALRfPT3k9Ucbi6GQmfLI/vwAA8Oc3X8jbr1gMQNeydn7+l7+RM/NODna1sRruW78m8Xq1d1fh12dvvxSA7/3pdVn3ubRzNu97w/K8AlM5RCs1IhKaz21Yy3MfuymRAU526SyH82Y28Fe/dRGvWzSroOMba2Ncvbyd+TMbp9xvshG2f3gsZXtyVc97rsmvH/+sGfEqpNECr9cfvnEFc5r9dXsNmq8AYGbrzGynmXWb2T0Z3m8ws2957z9tZsuS3vuIt32nmb05wLSLSIDqa2toa67nHV3x0nQhbQCFaqqv5fevX8HKeYVVu9TUGN/6w2u5zesFlM21588FOGfG0cn+9zUG16+cm9e562PxBu9Cp7Fef+ki1i7J3DhcajnbAMwsBtwP3AQcADaZ2UbnXPKY5fcDJ51zF5jZBuCTwO1mthrYAKwBFgI/NLNVzrlw5nsVkZwmuzKOF1gF9KX3XM7itqYgkxSYpvp4Zj2YFgCuu2AuD/yXK7hhVUdiPiK/EusAJM0CentXJ2sWTl2VNKelnjdcMIfmhhj33HIhR88M8bXfvzqvcxfLTyPwVUC3c24PgJk9DKwHkgPAeuCvveffAb5g8eFx64GHnXPDwF4z6/Y+75fBJF9EgnaxVw1z9fI5BR2/7uIFQSYnUJNVTFcsSy1xd7Y30dleWNBqbqhlSXvT2buIGuOTb78k53FXLmvn679/TeL1d+/O3oZQKn4CwCKgJ+n1ASA9TCX2cc6NmdkpYI63/am0Y8+5RzOzu4C7AJYsWeI37SJSAmuXtPHcx25K9MyZTi5eNItNH72RuT6nmvD7mU98+E2BfV45RaIR2Dn3gHOuyznX1dFR3pFwInKu6Zj5T+pobYjc0oxh8RMADgLJQ/MWe9sy7mNmtcAs4LjPY0VEJAR+AsAmYKWZLTezeuKNuhvT9tkI3Ok9fzvwYxcfD70R2OD1EloOrASeCSbpIiJSjJxtAF6d/t3Ao0AMeNA5t93M7gM2O+c2Al8FvuY18p4gHiTw9vtX4g3GY8AH1ANIRCQarJC1N0upq6vLbd68OexkiIhUFDPb4pzryueYSDQCi4hI+SkAiIhUKQUAEZEqpQAgIlKlItcIbGZHgVeK+Ii5wLGAkhM0pa0wSlthlLbCVGraljrn8hpJG7kAUCwz25xvS3i5KG2FUdoKo7QVpprSpiogEZEqpQAgIlKlpmMAeCDsBExBaSuM0lYYpa0wVZO2adcGICIi/kzHOwAREfFBAUBEpEpNmwCQa+H6Mpy/08weN7MdZrbdzP7M2/7XZnbQzLZ6P29JOuYjXnp3mtmbS5y+fWb2gpeGzd62djN7zMx2e49t3nYzs897aXvezC4vYbouTLo2W83stJl9MMzrZmYPmtkRM3sxaVve18rM7vT2321md2Y6V0Bp+7SZveyd/9/NbLa3fZmZDSZdwy8lHXOF9/fQ7aW/6BVSsqQt799jKf6Xs6TtW0np2mdmW73t5b5u2fKO0v/NOecq/of4NNW/AlYA9cA2YHWZ07AAuNx73grsAlYTXyv5LzLsv9pLZwOw3Et/rITp2wfMTdv2KeAe7/k9wCe9528Bvg8YcA3wdBl/j68BS8O8bsANwOXAi4VeK6Ad2OM9tnnP20qUtpuBWu/5J5PStix5v7TPecZLr3npv6VEacvr91iq/+VMaUt7/zPAvSFdt2x5R8n/5qbLHUBi4Xrn3AgwuXB92TjnDjnnnvWenwFeIsP6x0nWAw8754adc3uBbuLfo5zWAw95zx8Cbkva/s8u7ilgtpmVY6Xv3wR+5ZybaiR4ya+bc+4J4utapJ83n2v1ZuAx59wJ59xJ4DFgXSnS5pz7gXNuzHv5FPGV97Ly0jfTOfeUi+cc/5z0fQJN2xSy/R5L8r88Vdq8Uvw7gW9O9RklvG7Z8o6S/81NlwCQaeH6qTLfkjKzZcBa4Glv093erdqDk7dxlD/NDviBmW0xs7u8bfOcc4e8568B80JK26QNpP4TRuG6Tcr3WoWVzt8jXjqctNzMnjOzn5rZ9d62RV56ypW2fH6PYVy364HDzrndSdtCuW5peUfJ/+amSwCIDDNrAf4N+KBz7jTwReB84DLgEPFbzTBc55y7HLgF+ICZ3ZD8pleiCa1PsMWXG70V+La3KSrX7RxhX6tszOyjxFfe+7q36RCwxDm3FvgQ8A0zm1nmZEX295jkDlILHqFctwx5R0Kp/uamSwCIxOLzZlZH/Bf4defc/wVwzh12zo075yaAr3C2uqKsaXbOHfQejwD/7qXj8GTVjvd4JIy0eW4BnnXOHfbSGYnrliTfa1XWdJrZ+4C3Au/2Mgu86pXj3vMtxOvWV3npSK4mKlnaCvg9lvu61QK/A3wrKc1lv26Z8g7K8Dc3XQKAn4XrS8qrR/wq8JJz7n8nbU+uO/9tYLIXwkZgg5k1mNlyYCXxBqZSpK3ZzFonnxNvNHzRS8NkT4E7ge8mpe29Xm+Da4BTSbeipZJSCovCdUuT77V6FLjZzNq8ao+bvW2BM7N1wIeBW51zA0nbO8ws5j1fQfxa7fHSd9rMrvH+bt+b9H2CTlu+v8dy/y/fCLzsnEtU7ZT7umXLOyjH31yxLdhR+SHeMr6LeLT+aAjnv474LdrzwFbv5y3A14AXvO0bgQVJx3zUS+9OAuhNMEXaVhDvTbEN2D55fYA5wI+A3cAPgXZvuwH3e2l7Aegq8bVrBo4Ds5K2hXbdiAeiQ8Ao8XrU9xdyrYjXx3d7P/+1hGnrJl73O/l39yVv39/1ft9bgWeBtyV9ThfxzPhXwBfwZgUoQdry/j2W4n85U9q87f8E/FHavuW+btnyjpL/zWkqCBGRKjVdqoBERCRPCgAiIlVKAUBEpEopAIiIVCkFABGRKqUAICJSpRQARESq1P8HMK002n0fTVQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 85.7336  # Value for C0\n",
    "K0 = -0.0020  # Value for K0\n",
    "K1 = 0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0125    # Value for b\n",
    "c = 2.3008    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.200000    87.987115    87.774230    87.561345    87.348459   \n",
      "351    87.987115    87.774230    87.561345    87.348459    87.135574   \n",
      "352    87.774230    87.561345    87.348459    87.135574    86.922689   \n",
      "353    87.561345    87.348459    87.135574    86.922689    86.709804   \n",
      "354    87.348459    87.135574    86.922689    86.709804    86.496919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.135574    86.922689    86.709804    86.496919    86.294538  ...   \n",
      "351    86.922689    86.709804    86.496919    86.294538    86.221709  ...   \n",
      "352    86.709804    86.496919    86.294538    86.221709    86.148880  ...   \n",
      "353    86.496919    86.294538    86.221709    86.148880    86.076050  ...   \n",
      "354    86.294538    86.221709    86.148880    86.076050    86.003221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   76.094351    0.000263   76.058870    0.000263   76.023389    0.000263   \n",
      "351   76.058870    0.000263   76.023389    0.000263   75.987909    0.000262   \n",
      "352   76.023389    0.000263   75.987909    0.000262   75.952428    0.000262   \n",
      "353   75.987909    0.000262   75.952428    0.000262   75.916947    0.000262   \n",
      "354   75.952428    0.000262   75.916947    0.000262   75.881466    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   75.987909    0.000262   75.952428    0.000262  \n",
      "351   75.952428    0.000262   75.916947    0.000262  \n",
      "352   75.916947    0.000262   75.881466    0.000262  \n",
      "353   75.881466    0.000262   75.845985    0.000262  \n",
      "354   75.845985    0.000262   75.810504    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1, 251) (1500, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 2s 26ms/step - loss: 4686.0918 - val_loss: 3184.4612\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4439.3931 - val_loss: 3034.9749\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4326.1816 - val_loss: 2970.9609\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4249.0195 - val_loss: 2914.2383\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4172.8330 - val_loss: 2861.8359\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4098.9448 - val_loss: 2810.7366\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4026.5620 - val_loss: 2760.7871\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3955.5049 - val_loss: 2711.8816\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3885.6555 - val_loss: 2663.9524\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3816.9409 - val_loss: 2616.9526\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3749.3059 - val_loss: 2570.8481\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3682.7109 - val_loss: 2525.6116\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3617.1267 - val_loss: 2481.2209\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3552.5259 - val_loss: 2437.6575\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3488.8887 - val_loss: 2394.9053\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3426.1960 - val_loss: 2352.9490\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3364.4309 - val_loss: 2311.7754\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3303.5786 - val_loss: 2271.3728\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3243.6250 - val_loss: 2231.7288\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3184.5579 - val_loss: 2192.8330\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3126.3645 - val_loss: 2154.6755\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3069.0344 - val_loss: 2117.2451\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3012.5544 - val_loss: 2080.5334\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2956.9165 - val_loss: 2044.5304\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2902.1089 - val_loss: 2009.2269\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2848.1226 - val_loss: 1974.6147\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2794.9478 - val_loss: 1940.6848\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2742.5745 - val_loss: 1907.4286\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2690.9946 - val_loss: 1874.8384\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2640.1985 - val_loss: 1842.9052\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2590.1775 - val_loss: 1811.6212\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2540.9236 - val_loss: 1780.9788\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2492.4268 - val_loss: 1750.9700\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2444.6807 - val_loss: 1721.5873\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2397.6755 - val_loss: 1692.8224\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2351.4038 - val_loss: 1664.6683\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2305.8577 - val_loss: 1637.1176\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2261.0288 - val_loss: 1610.1630\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2216.9097 - val_loss: 1583.7966\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2173.4924 - val_loss: 1558.0118\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2130.7690 - val_loss: 1532.8005\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2088.7327 - val_loss: 1508.1567\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 2047.3756 - val_loss: 1484.0725\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2006.6896 - val_loss: 1460.5419\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1966.6687 - val_loss: 1437.5565\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1927.3043 - val_loss: 1415.1105\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1888.5898 - val_loss: 1393.1967\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1850.5177 - val_loss: 1371.8085\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1813.0817 - val_loss: 1350.9390\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1776.2738 - val_loss: 1330.5813\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1740.0873 - val_loss: 1310.7292\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1704.5151 - val_loss: 1291.3761\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1669.5505 - val_loss: 1272.5145\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1635.1869 - val_loss: 1254.1392\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1601.4172 - val_loss: 1236.2426\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1568.2341 - val_loss: 1218.8190\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1535.6320 - val_loss: 1201.8618\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1503.6034 - val_loss: 1185.3645\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1472.1422 - val_loss: 1169.3207\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1441.2415 - val_loss: 1153.7241\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1410.8948 - val_loss: 1138.5687\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1381.0956 - val_loss: 1123.8480\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1351.8375 - val_loss: 1109.5565\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1323.1145 - val_loss: 1095.6871\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1294.9197 - val_loss: 1082.2340\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1267.2468 - val_loss: 1069.1912\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1240.0897 - val_loss: 1056.5527\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1213.4423 - val_loss: 1044.3125\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1187.2980 - val_loss: 1032.4644\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1161.6510 - val_loss: 1021.0026\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1136.4948 - val_loss: 1009.9213\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1111.8235 - val_loss: 999.2139\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1087.6310 - val_loss: 988.8754\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1063.9116 - val_loss: 978.8996\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1040.6587 - val_loss: 969.2805\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1017.8666 - val_loss: 960.0126\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 995.5296 - val_loss: 951.0901\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 973.6412 - val_loss: 942.5071\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 952.1962 - val_loss: 934.2582\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 931.1881 - val_loss: 926.3372\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 910.6118 - val_loss: 918.7391\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 890.4611 - val_loss: 911.4578\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 870.7302 - val_loss: 904.4881\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 851.4139 - val_loss: 897.8242\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 832.5059 - val_loss: 891.4606\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 814.0010 - val_loss: 885.3918\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 795.8936 - val_loss: 879.6125\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 778.1776 - val_loss: 874.1170\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 760.8481 - val_loss: 868.9000\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 743.8990 - val_loss: 863.9561\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 727.3253 - val_loss: 859.2800\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 711.1213 - val_loss: 854.8665\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 695.2817 - val_loss: 850.7098\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 679.8010 - val_loss: 846.8052\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 664.6738 - val_loss: 843.1501\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 649.8919 - val_loss: 839.4689\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 633.3931 - val_loss: 834.0622\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 616.1271 - val_loss: 832.1133\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 599.9039 - val_loss: 829.0588\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 584.5920 - val_loss: 826.3643\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 569.9865 - val_loss: 823.9842\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 555.9714 - val_loss: 821.8902\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 542.4760 - val_loss: 820.0617\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 529.4529 - val_loss: 818.4828\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 516.8677 - val_loss: 817.1406\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 504.6942 - val_loss: 816.0237\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 492.9104 - val_loss: 815.1222\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 481.4987 - val_loss: 814.4269\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 470.4439 - val_loss: 813.9294\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 459.7319 - val_loss: 813.6220\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 449.3510 - val_loss: 813.4973\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 439.2899 - val_loss: 813.5481\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 429.5387 - val_loss: 813.7679\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 420.0876 - val_loss: 814.1500\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 410.9282 - val_loss: 814.6884\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 402.0518 - val_loss: 815.3769\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 393.4505 - val_loss: 816.2097\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 385.1169 - val_loss: 817.1808\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 377.0438 - val_loss: 818.2851\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 369.2241 - val_loss: 819.5170\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 361.6512 - val_loss: 820.8711\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 354.3186 - val_loss: 822.3425\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 347.2199 - val_loss: 823.9260\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 340.3493 - val_loss: 825.6175\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 333.7007 - val_loss: 827.4169\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 327.2466 - val_loss: 829.1887\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 321.2387 - val_loss: 831.4118\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 313.5993 - val_loss: 833.7198\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 306.5305 - val_loss: 836.1075\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 299.9661 - val_loss: 838.5712\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 293.8016 - val_loss: 841.1075\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 287.9729 - val_loss: 843.7123\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 282.4393 - val_loss: 846.3810\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 277.1721 - val_loss: 849.1094\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 272.1501 - val_loss: 851.8923\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 267.3562 - val_loss: 854.7252\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 262.7764 - val_loss: 857.6041\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 258.3985 - val_loss: 860.5240\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 254.2120 - val_loss: 863.4813\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 250.2075 - val_loss: 866.4717\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 246.3764 - val_loss: 869.4911\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 242.7109 - val_loss: 872.5361\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 239.2038 - val_loss: 875.6029\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 235.8483 - val_loss: 878.6876\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 232.6381 - val_loss: 881.7871\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 229.5673 - val_loss: 884.8980\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 226.6302 - val_loss: 888.0175\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 223.8213 - val_loss: 891.1420\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 221.1356 - val_loss: 894.2686\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 218.5682 - val_loss: 897.3949\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 216.1144 - val_loss: 900.5176\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 213.7697 - val_loss: 903.6347\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 211.5299 - val_loss: 906.7429\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 209.3908 - val_loss: 909.8403\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 207.3483 - val_loss: 912.9248\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 205.3988 - val_loss: 915.9933\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 203.5385 - val_loss: 919.0448\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 201.7638 - val_loss: 922.0765\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 200.0712 - val_loss: 925.0865\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 198.4576 - val_loss: 928.0729\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 196.9196 - val_loss: 931.0342\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 195.4544 - val_loss: 933.9689\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 194.0585 - val_loss: 936.8752\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 192.7295 - val_loss: 939.7515\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.4645 - val_loss: 942.5961\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 190.2607 - val_loss: 945.4086\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 189.1156 - val_loss: 948.1872\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 188.0268 - val_loss: 950.9308\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 186.9916 - val_loss: 953.6383\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 186.0080 - val_loss: 956.3087\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 185.0736 - val_loss: 958.9412\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 184.1863 - val_loss: 961.5347\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 183.3439 - val_loss: 964.0883\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 182.5445 - val_loss: 966.6019\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 181.7861 - val_loss: 969.0743\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.0670 - val_loss: 971.5054\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 180.3851 - val_loss: 973.8943\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 179.7389 - val_loss: 976.2410\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 179.1268 - val_loss: 978.5451\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 178.5469 - val_loss: 980.8058\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 177.9980 - val_loss: 983.0229\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 177.4784 - val_loss: 985.1962\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 176.9868 - val_loss: 987.3260\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 176.5219 - val_loss: 989.4120\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 176.0823 - val_loss: 991.4537\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 175.6667 - val_loss: 993.4515\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 175.2741 - val_loss: 995.4057\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 174.9032 - val_loss: 997.3160\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 174.5528 - val_loss: 999.1827\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 174.2221 - val_loss: 1001.0060\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 173.9100 - val_loss: 1002.7856\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 173.6155 - val_loss: 1004.5231\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 173.3376 - val_loss: 1006.2176\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 173.0756 - val_loss: 1007.8694\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 172.8285 - val_loss: 1009.4796\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 172.5957 - val_loss: 1011.0483\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 172.3763 - val_loss: 1012.5754\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 172.1696 - val_loss: 1014.0621\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 171.9749 - val_loss: 1015.5087\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 171.7916 - val_loss: 1016.9156\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 171.6189 - val_loss: 1018.2833\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 171.4564 - val_loss: 1019.6125\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 171.3035 - val_loss: 1020.9036\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 171.1597 - val_loss: 1022.1570\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 171.0242 - val_loss: 1023.3735\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 170.8969 - val_loss: 1024.5540\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 170.7772 - val_loss: 1025.6989\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 170.6645 - val_loss: 1026.8083\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 170.5587 - val_loss: 1027.8838\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 170.4591 - val_loss: 1028.9252\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 170.3656 - val_loss: 1029.9336\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 170.2776 - val_loss: 1030.9095\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 170.1950 - val_loss: 1031.8538\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 170.1174 - val_loss: 1032.7671\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 170.0444 - val_loss: 1033.6503\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.9758 - val_loss: 1034.5037\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.9114 - val_loss: 1035.3276\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.8509 - val_loss: 1036.1233\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.7940 - val_loss: 1036.8914\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.7406 - val_loss: 1037.6331\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.6905 - val_loss: 1038.3484\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.6433 - val_loss: 1039.0381\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.5990 - val_loss: 1039.7028\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.5574 - val_loss: 1040.3435\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.5183 - val_loss: 1040.9602\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.4815 - val_loss: 1041.5541\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.4469 - val_loss: 1042.1257\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.4145 - val_loss: 1042.6758\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 169.3841 - val_loss: 1043.2051\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 169.3554 - val_loss: 1043.7131\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.3285 - val_loss: 1044.2020\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.3032 - val_loss: 1044.6720\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.2794 - val_loss: 1045.1230\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.2570 - val_loss: 1045.5558\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.2361 - val_loss: 1045.9716\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.2162 - val_loss: 1046.3710\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.1976 - val_loss: 1046.7527\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.1803 - val_loss: 1047.1198\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.1638 - val_loss: 1047.4711\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.1484 - val_loss: 1047.8079\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.1339 - val_loss: 1048.1302\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.1203 - val_loss: 1048.4398\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.1074 - val_loss: 1048.7354\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.0953 - val_loss: 1049.0181\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.0839 - val_loss: 1049.2882\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.0733 - val_loss: 1049.5468\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.0633 - val_loss: 1049.7939\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.0538 - val_loss: 1050.0305\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.0449 - val_loss: 1050.2567\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.0365 - val_loss: 1050.4722\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.0287 - val_loss: 1050.6782\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.0213 - val_loss: 1050.8750\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.0144 - val_loss: 1051.0626\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 169.0078 - val_loss: 1051.2411\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.0016 - val_loss: 1051.4113\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9959 - val_loss: 1051.5734\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9906 - val_loss: 1051.7285\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9854 - val_loss: 1051.8761\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9806 - val_loss: 1052.0168\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 168.9761 - val_loss: 1052.1506\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9719 - val_loss: 1052.2777\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9679 - val_loss: 1052.3990\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9642 - val_loss: 1052.5143\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9607 - val_loss: 1052.6238\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9574 - val_loss: 1052.7277\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9544 - val_loss: 1052.8265\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9516 - val_loss: 1052.9208\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9489 - val_loss: 1053.0109\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9463 - val_loss: 1053.0956\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9440 - val_loss: 1053.1760\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9417 - val_loss: 1053.2524\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9397 - val_loss: 1053.3243\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9379 - val_loss: 1053.3936\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9360 - val_loss: 1053.4585\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9344 - val_loss: 1053.5201\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9328 - val_loss: 1053.5789\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9314 - val_loss: 1053.6345\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9301 - val_loss: 1053.6870\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9289 - val_loss: 1053.7371\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9277 - val_loss: 1053.7843\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9266 - val_loss: 1053.8287\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 168.9257 - val_loss: 1053.8707\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9248 - val_loss: 1053.9109\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9240 - val_loss: 1053.9485\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9232 - val_loss: 1053.9846\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9225 - val_loss: 1054.0179\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9219 - val_loss: 1054.0502\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9213 - val_loss: 1054.0802\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9208 - val_loss: 1054.1080\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9203 - val_loss: 1054.1355\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 168.9198 - val_loss: 1054.1606\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9195 - val_loss: 1054.1846\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9192 - val_loss: 1054.2074\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9189 - val_loss: 1054.2285\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9186 - val_loss: 1054.2484\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9184 - val_loss: 1054.2672\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9182 - val_loss: 1054.2852\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9180 - val_loss: 1054.3019\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9179 - val_loss: 1054.3179\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9178 - val_loss: 1054.3325\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9177 - val_loss: 1054.3469\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9176 - val_loss: 1054.3601\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9176 - val_loss: 1054.3723\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9177 - val_loss: 1054.3846\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9177 - val_loss: 1054.3959\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9176 - val_loss: 1054.4059\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9177 - val_loss: 1054.4159\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9177 - val_loss: 1054.4250\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9178 - val_loss: 1054.4337\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9179 - val_loss: 1054.4415\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9180 - val_loss: 1054.4493\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9181 - val_loss: 1054.4564\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9182 - val_loss: 1054.4631\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9183 - val_loss: 1054.4698\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9184 - val_loss: 1054.4753\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9186 - val_loss: 1054.4808\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9188 - val_loss: 1054.4860\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9189 - val_loss: 1054.4908\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9191 - val_loss: 1054.4957\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 168.9193 - val_loss: 1054.5004\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9194 - val_loss: 1054.5048\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9196 - val_loss: 1054.5088\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9198 - val_loss: 1054.5121\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9199 - val_loss: 1054.5153\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9202 - val_loss: 1054.5188\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9204 - val_loss: 1054.5212\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9206 - val_loss: 1054.5240\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9207 - val_loss: 1054.5271\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9210 - val_loss: 1054.5294\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 168.9212 - val_loss: 1054.5319\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9213 - val_loss: 1054.5337\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9216 - val_loss: 1054.5353\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9218 - val_loss: 1054.5376\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 168.9220 - val_loss: 1054.5391\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9221 - val_loss: 1054.5406\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9225 - val_loss: 1054.5427\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9226 - val_loss: 1054.5438\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9228 - val_loss: 1054.5449\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9229 - val_loss: 1054.5459\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9232 - val_loss: 1054.5475\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9234 - val_loss: 1054.5483\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9236 - val_loss: 1054.5493\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9238 - val_loss: 1054.5500\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9240 - val_loss: 1054.5514\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9242 - val_loss: 1054.5524\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9243 - val_loss: 1054.5531\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 168.9246 - val_loss: 1054.5536\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9248 - val_loss: 1054.5543\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 168.9249 - val_loss: 1054.5546\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9252 - val_loss: 1054.5557\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9254 - val_loss: 1054.5565\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9255 - val_loss: 1054.5574\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9256 - val_loss: 1054.5577\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9258 - val_loss: 1054.5576\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9261 - val_loss: 1054.5580\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9262 - val_loss: 1054.5582\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9264 - val_loss: 1054.5583\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9266 - val_loss: 1054.5587\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9267 - val_loss: 1054.5585\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9270 - val_loss: 1054.5593\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9271 - val_loss: 1054.5596\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9273 - val_loss: 1054.5601\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9274 - val_loss: 1054.5603\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9275 - val_loss: 1054.5603\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9277 - val_loss: 1054.5602\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9279 - val_loss: 1054.5607\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9281 - val_loss: 1054.5608\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9282 - val_loss: 1054.5607\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 168.9284 - val_loss: 1054.5608\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9285 - val_loss: 1054.5607\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9287 - val_loss: 1054.5607\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 168.9288 - val_loss: 1054.5610\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 168.9289 - val_loss: 1054.5613\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9291 - val_loss: 1054.5613\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 168.9292 - val_loss: 1054.5613\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9294 - val_loss: 1054.5614\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9295 - val_loss: 1054.5614\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9296 - val_loss: 1054.5613\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9298 - val_loss: 1054.5614\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9299 - val_loss: 1054.5614\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9300 - val_loss: 1054.5614\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9301 - val_loss: 1054.5614\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9303 - val_loss: 1054.5616\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9304 - val_loss: 1054.5618\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9305 - val_loss: 1054.5618\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9306 - val_loss: 1054.5618\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9308 - val_loss: 1054.5623\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9308 - val_loss: 1054.5625\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9309 - val_loss: 1054.5625\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9310 - val_loss: 1054.5625\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9312 - val_loss: 1054.5625\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9312 - val_loss: 1054.5624\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9314 - val_loss: 1054.5625\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9315 - val_loss: 1054.5625\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9316 - val_loss: 1054.5625\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9316 - val_loss: 1054.5623\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9317 - val_loss: 1054.5624\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9319 - val_loss: 1054.5626\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9319 - val_loss: 1054.5627\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9320 - val_loss: 1054.5627\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9321 - val_loss: 1054.5625\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9322 - val_loss: 1054.5625\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9323 - val_loss: 1054.5626\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9324 - val_loss: 1054.5626\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9325 - val_loss: 1054.5626\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 168.9326 - val_loss: 1054.5629\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9326 - val_loss: 1054.5629\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9327 - val_loss: 1054.5627\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9328 - val_loss: 1054.5627\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9328 - val_loss: 1054.5627\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9330 - val_loss: 1054.5634\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9329 - val_loss: 1054.5632\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9330 - val_loss: 1054.5621\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9331 - val_loss: 1054.5621\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9332 - val_loss: 1054.5619\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9333 - val_loss: 1054.5615\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9334 - val_loss: 1054.5614\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9335 - val_loss: 1054.5614\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9336 - val_loss: 1054.5614\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9337 - val_loss: 1054.5618\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9338 - val_loss: 1054.5619\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9338 - val_loss: 1054.5619\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9338 - val_loss: 1054.5623\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9339 - val_loss: 1054.5618\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9340 - val_loss: 1054.5621\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9340 - val_loss: 1054.5624\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9340 - val_loss: 1054.5624\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9341 - val_loss: 1054.5621\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9341 - val_loss: 1054.5629\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 168.9341 - val_loss: 1054.5621\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9342 - val_loss: 1054.5619\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9343 - val_loss: 1054.5621\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9343 - val_loss: 1054.5629\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9343 - val_loss: 1054.5632\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9343 - val_loss: 1054.5631\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9344 - val_loss: 1054.5629\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9345 - val_loss: 1054.5632\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9345 - val_loss: 1054.5632\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 168.9345 - val_loss: 1054.5632\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 168.9346 - val_loss: 1054.5631\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9346 - val_loss: 1054.5625\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 168.9347 - val_loss: 1054.5629\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9348 - val_loss: 1054.5631\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9348 - val_loss: 1054.5634\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9349 - val_loss: 1054.5634\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9349 - val_loss: 1054.5634\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9350 - val_loss: 1054.5634\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 168.9350 - val_loss: 1054.5634\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9350 - val_loss: 1054.5629\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 168.9351 - val_loss: 1054.5632\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9351 - val_loss: 1054.5632\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9352 - val_loss: 1054.5632\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9352 - val_loss: 1054.5632\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9351 - val_loss: 1054.5629\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9352 - val_loss: 1054.5621\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9353 - val_loss: 1054.5623\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9353 - val_loss: 1054.5625\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9354 - val_loss: 1054.5626\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9354 - val_loss: 1054.5629\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9355 - val_loss: 1054.5636\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 168.9354 - val_loss: 1054.5637\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 168.9355 - val_loss: 1054.5640\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9355 - val_loss: 1054.5643\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9355 - val_loss: 1054.5643\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9355 - val_loss: 1054.5643\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9355 - val_loss: 1054.5640\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9356 - val_loss: 1054.5640\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9357 - val_loss: 1054.5643\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9357 - val_loss: 1054.5643\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9357 - val_loss: 1054.5643\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9357 - val_loss: 1054.5640\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9357 - val_loss: 1054.5637\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 168.9357 - val_loss: 1054.5637\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9357 - val_loss: 1054.5637\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9358 - val_loss: 1054.5636\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9358 - val_loss: 1054.5634\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9358 - val_loss: 1054.5634\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 168.9359 - val_loss: 1054.5636\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9359 - val_loss: 1054.5637\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9359 - val_loss: 1054.5634\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9359 - val_loss: 1054.5636\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9360 - val_loss: 1054.5641\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9360 - val_loss: 1054.5643\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9360 - val_loss: 1054.5643\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9360 - val_loss: 1054.5642\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9360 - val_loss: 1054.5641\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9360 - val_loss: 1054.5636\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9360 - val_loss: 1054.5634\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9361 - val_loss: 1054.5634\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9361 - val_loss: 1054.5634\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9361 - val_loss: 1054.5631\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9361 - val_loss: 1054.5631\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9361 - val_loss: 1054.5634\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9362 - val_loss: 1054.5634\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9362 - val_loss: 1054.5636\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 168.9362 - val_loss: 1054.5636\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.9362 - val_loss: 1054.5634\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9362 - val_loss: 1054.5630\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9362 - val_loss: 1054.5621\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.9362 - val_loss: 1054.5619\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(85.7336, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0020, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0125, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3008, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 341ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.55913865e+01, 6.55157563e+01, 6.54401261e+01, 6.53644958e+01,\n",
       "        6.52888655e+01, 6.52132353e+01, 6.51376050e+01, 0.00000000e+00,\n",
       "        1.84284000e-01, 5.73102950e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.63160247e+01, 6.62361928e+01, 6.61563609e+01,\n",
       "        6.60765289e+01, 6.59966970e+01, 6.59168651e+01, 6.58370331e+01,\n",
       "        6.57594538e+01, 6.56838235e+01, 6.56081933e+01, 6.55325630e+01,\n",
       "        6.54569328e+01, 6.53813025e+01, 6.53056723e+01, 6.52300420e+01,\n",
       "        6.51544118e+01, 7.01633987e+01, 6.99234360e+01, 6.95200747e+01,\n",
       "        6.91167133e+01, 6.87133520e+01, 6.83071779e+01, 6.78912115e+01,\n",
       "        6.74752451e+01, 6.70592787e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.26903900e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.72087370e-01, 2.66606960e-01, 6.53981092e+01,\n",
       "        6.53224790e+01, 6.52468487e+01, 6.51712185e+01, 7.02082166e+01,\n",
       "        7.00065359e+01, 6.86097106e+01, 6.82063492e+01, 6.78029879e+01,\n",
       "        6.73996149e+01, 6.69843685e+01, 6.65832210e+01, 6.61828499e+01,\n",
       "        6.57834080e+01, 6.53840380e+01, 5.12230400e-01, 1.77785600e-01,\n",
       "        6.88328665e+01, 6.84295051e+01, 6.80144608e+01, 6.75984944e+01,\n",
       "        6.71825280e+01, 6.67665616e+01, 6.65200397e+01, 6.62805439e+01,\n",
       "        6.60410481e+01, 7.32400000e-04, 3.74972600e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.29632500e-01,\n",
       "        6.06198692e+01, 0.00000000e+00, 3.20638180e-01, 0.00000000e+00,\n",
       "        1.88546658e-01, 0.00000000e+00, 5.15083492e-01, 4.71665800e-01,\n",
       "        0.00000000e+00, 1.45723358e-01, 2.42086664e-01, 1.39785171e-01,\n",
       "        1.05602193e+00, 4.50234294e-01, 1.08848684e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.76236689e-01, 1.13051116e-01, 6.70922697e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59.54016106, 59.53502568, 59.52989029, 59.5247549 , 59.51961951,\n",
       "       59.51448413, 59.50934874, 59.50421335, 59.49907796, 59.49394258,\n",
       "       59.48880719, 59.4836718 , 59.47853641, 59.47340103, 59.46826564,\n",
       "       59.46313025, 59.45799486, 59.45285948, 59.44772409, 59.4425887 ,\n",
       "       59.43745331, 59.43231793, 59.42718254, 59.42204715, 59.41691176,\n",
       "       59.41177638, 59.40664099, 59.4015056 , 59.39637021, 59.39123483,\n",
       "       59.38609944, 59.38096405, 59.37582866, 59.37069328, 59.36555789,\n",
       "       59.3604225 , 59.35528711, 59.35015173, 59.34501634, 59.33988095,\n",
       "       59.33474556, 59.32961018, 59.32447479, 59.3193394 , 59.31420401,\n",
       "       59.30906863, 59.30393324, 59.29879785, 59.29366246, 59.28852708,\n",
       "       59.28339169, 59.2782563 , 59.27312092, 59.26798553, 59.26285014,\n",
       "       59.25771475, 59.25257937, 59.24744398, 59.24230859, 59.2371732 ,\n",
       "       59.23203782, 59.22690243, 59.22176704, 59.21663165, 59.21149627,\n",
       "       59.20636088, 59.20122549, 59.1960901 , 59.19095472, 59.18581933,\n",
       "       59.18068394, 59.17554855, 59.17041317, 59.16527778, 59.16014239,\n",
       "       59.155007  , 59.14987162, 59.14473623, 59.13960084, 59.13446545,\n",
       "       59.12933007, 59.12419468, 59.11905929, 59.1139239 , 59.10878852,\n",
       "       59.10365313, 59.09851774, 59.09338235, 59.08824697, 59.08311158,\n",
       "       59.07797619, 59.0728408 , 59.06770542, 59.06257003, 59.05743464,\n",
       "       59.05229925, 59.04716387, 59.04202848, 59.03689309, 59.0317577 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.11233867124846\n",
      "29.530073475428136\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
