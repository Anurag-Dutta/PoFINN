{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "1345    56.879155\n",
       "1346    56.874486\n",
       "1347    56.869818\n",
       "1348    56.865149\n",
       "1349    56.860481\n",
       "Name: C6, Length: 1350, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_1250_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "1245    57.346008\n",
       "1246    57.341340\n",
       "1247    57.336671\n",
       "1248    57.332003\n",
       "1249    57.327334\n",
       "Name: C6, Length: 1250, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1250)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1, 251) (800, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 3s 58ms/step - loss: 4433.5801 - val_loss: 3467.0938\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4373.3413 - val_loss: 3437.1594\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4341.8784 - val_loss: 3410.9531\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4312.4233 - val_loss: 3384.8013\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4283.0791 - val_loss: 3358.8040\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4253.9087 - val_loss: 3332.9792\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4224.9204 - val_loss: 3307.3267\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4193.1929 - val_loss: 3272.5579\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4156.3003 - val_loss: 3245.7173\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4126.0459 - val_loss: 3218.9653\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4095.9980 - val_loss: 3192.4817\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4066.2466 - val_loss: 3166.2695\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4036.7766 - val_loss: 3140.3054\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 4007.5613 - val_loss: 3114.5671\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3978.5789 - val_loss: 3089.0371\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 3949.8105 - val_loss: 3063.7017\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3921.2441 - val_loss: 3038.5508\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3892.8684 - val_loss: 3013.5779\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3864.6785 - val_loss: 2988.7761\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 3836.6660 - val_loss: 2964.1416\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3808.8274 - val_loss: 2939.6699\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3781.1582 - val_loss: 2915.3586\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3753.6550 - val_loss: 2891.2039\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3726.3159 - val_loss: 2867.2046\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3699.1382 - val_loss: 2843.3572\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3672.1196 - val_loss: 2819.6614\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3645.2578 - val_loss: 2796.1145\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3618.5508 - val_loss: 2772.7153\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3591.9985 - val_loss: 2749.4624\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3565.5981 - val_loss: 2726.3547\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3539.3491 - val_loss: 2703.3906\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3513.2495 - val_loss: 2680.5696\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3487.2993 - val_loss: 2657.8901\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3461.4956 - val_loss: 2635.3516\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3435.8391 - val_loss: 2612.9526\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3410.3281 - val_loss: 2590.6926\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3384.9617 - val_loss: 2568.5703\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3359.7390 - val_loss: 2546.5854\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3334.6589 - val_loss: 2524.7371\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3309.7219 - val_loss: 2503.0242\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3284.9250 - val_loss: 2481.4460\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3260.2690 - val_loss: 2460.0015\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3235.7524 - val_loss: 2438.6909\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3211.3750 - val_loss: 2417.5132\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3187.1357 - val_loss: 2396.4668\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3163.0339 - val_loss: 2375.5520\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3139.0688 - val_loss: 2354.7676\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3115.2407 - val_loss: 2334.1133\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3091.5471 - val_loss: 2313.5886\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3067.9888 - val_loss: 2293.1921\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3044.5647 - val_loss: 2272.9243\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 3021.2739 - val_loss: 2252.7834\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 2998.1162 - val_loss: 2232.7695\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2975.0903 - val_loss: 2212.8821\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2952.1968 - val_loss: 2193.1199\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2929.4341 - val_loss: 2173.4834\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2906.8020 - val_loss: 2153.9712\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2884.2996 - val_loss: 2134.5825\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2861.9268 - val_loss: 2115.3179\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2839.6826 - val_loss: 2096.1753\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2817.5664 - val_loss: 2077.1558\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2795.5779 - val_loss: 2058.2578\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2773.7168 - val_loss: 2039.4805\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2751.9822 - val_loss: 2020.8242\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2730.3735 - val_loss: 2002.2878\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2708.8899 - val_loss: 1983.8711\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2687.5315 - val_loss: 1965.5736\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2666.2976 - val_loss: 1947.3948\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2645.1870 - val_loss: 1929.3333\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2624.2004 - val_loss: 1911.3899\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2603.3364 - val_loss: 1893.5631\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2582.5942 - val_loss: 1875.8529\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2561.9744 - val_loss: 1858.2585\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 2541.4751 - val_loss: 1840.7795\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2521.0969 - val_loss: 1823.4156\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2500.8384 - val_loss: 1806.1663\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2480.7004 - val_loss: 1789.0305\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2460.6814 - val_loss: 1772.0085\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2440.7810 - val_loss: 1755.0992\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2420.9985 - val_loss: 1738.3027\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2401.3345 - val_loss: 1721.6179\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2381.7871 - val_loss: 1705.0449\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2362.3567 - val_loss: 1688.5828\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2343.0422 - val_loss: 1672.2312\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2323.8435 - val_loss: 1655.9899\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2304.7605 - val_loss: 1639.8580\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2285.7925 - val_loss: 1623.8347\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2266.9380 - val_loss: 1607.9211\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2248.1980 - val_loss: 1592.1150\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2229.5715 - val_loss: 1576.4171\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2211.0581 - val_loss: 1560.8263\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2192.6567 - val_loss: 1545.3425\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2174.3679 - val_loss: 1529.9651\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2156.1904 - val_loss: 1514.6934\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2138.1243 - val_loss: 1499.5267\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2120.1685 - val_loss: 1484.4656\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 2102.3228 - val_loss: 1469.5088\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2084.5864 - val_loss: 1454.6562\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2066.9604 - val_loss: 1439.9075\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2049.4429 - val_loss: 1425.2615\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2032.0336 - val_loss: 1410.7186\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2014.7321 - val_loss: 1396.2778\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1997.5383 - val_loss: 1381.9392\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1980.4515 - val_loss: 1367.7019\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1963.4713 - val_loss: 1353.5657\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1946.5977 - val_loss: 1339.5299\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1929.8293 - val_loss: 1325.5944\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1913.1663 - val_loss: 1311.7584\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1896.6086 - val_loss: 1298.0219\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1880.1550 - val_loss: 1284.3840\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1863.8054 - val_loss: 1270.8446\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1847.5598 - val_loss: 1257.4034\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1831.4172 - val_loss: 1244.0599\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1815.3773 - val_loss: 1230.8132\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1799.4397 - val_loss: 1217.6635\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1783.6041 - val_loss: 1204.6101\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1767.8699 - val_loss: 1191.6523\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1752.2367 - val_loss: 1178.7899\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1736.7043 - val_loss: 1166.0228\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1721.2721 - val_loss: 1153.3502\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1705.9395 - val_loss: 1140.7723\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1690.7067 - val_loss: 1128.2878\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1675.5726 - val_loss: 1115.8969\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1660.5375 - val_loss: 1103.5989\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1645.6006 - val_loss: 1091.3936\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1630.7615 - val_loss: 1079.2805\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1616.0193 - val_loss: 1067.2594\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1601.3743 - val_loss: 1055.3292\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1586.8259 - val_loss: 1043.4904\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1572.3738 - val_loss: 1031.7416\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1558.0170 - val_loss: 1020.0836\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1543.7561 - val_loss: 1008.5150\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1529.5896 - val_loss: 997.0356\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1515.5181 - val_loss: 985.6456\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1501.5408 - val_loss: 974.3444\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1487.6575 - val_loss: 963.1310\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1473.8669 - val_loss: 952.0055\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1460.1700 - val_loss: 940.9672\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1446.5654 - val_loss: 930.0161\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1433.0530 - val_loss: 919.1517\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1419.6326 - val_loss: 908.3734\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1406.3033 - val_loss: 897.6810\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1393.0654 - val_loss: 887.0744\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1379.9182 - val_loss: 876.5526\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1366.8615 - val_loss: 866.1156\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1353.8943 - val_loss: 855.7626\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1341.0168 - val_loss: 845.4938\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1328.2285 - val_loss: 835.3088\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1315.5289 - val_loss: 825.2064\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1302.9181 - val_loss: 815.1874\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1290.3950 - val_loss: 805.2501\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1277.9597 - val_loss: 795.3950\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1265.6115 - val_loss: 785.6222\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1253.3502 - val_loss: 775.9298\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1241.1750 - val_loss: 766.3188\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1229.0867 - val_loss: 756.7883\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1217.0837 - val_loss: 747.3376\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1205.1663 - val_loss: 737.9670\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1193.3337 - val_loss: 728.6758\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1181.5864 - val_loss: 719.4637\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1169.9231 - val_loss: 710.3301\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1158.3435 - val_loss: 701.2746\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1146.8475 - val_loss: 692.2972\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1135.4351 - val_loss: 683.3973\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1124.1051 - val_loss: 674.5747\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1112.8578 - val_loss: 665.8286\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1101.6924 - val_loss: 657.1594\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1090.6091 - val_loss: 648.5662\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1079.6071 - val_loss: 640.0482\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1068.6862 - val_loss: 631.6063\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1057.8458 - val_loss: 623.2393\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1047.0857 - val_loss: 614.9464\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1036.4056 - val_loss: 606.7281\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1025.8054 - val_loss: 598.5840\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1015.2844 - val_loss: 590.5131\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1004.8424 - val_loss: 582.5153\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 994.4786 - val_loss: 574.5902\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 984.1930 - val_loss: 566.7381\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 973.9855 - val_loss: 558.9579\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 963.8553 - val_loss: 551.2494\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 953.8024 - val_loss: 543.6124\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 943.8263 - val_loss: 536.0463\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 933.9268 - val_loss: 528.5511\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 924.1031 - val_loss: 521.1260\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 914.3551 - val_loss: 513.7713\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 904.6826 - val_loss: 506.4857\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 895.0851 - val_loss: 499.2701\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 885.5627 - val_loss: 492.1229\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 876.1146 - val_loss: 485.0443\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 866.7404 - val_loss: 478.0339\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 857.4398 - val_loss: 471.0916\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 848.2124 - val_loss: 464.2165\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 839.0581 - val_loss: 457.4089\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 829.9766 - val_loss: 450.6683\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 820.9672 - val_loss: 443.9936\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 812.0298 - val_loss: 437.3852\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 803.1642 - val_loss: 430.8428\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 794.3699 - val_loss: 424.3661\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 785.6465 - val_loss: 417.9540\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 776.9937 - val_loss: 411.6067\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 768.4111 - val_loss: 405.3242\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 759.8987 - val_loss: 399.1057\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 751.4559 - val_loss: 392.9507\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 743.0822 - val_loss: 386.8592\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 734.7776 - val_loss: 380.8305\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 726.5414 - val_loss: 374.8648\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 718.3735 - val_loss: 368.9613\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 710.2735 - val_loss: 363.1198\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 702.2411 - val_loss: 357.3398\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 694.2761 - val_loss: 351.6213\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 686.3782 - val_loss: 345.9640\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 678.5467 - val_loss: 340.3674\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 670.7816 - val_loss: 334.8306\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 663.0822 - val_loss: 329.3543\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 655.4487 - val_loss: 323.9373\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 647.8802 - val_loss: 318.5799\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 640.3770 - val_loss: 313.2812\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 632.9381 - val_loss: 308.0411\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 625.5637 - val_loss: 302.8596\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 618.2531 - val_loss: 297.7357\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 611.0062 - val_loss: 292.6695\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 603.8227 - val_loss: 287.6606\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 596.7022 - val_loss: 282.7086\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 589.6444 - val_loss: 277.8134\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 582.6489 - val_loss: 272.9744\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 575.7156 - val_loss: 268.1910\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 568.8437 - val_loss: 263.4637\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 562.0336 - val_loss: 258.7917\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 555.2842 - val_loss: 254.1743\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 548.5956 - val_loss: 249.6116\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 541.9674 - val_loss: 245.1035\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 535.3995 - val_loss: 240.6489\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 528.8910 - val_loss: 236.2481\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 522.4420 - val_loss: 231.9004\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 516.0522 - val_loss: 227.6060\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 509.7214 - val_loss: 223.3641\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 503.4491 - val_loss: 219.1744\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 497.2348 - val_loss: 215.0367\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 491.0783 - val_loss: 210.9509\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 484.9794 - val_loss: 206.9158\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 478.9377 - val_loss: 202.9322\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 472.9530 - val_loss: 198.9990\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 467.0246 - val_loss: 195.1163\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 461.1527 - val_loss: 191.2835\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 455.3367 - val_loss: 187.5007\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 449.5764 - val_loss: 183.7666\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 443.8712 - val_loss: 180.0820\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 438.2212 - val_loss: 176.4460\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 432.6258 - val_loss: 172.8584\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 427.0849 - val_loss: 169.3189\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 421.5978 - val_loss: 165.8268\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 416.1647 - val_loss: 162.3823\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 410.7849 - val_loss: 158.9847\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 405.4581 - val_loss: 155.6341\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 400.1844 - val_loss: 152.3297\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 394.9630 - val_loss: 149.0715\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 389.7938 - val_loss: 145.8591\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 384.6765 - val_loss: 142.6922\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 379.6108 - val_loss: 139.5702\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 374.5963 - val_loss: 136.4930\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 369.6326 - val_loss: 133.4604\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 364.7196 - val_loss: 130.4719\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 359.8568 - val_loss: 127.5274\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 355.0443 - val_loss: 124.6265\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 350.2813 - val_loss: 121.7683\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 345.5676 - val_loss: 118.9536\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 340.9033 - val_loss: 116.1812\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 336.2874 - val_loss: 113.4509\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 331.7202 - val_loss: 110.7626\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 327.2011 - val_loss: 108.1158\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 322.7298 - val_loss: 105.5105\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 318.3062 - val_loss: 102.9461\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 313.9298 - val_loss: 100.4224\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 309.6003 - val_loss: 97.9388\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 305.3174 - val_loss: 95.4956\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 301.0809 - val_loss: 93.0918\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 296.8904 - val_loss: 90.7274\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 292.7455 - val_loss: 88.4021\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 288.6461 - val_loss: 86.1152\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 284.5916 - val_loss: 83.8673\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 280.5822 - val_loss: 81.6571\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 276.6171 - val_loss: 79.4851\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 272.6966 - val_loss: 77.3503\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 268.8197 - val_loss: 75.2529\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 264.9865 - val_loss: 73.1920\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 261.1964 - val_loss: 71.1680\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 257.4494 - val_loss: 69.1802\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 253.7453 - val_loss: 67.2284\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 250.0835 - val_loss: 65.3121\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 246.4639 - val_loss: 63.4312\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 242.8860 - val_loss: 61.5852\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 239.3496 - val_loss: 59.7738\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 235.8545 - val_loss: 57.9969\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 232.4003 - val_loss: 56.2539\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 228.9865 - val_loss: 54.5449\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 225.6132 - val_loss: 52.8693\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 222.2800 - val_loss: 51.2268\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 218.9863 - val_loss: 49.6171\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 215.7321 - val_loss: 48.0400\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 212.5172 - val_loss: 46.4950\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 209.3410 - val_loss: 44.9821\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 206.2034 - val_loss: 43.5005\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 203.1040 - val_loss: 42.0505\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 200.0427 - val_loss: 40.6315\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 197.0190 - val_loss: 39.2431\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 194.0326 - val_loss: 37.8852\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 191.0835 - val_loss: 36.5572\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 188.1709 - val_loss: 35.2591\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 185.2950 - val_loss: 33.9906\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 182.4554 - val_loss: 32.7513\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 179.6518 - val_loss: 31.5407\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 176.8837 - val_loss: 30.3589\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 174.1510 - val_loss: 29.2052\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 171.4534 - val_loss: 28.0797\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 168.7905 - val_loss: 26.9817\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 166.1621 - val_loss: 25.9112\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 163.5681 - val_loss: 24.8678\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 161.0078 - val_loss: 23.8511\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 158.4812 - val_loss: 22.8611\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 155.9881 - val_loss: 21.8973\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 153.5280 - val_loss: 20.9594\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 151.1008 - val_loss: 20.0472\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 148.7060 - val_loss: 19.1602\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 146.3435 - val_loss: 18.2984\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 144.0129 - val_loss: 17.4613\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 141.7140 - val_loss: 16.6486\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 139.4466 - val_loss: 15.8601\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 137.2101 - val_loss: 15.0955\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 135.0045 - val_loss: 14.3546\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 132.8294 - val_loss: 13.6370\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 130.6848 - val_loss: 12.9424\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 128.5701 - val_loss: 12.2705\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 126.4851 - val_loss: 11.6211\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 124.4296 - val_loss: 10.9940\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 122.4033 - val_loss: 10.3887\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 120.4059 - val_loss: 9.8050\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 118.4372 - val_loss: 9.2427\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 116.4968 - val_loss: 8.7014\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 114.5844 - val_loss: 8.1809\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 112.6998 - val_loss: 7.6810\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 110.8430 - val_loss: 7.2012\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 109.0134 - val_loss: 6.7414\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 107.2109 - val_loss: 6.3013\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 105.4350 - val_loss: 5.8807\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 103.6857 - val_loss: 5.4791\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 101.9626 - val_loss: 5.0964\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 100.2656 - val_loss: 4.7323\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 98.5941 - val_loss: 4.3865\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 96.9483 - val_loss: 4.0588\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 95.3276 - val_loss: 3.7489\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 93.7319 - val_loss: 3.4565\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 92.1608 - val_loss: 3.1813\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 90.6140 - val_loss: 2.9232\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 89.0916 - val_loss: 2.6818\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 87.5928 - val_loss: 2.4568\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 86.1178 - val_loss: 2.2481\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 84.6662 - val_loss: 2.0553\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 83.2376 - val_loss: 1.8782\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 81.8320 - val_loss: 1.7165\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 80.4490 - val_loss: 1.5700\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 79.0883 - val_loss: 1.4385\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 77.7498 - val_loss: 1.3216\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 76.4332 - val_loss: 1.2191\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 75.1382 - val_loss: 1.1309\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 73.8647 - val_loss: 1.0565\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 72.6124 - val_loss: 0.9959\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 71.3809 - val_loss: 0.9486\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 70.1701 - val_loss: 0.9146\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 68.9796 - val_loss: 0.8935\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 67.8094 - val_loss: 0.8851\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 66.6591 - val_loss: 0.8892\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 65.5286 - val_loss: 0.9055\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 64.4175 - val_loss: 0.9338\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 63.3255 - val_loss: 0.9738\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 62.2527 - val_loss: 1.0253\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 61.1985 - val_loss: 1.0882\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 60.1630 - val_loss: 1.1621\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 59.1458 - val_loss: 1.2468\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 58.1465 - val_loss: 1.3421\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 57.1652 - val_loss: 1.4478\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 56.2015 - val_loss: 1.5636\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 55.2551 - val_loss: 1.6894\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 54.3259 - val_loss: 1.8248\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 53.4138 - val_loss: 1.9698\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 52.5183 - val_loss: 2.1240\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 51.6392 - val_loss: 2.2872\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 50.7766 - val_loss: 2.4593\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 49.9300 - val_loss: 2.6399\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 49.0993 - val_loss: 2.8290\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 48.2842 - val_loss: 3.0263\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 47.4846 - val_loss: 3.2315\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 46.7001 - val_loss: 3.4446\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 45.9306 - val_loss: 3.6652\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 45.1760 - val_loss: 3.8932\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 44.4359 - val_loss: 4.1284\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 43.7103 - val_loss: 4.3705\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 42.9987 - val_loss: 4.6194\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 42.3012 - val_loss: 4.8750\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 41.6175 - val_loss: 5.1368\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 40.9473 - val_loss: 5.4049\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 40.2905 - val_loss: 5.6790\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 39.6469 - val_loss: 5.9589\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 39.0163 - val_loss: 6.2445\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 38.3985 - val_loss: 6.5355\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 37.7932 - val_loss: 6.8317\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 37.2004 - val_loss: 7.1330\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 36.6199 - val_loss: 7.4392\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 36.0514 - val_loss: 7.7502\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 35.4947 - val_loss: 8.0657\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 34.9496 - val_loss: 8.3855\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 34.4162 - val_loss: 8.7096\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 33.8939 - val_loss: 9.0377\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 33.3828 - val_loss: 9.3698\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 32.8826 - val_loss: 9.7055\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 32.3931 - val_loss: 10.0448\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 31.9143 - val_loss: 10.3874\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 31.4459 - val_loss: 10.7333\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 30.9877 - val_loss: 11.0822\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 30.5396 - val_loss: 11.4341\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 30.1015 - val_loss: 11.7887\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 29.6730 - val_loss: 12.1460\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 29.2541 - val_loss: 12.5057\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 28.8447 - val_loss: 12.8677\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 28.4444 - val_loss: 13.2320\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 28.0533 - val_loss: 13.5982\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 27.6711 - val_loss: 13.9663\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 27.2977 - val_loss: 14.3362\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 26.9329 - val_loss: 14.7076\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 26.5766 - val_loss: 15.0806\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 26.2286 - val_loss: 15.4549\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 25.8887 - val_loss: 15.8304\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 25.5569 - val_loss: 16.2071\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 25.2329 - val_loss: 16.5847\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 24.9167 - val_loss: 16.9631\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 24.6080 - val_loss: 17.3423\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 24.3067 - val_loss: 17.7221\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 24.0128 - val_loss: 18.1024\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23.7260 - val_loss: 18.4829\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23.4462 - val_loss: 18.8638\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23.1734 - val_loss: 19.2449\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 22.9073 - val_loss: 19.6260\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22.6478 - val_loss: 20.0071\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 22.3947 - val_loss: 20.3880\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 22.1480 - val_loss: 20.7686\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 21.9076 - val_loss: 21.1488\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 21.6733 - val_loss: 21.5284\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 21.4451 - val_loss: 21.9077\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 21.2226 - val_loss: 22.2860\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 21.0059 - val_loss: 22.6638\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 20.7948 - val_loss: 23.0407\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 20.5893 - val_loss: 23.4166\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 20.3892 - val_loss: 23.7914\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 20.1943 - val_loss: 24.1653\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 20.0046 - val_loss: 24.5378\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 19.8200 - val_loss: 24.9091\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 19.6403 - val_loss: 25.2791\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 19.4655 - val_loss: 25.6477\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 19.2954 - val_loss: 26.0148\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 19.1299 - val_loss: 26.3803\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 18.9690 - val_loss: 26.7441\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 18.8125 - val_loss: 27.1062\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 18.6603 - val_loss: 27.4665\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 18.5124 - val_loss: 27.8250\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 18.3686 - val_loss: 28.1815\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 18.2289 - val_loss: 28.5362\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 18.0930 - val_loss: 28.8888\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 17.9611 - val_loss: 29.2394\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 17.8329 - val_loss: 29.5878\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 17.7084 - val_loss: 29.9340\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 17.5875 - val_loss: 30.2779\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 17.4701 - val_loss: 30.6197\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 17.3561 - val_loss: 30.9590\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 17.2455 - val_loss: 31.2960\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 17.1382 - val_loss: 31.6304\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 17.0340 - val_loss: 31.9625\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 16.9329 - val_loss: 32.2921\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 16.8349 - val_loss: 32.6189\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 16.7398 - val_loss: 32.9432\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 16.6476 - val_loss: 33.2648\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 16.5582 - val_loss: 33.5840\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 16.4715 - val_loss: 33.9004\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 16.3875 - val_loss: 34.2139\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 16.3061 - val_loss: 34.5248\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 16.2272 - val_loss: 34.8327\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 16.1508 - val_loss: 35.1379\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 16.0768 - val_loss: 35.4402\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 16.0052 - val_loss: 35.7398\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.9358 - val_loss: 36.0363\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 15.8686 - val_loss: 36.3300\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 15.8035 - val_loss: 36.6209\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.7405 - val_loss: 36.9088\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 15.6796 - val_loss: 37.1936\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.6207 - val_loss: 37.4754\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.5637 - val_loss: 37.7544\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 15.5086 - val_loss: 38.0303\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 15.4552 - val_loss: 38.3029\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 15.4037 - val_loss: 38.5729\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 15.3539 - val_loss: 38.8397\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 15.3057 - val_loss: 39.1033\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 15.2592 - val_loss: 39.3640\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 471ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62.97544351, 62.95303455, 62.93062558, 62.90821662, 62.88580766,\n",
       "        62.86339869, 62.84098973, 62.81858077, 62.7961718 , 62.77376284,\n",
       "        62.75135387, 62.72894491, 62.70653595, 62.65039683, 62.58036881,\n",
       "        62.5103408 , 62.44031279, 62.37028478, 62.30025677, 62.23022876,\n",
       "        62.16020075, 62.09017274, 62.02014472, 61.95011671, 61.8800887 ,\n",
       "        61.81006069, 61.74003268, 61.67000467, 61.59997666, 61.52994865,\n",
       "        61.45992063, 61.38989262, 61.31986461, 61.2498366 , 61.17980859,\n",
       "        61.10978058, 61.03975257, 60.96972456, 60.89969655, 60.82966853,\n",
       "        60.75964052, 60.68961251, 60.6195845 , 60.54955649, 60.47952848,\n",
       "        60.40950047, 60.33947246, 60.26944444, 60.19953315, 60.14351074,\n",
       "        60.08748833, 60.03146592, 59.97544351, 59.9194211 , 59.86339869,\n",
       "        59.80737628, 59.75135387, 59.69533147, 59.63930906, 59.58328665,\n",
       "        59.52726424, 59.47124183, 59.41521942, 59.35919701, 59.3031746 ,\n",
       "        59.24715219, 59.19112979, 59.13510738, 59.07908497, 59.02306256,\n",
       "        58.96704015, 58.91101774, 58.85499533, 58.79897292, 58.74295051,\n",
       "        58.6869281 , 58.6309057 , 58.57488329, 58.51886088, 58.46283847,\n",
       "        66.17388153,  0.31163469,  0.44068536,  0.        ,  0.12218942,\n",
       "         0.        ,  0.2638728 ,  0.        ,  0.        ,  0.12010509,\n",
       "         0.60259235,  0.        ,  0.61902517,  0.        ,  0.        ,\n",
       "         0.        ,  0.20256329,  0.21998081,  1.01625216,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([57.32266573, 57.3179972 , 57.31332866, 57.30866013, 57.3039916 ,\n",
       "       57.29932306, 57.29465453, 57.28998599, 57.28531746, 57.28064893,\n",
       "       57.27598039, 57.27131186, 57.26664332, 57.26197479, 57.25730626,\n",
       "       57.25263772, 57.24796919, 57.24330065, 57.23863212, 57.23396359,\n",
       "       57.22929505, 57.22462652, 57.21995798, 57.21528945, 57.21062092,\n",
       "       57.20595238, 57.20128385, 57.19661531, 57.19194678, 57.18727824,\n",
       "       57.18260971, 57.17794118, 57.17327264, 57.16860411, 57.16393557,\n",
       "       57.15926704, 57.15459851, 57.14992997, 57.14526144, 57.1405929 ,\n",
       "       57.13592437, 57.13125584, 57.1265873 , 57.12191877, 57.11725023,\n",
       "       57.1125817 , 57.10791317, 57.10324463, 57.0985761 , 57.09390756,\n",
       "       57.08923903, 57.08457049, 57.07990196, 57.07523343, 57.07056489,\n",
       "       57.06589636, 57.06122782, 57.05655929, 57.05189076, 57.04722222,\n",
       "       57.04255369, 57.03788515, 57.03321662, 57.02854809, 57.02387955,\n",
       "       57.01921102, 57.01454248, 57.00987395, 57.00520542, 57.00053688,\n",
       "       56.99586835, 56.99119981, 56.98653128, 56.98186275, 56.97719421,\n",
       "       56.97252568, 56.96785714, 56.96318861, 56.95852007, 56.95385154,\n",
       "       56.94918301, 56.94451447, 56.93984594, 56.9351774 , 56.93050887,\n",
       "       56.92584034, 56.9211718 , 56.91650327, 56.91183473, 56.9071662 ,\n",
       "       56.90249767, 56.89782913, 56.8931606 , 56.88849206, 56.88382353,\n",
       "       56.879155  , 56.87448646, 56.86981793, 56.86514939, 56.86048086])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.978823008051492\n",
      "13.820205966502046\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
