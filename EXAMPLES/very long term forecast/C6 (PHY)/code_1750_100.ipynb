{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "1845    52.872619\n",
       "1846    52.856746\n",
       "1847    52.840873\n",
       "1848    52.825000\n",
       "1849    52.809127\n",
       "Name: C6, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_1750_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "1745     0.183813\n",
       "1746     0.323350\n",
       "1747     0.000000\n",
       "1748     0.963653\n",
       "1749     0.273746\n",
       "Name: C6, Length: 1750, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1750)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAxBklEQVR4nO3dd3hUZdr48e89k0YaIZWWQCAJCIiU0EQEG6KroGtDXRfLio1dXbe87utv1dXXd1e3qKtYWHXVfVfFDupaUAELNfQOSQwh1JCETkh7fn/MmTDESTKTmWQymftzXXNl5sxzZu45Sc49TznPI8YYlFJKhS5boANQSikVWJoIlFIqxGkiUEqpEKeJQCmlQpwmAqWUCnFhgQ6gJZKTk03v3r0DHYZSSgWVFStW7DfGpDTcHpSJoHfv3uTl5QU6DKWUCioist3ddm0aUkqpEKeJQCmlQpwmAqWUCnGaCJRSKsRpIlBKqRCniUAppUKcJgKllApxfkkEIjJJRLaISL6I3Ofm+XtFZKOIrBWRL0Wkl8tz00Rkm3Wb5o94GvPa4iLmrtnVmm+hlFJBx+dEICJ2YCZwETAAuFZEBjQotgrINcYMBt4BHrf2TQQeBEYBI4EHRaSLrzE1ZvbyHbyzoqS1Xl4ppYKSP2oEI4F8Y0yhMaYKeBOY4lrAGDPfGHPMergE6GndvxCYZ4wpN8ZUAPOASX6Iya0+KbEUlh5prZdXSqmg5I9E0APY4fK4xNrWmFuAT7zdV0Smi0ieiOSVlpa2KNA+yTHsPHCcyuraFu2vlFIdUZt2FovIT4Bc4M/e7muMmWWMyTXG5Kak/GDOJI/0TY3FGCgqO9qi/ZVSqiPyRyLYCaS7PO5pbTuFiJwP3A9MNsac8GZff+mTHANAwT5NBEop5eSPRLAcyBaRTBGJAKYCc10LiMhQ4AUcSWCfy1OfARNFpIvVSTzR2tYq+qQ4EoH2Eyil1Ek+T0NtjKkRkRk4TuB24GVjzAYReRjIM8bMxdEUFAu8LSIAxcaYycaYchF5BEcyAXjYGFPua0yNiY4Io3vnKAr3a41AKaWc/LIegTHmP8B/Gmx7wOX++U3s+zLwsj/i8ISOHFJKqVOF3JXFfVJiKCw9ijEm0KEopVS7EHKJoG9KLIdP1FB6+ETzhZVSKgSEXCJwdhgXlGo/gVJKQQgmgr4psQBs23c4wJEopVT7EHKJoFvnKLrGR7H0+1YbnKSUUkEl5BKBiDC6TyJLC8u0w1gppQjBRAAwpm8S+49UUaDDSJVSKjQTweg+SQAsLtTmIaWUCslEkJEYTbfOUSwpLAt0KEopFXAhmQgc/QRJ2k+glFKEaCIAGNPH0U+Qv0/7CZRSoS1kE4Gzn0Cbh5RSoS5kE0F6Yie6d45iiXYYK6VCXMgmAhFhdN8klmg/gVIqxIVsIgBH81DZ0Sq2aT+BUiqEhXQiGJuVjE3guQUFWitQSoWskE4EPRI6cfd5Oby/aifvrCgJdDhKKRUQIZ0IAGacm8WYPkk8MGcD+TojqVIqBIV8IrDbhKemDiE6ws5d/15FZXVtoENSSqk2FfKJACA1Poq/XTOELXsP84cPNwY6HKWUalOaCCzjc1K4fXxf3lhWzIdrdgU6HKWUajN+SQQiMklEtohIvojc5+b5s0VkpYjUiMiVDZ6rFZHV1m2uP+JpqV9NzGFYRgK/e28d28t0KUulVGjwORGIiB2YCVwEDACuFZEBDYoVAzcCr7t5iePGmCHWbbKv8fgi3G7j79cOxW4TZry+ihM12l+glOr4/FEjGAnkG2MKjTFVwJvAFNcCxpgiY8xaoM4P79eqenaJ5vErB7Nu50H+9MnmQIejlFKtzh+JoAeww+VxibXNU1EikiciS0TkssYKich0q1xeaWlpC0P1zIUDu3Ljmb3553dFzNu4t1XfSymlAq09dBb3MsbkAtcBT4pIX3eFjDGzjDG5xpjclJSUVg/qdxf3Z1CPeH799hp2Hjje6u+nlFKB4o9EsBNId3nc09rmEWPMTutnIbAAGOqHmHwWGWbnmWuHUVtn+MUbq6ipbfetWkop1SL+SATLgWwRyRSRCGAq4NHoHxHpIiKR1v1kYCzQbgby906O4dHLB7FiewXPLywIdDhKKdUqfE4ExpgaYAbwGbAJeMsYs0FEHhaRyQAiMkJESoCrgBdEZIO1+2lAnoisAeYDfzLGtJtEADBlSA8uGdyNp77cxoZdBwMdjlJK+Z0E46ybubm5Ji8vr83er+JoFROf/JrE6Ajm/nwskWH2NntvpZTyFxFZYfXJnqI9dBa3e11iInj8isFs2XuYv83bGuhwlFLKrzQReOic/qlcOzKdWV8Xkleky1sqpToOTQReuP9HA+jZpRO/enuNzlKqlOowNBF4ITYyjEcvO53tZcd4O29H8zsopVQQ0ETgpXHZyeT26sKzCwp0LiKlVIegicBLIsIvzstm98FKXd5SKdUhaCJogXHZyQzNSODZ+QVU1egVx0qp4KaJoAWctYKdB47z3kqtFSilgpsmghaakJPCGT07M3NBPtU6D5FSKohpImghZ61gR/lx3l/l8Rx7SinV7mgi8MG5/VMZ1COemfPzdXZSpVTQ0kTgAxHhF+dms73sGHN1wXulVJDSROCjCwakcVq3eJ75Kp/auuCbwE8ppTQR+EhEuPu8LAr3H+WjtVorUEoFH00EfjBxQFf6pcXxxLytlB+tCnQ4SinlFU0EfmCzCQ9eOoBdByu54rlFFJcdC3RISinlMU0EfnJmVjL//tkoyo9W8ePnvmNdia5mppQKDpoI/GhE70TevWMMkWF2rpm1mAVb9gU6JKWUapYmAj/LSo3j/TvPpHdSDLe8mqfTVSul2j1NBK0gNT6K2beNZkyfJH7zzlqe/nIbwbg2tFIqNGgiaCVxUeG8fOMIfjy0B3+dt5X/fn+9Xn2slGqXwgIdQEcWEWbjr1efQdfOUTy7oIB9hyp5+rqhREfoYVdKtR9+qRGIyCQR2SIi+SJyn5vnzxaRlSJSIyJXNnhumohss27T/BFPeyIi/HZSfx6ZMpCvtuzjun8spezIiUCHpZRS9XxOBCJiB2YCFwEDgGtFZECDYsXAjcDrDfZNBB4ERgEjgQdFpIuvMbVHN4zpzfM/Gc6m3Ye44rlFbC87GuiQlFIK8E+NYCSQb4wpNMZUAW8CU1wLGGOKjDFrgYaN5BcC84wx5caYCmAeMMkPMbVLFw7syuu3juLA8Wp+/Owi1uw4EOiQlFLKL4mgB+A6RrLE2ubXfUVkuojkiUheaWlpiwJtD4b3SuTdO86kU4SdqbOWMH+zXmuglAqsoBk1ZIyZZYzJNcbkpqSkBDocn/RNieW9O8+kT0oMP3stjzeXFQc6JKVUCPNHItgJpLs87mlta+19g1pqXBSzbxvD2Kxk7ntvHX/8ZBN1Oo21UioA/JEIlgPZIpIpIhHAVGCuh/t+BkwUkS5WJ/FEa1tIiI0M4+VpufxkdAYvLCzkzn+v5HhVbaDDUkqFGJ8TgTGmBpiB4wS+CXjLGLNBRB4WkckAIjJCREqAq4AXRGSDtW858AiOZLIceNjaFjLC7DYemTKI318ygM827uGaWYvZd6gy0GEppUKIBOPUB7m5uSYvLy/QYfjdvI17ufvNVSR0CuelG0dwWrf4QIeklOpARGSFMSa34fag6SwOBRcMSOOt28ZQawxXPrdIRxQppdqEJoJ2ZlCPzsy56yx6J8dwy6vLeW1xUaBDUkp1cJoI2qGunaN467YxnNs/lQfmbOChuRuo1RFFSqlWoomgnYqJDOOFG3K55axMXllUxK2v5XHkRE2gw1JKdUCaCNoxu034/SUDeOSyQSzcWspVzy9m98HjgQ5LKdXBaCIIAjeM7sVL03LZUX6MKc/oeshKKf/SRBAkJvRL5d07ziTcbuPqFxbz2YY9gQ5JKdVBaCIIIv26xvH+XWeS0zWO2/9vBf/4ulCXwFRK+UwTQZBJjYvizVtHc9Ggrjz6n0386u01VFbrtBRKqZbTRBCEOkXYeebaYfzy/BzeW7mTq55fzM4D2omslGoZTQRBymYT7j4/mxd/mkvR/qNc+vS3/Gfdbm0qUkp5TRNBkDt/QBofzBhLalwkd/57JZc9u4hFBfsDHZZSKohoIugA+qbE8vEvxvH4lYPZd6iS6/6xlJ++vIwNu3SYqVKqeTr7aAdTWV3La4uLmDm/gIPHq5kypDu/uqAfGUnRgQ5NKRVgjc0+qomggzp4vJoXFhbw8nffU1tnuG5kBj8/L5vk2MhAh6aUChBNBCFq76FKnvxiG2/l7SAqzMbPxvXh1rP7EBsZFujQlFJtTBNBiCsoPcJfP9/Cf9btISkmghnnZnHdqAwiw+yBDk0p1UZ0YZoQ1zcllmevH84Hd40lJy2OP3y4kfP/tpAPVu2kTqe4ViqkaSIIMUPSE3j91lG8evNI4iLDuWf2an709LfM37JPr0FQKkRpIghBIsL4nBQ++vlZPDV1CEdOVHPTP5dz7T+WsKq4ItDhKaXamCaCEGazCVOG9ODLeyfwh8kD2bb3CJc/u4iHP9wY6NCUUm3IL4lARCaJyBYRyReR+9w8Hykis63nl4pIb2t7bxE5LiKrrdvz/ohHeScizMa0M3uz8LfncO3IdF7+7nvmbdwb6LCUUm3E50QgInZgJnARMAC4VkQGNCh2C1BhjMkCngAec3muwBgzxLrd7ms8quViI8P4w+RB9O8ax3+/v46Ko1WBDkkp1Qb8USMYCeQbYwqNMVXAm8CUBmWmAK9a998BzhMR8cN7Kz+LCLPx16vPoOJoFQ99uCHQ4Sil2oA/EkEPYIfL4xJrm9syxpga4CCQZD2XKSKrRGShiIxr7E1EZLqI5IlIXmlpqR/CVo0Z2L0zPz83mzmrd/Hp+t2BDkcp1coC3Vm8G8gwxgwF7gVeF5F4dwWNMbOMMbnGmNyUlJQ2DTIU3XlOXwZ2j+f+99dTduREoMNRSrUifySCnUC6y+Oe1ja3ZUQkDOgMlBljThhjygCMMSuAAiDHDzEpH4XbHU1EhyqreWCuNhEp1ZH5IxEsB7JFJFNEIoCpwNwGZeYC06z7VwJfGWOMiKRYnc2ISB8gGyj0Q0zKD/p3jeee83P4eO1uPl6rTURKdVQ+JwKrzX8G8BmwCXjLGLNBRB4WkclWsZeAJBHJx9EE5BxiejawVkRW4+hEvt0YU+5rTMp/bju7D4N7dub3c9azX5uIlOqQdNI51axtew/zo79/y3mnpfLs9cPQAV9KBSeddE61WHZaHL+8IIdP1u/hQ20iUqrD0USgPHLruEyGpCfwwJz17DtcGehwlFJ+pIlAeSTMbuMvV53Bsapa7n9/vc5UqlQHoolAeSwrNZbfTOzHvI17eX9VwxHCSqlgpYlAeeXmszLJ7dWFh+ZuYPfB44EORynlB5oIlFfsNuEvV51BTZ3hN2+v1dXNlOoANBEor/VOjuH+H53Gt/n7eW1xUaDDUUr5SBOBapHrRmZwTr8U/vjJZvL3HQ50OEopH2giUC0iIjx25WCiI+z8cvYaqmvrAh2SUqqFNBGoFkuNi+J/Lz+ddTsP8vRX+YEORynVQpoIlE8uOr0bPx7ag5nz81m940Cgw1FKtYAmAuWzh6YMJC0ukntnr+Z4VW2gw1FKeUkTgfJZfFQ4f7nqDAr3H+WPn2wKdDhKKS9pIlB+cWZWMreclclri7ezcKsuJapUMNFEoPzmNxf2Izs1lt+8vYYDx6oCHY5SykOaCJTfRIXbeeKaIZQfreL/fbA+0OEopTykiUD51aAenbnn/Gw+WrubOat1YjqlgkFYoANQHc/t4/syf0sp//3eOnYeOM6wjC4M7tmZ6Aj9c1OqPdL/TOV3YXYbz1w3lFteyePxT7cAjsnq+neNY1hGF4ZmJDAsowu9kqJ12Uul2gFds1i1qvKjVazeUcHK7QdYtaOC1cUHOGpda5AYE8HQ9ASG9erC0PQEzkhPICZSv5uEoh3lx3h2QT6PTBlEmL3lLdbvryohOzWOQT06+zE673y1eS+zvi5k5nXDSIqNDFgc7jS2ZrH+16lWlRgTwbn90zi3fxoAtXWGbfsOOxJDcQUriyv4cvM+AGwCOWlx9YlhWK8u9EmO0VpDCPjl7NXkba/g8qE9GZmZ2OLX+fXba7l9fJ+AJoI9B0+wpLCc6trg+ZLtl0QgIpOApwA78KIx5k8Nno8EXgOGA2XANcaYIuu53wG3ALXAL4wxn/kjJtU+OZqI4unfNZ7rRmUAcPBYNat2VLCy2JEcPlyzi9eXFgPQuVM4QzMSGJmZyLQxvbXG0EHZrGTvawuFMQYhsF8cDI7PYAui7y8+/1eJiB2YCVwAlADLRWSuMWajS7FbgApjTJaITAUeA64RkQHAVGAg0B34QkRyjDE6T0EI6RwdzoR+qUzolwpAXZ2hoPQIK4srWFV8gJXFFTz+6RZmL9/B364+g+G9Wv6NUbVPzkqfr+scGZfXCpT6zxBEicAfw0dHAvnGmEJjTBXwJjClQZkpwKvW/XeA88RR358CvGmMOWGM+R7It15PhTCbTchOi+OaERn86YrBfP7L8cyePpraOsNVzy/mz59tpqpGp73uSJw1gjqfawS+n39fWFjApU9/61sQEPCaiTf8kQh6ADtcHpdY29yWMcbUAAeBJA/3BUBEpotInojklZbqFAahZlSfJD65exxXDOvJzPkFXP7sd2zdqwvidBR2m38SAeBzleCPn2xm3c6DgKOpqdbLaoqz9N/mbeGGl5ZSWd3yBo7q2jpWFVew/8iJFr+GJ4LmgjJjzCxjTK4xJjclJSXQ4agAiIsK589XncGsG4az52Allzz9LS9+U6jrJncA/mgaMvXfxB0nUH/MhDv5me+Y/pp3IxSduayw9CjfbNvPE/O2tvj9Dx2v5vJnF/Hx2t0tfg1P+CMR7ATSXR73tLa5LSMiYUBnHJ3Gnuyr1CkmDuzKZ788m7OzU/ifjzdx3YtLKKk4FuiwlA/80TTk3FUEHvtkM8P/Z57PcYXZhSovV99zJiTnZ/Fl1FuNlRnD7K3bzOSPRLAcyBaRTBGJwNH5O7dBmbnANOv+lcBXxnG05gJTRSRSRDKBbGCZH2JSHVxybCT/+OlwHr9iMOtKDnLRk9/w7ooSn0edqMBwNg3NWbWTrzbvbdFrnOyjFWw2wR9/CuF2m9f9Uc63XV5UAUDR/qNNll9XcpBP1rn/xu9MBOG21m288fnVrTb/GcBnwCbgLWPMBhF5WEQmW8VeApJEJB+4F7jP2ncD8BawEfgUuEtHDClPiQhXj0jn03vO5rRu8fzq7TXc8X8rKT+qM58GG+dQyw9W7+LNZTuaLtyI+qYhgQPHqjheXcuv3lrT4pge+3Qzy74v93o97oYJqLKm6VPauytL+O27a90+97v31gHwl8+3sKSwzKs4vOGXNGOM+Y8xJscY09cY86i17QFjzFzrfqUx5ipjTJYxZqQxptBl30et/foZYz7xRzwqtKQnRvPG9NHcd1F/vtq8j4lPfN3ib5UqMFybT6pr69hR7n1Tn+uozXkbHb//d1eWtDimYisGr5uGvHyfEzW1RIXb3T73tbW2x77DJ5g6awnrrU5sfwuazmKlmmK3CbeP78ucGWNJjo3g5lfy+N176zh6oibQoSkP2F0SwfwtpVzzwmKvBwE4v4l/vnEvhyp9/71HWFNdVNd4G4d35Sur64gK9+xUXFB6xKvX9pQmAtWhnNYtnjkzxnLb+D68ubyYi//+DcuLygMdlmpGwybwXQcrOXC82qvXcF7Ru27nQa+HfLoTZrVXeds0VOPle1dW1xIV5r5G0NDigrJWGSWniUB1OJFhdn530WnMnj6GOmO4+oXFPDR3A8eqtHbQXrkbWePtCCJ/jxNw9jWd8LKz+FiDWmhzcZ2oqSPSwxrBm8t3eN1U5QlNBKrDGpmZyKd3n820Mb15ZVERFz75NYvy9wc6LOWG3V0iCPD1IUVljtE+d0zo69V+DefDau5TnKipJdLDGgGcHGHlT5oIVIcWExnGQ5MH8tZtY7CLcN2LS5n+Wh6vLipi465DAT/ZKIeYyB+eCGsDXCOICLMTGxnGT0b38i4OL9+nrs59ImyMN2U9pVM5qpAwMjORT+4+m6e+3Mac1Tv53BpVEh8VRm7vREb0TmRkZhdO75FARJh+P2prsW5mlfV+agf/ZoKIMJvX/QPgfUKqM8ajWTF6dulEScVxbK1QI9BEoEJGpwg7913Un/+a1I+SiuMsLypn2fflLCsq5ytrTYSocBtD0hMY2TuREZmJDMvoolNftwF3x9jbE6q/awSRdpvXHb/gfUIy5oed5e6ItE6zEGgiUCFIREhPjCY9MZofD+sJwP4jJ8grKmfp9+UsLyrnmfn51H3l+Mcb1D3eqjE4ag5dYiIC/Anar/x9h5nx+iruPCeLyWd093g/5zj6PikxFJY62uZbOtmbv4SHCbV1xrHGQRNf2V9dVMQA628EfpiQXIeTLi0s438/2cy/bhlJfFS4FbfBJs1nAkFapVkINBEoBTimrJg0qBuTBnUD4HBlNSuLD7Ds+zKWf1/Ba0u28+K33wOQnRrLiMxERmUmcuHAro1eDBSKCkqPsnnPYX7xxiq+3LSXx64Y7NHxcZ4reyVGn0wEXvcR+DcVnNk3mVGZSdQZaGqqnwfnbgCg4H8vbvYb+5w1u1iz4wCzFhby6wv7AY6J9jw9v2uNQKk2FBcVzvicFMbnOGa6rayuZd3Og46mpO/LmbvasYpaTlosT00dymnd4gMccfvgPBdfNqQ7H6zexWnd4rl9fPOjbpzNKa7rFXt7Yvd3jWB0n0SvFkHK33eEfl3jmoy7T3IMAB+t3VWfCIwx9ZPuNaU1m4a0V0wpD0SF2xnRO5G7zsni1ZtHsubBibw0LZfyo9VMmfkd//zue53wjpMn79vG92VcdjIvflPo0Xz8zkPXNyW2fpu3/bT+P/zenXQ37znUbBzOayOKyo7VN305agRNv1d2aizxUeGttvylJgKlWsBuE847LY3P7hnHuKxk/vDhRm56ZTmlh1t3AZH2znkOtIlw1zlZ7D9Sxdt5nk8i98sLsnn+J8MA7/sI/F0l8LS5JtIaZbZlj2OhJGfYj11x+g/KuiYJ53xKjnWWm/bBXWMZkp6gNQKl2qOk2EhenJbLw1MGsrigjIue+pr51gikUHRyDn4YlZnIsIwEXvi6kJpmvt6fXFRG6r8de31lsZ8zgSfNNXByKor8fUdOiaNr506Oxy5huea2LdYKe4bmF7oXcfSZaCJQqp0SEX46pjcf/vwskmMjuemV5Tw0d4NPSxQGK+dJzyaO43LHhCxKKo7zUTMrbLnuZ29pIrCK3z6+L31TYrza1x1PT7nOKPOtCeGccTgnrXO9WM41WW3b66xBNN9HYBOhrs6zvoSW0ESglJ/kpMXxwV1juWmsY0qLKc98V99cECpOnrwdJ6zz+qeSkxbLcwsKmuxDqd9LpP5bb0uHj3aNj/TLtR+ennOdn3l72TGqaurq4xjdJ5HfTurHn348+GSM1pNp8ZFs2etIHHV1nr1XbZ3WCJQKClHhdh68dCCv3DSCsqNVXPrMt7wSgh3JzvOVzZoefMvew/UX7blT36REy9cvPrkwjX9OluJhncAY6BofRW2dccxP5BLHnROyTrnuxBljv67x9TUC40HMzqYhrREoFUQm9Evl03vGMbZvEg99uJGbX1nO/iMdvyPZ3Tq9l57RnR4JnXhuQUGj+7muN+x8jS82ebe40MlahX9GEHl6zjUGstMco53y9x2xTuzuyzqTW/+ucRSUHqG6ts6jzmLB0TSkNQKlgkxybCQv3ziChy4dwHcFZUx68mvmb+nYHcmubf1O4XYb08/uQ972ikbXhnBtGgq32tafW1Dg1aSA9cmE5jtfPeFxIsCQlRqLCGzbewRjHLFMnbWYXQeOn1LWmeT6pcVRXWvYXnYUYxyL6Vz/4hI27jpUX/b6F5fU37cJdE/oRE5anO8fzA1NBEq1IhHhxrGZzJ0xlqSYSG7653J+/8H6Drs2Ql19Ijj1LHp1bjpJMRE8Oz/f/Y4uX+ETXZpS5nlRK6jviBWhU4TvV3vHRYZ7VK7OQHSEnR4JncgvPVIfx5LCco43GDDg/Jj9ujpO6Fv2HKlPDt/ll/H0V9vqy7oORRYRfjupPy9Oy23x52mKJgKl2kD/ro6V024em8m/lmzn4qe+YcX2jrdyWmN9IZ0i7Nw0tjfzt5SyafehHzzv2pwysHtn8h+9iF5J0Tz91TaP+1dcawS+GJedDEBGUrSH7+tou89OjXU0DRnX535YFqivQWzde5g6Y/jR6d0Ykp7AEZdFbVw7y1vpOrJ6mgiUaiNR4XYeuHQAb9w6mupaw1XPL+axTzdzoqbjDDOtbxpy0zZzw+jexETYeX7hD/sKjDn1ZBdmt3HXhCzW7zzEgi2lXr23iOPK5paKDLN7NWWI88rgrNRYCkqPNBjtdGomcF4zEBVup1diNFv3Hq5PgpFhNk5U153yuk6t1Edcz6dEICKJIjJPRLZZP7s0Um6aVWabiExz2b5ARLaIyGrrlupLPEoFgzF9k/j0nnFcNTyd5xYUMOWZ705pGw5mzmYRd+etztHhXD+6Fx+u2UVx2bEf7Ndw5Mzlw3rQI6ETf/ewVnDyvYVz+qVy67hMolvURNR85219SZfRTlmpsVTV1LGj4pjL86eWr3OZyTQnLc6RCIyjKS0q3E6ly5cC1+so/DUSqjG+1gjuA740xmQDX1qPTyEiicCDwChgJPBgg4RxvTFmiHXr2D1pSlniosJ57MrBvHxjLmVHq5gy81v+/NlmDld6t2B7e9NYH4HTLWdlEmaz8eSXW0/Z3rBGAI5O5jsm9GVV8QG+9WCJ0YYd1TYRry9Kq4/FixFDzvfKSnW0+2+1rg9orLwzvpy0OIrKjlFZXYuIYy0M14sQvZ5iwwe+JoIpwKvW/VeBy9yUuRCYZ4wpN8ZUAPOAST6+r1Idwrn90/j8nrO5ZHB3Zs4vYPyfF/DqoiKqvFwwvb1wbZ5xJy0+ilvGZfLeyp0s+/5kH0ljQy6vyu1J985RPPrxpuanqeDU9xYRr69FaCqW5t4zK/XkENKGzzvVmZPXJ+R0jaO2zrD7YCU2ERI6RbD/SFV9LaMtLz3xNRGkGWOc147vAdLclOkBuM46VWJtc/qn1Sz0e2mi/iMi00UkT0TySks9azNUKhh0iYngiWuGMHfGWHLSYnlw7gYmPrGQ/6zbHXQXornONdSYn5+bRY+ETvz+g/X1S0EalxOkq8gwO7+/ZACb9xzmlUVFTb6363xF9TG0JBEY4/HFZM7PaxPo3Cmcbp2jGrxWg9fm5LKUOWknZ1oVYGCPeMqPVrHrYCXQzmoEIvKFiKx3c5viWs44fgveRn69MeZ0YJx1u6GxgsaYWcaYXGNMbkpKipdvo1T7N7hnAm/cOpp/3jiCiDAbd/57JT9+blGjY+/bo4YnY3eiI8J48NIBbNl7mFe+K3LsR+Pr9k4a1JUJ/VJ4Yt5W9lgnSffvbd2pbxryfr4iRyzeTy/h/A57eo/ODV6rQWexS7NTZnJM/QViIsLgngkArCs5AHi/MI8vmk0ExpjzjTGD3NzmAHtFpBuA9dNdG/9OIN3lcU9rG8YY58/DwOs4+hCUClkiwjn9U/nk7rN5/IrB7DpwnKueX8z01/JOaXJor05OQ910uQsGpHFe/1Se+GIruw8ehyba5UWEP0weSE2d4ZGPNzYbg/NlfOoj8KKsI0bHz8E9O7t9/uTjk9NERIbZybQWqrGJ42rjMJuwtuRgfdm24mvT0FzAOQpoGjDHTZnPgIki0sXqJJ4IfCYiYSKSDCAi4cAlwHof41GqQ7DbhKtHpDP/1xP49cQcFhWUceGTX3P/++vYd7jxb8WB5rwSuPm5c4SHJg+kts7wyEcbHaNpmjj99kqK4a5zsvh47W6+3uq+afjkSfnkt+w6Q33zk6eMY2fPytZfu2DVCKxv9Q2fd6ozp3akO5uHxBpS2q9rHOt2OhJBu2oaasafgAtEZBtwvvUYEckVkRcBjDHlwCPAcuv2sLUtEkdCWAusxlFL+IeP8SjVoURHhDHj3GwW/GYCPxmVwezlO5jw5wU89cU2jp5of1cne1ojAEhPjGbGOVn8Z90evs0va/bce9v4PmQmx/DAnPVup/huOHR1WEYCAC9Za017ypO5fxq+p/PzetQ05PJ4YHdHeeeFZIN7dmZtyUGMMS3q6G4pnxKBMabMGHOeMSbbakIqt7bnGWN+5lLuZWNMlnX7p7XtqDFmuDFmsDFmoDHmbmNMx7myRik/So6N5A9TBjHv3vGO9vIvtjLhLwt4fWlxs6Np2lJdg2/lzZlundw37T7U7Mk3MszOw1MGUlR2rNGL0hzv7fg5oV8qEwek8eQXW+tXA/OU530Ep5Z3nR7DfflT+0KcTUkbrOtITu+RwMHj1RSXH/NqniVf6ZXFSgWRzOQYnr1+OO/ecSa9EqP57/fXceGTX/P5hj3tYoSR8WDUkCvnyd2xT/M7jctO4ZLB3Xh2QQFF+4+e+t7WT9eXeXDyQGwiPDR3g1dTVXh7QVlj1024e0vXz+msQWy3LrBzJoa1JQfbV2exUqr9Gd6rC2/fPoZZNwzHANP/tYLLZn7Hwq2lAU0IrhdYeWpcdgpThnQnIdqzSd5+f8kAIuw2Hmhwcnc3YqlHQid+eX4OX27ex+cbPZvAzt1Vzo1xVwOaO2Ms5/Z3P0mCYzWyk48ToiMY3qsLj14+CHBcZBYRZmPdzoMt6uhuKd+X8VFKBYSIMHFgV87tn8p7q3by1BfbmPbyMpJjI8hIjK6/pTvvJ0WTFhfldh4gf2lqiomm/PWqMzhc6VmfR1p8FPdekMPDH23kpleW89MxvRifk+q2RgBw49jevLuyhN+8vYaVxRVcNzKDXkmNL2XZsEZQV2caP2ZuJrob3DOBa0dm8NXmfW5GDf2w5vPuHWfW348IszGgWzxfbd5HZXXbNflpIlAqyIXZbVydm85lQ3rw/qoSVhUfoLj8GHnbK5i7ZtcpnY4RYTZ6dunkNlGkJ0YT6+MSj81NMdHUZ+jSTPu6q2ln9ubIiRpeW1zEza/k0SOhE+P7ub++KNxuY+b1w3jsk828+M33vLCwkLOykrluVAYXDEirX//AyXWs/5ETNUz820ImDuzKtSMz6qePdnK9oMyV82HDzuKGNQJ37pzQl+n/WtF0IT/TRKBUBxERZuOaERlcMyKjflt1bR27DhynuPwY28uOsaP8GMXWbUVRBYcbjDxKiok4WYNwSRC9kqJJi49qdoWs5qaY8Be7TfjFedncPr4vX2zayxvLinl9aTEAYbYftnj3TYll1k9z2XuoktnLdzB7+Q7u/PdKkmMjuHJ4OlNHpNPbGtNvODmU9UhlDcN7J/L60mJeWVTEsAzHt/1LBnenU4T9lAV1XDkfuhs+2lx9aeLArvzqghz+Om9rk+X8SROBUh1YuN1Gr6QYeiXFMC771OeMMfUjVJw3Z6JYtaOCj9ftPmUse4TdUZtId1ub6ERcVLhHU0z4U0SYjYtP78bFp3dje9lRvt62nwmN1AzA0az0i/OyueucLL7eVsobS4v5xzeFPL+wgLFZSUwdkUFVTR1hVi2ha+conr52KOVHq3hvZQmvLyvmN++s5eGPNnLZkB5MHOiYVecHNQJnIrAev7uihGNVNRyurPZoaO2Mc7NI6xzFb99Z6+0haRFNBEqFKBEhITqChOiI+ukNXFXX1rH7QKX7RFFcwaEGbfqJMRH1TUKeztXjT72SYrihibZ/V3abY6rqc/qlsvdQJW/n7eCNZTv4+RurABiVmXhK+cSYCH42rg+3nJXJsu/LeWNZMbPzdvCvJdsdBRrWCBp8/nkb9/Lphj0ApMVHNhufiHB1bromAqVUYIXbbWQkRTe6UtfBY6fWJpyJonOnRMLtbZ8IWiotPooZ52Zz54Qsvsnfz9t5OxjZIBE4iQij+iQxqk8SDx2r4r2VO/li0976i9caco5keu4nw1i38yBvLt9Bkhd9IW1FE4FSqkU6R4dzenRnTm8wv06wstmE8TkpjM/xbFLLhOgIbj4rk5vPyvzhkw2ahpyTyrmrebUHeh2BUkr5Wf2oocBf4+cRTQRKKeVnJ0cR+ZYJOnfy7CI7X2nTkFJK+Zm/agRf/Wo8FceqfI6nOZoIlFLKzxoOH22ppNhIkmKbH2XkK20aUkopPwvE8FlfaCJQSqlWop3FSikVok5OMREcmUATgVJK+Zl/xgy1HU0ESinlb41MOtdeaSJQSik/c3YWN5yGur3SRKCUUn7mp+vJ2owmAqWU8rPgGjzqYyIQkUQRmSci26yfXRop96mIHBCRjxpszxSRpSKSLyKzRaT9TcunlFItFCQVAp9rBPcBXxpjsoEvrcfu/Bm4wc32x4AnjDFZQAVwi4/xKKVUwDnnGgqVzuIpwKvW/VeBy9wVMsZ8CRx23SaOI3Uu8E5z+yulVDA5OcVEcGQCXxNBmjFmt3V/D5Dmxb5JwAFjjHOZoxKgh4/xKKVUwAXbNNTNTjonIl8AXd08db/rA2OMEZFW+9giMh2YDpCRkdFMaaWUChx/TTrXVppNBMaY8xt7TkT2ikg3Y8xuEekG7PPivcuABBEJs2oFPYGdTcQxC5gFkJubGyzHVykVkpx9BMFxqvK1aWguMM26Pw2Y4+mOxnGE5gNXtmR/pZRqryTIxo/6mgj+BFwgItuA863HiEiuiLzoLCQi3wBvA+eJSImIXGg99V/AvSKSj6PP4CUf41FKqXYjOOoDPi5MY4wpA85zsz0P+JnL43GN7F8IjPQlBqWUam/qKwRBkgn0ymKllPKz+usIgiQTaCJQSik/C7bho5oIlFLKz0SnoVZKqdB2chrq4KCJQCml/CzUho8qpZRqRKhcUKaUUqoRwZEGNBEopZTfaWexUkqFOCG41qrURKCUUn4W3ymMH53ejbT4qECH4hGfpphQSin1Qz27RDPz+mGBDsNjWiNQSqkQp4lAKaVCnCYCpZQKcZoIlFIqxGkiUEqpEKeJQCmlQpwmAqWUCnGaCJRSKsRJsMyO50pESoHtLdw9Gdjvx3BaUzDFCsEVbzDFCsEVbzDFCsEVr6+x9jLGpDTcGJSJwBcikmeMyQ10HJ4IplghuOINplghuOINplghuOJtrVi1aUgppUKcJgKllApxoZgIZgU6AC8EU6wQXPEGU6wQXPEGU6wQXPG2Sqwh10eglFLqVKFYI1BKKeVCE4FSSoW4kEkEIjJJRLaISL6I3BfoeABEJF1E5ovIRhHZICJ3W9sfEpGdIrLaul3sss/vrM+wRUQubON4i0RknRVTnrUtUUTmicg262cXa7uIyN+tWNeKSJuu0iEi/VyO32oROSQi97SnYysiL4vIPhFZ77LN6+MpItOs8ttEZFobxvpnEdlsxfO+iCRY23uLyHGXY/y8yz7Drb+hfOvziJu3a41Yvf69t9U5o5F4Z7vEWiQiq63trXNsjTEd/gbYgQKgDxABrAEGtIO4ugHDrPtxwFZgAPAQ8Gs35QdYsUcCmdZnsrdhvEVAcoNtjwP3WffvAx6z7l8MfAIIMBpYGuDf/x6gV3s6tsDZwDBgfUuPJ5AIFFo/u1j3u7RRrBOBMOv+Yy6x9nYt1+B1llnxi/V5LmqjWL36vbflOcNdvA2e/yvwQGse21CpEYwE8o0xhcaYKuBNYEqAY8IYs9sYs9K6fxjYBPRoYpcpwJvGmBPGmO+BfByfLZCmAK9a918FLnPZ/ppxWAIkiEi3AMQHcB5QYIxp6mr0Nj+2xpivgXI3cXhzPC8E5hljyo0xFcA8YFJbxGqM+dwYU2M9XAL0bOo1rHjjjTFLjOPM9RonP1+rxtqExn7vbXbOaCpe61v91cAbTb2Gr8c2VBJBD2CHy+MSmj7htjkR6Q0MBZZam2ZYVe6Xnc0DBP5zGOBzEVkhItOtbWnGmN3W/T1AmnU/0LG6msqp/0jt8dg6eXs820vcN+P4FuqUKSKrRGShiIyztvXAEZ9TW8fqze+9vRzXccBeY8w2l21+P7ahkgjaNRGJBd4F7jHGHAKeA/oCQ4DdOKqG7cFZxphhwEXAXSJytuuT1jeRdjUeWUQigMnA29am9npsf6A9Hk93ROR+oAb4t7VpN5BhjBkK3Au8LiLxgYrPEjS/9wau5dQvMa1ybEMlEewE0l0e97S2BZyIhONIAv82xrwHYIzZa4ypNcbUAf/gZBNFQD+HMWan9XMf8L4V115nk4/1c197iNXFRcBKY8xeaL/H1oW3xzOgcYvIjcAlwPVW4sJqZimz7q/A0daeY8Xl2nzUZrG24Pce8L8HEQkDfgzMdm5rrWMbKolgOZAtIpnWN8SpwNwAx+Rs/3sJ2GSM+ZvLdte29MsB52iCucBUEYkUkUwgG0cHUVvEGiMicc77ODoK11sxOUeqTAPmuMT6U2u0y2jgoEuTR1s65RtVezy2DXh7PD8DJopIF6u5Y6K1rdWJyCTgt8BkY8wxl+0pImK37vfBcSwLrXgPicho62//py6fr7Vj9fb33h7OGecDm40x9U0+rXZsW6MXvD3ecIy62Iojg94f6HismM7CUfVfC6y2bhcD/wLWWdvnAt1c9rnf+gxbaIURF03E2gfHyIk1wAbnMQSSgC+BbcAXQKK1XYCZVqzrgNwAHN8YoAzo7LKt3RxbHAlqN1CNo033lpYcTxzt8/nW7aY2jDUfRzu682/3eavsFdbfyGpgJXCpy+vk4jgJFwDPYM1u0Aaxev17b6tzhrt4re2vALc3KNsqx1anmFBKqRAXKk1DSimlGqGJQCmlQpwmAqWUCnGaCJRSKsRpIlBKqRCniUAppUKcJgKllApx/x9ra7dVVG9t9QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 1, 251) (1300, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 2s 29ms/step - loss: 3885.2607 - val_loss: 2507.6458\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3796.6899 - val_loss: 2464.0115\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3734.4846 - val_loss: 2425.4299\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3671.0754 - val_loss: 2386.7527\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3608.2861 - val_loss: 2348.7224\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3546.5061 - val_loss: 2311.3755\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3485.7041 - val_loss: 2274.6428\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3424.1106 - val_loss: 2231.4578\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3355.2898 - val_loss: 2193.6086\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3293.8557 - val_loss: 2156.5542\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3233.7200 - val_loss: 2120.0146\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3163.5649 - val_loss: 2073.7122\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3096.8328 - val_loss: 2036.8279\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3036.6733 - val_loss: 2001.0205\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2978.0227 - val_loss: 1966.1498\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2920.6589 - val_loss: 1932.0892\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2864.4246 - val_loss: 1898.7595\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2809.2180 - val_loss: 1866.1084\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2754.9731 - val_loss: 1834.1005\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2701.6428 - val_loss: 1802.7081\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2649.1919 - val_loss: 1771.9105\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2597.5903 - val_loss: 1741.6901\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2546.8162 - val_loss: 1712.0325\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2496.8494 - val_loss: 1682.9244\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2447.6724 - val_loss: 1654.3550\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2399.2698 - val_loss: 1626.3141\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2351.6274 - val_loss: 1598.7920\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2304.7332 - val_loss: 1571.7799\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2258.5747 - val_loss: 1545.2701\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2213.1418 - val_loss: 1519.2548\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2168.4231 - val_loss: 1493.7256\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2124.4089 - val_loss: 1468.6743\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2081.0903 - val_loss: 1444.0818\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2036.5577 - val_loss: 1414.0820\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1985.4641 - val_loss: 1387.4061\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1939.7959 - val_loss: 1361.7223\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1895.6624 - val_loss: 1337.0164\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1852.8621 - val_loss: 1313.1167\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1811.1758 - val_loss: 1289.9126\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1770.4672 - val_loss: 1267.3352\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1730.6490 - val_loss: 1245.3386\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1691.6626 - val_loss: 1223.8901\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1653.4648 - val_loss: 1202.9640\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1616.0217 - val_loss: 1182.5406\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1579.3071 - val_loss: 1162.6033\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1543.2977 - val_loss: 1143.1373\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1507.9749 - val_loss: 1124.1307\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1473.3210 - val_loss: 1105.5720\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1439.3208 - val_loss: 1087.4508\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1405.9613 - val_loss: 1069.7579\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1373.2291 - val_loss: 1052.4845\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1341.1127 - val_loss: 1035.6230\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1309.6008 - val_loss: 1019.1650\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1278.6833 - val_loss: 1003.1035\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1248.3499 - val_loss: 987.4313\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1218.5911 - val_loss: 972.1415\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1189.3987 - val_loss: 957.2277\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1160.7625 - val_loss: 942.6835\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1132.6748 - val_loss: 928.5031\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1105.1271 - val_loss: 914.6796\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1078.1118 - val_loss: 901.2081\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1051.6202 - val_loss: 888.0824\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1025.6456 - val_loss: 875.2970\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1000.1802 - val_loss: 862.8463\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 975.2162 - val_loss: 850.7250\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 950.7469 - val_loss: 838.9277\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 926.7653 - val_loss: 827.4490\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 903.2638 - val_loss: 816.2839\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 880.2362 - val_loss: 805.4274\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 857.6752 - val_loss: 794.8744\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 835.5745 - val_loss: 784.6199\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 813.9276 - val_loss: 774.6589\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 792.7277 - val_loss: 764.9868\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 771.9684 - val_loss: 755.5983\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 751.6437 - val_loss: 746.4891\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 731.7468 - val_loss: 737.6543\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 712.2720 - val_loss: 729.0894\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 693.2129 - val_loss: 720.7897\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 674.5636 - val_loss: 712.7507\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 656.3177 - val_loss: 704.9673\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 638.4691 - val_loss: 697.4358\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 621.0126 - val_loss: 690.1516\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 603.9418 - val_loss: 683.1096\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 587.2510 - val_loss: 676.3063\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 570.9343 - val_loss: 669.7368\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 554.9861 - val_loss: 663.3970\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 539.4010 - val_loss: 657.2826\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 524.1733 - val_loss: 651.3895\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 509.2974 - val_loss: 645.7134\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 494.7674 - val_loss: 640.2500\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 480.5784 - val_loss: 634.9952\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 466.7246 - val_loss: 629.9451\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 453.2006 - val_loss: 625.0953\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 440.0010 - val_loss: 620.4420\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 427.1206 - val_loss: 615.9811\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 414.5541 - val_loss: 611.7086\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 402.2963 - val_loss: 607.6206\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 390.3419 - val_loss: 603.7133\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 378.6859 - val_loss: 599.9824\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 367.3232 - val_loss: 596.4246\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 356.2488 - val_loss: 593.0357\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 345.4572 - val_loss: 589.8121\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 334.9441 - val_loss: 586.7499\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 324.7042 - val_loss: 583.8455\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 314.7326 - val_loss: 581.0952\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 305.0245 - val_loss: 578.4950\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 295.5751 - val_loss: 576.0418\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 286.3792 - val_loss: 573.7316\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 277.4326 - val_loss: 571.5612\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 268.7303 - val_loss: 569.5267\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 260.2679 - val_loss: 567.6248\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 252.0403 - val_loss: 565.8520\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 244.0432 - val_loss: 564.2048\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 236.2723 - val_loss: 562.6799\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 228.7229 - val_loss: 561.2739\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 221.3905 - val_loss: 559.9836\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 214.2706 - val_loss: 558.8055\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 207.3589 - val_loss: 557.7363\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 200.6512 - val_loss: 556.7731\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 194.1432 - val_loss: 555.9124\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 187.8306 - val_loss: 555.1512\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 181.7091 - val_loss: 554.4864\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 175.7747 - val_loss: 553.9149\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 170.0232 - val_loss: 553.4337\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 164.4505 - val_loss: 553.0397\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 159.0526 - val_loss: 552.7300\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 153.8257 - val_loss: 552.5016\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 148.7655 - val_loss: 552.3517\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 143.8684 - val_loss: 552.2776\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 139.1307 - val_loss: 552.2763\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 134.5484 - val_loss: 552.3452\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 130.1177 - val_loss: 552.4813\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 125.8350 - val_loss: 552.6821\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 121.6967 - val_loss: 552.9450\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 117.6989 - val_loss: 553.2673\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 113.8384 - val_loss: 553.6465\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 110.1116 - val_loss: 554.0803\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 106.5150 - val_loss: 554.5659\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 103.0451 - val_loss: 555.1010\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 99.6988 - val_loss: 555.6833\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 96.4725 - val_loss: 556.3102\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 93.3632 - val_loss: 556.9798\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 90.3676 - val_loss: 557.6896\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 87.4824 - val_loss: 558.4374\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 84.7046 - val_loss: 559.2211\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 82.0312 - val_loss: 560.0387\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 79.4592 - val_loss: 560.8878\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 76.9856 - val_loss: 561.7668\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 74.6075 - val_loss: 562.6733\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 72.3221 - val_loss: 563.6057\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 70.1265 - val_loss: 564.5620\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 68.0181 - val_loss: 565.5404\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 65.9940 - val_loss: 566.5389\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 64.0518 - val_loss: 567.5560\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 62.1888 - val_loss: 568.5900\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 60.4024 - val_loss: 569.6389\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 58.6903 - val_loss: 570.7017\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 57.0498 - val_loss: 571.7762\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 55.4786 - val_loss: 572.8614\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 53.9745 - val_loss: 573.9556\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 52.5351 - val_loss: 575.0574\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 51.1583 - val_loss: 576.1653\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 49.8419 - val_loss: 577.2781\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 48.5836 - val_loss: 578.3946\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 47.3815 - val_loss: 579.5133\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 46.2335 - val_loss: 580.6332\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 45.1376 - val_loss: 581.7530\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 44.0920 - val_loss: 582.8719\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 43.0947 - val_loss: 583.9886\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 42.1439 - val_loss: 585.1019\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 41.2378 - val_loss: 586.2111\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 40.3748 - val_loss: 587.3152\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 39.5531 - val_loss: 588.4133\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 38.7710 - val_loss: 589.5046\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 38.0270 - val_loss: 590.5881\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 37.3197 - val_loss: 591.6631\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 36.6474 - val_loss: 592.7291\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 36.0087 - val_loss: 593.7852\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 35.4022 - val_loss: 594.8307\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 34.8265 - val_loss: 595.8651\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 34.2803 - val_loss: 596.8876\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 33.7624 - val_loss: 597.8979\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.2715 - val_loss: 598.8955\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.8063 - val_loss: 599.8798\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.3659 - val_loss: 600.8504\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 31.9489 - val_loss: 601.8069\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.5545 - val_loss: 602.7489\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.1814 - val_loss: 603.6761\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.8288 - val_loss: 604.5882\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.4956 - val_loss: 605.4847\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.1810 - val_loss: 606.3658\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.8840 - val_loss: 607.2309\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.6038 - val_loss: 608.0801\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 29.3395 - val_loss: 608.9129\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.0904 - val_loss: 609.7294\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.8556 - val_loss: 610.5295\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.6345 - val_loss: 611.3129\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.4264 - val_loss: 612.0798\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.2306 - val_loss: 612.8299\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 28.0464 - val_loss: 613.5635\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.8732 - val_loss: 614.2800\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.7106 - val_loss: 614.9802\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.5577 - val_loss: 615.6636\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.4143 - val_loss: 616.3303\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.2796 - val_loss: 616.9808\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.1533 - val_loss: 617.6148\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.0349 - val_loss: 618.2324\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.9239 - val_loss: 618.8337\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.8200 - val_loss: 619.4193\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 26.7226 - val_loss: 619.9887\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.6314 - val_loss: 620.5425\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 26.5461 - val_loss: 621.0806\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.4663 - val_loss: 621.6036\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.3918 - val_loss: 622.1112\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.3221 - val_loss: 622.6040\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 26.2570 - val_loss: 623.0820\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 26.1961 - val_loss: 623.5453\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 26.1394 - val_loss: 623.9946\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.0863 - val_loss: 624.4296\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.0369 - val_loss: 624.8510\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.9908 - val_loss: 625.2585\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.9479 - val_loss: 625.6528\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.9078 - val_loss: 626.0339\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.8705 - val_loss: 626.4026\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.8357 - val_loss: 626.7585\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.8034 - val_loss: 627.1023\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.7733 - val_loss: 627.4339\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.7452 - val_loss: 627.7539\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.7192 - val_loss: 628.0624\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.6949 - val_loss: 628.3598\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.6724 - val_loss: 628.6464\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.6514 - val_loss: 628.9221\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.6319 - val_loss: 629.1877\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.6138 - val_loss: 629.4431\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5969 - val_loss: 629.6886\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5813 - val_loss: 629.9246\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5668 - val_loss: 630.1513\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.5534 - val_loss: 630.3691\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5409 - val_loss: 630.5781\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5293 - val_loss: 630.7786\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5185 - val_loss: 630.9708\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5085 - val_loss: 631.1550\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 25.4993 - val_loss: 631.3315\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 25.4907 - val_loss: 631.5006\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4828 - val_loss: 631.6625\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4754 - val_loss: 631.8173\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4686 - val_loss: 631.9655\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4622 - val_loss: 632.1069\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.4564 - val_loss: 632.2422\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4509 - val_loss: 632.3712\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4460 - val_loss: 632.4945\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4413 - val_loss: 632.6122\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4370 - val_loss: 632.7243\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4331 - val_loss: 632.8312\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4294 - val_loss: 632.9330\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4261 - val_loss: 633.0299\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4230 - val_loss: 633.1224\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4201 - val_loss: 633.2100\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.4175 - val_loss: 633.2935\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4151 - val_loss: 633.3730\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4129 - val_loss: 633.4483\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4108 - val_loss: 633.5199\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4089 - val_loss: 633.5878\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4073 - val_loss: 633.6522\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4057 - val_loss: 633.7131\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4043 - val_loss: 633.7709\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4030 - val_loss: 633.8257\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4019 - val_loss: 633.8776\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4008 - val_loss: 633.9265\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3999 - val_loss: 633.9728\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3990 - val_loss: 634.0168\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3983 - val_loss: 634.0580\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3976 - val_loss: 634.0970\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 25.3970 - val_loss: 634.1338\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3966 - val_loss: 634.1686\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3961 - val_loss: 634.2012\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3957 - val_loss: 634.2322\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3954 - val_loss: 634.2609\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3952 - val_loss: 634.2885\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3950 - val_loss: 634.3141\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3949 - val_loss: 634.3380\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3948 - val_loss: 634.3607\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3947 - val_loss: 634.3820\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3947 - val_loss: 634.4016\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3948 - val_loss: 634.4202\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3948 - val_loss: 634.4376\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3949 - val_loss: 634.4538\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3951 - val_loss: 634.4691\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3953 - val_loss: 634.4834\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3954 - val_loss: 634.4965\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3957 - val_loss: 634.5089\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3960 - val_loss: 634.5205\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3962 - val_loss: 634.5310\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3965 - val_loss: 634.5410\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3968 - val_loss: 634.5500\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3972 - val_loss: 634.5587\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3975 - val_loss: 634.5665\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3979 - val_loss: 634.5737\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3983 - val_loss: 634.5806\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3987 - val_loss: 634.5866\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3991 - val_loss: 634.5923\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3995 - val_loss: 634.5977\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4000 - val_loss: 634.6023\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4005 - val_loss: 634.6068\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4009 - val_loss: 634.6110\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4013 - val_loss: 634.6145\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4018 - val_loss: 634.6177\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 25.4023 - val_loss: 634.6207\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4028 - val_loss: 634.6234\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4033 - val_loss: 634.6258\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4038 - val_loss: 634.6277\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4044 - val_loss: 634.6300\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4049 - val_loss: 634.6317\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4054 - val_loss: 634.6329\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4059 - val_loss: 634.6343\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4065 - val_loss: 634.6354\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4070 - val_loss: 634.6363\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4075 - val_loss: 634.6371\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4081 - val_loss: 634.6377\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4086 - val_loss: 634.6380\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4092 - val_loss: 634.6382\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4097 - val_loss: 634.6386\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4102 - val_loss: 634.6387\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4108 - val_loss: 634.6387\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4113 - val_loss: 634.6385\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4119 - val_loss: 634.6384\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4124 - val_loss: 634.6382\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4130 - val_loss: 634.6379\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4136 - val_loss: 634.6375\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4141 - val_loss: 634.6370\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4146 - val_loss: 634.6364\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4152 - val_loss: 634.6359\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4157 - val_loss: 634.6352\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4163 - val_loss: 634.6347\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 25.4168 - val_loss: 634.6340\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4174 - val_loss: 634.6332\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4179 - val_loss: 634.6324\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4184 - val_loss: 634.6316\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4190 - val_loss: 634.6308\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4195 - val_loss: 634.6298\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4201 - val_loss: 634.6290\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4206 - val_loss: 634.6281\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4211 - val_loss: 634.6271\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4216 - val_loss: 634.6262\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4222 - val_loss: 634.6254\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4227 - val_loss: 634.6245\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4232 - val_loss: 634.6234\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4237 - val_loss: 634.6225\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4242 - val_loss: 634.6216\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4247 - val_loss: 634.6207\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4252 - val_loss: 634.6193\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4258 - val_loss: 634.6184\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4262 - val_loss: 634.6174\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4268 - val_loss: 634.6164\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4272 - val_loss: 634.6154\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4277 - val_loss: 634.6144\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4282 - val_loss: 634.6135\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4287 - val_loss: 634.6125\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4292 - val_loss: 634.6115\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4296 - val_loss: 634.6105\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 25.4301 - val_loss: 634.6094\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4306 - val_loss: 634.6086\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4311 - val_loss: 634.6075\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 25.4315 - val_loss: 634.6065\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4320 - val_loss: 634.6055\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4324 - val_loss: 634.6045\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4329 - val_loss: 634.6036\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4333 - val_loss: 634.6027\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4338 - val_loss: 634.6016\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4342 - val_loss: 634.6008\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4346 - val_loss: 634.5998\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4351 - val_loss: 634.5989\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4355 - val_loss: 634.5980\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4360 - val_loss: 634.5971\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4364 - val_loss: 634.5961\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4368 - val_loss: 634.5953\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4372 - val_loss: 634.5942\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4376 - val_loss: 634.5933\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4380 - val_loss: 634.5923\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4384 - val_loss: 634.5913\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4388 - val_loss: 634.5905\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4392 - val_loss: 634.5895\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4396 - val_loss: 634.5887\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4400 - val_loss: 634.5878\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4404 - val_loss: 634.5871\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 25.4408 - val_loss: 634.5862\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4411 - val_loss: 634.5854\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4415 - val_loss: 634.5847\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4419 - val_loss: 634.5837\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4422 - val_loss: 634.5829\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4426 - val_loss: 634.5822\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4430 - val_loss: 634.5812\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4433 - val_loss: 634.5805\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4437 - val_loss: 634.5797\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4440 - val_loss: 634.5790\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4443 - val_loss: 634.5784\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4447 - val_loss: 634.5775\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4450 - val_loss: 634.5769\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4453 - val_loss: 634.5761\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4457 - val_loss: 634.5753\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4460 - val_loss: 634.5746\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4463 - val_loss: 634.5740\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4466 - val_loss: 634.5732\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4470 - val_loss: 634.5726\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4473 - val_loss: 634.5718\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4476 - val_loss: 634.5712\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4479 - val_loss: 634.5705\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4482 - val_loss: 634.5698\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4485 - val_loss: 634.5691\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4487 - val_loss: 634.5685\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4490 - val_loss: 634.5678\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4493 - val_loss: 634.5672\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4496 - val_loss: 634.5664\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4499 - val_loss: 634.5660\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4501 - val_loss: 634.5652\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 25.4504 - val_loss: 634.5646\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4507 - val_loss: 634.5640\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4510 - val_loss: 634.5635\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4512 - val_loss: 634.5627\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4515 - val_loss: 634.5622\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4517 - val_loss: 634.5615\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4520 - val_loss: 634.5609\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4522 - val_loss: 634.5605\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4525 - val_loss: 634.5598\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4527 - val_loss: 634.5593\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4530 - val_loss: 634.5587\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4532 - val_loss: 634.5582\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4534 - val_loss: 634.5576\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4537 - val_loss: 634.5571\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4539 - val_loss: 634.5566\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4541 - val_loss: 634.5560\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4543 - val_loss: 634.5555\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4545 - val_loss: 634.5550\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4547 - val_loss: 634.5543\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4550 - val_loss: 634.5540\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 25.4552 - val_loss: 634.5534\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4554 - val_loss: 634.5529\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4556 - val_loss: 634.5526\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4558 - val_loss: 634.5521\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4560 - val_loss: 634.5514\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4562 - val_loss: 634.5510\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4564 - val_loss: 634.5504\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4566 - val_loss: 634.5500\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4568 - val_loss: 634.5498\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 25.4569 - val_loss: 634.5493\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4571 - val_loss: 634.5488\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4573 - val_loss: 634.5485\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4575 - val_loss: 634.5481\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4577 - val_loss: 634.5475\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4578 - val_loss: 634.5472\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4580 - val_loss: 634.5470\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4582 - val_loss: 634.5465\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4583 - val_loss: 634.5461\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4585 - val_loss: 634.5457\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4586 - val_loss: 634.5452\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4588 - val_loss: 634.5449\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4590 - val_loss: 634.5444\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4591 - val_loss: 634.5443\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4593 - val_loss: 634.5439\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4594 - val_loss: 634.5433\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4596 - val_loss: 634.5432\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4597 - val_loss: 634.5428\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4599 - val_loss: 634.5424\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4600 - val_loss: 634.5421\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4601 - val_loss: 634.5416\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4603 - val_loss: 634.5414\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4604 - val_loss: 634.5413\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4605 - val_loss: 634.5410\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4607 - val_loss: 634.5405\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 25.4608 - val_loss: 634.5403\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4609 - val_loss: 634.5400\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4610 - val_loss: 634.5396\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4612 - val_loss: 634.5394\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4613 - val_loss: 634.5390\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4614 - val_loss: 634.5388\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4615 - val_loss: 634.5385\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4616 - val_loss: 634.5381\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4618 - val_loss: 634.5379\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4619 - val_loss: 634.5377\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4620 - val_loss: 634.5373\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4621 - val_loss: 634.5371\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4622 - val_loss: 634.5369\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4623 - val_loss: 634.5365\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4624 - val_loss: 634.5360\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4625 - val_loss: 634.5358\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4626 - val_loss: 634.5356\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4627 - val_loss: 634.5355\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4628 - val_loss: 634.5350\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4629 - val_loss: 634.5346\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4630 - val_loss: 634.5345\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4631 - val_loss: 634.5341\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4632 - val_loss: 634.5339\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4633 - val_loss: 634.5336\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 25.4634 - val_loss: 634.5334\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4634 - val_loss: 634.5331\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4636 - val_loss: 634.5330\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4636 - val_loss: 634.5330\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4637 - val_loss: 634.5328\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4638 - val_loss: 634.5325\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4639 - val_loss: 634.5323\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 387ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59.47124183, 59.3031746 , 59.13510738, 58.96704015, 58.79897292,\n",
       "        58.6309057 , 58.46283847,  0.44068536,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.21998081, 61.22649393, 61.0164099 ,\n",
       "        60.80632586, 60.59624183, 60.3861578 , 60.18085901, 60.01279178,\n",
       "        59.84472456, 59.67665733, 59.5085901 , 59.34052288, 59.17245565,\n",
       "        59.00438842, 58.8363212 , 58.66825397, 58.50018674, 58.33211951,\n",
       "        58.19101307, 58.14899627, 58.10697946, 58.06496265, 58.02294585,\n",
       "        57.98092904, 57.93891223, 57.89689542, 57.85487862, 57.81286181,\n",
       "         0.        ,  0.23122965,  0.        ,  0.        ,  0.        ,\n",
       "         0.13909158,  0.24003939, 59.0417367 , 58.8736695 , 58.7056022 ,\n",
       "        58.537535  , 58.3694678 , 58.2014006 , 58.1583333 , 58.1163165 ,\n",
       "        58.0742997 , 58.0322829 , 57.9902661 , 57.9482493 , 57.9062325 ,\n",
       "        57.8642157 , 57.8221989 , 57.7801821 , 57.7381653 , 57.6961485 ,\n",
       "        57.6541316 , 57.6121148 , 57.570098  , 57.5280812 , 57.4860644 ,\n",
       "        57.4440476 , 57.4020308 , 57.360014  , 65.501976  ,  0.        ,\n",
       "         0.        ,  0.        ,  0.49546638,  0.        ,  0.        ,\n",
       "        52.98059082,  0.2483151 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.38080922,  0.        ,  0.        ,\n",
       "         0.65767401,  0.84494126,  0.22583157,  0.41648197,  0.        ,\n",
       "         0.        ,  0.24465945,  0.11996679,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53.91911765, 53.91071429, 53.90231092, 53.89390756, 53.8855042 ,\n",
       "       53.87710084, 53.86869748, 53.86029412, 53.85189076, 53.84348739,\n",
       "       53.83508403, 53.82668067, 53.81827731, 53.80987395, 53.80147059,\n",
       "       53.79306723, 53.78466387, 53.7762605 , 53.76785714, 53.75945378,\n",
       "       53.75105042, 53.74264706, 53.7342437 , 53.72584034, 53.71743697,\n",
       "       53.70903361, 53.70063025, 53.69222689, 53.68382353, 53.67542017,\n",
       "       53.66701681, 53.65861345, 53.65021008, 53.64180672, 53.63340336,\n",
       "       53.625     , 53.61659664, 53.60819328, 53.59978992, 53.59138655,\n",
       "       53.58298319, 53.57457983, 53.56617647, 53.55777311, 53.54936975,\n",
       "       53.54096639, 53.53256303, 53.52415966, 53.5157563 , 53.50735294,\n",
       "       53.49894958, 53.49054622, 53.48214286, 53.4737395 , 53.46533613,\n",
       "       53.45693277, 53.44852941, 53.44012605, 53.43172269, 53.42331933,\n",
       "       53.41491597, 53.40651261, 53.39642857, 53.38055556, 53.36468254,\n",
       "       53.34880952, 53.33293651, 53.31706349, 53.30119048, 53.28531746,\n",
       "       53.26944444, 53.25357143, 53.23769841, 53.2218254 , 53.20595238,\n",
       "       53.19007937, 53.17420635, 53.15833333, 53.14246032, 53.1265873 ,\n",
       "       53.11071429, 53.09484127, 53.07896825, 53.06309524, 53.04722222,\n",
       "       53.03134921, 53.01547619, 52.99960317, 52.98373016, 52.96785714,\n",
       "       52.95198413, 52.93611111, 52.9202381 , 52.90436508, 52.88849206,\n",
       "       52.87261905, 52.85674603, 52.84087302, 52.825     , 52.80912698])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.995432406641484\n",
      "23.296994757984034\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
