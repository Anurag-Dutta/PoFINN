{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "1945    51.346300\n",
       "1946    51.332761\n",
       "1947    51.319223\n",
       "1948    51.305684\n",
       "1949    51.292145\n",
       "Name: C6, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_1850_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "1845     0.000000\n",
       "1846     0.244659\n",
       "1847     0.119967\n",
       "1848     0.000000\n",
       "1849     0.000000\n",
       "Name: C6, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1850)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 1, 251) (1400, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "18/18 [==============================] - 2s 29ms/step - loss: 3848.8018 - val_loss: 2494.5508\n",
      "Epoch 2/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3752.9875 - val_loss: 2427.4517\n",
      "Epoch 3/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3665.4136 - val_loss: 2374.7668\n",
      "Epoch 4/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3586.2388 - val_loss: 2327.8494\n",
      "Epoch 5/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3529.2534 - val_loss: 2291.2939\n",
      "Epoch 6/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3474.3625 - val_loss: 2255.8015\n",
      "Epoch 7/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3420.7815 - val_loss: 2221.1628\n",
      "Epoch 8/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3368.2578 - val_loss: 2187.2468\n",
      "Epoch 9/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3316.6367 - val_loss: 2153.9751\n",
      "Epoch 10/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3265.8254 - val_loss: 2121.2971\n",
      "Epoch 11/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3215.7617 - val_loss: 2089.1794\n",
      "Epoch 12/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3166.4026 - val_loss: 2057.5972\n",
      "Epoch 13/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3117.7185 - val_loss: 2026.5321\n",
      "Epoch 14/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3069.6846 - val_loss: 1995.9685\n",
      "Epoch 15/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3022.2822 - val_loss: 1965.8947\n",
      "Epoch 16/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2975.4949 - val_loss: 1936.2996\n",
      "Epoch 17/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2929.3098 - val_loss: 1907.1743\n",
      "Epoch 18/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2883.7148 - val_loss: 1878.5107\n",
      "Epoch 19/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2838.7007 - val_loss: 1850.3011\n",
      "Epoch 20/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2794.2566 - val_loss: 1822.5392\n",
      "Epoch 21/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2750.3750 - val_loss: 1795.2183\n",
      "Epoch 22/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2707.0483 - val_loss: 1768.3326\n",
      "Epoch 23/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2664.2683 - val_loss: 1741.8767\n",
      "Epoch 24/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2622.0293 - val_loss: 1715.8450\n",
      "Epoch 25/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2580.3232 - val_loss: 1690.2324\n",
      "Epoch 26/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2539.1450 - val_loss: 1665.0341\n",
      "Epoch 27/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2498.4895 - val_loss: 1640.2455\n",
      "Epoch 28/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2458.3489 - val_loss: 1615.8615\n",
      "Epoch 29/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2418.7195 - val_loss: 1591.8779\n",
      "Epoch 30/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2379.5947 - val_loss: 1568.2904\n",
      "Epoch 31/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2340.9697 - val_loss: 1545.0946\n",
      "Epoch 32/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2302.8398 - val_loss: 1522.2863\n",
      "Epoch 33/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2265.1995 - val_loss: 1499.8611\n",
      "Epoch 34/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2228.0447 - val_loss: 1477.8152\n",
      "Epoch 35/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2191.3694 - val_loss: 1456.1450\n",
      "Epoch 36/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2155.1704 - val_loss: 1434.8457\n",
      "Epoch 37/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2119.4419 - val_loss: 1413.9142\n",
      "Epoch 38/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2084.1799 - val_loss: 1393.3462\n",
      "Epoch 39/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2049.3799 - val_loss: 1373.1381\n",
      "Epoch 40/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2015.0377 - val_loss: 1353.2859\n",
      "Epoch 41/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1981.1484 - val_loss: 1333.7864\n",
      "Epoch 42/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1947.7090 - val_loss: 1314.6354\n",
      "Epoch 43/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1914.7136 - val_loss: 1295.8291\n",
      "Epoch 44/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1882.1589 - val_loss: 1277.3641\n",
      "Epoch 45/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1850.0408 - val_loss: 1259.2349\n",
      "Epoch 46/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1818.3549 - val_loss: 1241.4242\n",
      "Epoch 47/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1787.0979 - val_loss: 1222.6318\n",
      "Epoch 48/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1745.3939 - val_loss: 1198.1674\n",
      "Epoch 49/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1709.4938 - val_loss: 1178.6052\n",
      "Epoch 50/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1676.0994 - val_loss: 1160.2964\n",
      "Epoch 51/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1642.7144 - val_loss: 1142.5085\n",
      "Epoch 52/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1610.9023 - val_loss: 1125.3171\n",
      "Epoch 53/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1579.8866 - val_loss: 1108.6462\n",
      "Epoch 54/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1549.5676 - val_loss: 1092.4460\n",
      "Epoch 55/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1519.8793 - val_loss: 1076.6841\n",
      "Epoch 56/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1490.7764 - val_loss: 1061.3348\n",
      "Epoch 57/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1462.2244 - val_loss: 1046.3790\n",
      "Epoch 58/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1434.1980 - val_loss: 1031.8014\n",
      "Epoch 59/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1406.6752 - val_loss: 1017.5887\n",
      "Epoch 60/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1379.6384 - val_loss: 1003.7303\n",
      "Epoch 61/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1353.0725 - val_loss: 990.2159\n",
      "Epoch 62/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1326.9655 - val_loss: 977.0375\n",
      "Epoch 63/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1301.3052 - val_loss: 964.1872\n",
      "Epoch 64/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1276.0813 - val_loss: 951.6576\n",
      "Epoch 65/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1251.2845 - val_loss: 939.4420\n",
      "Epoch 66/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1226.9069 - val_loss: 927.5350\n",
      "Epoch 67/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1202.9403 - val_loss: 915.9304\n",
      "Epoch 68/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1179.3776 - val_loss: 904.6229\n",
      "Epoch 69/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1156.2113 - val_loss: 893.6076\n",
      "Epoch 70/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1133.4349 - val_loss: 882.8795\n",
      "Epoch 71/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1111.0428 - val_loss: 872.4343\n",
      "Epoch 72/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1089.0293 - val_loss: 862.2679\n",
      "Epoch 73/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 1067.3881 - val_loss: 852.3784\n",
      "Epoch 74/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1046.1138 - val_loss: 842.7703\n",
      "Epoch 75/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1025.2225 - val_loss: 833.3223\n",
      "Epoch 76/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1004.6460 - val_loss: 824.2875\n",
      "Epoch 77/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 984.4420 - val_loss: 815.5705\n",
      "Epoch 78/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 964.5858 - val_loss: 806.4899\n",
      "Epoch 79/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 945.0721 - val_loss: 798.1296\n",
      "Epoch 80/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 925.8965 - val_loss: 790.0201\n",
      "Epoch 81/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 907.0544 - val_loss: 782.1508\n",
      "Epoch 82/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 888.5414 - val_loss: 774.5182\n",
      "Epoch 83/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 870.3533 - val_loss: 767.1185\n",
      "Epoch 84/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 852.4858 - val_loss: 759.9485\n",
      "Epoch 85/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 834.9352 - val_loss: 753.0042\n",
      "Epoch 86/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 817.6974 - val_loss: 746.2824\n",
      "Epoch 87/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 800.7678 - val_loss: 739.7797\n",
      "Epoch 88/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 784.1430 - val_loss: 733.4924\n",
      "Epoch 89/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 767.8192 - val_loss: 727.4173\n",
      "Epoch 90/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 751.7922 - val_loss: 721.5510\n",
      "Epoch 91/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 736.0583 - val_loss: 715.8903\n",
      "Epoch 92/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 720.6139 - val_loss: 710.4320\n",
      "Epoch 93/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 705.4554 - val_loss: 705.1727\n",
      "Epoch 94/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 690.5792 - val_loss: 700.1092\n",
      "Epoch 95/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 675.9814 - val_loss: 695.2383\n",
      "Epoch 96/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 661.6588 - val_loss: 690.5570\n",
      "Epoch 97/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 647.6074 - val_loss: 686.0621\n",
      "Epoch 98/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 633.8241 - val_loss: 681.7502\n",
      "Epoch 99/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 620.3052 - val_loss: 677.6186\n",
      "Epoch 100/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 607.0472 - val_loss: 673.6639\n",
      "Epoch 101/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 594.0469 - val_loss: 669.8834\n",
      "Epoch 102/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 581.3011 - val_loss: 666.2737\n",
      "Epoch 103/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 568.8060 - val_loss: 662.8322\n",
      "Epoch 104/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 556.5584 - val_loss: 659.5556\n",
      "Epoch 105/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 544.5554 - val_loss: 656.4410\n",
      "Epoch 106/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 532.7931 - val_loss: 653.4856\n",
      "Epoch 107/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 521.2687 - val_loss: 650.6863\n",
      "Epoch 108/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 509.9789 - val_loss: 648.0402\n",
      "Epoch 109/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 498.9204 - val_loss: 645.5446\n",
      "Epoch 110/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 488.0900 - val_loss: 643.1962\n",
      "Epoch 111/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 477.4845 - val_loss: 640.9927\n",
      "Epoch 112/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 467.1010 - val_loss: 638.9308\n",
      "Epoch 113/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 456.9364 - val_loss: 637.0079\n",
      "Epoch 114/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 446.9873 - val_loss: 635.2212\n",
      "Epoch 115/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 437.2508 - val_loss: 633.5678\n",
      "Epoch 116/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 427.7237 - val_loss: 632.0451\n",
      "Epoch 117/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 418.4033 - val_loss: 630.6502\n",
      "Epoch 118/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 409.2862 - val_loss: 629.3804\n",
      "Epoch 119/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 400.3697 - val_loss: 628.2329\n",
      "Epoch 120/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 391.6505 - val_loss: 627.2051\n",
      "Epoch 121/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 383.1262 - val_loss: 626.2944\n",
      "Epoch 122/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 374.7933 - val_loss: 625.4979\n",
      "Epoch 123/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 366.6491 - val_loss: 624.8130\n",
      "Epoch 124/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 358.6907 - val_loss: 624.2374\n",
      "Epoch 125/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 350.9152 - val_loss: 623.7681\n",
      "Epoch 126/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 343.3198 - val_loss: 623.4026\n",
      "Epoch 127/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 335.9015 - val_loss: 623.1384\n",
      "Epoch 128/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 328.6577 - val_loss: 622.9728\n",
      "Epoch 129/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 321.5856 - val_loss: 622.9033\n",
      "Epoch 130/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 314.6822 - val_loss: 622.9276\n",
      "Epoch 131/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 307.9450 - val_loss: 623.0428\n",
      "Epoch 132/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 301.3711 - val_loss: 623.2468\n",
      "Epoch 133/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 294.9576 - val_loss: 623.5368\n",
      "Epoch 134/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 288.7021 - val_loss: 623.9106\n",
      "Epoch 135/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 282.6017 - val_loss: 624.3656\n",
      "Epoch 136/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 276.6539 - val_loss: 624.8995\n",
      "Epoch 137/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 270.8560 - val_loss: 625.5098\n",
      "Epoch 138/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 265.2053 - val_loss: 626.1943\n",
      "Epoch 139/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 259.6991 - val_loss: 626.9505\n",
      "Epoch 140/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 254.3350 - val_loss: 627.7760\n",
      "Epoch 141/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 249.1103 - val_loss: 628.6687\n",
      "Epoch 142/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 244.0227 - val_loss: 629.6263\n",
      "Epoch 143/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 239.0693 - val_loss: 630.6463\n",
      "Epoch 144/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 234.2478 - val_loss: 631.7267\n",
      "Epoch 145/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 229.5557 - val_loss: 632.8652\n",
      "Epoch 146/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 224.9905 - val_loss: 634.0595\n",
      "Epoch 147/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 220.5496 - val_loss: 635.3076\n",
      "Epoch 148/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 216.2309 - val_loss: 636.6072\n",
      "Epoch 149/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 212.0318 - val_loss: 637.9565\n",
      "Epoch 150/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 207.9500 - val_loss: 639.3529\n",
      "Epoch 151/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 203.9829 - val_loss: 640.7946\n",
      "Epoch 152/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 200.1284 - val_loss: 642.2797\n",
      "Epoch 153/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 196.3842 - val_loss: 643.8058\n",
      "Epoch 154/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 192.7479 - val_loss: 645.3713\n",
      "Epoch 155/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 189.2173 - val_loss: 646.9738\n",
      "Epoch 156/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 185.7902 - val_loss: 648.6117\n",
      "Epoch 157/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 182.4641 - val_loss: 650.2830\n",
      "Epoch 158/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 179.2371 - val_loss: 651.9860\n",
      "Epoch 159/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 176.1069 - val_loss: 653.7182\n",
      "Epoch 160/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 173.0715 - val_loss: 655.4783\n",
      "Epoch 161/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 170.1285 - val_loss: 657.2644\n",
      "Epoch 162/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 167.2759 - val_loss: 659.0748\n",
      "Epoch 163/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 164.5118 - val_loss: 660.9075\n",
      "Epoch 164/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 161.8340 - val_loss: 662.7609\n",
      "Epoch 165/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 159.2404 - val_loss: 664.6335\n",
      "Epoch 166/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 156.7290 - val_loss: 666.5233\n",
      "Epoch 167/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 154.2980 - val_loss: 668.4288\n",
      "Epoch 168/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 151.9454 - val_loss: 670.3487\n",
      "Epoch 169/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 149.6691 - val_loss: 672.2810\n",
      "Epoch 170/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 147.4673 - val_loss: 674.2243\n",
      "Epoch 171/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 145.3383 - val_loss: 676.1772\n",
      "Epoch 172/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 143.2800 - val_loss: 678.1383\n",
      "Epoch 173/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 141.2907 - val_loss: 680.1059\n",
      "Epoch 174/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 139.3686 - val_loss: 682.0787\n",
      "Epoch 175/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 137.5120 - val_loss: 684.0552\n",
      "Epoch 176/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 135.7191 - val_loss: 686.0342\n",
      "Epoch 177/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 133.9882 - val_loss: 688.0146\n",
      "Epoch 178/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 132.3175 - val_loss: 689.9948\n",
      "Epoch 179/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 130.7055 - val_loss: 691.9737\n",
      "Epoch 180/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 129.1505 - val_loss: 693.9501\n",
      "Epoch 181/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 127.6509 - val_loss: 695.9227\n",
      "Epoch 182/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 126.2051 - val_loss: 697.8904\n",
      "Epoch 183/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 124.8116 - val_loss: 699.8522\n",
      "Epoch 184/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 123.4689 - val_loss: 701.8068\n",
      "Epoch 185/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 122.1756 - val_loss: 703.7535\n",
      "Epoch 186/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 120.9300 - val_loss: 705.6910\n",
      "Epoch 187/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 119.7308 - val_loss: 707.6184\n",
      "Epoch 188/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 118.5767 - val_loss: 709.5349\n",
      "Epoch 189/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 117.4661 - val_loss: 711.4394\n",
      "Epoch 190/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 116.3978 - val_loss: 713.3311\n",
      "Epoch 191/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 115.3705 - val_loss: 715.2090\n",
      "Epoch 192/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 114.3829 - val_loss: 717.0726\n",
      "Epoch 193/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 113.4336 - val_loss: 718.9208\n",
      "Epoch 194/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 112.5215 - val_loss: 720.7532\n",
      "Epoch 195/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 111.6453 - val_loss: 722.5690\n",
      "Epoch 196/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 110.8039 - val_loss: 724.3674\n",
      "Epoch 197/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 109.9960 - val_loss: 726.1482\n",
      "Epoch 198/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.2206 - val_loss: 727.9099\n",
      "Epoch 199/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 108.4765 - val_loss: 729.6523\n",
      "Epoch 200/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 107.7629 - val_loss: 731.3751\n",
      "Epoch 201/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.0785 - val_loss: 733.0779\n",
      "Epoch 202/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 106.4222 - val_loss: 734.7601\n",
      "Epoch 203/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 105.7933 - val_loss: 736.4207\n",
      "Epoch 204/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 105.1906 - val_loss: 738.0598\n",
      "Epoch 205/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 104.6131 - val_loss: 739.6771\n",
      "Epoch 206/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 104.0601 - val_loss: 741.2722\n",
      "Epoch 207/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 103.5305 - val_loss: 742.8444\n",
      "Epoch 208/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 103.0235 - val_loss: 744.3936\n",
      "Epoch 209/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 102.5385 - val_loss: 745.9197\n",
      "Epoch 210/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 102.0742 - val_loss: 747.4221\n",
      "Epoch 211/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 101.6303 - val_loss: 748.9007\n",
      "Epoch 212/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.2057 - val_loss: 750.3554\n",
      "Epoch 213/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 100.7998 - val_loss: 751.7858\n",
      "Epoch 214/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 100.4118 - val_loss: 753.1921\n",
      "Epoch 215/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 100.0410 - val_loss: 754.5740\n",
      "Epoch 216/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 99.6867 - val_loss: 755.9318\n",
      "Epoch 217/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 99.3483 - val_loss: 757.2644\n",
      "Epoch 218/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 99.0252 - val_loss: 758.5723\n",
      "Epoch 219/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 98.7167 - val_loss: 759.8563\n",
      "Epoch 220/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 98.4221 - val_loss: 761.1149\n",
      "Epoch 221/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 98.1411 - val_loss: 762.3494\n",
      "Epoch 222/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.8728 - val_loss: 763.5589\n",
      "Epoch 223/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.6169 - val_loss: 764.7442\n",
      "Epoch 224/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.3728 - val_loss: 765.9048\n",
      "Epoch 225/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.1401 - val_loss: 767.0413\n",
      "Epoch 226/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 96.9180 - val_loss: 768.1531\n",
      "Epoch 227/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 96.7065 - val_loss: 769.2412\n",
      "Epoch 228/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 96.5048 - val_loss: 770.3051\n",
      "Epoch 229/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 96.3126 - val_loss: 771.3447\n",
      "Epoch 230/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 96.1294 - val_loss: 772.3615\n",
      "Epoch 231/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 95.9550 - val_loss: 773.3543\n",
      "Epoch 232/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 95.7887 - val_loss: 774.3240\n",
      "Epoch 233/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 95.6304 - val_loss: 775.2706\n",
      "Epoch 234/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 95.4796 - val_loss: 776.1946\n",
      "Epoch 235/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 95.3360 - val_loss: 777.0957\n",
      "Epoch 236/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 95.1993 - val_loss: 777.9744\n",
      "Epoch 237/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 95.0692 - val_loss: 778.8315\n",
      "Epoch 238/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 94.9452 - val_loss: 779.6661\n",
      "Epoch 239/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 94.8273 - val_loss: 780.4797\n",
      "Epoch 240/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 94.7151 - val_loss: 781.2720\n",
      "Epoch 241/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 94.6083 - val_loss: 782.0430\n",
      "Epoch 242/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 94.5066 - val_loss: 782.7935\n",
      "Epoch 243/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 94.4099 - val_loss: 783.5236\n",
      "Epoch 244/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 94.3179 - val_loss: 784.2339\n",
      "Epoch 245/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 94.2303 - val_loss: 784.9243\n",
      "Epoch 246/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 94.1471 - val_loss: 785.5953\n",
      "Epoch 247/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 94.0678 - val_loss: 786.2473\n",
      "Epoch 248/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 93.9924 - val_loss: 786.8805\n",
      "Epoch 249/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 93.9207 - val_loss: 787.4955\n",
      "Epoch 250/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 93.8525 - val_loss: 788.0921\n",
      "Epoch 251/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 93.7876 - val_loss: 788.6711\n",
      "Epoch 252/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 93.7259 - val_loss: 789.2328\n",
      "Epoch 253/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 93.6672 - val_loss: 789.7776\n",
      "Epoch 254/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 93.6114 - val_loss: 790.3057\n",
      "Epoch 255/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 93.5583 - val_loss: 790.8177\n",
      "Epoch 256/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 93.5077 - val_loss: 791.3135\n",
      "Epoch 257/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 93.4597 - val_loss: 791.7936\n",
      "Epoch 258/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 93.4139 - val_loss: 792.2585\n",
      "Epoch 259/500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 93.3705 - val_loss: 792.7083\n",
      "Epoch 260/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 93.3292 - val_loss: 793.1440\n",
      "Epoch 261/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 93.2898 - val_loss: 793.5648\n",
      "Epoch 262/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 93.2524 - val_loss: 793.9725\n",
      "Epoch 263/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 93.2168 - val_loss: 794.3662\n",
      "Epoch 264/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 93.1829 - val_loss: 794.7466\n",
      "Epoch 265/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 93.1507 - val_loss: 795.1141\n",
      "Epoch 266/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 93.1201 - val_loss: 795.4692\n",
      "Epoch 267/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 93.0909 - val_loss: 795.8118\n",
      "Epoch 268/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 93.0632 - val_loss: 796.1426\n",
      "Epoch 269/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 93.0367 - val_loss: 796.4617\n",
      "Epoch 270/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 93.0117 - val_loss: 796.7698\n",
      "Epoch 271/500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 92.9878 - val_loss: 797.0668\n",
      "Epoch 272/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 92.9650 - val_loss: 797.3532\n",
      "Epoch 273/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.9434 - val_loss: 797.6291\n",
      "Epoch 274/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.9228 - val_loss: 797.8951\n",
      "Epoch 275/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.9032 - val_loss: 798.1514\n",
      "Epoch 276/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 92.8846 - val_loss: 798.3981\n",
      "Epoch 277/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 92.8669 - val_loss: 798.6354\n",
      "Epoch 278/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 92.8500 - val_loss: 798.8642\n",
      "Epoch 279/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 92.8339 - val_loss: 799.0841\n",
      "Epoch 280/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 92.8186 - val_loss: 799.2957\n",
      "Epoch 281/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 92.8041 - val_loss: 799.4993\n",
      "Epoch 282/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 92.7902 - val_loss: 799.6949\n",
      "Epoch 283/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 92.7771 - val_loss: 799.8829\n",
      "Epoch 284/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.7645 - val_loss: 800.0634\n",
      "Epoch 285/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.7526 - val_loss: 800.2374\n",
      "Epoch 286/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.7413 - val_loss: 800.4042\n",
      "Epoch 287/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.7305 - val_loss: 800.5643\n",
      "Epoch 288/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.7202 - val_loss: 800.7180\n",
      "Epoch 289/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.7104 - val_loss: 800.8651\n",
      "Epoch 290/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.7011 - val_loss: 801.0066\n",
      "Epoch 291/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.6923 - val_loss: 801.1424\n",
      "Epoch 292/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.6839 - val_loss: 801.2726\n",
      "Epoch 293/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.6759 - val_loss: 801.3975\n",
      "Epoch 294/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.6683 - val_loss: 801.5168\n",
      "Epoch 295/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.6610 - val_loss: 801.6312\n",
      "Epoch 296/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 92.6542 - val_loss: 801.7407\n",
      "Epoch 297/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.6477 - val_loss: 801.8456\n",
      "Epoch 298/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.6414 - val_loss: 801.9462\n",
      "Epoch 299/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.6355 - val_loss: 802.0423\n",
      "Epoch 300/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.6300 - val_loss: 802.1346\n",
      "Epoch 301/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.6246 - val_loss: 802.2224\n",
      "Epoch 302/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.6195 - val_loss: 802.3069\n",
      "Epoch 303/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.6148 - val_loss: 802.3873\n",
      "Epoch 304/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.6102 - val_loss: 802.4642\n",
      "Epoch 305/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.6058 - val_loss: 802.5379\n",
      "Epoch 306/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.6018 - val_loss: 802.6083\n",
      "Epoch 307/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5978 - val_loss: 802.6755\n",
      "Epoch 308/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5941 - val_loss: 802.7394\n",
      "Epoch 309/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5906 - val_loss: 802.8006\n",
      "Epoch 310/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5873 - val_loss: 802.8594\n",
      "Epoch 311/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5842 - val_loss: 802.9152\n",
      "Epoch 312/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5811 - val_loss: 802.9684\n",
      "Epoch 313/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5783 - val_loss: 803.0190\n",
      "Epoch 314/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5756 - val_loss: 803.0680\n",
      "Epoch 315/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5730 - val_loss: 803.1136\n",
      "Epoch 316/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5707 - val_loss: 803.1578\n",
      "Epoch 317/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5684 - val_loss: 803.1996\n",
      "Epoch 318/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5662 - val_loss: 803.2395\n",
      "Epoch 319/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5642 - val_loss: 803.2780\n",
      "Epoch 320/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5623 - val_loss: 803.3143\n",
      "Epoch 321/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5604 - val_loss: 803.3486\n",
      "Epoch 322/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5587 - val_loss: 803.3816\n",
      "Epoch 323/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5571 - val_loss: 803.4124\n",
      "Epoch 324/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 92.5556 - val_loss: 803.4423\n",
      "Epoch 325/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 92.5542 - val_loss: 803.4707\n",
      "Epoch 326/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5528 - val_loss: 803.4977\n",
      "Epoch 327/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5515 - val_loss: 803.5232\n",
      "Epoch 328/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5504 - val_loss: 803.5477\n",
      "Epoch 329/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5492 - val_loss: 803.5707\n",
      "Epoch 330/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5482 - val_loss: 803.5931\n",
      "Epoch 331/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5471 - val_loss: 803.6138\n",
      "Epoch 332/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5462 - val_loss: 803.6336\n",
      "Epoch 333/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5453 - val_loss: 803.6524\n",
      "Epoch 334/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5445 - val_loss: 803.6702\n",
      "Epoch 335/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5437 - val_loss: 803.6871\n",
      "Epoch 336/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5431 - val_loss: 803.7034\n",
      "Epoch 337/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5423 - val_loss: 803.7189\n",
      "Epoch 338/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5417 - val_loss: 803.7333\n",
      "Epoch 339/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5411 - val_loss: 803.7466\n",
      "Epoch 340/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5406 - val_loss: 803.7601\n",
      "Epoch 341/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 92.5401 - val_loss: 803.7725\n",
      "Epoch 342/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5396 - val_loss: 803.7846\n",
      "Epoch 343/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5392 - val_loss: 803.7956\n",
      "Epoch 344/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 92.5387 - val_loss: 803.8059\n",
      "Epoch 345/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 92.5384 - val_loss: 803.8159\n",
      "Epoch 346/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 92.5381 - val_loss: 803.8253\n",
      "Epoch 347/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 92.5378 - val_loss: 803.8343\n",
      "Epoch 348/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 92.5375 - val_loss: 803.8425\n",
      "Epoch 349/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 92.5372 - val_loss: 803.8506\n",
      "Epoch 350/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5370 - val_loss: 803.8582\n",
      "Epoch 351/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5367 - val_loss: 803.8653\n",
      "Epoch 352/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5365 - val_loss: 803.8719\n",
      "Epoch 353/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5364 - val_loss: 803.8781\n",
      "Epoch 354/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5362 - val_loss: 803.8839\n",
      "Epoch 355/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5361 - val_loss: 803.8900\n",
      "Epoch 356/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5360 - val_loss: 803.8954\n",
      "Epoch 357/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5359 - val_loss: 803.9006\n",
      "Epoch 358/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5358 - val_loss: 803.9055\n",
      "Epoch 359/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5357 - val_loss: 803.9100\n",
      "Epoch 360/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5356 - val_loss: 803.9143\n",
      "Epoch 361/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5355 - val_loss: 803.9182\n",
      "Epoch 362/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5355 - val_loss: 803.9218\n",
      "Epoch 363/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5355 - val_loss: 803.9254\n",
      "Epoch 364/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5355 - val_loss: 803.9288\n",
      "Epoch 365/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5355 - val_loss: 803.9321\n",
      "Epoch 366/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 92.5354 - val_loss: 803.9352\n",
      "Epoch 367/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 92.5354 - val_loss: 803.9380\n",
      "Epoch 368/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 92.5355 - val_loss: 803.9407\n",
      "Epoch 369/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5355 - val_loss: 803.9432\n",
      "Epoch 370/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5355 - val_loss: 803.9454\n",
      "Epoch 371/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5356 - val_loss: 803.9480\n",
      "Epoch 372/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5356 - val_loss: 803.9500\n",
      "Epoch 373/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5356 - val_loss: 803.9518\n",
      "Epoch 374/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5356 - val_loss: 803.9535\n",
      "Epoch 375/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5357 - val_loss: 803.9554\n",
      "Epoch 376/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5358 - val_loss: 803.9570\n",
      "Epoch 377/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5359 - val_loss: 803.9587\n",
      "Epoch 378/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5359 - val_loss: 803.9602\n",
      "Epoch 379/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5360 - val_loss: 803.9617\n",
      "Epoch 380/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5360 - val_loss: 803.9631\n",
      "Epoch 381/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5361 - val_loss: 803.9641\n",
      "Epoch 382/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 92.5361 - val_loss: 803.9651\n",
      "Epoch 383/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5363 - val_loss: 803.9660\n",
      "Epoch 384/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5364 - val_loss: 803.9670\n",
      "Epoch 385/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5364 - val_loss: 803.9680\n",
      "Epoch 386/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5365 - val_loss: 803.9686\n",
      "Epoch 387/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 92.5366 - val_loss: 803.9692\n",
      "Epoch 388/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5367 - val_loss: 803.9702\n",
      "Epoch 389/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5368 - val_loss: 803.9710\n",
      "Epoch 390/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5368 - val_loss: 803.9715\n",
      "Epoch 391/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5369 - val_loss: 803.9719\n",
      "Epoch 392/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5371 - val_loss: 803.9726\n",
      "Epoch 393/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5371 - val_loss: 803.9733\n",
      "Epoch 394/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5372 - val_loss: 803.9737\n",
      "Epoch 395/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5373 - val_loss: 803.9742\n",
      "Epoch 396/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5374 - val_loss: 803.9744\n",
      "Epoch 397/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5375 - val_loss: 803.9748\n",
      "Epoch 398/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5376 - val_loss: 803.9751\n",
      "Epoch 399/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5377 - val_loss: 803.9752\n",
      "Epoch 400/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5378 - val_loss: 803.9755\n",
      "Epoch 401/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5379 - val_loss: 803.9761\n",
      "Epoch 402/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5379 - val_loss: 803.9763\n",
      "Epoch 403/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5380 - val_loss: 803.9766\n",
      "Epoch 404/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5381 - val_loss: 803.9768\n",
      "Epoch 405/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5382 - val_loss: 803.9770\n",
      "Epoch 406/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5383 - val_loss: 803.9770\n",
      "Epoch 407/500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 92.5384 - val_loss: 803.9775\n",
      "Epoch 408/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 92.5384 - val_loss: 803.9774\n",
      "Epoch 409/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5385 - val_loss: 803.9772\n",
      "Epoch 410/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5387 - val_loss: 803.9775\n",
      "Epoch 411/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5387 - val_loss: 803.9772\n",
      "Epoch 412/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 92.5388 - val_loss: 803.9775\n",
      "Epoch 413/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 92.5389 - val_loss: 803.9777\n",
      "Epoch 414/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5390 - val_loss: 803.9775\n",
      "Epoch 415/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5391 - val_loss: 803.9772\n",
      "Epoch 416/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5392 - val_loss: 803.9772\n",
      "Epoch 417/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5393 - val_loss: 803.9772\n",
      "Epoch 418/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5394 - val_loss: 803.9772\n",
      "Epoch 419/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5394 - val_loss: 803.9772\n",
      "Epoch 420/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5395 - val_loss: 803.9772\n",
      "Epoch 421/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 92.5396 - val_loss: 803.9771\n",
      "Epoch 422/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5397 - val_loss: 803.9774\n",
      "Epoch 423/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5397 - val_loss: 803.9772\n",
      "Epoch 424/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5399 - val_loss: 803.9775\n",
      "Epoch 425/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5399 - val_loss: 803.9775\n",
      "Epoch 426/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5400 - val_loss: 803.9777\n",
      "Epoch 427/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5400 - val_loss: 803.9775\n",
      "Epoch 428/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5400 - val_loss: 803.9773\n",
      "Epoch 429/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 92.5402 - val_loss: 803.9771\n",
      "Epoch 430/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 92.5403 - val_loss: 803.9771\n",
      "Epoch 431/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5403 - val_loss: 803.9769\n",
      "Epoch 432/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5404 - val_loss: 803.9769\n",
      "Epoch 433/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5405 - val_loss: 803.9769\n",
      "Epoch 434/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5405 - val_loss: 803.9769\n",
      "Epoch 435/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5406 - val_loss: 803.9770\n",
      "Epoch 436/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5407 - val_loss: 803.9773\n",
      "Epoch 437/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5407 - val_loss: 803.9775\n",
      "Epoch 438/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5407 - val_loss: 803.9774\n",
      "Epoch 439/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5408 - val_loss: 803.9772\n",
      "Epoch 440/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5409 - val_loss: 803.9772\n",
      "Epoch 441/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5410 - val_loss: 803.9772\n",
      "Epoch 442/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5410 - val_loss: 803.9774\n",
      "Epoch 443/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5411 - val_loss: 803.9775\n",
      "Epoch 444/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5411 - val_loss: 803.9774\n",
      "Epoch 445/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5411 - val_loss: 803.9771\n",
      "Epoch 446/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5412 - val_loss: 803.9769\n",
      "Epoch 447/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5413 - val_loss: 803.9769\n",
      "Epoch 448/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5414 - val_loss: 803.9771\n",
      "Epoch 449/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5414 - val_loss: 803.9771\n",
      "Epoch 450/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5414 - val_loss: 803.9768\n",
      "Epoch 451/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5415 - val_loss: 803.9768\n",
      "Epoch 452/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5416 - val_loss: 803.9770\n",
      "Epoch 453/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5416 - val_loss: 803.9769\n",
      "Epoch 454/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5416 - val_loss: 803.9766\n",
      "Epoch 455/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5417 - val_loss: 803.9768\n",
      "Epoch 456/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 92.5417 - val_loss: 803.9770\n",
      "Epoch 457/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5418 - val_loss: 803.9770\n",
      "Epoch 458/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5418 - val_loss: 803.9769\n",
      "Epoch 459/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5418 - val_loss: 803.9769\n",
      "Epoch 460/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5419 - val_loss: 803.9769\n",
      "Epoch 461/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5419 - val_loss: 803.9766\n",
      "Epoch 462/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5420 - val_loss: 803.9768\n",
      "Epoch 463/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5420 - val_loss: 803.9769\n",
      "Epoch 464/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5421 - val_loss: 803.9769\n",
      "Epoch 465/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5421 - val_loss: 803.9769\n",
      "Epoch 466/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5421 - val_loss: 803.9770\n",
      "Epoch 467/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5422 - val_loss: 803.9769\n",
      "Epoch 468/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5422 - val_loss: 803.9766\n",
      "Epoch 469/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5422 - val_loss: 803.9763\n",
      "Epoch 470/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5423 - val_loss: 803.9762\n",
      "Epoch 471/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5423 - val_loss: 803.9761\n",
      "Epoch 472/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5424 - val_loss: 803.9759\n",
      "Epoch 473/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5424 - val_loss: 803.9761\n",
      "Epoch 474/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5425 - val_loss: 803.9763\n",
      "Epoch 475/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5425 - val_loss: 803.9763\n",
      "Epoch 476/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5425 - val_loss: 803.9763\n",
      "Epoch 477/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5425 - val_loss: 803.9762\n",
      "Epoch 478/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5426 - val_loss: 803.9762\n",
      "Epoch 479/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5426 - val_loss: 803.9761\n",
      "Epoch 480/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5427 - val_loss: 803.9763\n",
      "Epoch 481/500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 92.5427 - val_loss: 803.9763\n",
      "Epoch 482/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5426 - val_loss: 803.9762\n",
      "Epoch 483/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5427 - val_loss: 803.9756\n",
      "Epoch 484/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5428 - val_loss: 803.9758\n",
      "Epoch 485/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5428 - val_loss: 803.9758\n",
      "Epoch 486/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5428 - val_loss: 803.9760\n",
      "Epoch 487/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5429 - val_loss: 803.9762\n",
      "Epoch 488/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5428 - val_loss: 803.9761\n",
      "Epoch 489/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 92.5429 - val_loss: 803.9761\n",
      "Epoch 490/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5429 - val_loss: 803.9760\n",
      "Epoch 491/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5430 - val_loss: 803.9761\n",
      "Epoch 492/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5430 - val_loss: 803.9761\n",
      "Epoch 493/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5430 - val_loss: 803.9758\n",
      "Epoch 494/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5430 - val_loss: 803.9756\n",
      "Epoch 495/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5430 - val_loss: 803.9752\n",
      "Epoch 496/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5431 - val_loss: 803.9751\n",
      "Epoch 497/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 92.5431 - val_loss: 803.9749\n",
      "Epoch 498/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5432 - val_loss: 803.9756\n",
      "Epoch 499/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5432 - val_loss: 803.9758\n",
      "Epoch 500/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 92.5432 - val_loss: 803.9758\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 524ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.80509571e+01, 5.80089402e+01, 5.79669234e+01, 5.79249066e+01,\n",
       "        5.78828898e+01, 5.78408730e+01, 5.77988562e+01, 0.00000000e+00,\n",
       "        7.16493960e-01, 2.20957430e-01, 0.00000000e+00, 6.86268800e-02,\n",
       "        1.00525665e+00, 5.91537815e+01, 5.89857143e+01, 5.88176471e+01,\n",
       "        5.86495798e+01, 5.84815126e+01, 5.83134454e+01, 5.81863445e+01,\n",
       "        5.81443277e+01, 5.81023109e+01, 5.80602941e+01, 5.80182773e+01,\n",
       "        5.79762605e+01, 5.79342437e+01, 5.78922269e+01, 5.78502101e+01,\n",
       "        5.78081933e+01, 5.77661765e+01, 5.77241597e+01, 5.76821429e+01,\n",
       "        5.76401260e+01, 5.75981092e+01, 5.75560924e+01, 5.75140756e+01,\n",
       "        5.74720588e+01, 5.74300420e+01, 5.73880252e+01, 5.73460084e+01,\n",
       "        1.05346406e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.05044300e-02, 0.00000000e+00, 5.79435808e+01,\n",
       "        5.79015640e+01, 5.78595471e+01, 5.78175303e+01, 5.77755135e+01,\n",
       "        5.77334967e+01, 5.76914799e+01, 5.76494631e+01, 5.76074463e+01,\n",
       "        5.75654295e+01, 5.75234127e+01, 5.74813959e+01, 5.74393791e+01,\n",
       "        5.73973623e+01, 5.73553455e+01, 6.29306256e+01, 6.27289449e+01,\n",
       "        6.21602008e+01, 6.15299487e+01, 6.08996966e+01, 6.02694444e+01,\n",
       "        5.97513539e+01, 5.92471522e+01, 5.87429505e+01, 0.00000000e+00,\n",
       "        6.19025170e-01, 5.03264771e+01, 1.97836610e-02, 7.93619275e-01,\n",
       "        0.00000000e+00, 4.12894547e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.67768288e+01, 2.83631295e-01, 8.27213451e-02, 8.75653625e-02,\n",
       "        0.00000000e+00, 3.25177640e-01, 0.00000000e+00, 2.03480452e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.01974100e-01, 3.19956124e-01,\n",
       "        5.97576737e-01, 5.16042829e-01, 2.83000529e-01, 6.01354837e-01,\n",
       "        0.00000000e+00, 2.59597063e-01, 1.08075157e-01, 2.68835902e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52.79325397, 52.77738095, 52.76150794, 52.74563492, 52.7297619 ,\n",
       "       52.71388889, 52.69801587, 52.68214286, 52.66626984, 52.65039683,\n",
       "       52.63452381, 52.61865079, 52.60277778, 52.58690476, 52.57103175,\n",
       "       52.55515873, 52.53928571, 52.5234127 , 52.50753968, 52.49166667,\n",
       "       52.47579365, 52.45992063, 52.44404762, 52.4281746 , 52.41230159,\n",
       "       52.39642857, 52.38055556, 52.36468254, 52.34880952, 52.33293651,\n",
       "       52.31706349, 52.30119048, 52.28531746, 52.26944444, 52.25357143,\n",
       "       52.23769841, 52.2218254 , 52.20595238, 52.19007937, 52.17420635,\n",
       "       52.15833333, 52.14246032, 52.1265873 , 52.11071429, 52.09484127,\n",
       "       52.07896825, 52.06309524, 52.04722222, 52.03134921, 52.01547619,\n",
       "       51.99960317, 51.98373016, 51.96785714, 51.95198413, 51.93611111,\n",
       "       51.9202381 , 51.90436508, 51.88849206, 51.87261905, 51.85674603,\n",
       "       51.84087302, 51.825     , 51.80912698, 51.79325397, 51.77738095,\n",
       "       51.76150794, 51.74563492, 51.7297619 , 51.71388889, 51.69830766,\n",
       "       51.68476891, 51.67123016, 51.65769141, 51.64415266, 51.63061391,\n",
       "       51.61707516, 51.60353641, 51.58999767, 51.57645892, 51.56292017,\n",
       "       51.54938142, 51.53584267, 51.52230392, 51.50876517, 51.49522642,\n",
       "       51.48168768, 51.46814893, 51.45461018, 51.44107143, 51.42753268,\n",
       "       51.41399393, 51.40045518, 51.38691643, 51.37337768, 51.35983894,\n",
       "       51.34630019, 51.33276144, 51.31922269, 51.30568394, 51.29214519])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.951217236338856\n",
      "24.23678931760318\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
