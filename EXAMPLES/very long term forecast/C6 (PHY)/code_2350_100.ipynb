{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2445    45.731256\n",
       "2446    45.721418\n",
       "2447    45.711580\n",
       "2448    45.701742\n",
       "2449    45.691904\n",
       "Name: C6, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_2350_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2345     0.424734\n",
       "2346     0.000000\n",
       "2347     0.000000\n",
       "2348     0.000000\n",
       "2349     0.000000\n",
       "Name: C6, Length: 2350, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2350)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 1, 251) (1900, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 3s 24ms/step - loss: 3590.9558 - val_loss: 1855.6019\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3320.9099 - val_loss: 1747.2354\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3222.4993 - val_loss: 1690.6415\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3127.5537 - val_loss: 1645.8798\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3048.6716 - val_loss: 1605.4192\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2973.9954 - val_loss: 1566.6213\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2902.0679 - val_loss: 1529.7042\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2832.4700 - val_loss: 1494.6945\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2764.7380 - val_loss: 1460.6304\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2697.0820 - val_loss: 1425.0967\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2626.8723 - val_loss: 1389.4592\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2560.0215 - val_loss: 1357.1940\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2495.5132 - val_loss: 1328.8038\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2432.9343 - val_loss: 1299.5688\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2372.1062 - val_loss: 1271.5574\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2312.8711 - val_loss: 1244.7012\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2255.1313 - val_loss: 1218.9492\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2198.8171 - val_loss: 1194.2605\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2143.8730 - val_loss: 1170.5249\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2084.8230 - val_loss: 1142.6954\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2023.4374 - val_loss: 1119.1202\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1968.3690 - val_loss: 1096.7643\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1915.0474 - val_loss: 1076.1693\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1863.8730 - val_loss: 1056.5873\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1814.3129 - val_loss: 1038.0667\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1766.2178 - val_loss: 1020.5444\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1719.4897 - val_loss: 1003.9742\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1674.0601 - val_loss: 988.3179\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1629.8726 - val_loss: 973.5432\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1586.8820 - val_loss: 959.6252\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1545.0485 - val_loss: 946.5610\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1504.6959 - val_loss: 933.7527\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1464.7214 - val_loss: 922.2266\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1426.1676 - val_loss: 911.5320\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1388.6472 - val_loss: 901.6553\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1352.1403 - val_loss: 892.3298\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1316.6217 - val_loss: 883.6978\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1282.0692 - val_loss: 875.7397\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1248.4608 - val_loss: 868.4373\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1215.7767 - val_loss: 861.7723\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1183.9967 - val_loss: 855.7268\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1153.1010 - val_loss: 850.2836\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1123.0709 - val_loss: 845.4255\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1093.8888 - val_loss: 841.1355\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1065.5360 - val_loss: 837.3977\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1037.9954 - val_loss: 834.1949\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1011.2498 - val_loss: 831.5118\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 985.2824 - val_loss: 829.3322\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 960.0768 - val_loss: 827.6406\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 935.6166 - val_loss: 826.4214\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 911.8860 - val_loss: 825.6592\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 888.8695 - val_loss: 825.3388\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 866.5516 - val_loss: 825.4451\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 844.9169 - val_loss: 825.9631\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 823.9507 - val_loss: 826.8774\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 803.6381 - val_loss: 828.1726\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 783.9643 - val_loss: 829.8314\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 764.9155 - val_loss: 831.8345\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 746.4771 - val_loss: 834.1526\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 728.6353 - val_loss: 836.7051\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 711.3764 - val_loss: 837.2863\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 693.4935 - val_loss: 841.9315\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 678.5231 - val_loss: 847.9562\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 662.9167 - val_loss: 851.8839\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 647.8552 - val_loss: 856.0760\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 633.3113 - val_loss: 860.5211\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 619.2711 - val_loss: 865.2065\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 605.7222 - val_loss: 870.1201\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 592.6518 - val_loss: 875.2498\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 580.0480 - val_loss: 880.5843\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 567.8985 - val_loss: 886.1118\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 556.1914 - val_loss: 891.8208\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 544.9150 - val_loss: 897.7003\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 534.0577 - val_loss: 903.7391\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 523.6080 - val_loss: 909.9266\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 513.5548 - val_loss: 916.2516\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 503.8868 - val_loss: 922.7046\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 494.5932 - val_loss: 929.2747\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 485.6632 - val_loss: 935.9520\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 477.0863 - val_loss: 942.7266\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 468.8519 - val_loss: 949.5892\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 460.9499 - val_loss: 956.5300\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 453.3700 - val_loss: 963.5399\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 446.1025 - val_loss: 970.6102\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 439.1374 - val_loss: 977.7321\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 432.4654 - val_loss: 984.8967\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 426.0769 - val_loss: 992.0958\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 419.9627 - val_loss: 999.3215\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 414.1139 - val_loss: 1006.5658\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.5213 - val_loss: 1013.8207\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 403.1765 - val_loss: 1021.0798\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 398.0707 - val_loss: 1028.3348\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 393.1957 - val_loss: 1035.5792\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 388.5434 - val_loss: 1042.8065\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 384.1056 - val_loss: 1050.0099\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 379.8746 - val_loss: 1057.1833\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 375.8428 - val_loss: 1064.3208\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 372.0026 - val_loss: 1071.4161\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 368.3467 - val_loss: 1078.4645\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 364.8682 - val_loss: 1085.4600\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 361.5600 - val_loss: 1092.3977\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 358.4154 - val_loss: 1099.2731\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 355.4277 - val_loss: 1106.0811\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 352.5907 - val_loss: 1112.8179\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 349.8980 - val_loss: 1119.4788\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 347.3438 - val_loss: 1126.0602\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 344.9220 - val_loss: 1132.5586\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 342.6269 - val_loss: 1138.9698\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 340.4532 - val_loss: 1145.2916\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 338.3953 - val_loss: 1151.5200\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 336.4481 - val_loss: 1157.6530\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 334.6066 - val_loss: 1163.6875\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 332.8660 - val_loss: 1169.6208\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 331.2215 - val_loss: 1175.4514\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 329.6686 - val_loss: 1181.1766\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 328.2030 - val_loss: 1186.7947\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 326.8205 - val_loss: 1192.3038\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 325.5168 - val_loss: 1197.7018\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 324.2883 - val_loss: 1202.9873\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 323.1310 - val_loss: 1208.1581\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 322.0414 - val_loss: 1213.2119\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 321.0161 - val_loss: 1218.1467\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 320.0517 - val_loss: 1222.9590\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 319.1450 - val_loss: 1227.6464\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 318.2899 - val_loss: 1229.2080\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 319.0173 - val_loss: 1239.6136\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 316.7347 - val_loss: 1244.0430\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 316.0291 - val_loss: 1248.3564\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 315.3679 - val_loss: 1252.5591\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 314.7479 - val_loss: 1256.6511\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 314.1667 - val_loss: 1260.6331\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 313.6222 - val_loss: 1264.5063\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 313.1122 - val_loss: 1268.2719\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 312.6347 - val_loss: 1271.9304\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 312.1879 - val_loss: 1275.4835\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 311.7697 - val_loss: 1278.9329\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 311.3787 - val_loss: 1282.2788\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 311.0132 - val_loss: 1285.5233\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 310.6714 - val_loss: 1288.6678\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 310.3522 - val_loss: 1291.7144\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 310.0540 - val_loss: 1294.6635\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 309.7755 - val_loss: 1297.5183\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 309.5154 - val_loss: 1300.2793\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 309.2728 - val_loss: 1302.9492\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 309.0463 - val_loss: 1305.5288\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 308.8350 - val_loss: 1308.0212\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 308.6379 - val_loss: 1310.4275\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 308.4541 - val_loss: 1312.7496\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 308.2826 - val_loss: 1314.9890\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 308.1229 - val_loss: 1317.1493\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 307.9739 - val_loss: 1319.2307\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 307.8351 - val_loss: 1321.2366\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 307.7055 - val_loss: 1323.1672\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 307.5850 - val_loss: 1325.0260\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 307.4726 - val_loss: 1326.8149\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 307.3678 - val_loss: 1328.5344\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 307.2703 - val_loss: 1330.1884\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 307.1793 - val_loss: 1331.7778\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 307.0946 - val_loss: 1333.3036\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 307.0156 - val_loss: 1334.7690\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.9421 - val_loss: 1336.1760\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.8734 - val_loss: 1337.5258\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 306.8095 - val_loss: 1338.8202\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 306.7500 - val_loss: 1340.0613\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 306.6945 - val_loss: 1341.2504\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.6427 - val_loss: 1342.3901\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 306.5945 - val_loss: 1343.4811\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.5495 - val_loss: 1344.5255\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.5076 - val_loss: 1345.5254\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.4685 - val_loss: 1346.4818\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.4321 - val_loss: 1347.3966\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.3980 - val_loss: 1348.2708\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 306.3663 - val_loss: 1349.1064\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.3366 - val_loss: 1349.9043\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 306.3091 - val_loss: 1350.6670\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 306.2833 - val_loss: 1351.3949\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 306.2592 - val_loss: 1352.0896\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.2367 - val_loss: 1352.7526\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.2157 - val_loss: 1353.3846\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 306.1962 - val_loss: 1353.9878\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 306.1778 - val_loss: 1354.5626\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 306.1607 - val_loss: 1355.1102\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 306.1448 - val_loss: 1355.6326\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 306.1299 - val_loss: 1356.1290\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 306.1159 - val_loss: 1356.6028\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 306.1029 - val_loss: 1357.0530\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 306.0908 - val_loss: 1357.4816\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 306.0794 - val_loss: 1357.8896\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0688 - val_loss: 1358.2776\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0589 - val_loss: 1358.6469\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0496 - val_loss: 1358.9980\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 306.0409 - val_loss: 1359.3311\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 306.0328 - val_loss: 1359.6478\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 306.0252 - val_loss: 1359.9487\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 306.0182 - val_loss: 1360.2344\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 306.0116 - val_loss: 1360.5059\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 306.0054 - val_loss: 1360.7632\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9997 - val_loss: 1361.0072\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 305.9942 - val_loss: 1361.2393\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9893 - val_loss: 1361.4597\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9846 - val_loss: 1361.6683\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9802 - val_loss: 1361.8658\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 305.9761 - val_loss: 1362.0531\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 305.9724 - val_loss: 1362.2306\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9688 - val_loss: 1362.3995\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9655 - val_loss: 1362.5591\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 305.9624 - val_loss: 1362.7100\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 305.9595 - val_loss: 1362.8539\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9569 - val_loss: 1362.9893\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9544 - val_loss: 1363.1173\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9521 - val_loss: 1363.2388\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9500 - val_loss: 1363.3540\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 305.9481 - val_loss: 1363.4628\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9462 - val_loss: 1363.5657\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 305.9445 - val_loss: 1363.6624\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 305.9430 - val_loss: 1363.7544\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9416 - val_loss: 1363.8416\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 305.9402 - val_loss: 1363.9235\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 305.9390 - val_loss: 1364.0013\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 305.9378 - val_loss: 1364.0750\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9368 - val_loss: 1364.1439\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 305.9359 - val_loss: 1364.2094\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 305.9350 - val_loss: 1364.2714\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 305.9342 - val_loss: 1364.3301\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9334 - val_loss: 1364.3849\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9328 - val_loss: 1364.4370\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9323 - val_loss: 1364.4861\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9317 - val_loss: 1364.5326\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9312 - val_loss: 1364.5767\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9308 - val_loss: 1364.6182\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9304 - val_loss: 1364.6569\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9300 - val_loss: 1364.6935\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9297 - val_loss: 1364.7281\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9294 - val_loss: 1364.7612\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9292 - val_loss: 1364.7913\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9290 - val_loss: 1364.8209\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9290 - val_loss: 1364.8485\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9287 - val_loss: 1364.8745\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9286 - val_loss: 1364.8983\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9286 - val_loss: 1364.9220\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9285 - val_loss: 1364.9435\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9284 - val_loss: 1364.9635\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9285 - val_loss: 1364.9829\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9284 - val_loss: 1365.0016\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9284 - val_loss: 1365.0178\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9285 - val_loss: 1365.0334\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9285 - val_loss: 1365.0491\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9286 - val_loss: 1365.0634\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9286 - val_loss: 1365.0765\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9287 - val_loss: 1365.0891\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9288 - val_loss: 1365.1014\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9289 - val_loss: 1365.1118\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9290 - val_loss: 1365.1230\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9291 - val_loss: 1365.1324\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9293 - val_loss: 1365.1425\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 305.9294 - val_loss: 1365.1511\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9295 - val_loss: 1365.1591\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9296 - val_loss: 1365.1670\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9298 - val_loss: 1365.1742\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9300 - val_loss: 1365.1810\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9301 - val_loss: 1365.1876\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9302 - val_loss: 1365.1936\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9304 - val_loss: 1365.1997\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9305 - val_loss: 1365.2043\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9308 - val_loss: 1365.2097\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9308 - val_loss: 1365.2145\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9310 - val_loss: 1365.2183\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 305.9312 - val_loss: 1365.2229\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9314 - val_loss: 1365.2262\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9315 - val_loss: 1365.2301\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9317 - val_loss: 1365.2333\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9319 - val_loss: 1365.2371\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9320 - val_loss: 1365.2399\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9322 - val_loss: 1365.2430\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9323 - val_loss: 1365.2457\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9325 - val_loss: 1365.2477\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9327 - val_loss: 1365.2509\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9328 - val_loss: 1365.2527\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9330 - val_loss: 1365.2548\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9331 - val_loss: 1365.2560\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9333 - val_loss: 1365.2585\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 305.9334 - val_loss: 1365.2601\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9336 - val_loss: 1365.2617\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9337 - val_loss: 1365.2629\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9339 - val_loss: 1365.2648\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9341 - val_loss: 1365.2667\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 305.9342 - val_loss: 1365.2675\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9343 - val_loss: 1365.2689\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9344 - val_loss: 1365.2695\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9346 - val_loss: 1365.2704\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9348 - val_loss: 1365.2710\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9349 - val_loss: 1365.2725\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9350 - val_loss: 1365.2739\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9351 - val_loss: 1365.2747\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9352 - val_loss: 1365.2753\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9353 - val_loss: 1365.2760\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9355 - val_loss: 1365.2769\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9356 - val_loss: 1365.2778\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9357 - val_loss: 1365.2784\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9358 - val_loss: 1365.2791\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9359 - val_loss: 1365.2794\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9361 - val_loss: 1365.2799\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9362 - val_loss: 1365.2804\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 305.9363 - val_loss: 1365.2804\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 305.9364 - val_loss: 1365.2810\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9366 - val_loss: 1365.2814\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9366 - val_loss: 1365.2821\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9367 - val_loss: 1365.2823\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 305.9368 - val_loss: 1365.2832\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9369 - val_loss: 1365.2836\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9370 - val_loss: 1365.2838\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9370 - val_loss: 1365.2843\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9372 - val_loss: 1365.2844\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9373 - val_loss: 1365.2849\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9373 - val_loss: 1365.2850\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9375 - val_loss: 1365.2855\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9375 - val_loss: 1365.2860\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9377 - val_loss: 1365.2865\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9377 - val_loss: 1365.2872\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9377 - val_loss: 1365.2875\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9378 - val_loss: 1365.2881\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 305.9379 - val_loss: 1365.2880\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9380 - val_loss: 1365.2888\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9380 - val_loss: 1365.2892\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9381 - val_loss: 1365.2897\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9382 - val_loss: 1365.2899\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9382 - val_loss: 1365.2902\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9383 - val_loss: 1365.2908\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9384 - val_loss: 1365.2911\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9385 - val_loss: 1365.2915\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9385 - val_loss: 1365.2917\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9386 - val_loss: 1365.2922\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9386 - val_loss: 1365.2927\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9387 - val_loss: 1365.2925\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9387 - val_loss: 1365.2927\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 305.9388 - val_loss: 1365.2942\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9388 - val_loss: 1365.2944\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9388 - val_loss: 1365.2949\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9389 - val_loss: 1365.2963\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9390 - val_loss: 1365.2980\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9390 - val_loss: 1365.3031\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9389 - val_loss: 1365.3500\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.5200 - val_loss: 1359.6038\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.2098 - val_loss: 1360.4272\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.1199 - val_loss: 1360.7866\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0966 - val_loss: 1361.0905\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0816 - val_loss: 1361.3661\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0700 - val_loss: 1361.6185\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0602 - val_loss: 1361.8545\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0516 - val_loss: 1362.0720\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0441 - val_loss: 1362.2749\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0374 - val_loss: 1362.4640\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0312 - val_loss: 1362.6406\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0256 - val_loss: 1362.8036\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0207 - val_loss: 1362.9581\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0160 - val_loss: 1363.1017\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0116 - val_loss: 1363.2358\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0077 - val_loss: 1363.3617\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0039 - val_loss: 1363.4784\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 306.0005 - val_loss: 1363.5878\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9974 - val_loss: 1363.6906\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9945 - val_loss: 1363.7866\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9918 - val_loss: 1363.8766\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9893 - val_loss: 1363.9601\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9870 - val_loss: 1364.0397\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9847 - val_loss: 1364.1139\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 305.9827 - val_loss: 1364.1825\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9808 - val_loss: 1364.2476\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9791 - val_loss: 1364.3081\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9774 - val_loss: 1364.3655\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9758 - val_loss: 1364.4182\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9743 - val_loss: 1364.4680\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9731 - val_loss: 1364.5149\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9718 - val_loss: 1364.5586\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9706 - val_loss: 1364.5989\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9695 - val_loss: 1364.6384\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9684 - val_loss: 1364.6736\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9675 - val_loss: 1364.7079\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9666 - val_loss: 1364.7399\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9657 - val_loss: 1364.7695\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9649 - val_loss: 1364.7980\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9641 - val_loss: 1364.8229\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9636 - val_loss: 1364.8486\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9628 - val_loss: 1364.8713\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9621 - val_loss: 1364.8933\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9615 - val_loss: 1364.9128\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9611 - val_loss: 1364.9321\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9605 - val_loss: 1364.9500\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9600 - val_loss: 1364.9668\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9596 - val_loss: 1364.9833\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9591 - val_loss: 1364.9977\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9588 - val_loss: 1365.0109\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9585 - val_loss: 1365.0243\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9581 - val_loss: 1365.0374\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 305.9577 - val_loss: 1365.0479\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9574 - val_loss: 1365.0594\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9572 - val_loss: 1365.0692\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9569 - val_loss: 1365.0786\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9566 - val_loss: 1365.0875\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9564 - val_loss: 1365.0962\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9561 - val_loss: 1365.1049\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9560 - val_loss: 1365.1128\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9556 - val_loss: 1365.1188\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9555 - val_loss: 1365.1256\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9554 - val_loss: 1365.1321\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9552 - val_loss: 1365.1383\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9549 - val_loss: 1365.1431\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9549 - val_loss: 1365.1486\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9547 - val_loss: 1365.1533\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9546 - val_loss: 1365.1578\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9545 - val_loss: 1365.1625\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9543 - val_loss: 1365.1663\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9543 - val_loss: 1365.1705\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9541 - val_loss: 1365.1741\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9540 - val_loss: 1365.1772\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9540 - val_loss: 1365.1815\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9538 - val_loss: 1365.1838\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9537 - val_loss: 1365.1869\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 305.9537 - val_loss: 1365.1902\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9536 - val_loss: 1365.1923\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9535 - val_loss: 1365.1949\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9535 - val_loss: 1365.1969\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9535 - val_loss: 1365.2000\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9534 - val_loss: 1365.2020\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9533 - val_loss: 1365.2043\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9532 - val_loss: 1365.2062\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9533 - val_loss: 1365.2087\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9532 - val_loss: 1365.2107\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9531 - val_loss: 1365.2125\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9531 - val_loss: 1365.2145\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9530 - val_loss: 1365.2166\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9531 - val_loss: 1365.2186\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9530 - val_loss: 1365.2205\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9529 - val_loss: 1365.2223\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9529 - val_loss: 1365.2231\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9529 - val_loss: 1365.2246\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9528 - val_loss: 1365.2256\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9528 - val_loss: 1365.2269\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9528 - val_loss: 1365.2281\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9528 - val_loss: 1365.2296\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9527 - val_loss: 1365.2310\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9528 - val_loss: 1365.2322\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9527 - val_loss: 1365.2338\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 305.9528 - val_loss: 1365.2350\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9527 - val_loss: 1365.2366\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9526 - val_loss: 1365.2380\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9525 - val_loss: 1365.2391\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9525 - val_loss: 1365.2399\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9525 - val_loss: 1365.2408\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9525 - val_loss: 1365.2422\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9525 - val_loss: 1365.2430\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9525 - val_loss: 1365.2443\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9525 - val_loss: 1365.2451\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9525 - val_loss: 1365.2466\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9525 - val_loss: 1365.2477\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9525 - val_loss: 1365.2488\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9525 - val_loss: 1365.2499\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9525 - val_loss: 1365.2509\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9525 - val_loss: 1365.2517\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9524 - val_loss: 1365.2532\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9524 - val_loss: 1365.2542\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9524 - val_loss: 1365.2550\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9524 - val_loss: 1365.2565\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9524 - val_loss: 1365.2574\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9524 - val_loss: 1365.2583\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9524 - val_loss: 1365.2592\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9524 - val_loss: 1365.2599\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9524 - val_loss: 1365.2605\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 305.9524 - val_loss: 1365.2620\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9524 - val_loss: 1365.2629\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9524 - val_loss: 1365.2633\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9524 - val_loss: 1365.2642\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9524 - val_loss: 1365.2650\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9524 - val_loss: 1365.2656\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2665\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2671\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2683\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.9523 - val_loss: 1365.2692\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2700\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2710\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2721\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2731\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2740\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2751\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2761\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2771\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2781\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2788\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2799\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2809\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2819\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2833\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 305.9523 - val_loss: 1365.2844\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 305.9523 - val_loss: 1365.2855\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2867\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2878\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2893\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9524 - val_loss: 1365.2906\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2919\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 305.9523 - val_loss: 1365.2930\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 365ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.73553455e+01, 6.21602008e+01, 6.02694444e+01, 5.87429505e+01,\n",
       "        5.03264771e+01, 0.00000000e+00, 0.00000000e+00, 8.27213450e-02,\n",
       "        3.25177640e-01, 0.00000000e+00, 3.19956124e-01, 2.83000529e-01,\n",
       "        2.59597063e-01, 5.80509571e+01, 5.79249066e+01, 5.77988562e+01,\n",
       "        2.20957430e-01, 1.00525665e+00, 5.88176471e+01, 5.83134454e+01,\n",
       "        5.81023109e+01, 5.79762605e+01, 5.78502101e+01, 5.77241597e+01,\n",
       "        5.75981092e+01, 5.74720588e+01, 5.73460084e+01, 0.00000000e+00,\n",
       "        4.05044300e-02, 5.79015640e+01, 5.77755135e+01, 5.76494631e+01,\n",
       "        5.75234127e+01, 5.73973623e+01, 6.27289449e+01, 6.08996966e+01,\n",
       "        5.92471522e+01, 6.19025170e-01, 7.93619275e-01, 0.00000000e+00,\n",
       "        2.83631295e-01, 0.00000000e+00, 2.03480452e-01, 1.01974100e-01,\n",
       "        5.16042829e-01, 0.00000000e+00, 2.68835902e-01, 5.94152194e+01,\n",
       "        1.20105090e-01, 1.07094742e-01, 0.00000000e+00, 5.74627218e+01,\n",
       "        5.73366713e+01, 6.18800887e+01, 6.00314659e+01, 5.85188609e+01,\n",
       "        6.10876354e+01, 5.92284781e+01, 5.80789683e+01, 0.00000000e+00,\n",
       "        3.47389130e-02, 3.86974573e-01, 5.91351074e+01, 0.00000000e+00,\n",
       "        5.98447246e+01, 5.83321195e+01, 5.78548786e+01, 5.90417367e+01,\n",
       "        5.80322829e+01, 5.76541316e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.25831570e-01, 5.82638283e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.39277840e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.74987717e+01, 0.00000000e+00, 7.99272537e-01, 0.00000000e+00,\n",
       "        4.33513701e-01, 6.02338970e-01, 0.00000000e+00, 5.09336770e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.63921517e-01, 1.88844875e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.69227743e-01,\n",
       "        0.00000000e+00, 1.46271661e-01, 0.00000000e+00, 3.57824296e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46.66587415, 46.65603607, 46.64619799, 46.63635991, 46.62652183,\n",
       "       46.61668375, 46.60684567, 46.59700758, 46.5871695 , 46.57733142,\n",
       "       46.56749334, 46.55765526, 46.54781718, 46.53797909, 46.52814101,\n",
       "       46.51830293, 46.50846485, 46.49862677, 46.48878869, 46.4789506 ,\n",
       "       46.46911252, 46.45927444, 46.44943636, 46.43959828, 46.4297602 ,\n",
       "       46.41992212, 46.41008403, 46.40024595, 46.39040787, 46.38056979,\n",
       "       46.37073171, 46.36089363, 46.35105554, 46.34121746, 46.33137938,\n",
       "       46.3215413 , 46.31170322, 46.30186514, 46.29202705, 46.28218897,\n",
       "       46.27235089, 46.26251281, 46.25267473, 46.24283665, 46.23299857,\n",
       "       46.22316048, 46.2133224 , 46.20348432, 46.19364624, 46.18380816,\n",
       "       46.17397008, 46.16413199, 46.15429391, 46.14445583, 46.13461775,\n",
       "       46.12477967, 46.11494159, 46.1051035 , 46.09526542, 46.08542734,\n",
       "       46.07558926, 46.06575118, 46.0559131 , 46.04607502, 46.03623693,\n",
       "       46.02639885, 46.01656077, 46.00672269, 45.99688461, 45.98704653,\n",
       "       45.97720844, 45.96737036, 45.95753228, 45.9476942 , 45.93785612,\n",
       "       45.92801804, 45.91817995, 45.90834187, 45.89850379, 45.88866571,\n",
       "       45.87882763, 45.86898955, 45.85915147, 45.84931338, 45.8394753 ,\n",
       "       45.82963722, 45.81979914, 45.80996106, 45.80012298, 45.79028489,\n",
       "       45.78044681, 45.77060873, 45.76077065, 45.75093257, 45.74109449,\n",
       "       45.73125641, 45.72141832, 45.71158024, 45.70174216, 45.69190408])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.59428438923234\n",
      "31.400804326595825\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
