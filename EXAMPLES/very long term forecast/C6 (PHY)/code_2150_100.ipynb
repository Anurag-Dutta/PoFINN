{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2245    47.698873\n",
       "2246    47.689035\n",
       "2247    47.679197\n",
       "2248    47.669358\n",
       "2249    47.659520\n",
       "Name: C6, Length: 2250, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_2150_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2145     0.000000\n",
       "2146     0.405019\n",
       "2147     0.122501\n",
       "2148     0.000000\n",
       "2149     0.000000\n",
       "Name: C6, Length: 2150, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2150)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 1, 251) (1700, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/22 [==============================] - 2s 23ms/step - loss: 3717.2478 - val_loss: 1957.1167\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3420.6941 - val_loss: 1822.8726\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3302.5808 - val_loss: 1764.9120\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3198.3457 - val_loss: 1710.7013\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3105.5867 - val_loss: 1661.7991\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3016.7371 - val_loss: 1615.2090\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2931.0989 - val_loss: 1570.9458\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2848.1440 - val_loss: 1528.5643\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2767.5786 - val_loss: 1487.9238\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2689.2141 - val_loss: 1448.9231\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2612.9155 - val_loss: 1411.3770\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2531.4973 - val_loss: 1370.4712\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2454.0625 - val_loss: 1334.2428\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2380.0308 - val_loss: 1299.9143\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2308.5139 - val_loss: 1267.2701\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2239.1953 - val_loss: 1236.1765\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2171.8872 - val_loss: 1206.5460\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2106.4690 - val_loss: 1178.3129\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2042.8522 - val_loss: 1151.4247\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1980.9684 - val_loss: 1125.8365\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1920.7592 - val_loss: 1101.5078\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1862.1765 - val_loss: 1078.4022\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1805.1747 - val_loss: 1056.4847\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1749.7145 - val_loss: 1035.7241\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1695.7584 - val_loss: 1016.0887\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1643.2714 - val_loss: 997.5494\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1592.2206 - val_loss: 980.0771\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1542.5742 - val_loss: 963.6447\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1494.3022 - val_loss: 948.2246\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1447.3750 - val_loss: 933.7905\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1401.7648 - val_loss: 920.3168\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1357.4438 - val_loss: 907.7776\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1314.3856 - val_loss: 896.1481\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1272.5635 - val_loss: 885.4039\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1231.9517 - val_loss: 875.5216\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1192.5256 - val_loss: 866.5276\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1154.2588 - val_loss: 858.2196\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1117.5918 - val_loss: 850.8038\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1081.1107 - val_loss: 844.1350\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1046.1847 - val_loss: 838.2120\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1012.3253 - val_loss: 833.0129\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 979.5091 - val_loss: 828.5153\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 947.7141 - val_loss: 824.6975\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 916.9177 - val_loss: 821.5380\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 887.0987 - val_loss: 819.0156\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 858.2347 - val_loss: 817.1093\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 830.3051 - val_loss: 815.7983\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 803.2883 - val_loss: 815.0623\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 777.1638 - val_loss: 814.8809\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 751.9112 - val_loss: 815.2338\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 727.5096 - val_loss: 816.1017\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 703.9396 - val_loss: 817.4646\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 681.1810 - val_loss: 819.3035\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 659.2144 - val_loss: 821.5991\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 638.0205 - val_loss: 824.3326\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 617.5801 - val_loss: 827.4857\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 597.8741 - val_loss: 831.0396\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 578.8844 - val_loss: 834.9766\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 560.5922 - val_loss: 839.2784\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 542.9794 - val_loss: 843.9279\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 526.0280 - val_loss: 848.9077\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 509.7205 - val_loss: 854.2002\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 494.0393 - val_loss: 859.7892\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 478.9673 - val_loss: 865.6579\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 464.4873 - val_loss: 871.7903\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 450.5827 - val_loss: 878.1697\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 437.2369 - val_loss: 884.7812\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 424.4337 - val_loss: 891.6086\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 412.1571 - val_loss: 898.6377\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 400.3911 - val_loss: 905.8528\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 389.1202 - val_loss: 913.2398\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 378.3293 - val_loss: 920.7844\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 368.0031 - val_loss: 928.4726\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 358.1270 - val_loss: 936.2910\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 348.6863 - val_loss: 944.2255\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 339.6668 - val_loss: 952.2636\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 331.0545 - val_loss: 960.3932\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 322.8356 - val_loss: 968.6008\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 314.9965 - val_loss: 976.8751\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 307.5240 - val_loss: 985.2040\n",
      "Epoch 81/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 300.4051 - val_loss: 993.5762\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 293.6272 - val_loss: 1001.9811\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 287.1777 - val_loss: 1010.4073\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 281.0445 - val_loss: 1018.8453\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 275.2155 - val_loss: 1027.2845\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 269.6793 - val_loss: 1035.7152\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 264.4243 - val_loss: 1044.1277\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 259.4395 - val_loss: 1052.5144\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 254.7140 - val_loss: 1060.8649\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 250.2373 - val_loss: 1069.1726\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 245.9991 - val_loss: 1077.4286\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 241.9894 - val_loss: 1085.6252\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 238.1983 - val_loss: 1093.7560\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 234.6165 - val_loss: 1101.8134\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.2347 - val_loss: 1109.7919\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 228.0439 - val_loss: 1117.6838\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 225.0355 - val_loss: 1125.4844\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 222.2011 - val_loss: 1133.1874\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 219.5326 - val_loss: 1140.7887\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 217.0220 - val_loss: 1148.2825\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 214.6618 - val_loss: 1155.6649\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 212.4445 - val_loss: 1162.9314\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 210.3632 - val_loss: 1170.0791\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 208.4107 - val_loss: 1177.1033\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 206.5807 - val_loss: 1184.0013\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 204.8668 - val_loss: 1190.7705\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 203.2628 - val_loss: 1197.4076\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 201.7627 - val_loss: 1203.9111\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 200.3611 - val_loss: 1210.2789\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 199.0524 - val_loss: 1216.5090\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 197.8314 - val_loss: 1222.5995\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 196.6933 - val_loss: 1228.5504\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 195.6331 - val_loss: 1234.3601\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 194.6464 - val_loss: 1240.0281\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 193.7288 - val_loss: 1245.5536\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 192.8761 - val_loss: 1250.9374\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 192.0845 - val_loss: 1256.1780\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 191.3501 - val_loss: 1261.2773\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 190.6693 - val_loss: 1266.2344\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 190.0389 - val_loss: 1271.0508\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 189.4555 - val_loss: 1275.7273\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 188.9160 - val_loss: 1280.2646\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 188.4176 - val_loss: 1284.6638\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 187.9576 - val_loss: 1288.9270\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 187.5333 - val_loss: 1293.0551\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 187.1424 - val_loss: 1297.0500\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 186.7824 - val_loss: 1300.9133\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 186.4511 - val_loss: 1304.6464\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 186.1467 - val_loss: 1308.2527\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 185.8670 - val_loss: 1311.7334\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 185.6104 - val_loss: 1315.0906\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 185.3751 - val_loss: 1318.3270\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 185.1596 - val_loss: 1321.4447\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 184.9623 - val_loss: 1324.4465\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 184.7818 - val_loss: 1327.3347\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 184.6169 - val_loss: 1330.1112\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 184.4663 - val_loss: 1332.7803\n",
      "Epoch 138/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 184.3289 - val_loss: 1335.3424\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 184.2037 - val_loss: 1337.8027\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 184.0897 - val_loss: 1340.1616\n",
      "Epoch 141/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.9859 - val_loss: 1342.4226\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.8915 - val_loss: 1344.5891\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.8058 - val_loss: 1346.6631\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.7279 - val_loss: 1348.6476\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.6573 - val_loss: 1350.5452\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.5933 - val_loss: 1352.3584\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.5355 - val_loss: 1354.0909\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.4831 - val_loss: 1355.7439\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.4357 - val_loss: 1357.3209\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.3929 - val_loss: 1358.8248\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.3543 - val_loss: 1360.2570\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.3196 - val_loss: 1361.6217\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.2882 - val_loss: 1362.9198\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.2600 - val_loss: 1364.1544\n",
      "Epoch 155/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 183.2347 - val_loss: 1365.3284\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.2119 - val_loss: 1366.4430\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1915 - val_loss: 1367.5018\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1732 - val_loss: 1368.5060\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1569 - val_loss: 1369.4587\n",
      "Epoch 160/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1423 - val_loss: 1370.3627\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1291 - val_loss: 1371.2178\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 183.1175 - val_loss: 1372.0270\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1072 - val_loss: 1372.7939\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0980 - val_loss: 1373.5184\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0898 - val_loss: 1374.2025\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0827 - val_loss: 1374.8497\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0763 - val_loss: 1375.4602\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0707 - val_loss: 1376.0366\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0658 - val_loss: 1376.5798\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0615 - val_loss: 1377.0918\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0578 - val_loss: 1377.5741\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0546 - val_loss: 1378.0278\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0519 - val_loss: 1378.4552\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0495 - val_loss: 1378.8564\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0475 - val_loss: 1379.2338\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0459 - val_loss: 1379.5880\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0445 - val_loss: 1379.9209\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0434 - val_loss: 1380.2330\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0425 - val_loss: 1380.5255\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0420 - val_loss: 1380.7997\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0415 - val_loss: 1381.0564\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0413 - val_loss: 1381.2971\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0412 - val_loss: 1381.5216\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0412 - val_loss: 1381.7319\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0413 - val_loss: 1381.9279\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0416 - val_loss: 1382.1115\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0420 - val_loss: 1382.2826\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0424 - val_loss: 1382.4423\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0430 - val_loss: 1382.5913\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0437 - val_loss: 1382.7300\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0443 - val_loss: 1382.8588\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0451 - val_loss: 1382.9790\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0459 - val_loss: 1383.0902\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0468 - val_loss: 1383.1932\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0477 - val_loss: 1383.2899\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 183.0486 - val_loss: 1383.3787\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0496 - val_loss: 1383.4614\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0505 - val_loss: 1383.5364\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0516 - val_loss: 1383.6044\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0527 - val_loss: 1383.6646\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0537 - val_loss: 1383.7115\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0548 - val_loss: 1382.9950\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1729 - val_loss: 1383.7651\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0571 - val_loss: 1383.8129\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0581 - val_loss: 1383.8551\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0592 - val_loss: 1383.8945\n",
      "Epoch 207/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0604 - val_loss: 1383.9302\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0615 - val_loss: 1383.9640\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0627 - val_loss: 1383.9935\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0638 - val_loss: 1384.0214\n",
      "Epoch 211/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0650 - val_loss: 1384.0466\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0662 - val_loss: 1384.0706\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0674 - val_loss: 1384.0917\n",
      "Epoch 214/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0685 - val_loss: 1384.1115\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0696 - val_loss: 1384.1285\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0708 - val_loss: 1384.1445\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0718 - val_loss: 1384.1591\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0730 - val_loss: 1384.1718\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0741 - val_loss: 1384.1831\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0752 - val_loss: 1384.1941\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0763 - val_loss: 1384.2034\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0775 - val_loss: 1384.2119\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0786 - val_loss: 1384.2189\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0796 - val_loss: 1384.2262\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0807 - val_loss: 1384.2319\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0817 - val_loss: 1384.2361\n",
      "Epoch 227/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 183.0828 - val_loss: 1384.2408\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0838 - val_loss: 1384.2443\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0848 - val_loss: 1384.2478\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0859 - val_loss: 1384.2500\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0869 - val_loss: 1384.2524\n",
      "Epoch 232/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0879 - val_loss: 1384.2539\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0889 - val_loss: 1384.2559\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0899 - val_loss: 1384.2567\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0908 - val_loss: 1384.2576\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0917 - val_loss: 1384.2581\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0927 - val_loss: 1384.2581\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0936 - val_loss: 1384.2577\n",
      "Epoch 239/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0945 - val_loss: 1384.2576\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0954 - val_loss: 1384.2568\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0963 - val_loss: 1384.2563\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0972 - val_loss: 1384.2556\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0981 - val_loss: 1384.2546\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.0989 - val_loss: 1384.2532\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.0997 - val_loss: 1384.2517\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1006 - val_loss: 1384.2511\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1014 - val_loss: 1384.2498\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1022 - val_loss: 1384.2479\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1030 - val_loss: 1384.2463\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1037 - val_loss: 1384.2446\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1045 - val_loss: 1384.2430\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1052 - val_loss: 1384.2413\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1060 - val_loss: 1384.2397\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 183.1067 - val_loss: 1384.2375\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1075 - val_loss: 1384.2361\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1082 - val_loss: 1384.2344\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1089 - val_loss: 1384.2327\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1096 - val_loss: 1384.2303\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1102 - val_loss: 1384.2289\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1108 - val_loss: 1384.2269\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1116 - val_loss: 1384.2255\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1122 - val_loss: 1384.2241\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1127 - val_loss: 1384.2219\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1134 - val_loss: 1384.2196\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1140 - val_loss: 1384.2177\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1146 - val_loss: 1384.2161\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 183.1152 - val_loss: 1384.2145\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1158 - val_loss: 1384.2126\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1163 - val_loss: 1384.2103\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1169 - val_loss: 1384.2089\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 183.1175 - val_loss: 1384.2074\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1180 - val_loss: 1384.2052\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1185 - val_loss: 1384.2034\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1190 - val_loss: 1384.2018\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1196 - val_loss: 1384.1997\n",
      "Epoch 276/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1201 - val_loss: 1384.1985\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1205 - val_loss: 1384.1974\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1210 - val_loss: 1384.1958\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1214 - val_loss: 1384.1941\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1219 - val_loss: 1384.1921\n",
      "Epoch 281/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1224 - val_loss: 1384.1907\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1228 - val_loss: 1384.1892\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 183.1233 - val_loss: 1384.1875\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1237 - val_loss: 1384.1862\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1241 - val_loss: 1384.1841\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 183.1245 - val_loss: 1384.1829\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 183.1249 - val_loss: 1384.1813\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1254 - val_loss: 1384.1798\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1257 - val_loss: 1384.1788\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1261 - val_loss: 1384.1772\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1265 - val_loss: 1384.1754\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1269 - val_loss: 1384.1746\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1272 - val_loss: 1384.1736\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1276 - val_loss: 1384.1722\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 183.1279 - val_loss: 1384.1709\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1283 - val_loss: 1384.1704\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1286 - val_loss: 1384.1691\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1289 - val_loss: 1384.1678\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1292 - val_loss: 1384.1661\n",
      "Epoch 300/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1296 - val_loss: 1384.1658\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 183.1299 - val_loss: 1384.1649\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 183.1302 - val_loss: 1384.1639\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1305 - val_loss: 1384.1631\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1308 - val_loss: 1384.1620\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1310 - val_loss: 1384.1609\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1313 - val_loss: 1384.1598\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1316 - val_loss: 1384.1587\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1319 - val_loss: 1384.1577\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1321 - val_loss: 1384.1566\n",
      "Epoch 310/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 183.1324 - val_loss: 1384.1553\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1327 - val_loss: 1384.1549\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1329 - val_loss: 1384.1545\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1331 - val_loss: 1384.1537\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1334 - val_loss: 1384.1528\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1336 - val_loss: 1384.1523\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1338 - val_loss: 1384.1512\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1341 - val_loss: 1384.1504\n",
      "Epoch 318/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1343 - val_loss: 1384.1498\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1345 - val_loss: 1384.1494\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1347 - val_loss: 1384.1487\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1350 - val_loss: 1384.1476\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1352 - val_loss: 1384.1465\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1353 - val_loss: 1384.1459\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 183.1355 - val_loss: 1384.1453\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1357 - val_loss: 1384.1447\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1358 - val_loss: 1384.1436\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1360 - val_loss: 1384.1429\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1363 - val_loss: 1384.1423\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1364 - val_loss: 1384.1416\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1366 - val_loss: 1384.1412\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1368 - val_loss: 1384.1409\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 183.1369 - val_loss: 1384.1405\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 183.1371 - val_loss: 1384.1400\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 183.1372 - val_loss: 1384.1394\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1374 - val_loss: 1384.1384\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1375 - val_loss: 1384.1377\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1377 - val_loss: 1384.1371\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1378 - val_loss: 1384.1370\n",
      "Epoch 339/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1380 - val_loss: 1384.1364\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1381 - val_loss: 1384.1360\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1382 - val_loss: 1384.1353\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1384 - val_loss: 1384.1346\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1385 - val_loss: 1384.1346\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1386 - val_loss: 1384.1342\n",
      "Epoch 345/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1387 - val_loss: 1384.1335\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1389 - val_loss: 1384.1331\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1390 - val_loss: 1384.1326\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1391 - val_loss: 1384.1326\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1393 - val_loss: 1384.1322\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1393 - val_loss: 1384.1318\n",
      "Epoch 351/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1394 - val_loss: 1384.1315\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1396 - val_loss: 1384.1311\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1396 - val_loss: 1384.1307\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1397 - val_loss: 1384.1301\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1398 - val_loss: 1384.1290\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1400 - val_loss: 1384.1287\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1401 - val_loss: 1384.1287\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 183.1402 - val_loss: 1384.1282\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 183.1403 - val_loss: 1384.1279\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1404 - val_loss: 1384.1274\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1404 - val_loss: 1384.1274\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1405 - val_loss: 1384.1272\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1406 - val_loss: 1384.1267\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1406 - val_loss: 1384.1263\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1407 - val_loss: 1384.1256\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1409 - val_loss: 1384.1254\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1409 - val_loss: 1384.1256\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1411 - val_loss: 1384.1255\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1411 - val_loss: 1384.1252\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1412 - val_loss: 1384.1250\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1413 - val_loss: 1384.1248\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1413 - val_loss: 1384.1244\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1414 - val_loss: 1384.1240\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1415 - val_loss: 1384.1243\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1415 - val_loss: 1384.1235\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1416 - val_loss: 1384.1234\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1416 - val_loss: 1384.1233\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1417 - val_loss: 1384.1233\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1418 - val_loss: 1384.1234\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1418 - val_loss: 1384.1233\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1419 - val_loss: 1384.1233\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 183.1419 - val_loss: 1384.1232\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1420 - val_loss: 1384.1229\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1420 - val_loss: 1384.1226\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1421 - val_loss: 1384.1224\n",
      "Epoch 386/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1421 - val_loss: 1384.1222\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1422 - val_loss: 1384.1218\n",
      "Epoch 388/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1422 - val_loss: 1384.1215\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1423 - val_loss: 1384.1213\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1423 - val_loss: 1384.1215\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1423 - val_loss: 1384.1213\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1424 - val_loss: 1384.1213\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1424 - val_loss: 1384.1215\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1424 - val_loss: 1384.1213\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1425 - val_loss: 1384.1206\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1425 - val_loss: 1384.1196\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1426 - val_loss: 1384.1202\n",
      "Epoch 398/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1427 - val_loss: 1384.1200\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1427 - val_loss: 1384.1200\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1427 - val_loss: 1384.1200\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 183.1428 - val_loss: 1384.1200\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1428 - val_loss: 1384.1200\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1428 - val_loss: 1384.1198\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 183.1429 - val_loss: 1384.1196\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 183.1429 - val_loss: 1384.1196\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1430 - val_loss: 1384.1196\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1430 - val_loss: 1384.1198\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1430 - val_loss: 1384.1198\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1431 - val_loss: 1384.1198\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1431 - val_loss: 1384.1199\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1431 - val_loss: 1384.1199\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1431 - val_loss: 1384.1195\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1431 - val_loss: 1384.1191\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1432 - val_loss: 1384.1189\n",
      "Epoch 415/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1432 - val_loss: 1384.1190\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1432 - val_loss: 1384.1195\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1432 - val_loss: 1384.1196\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1432 - val_loss: 1384.1195\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1432 - val_loss: 1384.1193\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1433 - val_loss: 1384.1189\n",
      "Epoch 421/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1433 - val_loss: 1384.1190\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 183.1434 - val_loss: 1384.1190\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1434 - val_loss: 1384.1193\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1434 - val_loss: 1384.1189\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1434 - val_loss: 1384.1191\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1435 - val_loss: 1384.1188\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1435 - val_loss: 1384.1180\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1435 - val_loss: 1384.1182\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1436 - val_loss: 1384.1183\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 183.1436 - val_loss: 1384.1185\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1436 - val_loss: 1384.1193\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1437 - val_loss: 1384.1202\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1436 - val_loss: 1384.1210\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1436 - val_loss: 1384.1218\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1436 - val_loss: 1384.1224\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1436 - val_loss: 1384.1237\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1436 - val_loss: 1384.1244\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1437 - val_loss: 1384.1252\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1437 - val_loss: 1384.1260\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1437 - val_loss: 1384.1271\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1437 - val_loss: 1384.1279\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1437 - val_loss: 1384.1296\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1437 - val_loss: 1384.0945\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1310 - val_loss: 1379.0798\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 184.3369 - val_loss: 1384.2594\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1446 - val_loss: 1384.2648\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1427 - val_loss: 1384.2502\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1426 - val_loss: 1384.2344\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1428 - val_loss: 1384.2196\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1429 - val_loss: 1384.2068\n",
      "Epoch 451/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1429 - val_loss: 1384.1951\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1431 - val_loss: 1384.1847\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1432 - val_loss: 1384.1758\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 183.1432 - val_loss: 1384.1667\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1433 - val_loss: 1384.1583\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1434 - val_loss: 1384.1519\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1435 - val_loss: 1384.1453\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1436 - val_loss: 1384.1401\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1436 - val_loss: 1384.1356\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1436 - val_loss: 1384.1307\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1436 - val_loss: 1384.1266\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1437 - val_loss: 1384.1222\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1438 - val_loss: 1384.1185\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1438 - val_loss: 1384.1155\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1438 - val_loss: 1384.1129\n",
      "Epoch 466/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1438 - val_loss: 1384.1100\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1439 - val_loss: 1384.1080\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1439 - val_loss: 1384.1060\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1440 - val_loss: 1384.1044\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1440 - val_loss: 1384.1027\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1440 - val_loss: 1384.1010\n",
      "Epoch 472/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1440 - val_loss: 1384.1002\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1440 - val_loss: 1384.0986\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1440 - val_loss: 1384.0969\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1440 - val_loss: 1384.0955\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 183.1440 - val_loss: 1384.0941\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1440 - val_loss: 1384.0931\n",
      "Epoch 478/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1441 - val_loss: 1384.0920\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1441 - val_loss: 1384.0912\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1441 - val_loss: 1384.0901\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1441 - val_loss: 1384.0892\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 183.1441 - val_loss: 1384.0884\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1441 - val_loss: 1384.0873\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1441 - val_loss: 1384.0859\n",
      "Epoch 485/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1442 - val_loss: 1384.0852\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1442 - val_loss: 1384.0848\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1442 - val_loss: 1384.0847\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1442 - val_loss: 1384.0845\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 183.1441 - val_loss: 1384.0840\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1441 - val_loss: 1384.0837\n",
      "Epoch 491/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1441 - val_loss: 1384.0835\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1441 - val_loss: 1384.0831\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1441 - val_loss: 1384.0828\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1441 - val_loss: 1384.0828\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1442 - val_loss: 1384.0823\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1442 - val_loss: 1384.0823\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 183.1442 - val_loss: 1384.0822\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1442 - val_loss: 1384.0822\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1442 - val_loss: 1384.0826\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 183.1443 - val_loss: 1384.0828\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 371ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.85562092e+01, 5.81630019e+01, 5.80369514e+01, 5.79159210e+01,\n",
       "        5.77958965e+01, 0.00000000e+00, 1.14280570e+00, 4.29714561e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.94712418e+01, 5.89670402e+01, 5.84628385e+01,\n",
       "        0.00000000e+00, 2.19980810e-01, 6.08063259e+01, 6.01808590e+01,\n",
       "        5.96766573e+01, 5.91724557e+01, 5.86682540e+01, 5.81910131e+01,\n",
       "        5.80649626e+01, 5.79389122e+01, 5.78128618e+01, 0.00000000e+00,\n",
       "        1.39091580e-01, 5.88736695e+01, 5.83694678e+01, 5.81163165e+01,\n",
       "        5.79902661e+01, 5.78642157e+01, 5.77381653e+01, 5.76121148e+01,\n",
       "        5.74860644e+01, 5.73600140e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.48315100e-01, 0.00000000e+00, 3.80809220e-01, 6.57674010e-01,\n",
       "        4.16481970e-01, 2.44659450e-01, 0.00000000e+00, 5.79669234e+01,\n",
       "        5.78408730e+01, 7.16493960e-01, 6.86268800e-02, 5.89857143e+01,\n",
       "        5.84815126e+01, 5.81863477e+01, 5.79818277e+01, 5.78922269e+01,\n",
       "        5.77661765e+01, 5.76401260e+01, 5.75154076e+01, 5.73870252e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.79435808e+01, 5.78175303e+01,\n",
       "        5.76914799e+01, 5.75654295e+01, 5.74393791e+01, 6.29306256e+01,\n",
       "        6.15299487e+01, 5.97513539e+01, 0.00000000e+00, 1.97836610e-02,\n",
       "        4.12894547e-01, 5.67768288e+01, 8.75653630e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.97576737e-01, 6.01354837e-01, 1.08075157e-01,\n",
       "        5.27414246e+01, 3.22935939e-01, 0.00000000e+00, 8.28673601e-01,\n",
       "        8.27921271e-01, 8.09421003e-01, 0.00000000e+00, 2.18132302e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.39829469e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.00952375e-01, 7.60488570e-01, 0.00000000e+00, 1.26473919e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48.63349047, 48.62365239, 48.61381431, 48.60397622, 48.59413814,\n",
       "       48.58430006, 48.57446198, 48.5646239 , 48.55478582, 48.54494774,\n",
       "       48.53510965, 48.52527157, 48.51543349, 48.50559541, 48.49575733,\n",
       "       48.48591925, 48.47608116, 48.46624308, 48.456405  , 48.44656692,\n",
       "       48.43672884, 48.42689076, 48.41705267, 48.40721459, 48.39737651,\n",
       "       48.38753843, 48.37770035, 48.36786227, 48.35802419, 48.3481861 ,\n",
       "       48.33834802, 48.32850994, 48.31867186, 48.30883378, 48.2989957 ,\n",
       "       48.28915761, 48.27931953, 48.26948145, 48.25964337, 48.24980529,\n",
       "       48.23996721, 48.23012912, 48.22029104, 48.21045296, 48.20061488,\n",
       "       48.1907768 , 48.18093872, 48.17110064, 48.16126255, 48.15142447,\n",
       "       48.14158639, 48.13174831, 48.12191023, 48.11207215, 48.10223406,\n",
       "       48.09239598, 48.0825579 , 48.07271982, 48.06288174, 48.05304366,\n",
       "       48.04320557, 48.03336749, 48.02352941, 48.01369133, 48.00385325,\n",
       "       47.99401517, 47.98417709, 47.974339  , 47.96450092, 47.95466284,\n",
       "       47.94482476, 47.93498668, 47.9251486 , 47.91531051, 47.90547243,\n",
       "       47.89563435, 47.88579627, 47.87595819, 47.86612011, 47.85628203,\n",
       "       47.84644394, 47.83660586, 47.82676778, 47.8169297 , 47.80709162,\n",
       "       47.79725354, 47.78741545, 47.77757737, 47.76773929, 47.75790121,\n",
       "       47.74806313, 47.73822505, 47.72838696, 47.71854888, 47.7087108 ,\n",
       "       47.69887272, 47.68903464, 47.67919656, 47.66935848, 47.65952039])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.51450958044528\n",
      "30.06791705189252\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
