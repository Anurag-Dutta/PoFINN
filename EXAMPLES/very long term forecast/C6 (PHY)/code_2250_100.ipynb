{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2345    46.715065\n",
       "2346    46.705226\n",
       "2347    46.695388\n",
       "2348    46.685550\n",
       "2349    46.675712\n",
       "Name: C6, Length: 2350, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_2250_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2245     0.000000\n",
       "2246     0.300952\n",
       "2247     0.760489\n",
       "2248     0.000000\n",
       "2249     0.126474\n",
       "Name: C6, Length: 2250, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2250)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 1, 251) (1800, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "23/23 [==============================] - 4s 33ms/step - loss: 3697.3125 - val_loss: 1892.0702\n",
      "Epoch 2/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 3444.4507 - val_loss: 1795.6743\n",
      "Epoch 3/500\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 3309.0566 - val_loss: 1727.6858\n",
      "Epoch 4/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 3195.8176 - val_loss: 1672.1450\n",
      "Epoch 5/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 3092.4575 - val_loss: 1618.7505\n",
      "Epoch 6/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 3000.3882 - val_loss: 1572.7871\n",
      "Epoch 7/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 2914.6531 - val_loss: 1529.0266\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 2831.0112 - val_loss: 1481.3728\n",
      "Epoch 9/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 2736.2456 - val_loss: 1440.1200\n",
      "Epoch 10/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 2655.5569 - val_loss: 1401.4399\n",
      "Epoch 11/500\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 2578.0237 - val_loss: 1364.7369\n",
      "Epoch 12/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 2503.1694 - val_loss: 1329.7922\n",
      "Epoch 13/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 2430.6594 - val_loss: 1296.1592\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 2360.1729 - val_loss: 1261.8162\n",
      "Epoch 15/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 2279.3040 - val_loss: 1227.1140\n",
      "Epoch 16/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2207.8679 - val_loss: 1196.6698\n",
      "Epoch 17/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2139.8716 - val_loss: 1168.0337\n",
      "Epoch 18/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2074.4138 - val_loss: 1141.0089\n",
      "Epoch 19/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2011.1488 - val_loss: 1115.4608\n",
      "Epoch 20/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1949.8750 - val_loss: 1091.3031\n",
      "Epoch 21/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1890.4128 - val_loss: 1068.4689\n",
      "Epoch 22/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1833.3763 - val_loss: 1046.0685\n",
      "Epoch 23/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1772.6998 - val_loss: 1024.2004\n",
      "Epoch 24/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1714.6654 - val_loss: 1003.9918\n",
      "Epoch 25/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1658.9498 - val_loss: 984.3071\n",
      "Epoch 26/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1601.3944 - val_loss: 965.4422\n",
      "Epoch 27/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1545.0920 - val_loss: 948.0823\n",
      "Epoch 28/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1491.7302 - val_loss: 932.2955\n",
      "Epoch 29/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1440.8351 - val_loss: 917.8853\n",
      "Epoch 30/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1392.0427 - val_loss: 904.7307\n",
      "Epoch 31/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1345.1366 - val_loss: 892.7465\n",
      "Epoch 32/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1299.9736 - val_loss: 881.8666\n",
      "Epoch 33/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1256.4470 - val_loss: 872.0366\n",
      "Epoch 34/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1214.4727 - val_loss: 863.2078\n",
      "Epoch 35/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1173.9805 - val_loss: 855.3373\n",
      "Epoch 36/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1134.9098 - val_loss: 848.3857\n",
      "Epoch 37/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1097.2075 - val_loss: 842.3158\n",
      "Epoch 38/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1060.8250 - val_loss: 837.0929\n",
      "Epoch 39/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1025.7186 - val_loss: 832.6836\n",
      "Epoch 40/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 991.8464 - val_loss: 829.0563\n",
      "Epoch 41/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 959.1709 - val_loss: 826.1805\n",
      "Epoch 42/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 927.6548 - val_loss: 824.0267\n",
      "Epoch 43/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 897.2642 - val_loss: 822.5660\n",
      "Epoch 44/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 867.9656 - val_loss: 821.7709\n",
      "Epoch 45/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 839.7277 - val_loss: 821.6143\n",
      "Epoch 46/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 812.5197 - val_loss: 822.0696\n",
      "Epoch 47/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 786.3121 - val_loss: 823.1112\n",
      "Epoch 48/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 761.0763 - val_loss: 824.7138\n",
      "Epoch 49/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 736.7845 - val_loss: 826.8527\n",
      "Epoch 50/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 713.4096 - val_loss: 829.5037\n",
      "Epoch 51/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 690.9254 - val_loss: 832.6433\n",
      "Epoch 52/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 669.3062 - val_loss: 836.2480\n",
      "Epoch 53/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 648.5269 - val_loss: 840.2952\n",
      "Epoch 54/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 628.5630 - val_loss: 844.7627\n",
      "Epoch 55/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 609.3904 - val_loss: 849.6284\n",
      "Epoch 56/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 590.9858 - val_loss: 854.8709\n",
      "Epoch 57/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 573.3264 - val_loss: 860.4693\n",
      "Epoch 58/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 556.3892 - val_loss: 866.4030\n",
      "Epoch 59/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 540.1524 - val_loss: 872.6515\n",
      "Epoch 60/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 524.5945 - val_loss: 879.1954\n",
      "Epoch 61/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 509.6942 - val_loss: 886.0151\n",
      "Epoch 62/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 495.4306 - val_loss: 893.0919\n",
      "Epoch 63/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 481.7835 - val_loss: 900.4069\n",
      "Epoch 64/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 468.7327 - val_loss: 907.9421\n",
      "Epoch 65/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 456.2582 - val_loss: 915.6830\n",
      "Epoch 66/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 444.3387 - val_loss: 923.6537\n",
      "Epoch 67/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 432.9386 - val_loss: 931.8316\n",
      "Epoch 68/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 422.0840 - val_loss: 940.0162\n",
      "Epoch 69/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 411.7173 - val_loss: 948.4742\n",
      "Epoch 70/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 401.8470 - val_loss: 956.8661\n",
      "Epoch 71/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 392.4497 - val_loss: 965.4604\n",
      "Epoch 72/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 383.5117 - val_loss: 973.9427\n",
      "Epoch 73/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 374.9798 - val_loss: 982.6703\n",
      "Epoch 74/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 366.8452 - val_loss: 992.0026\n",
      "Epoch 75/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 358.2521 - val_loss: 1003.1766\n",
      "Epoch 76/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 349.6478 - val_loss: 1013.1812\n",
      "Epoch 77/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 342.0535 - val_loss: 1023.1192\n",
      "Epoch 78/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 334.9636 - val_loss: 1032.9600\n",
      "Epoch 79/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 328.3446 - val_loss: 1042.7092\n",
      "Epoch 80/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 322.1553 - val_loss: 1052.3691\n",
      "Epoch 81/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 316.3616 - val_loss: 1061.9388\n",
      "Epoch 82/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 310.9348 - val_loss: 1071.4154\n",
      "Epoch 83/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 305.8505 - val_loss: 1080.7938\n",
      "Epoch 84/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 301.0868 - val_loss: 1090.0684\n",
      "Epoch 85/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 296.6241 - val_loss: 1099.2341\n",
      "Epoch 86/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 292.4443 - val_loss: 1108.2844\n",
      "Epoch 87/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 288.5307 - val_loss: 1117.2142\n",
      "Epoch 88/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 284.8678 - val_loss: 1126.0170\n",
      "Epoch 89/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 281.4411 - val_loss: 1134.6886\n",
      "Epoch 90/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 278.2370 - val_loss: 1143.2231\n",
      "Epoch 91/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 275.2425 - val_loss: 1151.6158\n",
      "Epoch 92/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 272.4457 - val_loss: 1159.8628\n",
      "Epoch 93/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.8348 - val_loss: 1167.9592\n",
      "Epoch 94/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 267.3993 - val_loss: 1175.9021\n",
      "Epoch 95/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 265.1286 - val_loss: 1183.6874\n",
      "Epoch 96/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 263.0132 - val_loss: 1191.3124\n",
      "Epoch 97/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 261.0435 - val_loss: 1198.7744\n",
      "Epoch 98/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 259.2111 - val_loss: 1206.0719\n",
      "Epoch 99/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 257.5071 - val_loss: 1213.2012\n",
      "Epoch 100/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 255.9241 - val_loss: 1220.1628\n",
      "Epoch 101/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 254.4544 - val_loss: 1226.9542\n",
      "Epoch 102/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 253.0909 - val_loss: 1233.5750\n",
      "Epoch 103/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 251.8268 - val_loss: 1240.0239\n",
      "Epoch 104/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 250.6558 - val_loss: 1246.3018\n",
      "Epoch 105/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 249.5718 - val_loss: 1252.4082\n",
      "Epoch 106/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 248.5691 - val_loss: 1258.3427\n",
      "Epoch 107/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 247.6424 - val_loss: 1264.1066\n",
      "Epoch 108/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 246.7864 - val_loss: 1269.7012\n",
      "Epoch 109/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 245.9965 - val_loss: 1275.1257\n",
      "Epoch 110/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 245.2680 - val_loss: 1280.3832\n",
      "Epoch 111/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 244.5968 - val_loss: 1285.4751\n",
      "Epoch 112/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 243.9787 - val_loss: 1290.4025\n",
      "Epoch 113/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 243.4100 - val_loss: 1295.1667\n",
      "Epoch 114/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 242.8871 - val_loss: 1299.7715\n",
      "Epoch 115/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 242.4068 - val_loss: 1304.2174\n",
      "Epoch 116/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 241.9660 - val_loss: 1308.5084\n",
      "Epoch 117/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 241.5615 - val_loss: 1312.6456\n",
      "Epoch 118/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 241.1908 - val_loss: 1316.6327\n",
      "Epoch 119/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 240.8512 - val_loss: 1320.4713\n",
      "Epoch 120/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 240.5405 - val_loss: 1324.1652\n",
      "Epoch 121/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 240.2563 - val_loss: 1327.7155\n",
      "Epoch 122/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 239.9965 - val_loss: 1331.1265\n",
      "Epoch 123/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 239.7594 - val_loss: 1334.4009\n",
      "Epoch 124/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 239.5429 - val_loss: 1337.5404\n",
      "Epoch 125/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 239.3454 - val_loss: 1340.5480\n",
      "Epoch 126/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 239.1655 - val_loss: 1343.4240\n",
      "Epoch 127/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 239.0017 - val_loss: 1346.1714\n",
      "Epoch 128/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 238.8526 - val_loss: 1348.7883\n",
      "Epoch 129/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 238.7170 - val_loss: 1351.2716\n",
      "Epoch 130/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 238.5937 - val_loss: 1353.6110\n",
      "Epoch 131/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 238.4818 - val_loss: 1355.7842\n",
      "Epoch 132/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 238.3802 - val_loss: 1357.7316\n",
      "Epoch 133/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 238.2880 - val_loss: 1359.3549\n",
      "Epoch 134/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 236.8918 - val_loss: 1314.1648\n",
      "Epoch 135/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 241.2529 - val_loss: 1316.2682\n",
      "Epoch 136/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 240.9842 - val_loss: 1320.5386\n",
      "Epoch 137/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 240.6392 - val_loss: 1324.6974\n",
      "Epoch 138/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 240.3181 - val_loss: 1328.6779\n",
      "Epoch 139/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 240.0274 - val_loss: 1332.4786\n",
      "Epoch 140/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 239.7651 - val_loss: 1336.1044\n",
      "Epoch 141/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 239.5287 - val_loss: 1339.5618\n",
      "Epoch 142/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 239.3156 - val_loss: 1342.8553\n",
      "Epoch 143/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 239.1238 - val_loss: 1345.9915\n",
      "Epoch 144/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 238.9512 - val_loss: 1348.9755\n",
      "Epoch 145/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 238.7959 - val_loss: 1351.8130\n",
      "Epoch 146/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 238.6562 - val_loss: 1354.5098\n",
      "Epoch 147/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 238.5309 - val_loss: 1357.0709\n",
      "Epoch 148/500\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 238.4182 - val_loss: 1359.5016\n",
      "Epoch 149/500\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 238.3171 - val_loss: 1361.8073\n",
      "Epoch 150/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 238.2263 - val_loss: 1363.9926\n",
      "Epoch 151/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 238.1449 - val_loss: 1366.0635\n",
      "Epoch 152/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 238.0719 - val_loss: 1368.0244\n",
      "Epoch 153/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 238.0065 - val_loss: 1369.8800\n",
      "Epoch 154/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.9479 - val_loss: 1371.6350\n",
      "Epoch 155/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.8955 - val_loss: 1373.2937\n",
      "Epoch 156/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.8485 - val_loss: 1374.8607\n",
      "Epoch 157/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.8064 - val_loss: 1376.3406\n",
      "Epoch 158/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.7688 - val_loss: 1377.7369\n",
      "Epoch 159/500\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 237.7352 - val_loss: 1379.0540\n",
      "Epoch 160/500\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 237.7051 - val_loss: 1380.2952\n",
      "Epoch 161/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.6783 - val_loss: 1381.4646\n",
      "Epoch 162/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 237.6543 - val_loss: 1382.5658\n",
      "Epoch 163/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.6329 - val_loss: 1383.6024\n",
      "Epoch 164/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.6138 - val_loss: 1384.5769\n",
      "Epoch 165/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5968 - val_loss: 1385.4939\n",
      "Epoch 166/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5816 - val_loss: 1386.3550\n",
      "Epoch 167/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5681 - val_loss: 1387.1641\n",
      "Epoch 168/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5560 - val_loss: 1387.9231\n",
      "Epoch 169/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5453 - val_loss: 1388.6353\n",
      "Epoch 170/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5358 - val_loss: 1389.3042\n",
      "Epoch 171/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5273 - val_loss: 1389.9302\n",
      "Epoch 172/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5198 - val_loss: 1390.5170\n",
      "Epoch 173/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5132 - val_loss: 1391.0663\n",
      "Epoch 174/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5074 - val_loss: 1391.5804\n",
      "Epoch 175/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5022 - val_loss: 1392.0621\n",
      "Epoch 176/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.4976 - val_loss: 1392.5118\n",
      "Epoch 177/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.4936 - val_loss: 1392.9319\n",
      "Epoch 178/500\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 237.4901 - val_loss: 1393.3253\n",
      "Epoch 179/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.4871 - val_loss: 1393.6915\n",
      "Epoch 180/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.4846 - val_loss: 1394.0341\n",
      "Epoch 181/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.4823 - val_loss: 1394.3536\n",
      "Epoch 182/500\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 237.4803 - val_loss: 1394.6516\n",
      "Epoch 183/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.4787 - val_loss: 1394.9290\n",
      "Epoch 184/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4773 - val_loss: 1395.1875\n",
      "Epoch 185/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4762 - val_loss: 1395.4287\n",
      "Epoch 186/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4753 - val_loss: 1395.6527\n",
      "Epoch 187/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4745 - val_loss: 1395.8615\n",
      "Epoch 188/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4740 - val_loss: 1396.0558\n",
      "Epoch 189/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4736 - val_loss: 1396.2356\n",
      "Epoch 190/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.4734 - val_loss: 1396.4033\n",
      "Epoch 191/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4732 - val_loss: 1396.5582\n",
      "Epoch 192/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.4732 - val_loss: 1396.7030\n",
      "Epoch 193/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.4733 - val_loss: 1396.8361\n",
      "Epoch 194/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4735 - val_loss: 1396.9609\n",
      "Epoch 195/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4738 - val_loss: 1397.0756\n",
      "Epoch 196/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4742 - val_loss: 1397.1825\n",
      "Epoch 197/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.4746 - val_loss: 1397.2816\n",
      "Epoch 198/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.4750 - val_loss: 1397.3723\n",
      "Epoch 199/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.4756 - val_loss: 1397.4576\n",
      "Epoch 200/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.4762 - val_loss: 1397.5349\n",
      "Epoch 201/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.4768 - val_loss: 1397.6073\n",
      "Epoch 202/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.4775 - val_loss: 1397.6741\n",
      "Epoch 203/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4782 - val_loss: 1397.7357\n",
      "Epoch 204/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4789 - val_loss: 1397.7925\n",
      "Epoch 205/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4796 - val_loss: 1397.8451\n",
      "Epoch 206/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.4805 - val_loss: 1397.8934\n",
      "Epoch 207/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4812 - val_loss: 1397.9377\n",
      "Epoch 208/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4821 - val_loss: 1397.9790\n",
      "Epoch 209/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4828 - val_loss: 1398.0164\n",
      "Epoch 210/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4837 - val_loss: 1398.0511\n",
      "Epoch 211/500\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 237.4845 - val_loss: 1398.0828\n",
      "Epoch 212/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4854 - val_loss: 1398.1123\n",
      "Epoch 213/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4863 - val_loss: 1398.1390\n",
      "Epoch 214/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 237.4871 - val_loss: 1398.1636\n",
      "Epoch 215/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4880 - val_loss: 1398.1857\n",
      "Epoch 216/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4889 - val_loss: 1398.2064\n",
      "Epoch 217/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4897 - val_loss: 1398.2252\n",
      "Epoch 218/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4906 - val_loss: 1398.2426\n",
      "Epoch 219/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4915 - val_loss: 1398.2577\n",
      "Epoch 220/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4924 - val_loss: 1398.2721\n",
      "Epoch 221/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4932 - val_loss: 1398.2848\n",
      "Epoch 222/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4941 - val_loss: 1398.2970\n",
      "Epoch 223/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4949 - val_loss: 1398.3073\n",
      "Epoch 224/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.4957 - val_loss: 1398.3169\n",
      "Epoch 225/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4966 - val_loss: 1398.3256\n",
      "Epoch 226/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4974 - val_loss: 1398.3335\n",
      "Epoch 227/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4982 - val_loss: 1398.3406\n",
      "Epoch 228/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4990 - val_loss: 1398.3470\n",
      "Epoch 229/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4998 - val_loss: 1398.3521\n",
      "Epoch 230/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5007 - val_loss: 1398.3573\n",
      "Epoch 231/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5014 - val_loss: 1398.3618\n",
      "Epoch 232/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5022 - val_loss: 1398.3657\n",
      "Epoch 233/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5029 - val_loss: 1398.3688\n",
      "Epoch 234/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5037 - val_loss: 1398.3717\n",
      "Epoch 235/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5045 - val_loss: 1398.3739\n",
      "Epoch 236/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5052 - val_loss: 1398.3766\n",
      "Epoch 237/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 237.5059 - val_loss: 1398.3772\n",
      "Epoch 238/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5066 - val_loss: 1398.3782\n",
      "Epoch 239/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5073 - val_loss: 1398.3770\n",
      "Epoch 240/500\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 237.5080 - val_loss: 1398.2750\n",
      "Epoch 241/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5057 - val_loss: 1398.4514\n",
      "Epoch 242/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5094 - val_loss: 1398.4524\n",
      "Epoch 243/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5100 - val_loss: 1398.4526\n",
      "Epoch 244/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5107 - val_loss: 1398.4536\n",
      "Epoch 245/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5113 - val_loss: 1398.4540\n",
      "Epoch 246/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 237.5119 - val_loss: 1398.4540\n",
      "Epoch 247/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5125 - val_loss: 1398.4542\n",
      "Epoch 248/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5132 - val_loss: 1398.4542\n",
      "Epoch 249/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5138 - val_loss: 1398.4542\n",
      "Epoch 250/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5143 - val_loss: 1398.4542\n",
      "Epoch 251/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5150 - val_loss: 1398.4539\n",
      "Epoch 252/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5155 - val_loss: 1398.4536\n",
      "Epoch 253/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5160 - val_loss: 1398.4532\n",
      "Epoch 254/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5166 - val_loss: 1398.4530\n",
      "Epoch 255/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5171 - val_loss: 1398.4526\n",
      "Epoch 256/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5176 - val_loss: 1398.4518\n",
      "Epoch 257/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5181 - val_loss: 1398.4509\n",
      "Epoch 258/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5186 - val_loss: 1398.4502\n",
      "Epoch 259/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5191 - val_loss: 1398.4497\n",
      "Epoch 260/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5196 - val_loss: 1398.4487\n",
      "Epoch 261/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5201 - val_loss: 1398.4481\n",
      "Epoch 262/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5206 - val_loss: 1398.4467\n",
      "Epoch 263/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5210 - val_loss: 1398.4458\n",
      "Epoch 264/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5215 - val_loss: 1398.4452\n",
      "Epoch 265/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 237.5219 - val_loss: 1398.4442\n",
      "Epoch 266/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5223 - val_loss: 1398.4431\n",
      "Epoch 267/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 237.5228 - val_loss: 1398.4427\n",
      "Epoch 268/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5232 - val_loss: 1398.4421\n",
      "Epoch 269/500\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 237.5236 - val_loss: 1398.4409\n",
      "Epoch 270/500\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 237.5240 - val_loss: 1398.4402\n",
      "Epoch 271/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 237.5244 - val_loss: 1398.4395\n",
      "Epoch 272/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 237.5248 - val_loss: 1398.4388\n",
      "Epoch 273/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 237.5251 - val_loss: 1398.4376\n",
      "Epoch 274/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5255 - val_loss: 1398.4364\n",
      "Epoch 275/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5258 - val_loss: 1398.4358\n",
      "Epoch 276/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5262 - val_loss: 1398.4349\n",
      "Epoch 277/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5266 - val_loss: 1398.4341\n",
      "Epoch 278/500\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 237.5269 - val_loss: 1398.4326\n",
      "Epoch 279/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 237.5272 - val_loss: 1398.4318\n",
      "Epoch 280/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5276 - val_loss: 1398.4308\n",
      "Epoch 281/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5278 - val_loss: 1398.4302\n",
      "Epoch 282/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5282 - val_loss: 1398.4296\n",
      "Epoch 283/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5285 - val_loss: 1398.4279\n",
      "Epoch 284/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5288 - val_loss: 1398.4271\n",
      "Epoch 285/500\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 237.5291 - val_loss: 1398.4260\n",
      "Epoch 286/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 237.5294 - val_loss: 1398.4257\n",
      "Epoch 287/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5296 - val_loss: 1398.4248\n",
      "Epoch 288/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 237.5299 - val_loss: 1398.4240\n",
      "Epoch 289/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5302 - val_loss: 1398.4230\n",
      "Epoch 290/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5305 - val_loss: 1398.4220\n",
      "Epoch 291/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5307 - val_loss: 1398.4207\n",
      "Epoch 292/500\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 237.5310 - val_loss: 1398.4199\n",
      "Epoch 293/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5312 - val_loss: 1398.4194\n",
      "Epoch 294/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5314 - val_loss: 1398.4191\n",
      "Epoch 295/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5317 - val_loss: 1398.4181\n",
      "Epoch 296/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5319 - val_loss: 1398.4174\n",
      "Epoch 297/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5321 - val_loss: 1398.4160\n",
      "Epoch 298/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5323 - val_loss: 1398.4149\n",
      "Epoch 299/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 237.5326 - val_loss: 1398.4135\n",
      "Epoch 300/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 237.5328 - val_loss: 1398.4116\n",
      "Epoch 301/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5330 - val_loss: 1398.3754\n",
      "Epoch 302/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4948 - val_loss: 1397.5659\n",
      "Epoch 303/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.6462 - val_loss: 1397.9929\n",
      "Epoch 304/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5907 - val_loss: 1398.0710\n",
      "Epoch 305/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5784 - val_loss: 1398.1123\n",
      "Epoch 306/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5723 - val_loss: 1398.1433\n",
      "Epoch 307/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5683 - val_loss: 1398.1688\n",
      "Epoch 308/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5656 - val_loss: 1398.1897\n",
      "Epoch 309/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5634 - val_loss: 1398.2078\n",
      "Epoch 310/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5618 - val_loss: 1398.2236\n",
      "Epoch 311/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5604 - val_loss: 1398.2378\n",
      "Epoch 312/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5592 - val_loss: 1398.2500\n",
      "Epoch 313/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5583 - val_loss: 1398.2607\n",
      "Epoch 314/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5575 - val_loss: 1398.2700\n",
      "Epoch 315/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5569 - val_loss: 1398.2793\n",
      "Epoch 316/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5563 - val_loss: 1398.2869\n",
      "Epoch 317/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5558 - val_loss: 1398.2935\n",
      "Epoch 318/500\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 237.5554 - val_loss: 1398.3000\n",
      "Epoch 319/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 237.5549 - val_loss: 1398.3053\n",
      "Epoch 320/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5546 - val_loss: 1398.3108\n",
      "Epoch 321/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5543 - val_loss: 1398.3157\n",
      "Epoch 322/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5540 - val_loss: 1398.3196\n",
      "Epoch 323/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5538 - val_loss: 1398.3229\n",
      "Epoch 324/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5536 - val_loss: 1398.3268\n",
      "Epoch 325/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5534 - val_loss: 1398.3292\n",
      "Epoch 326/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5532 - val_loss: 1398.3317\n",
      "Epoch 327/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5530 - val_loss: 1398.3340\n",
      "Epoch 328/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5529 - val_loss: 1398.3361\n",
      "Epoch 329/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5527 - val_loss: 1398.3376\n",
      "Epoch 330/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5526 - val_loss: 1398.3385\n",
      "Epoch 331/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5526 - val_loss: 1398.3403\n",
      "Epoch 332/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5525 - val_loss: 1398.3425\n",
      "Epoch 333/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5524 - val_loss: 1398.3436\n",
      "Epoch 334/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.3448\n",
      "Epoch 335/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 237.5523 - val_loss: 1398.3455\n",
      "Epoch 336/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.3464\n",
      "Epoch 337/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.3467\n",
      "Epoch 338/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5521 - val_loss: 1398.3472\n",
      "Epoch 339/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5521 - val_loss: 1398.3475\n",
      "Epoch 340/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3475\n",
      "Epoch 341/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 237.5520 - val_loss: 1398.3479\n",
      "Epoch 342/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 237.5519 - val_loss: 1398.3474\n",
      "Epoch 343/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5520 - val_loss: 1398.3478\n",
      "Epoch 344/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3479\n",
      "Epoch 345/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3477\n",
      "Epoch 346/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3477\n",
      "Epoch 347/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5518 - val_loss: 1398.3475\n",
      "Epoch 348/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5518 - val_loss: 1398.3472\n",
      "Epoch 349/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3472\n",
      "Epoch 350/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3467\n",
      "Epoch 351/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5518 - val_loss: 1398.3466\n",
      "Epoch 352/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3466\n",
      "Epoch 353/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5518 - val_loss: 1398.3466\n",
      "Epoch 354/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5518 - val_loss: 1398.3461\n",
      "Epoch 355/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5518 - val_loss: 1398.3456\n",
      "Epoch 356/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5518 - val_loss: 1398.3450\n",
      "Epoch 357/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5518 - val_loss: 1398.3442\n",
      "Epoch 358/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5518 - val_loss: 1398.3435\n",
      "Epoch 359/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 237.5518 - val_loss: 1398.3429\n",
      "Epoch 360/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5518 - val_loss: 1398.3422\n",
      "Epoch 361/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5518 - val_loss: 1398.3416\n",
      "Epoch 362/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5518 - val_loss: 1398.3409\n",
      "Epoch 363/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3406\n",
      "Epoch 364/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3398\n",
      "Epoch 365/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3391\n",
      "Epoch 366/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3381\n",
      "Epoch 367/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3373\n",
      "Epoch 368/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3367\n",
      "Epoch 369/500\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 237.5519 - val_loss: 1398.3361\n",
      "Epoch 370/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5519 - val_loss: 1398.3353\n",
      "Epoch 371/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3347\n",
      "Epoch 372/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5519 - val_loss: 1398.3340\n",
      "Epoch 373/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3331\n",
      "Epoch 374/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3326\n",
      "Epoch 375/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3315\n",
      "Epoch 376/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3309\n",
      "Epoch 377/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3301\n",
      "Epoch 378/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5519 - val_loss: 1398.3293\n",
      "Epoch 379/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3284\n",
      "Epoch 380/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3276\n",
      "Epoch 381/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3263\n",
      "Epoch 382/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3253\n",
      "Epoch 383/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3245\n",
      "Epoch 384/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3235\n",
      "Epoch 385/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3225\n",
      "Epoch 386/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3215\n",
      "Epoch 387/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3203\n",
      "Epoch 388/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3192\n",
      "Epoch 389/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3181\n",
      "Epoch 390/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3169\n",
      "Epoch 391/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5520 - val_loss: 1398.3158\n",
      "Epoch 392/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5521 - val_loss: 1398.3146\n",
      "Epoch 393/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5521 - val_loss: 1398.3140\n",
      "Epoch 394/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5521 - val_loss: 1398.3131\n",
      "Epoch 395/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5521 - val_loss: 1398.3120\n",
      "Epoch 396/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5521 - val_loss: 1398.3103\n",
      "Epoch 397/500\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 237.5521 - val_loss: 1398.3088\n",
      "Epoch 398/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5521 - val_loss: 1398.3073\n",
      "Epoch 399/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5521 - val_loss: 1398.3054\n",
      "Epoch 400/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5521 - val_loss: 1398.3038\n",
      "Epoch 401/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5521 - val_loss: 1398.3021\n",
      "Epoch 402/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5521 - val_loss: 1398.3007\n",
      "Epoch 403/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5521 - val_loss: 1398.2990\n",
      "Epoch 404/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5522 - val_loss: 1398.2972\n",
      "Epoch 405/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.2958\n",
      "Epoch 406/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.2944\n",
      "Epoch 407/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.2931\n",
      "Epoch 408/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.2913\n",
      "Epoch 409/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.2893\n",
      "Epoch 410/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.2876\n",
      "Epoch 411/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.2855\n",
      "Epoch 412/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.2838\n",
      "Epoch 413/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.2820\n",
      "Epoch 414/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.2803\n",
      "Epoch 415/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.2783\n",
      "Epoch 416/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.2762\n",
      "Epoch 417/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 237.5522 - val_loss: 1398.2743\n",
      "Epoch 418/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.2723\n",
      "Epoch 419/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5522 - val_loss: 1398.2703\n",
      "Epoch 420/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2682\n",
      "Epoch 421/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2661\n",
      "Epoch 422/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2644\n",
      "Epoch 423/500\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 237.5523 - val_loss: 1398.2625\n",
      "Epoch 424/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5523 - val_loss: 1398.2604\n",
      "Epoch 425/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5523 - val_loss: 1398.2585\n",
      "Epoch 426/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2560\n",
      "Epoch 427/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2537\n",
      "Epoch 428/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2511\n",
      "Epoch 429/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2484\n",
      "Epoch 430/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2458\n",
      "Epoch 431/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2429\n",
      "Epoch 432/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2401\n",
      "Epoch 433/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2369\n",
      "Epoch 434/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2341\n",
      "Epoch 435/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2311\n",
      "Epoch 436/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2279\n",
      "Epoch 437/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2249\n",
      "Epoch 438/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2218\n",
      "Epoch 439/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.2189\n",
      "Epoch 440/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.2157\n",
      "Epoch 441/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.2123\n",
      "Epoch 442/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.2089\n",
      "Epoch 443/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.2053\n",
      "Epoch 444/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.2013\n",
      "Epoch 445/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.1974\n",
      "Epoch 446/500\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 237.5523 - val_loss: 1398.1934\n",
      "Epoch 447/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5524 - val_loss: 1398.1892\n",
      "Epoch 448/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.1849\n",
      "Epoch 449/500\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 237.5524 - val_loss: 1398.1808\n",
      "Epoch 450/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5524 - val_loss: 1398.1760\n",
      "Epoch 451/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.1715\n",
      "Epoch 452/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.1672\n",
      "Epoch 453/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.1625\n",
      "Epoch 454/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.1573\n",
      "Epoch 455/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.1525\n",
      "Epoch 456/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5523 - val_loss: 1398.1471\n",
      "Epoch 457/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5523 - val_loss: 1398.1414\n",
      "Epoch 458/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.1355\n",
      "Epoch 459/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5524 - val_loss: 1398.1294\n",
      "Epoch 460/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.1232\n",
      "Epoch 461/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5525 - val_loss: 1398.1168\n",
      "Epoch 462/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.1101\n",
      "Epoch 463/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.1033\n",
      "Epoch 464/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.0957\n",
      "Epoch 465/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.0879\n",
      "Epoch 466/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.0791\n",
      "Epoch 467/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.0702\n",
      "Epoch 468/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.0599\n",
      "Epoch 469/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.5524 - val_loss: 1398.0482\n",
      "Epoch 470/500\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 237.5524 - val_loss: 1398.0332\n",
      "Epoch 471/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5524 - val_loss: 1398.0059\n",
      "Epoch 472/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.5524 - val_loss: 1397.7089\n",
      "Epoch 473/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.4574 - val_loss: 1380.0784\n",
      "Epoch 474/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 237.7663 - val_loss: 1348.5138\n",
      "Epoch 475/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 239.3393 - val_loss: 1353.0548\n",
      "Epoch 476/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 239.0985 - val_loss: 1357.3855\n",
      "Epoch 477/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 238.8764 - val_loss: 1361.3634\n",
      "Epoch 478/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 238.6868 - val_loss: 1365.0016\n",
      "Epoch 479/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 238.5259 - val_loss: 1368.3280\n",
      "Epoch 480/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 238.3891 - val_loss: 1371.3663\n",
      "Epoch 481/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 238.2731 - val_loss: 1374.1426\n",
      "Epoch 482/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 238.1743 - val_loss: 1376.6780\n",
      "Epoch 483/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 238.0900 - val_loss: 1378.9921\n",
      "Epoch 484/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 238.0181 - val_loss: 1381.1063\n",
      "Epoch 485/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.9563 - val_loss: 1383.0358\n",
      "Epoch 486/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.9033 - val_loss: 1384.7958\n",
      "Epoch 487/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.8579 - val_loss: 1386.4022\n",
      "Epoch 488/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.8187 - val_loss: 1387.8679\n",
      "Epoch 489/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.7848 - val_loss: 1389.2048\n",
      "Epoch 490/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.7556 - val_loss: 1390.4247\n",
      "Epoch 491/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.7302 - val_loss: 1391.5371\n",
      "Epoch 492/500\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 237.7082 - val_loss: 1392.5515\n",
      "Epoch 493/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.6890 - val_loss: 1393.4763\n",
      "Epoch 494/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.6723 - val_loss: 1394.3198\n",
      "Epoch 495/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.6577 - val_loss: 1395.0895\n",
      "Epoch 496/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.6448 - val_loss: 1395.7903\n",
      "Epoch 497/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.6336 - val_loss: 1396.4283\n",
      "Epoch 498/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.6237 - val_loss: 1397.0115\n",
      "Epoch 499/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.6151 - val_loss: 1397.5432\n",
      "Epoch 500/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 237.6073 - val_loss: 1398.0266\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 415ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.78221989e+01, 5.76961485e+01, 5.75700980e+01, 5.74440476e+01,\n",
       "        6.55019760e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 8.44941260e-01, 0.00000000e+00,\n",
       "        1.19966790e-01, 5.80509571e+01, 5.79249066e+01, 5.77988562e+01,\n",
       "        2.20957430e-01, 1.00525665e+00, 5.88176471e+01, 5.83134454e+01,\n",
       "        5.81023109e+01, 5.79762605e+01, 5.78502101e+01, 5.77241597e+01,\n",
       "        5.75978092e+01, 5.74720588e+01, 5.73436084e+01, 0.00000000e+00,\n",
       "        4.05044300e-02, 5.79015640e+01, 5.77755135e+01, 5.76494631e+01,\n",
       "        5.75234127e+01, 5.73973623e+01, 6.27289449e+01, 6.08996966e+01,\n",
       "        5.92471522e+01, 6.19025170e-01, 7.93619275e-01, 0.00000000e+00,\n",
       "        2.83631295e-01, 0.00000000e+00, 2.03480452e-01, 1.01974100e-01,\n",
       "        5.16042829e-01, 0.00000000e+00, 2.68835902e-01, 5.79669234e+01,\n",
       "        5.78408730e+01, 7.16493960e-01, 6.86268800e-02, 5.89857143e+01,\n",
       "        5.84815126e+01, 5.81843277e+01, 5.80182773e+01, 5.78922269e+01,\n",
       "        5.77661765e+01, 5.76401260e+01, 5.75140756e+01, 5.73880252e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.79435808e+01, 5.78175303e+01,\n",
       "        5.76914799e+01, 5.75654295e+01, 5.74393791e+01, 6.29306256e+01,\n",
       "        6.15299487e+01, 5.97513539e+01, 0.00000000e+00, 1.97836610e-02,\n",
       "        4.12894547e-01, 5.67768288e+01, 8.75653630e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.97576737e-01, 6.01354837e-01, 1.08075157e-01,\n",
       "        5.51657982e+01, 0.00000000e+00, 1.02000415e+00, 4.79767397e-02,\n",
       "        0.00000000e+00, 4.89872694e-02, 4.61267643e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.53469706e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.80275846e-01, 6.13952100e-01, 0.00000000e+00, 4.24734175e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47.64968231, 47.63984423, 47.63000615, 47.62016807, 47.61032999,\n",
       "       47.6004919 , 47.59065382, 47.58081574, 47.57097766, 47.56113958,\n",
       "       47.5513015 , 47.54146341, 47.53162533, 47.52178725, 47.51194917,\n",
       "       47.50211109, 47.49227301, 47.48243493, 47.47259684, 47.46275876,\n",
       "       47.45292068, 47.4430826 , 47.43324452, 47.42340644, 47.41356835,\n",
       "       47.40373027, 47.39389219, 47.38405411, 47.37421603, 47.36437795,\n",
       "       47.35453986, 47.34470178, 47.3348637 , 47.32502562, 47.31518754,\n",
       "       47.30534946, 47.29551138, 47.28567329, 47.27583521, 47.26599713,\n",
       "       47.25615905, 47.24632097, 47.23648289, 47.2266448 , 47.21680672,\n",
       "       47.20696864, 47.19713056, 47.18729248, 47.1774544 , 47.16761631,\n",
       "       47.15777823, 47.14794015, 47.13810207, 47.12826399, 47.11842591,\n",
       "       47.10858783, 47.09874974, 47.08891166, 47.07907358, 47.0692355 ,\n",
       "       47.05939742, 47.04955934, 47.03972125, 47.02988317, 47.02004509,\n",
       "       47.01020701, 47.00036893, 46.99053085, 46.98069276, 46.97085468,\n",
       "       46.9610166 , 46.95117852, 46.94134044, 46.93150236, 46.92166428,\n",
       "       46.91182619, 46.90198811, 46.89215003, 46.88231195, 46.87247387,\n",
       "       46.86263579, 46.8527977 , 46.84295962, 46.83312154, 46.82328346,\n",
       "       46.81344538, 46.8036073 , 46.79376922, 46.78393113, 46.77409305,\n",
       "       46.76425497, 46.75441689, 46.74457881, 46.73474073, 46.72490264,\n",
       "       46.71506456, 46.70522648, 46.6953884 , 46.68555032, 46.67571224])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.2733513327941\n",
      "30.409173847190388\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
