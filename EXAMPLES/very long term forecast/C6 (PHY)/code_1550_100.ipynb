{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "1645    54.634314\n",
       "1646    54.628711\n",
       "1647    54.623109\n",
       "1648    54.617507\n",
       "1649    54.611905\n",
       "Name: C6, Length: 1650, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_1550_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "1545     0.000000\n",
       "1546     0.040504\n",
       "1547     0.280666\n",
       "1548     0.000000\n",
       "1549     0.000000\n",
       "Name: C6, Length: 1550, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1550)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 1, 251) (1100, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "14/14 [==============================] - 2s 37ms/step - loss: 4125.5205 - val_loss: 3022.2383\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4051.6074 - val_loss: 2988.6177\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4010.5872 - val_loss: 2954.8716\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3969.6819 - val_loss: 2921.4446\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3929.1567 - val_loss: 2888.3748\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3889.0203 - val_loss: 2855.6482\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3849.2507 - val_loss: 2823.2466\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3809.8311 - val_loss: 2791.1575\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3770.7458 - val_loss: 2759.3711\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3731.9858 - val_loss: 2727.8801\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3693.5444 - val_loss: 2696.6790\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3655.4138 - val_loss: 2665.7637\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3617.5930 - val_loss: 2635.1304\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3580.0750 - val_loss: 2604.7761\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3539.3489 - val_loss: 2569.4231\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3497.9097 - val_loss: 2536.8245\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3458.0164 - val_loss: 2504.8718\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3418.8757 - val_loss: 2473.5325\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 3380.3921 - val_loss: 2442.7107\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3342.4614 - val_loss: 2412.3384\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3305.0149 - val_loss: 2382.3699\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3268.0046 - val_loss: 2352.7754\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3231.4006 - val_loss: 2323.5330\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3195.1790 - val_loss: 2294.6267\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3159.3240 - val_loss: 2266.0444\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3123.8201 - val_loss: 2237.7764\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3088.6584 - val_loss: 2209.8147\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3053.8296 - val_loss: 2182.1511\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3019.3262 - val_loss: 2154.7815\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2985.1418 - val_loss: 2127.7007\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2951.2705 - val_loss: 2100.9026\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2917.7080 - val_loss: 2074.3845\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2884.4485 - val_loss: 2048.1421\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2851.4900 - val_loss: 2022.1726\n",
      "Epoch 35/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2818.8274 - val_loss: 1996.4722\n",
      "Epoch 36/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2786.4570 - val_loss: 1971.0378\n",
      "Epoch 37/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2754.3762 - val_loss: 1945.8673\n",
      "Epoch 38/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2722.5823 - val_loss: 1920.9575\n",
      "Epoch 39/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2691.0718 - val_loss: 1896.3065\n",
      "Epoch 40/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2659.8425 - val_loss: 1871.9114\n",
      "Epoch 41/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2628.8911 - val_loss: 1847.7693\n",
      "Epoch 42/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2598.2163 - val_loss: 1823.8794\n",
      "Epoch 43/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2567.8147 - val_loss: 1800.2385\n",
      "Epoch 44/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2537.6838 - val_loss: 1776.8447\n",
      "Epoch 45/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2507.8228 - val_loss: 1753.6963\n",
      "Epoch 46/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2478.2280 - val_loss: 1730.7910\n",
      "Epoch 47/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2448.8987 - val_loss: 1708.1273\n",
      "Epoch 48/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2419.8315 - val_loss: 1685.7029\n",
      "Epoch 49/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2391.0256 - val_loss: 1663.5159\n",
      "Epoch 50/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2362.4783 - val_loss: 1641.5649\n",
      "Epoch 51/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 2334.1880 - val_loss: 1619.8480\n",
      "Epoch 52/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2306.1526 - val_loss: 1598.3630\n",
      "Epoch 53/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2278.3711 - val_loss: 1577.1091\n",
      "Epoch 54/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2250.8408 - val_loss: 1556.0836\n",
      "Epoch 55/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2223.5603 - val_loss: 1535.2858\n",
      "Epoch 56/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2196.5276 - val_loss: 1514.7133\n",
      "Epoch 57/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2169.7415 - val_loss: 1494.3647\n",
      "Epoch 58/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2143.2000 - val_loss: 1474.2386\n",
      "Epoch 59/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2116.9016 - val_loss: 1454.3334\n",
      "Epoch 60/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2090.8445 - val_loss: 1434.6475\n",
      "Epoch 61/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2065.0273 - val_loss: 1415.1793\n",
      "Epoch 62/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2039.4479 - val_loss: 1395.9269\n",
      "Epoch 63/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2014.1051 - val_loss: 1376.8894\n",
      "Epoch 64/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1988.9974 - val_loss: 1358.0649\n",
      "Epoch 65/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1964.1233 - val_loss: 1339.4524\n",
      "Epoch 66/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1939.4810 - val_loss: 1321.0497\n",
      "Epoch 67/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1915.0688 - val_loss: 1302.8558\n",
      "Epoch 68/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1890.8855 - val_loss: 1284.8695\n",
      "Epoch 69/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1866.9303 - val_loss: 1267.0886\n",
      "Epoch 70/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1843.2004 - val_loss: 1249.5120\n",
      "Epoch 71/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1819.6949 - val_loss: 1232.1390\n",
      "Epoch 72/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1796.4125 - val_loss: 1214.9670\n",
      "Epoch 73/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1773.3518 - val_loss: 1197.9954\n",
      "Epoch 74/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1750.5111 - val_loss: 1181.2225\n",
      "Epoch 75/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1727.8892 - val_loss: 1164.6472\n",
      "Epoch 76/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1705.4846 - val_loss: 1148.2675\n",
      "Epoch 77/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1683.2958 - val_loss: 1132.0828\n",
      "Epoch 78/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1661.3213 - val_loss: 1116.0918\n",
      "Epoch 79/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1639.5605 - val_loss: 1100.2922\n",
      "Epoch 80/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1618.0107 - val_loss: 1084.6835\n",
      "Epoch 81/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1596.6719 - val_loss: 1069.2639\n",
      "Epoch 82/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1575.5420 - val_loss: 1054.0326\n",
      "Epoch 83/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1554.6198 - val_loss: 1038.9879\n",
      "Epoch 84/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1533.9039 - val_loss: 1024.1288\n",
      "Epoch 85/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1513.3932 - val_loss: 1009.4533\n",
      "Epoch 86/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1493.0858 - val_loss: 994.9605\n",
      "Epoch 87/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1472.9810 - val_loss: 980.6496\n",
      "Epoch 88/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1453.0775 - val_loss: 966.5187\n",
      "Epoch 89/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1433.3740 - val_loss: 952.5668\n",
      "Epoch 90/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1413.8684 - val_loss: 938.7930\n",
      "Epoch 91/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1394.5604 - val_loss: 925.1948\n",
      "Epoch 92/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1375.4481 - val_loss: 911.7721\n",
      "Epoch 93/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1356.5306 - val_loss: 898.5234\n",
      "Epoch 94/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1337.8068 - val_loss: 885.4476\n",
      "Epoch 95/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1319.2749 - val_loss: 872.5425\n",
      "Epoch 96/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1300.9333 - val_loss: 859.8078\n",
      "Epoch 97/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1282.7819 - val_loss: 847.2420\n",
      "Epoch 98/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1264.8186 - val_loss: 834.8439\n",
      "Epoch 99/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1247.0426 - val_loss: 822.6124\n",
      "Epoch 100/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1229.4524 - val_loss: 810.5458\n",
      "Epoch 101/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1212.0469 - val_loss: 798.6437\n",
      "Epoch 102/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1194.8252 - val_loss: 786.9044\n",
      "Epoch 103/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1177.7855 - val_loss: 775.3264\n",
      "Epoch 104/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1160.9269 - val_loss: 763.9091\n",
      "Epoch 105/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1144.2482 - val_loss: 752.6511\n",
      "Epoch 106/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1127.7480 - val_loss: 741.5509\n",
      "Epoch 107/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1111.4255 - val_loss: 730.6078\n",
      "Epoch 108/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1095.2788 - val_loss: 719.8202\n",
      "Epoch 109/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1079.3075 - val_loss: 709.1872\n",
      "Epoch 110/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1063.5103 - val_loss: 698.7076\n",
      "Epoch 111/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1047.8857 - val_loss: 688.3802\n",
      "Epoch 112/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1032.4326 - val_loss: 678.2037\n",
      "Epoch 113/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1017.1500 - val_loss: 668.1771\n",
      "Epoch 114/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1002.0366 - val_loss: 658.2994\n",
      "Epoch 115/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 987.0915 - val_loss: 648.5687\n",
      "Epoch 116/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 972.3129 - val_loss: 638.9846\n",
      "Epoch 117/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 957.7001 - val_loss: 629.5461\n",
      "Epoch 118/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 943.2523 - val_loss: 620.2513\n",
      "Epoch 119/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 928.9680 - val_loss: 611.0992\n",
      "Epoch 120/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 914.8458 - val_loss: 602.0895\n",
      "Epoch 121/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 900.8849 - val_loss: 593.2204\n",
      "Epoch 122/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 887.0842 - val_loss: 584.4908\n",
      "Epoch 123/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 873.4426 - val_loss: 575.8994\n",
      "Epoch 124/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 859.9587 - val_loss: 567.4453\n",
      "Epoch 125/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 846.6316 - val_loss: 559.1276\n",
      "Epoch 126/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 833.4606 - val_loss: 550.9449\n",
      "Epoch 127/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 820.4437 - val_loss: 542.8962\n",
      "Epoch 128/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 807.5803 - val_loss: 534.9803\n",
      "Epoch 129/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 794.8691 - val_loss: 527.1959\n",
      "Epoch 130/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 782.3091 - val_loss: 519.5422\n",
      "Epoch 131/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 769.8992 - val_loss: 512.0179\n",
      "Epoch 132/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 757.6383 - val_loss: 504.6222\n",
      "Epoch 133/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 745.5253 - val_loss: 497.3538\n",
      "Epoch 134/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 733.5596 - val_loss: 490.2118\n",
      "Epoch 135/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 721.7393 - val_loss: 483.1944\n",
      "Epoch 136/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 710.0638 - val_loss: 476.3014\n",
      "Epoch 137/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 698.5322 - val_loss: 469.5312\n",
      "Epoch 138/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 687.1431 - val_loss: 462.8830\n",
      "Epoch 139/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 675.8953 - val_loss: 456.3553\n",
      "Epoch 140/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 664.7877 - val_loss: 449.9475\n",
      "Epoch 141/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 653.8197 - val_loss: 443.6583\n",
      "Epoch 142/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 642.9899 - val_loss: 437.4866\n",
      "Epoch 143/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 632.2972 - val_loss: 431.4313\n",
      "Epoch 144/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 621.7408 - val_loss: 425.4915\n",
      "Epoch 145/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 611.3196 - val_loss: 419.6658\n",
      "Epoch 146/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 601.0324 - val_loss: 413.9533\n",
      "Epoch 147/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 590.8780 - val_loss: 408.3532\n",
      "Epoch 148/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 580.8558 - val_loss: 402.8643\n",
      "Epoch 149/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 570.9647 - val_loss: 397.4853\n",
      "Epoch 150/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 561.2032 - val_loss: 392.2153\n",
      "Epoch 151/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 551.5707 - val_loss: 387.0531\n",
      "Epoch 152/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 542.0660 - val_loss: 381.9981\n",
      "Epoch 153/500\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 532.6881 - val_loss: 377.0489\n",
      "Epoch 154/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 523.4361 - val_loss: 372.2044\n",
      "Epoch 155/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 514.3086 - val_loss: 367.4636\n",
      "Epoch 156/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 505.3049 - val_loss: 362.8256\n",
      "Epoch 157/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 496.4239 - val_loss: 358.2891\n",
      "Epoch 158/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 487.6645 - val_loss: 353.8533\n",
      "Epoch 159/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 479.0260 - val_loss: 349.5173\n",
      "Epoch 160/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 470.5069 - val_loss: 345.2795\n",
      "Epoch 161/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 462.1065 - val_loss: 341.1393\n",
      "Epoch 162/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 453.8236 - val_loss: 337.0954\n",
      "Epoch 163/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 445.6575 - val_loss: 333.1472\n",
      "Epoch 164/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 437.6070 - val_loss: 329.2933\n",
      "Epoch 165/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 429.6711 - val_loss: 325.5330\n",
      "Epoch 166/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 421.8487 - val_loss: 321.8645\n",
      "Epoch 167/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 414.1389 - val_loss: 318.2878\n",
      "Epoch 168/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 406.5409 - val_loss: 314.8014\n",
      "Epoch 169/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 399.0533 - val_loss: 311.4042\n",
      "Epoch 170/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 391.6754 - val_loss: 308.0951\n",
      "Epoch 171/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 384.4062 - val_loss: 304.8734\n",
      "Epoch 172/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 377.2444 - val_loss: 301.7379\n",
      "Epoch 173/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 370.1896 - val_loss: 298.6877\n",
      "Epoch 174/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 363.2403 - val_loss: 295.7216\n",
      "Epoch 175/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 356.3957 - val_loss: 292.8389\n",
      "Epoch 176/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 349.6549 - val_loss: 290.0384\n",
      "Epoch 177/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 343.0168 - val_loss: 287.3191\n",
      "Epoch 178/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 336.4805 - val_loss: 284.6798\n",
      "Epoch 179/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 330.0451 - val_loss: 282.1199\n",
      "Epoch 180/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 323.7096 - val_loss: 279.6382\n",
      "Epoch 181/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 317.4728 - val_loss: 277.2338\n",
      "Epoch 182/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 311.3340 - val_loss: 274.9055\n",
      "Epoch 183/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 305.2920 - val_loss: 272.6526\n",
      "Epoch 184/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 299.3461 - val_loss: 270.4738\n",
      "Epoch 185/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 293.4953 - val_loss: 268.3685\n",
      "Epoch 186/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 287.7387 - val_loss: 266.3353\n",
      "Epoch 187/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 282.0750 - val_loss: 264.3736\n",
      "Epoch 188/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 276.5037 - val_loss: 262.4821\n",
      "Epoch 189/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 271.0234 - val_loss: 260.6599\n",
      "Epoch 190/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 265.6335 - val_loss: 258.9063\n",
      "Epoch 191/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 260.3330 - val_loss: 257.2201\n",
      "Epoch 192/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 255.1210 - val_loss: 255.6004\n",
      "Epoch 193/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 249.9965 - val_loss: 254.0460\n",
      "Epoch 194/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 244.9584 - val_loss: 252.5563\n",
      "Epoch 195/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 240.0060 - val_loss: 251.1302\n",
      "Epoch 196/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 235.1383 - val_loss: 249.7666\n",
      "Epoch 197/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 230.3544 - val_loss: 248.4648\n",
      "Epoch 198/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 225.6534 - val_loss: 247.2237\n",
      "Epoch 199/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 221.0342 - val_loss: 246.0423\n",
      "Epoch 200/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 216.4960 - val_loss: 244.9200\n",
      "Epoch 201/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 212.0380 - val_loss: 243.8554\n",
      "Epoch 202/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 207.6593 - val_loss: 242.8478\n",
      "Epoch 203/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 203.3587 - val_loss: 241.8962\n",
      "Epoch 204/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 199.1356 - val_loss: 240.9998\n",
      "Epoch 205/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 194.9888 - val_loss: 240.1575\n",
      "Epoch 206/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 190.9177 - val_loss: 239.3686\n",
      "Epoch 207/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 186.9213 - val_loss: 238.6319\n",
      "Epoch 208/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 182.9987 - val_loss: 237.9465\n",
      "Epoch 209/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 179.1489 - val_loss: 237.3118\n",
      "Epoch 210/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 175.3712 - val_loss: 236.7267\n",
      "Epoch 211/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 171.6647 - val_loss: 236.1903\n",
      "Epoch 212/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 168.0284 - val_loss: 235.7016\n",
      "Epoch 213/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 164.4615 - val_loss: 235.2598\n",
      "Epoch 214/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 160.9629 - val_loss: 234.8640\n",
      "Epoch 215/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 157.5320 - val_loss: 234.5134\n",
      "Epoch 216/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 154.1679 - val_loss: 234.2070\n",
      "Epoch 217/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 150.8696 - val_loss: 233.9439\n",
      "Epoch 218/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 147.6366 - val_loss: 233.7232\n",
      "Epoch 219/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 144.4676 - val_loss: 233.5443\n",
      "Epoch 220/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 141.3619 - val_loss: 233.4060\n",
      "Epoch 221/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 138.3187 - val_loss: 233.3076\n",
      "Epoch 222/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 135.3372 - val_loss: 233.2482\n",
      "Epoch 223/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 132.4165 - val_loss: 233.2269\n",
      "Epoch 224/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 129.5558 - val_loss: 233.2430\n",
      "Epoch 225/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 126.7542 - val_loss: 233.2956\n",
      "Epoch 226/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 124.0108 - val_loss: 233.3837\n",
      "Epoch 227/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 121.3250 - val_loss: 233.5067\n",
      "Epoch 228/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 118.6958 - val_loss: 233.6636\n",
      "Epoch 229/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 116.1225 - val_loss: 233.8537\n",
      "Epoch 230/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 113.6042 - val_loss: 234.0761\n",
      "Epoch 231/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 111.1400 - val_loss: 234.3300\n",
      "Epoch 232/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 108.7294 - val_loss: 234.6146\n",
      "Epoch 233/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 106.3713 - val_loss: 234.9292\n",
      "Epoch 234/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 104.0652 - val_loss: 235.2728\n",
      "Epoch 235/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 101.8099 - val_loss: 235.6448\n",
      "Epoch 236/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 99.6049 - val_loss: 236.0443\n",
      "Epoch 237/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 97.4494 - val_loss: 236.4706\n",
      "Epoch 238/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 95.3427 - val_loss: 236.9228\n",
      "Epoch 239/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 93.2838 - val_loss: 237.4003\n",
      "Epoch 240/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 91.2721 - val_loss: 237.9022\n",
      "Epoch 241/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 89.3070 - val_loss: 238.4279\n",
      "Epoch 242/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 87.3875 - val_loss: 238.9765\n",
      "Epoch 243/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 85.5129 - val_loss: 239.5475\n",
      "Epoch 244/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 83.6823 - val_loss: 240.1398\n",
      "Epoch 245/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 81.8953 - val_loss: 240.7530\n",
      "Epoch 246/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 80.1509 - val_loss: 241.3862\n",
      "Epoch 247/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 78.4484 - val_loss: 242.0388\n",
      "Epoch 248/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 76.7873 - val_loss: 242.7101\n",
      "Epoch 249/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 75.1668 - val_loss: 243.3992\n",
      "Epoch 250/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 73.5860 - val_loss: 244.1056\n",
      "Epoch 251/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 72.0443 - val_loss: 244.8286\n",
      "Epoch 252/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 70.5411 - val_loss: 245.5675\n",
      "Epoch 253/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 69.0756 - val_loss: 246.3217\n",
      "Epoch 254/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 67.6472 - val_loss: 247.0904\n",
      "Epoch 255/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 66.2551 - val_loss: 247.8731\n",
      "Epoch 256/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 64.8986 - val_loss: 248.6690\n",
      "Epoch 257/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 63.5771 - val_loss: 249.4776\n",
      "Epoch 258/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 62.2901 - val_loss: 250.2982\n",
      "Epoch 259/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 61.0368 - val_loss: 251.1302\n",
      "Epoch 260/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 59.8165 - val_loss: 251.9731\n",
      "Epoch 261/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 58.6286 - val_loss: 252.8260\n",
      "Epoch 262/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 57.4725 - val_loss: 253.6885\n",
      "Epoch 263/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 56.3476 - val_loss: 254.5601\n",
      "Epoch 264/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 55.2531 - val_loss: 255.4402\n",
      "Epoch 265/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 54.1885 - val_loss: 256.3280\n",
      "Epoch 266/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 53.1533 - val_loss: 257.2232\n",
      "Epoch 267/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 52.1468 - val_loss: 258.1251\n",
      "Epoch 268/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 51.1682 - val_loss: 259.0332\n",
      "Epoch 269/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 50.2173 - val_loss: 259.9470\n",
      "Epoch 270/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 49.2933 - val_loss: 260.8660\n",
      "Epoch 271/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 48.3955 - val_loss: 261.7896\n",
      "Epoch 272/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 47.5236 - val_loss: 262.7172\n",
      "Epoch 273/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 46.6769 - val_loss: 263.6486\n",
      "Epoch 274/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 45.8548 - val_loss: 264.5831\n",
      "Epoch 275/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 45.0568 - val_loss: 265.5201\n",
      "Epoch 276/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 44.2824 - val_loss: 266.4594\n",
      "Epoch 277/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 43.5310 - val_loss: 267.4004\n",
      "Epoch 278/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 42.8022 - val_loss: 268.3428\n",
      "Epoch 279/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 42.0953 - val_loss: 269.2860\n",
      "Epoch 280/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 41.4098 - val_loss: 270.2294\n",
      "Epoch 281/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 40.7454 - val_loss: 271.1729\n",
      "Epoch 282/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 40.1014 - val_loss: 272.1159\n",
      "Epoch 283/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 39.4775 - val_loss: 273.0583\n",
      "Epoch 284/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 38.8729 - val_loss: 273.9992\n",
      "Epoch 285/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 38.2874 - val_loss: 274.9384\n",
      "Epoch 286/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 37.7204 - val_loss: 275.8759\n",
      "Epoch 287/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 37.1715 - val_loss: 276.8109\n",
      "Epoch 288/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 36.6402 - val_loss: 277.7431\n",
      "Epoch 289/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 36.1261 - val_loss: 278.6724\n",
      "Epoch 290/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 35.6288 - val_loss: 279.5981\n",
      "Epoch 291/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 35.1477 - val_loss: 280.5203\n",
      "Epoch 292/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 34.6825 - val_loss: 281.4382\n",
      "Epoch 293/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 34.2328 - val_loss: 282.3518\n",
      "Epoch 294/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 33.7982 - val_loss: 283.2608\n",
      "Epoch 295/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 33.3781 - val_loss: 284.1648\n",
      "Epoch 296/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 32.9723 - val_loss: 285.0635\n",
      "Epoch 297/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 32.5804 - val_loss: 285.9567\n",
      "Epoch 298/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 32.2020 - val_loss: 286.8440\n",
      "Epoch 299/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 31.8367 - val_loss: 287.7253\n",
      "Epoch 300/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 31.4841 - val_loss: 288.6003\n",
      "Epoch 301/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 31.1439 - val_loss: 289.4689\n",
      "Epoch 302/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 30.8157 - val_loss: 290.3307\n",
      "Epoch 303/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 30.4991 - val_loss: 291.1854\n",
      "Epoch 304/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 30.1940 - val_loss: 292.0333\n",
      "Epoch 305/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 29.8997 - val_loss: 292.8737\n",
      "Epoch 306/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 29.6162 - val_loss: 293.7064\n",
      "Epoch 307/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 29.3430 - val_loss: 294.5311\n",
      "Epoch 308/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 29.0799 - val_loss: 295.3482\n",
      "Epoch 309/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 28.8265 - val_loss: 296.1570\n",
      "Epoch 310/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 28.5825 - val_loss: 296.9575\n",
      "Epoch 311/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 28.3477 - val_loss: 297.7497\n",
      "Epoch 312/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 28.1218 - val_loss: 298.5333\n",
      "Epoch 313/500\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 27.9044 - val_loss: 299.3083\n",
      "Epoch 314/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 27.6952 - val_loss: 300.0747\n",
      "Epoch 315/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 27.4942 - val_loss: 300.8320\n",
      "Epoch 316/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 27.3009 - val_loss: 301.5801\n",
      "Epoch 317/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 27.1151 - val_loss: 302.3194\n",
      "Epoch 318/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 26.9366 - val_loss: 303.0494\n",
      "Epoch 319/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 26.7651 - val_loss: 303.7699\n",
      "Epoch 320/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 26.6005 - val_loss: 304.4810\n",
      "Epoch 321/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 26.4424 - val_loss: 305.1827\n",
      "Epoch 322/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 26.2907 - val_loss: 305.8749\n",
      "Epoch 323/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 26.1450 - val_loss: 306.5576\n",
      "Epoch 324/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 26.0053 - val_loss: 307.2303\n",
      "Epoch 325/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 25.8713 - val_loss: 307.8936\n",
      "Epoch 326/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 25.7429 - val_loss: 308.5473\n",
      "Epoch 327/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 25.6197 - val_loss: 309.1910\n",
      "Epoch 328/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 25.5016 - val_loss: 309.8251\n",
      "Epoch 329/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 25.3885 - val_loss: 310.4495\n",
      "Epoch 330/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 25.2801 - val_loss: 311.0638\n",
      "Epoch 331/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 25.1763 - val_loss: 311.6689\n",
      "Epoch 332/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 25.0769 - val_loss: 312.2638\n",
      "Epoch 333/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 24.9817 - val_loss: 312.8489\n",
      "Epoch 334/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 24.8907 - val_loss: 313.4242\n",
      "Epoch 335/500\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 24.8036 - val_loss: 313.9897\n",
      "Epoch 336/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 24.7202 - val_loss: 314.5456\n",
      "Epoch 337/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 24.6405 - val_loss: 315.0918\n",
      "Epoch 338/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 24.5643 - val_loss: 315.6282\n",
      "Epoch 339/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 24.4915 - val_loss: 316.1550\n",
      "Epoch 340/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 24.4219 - val_loss: 316.6721\n",
      "Epoch 341/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 24.3554 - val_loss: 317.1797\n",
      "Epoch 342/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 24.2919 - val_loss: 317.6778\n",
      "Epoch 343/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 24.2312 - val_loss: 318.1662\n",
      "Epoch 344/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 24.1733 - val_loss: 318.6455\n",
      "Epoch 345/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 24.1180 - val_loss: 319.1153\n",
      "Epoch 346/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 24.0652 - val_loss: 319.5758\n",
      "Epoch 347/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 24.0149 - val_loss: 320.0273\n",
      "Epoch 348/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.9669 - val_loss: 320.4696\n",
      "Epoch 349/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.9211 - val_loss: 320.9028\n",
      "Epoch 350/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.8774 - val_loss: 321.3271\n",
      "Epoch 351/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.8358 - val_loss: 321.7422\n",
      "Epoch 352/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.7961 - val_loss: 322.1486\n",
      "Epoch 353/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.7583 - val_loss: 322.5462\n",
      "Epoch 354/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.7223 - val_loss: 322.9353\n",
      "Epoch 355/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.6880 - val_loss: 323.3157\n",
      "Epoch 356/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 23.6554 - val_loss: 323.6882\n",
      "Epoch 357/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.6242 - val_loss: 324.0521\n",
      "Epoch 358/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 23.5946 - val_loss: 324.4075\n",
      "Epoch 359/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.5664 - val_loss: 324.7549\n",
      "Epoch 360/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.5395 - val_loss: 325.0944\n",
      "Epoch 361/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.5140 - val_loss: 325.4254\n",
      "Epoch 362/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.4897 - val_loss: 325.7491\n",
      "Epoch 363/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.4666 - val_loss: 326.0652\n",
      "Epoch 364/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.4447 - val_loss: 326.3734\n",
      "Epoch 365/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 23.4237 - val_loss: 326.6739\n",
      "Epoch 366/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.4039 - val_loss: 326.9671\n",
      "Epoch 367/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.3850 - val_loss: 327.2530\n",
      "Epoch 368/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.3671 - val_loss: 327.5320\n",
      "Epoch 369/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.3500 - val_loss: 327.8037\n",
      "Epoch 370/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.3338 - val_loss: 328.0684\n",
      "Epoch 371/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.3185 - val_loss: 328.3264\n",
      "Epoch 372/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.3039 - val_loss: 328.5779\n",
      "Epoch 373/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.2899 - val_loss: 328.8225\n",
      "Epoch 374/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.2767 - val_loss: 329.0607\n",
      "Epoch 375/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.2642 - val_loss: 329.2927\n",
      "Epoch 376/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.2523 - val_loss: 329.5182\n",
      "Epoch 377/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 23.2410 - val_loss: 329.7376\n",
      "Epoch 378/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.2303 - val_loss: 329.9510\n",
      "Epoch 379/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.2202 - val_loss: 330.1586\n",
      "Epoch 380/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.2104 - val_loss: 330.3603\n",
      "Epoch 381/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.2013 - val_loss: 330.5564\n",
      "Epoch 382/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.1926 - val_loss: 330.7468\n",
      "Epoch 383/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.1844 - val_loss: 330.9319\n",
      "Epoch 384/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.1765 - val_loss: 331.1117\n",
      "Epoch 385/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.1691 - val_loss: 331.2862\n",
      "Epoch 386/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.1621 - val_loss: 331.4556\n",
      "Epoch 387/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.1554 - val_loss: 331.6201\n",
      "Epoch 388/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.1490 - val_loss: 331.7793\n",
      "Epoch 389/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.1430 - val_loss: 331.9344\n",
      "Epoch 390/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.1373 - val_loss: 332.0844\n",
      "Epoch 391/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.1319 - val_loss: 332.2294\n",
      "Epoch 392/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.1268 - val_loss: 332.3706\n",
      "Epoch 393/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.1219 - val_loss: 332.5073\n",
      "Epoch 394/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.1172 - val_loss: 332.6397\n",
      "Epoch 395/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.1129 - val_loss: 332.7676\n",
      "Epoch 396/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 23.1087 - val_loss: 332.8916\n",
      "Epoch 397/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.1048 - val_loss: 333.0117\n",
      "Epoch 398/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 23.1011 - val_loss: 333.1278\n",
      "Epoch 399/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0975 - val_loss: 333.2405\n",
      "Epoch 400/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0942 - val_loss: 333.3495\n",
      "Epoch 401/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0910 - val_loss: 333.4546\n",
      "Epoch 402/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0880 - val_loss: 333.5565\n",
      "Epoch 403/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0851 - val_loss: 333.6545\n",
      "Epoch 404/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0824 - val_loss: 333.7497\n",
      "Epoch 405/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0799 - val_loss: 333.8418\n",
      "Epoch 406/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0774 - val_loss: 333.9303\n",
      "Epoch 407/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0751 - val_loss: 334.0159\n",
      "Epoch 408/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0729 - val_loss: 334.0987\n",
      "Epoch 409/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0709 - val_loss: 334.1787\n",
      "Epoch 410/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0690 - val_loss: 334.2558\n",
      "Epoch 411/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0671 - val_loss: 334.3299\n",
      "Epoch 412/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0654 - val_loss: 334.4015\n",
      "Epoch 413/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0637 - val_loss: 334.4708\n",
      "Epoch 414/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0621 - val_loss: 334.5374\n",
      "Epoch 415/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0606 - val_loss: 334.6015\n",
      "Epoch 416/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0593 - val_loss: 334.6634\n",
      "Epoch 417/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0579 - val_loss: 334.7234\n",
      "Epoch 418/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0566 - val_loss: 334.7808\n",
      "Epoch 419/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0554 - val_loss: 334.8360\n",
      "Epoch 420/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0543 - val_loss: 334.8893\n",
      "Epoch 421/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0533 - val_loss: 334.9405\n",
      "Epoch 422/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0523 - val_loss: 334.9900\n",
      "Epoch 423/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0513 - val_loss: 335.0375\n",
      "Epoch 424/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0504 - val_loss: 335.0833\n",
      "Epoch 425/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 23.0496 - val_loss: 335.1270\n",
      "Epoch 426/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0488 - val_loss: 335.1691\n",
      "Epoch 427/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0481 - val_loss: 335.2094\n",
      "Epoch 428/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0474 - val_loss: 335.2485\n",
      "Epoch 429/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0467 - val_loss: 335.2856\n",
      "Epoch 430/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0461 - val_loss: 335.3214\n",
      "Epoch 431/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0455 - val_loss: 335.3560\n",
      "Epoch 432/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0450 - val_loss: 335.3890\n",
      "Epoch 433/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0444 - val_loss: 335.4209\n",
      "Epoch 434/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0440 - val_loss: 335.4514\n",
      "Epoch 435/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0435 - val_loss: 335.4802\n",
      "Epoch 436/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0431 - val_loss: 335.5082\n",
      "Epoch 437/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 23.0427 - val_loss: 335.5349\n",
      "Epoch 438/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0424 - val_loss: 335.5606\n",
      "Epoch 439/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0421 - val_loss: 335.5854\n",
      "Epoch 440/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0417 - val_loss: 335.6088\n",
      "Epoch 441/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0414 - val_loss: 335.6314\n",
      "Epoch 442/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0412 - val_loss: 335.6528\n",
      "Epoch 443/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0409 - val_loss: 335.6738\n",
      "Epoch 444/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0407 - val_loss: 335.6935\n",
      "Epoch 445/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0405 - val_loss: 335.7123\n",
      "Epoch 446/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0403 - val_loss: 335.7306\n",
      "Epoch 447/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0401 - val_loss: 335.7479\n",
      "Epoch 448/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0400 - val_loss: 335.7645\n",
      "Epoch 449/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0398 - val_loss: 335.7802\n",
      "Epoch 450/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0397 - val_loss: 335.7954\n",
      "Epoch 451/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0396 - val_loss: 335.8098\n",
      "Epoch 452/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0395 - val_loss: 335.8234\n",
      "Epoch 453/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0394 - val_loss: 335.8365\n",
      "Epoch 454/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 23.0393 - val_loss: 335.8489\n",
      "Epoch 455/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0393 - val_loss: 335.8609\n",
      "Epoch 456/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0393 - val_loss: 335.8725\n",
      "Epoch 457/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0392 - val_loss: 335.8836\n",
      "Epoch 458/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0392 - val_loss: 335.8940\n",
      "Epoch 459/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0392 - val_loss: 335.9038\n",
      "Epoch 460/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0391 - val_loss: 335.9132\n",
      "Epoch 461/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0392 - val_loss: 335.9221\n",
      "Epoch 462/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0392 - val_loss: 335.9304\n",
      "Epoch 463/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 23.0392 - val_loss: 335.9387\n",
      "Epoch 464/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0392 - val_loss: 335.9464\n",
      "Epoch 465/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0392 - val_loss: 335.9537\n",
      "Epoch 466/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 23.0393 - val_loss: 335.9607\n",
      "Epoch 467/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0393 - val_loss: 335.9674\n",
      "Epoch 468/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0394 - val_loss: 335.9734\n",
      "Epoch 469/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0395 - val_loss: 335.9797\n",
      "Epoch 470/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0395 - val_loss: 335.9851\n",
      "Epoch 471/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0396 - val_loss: 335.9903\n",
      "Epoch 472/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0397 - val_loss: 335.9957\n",
      "Epoch 473/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0397 - val_loss: 336.0005\n",
      "Epoch 474/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0398 - val_loss: 336.0048\n",
      "Epoch 475/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0399 - val_loss: 336.0093\n",
      "Epoch 476/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0400 - val_loss: 336.0134\n",
      "Epoch 477/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0401 - val_loss: 336.0174\n",
      "Epoch 478/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0401 - val_loss: 336.0208\n",
      "Epoch 479/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 23.0402 - val_loss: 336.0241\n",
      "Epoch 480/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 23.0403 - val_loss: 336.0273\n",
      "Epoch 481/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0404 - val_loss: 336.0304\n",
      "Epoch 482/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0406 - val_loss: 336.0333\n",
      "Epoch 483/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0407 - val_loss: 336.0363\n",
      "Epoch 484/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0408 - val_loss: 336.0389\n",
      "Epoch 485/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0409 - val_loss: 336.0413\n",
      "Epoch 486/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0410 - val_loss: 336.0434\n",
      "Epoch 487/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0412 - val_loss: 336.0456\n",
      "Epoch 488/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0413 - val_loss: 336.0475\n",
      "Epoch 489/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0414 - val_loss: 336.0496\n",
      "Epoch 490/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0415 - val_loss: 336.0512\n",
      "Epoch 491/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0417 - val_loss: 336.0530\n",
      "Epoch 492/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0418 - val_loss: 336.0545\n",
      "Epoch 493/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0419 - val_loss: 336.0560\n",
      "Epoch 494/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0420 - val_loss: 336.0575\n",
      "Epoch 495/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0422 - val_loss: 336.0587\n",
      "Epoch 496/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0423 - val_loss: 336.0599\n",
      "Epoch 497/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0424 - val_loss: 336.0610\n",
      "Epoch 498/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0426 - val_loss: 336.0620\n",
      "Epoch 499/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0427 - val_loss: 336.0628\n",
      "Epoch 500/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.0428 - val_loss: 336.0636\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 417ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.79715920e+01, 5.79575864e+01, 5.79435808e+01, 5.79295752e+01,\n",
       "        5.79155696e+01, 5.79015640e+01, 5.78875584e+01, 5.78735528e+01,\n",
       "        5.78595471e+01, 5.78455416e+01, 5.78315360e+01, 5.78175303e+01,\n",
       "        5.78035247e+01, 5.77895191e+01, 5.77755135e+01, 5.77615079e+01,\n",
       "        5.77475023e+01, 5.77334967e+01, 5.77194911e+01, 5.77054855e+01,\n",
       "        5.76914799e+01, 5.76774743e+01, 5.76634687e+01, 5.76494631e+01,\n",
       "        5.76354575e+01, 5.76214519e+01, 5.76074463e+01, 5.75934407e+01,\n",
       "        5.75794351e+01, 5.75654295e+01, 5.75514239e+01, 5.75374183e+01,\n",
       "        5.75234127e+01, 5.75094071e+01, 5.74954015e+01, 5.74813959e+01,\n",
       "        5.74673903e+01, 5.74533847e+01, 5.74393791e+01, 5.74253735e+01,\n",
       "        5.74113679e+01, 5.73973623e+01, 5.73833567e+01, 5.73693511e+01,\n",
       "        5.73553455e+01, 5.73413399e+01, 5.73273343e+01, 6.29306256e+01,\n",
       "        6.28633987e+01, 6.27961718e+01, 6.27289449e+01, 6.25803688e+01,\n",
       "        6.23702848e+01, 6.21602008e+01, 6.19501167e+01, 6.17400327e+01,\n",
       "        6.15299487e+01, 6.13198646e+01, 6.11097806e+01, 6.08996966e+01,\n",
       "        6.06896125e+01, 6.04795285e+01, 6.02694444e+01, 6.00874883e+01,\n",
       "        5.99194211e+01, 5.97513539e+01, 5.95832866e+01, 5.94152194e+01,\n",
       "        5.92471522e+01, 5.90790850e+01, 5.89110177e+01, 5.87429505e+01,\n",
       "        5.85748833e+01, 6.61738815e+01, 0.00000000e+00, 2.63872800e-01,\n",
       "        1.20105090e-01, 6.19025170e-01, 0.00000000e+00, 1.01625216e+00,\n",
       "        5.03264771e+01, 0.00000000e+00, 4.12037313e-01, 1.97836608e-02,\n",
       "        0.00000000e+00, 1.07094742e-01, 7.93619275e-01, 3.88647765e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.12894547e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.82706046e-01, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55.21094771, 55.20441176, 55.19787582, 55.19133987, 55.18480392,\n",
       "       55.17826797, 55.17173203, 55.16519608, 55.15866013, 55.15212418,\n",
       "       55.14558824, 55.13905229, 55.13251634, 55.12598039, 55.11944444,\n",
       "       55.1129085 , 55.10637255, 55.0998366 , 55.09330065, 55.08676471,\n",
       "       55.08022876, 55.07369281, 55.06715686, 55.06062092, 55.05408497,\n",
       "       55.04754902, 55.04101307, 55.03447712, 55.02794118, 55.02140523,\n",
       "       55.01486928, 55.00833333, 55.00179739, 54.99526144, 54.98872549,\n",
       "       54.98218954, 54.97565359, 54.96911765, 54.9625817 , 54.95604575,\n",
       "       54.9495098 , 54.94297386, 54.93643791, 54.92990196, 54.92336601,\n",
       "       54.91683007, 54.91029412, 54.90375817, 54.89761905, 54.89201681,\n",
       "       54.88641457, 54.88081232, 54.87521008, 54.86960784, 54.8640056 ,\n",
       "       54.85840336, 54.85280112, 54.84719888, 54.84159664, 54.8359944 ,\n",
       "       54.83039216, 54.82478992, 54.81918768, 54.81358543, 54.80798319,\n",
       "       54.80238095, 54.79677871, 54.79117647, 54.78557423, 54.77997199,\n",
       "       54.77436975, 54.76876751, 54.76316527, 54.75756303, 54.75196078,\n",
       "       54.74635854, 54.7407563 , 54.73515406, 54.72955182, 54.72394958,\n",
       "       54.71834734, 54.7127451 , 54.70714286, 54.70154062, 54.69593838,\n",
       "       54.69033613, 54.68473389, 54.67913165, 54.67352941, 54.66792717,\n",
       "       54.66232493, 54.65672269, 54.65112045, 54.64551821, 54.63991597,\n",
       "       54.63431373, 54.62871148, 54.62310924, 54.617507  , 54.61190476])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.521592076444914\n",
      "16.56375738028432\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
