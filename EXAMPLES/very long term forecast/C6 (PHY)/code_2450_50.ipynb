{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2495    45.239352\n",
       "2496    45.229514\n",
       "2497    45.219676\n",
       "2498    45.209838\n",
       "2499    45.200000\n",
       "Name: C6, Length: 2500, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_2450_50.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2445     0.269228\n",
       "2446     0.000000\n",
       "2447     0.146272\n",
       "2448     0.000000\n",
       "2449     0.357824\n",
       "Name: C6, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(50)\n",
    "test\n",
    "training_set = training_set.head(2450)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-175)  var1(t-174)  var1(t-173)  var1(t-172)  var1(t-171)  \\\n",
      "175    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "176    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "177    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "178    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "179    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-170)  var1(t-169)  var1(t-168)  var1(t-167)  var1(t-166)  ...  \\\n",
      "175    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "176    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "177    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "178    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "179    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+45)  var2(t+45)  var1(t+46)  var2(t+46)  var1(t+47)  var2(t+47)  \\\n",
      "175   74.856279    0.000280   74.832937    0.000280   74.809594    0.000280   \n",
      "176   74.832937    0.000280   74.809594    0.000280   74.786251    0.000280   \n",
      "177   74.809594    0.000280   74.786251    0.000280   74.762908    0.000279   \n",
      "178   74.786251    0.000280   74.762908    0.000279   74.739566    0.000279   \n",
      "179   74.762908    0.000279   74.739566    0.000279   74.716223    0.000279   \n",
      "\n",
      "     var1(t+48)  var2(t+48)  var1(t+49)  var2(t+49)  \n",
      "175   74.786251    0.000280   74.762908    0.000279  \n",
      "176   74.762908    0.000279   74.739566    0.000279  \n",
      "177   74.739566    0.000279   74.716223    0.000279  \n",
      "178   74.716223    0.000279   74.692880    0.000279  \n",
      "179   74.692880    0.000279   74.669538    0.000279  \n",
      "\n",
      "[5 rows x 276 columns]\n",
      "Index(['var1(t-175)', 'var1(t-174)', 'var1(t-173)', 'var1(t-172)',\n",
      "       'var1(t-171)', 'var1(t-170)', 'var1(t-169)', 'var1(t-168)',\n",
      "       'var1(t-167)', 'var1(t-166)',\n",
      "       ...\n",
      "       'var1(t+45)', 'var2(t+45)', 'var1(t+46)', 'var2(t+46)', 'var1(t+47)',\n",
      "       'var2(t+47)', 'var1(t+48)', 'var2(t+48)', 'var1(t+49)', 'var2(t+49)'],\n",
      "      dtype='object', length=276)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 175, n_out = 50)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 176):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-150:]\n",
    "trainX = train[:,:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-150:]\n",
    "forecastX = forecast[:,:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 1, 126) (2225, 150) (1, 1, 126)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28/28 [==============================] - 3s 20ms/step - loss: 3428.8923 - val_loss: 1546.5048\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3174.4314 - val_loss: 1399.5354\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2894.9446 - val_loss: 1296.3777\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 2718.9585 - val_loss: 1228.6165\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 2577.7700 - val_loss: 1172.3701\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 2440.2271 - val_loss: 1117.5099\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2303.5781 - val_loss: 1066.1873\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2170.4265 - val_loss: 1019.8853\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2052.1172 - val_loss: 982.5939\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1940.1334 - val_loss: 945.5159\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1836.2743 - val_loss: 911.6049\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1737.4873 - val_loss: 877.9828\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1642.5645 - val_loss: 847.0158\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1545.6318 - val_loss: 816.2198\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1439.8086 - val_loss: 787.9049\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1355.2843 - val_loss: 773.4798\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1275.3900 - val_loss: 752.5640\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1205.1991 - val_loss: 739.8545\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1171.3361 - val_loss: 731.1317\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1068.8988 - val_loss: 712.1578\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1021.3947 - val_loss: 698.7426\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 951.4039 - val_loss: 687.9659\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 897.6384 - val_loss: 688.3765\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 847.9146 - val_loss: 680.1785\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 800.1094 - val_loss: 674.0261\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 765.7837 - val_loss: 669.0305\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 757.6642 - val_loss: 665.6063\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 719.3657 - val_loss: 664.7914\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 679.5278 - val_loss: 646.7770\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 637.5479 - val_loss: 626.9243\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 674.9726 - val_loss: 646.3704\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 590.1163 - val_loss: 663.4635\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 536.8726 - val_loss: 672.0089\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 511.7698 - val_loss: 675.2973\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 511.0154 - val_loss: 661.1572\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 451.4950 - val_loss: 659.4631\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 425.1683 - val_loss: 646.7622\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 407.4189 - val_loss: 681.8320\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 413.4485 - val_loss: 735.5493\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 404.9459 - val_loss: 768.9976\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 405.5294 - val_loss: 776.5543\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 375.2964 - val_loss: 790.2393\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 366.4201 - val_loss: 816.9016\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 392.7010 - val_loss: 803.7698\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 374.6896 - val_loss: 815.1121\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 356.5491 - val_loss: 878.6310\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 334.1939 - val_loss: 909.8789\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 320.5873 - val_loss: 894.1963\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 332.4333 - val_loss: 882.9991\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 314.5297 - val_loss: 876.5447\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 303.5069 - val_loss: 864.8117\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 315.2740 - val_loss: 908.7399\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 329.2726 - val_loss: 915.6403\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 349.7421 - val_loss: 927.6367\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 319.8121 - val_loss: 930.7659\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 301.6234 - val_loss: 1031.1603\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 311.7603 - val_loss: 1039.6329\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 302.9839 - val_loss: 1035.2009\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 303.2321 - val_loss: 1045.4417\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 305.0830 - val_loss: 1023.8742\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 297.5725 - val_loss: 1018.2934\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.1266 - val_loss: 1004.1970\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 271.5407 - val_loss: 980.0898\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.4140 - val_loss: 988.1898\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 268.2761 - val_loss: 984.4292\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 263.0459 - val_loss: 984.2415\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 257.4667 - val_loss: 982.2623\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.8141 - val_loss: 980.5411\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 238.6946 - val_loss: 977.0782\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 238.2097 - val_loss: 978.6716\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 235.4724 - val_loss: 973.9146\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 231.4902 - val_loss: 965.1796\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 227.6033 - val_loss: 955.6195\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 234.8406 - val_loss: 984.0107\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 235.0848 - val_loss: 997.4535\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 241.9371 - val_loss: 995.0622\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 236.2475 - val_loss: 973.3451\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 233.9763 - val_loss: 966.6491\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 217.5341 - val_loss: 909.6909\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 232.5205 - val_loss: 901.0414\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.8848 - val_loss: 922.8776\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 229.2953 - val_loss: 928.4935\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 226.1548 - val_loss: 929.2959\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 223.4433 - val_loss: 930.8278\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 229.4578 - val_loss: 967.7611\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 226.1404 - val_loss: 961.8137\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 222.3873 - val_loss: 956.2131\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 241.1255 - val_loss: 955.8764\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 237.3831 - val_loss: 950.4501\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 234.1752 - val_loss: 935.1759\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 235.6417 - val_loss: 917.3340\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 232.7764 - val_loss: 927.3807\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 230.5506 - val_loss: 936.0690\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 228.6093 - val_loss: 943.2914\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 226.6856 - val_loss: 947.0557\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 224.3983 - val_loss: 948.0065\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 222.8161 - val_loss: 946.6786\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 265.0278 - val_loss: 1032.2230\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 262.5150 - val_loss: 1042.3423\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 260.0706 - val_loss: 1043.9243\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 257.9826 - val_loss: 1050.5823\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 255.8970 - val_loss: 1054.8662\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 253.7677 - val_loss: 1057.3004\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 265.2813 - val_loss: 1059.3877\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 263.1454 - val_loss: 1068.5081\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 261.2062 - val_loss: 1073.5553\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 260.7225 - val_loss: 1088.3352\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 257.9767 - val_loss: 1085.8976\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 256.6676 - val_loss: 1090.4844\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 266.3195 - val_loss: 1142.4291\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 264.2541 - val_loss: 1145.8632\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 263.2946 - val_loss: 1147.6075\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 262.4311 - val_loss: 1149.4048\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 261.6247 - val_loss: 1150.7205\n",
      "Epoch 115/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 260.8279 - val_loss: 1152.2340\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 264.1636 - val_loss: 1163.2633\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 259.2257 - val_loss: 1140.9663\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 259.7726 - val_loss: 1151.1127\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 262.6349 - val_loss: 1077.7712\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 278.8158 - val_loss: 1050.5701\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 291.6979 - val_loss: 1096.7759\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 287.9520 - val_loss: 1103.4210\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 284.6437 - val_loss: 1117.4890\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 279.3368 - val_loss: 1114.6843\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 272.9274 - val_loss: 1105.9747\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 271.9626 - val_loss: 1114.7646\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 269.2620 - val_loss: 1114.8961\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 265.3949 - val_loss: 1117.8551\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 263.4609 - val_loss: 1112.3561\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 263.0215 - val_loss: 1121.1257\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 262.4586 - val_loss: 1098.8871\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 262.6389 - val_loss: 1093.0719\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 261.4596 - val_loss: 1060.8240\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 248.9940 - val_loss: 1034.5786\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 240.6766 - val_loss: 1027.2031\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 239.1796 - val_loss: 1034.2053\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.8632 - val_loss: 1063.8828\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.0090 - val_loss: 1051.0297\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.5756 - val_loss: 1048.0010\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 246.2887 - val_loss: 996.8445\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 268.4985 - val_loss: 957.5375\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 295.0046 - val_loss: 987.9663\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 284.9728 - val_loss: 998.8041\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 243.7292 - val_loss: 999.8791\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 237.6264 - val_loss: 997.4114\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 233.8537 - val_loss: 997.0266\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 228.3229 - val_loss: 994.1534\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 236.6587 - val_loss: 1032.9579\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 233.2686 - val_loss: 1025.6195\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 231.3684 - val_loss: 1022.4384\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 252.2801 - val_loss: 1050.4845\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 232.5722 - val_loss: 1031.7394\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 245.6167 - val_loss: 1021.8206\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 243.3330 - val_loss: 1014.2173\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 242.6861 - val_loss: 987.9026\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 242.2549 - val_loss: 992.5223\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 239.2288 - val_loss: 997.7939\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 234.7476 - val_loss: 986.7737\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 226.7753 - val_loss: 924.4125\n",
      "Epoch 160/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 236.7037 - val_loss: 890.4314\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 232.2563 - val_loss: 874.5046\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 260.9779 - val_loss: 890.3728\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.8853 - val_loss: 902.5884\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 243.9964 - val_loss: 904.4357\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.8998 - val_loss: 911.3279\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 232.8032 - val_loss: 923.3636\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 228.5824 - val_loss: 931.2015\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 225.6330 - val_loss: 941.0229\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 222.7455 - val_loss: 943.1701\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 242.9400 - val_loss: 939.8093\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 246.0598 - val_loss: 959.9464\n",
      "Epoch 172/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 235.7874 - val_loss: 966.7076\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 233.1460 - val_loss: 972.5875\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 230.8898 - val_loss: 983.5759\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 229.7754 - val_loss: 981.4972\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 228.5930 - val_loss: 998.5536\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 226.5635 - val_loss: 1003.9875\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 225.2997 - val_loss: 1007.6507\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 224.4849 - val_loss: 1011.6708\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 223.2992 - val_loss: 1014.4944\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 222.2545 - val_loss: 1016.1477\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 221.3673 - val_loss: 1019.0376\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 220.3534 - val_loss: 1019.5779\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 219.5862 - val_loss: 1019.6155\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 218.8416 - val_loss: 1019.3303\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 218.0471 - val_loss: 1019.1823\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 217.0696 - val_loss: 1018.8562\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 215.7739 - val_loss: 1010.0950\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 214.8783 - val_loss: 1009.8231\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 213.9005 - val_loss: 1000.0433\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 260.1181 - val_loss: 1008.6967\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 256.8036 - val_loss: 1020.9575\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 256.0990 - val_loss: 1043.2457\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 250.9343 - val_loss: 1042.8280\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 248.9594 - val_loss: 1057.3806\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 246.2352 - val_loss: 1061.1051\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 244.5707 - val_loss: 1070.2524\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 243.1309 - val_loss: 1075.2637\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.8005 - val_loss: 1080.6023\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.4574 - val_loss: 1085.4917\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 239.4266 - val_loss: 1084.8320\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 238.4870 - val_loss: 1090.0358\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.9385 - val_loss: 1094.2936\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.0610 - val_loss: 1096.2195\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 236.1564 - val_loss: 1092.3984\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 235.0546 - val_loss: 1089.0115\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 234.4328 - val_loss: 1086.8226\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 233.8572 - val_loss: 1087.8328\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 245.3809 - val_loss: 1112.6024\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 239.5919 - val_loss: 1101.3617\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.8245 - val_loss: 1119.8912\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 234.3003 - val_loss: 1088.7144\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 246.2485 - val_loss: 1146.6387\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.1624 - val_loss: 1113.7478\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 235.5665 - val_loss: 1101.5022\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 246.9550 - val_loss: 1101.6993\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 231.4843 - val_loss: 1094.4852\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 229.7704 - val_loss: 1089.8674\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 228.7820 - val_loss: 1084.7820\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 228.2247 - val_loss: 1083.6450\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.6541 - val_loss: 1083.1080\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.1545 - val_loss: 1081.5912\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 226.6752 - val_loss: 1079.5833\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 226.1905 - val_loss: 1079.5604\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 225.7160 - val_loss: 1076.8109\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 217.1841 - val_loss: 1028.0315\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 225.7666 - val_loss: 1032.2610\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 225.0060 - val_loss: 1037.0319\n",
      "Epoch 229/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 224.2378 - val_loss: 1037.8337\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 223.5149 - val_loss: 1039.7817\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 222.8593 - val_loss: 1040.5571\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 222.2217 - val_loss: 1045.1134\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 221.6359 - val_loss: 1042.6156\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 221.1030 - val_loss: 1044.4254\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 220.5031 - val_loss: 1046.6946\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 219.9418 - val_loss: 1046.1422\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 219.4277 - val_loss: 1045.7949\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 218.9021 - val_loss: 1045.6851\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 218.4059 - val_loss: 1044.2283\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 217.9172 - val_loss: 1042.2786\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 208.3337 - val_loss: 991.4514\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 218.3246 - val_loss: 998.7517\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 217.5460 - val_loss: 994.1147\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 242.6375 - val_loss: 996.9492\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.3591 - val_loss: 997.8813\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.0739 - val_loss: 1000.3378\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 235.0542 - val_loss: 1007.8680\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 233.4282 - val_loss: 1013.9890\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 231.9702 - val_loss: 1022.0984\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 230.8099 - val_loss: 1026.0892\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 229.7365 - val_loss: 1031.3029\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 231.4886 - val_loss: 1038.7928\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 228.5038 - val_loss: 1041.7354\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.2635 - val_loss: 1038.3613\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 226.5325 - val_loss: 1034.4430\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 210.6816 - val_loss: 963.0089\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 232.4444 - val_loss: 953.6561\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 231.4243 - val_loss: 962.4969\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 229.0090 - val_loss: 971.3329\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.1192 - val_loss: 981.1171\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 225.5692 - val_loss: 991.8293\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 224.4978 - val_loss: 993.1799\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 228.9453 - val_loss: 1011.5156\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 222.1574 - val_loss: 997.3331\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 234.3084 - val_loss: 1025.4635\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 224.8219 - val_loss: 1024.2532\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 223.6240 - val_loss: 1024.0287\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 222.9156 - val_loss: 1004.9631\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 211.6519 - val_loss: 981.4338\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 205.1762 - val_loss: 926.9479\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 212.2651 - val_loss: 957.6216\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 220.4276 - val_loss: 980.5622\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 218.6273 - val_loss: 975.0439\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 216.4368 - val_loss: 959.2116\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 205.9367 - val_loss: 938.5195\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.9528 - val_loss: 1066.6119\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 231.1064 - val_loss: 1066.0427\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 223.9620 - val_loss: 1039.2178\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 217.6538 - val_loss: 1003.7816\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 215.6586 - val_loss: 994.8588\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 247.4616 - val_loss: 1006.3685\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 238.5809 - val_loss: 1102.7285\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 228.1647 - val_loss: 1079.2316\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 223.7455 - val_loss: 1056.1483\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 218.6823 - val_loss: 1032.1753\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 235.0533 - val_loss: 1020.6245\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 234.0559 - val_loss: 1025.8734\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 232.6559 - val_loss: 1033.7932\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 231.8546 - val_loss: 1033.4347\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 230.8042 - val_loss: 1032.7882\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.0534 - val_loss: 1066.0216\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 236.1961 - val_loss: 1060.0773\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 235.1622 - val_loss: 1055.2894\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 232.5331 - val_loss: 1050.1117\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 230.6934 - val_loss: 1041.2032\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 229.4326 - val_loss: 1040.2605\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 228.1772 - val_loss: 1040.1702\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 227.0614 - val_loss: 1037.6118\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 234.7642 - val_loss: 1047.3955\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 224.1557 - val_loss: 1032.8374\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 249.1431 - val_loss: 1136.3929\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 245.4014 - val_loss: 1130.5743\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 244.7584 - val_loss: 1125.0348\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 243.5816 - val_loss: 1115.3767\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.2221 - val_loss: 1097.1516\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 231.7395 - val_loss: 1074.9481\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 230.5336 - val_loss: 1067.2826\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 228.1570 - val_loss: 1054.2006\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 226.2625 - val_loss: 1042.3511\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 224.5216 - val_loss: 1038.2378\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 222.3651 - val_loss: 1033.7815\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 220.6051 - val_loss: 1026.2310\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 217.9223 - val_loss: 1021.8760\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 217.2959 - val_loss: 1019.9078\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 216.7692 - val_loss: 1017.9667\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 216.3425 - val_loss: 1017.2834\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 215.9141 - val_loss: 1016.7881\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 215.4855 - val_loss: 1016.2607\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 215.0572 - val_loss: 1015.5167\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 214.6412 - val_loss: 1014.8469\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 214.2450 - val_loss: 1014.0513\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 213.8083 - val_loss: 1012.7516\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 213.4017 - val_loss: 1010.9122\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 218.7185 - val_loss: 1027.3346\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 217.7336 - val_loss: 1022.3173\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 217.2841 - val_loss: 1019.8632\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 216.2766 - val_loss: 1015.1824\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 215.0601 - val_loss: 1010.0855\n",
      "Epoch 329/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 214.4215 - val_loss: 1006.4663\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 227.9422 - val_loss: 1075.2791\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 225.3384 - val_loss: 1065.4707\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 221.6381 - val_loss: 1051.3257\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 220.4244 - val_loss: 1039.2292\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 217.7584 - val_loss: 1022.3871\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 215.8695 - val_loss: 1010.4677\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 213.9116 - val_loss: 1004.2182\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 211.7144 - val_loss: 995.2203\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 208.2395 - val_loss: 986.4380\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 207.3309 - val_loss: 982.7996\n",
      "Epoch 340/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 206.8816 - val_loss: 981.2359\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 206.3534 - val_loss: 979.7001\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 213.4651 - val_loss: 1003.4290\n",
      "Epoch 343/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 211.5288 - val_loss: 994.7083\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 208.9031 - val_loss: 988.7244\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 207.7534 - val_loss: 979.2177\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 206.4873 - val_loss: 982.9243\n",
      "Epoch 347/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 204.5303 - val_loss: 976.9625\n",
      "Epoch 348/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 203.8910 - val_loss: 971.3140\n",
      "Epoch 349/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 203.3392 - val_loss: 964.7242\n",
      "Epoch 350/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 209.5481 - val_loss: 962.2869\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 207.0054 - val_loss: 951.7115\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 203.2845 - val_loss: 946.2449\n",
      "Epoch 353/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 202.6683 - val_loss: 946.1547\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 202.1487 - val_loss: 947.1045\n",
      "Epoch 355/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 201.6725 - val_loss: 948.1306\n",
      "Epoch 356/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 201.1822 - val_loss: 948.1235\n",
      "Epoch 357/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 200.8023 - val_loss: 946.3445\n",
      "Epoch 358/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 200.2786 - val_loss: 948.4581\n",
      "Epoch 359/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 205.6799 - val_loss: 965.8209\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 203.4089 - val_loss: 958.4937\n",
      "Epoch 361/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 201.4582 - val_loss: 950.2817\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 198.8669 - val_loss: 945.7397\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 198.4752 - val_loss: 945.2674\n",
      "Epoch 364/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 191.4111 - val_loss: 893.0406\n",
      "Epoch 365/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 199.4657 - val_loss: 897.4089\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 198.7025 - val_loss: 901.8227\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 197.8941 - val_loss: 905.4504\n",
      "Epoch 368/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 197.2204 - val_loss: 908.2513\n",
      "Epoch 369/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 196.4968 - val_loss: 910.7371\n",
      "Epoch 370/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 195.8785 - val_loss: 899.7355\n",
      "Epoch 371/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 195.4452 - val_loss: 914.8713\n",
      "Epoch 372/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 194.8852 - val_loss: 917.1656\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 192.4718 - val_loss: 893.5998\n",
      "Epoch 374/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 191.9372 - val_loss: 870.3900\n",
      "Epoch 375/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 195.6880 - val_loss: 874.6870\n",
      "Epoch 376/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 194.6885 - val_loss: 879.5132\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 194.0307 - val_loss: 877.7120\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 187.7108 - val_loss: 838.1702\n",
      "Epoch 379/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 195.8890 - val_loss: 844.2927\n",
      "Epoch 380/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 194.5662 - val_loss: 851.2322\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 193.2872 - val_loss: 856.8088\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 192.1880 - val_loss: 862.2650\n",
      "Epoch 383/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 191.2055 - val_loss: 867.1697\n",
      "Epoch 384/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 190.4192 - val_loss: 869.5400\n",
      "Epoch 385/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 189.7007 - val_loss: 873.4921\n",
      "Epoch 386/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 188.8834 - val_loss: 876.4273\n",
      "Epoch 387/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 188.2337 - val_loss: 878.9951\n",
      "Epoch 388/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 187.6859 - val_loss: 883.6547\n",
      "Epoch 389/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 187.3313 - val_loss: 875.3665\n",
      "Epoch 390/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 229.6109 - val_loss: 1069.0947\n",
      "Epoch 391/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 229.6649 - val_loss: 1077.4518\n",
      "Epoch 392/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.0388 - val_loss: 1052.5190\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 221.5544 - val_loss: 1035.9252\n",
      "Epoch 394/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 215.2376 - val_loss: 1001.6429\n",
      "Epoch 395/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 213.9991 - val_loss: 993.5894\n",
      "Epoch 396/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 212.6037 - val_loss: 986.8262\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 207.4845 - val_loss: 964.7584\n",
      "Epoch 398/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 205.2726 - val_loss: 958.8624\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 208.0891 - val_loss: 964.3291\n",
      "Epoch 400/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 203.4223 - val_loss: 953.1013\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 202.7065 - val_loss: 949.8958\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 202.4068 - val_loss: 948.7404\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 202.0972 - val_loss: 948.0916\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 201.8979 - val_loss: 945.2772\n",
      "Epoch 405/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 201.5542 - val_loss: 944.6573\n",
      "Epoch 406/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 201.2007 - val_loss: 942.9368\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 211.1365 - val_loss: 951.1893\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 200.5394 - val_loss: 942.8408\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 200.2764 - val_loss: 942.1673\n",
      "Epoch 410/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 199.9810 - val_loss: 941.2728\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 199.6845 - val_loss: 940.3979\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 199.3997 - val_loss: 939.4604\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 199.1083 - val_loss: 938.5638\n",
      "Epoch 414/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 198.4692 - val_loss: 922.1064\n",
      "Epoch 415/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 199.5908 - val_loss: 936.8615\n",
      "Epoch 416/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 198.2543 - val_loss: 935.8311\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 197.9667 - val_loss: 934.8764\n",
      "Epoch 418/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 197.6847 - val_loss: 933.8042\n",
      "Epoch 419/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 197.4006 - val_loss: 932.8293\n",
      "Epoch 420/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 197.1185 - val_loss: 931.7368\n",
      "Epoch 421/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 196.8383 - val_loss: 930.7548\n",
      "Epoch 422/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 196.5534 - val_loss: 929.6428\n",
      "Epoch 423/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 196.2762 - val_loss: 928.6725\n",
      "Epoch 424/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 195.9892 - val_loss: 927.5825\n",
      "Epoch 425/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 195.7135 - val_loss: 926.4854\n",
      "Epoch 426/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 195.4322 - val_loss: 925.3908\n",
      "Epoch 427/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 195.1586 - val_loss: 924.3490\n",
      "Epoch 428/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 194.8745 - val_loss: 923.2697\n",
      "Epoch 429/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 194.6038 - val_loss: 922.1645\n",
      "Epoch 430/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 194.3317 - val_loss: 921.0629\n",
      "Epoch 431/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 194.0526 - val_loss: 919.9813\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 193.7217 - val_loss: 914.7895\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 228.4700 - val_loss: 916.5521\n",
      "Epoch 434/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 226.9626 - val_loss: 926.9089\n",
      "Epoch 435/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 225.3923 - val_loss: 934.6808\n",
      "Epoch 436/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 224.0477 - val_loss: 943.4664\n",
      "Epoch 437/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 222.9033 - val_loss: 946.9174\n",
      "Epoch 438/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 221.9307 - val_loss: 949.3662\n",
      "Epoch 439/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 221.0429 - val_loss: 952.5891\n",
      "Epoch 440/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 220.2795 - val_loss: 954.0945\n",
      "Epoch 441/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 219.5434 - val_loss: 955.8455\n",
      "Epoch 442/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 218.8779 - val_loss: 957.0280\n",
      "Epoch 443/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 218.2379 - val_loss: 955.4222\n",
      "Epoch 444/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 216.2368 - val_loss: 945.8908\n",
      "Epoch 445/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 215.6774 - val_loss: 947.7057\n",
      "Epoch 446/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 215.2568 - val_loss: 936.2231\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 273.9359 - val_loss: 951.8823\n",
      "Epoch 448/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 213.1825 - val_loss: 939.4375\n",
      "Epoch 449/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 272.0920 - val_loss: 937.9537\n",
      "Epoch 450/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 268.4325 - val_loss: 957.9898\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 264.0993 - val_loss: 976.4956\n",
      "Epoch 452/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 261.0810 - val_loss: 995.1305\n",
      "Epoch 453/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 258.8937 - val_loss: 1003.2454\n",
      "Epoch 454/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 257.6063 - val_loss: 1011.6896\n",
      "Epoch 455/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 246.8260 - val_loss: 961.3945\n",
      "Epoch 456/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 262.2294 - val_loss: 970.4255\n",
      "Epoch 457/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 259.5421 - val_loss: 983.2354\n",
      "Epoch 458/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 257.0520 - val_loss: 997.6118\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 255.0851 - val_loss: 1008.7020\n",
      "Epoch 460/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 253.5481 - val_loss: 1014.6342\n",
      "Epoch 461/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.2170 - val_loss: 1018.3741\n",
      "Epoch 462/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.0410 - val_loss: 1027.5308\n",
      "Epoch 463/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 249.8844 - val_loss: 1035.8431\n",
      "Epoch 464/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 249.0449 - val_loss: 1043.8141\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 248.2023 - val_loss: 1046.3140\n",
      "Epoch 466/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.4138 - val_loss: 1048.4232\n",
      "Epoch 467/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 246.7530 - val_loss: 1052.9596\n",
      "Epoch 468/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 245.9896 - val_loss: 1056.4728\n",
      "Epoch 469/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 245.4759 - val_loss: 1060.2382\n",
      "Epoch 470/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 244.9880 - val_loss: 1063.1294\n",
      "Epoch 471/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 244.5066 - val_loss: 1065.4681\n",
      "Epoch 472/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 244.0094 - val_loss: 1066.6517\n",
      "Epoch 473/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 243.6484 - val_loss: 1069.0645\n",
      "Epoch 474/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 243.3005 - val_loss: 1071.3491\n",
      "Epoch 475/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 242.9816 - val_loss: 1073.3402\n",
      "Epoch 476/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 242.6760 - val_loss: 1074.9501\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 242.3949 - val_loss: 1076.2396\n",
      "Epoch 478/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 242.1209 - val_loss: 1077.4166\n",
      "Epoch 479/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.8650 - val_loss: 1078.3091\n",
      "Epoch 480/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.6134 - val_loss: 1079.1194\n",
      "Epoch 481/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 241.3748 - val_loss: 1079.6980\n",
      "Epoch 482/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.1394 - val_loss: 1080.2014\n",
      "Epoch 483/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 240.9126 - val_loss: 1080.5350\n",
      "Epoch 484/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.6881 - val_loss: 1080.7772\n",
      "Epoch 485/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 240.4630 - val_loss: 1080.5381\n",
      "Epoch 486/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 240.2323 - val_loss: 1079.4884\n",
      "Epoch 487/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.0218 - val_loss: 1079.5209\n",
      "Epoch 488/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 239.8104 - val_loss: 1078.6221\n",
      "Epoch 489/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 239.6044 - val_loss: 1078.7738\n",
      "Epoch 490/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 239.3968 - val_loss: 1078.7289\n",
      "Epoch 491/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 239.1951 - val_loss: 1078.0642\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 238.9914 - val_loss: 1078.0199\n",
      "Epoch 493/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 238.7913 - val_loss: 1077.5537\n",
      "Epoch 494/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 238.5915 - val_loss: 1076.6125\n",
      "Epoch 495/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 238.3935 - val_loss: 1076.2532\n",
      "Epoch 496/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 238.1940 - val_loss: 1076.0441\n",
      "Epoch 497/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 237.9981 - val_loss: 1075.5027\n",
      "Epoch 498/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 237.8008 - val_loss: 1074.2809\n",
      "Epoch 499/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.6074 - val_loss: 1073.6384\n",
      "Epoch 500/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.4108 - val_loss: 1072.7522\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 438ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 126)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 126)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 186)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:150:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 5.79249066e+01, 1.00525665e+00, 5.81023109e+01,\n",
       "        5.77241597e+01, 5.73436084e+01, 5.79015640e+01, 5.75234127e+01,\n",
       "        6.08996966e+01, 7.93619275e-01, 0.00000000e+00, 5.16042829e-01,\n",
       "        5.79669234e+01, 6.86268800e-02, 5.81843277e+01, 5.77661765e+01,\n",
       "        5.73880252e+01, 5.79435808e+01, 5.75654295e+01, 6.15299487e+01,\n",
       "        1.97836610e-02, 8.75653630e-02, 5.97576737e-01, 5.51657982e+01,\n",
       "        4.79767400e-02, 4.61267640e-02, 7.53469706e-01, 3.80275846e-01,\n",
       "        4.24734175e-01, 0.00000000e+00, 5.80043602e+01, 0.00000000e+00,\n",
       "        2.37494081e-01, 0.00000000e+00, 2.02574909e-01, 0.00000000e+00,\n",
       "        5.61104894e-01, 8.51017684e-02, 8.90694559e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.14731598e+00, 4.73472685e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.11006266e-02, 4.91480380e-01,\n",
       "        0.00000000e+00, 2.57971823e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45.682066  , 45.67222792, 45.66238983, 45.65255175, 45.64271367,\n",
       "       45.63287559, 45.62303751, 45.61319943, 45.60336134, 45.59352326,\n",
       "       45.58368518, 45.5738471 , 45.56400902, 45.55417094, 45.54433286,\n",
       "       45.53449477, 45.52465669, 45.51481861, 45.50498053, 45.49514245,\n",
       "       45.48530437, 45.47546628, 45.4656282 , 45.45579012, 45.44595204,\n",
       "       45.43611396, 45.42627588, 45.41643779, 45.40659971, 45.39676163,\n",
       "       45.38692355, 45.37708547, 45.36724739, 45.35740931, 45.34757122,\n",
       "       45.33773314, 45.32789506, 45.31805698, 45.3082189 , 45.29838082,\n",
       "       45.28854273, 45.27870465, 45.26886657, 45.25902849, 45.24919041,\n",
       "       45.23935233, 45.22951424, 45.21967616, 45.20983808, 45.2       ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.87846937611805\n",
      "34.678325621571545\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
