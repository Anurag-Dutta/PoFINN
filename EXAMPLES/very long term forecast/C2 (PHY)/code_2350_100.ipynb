{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "2445    52.941156\n",
       "2446    52.925579\n",
       "2447    52.910002\n",
       "2448    52.894425\n",
       "2449    52.878848\n",
       "Name: C2, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c2_interpolated_2350_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "2345     0.000000\n",
       "2346     0.752908\n",
       "2347     0.000000\n",
       "2348     0.000000\n",
       "2349     0.000000\n",
       "Name: C2, Length: 2350, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2350)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.500000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.275910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.051821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.827731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.603641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     90.500000  0.000298\n",
       "1     90.275910  0.000298\n",
       "2     90.051821  0.000297\n",
       "3     89.827731  0.000297\n",
       "4     89.603641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.1552  # Value for C0\n",
    "K0 = -0.0026  # Value for K0\n",
    "K1 = -0.0004  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0102    # Value for b\n",
    "c = 2.8734    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    90.500000    90.275910    90.051821    89.827731    89.603641   \n",
      "351    90.275910    90.051821    89.827731    89.603641    89.379552   \n",
      "352    90.051821    89.827731    89.603641    89.379552    89.155462   \n",
      "353    89.827731    89.603641    89.379552    89.155462    88.931373   \n",
      "354    89.603641    89.379552    89.155462    88.931373    88.707283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.379552    89.155462    88.931373    88.707283    88.494958  ...   \n",
      "351    89.155462    88.931373    88.707283    88.494958    88.427731  ...   \n",
      "352    88.931373    88.707283    88.494958    88.427731    88.360504  ...   \n",
      "353    88.707283    88.494958    88.427731    88.360504    88.293277  ...   \n",
      "354    88.494958    88.427731    88.360504    88.293277    88.226050  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.071008    0.000263   79.054202    0.000263   79.037395    0.000263   \n",
      "351   79.054202    0.000263   79.037395    0.000263   79.020588    0.000262   \n",
      "352   79.037395    0.000263   79.020588    0.000262   79.003782    0.000262   \n",
      "353   79.020588    0.000262   79.003782    0.000262   78.986975    0.000262   \n",
      "354   79.003782    0.000262   78.986975    0.000262   78.970168    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.020588    0.000262   79.003782    0.000262  \n",
      "351   79.003782    0.000262   78.986975    0.000262  \n",
      "352   78.986975    0.000262   78.970168    0.000262  \n",
      "353   78.970168    0.000262   78.953361    0.000262  \n",
      "354   78.953361    0.000262   78.936555    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 1, 251) (1900, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 3s 22ms/step - loss: 4889.9019 - val_loss: 2658.0205\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4541.8042 - val_loss: 2502.2029\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4388.1196 - val_loss: 2421.6221\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4243.1885 - val_loss: 2350.5815\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4117.3716 - val_loss: 2285.7932\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3998.3003 - val_loss: 2224.4246\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3883.7271 - val_loss: 2166.1792\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3773.0740 - val_loss: 2110.5247\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3665.8022 - val_loss: 2057.2236\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3561.6873 - val_loss: 2006.4431\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3460.4915 - val_loss: 1957.8514\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3362.0693 - val_loss: 1911.3612\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3266.3071 - val_loss: 1866.8964\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3173.1099 - val_loss: 1824.3925\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3082.3940 - val_loss: 1783.7904\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2994.0898 - val_loss: 1745.0361\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2908.1328 - val_loss: 1708.0790\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2824.4656 - val_loss: 1672.8718\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2743.0310 - val_loss: 1639.3689\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2663.7788 - val_loss: 1607.5269\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2586.6611 - val_loss: 1577.3033\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2511.6309 - val_loss: 1548.6577\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2438.6438 - val_loss: 1521.5507\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2367.6565 - val_loss: 1495.9431\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2298.6279 - val_loss: 1471.7969\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2231.5173 - val_loss: 1449.0754\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2166.2861 - val_loss: 1427.7426\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2102.8950 - val_loss: 1407.7628\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2041.3030 - val_loss: 1388.9296\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1981.4833 - val_loss: 1371.6552\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1923.3898 - val_loss: 1355.5176\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1866.9905 - val_loss: 1340.5931\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1812.2500 - val_loss: 1326.8484\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1759.1334 - val_loss: 1314.2504\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1707.6072 - val_loss: 1302.7662\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1657.6382 - val_loss: 1292.3643\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1609.1932 - val_loss: 1283.0122\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1562.2397 - val_loss: 1274.6787\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1516.7457 - val_loss: 1267.3330\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1472.6793 - val_loss: 1260.9482\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1430.0094 - val_loss: 1255.4784\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1388.7041 - val_loss: 1250.9109\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1348.7345 - val_loss: 1247.2097\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1310.0692 - val_loss: 1244.3453\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1272.6788 - val_loss: 1242.2889\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1236.5339 - val_loss: 1241.0118\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1201.6052 - val_loss: 1240.4855\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1167.8643 - val_loss: 1240.6820\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1135.2823 - val_loss: 1241.5737\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1103.8315 - val_loss: 1243.1331\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1073.4843 - val_loss: 1245.3334\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1044.2128 - val_loss: 1248.1481\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1015.9902 - val_loss: 1251.5505\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 988.7900 - val_loss: 1255.5151\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 962.5859 - val_loss: 1260.0161\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 937.3509 - val_loss: 1265.0283\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 913.0605 - val_loss: 1270.5272\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 889.6887 - val_loss: 1276.4883\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 867.2108 - val_loss: 1282.8873\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 845.6016 - val_loss: 1289.7003\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 824.8373 - val_loss: 1296.9048\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 804.8932 - val_loss: 1304.4774\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 785.7465 - val_loss: 1312.3958\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 767.3735 - val_loss: 1320.6379\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 749.7512 - val_loss: 1329.1821\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 732.8571 - val_loss: 1338.0067\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 716.6688 - val_loss: 1347.0919\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 701.1646 - val_loss: 1356.4166\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 686.3226 - val_loss: 1365.9613\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 672.1221 - val_loss: 1375.7058\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 658.5423 - val_loss: 1385.6320\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 645.5623 - val_loss: 1395.7207\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 633.1625 - val_loss: 1405.9545\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 621.3229 - val_loss: 1416.3147\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 610.0247 - val_loss: 1426.7852\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 599.2483 - val_loss: 1437.3489\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 588.9755 - val_loss: 1447.9896\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 579.1882 - val_loss: 1458.6923\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 569.8685 - val_loss: 1469.4403\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 560.9991 - val_loss: 1480.2202\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 552.5630 - val_loss: 1491.0175\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 544.5435 - val_loss: 1501.8181\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 536.9245 - val_loss: 1512.6090\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 529.6902 - val_loss: 1523.3778\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 522.8251 - val_loss: 1534.1118\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 516.3143 - val_loss: 1544.7997\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 510.1429 - val_loss: 1555.4304\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 504.2969 - val_loss: 1565.9928\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 498.7623 - val_loss: 1576.4779\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 493.5257 - val_loss: 1586.8737\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 488.5742 - val_loss: 1597.1729\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 483.8949 - val_loss: 1607.3666\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 479.4755 - val_loss: 1617.4465\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 475.3042 - val_loss: 1627.4052\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 471.3693 - val_loss: 1637.2343\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 467.6599 - val_loss: 1646.9288\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 464.1648 - val_loss: 1656.4810\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 460.8741 - val_loss: 1665.8855\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 457.7775 - val_loss: 1675.1384\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 454.8652 - val_loss: 1684.2335\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 452.1280 - val_loss: 1693.1665\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 449.5571 - val_loss: 1701.9329\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 447.1435 - val_loss: 1710.5306\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 444.8790 - val_loss: 1718.9558\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 442.7558 - val_loss: 1727.2053\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 440.7664 - val_loss: 1735.2770\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 438.9030 - val_loss: 1743.1692\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 437.1589 - val_loss: 1750.8806\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 435.5274 - val_loss: 1758.4091\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 434.0020 - val_loss: 1765.7546\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 432.5767 - val_loss: 1772.9165\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 431.2456 - val_loss: 1779.8940\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 430.0031 - val_loss: 1786.6879\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 428.8441 - val_loss: 1793.2985\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 427.7632 - val_loss: 1799.7258\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 426.7560 - val_loss: 1805.9714\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 425.8178 - val_loss: 1812.0356\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 424.9443 - val_loss: 1817.9214\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 424.1315 - val_loss: 1823.6288\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 423.3755 - val_loss: 1829.1606\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 422.6725 - val_loss: 1834.5190\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 422.0192 - val_loss: 1839.7042\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 421.4123 - val_loss: 1844.7219\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 420.8488 - val_loss: 1849.5734\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 420.3257 - val_loss: 1854.2595\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 419.8403 - val_loss: 1858.7849\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 419.3902 - val_loss: 1863.1530\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 418.9727 - val_loss: 1867.3656\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 418.5857 - val_loss: 1871.4258\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 418.2271 - val_loss: 1875.3380\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 417.8949 - val_loss: 1879.1047\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 417.5872 - val_loss: 1882.7292\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 417.3022 - val_loss: 1886.2161\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 417.0382 - val_loss: 1889.5664\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 416.7943 - val_loss: 1892.7865\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 416.5682 - val_loss: 1895.8783\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 416.3592 - val_loss: 1898.8464\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 416.1657 - val_loss: 1901.6957\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 415.9866 - val_loss: 1904.4318\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 415.8211 - val_loss: 1907.0773\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 415.8878 - val_loss: 1911.2292\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 415.4304 - val_loss: 1911.7552\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 415.3961 - val_loss: 1914.0453\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 415.2749 - val_loss: 1916.2357\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 415.1628 - val_loss: 1918.3301\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 415.0591 - val_loss: 1920.3295\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 414.9632 - val_loss: 1922.2397\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 414.8744 - val_loss: 1924.0624\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 414.7922 - val_loss: 1925.8008\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 414.7162 - val_loss: 1927.4589\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 414.6458 - val_loss: 1929.0383\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 414.5808 - val_loss: 1930.5437\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 414.5206 - val_loss: 1931.9762\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 414.4649 - val_loss: 1933.3406\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 414.4132 - val_loss: 1934.6373\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 414.3655 - val_loss: 1935.8706\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 414.3214 - val_loss: 1937.0432\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 414.2803 - val_loss: 1938.1569\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 414.2424 - val_loss: 1939.2145\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 414.2074 - val_loss: 1940.2197\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 414.1747 - val_loss: 1941.1720\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 414.1446 - val_loss: 1942.0765\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 414.1167 - val_loss: 1942.9329\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 414.0909 - val_loss: 1943.7451\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 414.0670 - val_loss: 1944.5150\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 414.0448 - val_loss: 1945.2434\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 414.0242 - val_loss: 1945.9336\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 414.0051 - val_loss: 1946.5865\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.9875 - val_loss: 1947.2037\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.9711 - val_loss: 1947.7875\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.9561 - val_loss: 1948.3413\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.9420 - val_loss: 1948.8621\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.9290 - val_loss: 1949.3552\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 413.9169 - val_loss: 1949.8210\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.9059 - val_loss: 1950.2603\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8956 - val_loss: 1950.6741\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8861 - val_loss: 1951.0658\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8772 - val_loss: 1951.4346\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8692 - val_loss: 1951.7823\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.8616 - val_loss: 1952.1102\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.8548 - val_loss: 1952.4192\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.8483 - val_loss: 1952.7107\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8423 - val_loss: 1952.9835\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8371 - val_loss: 1953.2415\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.8321 - val_loss: 1953.4844\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8275 - val_loss: 1953.7122\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.8233 - val_loss: 1953.9266\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.8195 - val_loss: 1954.1293\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.8159 - val_loss: 1954.3187\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.8127 - val_loss: 1954.4973\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 413.8098 - val_loss: 1954.6652\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.8072 - val_loss: 1954.8217\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.8047 - val_loss: 1954.9701\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.8026 - val_loss: 1955.1085\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 413.8006 - val_loss: 1955.2386\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 413.7987 - val_loss: 1955.3608\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7971 - val_loss: 1955.4750\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7956 - val_loss: 1955.5823\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7944 - val_loss: 1955.6829\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7932 - val_loss: 1955.7778\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 413.7922 - val_loss: 1955.8661\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7913 - val_loss: 1955.9492\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7907 - val_loss: 1956.0266\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7900 - val_loss: 1956.1002\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7894 - val_loss: 1956.1675\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7890 - val_loss: 1956.2314\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7886 - val_loss: 1956.2917\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7884 - val_loss: 1956.3470\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7881 - val_loss: 1956.3997\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7879 - val_loss: 1956.4478\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7879 - val_loss: 1956.4943\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7878 - val_loss: 1956.5369\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7879 - val_loss: 1956.5759\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7880 - val_loss: 1956.6138\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7880 - val_loss: 1956.6481\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7883 - val_loss: 1956.6804\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7884 - val_loss: 1956.7115\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7886 - val_loss: 1956.7404\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7888 - val_loss: 1956.7665\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7893 - val_loss: 1956.7911\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7896 - val_loss: 1956.8147\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7899 - val_loss: 1956.8372\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.7901 - val_loss: 1956.8562\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7906 - val_loss: 1956.8754\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7909 - val_loss: 1956.8950\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7914 - val_loss: 1956.9109\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7917 - val_loss: 1956.9291\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.7921 - val_loss: 1956.9441\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7927 - val_loss: 1956.9606\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 413.7931 - val_loss: 1956.9779\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 413.7935 - val_loss: 1956.9977\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.7939 - val_loss: 1957.0233\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.7945 - val_loss: 1956.9441\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7950 - val_loss: 1957.7224\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7953 - val_loss: 1957.6805\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7958 - val_loss: 1957.6897\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.7963 - val_loss: 1957.6998\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7966 - val_loss: 1957.7059\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7972 - val_loss: 1957.7136\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7975 - val_loss: 1957.7217\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7980 - val_loss: 1957.7277\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7984 - val_loss: 1957.7338\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7990 - val_loss: 1957.7396\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.7993 - val_loss: 1957.7456\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.7999 - val_loss: 1957.7509\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8003 - val_loss: 1957.7557\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8008 - val_loss: 1957.7599\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8011 - val_loss: 1957.7646\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8016 - val_loss: 1957.7679\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8021 - val_loss: 1957.7726\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8024 - val_loss: 1957.7764\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8028 - val_loss: 1957.7799\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8032 - val_loss: 1957.7827\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8037 - val_loss: 1957.7859\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8040 - val_loss: 1957.7894\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8045 - val_loss: 1957.7931\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 413.8048 - val_loss: 1957.7954\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 413.8052 - val_loss: 1957.7975\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8055 - val_loss: 1957.8000\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8059 - val_loss: 1957.8026\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8063 - val_loss: 1957.8049\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8066 - val_loss: 1957.8076\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8069 - val_loss: 1957.8105\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8073 - val_loss: 1957.8125\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8077 - val_loss: 1957.8147\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8080 - val_loss: 1957.8159\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8083 - val_loss: 1957.8177\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8085 - val_loss: 1957.8196\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8089 - val_loss: 1957.8210\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8092 - val_loss: 1957.8230\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8095 - val_loss: 1957.8250\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8098 - val_loss: 1957.8267\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8100 - val_loss: 1957.8280\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8104 - val_loss: 1957.8297\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8107 - val_loss: 1957.8314\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8109 - val_loss: 1957.8333\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8113 - val_loss: 1957.8351\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8114 - val_loss: 1957.8363\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8117 - val_loss: 1957.8375\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8119 - val_loss: 1957.8389\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8122 - val_loss: 1957.8405\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8124 - val_loss: 1957.8418\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8127 - val_loss: 1957.8431\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 413.8129 - val_loss: 1957.8444\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8131 - val_loss: 1957.8459\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8134 - val_loss: 1957.8475\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8135 - val_loss: 1957.8486\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8138 - val_loss: 1957.8507\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8140 - val_loss: 1957.8519\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8142 - val_loss: 1957.8540\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8144 - val_loss: 1957.8557\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8145 - val_loss: 1957.8569\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8147 - val_loss: 1957.8583\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8148 - val_loss: 1957.8594\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8150 - val_loss: 1957.8605\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8152 - val_loss: 1957.8621\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8154 - val_loss: 1957.8630\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8156 - val_loss: 1957.8650\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8157 - val_loss: 1957.8661\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8158 - val_loss: 1957.8678\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8160 - val_loss: 1957.8688\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8162 - val_loss: 1957.8698\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8164 - val_loss: 1957.8706\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8165 - val_loss: 1957.8722\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8166 - val_loss: 1957.8732\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8168 - val_loss: 1957.8746\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8169 - val_loss: 1957.8760\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8171 - val_loss: 1957.8773\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8172 - val_loss: 1957.8787\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8174 - val_loss: 1957.8801\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8175 - val_loss: 1957.8815\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 413.8176 - val_loss: 1957.8822\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8177 - val_loss: 1957.8837\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8179 - val_loss: 1957.8854\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8179 - val_loss: 1957.8865\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8180 - val_loss: 1957.8878\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8181 - val_loss: 1957.8893\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8183 - val_loss: 1957.8910\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8183 - val_loss: 1957.8925\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8184 - val_loss: 1957.8934\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8186 - val_loss: 1957.8950\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8187 - val_loss: 1957.8964\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8187 - val_loss: 1957.8978\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8188 - val_loss: 1957.8988\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8189 - val_loss: 1957.9005\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8191 - val_loss: 1957.9021\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8191 - val_loss: 1957.9036\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8192 - val_loss: 1957.9048\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8192 - val_loss: 1957.9058\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8193 - val_loss: 1957.9072\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8194 - val_loss: 1957.9084\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8195 - val_loss: 1957.9099\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8195 - val_loss: 1957.9109\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8196 - val_loss: 1957.9125\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8196 - val_loss: 1957.9142\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8198 - val_loss: 1957.9158\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8198 - val_loss: 1957.9171\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 413.8199 - val_loss: 1957.9185\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8199 - val_loss: 1957.9197\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8200 - val_loss: 1957.9214\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8202 - val_loss: 1957.9230\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8202 - val_loss: 1957.9242\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8202 - val_loss: 1957.9257\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8203 - val_loss: 1957.9266\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8204 - val_loss: 1957.9290\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8204 - val_loss: 1957.9305\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8204 - val_loss: 1957.9319\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8205 - val_loss: 1957.9338\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8206 - val_loss: 1957.9359\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8206 - val_loss: 1957.9374\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8207 - val_loss: 1957.9388\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8206 - val_loss: 1957.9404\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8206 - val_loss: 1957.9417\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8207 - val_loss: 1957.9431\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8208 - val_loss: 1957.9441\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8208 - val_loss: 1957.9456\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8209 - val_loss: 1957.9470\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8209 - val_loss: 1957.9484\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8210 - val_loss: 1957.9500\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8210 - val_loss: 1957.9513\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8210 - val_loss: 1957.9530\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8211 - val_loss: 1957.9546\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8211 - val_loss: 1957.9559\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 413.8212 - val_loss: 1957.9575\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8212 - val_loss: 1957.9594\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8213 - val_loss: 1957.9611\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8213 - val_loss: 1957.9626\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8214 - val_loss: 1957.9644\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8214 - val_loss: 1957.9661\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8214 - val_loss: 1957.9678\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8214 - val_loss: 1957.9696\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8214 - val_loss: 1957.9711\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8214 - val_loss: 1957.9730\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8215 - val_loss: 1957.9745\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8215 - val_loss: 1957.9764\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8215 - val_loss: 1957.9784\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8215 - val_loss: 1957.9797\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8215 - val_loss: 1957.9810\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8216 - val_loss: 1957.9822\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8216 - val_loss: 1957.9843\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8216 - val_loss: 1957.9857\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8217 - val_loss: 1957.9875\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8218 - val_loss: 1957.9895\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8218 - val_loss: 1957.9918\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8217 - val_loss: 1957.9939\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8217 - val_loss: 1957.9954\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8218 - val_loss: 1957.9973\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 413.8218 - val_loss: 1957.9990\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8219 - val_loss: 1958.0009\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8219 - val_loss: 1958.0027\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8218 - val_loss: 1958.0044\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8218 - val_loss: 1958.0060\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8218 - val_loss: 1958.0076\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8219 - val_loss: 1958.0089\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8219 - val_loss: 1958.0105\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8219 - val_loss: 1958.0122\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8219 - val_loss: 1958.0143\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8220 - val_loss: 1958.0161\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8220 - val_loss: 1958.0181\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8220 - val_loss: 1958.0204\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8219 - val_loss: 1958.0212\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8220 - val_loss: 1958.0221\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.7480 - val_loss: 1956.9744\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.9301 - val_loss: 1957.1349\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8986 - val_loss: 1957.2262\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8859 - val_loss: 1957.2997\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8782 - val_loss: 1957.3625\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8725 - val_loss: 1957.4176\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8684 - val_loss: 1957.4694\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8649 - val_loss: 1957.5148\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 413.8621 - val_loss: 1957.5569\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8596 - val_loss: 1957.5948\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8576 - val_loss: 1957.6306\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8556 - val_loss: 1957.6632\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8539 - val_loss: 1957.6924\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8526 - val_loss: 1957.7207\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8512 - val_loss: 1957.7458\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8500 - val_loss: 1957.7694\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8489 - val_loss: 1957.7915\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8480 - val_loss: 1957.8121\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8470 - val_loss: 1957.8306\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8462 - val_loss: 1957.8479\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8454 - val_loss: 1957.8630\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8447 - val_loss: 1957.8779\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8441 - val_loss: 1957.8926\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8435 - val_loss: 1957.9053\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8430 - val_loss: 1957.9177\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8423 - val_loss: 1957.9290\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.8420 - val_loss: 1957.9393\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8416 - val_loss: 1957.9503\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8411 - val_loss: 1957.9592\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8408 - val_loss: 1957.9674\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8404 - val_loss: 1957.9757\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 413.8401 - val_loss: 1957.9833\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8397 - val_loss: 1957.9901\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8395 - val_loss: 1957.9966\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8392 - val_loss: 1958.0027\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8390 - val_loss: 1958.0090\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8388 - val_loss: 1958.0143\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8386 - val_loss: 1958.0203\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8383 - val_loss: 1958.0265\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8382 - val_loss: 1958.0308\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8380 - val_loss: 1958.0359\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8378 - val_loss: 1958.0413\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8376 - val_loss: 1958.0455\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8375 - val_loss: 1958.0496\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8373 - val_loss: 1958.0540\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 413.8372 - val_loss: 1958.0586\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8370 - val_loss: 1958.0620\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8369 - val_loss: 1958.0662\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8368 - val_loss: 1958.0695\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8366 - val_loss: 1958.0724\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8365 - val_loss: 1958.0753\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8364 - val_loss: 1958.0778\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8363 - val_loss: 1958.0804\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8363 - val_loss: 1958.0828\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 413.8362 - val_loss: 1958.0856\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8361 - val_loss: 1958.0884\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8360 - val_loss: 1958.0906\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8359 - val_loss: 1958.0928\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8359 - val_loss: 1958.0952\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8358 - val_loss: 1958.0977\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8357 - val_loss: 1958.1002\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8357 - val_loss: 1958.1027\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8356 - val_loss: 1958.1046\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8356 - val_loss: 1958.1069\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8355 - val_loss: 1958.1090\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8354 - val_loss: 1958.1112\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8354 - val_loss: 1958.1128\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8354 - val_loss: 1958.1150\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8354 - val_loss: 1958.1166\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8354 - val_loss: 1958.1188\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8353 - val_loss: 1958.1207\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8353 - val_loss: 1958.1223\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8352 - val_loss: 1958.1244\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8352 - val_loss: 1958.1261\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8351 - val_loss: 1958.1279\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8351 - val_loss: 1958.1299\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 413.8351 - val_loss: 1958.1317\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8351 - val_loss: 1958.1335\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8350 - val_loss: 1958.1354\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8350 - val_loss: 1958.1372\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8350 - val_loss: 1958.1390\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8350 - val_loss: 1958.1410\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8350 - val_loss: 1958.1434\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8349 - val_loss: 1958.1453\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8349 - val_loss: 1958.1472\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8349 - val_loss: 1958.1493\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8349 - val_loss: 1958.1516\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8348 - val_loss: 1958.1534\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8348 - val_loss: 1958.1554\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8348 - val_loss: 1958.1572\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8348 - val_loss: 1958.1594\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8347 - val_loss: 1958.1614\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8347 - val_loss: 1958.1632\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8347 - val_loss: 1958.1648\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8347 - val_loss: 1958.1665\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 413.8346 - val_loss: 1958.1682\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8346 - val_loss: 1958.1699\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.8346 - val_loss: 1958.1719\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.1552, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0026, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0004, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0102, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.8734, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 531ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.09782073e+01, 7.08976891e+01, 7.08220588e+01, 7.07464286e+01,\n",
       "        7.64097366e+01, 0.00000000e+00, 0.00000000e+00, 2.90957689e-01,\n",
       "        0.00000000e+00, 9.80372650e-02, 3.11266243e-01, 0.00000000e+00,\n",
       "        1.20284572e-01, 7.08304622e+01, 7.07548319e+01, 7.06792017e+01,\n",
       "        0.00000000e+00, 2.92133838e-01, 7.10200373e+01, 7.09393651e+01,\n",
       "        7.08612745e+01, 7.07856443e+01, 7.07100140e+01, 7.41377918e+01,\n",
       "        7.31545985e+01, 7.19584314e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.53423450e-01, 7.07408263e+01, 7.45123249e+01, 7.35551587e+01,\n",
       "        7.24760784e+01, 3.73652940e-01, 7.30332166e+01, 7.18015686e+01,\n",
       "        7.10887582e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 8.96524251e-01, 9.36779916e-01,\n",
       "        2.18388677e-01, 0.00000000e+00, 0.00000000e+00, 7.22407843e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.82640300e-02, 7.07576330e+01,\n",
       "        7.06820028e+01, 7.37736461e+01, 7.27584314e+01, 7.14878431e+01,\n",
       "        7.32517040e+01, 7.20839216e+01, 7.11425397e+01, 1.65300410e-01,\n",
       "        5.36403780e-01, 1.91368850e-01, 7.20054902e+01, 0.00000000e+00,\n",
       "        7.26015686e+01, 7.13309804e+01, 7.09991223e+01, 7.19270588e+01,\n",
       "        7.11126611e+01, 7.08724790e+01, 2.27639120e-02, 1.04988220e-02,\n",
       "        0.00000000e+00, 6.59078369e+01, 3.17293674e-01, 1.13219619e+00,\n",
       "        2.59423435e-01, 3.85792700e-02, 3.00421208e-01, 0.00000000e+00,\n",
       "        6.70597534e+01, 7.52156317e-01, 1.59010077e+00, 7.20153600e-02,\n",
       "        0.00000000e+00, 7.21911669e-01, 3.10237676e-01, 5.40590703e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.64123344e-01, 8.70277435e-02,\n",
       "        2.17658967e-01, 4.51374233e-01, 4.11783934e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.16940394e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54.42096741, 54.40539045, 54.38981349, 54.37423652, 54.35865956,\n",
       "       54.3430826 , 54.32750564, 54.31192867, 54.29635171, 54.28077475,\n",
       "       54.26519779, 54.24962082, 54.23404386, 54.2184669 , 54.20288994,\n",
       "       54.18731297, 54.17173601, 54.15615905, 54.14058209, 54.12500512,\n",
       "       54.10942816, 54.0938512 , 54.07827424, 54.06269727, 54.04712031,\n",
       "       54.03154335, 54.01596639, 54.00038942, 53.98481246, 53.9692355 ,\n",
       "       53.95365854, 53.93808157, 53.92250461, 53.90692765, 53.89135069,\n",
       "       53.87577372, 53.86019676, 53.8446198 , 53.82904284, 53.81346587,\n",
       "       53.79788891, 53.78231195, 53.76673499, 53.75115802, 53.73558106,\n",
       "       53.7200041 , 53.70442714, 53.68885017, 53.67327321, 53.65769625,\n",
       "       53.64211929, 53.62654232, 53.61096536, 53.5953884 , 53.57981144,\n",
       "       53.56423447, 53.54865751, 53.53308055, 53.51750359, 53.50192662,\n",
       "       53.48634966, 53.4707727 , 53.45519574, 53.43961877, 53.42404181,\n",
       "       53.40846485, 53.39288789, 53.37731092, 53.36173396, 53.346157  ,\n",
       "       53.33058004, 53.31500307, 53.29942611, 53.28384915, 53.26827219,\n",
       "       53.25269522, 53.23711826, 53.2215413 , 53.20596434, 53.19038737,\n",
       "       53.17481041, 53.15923345, 53.14365649, 53.12807952, 53.11250256,\n",
       "       53.0969256 , 53.08134864, 53.06577167, 53.05019471, 53.03461775,\n",
       "       53.01904079, 53.00346382, 52.98788686, 52.9723099 , 52.95673294,\n",
       "       52.94115597, 52.92557901, 52.91000205, 52.89442509, 52.87884812])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.512029362456985\n",
      "38.73007002920227\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
