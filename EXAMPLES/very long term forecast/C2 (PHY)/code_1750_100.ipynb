{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "1845    65.224440\n",
       "1846    65.201097\n",
       "1847    65.177754\n",
       "1848    65.154412\n",
       "1849    65.131069\n",
       "Name: C2, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c2_interpolated_1750_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "1745     0.000000\n",
       "1746     0.000000\n",
       "1747     0.663506\n",
       "1748     0.750860\n",
       "1749     0.370620\n",
       "Name: C2, Length: 1750, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1750)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.500000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.275910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.051821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.827731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.603641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     90.500000  0.000298\n",
       "1     90.275910  0.000298\n",
       "2     90.051821  0.000297\n",
       "3     89.827731  0.000297\n",
       "4     89.603641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.1552  # Value for C0\n",
    "K0 = -0.0026  # Value for K0\n",
    "K1 = -0.0004  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0102    # Value for b\n",
    "c = 2.8734    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    90.500000    90.275910    90.051821    89.827731    89.603641   \n",
      "351    90.275910    90.051821    89.827731    89.603641    89.379552   \n",
      "352    90.051821    89.827731    89.603641    89.379552    89.155462   \n",
      "353    89.827731    89.603641    89.379552    89.155462    88.931373   \n",
      "354    89.603641    89.379552    89.155462    88.931373    88.707283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.379552    89.155462    88.931373    88.707283    88.494958  ...   \n",
      "351    89.155462    88.931373    88.707283    88.494958    88.427731  ...   \n",
      "352    88.931373    88.707283    88.494958    88.427731    88.360504  ...   \n",
      "353    88.707283    88.494958    88.427731    88.360504    88.293277  ...   \n",
      "354    88.494958    88.427731    88.360504    88.293277    88.226050  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.071008    0.000263   79.054202    0.000263   79.037395    0.000263   \n",
      "351   79.054202    0.000263   79.037395    0.000263   79.020588    0.000262   \n",
      "352   79.037395    0.000263   79.020588    0.000262   79.003782    0.000262   \n",
      "353   79.020588    0.000262   79.003782    0.000262   78.986975    0.000262   \n",
      "354   79.003782    0.000262   78.986975    0.000262   78.970168    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.020588    0.000262   79.003782    0.000262  \n",
      "351   79.003782    0.000262   78.986975    0.000262  \n",
      "352   78.986975    0.000262   78.970168    0.000262  \n",
      "353   78.970168    0.000262   78.953361    0.000262  \n",
      "354   78.953361    0.000262   78.936555    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 1, 251) (1300, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 3s 35ms/step - loss: 5587.1084 - val_loss: 3908.9001\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5490.8979 - val_loss: 3876.1492\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5434.6987 - val_loss: 3835.7842\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 5375.6870 - val_loss: 3803.3147\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 5322.7256 - val_loss: 3771.3889\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5270.5430 - val_loss: 3740.0791\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5205.5161 - val_loss: 3696.6804\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5149.9951 - val_loss: 3663.4497\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5096.1675 - val_loss: 3630.9568\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5043.2529 - val_loss: 3599.0254\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4991.0854 - val_loss: 3567.5579\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4939.5503 - val_loss: 3536.4932\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4888.5781 - val_loss: 3505.7925\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4838.1221 - val_loss: 3475.4299\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4788.1514 - val_loss: 3445.3862\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4738.6406 - val_loss: 3415.6482\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4689.5757 - val_loss: 3386.2046\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4640.9395 - val_loss: 3357.0464\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4592.7227 - val_loss: 3328.1665\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4544.9155 - val_loss: 3299.5586\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4497.5103 - val_loss: 3271.2180\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 4450.4980 - val_loss: 3243.1399\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4403.8755 - val_loss: 3215.3203\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4357.6348 - val_loss: 3187.7551\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4311.7715 - val_loss: 3160.4414\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4266.2837 - val_loss: 3133.3765\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4221.1636 - val_loss: 3106.5564\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4176.4087 - val_loss: 3079.9797\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4132.0161 - val_loss: 3053.6438\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4087.9822 - val_loss: 3027.5452\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4044.3030 - val_loss: 3001.6829\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4000.9749 - val_loss: 2976.0547\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3957.9968 - val_loss: 2950.6582\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3915.3647 - val_loss: 2925.4912\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3873.0762 - val_loss: 2900.5522\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3831.1282 - val_loss: 2875.8394\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3789.5181 - val_loss: 2851.3511\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3748.2444 - val_loss: 2827.0854\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3707.3032 - val_loss: 2803.0405\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3666.6934 - val_loss: 2779.2148\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3626.4121 - val_loss: 2755.6077\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3586.4573 - val_loss: 2732.2161\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3546.8264 - val_loss: 2709.0396\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 3507.5178 - val_loss: 2686.0764\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3468.5291 - val_loss: 2663.3247\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3429.8579 - val_loss: 2640.7837\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3391.5024 - val_loss: 2618.4514\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3353.4609 - val_loss: 2596.3269\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3315.7307 - val_loss: 2574.4080\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3278.3101 - val_loss: 2552.6946\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3241.1973 - val_loss: 2531.1833\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3204.3899 - val_loss: 2509.8752\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3167.8865 - val_loss: 2488.7678\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3131.6855 - val_loss: 2467.8601\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3095.7849 - val_loss: 2447.1504\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 3060.1821 - val_loss: 2426.6379\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3024.8760 - val_loss: 2406.3208\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2989.8647 - val_loss: 2386.1985\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2955.1465 - val_loss: 2366.2693\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2920.7192 - val_loss: 2346.5325\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2886.5818 - val_loss: 2326.9863\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2852.7319 - val_loss: 2307.6301\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2819.1680 - val_loss: 2288.4622\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2785.8884 - val_loss: 2269.4817\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2752.8926 - val_loss: 2250.6875\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2720.1768 - val_loss: 2232.0786\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2687.7407 - val_loss: 2213.6533\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2655.5825 - val_loss: 2195.4111\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2623.7004 - val_loss: 2177.3506\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2592.0925 - val_loss: 2159.4700\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2560.7578 - val_loss: 2141.7693\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2529.6938 - val_loss: 2124.2468\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2498.8999 - val_loss: 2106.9019\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2468.3748 - val_loss: 2089.7329\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2438.1162 - val_loss: 2072.7395\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2408.1226 - val_loss: 2055.9199\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2378.3923 - val_loss: 2039.2733\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2348.9246 - val_loss: 2022.7988\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2319.7173 - val_loss: 2006.4951\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2290.7688 - val_loss: 1990.3613\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2262.0786 - val_loss: 1974.3966\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2233.6445 - val_loss: 1958.5995\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2205.4644 - val_loss: 1942.9696\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2177.5386 - val_loss: 1927.5050\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2149.8635 - val_loss: 1912.2058\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2122.4395 - val_loss: 1897.0701\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 2095.2639 - val_loss: 1882.0972\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 2068.3362 - val_loss: 1867.2856\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2041.6545 - val_loss: 1852.6357\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2015.2173 - val_loss: 1838.1450\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1989.0233 - val_loss: 1823.8136\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1963.0710 - val_loss: 1809.6399\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1937.3596 - val_loss: 1795.6229\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1911.8871 - val_loss: 1781.7623\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1886.6528 - val_loss: 1768.0568\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1861.6543 - val_loss: 1754.5050\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1836.8914 - val_loss: 1741.1067\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1812.3621 - val_loss: 1727.8602\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1788.0647 - val_loss: 1714.7654\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1763.9988 - val_loss: 1701.8207\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1740.1622 - val_loss: 1689.0255\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1716.5544 - val_loss: 1676.3787\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1693.1738 - val_loss: 1663.8794\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1670.0190 - val_loss: 1651.5272\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1647.0887 - val_loss: 1639.3203\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1624.3812 - val_loss: 1627.2584\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1601.8961 - val_loss: 1615.3403\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1579.6316 - val_loss: 1603.5653\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1557.5859 - val_loss: 1591.9325\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1535.7588 - val_loss: 1580.4407\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1514.1482 - val_loss: 1569.0892\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1492.7534 - val_loss: 1557.8773\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1471.5729 - val_loss: 1546.8041\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1450.6055 - val_loss: 1535.8682\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1429.8500 - val_loss: 1525.0693\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1409.3049 - val_loss: 1514.4064\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1388.9690 - val_loss: 1503.8784\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1368.8416 - val_loss: 1493.4849\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1348.9210 - val_loss: 1483.2241\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1329.2062 - val_loss: 1473.0962\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1309.6954 - val_loss: 1463.0997\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1290.3881 - val_loss: 1453.2339\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1271.2830 - val_loss: 1443.4979\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1252.3787 - val_loss: 1433.8912\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1233.6738 - val_loss: 1424.4125\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1215.1677 - val_loss: 1415.0609\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1196.8586 - val_loss: 1405.8359\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1178.7457 - val_loss: 1396.7365\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1160.8276 - val_loss: 1387.7615\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1143.1029 - val_loss: 1378.9106\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1125.5712 - val_loss: 1370.1829\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1108.2306 - val_loss: 1361.5773\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1091.0803 - val_loss: 1353.0933\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1074.1190 - val_loss: 1344.7296\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1057.3457 - val_loss: 1336.4856\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1040.7590 - val_loss: 1328.3604\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1024.3575 - val_loss: 1320.3534\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1008.1408 - val_loss: 1312.4634\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 992.1069 - val_loss: 1304.6898\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 976.2556 - val_loss: 1297.0320\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 960.5848 - val_loss: 1289.4886\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 945.0940 - val_loss: 1282.0592\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 929.7820 - val_loss: 1274.7433\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 914.6476 - val_loss: 1267.5392\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 899.6892 - val_loss: 1260.4465\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 884.9058 - val_loss: 1253.4645\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 870.2966 - val_loss: 1246.5920\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 855.8605 - val_loss: 1239.8285\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 841.5959 - val_loss: 1233.1735\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 827.5025 - val_loss: 1226.6257\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 813.5787 - val_loss: 1220.1842\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 799.8230 - val_loss: 1213.8485\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 786.2350 - val_loss: 1207.6178\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 772.8131 - val_loss: 1201.4912\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 759.5565 - val_loss: 1195.4678\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 746.4636 - val_loss: 1189.5466\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 733.5337 - val_loss: 1183.7271\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 720.7653 - val_loss: 1178.0084\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 708.1577 - val_loss: 1172.3896\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 695.7097 - val_loss: 1166.8701\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 683.4199 - val_loss: 1161.4489\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 671.2876 - val_loss: 1156.1252\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 659.3114 - val_loss: 1150.8983\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 647.4905 - val_loss: 1145.7675\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 635.8235 - val_loss: 1140.7316\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 624.3097 - val_loss: 1135.7902\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 612.9476 - val_loss: 1130.9420\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 601.7360 - val_loss: 1126.1868\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 590.6741 - val_loss: 1121.5234\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 579.7606 - val_loss: 1116.9509\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 568.9943 - val_loss: 1112.4688\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 558.3745 - val_loss: 1108.0758\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 547.8999 - val_loss: 1103.7720\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 537.5693 - val_loss: 1099.5555\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 527.3818 - val_loss: 1095.4264\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 517.3364 - val_loss: 1091.3833\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 507.4315 - val_loss: 1087.4257\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 497.6665 - val_loss: 1083.5525\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 488.0401 - val_loss: 1079.7632\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 478.5513 - val_loss: 1076.0571\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 469.1988 - val_loss: 1072.4327\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 459.9819 - val_loss: 1068.8899\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 450.8992 - val_loss: 1065.4277\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 441.9496 - val_loss: 1062.0452\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 433.1321 - val_loss: 1058.7416\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 424.4453 - val_loss: 1055.5160\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 415.8885 - val_loss: 1052.3677\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 407.4604 - val_loss: 1049.2957\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 399.1600 - val_loss: 1046.2997\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 390.9863 - val_loss: 1043.3784\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 382.9383 - val_loss: 1040.5312\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 375.0146 - val_loss: 1037.7573\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 367.2144 - val_loss: 1035.0555\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 359.5364 - val_loss: 1032.4258\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 351.9800 - val_loss: 1029.8668\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 344.5437 - val_loss: 1027.3779\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 337.2263 - val_loss: 1024.9578\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 330.0268 - val_loss: 1022.6064\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 322.9439 - val_loss: 1020.3223\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 315.9769 - val_loss: 1018.1050\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 309.1247 - val_loss: 1015.9537\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 302.3860 - val_loss: 1013.8676\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 295.7598 - val_loss: 1011.8457\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 289.2451 - val_loss: 1009.8873\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 282.8405 - val_loss: 1007.9916\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 276.5453 - val_loss: 1006.1577\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 270.3581 - val_loss: 1004.3848\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 264.2780 - val_loss: 1002.6722\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 258.3038 - val_loss: 1001.0190\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 252.4348 - val_loss: 999.4246\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 246.6695 - val_loss: 997.8878\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 241.0068 - val_loss: 996.4081\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 235.4458 - val_loss: 994.9847\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 229.9855 - val_loss: 993.6165\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 224.6248 - val_loss: 992.3030\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 219.3626 - val_loss: 991.0432\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 214.1977 - val_loss: 989.8365\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 209.1291 - val_loss: 988.6818\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 204.1557 - val_loss: 987.5787\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 199.2764 - val_loss: 986.5260\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 194.4903 - val_loss: 985.5229\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 189.7960 - val_loss: 984.5689\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 185.1929 - val_loss: 983.6631\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 180.6796 - val_loss: 982.8046\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 176.2550 - val_loss: 981.9928\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 171.9182 - val_loss: 981.2265\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 167.6678 - val_loss: 980.5052\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 163.5034 - val_loss: 979.8281\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 159.4236 - val_loss: 979.1944\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 155.4270 - val_loss: 978.6034\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 151.5129 - val_loss: 978.0538\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 147.6803 - val_loss: 977.5455\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 143.9279 - val_loss: 977.0773\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 140.2548 - val_loss: 976.6486\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 136.6599 - val_loss: 976.2585\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 133.1422 - val_loss: 975.9064\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 129.7006 - val_loss: 975.5911\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 126.3341 - val_loss: 975.3123\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 123.0416 - val_loss: 975.0689\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 119.8223 - val_loss: 974.8604\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 116.6748 - val_loss: 974.6859\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 113.5984 - val_loss: 974.5446\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 110.5917 - val_loss: 974.4359\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 107.6541 - val_loss: 974.3588\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 104.7843 - val_loss: 974.3127\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 101.9814 - val_loss: 974.2967\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 99.2443 - val_loss: 974.3104\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 96.5721 - val_loss: 974.3527\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 93.9639 - val_loss: 974.4229\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 91.4184 - val_loss: 974.5205\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 88.9347 - val_loss: 974.6446\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 86.5119 - val_loss: 974.7944\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 84.1491 - val_loss: 974.9693\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 81.8452 - val_loss: 975.1686\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 79.5992 - val_loss: 975.3914\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 77.4100 - val_loss: 975.6373\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 75.2767 - val_loss: 975.9052\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 73.1987 - val_loss: 976.1947\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 71.1747 - val_loss: 976.5051\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 69.2036 - val_loss: 976.8356\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 67.2847 - val_loss: 977.1855\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 65.4168 - val_loss: 977.5543\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 63.5995 - val_loss: 977.9411\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 61.8312 - val_loss: 978.3454\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 60.1116 - val_loss: 978.7664\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 58.4394 - val_loss: 979.2037\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 56.8138 - val_loss: 979.6563\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 55.2339 - val_loss: 980.1237\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 53.6988 - val_loss: 980.6053\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 52.2076 - val_loss: 981.1008\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 50.7593 - val_loss: 981.6089\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 49.3532 - val_loss: 982.1294\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 47.9884 - val_loss: 982.6616\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 46.6641 - val_loss: 983.2051\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 45.3793 - val_loss: 983.7590\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 44.1333 - val_loss: 984.3228\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 42.9252 - val_loss: 984.8962\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 41.7541 - val_loss: 985.4781\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 40.6192 - val_loss: 986.0685\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 39.5198 - val_loss: 986.6665\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 38.4550 - val_loss: 987.2717\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 37.4240 - val_loss: 987.8837\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 36.4260 - val_loss: 988.5016\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 35.4602 - val_loss: 989.1252\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 34.5260 - val_loss: 989.7538\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 33.6226 - val_loss: 990.3868\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 32.7491 - val_loss: 991.0240\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 31.9049 - val_loss: 991.6649\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 31.0892 - val_loss: 992.3088\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 30.3013 - val_loss: 992.9556\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 29.5405 - val_loss: 993.6042\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.8062 - val_loss: 994.2549\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.0975 - val_loss: 994.9069\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 27.4138 - val_loss: 995.5597\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 26.7545 - val_loss: 996.2130\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 26.1189 - val_loss: 996.8664\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.5064 - val_loss: 997.5195\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 24.9163 - val_loss: 998.1718\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 24.3479 - val_loss: 998.8232\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 23.8006 - val_loss: 999.4731\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 23.2740 - val_loss: 1000.1209\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.7673 - val_loss: 1000.7668\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.2800 - val_loss: 1001.4103\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.8114 - val_loss: 1002.0510\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.3610 - val_loss: 1002.6885\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.9283 - val_loss: 1003.3226\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.5127 - val_loss: 1003.9531\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.1137 - val_loss: 1004.5793\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.7307 - val_loss: 1005.2014\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.3633 - val_loss: 1005.8190\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.0110 - val_loss: 1006.4318\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.6732 - val_loss: 1007.0393\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.3495 - val_loss: 1007.6417\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.0394 - val_loss: 1008.2385\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.7424 - val_loss: 1008.8296\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.4581 - val_loss: 1009.4150\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.1860 - val_loss: 1009.9942\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 16.9258 - val_loss: 1010.5668\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.6770 - val_loss: 1011.1333\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.4391 - val_loss: 1011.6931\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2119 - val_loss: 1012.2458\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.9949 - val_loss: 1012.7917\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.7877 - val_loss: 1013.3306\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.5900 - val_loss: 1013.8620\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.4014 - val_loss: 1014.3863\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.2216 - val_loss: 1014.9031\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.0501 - val_loss: 1015.4125\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.8867 - val_loss: 1015.9142\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.7311 - val_loss: 1016.4081\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5830 - val_loss: 1016.8942\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.4420 - val_loss: 1017.3726\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.3079 - val_loss: 1017.8428\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.1804 - val_loss: 1018.3051\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.0592 - val_loss: 1018.7594\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.9440 - val_loss: 1019.2056\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.8347 - val_loss: 1019.6437\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.7308 - val_loss: 1020.0737\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.6323 - val_loss: 1020.4958\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.5387 - val_loss: 1020.9096\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.4501 - val_loss: 1021.3152\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.3660 - val_loss: 1021.7129\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.2864 - val_loss: 1022.1023\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.2110 - val_loss: 1022.4836\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.1396 - val_loss: 1022.8568\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 13.0721 - val_loss: 1023.2220\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0081 - val_loss: 1023.5792\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9477 - val_loss: 1023.9286\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.8906 - val_loss: 1024.2700\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.8366 - val_loss: 1024.6035\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7856 - val_loss: 1024.9293\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7375 - val_loss: 1025.2471\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.6921 - val_loss: 1025.5574\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.6492 - val_loss: 1025.8600\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.6088 - val_loss: 1026.1552\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.5707 - val_loss: 1026.4427\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.5348 - val_loss: 1026.7231\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.5010 - val_loss: 1026.9961\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.4691 - val_loss: 1027.2618\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.4392 - val_loss: 1027.5205\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.4110 - val_loss: 1027.7722\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3845 - val_loss: 1028.0171\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3595 - val_loss: 1028.2549\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3361 - val_loss: 1028.4862\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.3140 - val_loss: 1028.7108\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.2933 - val_loss: 1028.9291\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.2738 - val_loss: 1029.1407\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.2556 - val_loss: 1029.3463\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.2385 - val_loss: 1029.5455\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.2224 - val_loss: 1029.7388\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 12.2074 - val_loss: 1029.9260\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 12.1932 - val_loss: 1030.1075\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1800 - val_loss: 1030.2832\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1675 - val_loss: 1030.4531\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1559 - val_loss: 1030.6178\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1450 - val_loss: 1030.7771\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1348 - val_loss: 1030.9312\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1253 - val_loss: 1031.0800\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.1163 - val_loss: 1031.2235\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.1080 - val_loss: 1031.3623\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1001 - val_loss: 1031.4965\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0929 - val_loss: 1031.6259\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0860 - val_loss: 1031.7507\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0796 - val_loss: 1031.8712\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0736 - val_loss: 1031.9872\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0681 - val_loss: 1032.0989\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0628 - val_loss: 1032.2065\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0580 - val_loss: 1032.3101\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0534 - val_loss: 1032.4099\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0492 - val_loss: 1032.5056\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0452 - val_loss: 1032.5977\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0415 - val_loss: 1032.6865\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0381 - val_loss: 1032.7716\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0349 - val_loss: 1032.8536\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0319 - val_loss: 1032.9321\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 12.0291 - val_loss: 1033.0074\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 12.0265 - val_loss: 1033.0795\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0241 - val_loss: 1033.1489\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0218 - val_loss: 1033.2155\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0197 - val_loss: 1033.2793\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0178 - val_loss: 1033.3401\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0160 - val_loss: 1033.3986\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0143 - val_loss: 1033.4543\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0127 - val_loss: 1033.5076\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0113 - val_loss: 1033.5586\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0099 - val_loss: 1033.6073\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0087 - val_loss: 1033.6538\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.0076 - val_loss: 1033.6985\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0065 - val_loss: 1033.7407\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0055 - val_loss: 1033.7811\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 12.0046 - val_loss: 1033.8198\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 12.0037 - val_loss: 1033.8563\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 12.0030 - val_loss: 1033.8912\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0023 - val_loss: 1033.9247\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0016 - val_loss: 1033.9564\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 12.0010 - val_loss: 1033.9866\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 12.0005 - val_loss: 1034.0153\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0000 - val_loss: 1034.0427\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 11.9996 - val_loss: 1034.0684\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 11.9992 - val_loss: 1034.0928\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 11.9988 - val_loss: 1034.1162\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9985 - val_loss: 1034.1383\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9982 - val_loss: 1034.1594\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 11.9979 - val_loss: 1034.1792\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9977 - val_loss: 1034.1981\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9975 - val_loss: 1034.2157\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9974 - val_loss: 1034.2327\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9972 - val_loss: 1034.2485\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 11.9971 - val_loss: 1034.2637\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 11.9970 - val_loss: 1034.2778\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9969 - val_loss: 1034.2914\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9969 - val_loss: 1034.3038\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9969 - val_loss: 1034.3158\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9969 - val_loss: 1034.3268\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.9969 - val_loss: 1034.3375\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9970 - val_loss: 1034.3477\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9969 - val_loss: 1034.3568\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9970 - val_loss: 1034.3655\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9971 - val_loss: 1034.3738\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9972 - val_loss: 1034.3817\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.9973 - val_loss: 1034.3890\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9973 - val_loss: 1034.3959\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9975 - val_loss: 1034.4020\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9976 - val_loss: 1034.4078\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9977 - val_loss: 1034.4133\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9979 - val_loss: 1034.4186\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9980 - val_loss: 1034.4235\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9982 - val_loss: 1034.4280\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9984 - val_loss: 1034.4323\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9985 - val_loss: 1034.4362\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9987 - val_loss: 1034.4398\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.9989 - val_loss: 1034.4432\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 11.9991 - val_loss: 1034.4464\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9993 - val_loss: 1034.4492\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9995 - val_loss: 1034.4518\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.9997 - val_loss: 1034.4542\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9999 - val_loss: 1034.4564\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0002 - val_loss: 1034.4584\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0004 - val_loss: 1034.4604\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0006 - val_loss: 1034.4619\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0008 - val_loss: 1034.4637\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0010 - val_loss: 1034.4648\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0013 - val_loss: 1034.4659\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0015 - val_loss: 1034.4674\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0017 - val_loss: 1034.4683\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0020 - val_loss: 1034.4692\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0022 - val_loss: 1034.4701\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0025 - val_loss: 1034.4709\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0027 - val_loss: 1034.4714\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0029 - val_loss: 1034.4716\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0032 - val_loss: 1034.4723\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 12.0035 - val_loss: 1034.4725\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0037 - val_loss: 1034.4727\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 12.0039 - val_loss: 1034.4730\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0042 - val_loss: 1034.4730\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0044 - val_loss: 1034.4733\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0047 - val_loss: 1034.4733\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0049 - val_loss: 1034.4733\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0052 - val_loss: 1034.4733\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0054 - val_loss: 1034.4730\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0057 - val_loss: 1034.4727\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0060 - val_loss: 1034.4727\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0062 - val_loss: 1034.4727\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 12.0065 - val_loss: 1034.4725\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 12.0067 - val_loss: 1034.4723\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0070 - val_loss: 1034.4720\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.0072 - val_loss: 1034.4718\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0075 - val_loss: 1034.4713\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0077 - val_loss: 1034.4709\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 12.0080 - val_loss: 1034.4707\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0082 - val_loss: 1034.4701\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0084 - val_loss: 1034.4697\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 12.0087 - val_loss: 1034.4692\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 12.0089 - val_loss: 1034.4688\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 12.0092 - val_loss: 1034.4684\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0094 - val_loss: 1034.4679\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0096 - val_loss: 1034.4677\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0099 - val_loss: 1034.4669\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0102 - val_loss: 1034.4666\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.0104 - val_loss: 1034.4663\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0106 - val_loss: 1034.4655\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.1552, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0026, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0004, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0102, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.8734, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 416ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.22878431e+01, 7.21466667e+01, 7.20054902e+01, 7.18643137e+01,\n",
       "        7.17231372e+01, 7.15819608e+01, 7.14407843e+01, 5.20513415e-01,\n",
       "        0.00000000e+00, 3.64094080e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.34337768e+01, 7.33245331e+01, 7.32152895e+01,\n",
       "        7.31060458e+01, 7.29968020e+01, 7.28839216e+01, 7.27427451e+01,\n",
       "        7.26015686e+01, 7.24603922e+01, 7.23192157e+01, 7.21780392e+01,\n",
       "        7.20368627e+01, 7.18956863e+01, 7.17545098e+01, 7.16133333e+01,\n",
       "        7.14721569e+01, 7.13309804e+01, 7.12142484e+01, 7.11873576e+01,\n",
       "        7.11604669e+01, 7.11335761e+01, 7.11066853e+01, 7.10797946e+01,\n",
       "        7.10529038e+01, 7.10260131e+01, 7.09991223e+01, 7.09722316e+01,\n",
       "        1.22558773e-01, 1.08551530e-02, 0.00000000e+00, 3.29043865e-01,\n",
       "        1.52217552e-01, 8.18514680e-02, 1.72429889e-01, 7.19270588e+01,\n",
       "        7.17858823e+01, 7.16447059e+01, 7.15035294e+01, 7.13623529e+01,\n",
       "        7.12211765e+01, 7.11933333e+01, 7.11664426e+01, 7.11395518e+01,\n",
       "        7.11126611e+01, 7.10857703e+01, 7.10588796e+01, 7.10319888e+01,\n",
       "        7.10050980e+01, 7.09782073e+01, 7.09513165e+01, 7.09244258e+01,\n",
       "        7.08976891e+01, 7.08724790e+01, 7.08472689e+01, 7.08220588e+01,\n",
       "        7.07968487e+01, 7.07716387e+01, 7.07464286e+01, 7.07212185e+01,\n",
       "        7.06960084e+01, 7.64097366e+01, 2.27639120e-02, 1.45036131e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.25366127e-01, 0.00000000e+00,\n",
       "        4.54919891e+01, 0.00000000e+00, 2.90957689e-01, 1.04988217e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.80814075e-01, 0.00000000e+00,\n",
       "        9.80372652e-02, 1.42019778e-01, 3.91179383e-01, 3.11266243e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.29398620e-01, 1.20284572e-01, 0.00000000e+00, 3.80662382e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66.46143791, 66.45396825, 66.4464986 , 66.43902894, 66.43155929,\n",
       "       66.42408964, 66.41661998, 66.40915033, 66.40168067, 66.39421102,\n",
       "       66.38674136, 66.37927171, 66.37180205, 66.3643324 , 66.35686275,\n",
       "       66.34939309, 66.34192344, 66.33445378, 66.32698413, 66.31951447,\n",
       "       66.31204482, 66.30457516, 66.29710551, 66.28963585, 66.2821662 ,\n",
       "       66.27469655, 66.26722689, 66.25975724, 66.25228758, 66.24481793,\n",
       "       66.23734827, 66.22987862, 66.22240896, 66.21493931, 66.20746965,\n",
       "       66.2       , 66.19253035, 66.18506069, 66.17759104, 66.17012138,\n",
       "       66.16265173, 66.15518207, 66.14771242, 66.14024276, 66.13277311,\n",
       "       66.12530345, 66.1178338 , 66.11036415, 66.10289449, 66.09542484,\n",
       "       66.08795518, 66.08048553, 66.07301587, 66.06554622, 66.05807656,\n",
       "       66.05060691, 66.04313725, 66.0356676 , 66.02819795, 66.02072829,\n",
       "       66.01325864, 66.00578898, 65.9947479 , 65.97140523, 65.94806256,\n",
       "       65.92471989, 65.90137722, 65.87803455, 65.85469188, 65.83134921,\n",
       "       65.80800654, 65.78466387, 65.7613212 , 65.73797852, 65.71463585,\n",
       "       65.69129318, 65.66795051, 65.64460784, 65.62126517, 65.5979225 ,\n",
       "       65.57457983, 65.55123716, 65.52789449, 65.50455182, 65.48120915,\n",
       "       65.45786648, 65.43452381, 65.41118114, 65.38783847, 65.3644958 ,\n",
       "       65.34115313, 65.31781046, 65.29446779, 65.27112512, 65.24778245,\n",
       "       65.22443978, 65.20109711, 65.17775444, 65.15441176, 65.13106909])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.70805324105439\n",
      "28.46518942350756\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
