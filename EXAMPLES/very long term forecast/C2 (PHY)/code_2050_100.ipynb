{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "2145    57.614245\n",
       "2146    57.598668\n",
       "2147    57.583091\n",
       "2148    57.567514\n",
       "2149    57.551937\n",
       "Name: C2, Length: 2150, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c2_interpolated_2050_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "2045     0.887261\n",
       "2046     0.000000\n",
       "2047     0.364820\n",
       "2048     0.075120\n",
       "2049     0.000000\n",
       "Name: C2, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2050)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.500000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.275910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.051821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.827731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.603641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     90.500000  0.000298\n",
       "1     90.275910  0.000298\n",
       "2     90.051821  0.000297\n",
       "3     89.827731  0.000297\n",
       "4     89.603641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.1552  # Value for C0\n",
    "K0 = -0.0026  # Value for K0\n",
    "K1 = -0.0004  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0102    # Value for b\n",
    "c = 2.8734    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    90.500000    90.275910    90.051821    89.827731    89.603641   \n",
      "351    90.275910    90.051821    89.827731    89.603641    89.379552   \n",
      "352    90.051821    89.827731    89.603641    89.379552    89.155462   \n",
      "353    89.827731    89.603641    89.379552    89.155462    88.931373   \n",
      "354    89.603641    89.379552    89.155462    88.931373    88.707283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.379552    89.155462    88.931373    88.707283    88.494958  ...   \n",
      "351    89.155462    88.931373    88.707283    88.494958    88.427731  ...   \n",
      "352    88.931373    88.707283    88.494958    88.427731    88.360504  ...   \n",
      "353    88.707283    88.494958    88.427731    88.360504    88.293277  ...   \n",
      "354    88.494958    88.427731    88.360504    88.293277    88.226050  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.071008    0.000263   79.054202    0.000263   79.037395    0.000263   \n",
      "351   79.054202    0.000263   79.037395    0.000263   79.020588    0.000262   \n",
      "352   79.037395    0.000263   79.020588    0.000262   79.003782    0.000262   \n",
      "353   79.020588    0.000262   79.003782    0.000262   78.986975    0.000262   \n",
      "354   79.003782    0.000262   78.986975    0.000262   78.970168    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.020588    0.000262   79.003782    0.000262  \n",
      "351   79.003782    0.000262   78.986975    0.000262  \n",
      "352   78.986975    0.000262   78.970168    0.000262  \n",
      "353   78.970168    0.000262   78.953361    0.000262  \n",
      "354   78.953361    0.000262   78.936555    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 1, 251) (1600, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 30ms/step - loss: 5320.2725 - val_loss: 3182.2231\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 5107.6704 - val_loss: 3056.9946\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5011.2563 - val_loss: 3001.1277\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4919.4897 - val_loss: 2952.1260\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4845.6826 - val_loss: 2908.3042\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4774.5674 - val_loss: 2866.1079\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4705.5049 - val_loss: 2825.1592\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4638.0049 - val_loss: 2785.2297\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4571.7837 - val_loss: 2746.1870\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4506.6694 - val_loss: 2707.9468\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4442.5522 - val_loss: 2670.4514\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 4379.3604 - val_loss: 2633.6616\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4317.0342 - val_loss: 2597.5452\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4255.5352 - val_loss: 2562.0779\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4194.8286 - val_loss: 2527.2400\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4134.8896 - val_loss: 2493.0146\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4075.6958 - val_loss: 2459.3884\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4017.2280 - val_loss: 2426.3477\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3959.4700 - val_loss: 2393.8823\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3902.4087 - val_loss: 2361.9819\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3846.0293 - val_loss: 2330.6375\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3790.3228 - val_loss: 2299.8403\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3735.2754 - val_loss: 2269.5825\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3680.8816 - val_loss: 2239.8574\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3627.1301 - val_loss: 2210.6572\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3574.0117 - val_loss: 2181.9758\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3521.5200 - val_loss: 2153.8066\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3469.6470 - val_loss: 2126.1438\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3418.3853 - val_loss: 2098.9810\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3367.7278 - val_loss: 2072.3127\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 3317.6685 - val_loss: 2046.1342\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3268.2007 - val_loss: 2020.4382\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3219.3191 - val_loss: 1995.2213\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 3171.0168 - val_loss: 1970.4778\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3123.2881 - val_loss: 1946.2021\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3076.1270 - val_loss: 1922.3900\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3029.5291 - val_loss: 1899.0365\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2983.4885 - val_loss: 1876.1370\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2937.9993 - val_loss: 1853.6862\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 2893.0571 - val_loss: 1831.6801\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2848.6577 - val_loss: 1810.1140\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2804.7942 - val_loss: 1788.9836\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2761.4629 - val_loss: 1768.2845\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 2718.6589 - val_loss: 1748.0121\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2676.3774 - val_loss: 1728.1621\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2634.6135 - val_loss: 1708.7305\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2593.3628 - val_loss: 1689.7125\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 2552.6211 - val_loss: 1671.1049\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2512.3833 - val_loss: 1652.9030\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2472.6458 - val_loss: 1635.1025\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2433.4038 - val_loss: 1617.7000\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2394.6531 - val_loss: 1600.6908\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2356.3889 - val_loss: 1584.0715\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2318.6084 - val_loss: 1567.8375\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2281.3052 - val_loss: 1551.9857\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2244.4773 - val_loss: 1536.5117\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2208.1199 - val_loss: 1521.4115\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2172.2285 - val_loss: 1506.6819\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2136.7996 - val_loss: 1492.3187\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2101.8296 - val_loss: 1478.3180\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2067.3140 - val_loss: 1464.6763\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2033.2480 - val_loss: 1451.3899\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1999.6296 - val_loss: 1438.4546\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1966.4537 - val_loss: 1425.8674\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1933.7175 - val_loss: 1413.6243\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1901.4160 - val_loss: 1401.7219\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1869.5471 - val_loss: 1390.1561\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1838.1049 - val_loss: 1378.9238\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1807.0872 - val_loss: 1368.0210\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1776.4906 - val_loss: 1357.4446\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1746.3105 - val_loss: 1347.1907\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1716.5437 - val_loss: 1337.2561\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1687.1868 - val_loss: 1327.6370\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1658.2361 - val_loss: 1318.3298\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1629.6881 - val_loss: 1309.3313\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 1601.5389 - val_loss: 1300.6381\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1573.7859 - val_loss: 1292.2465\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1546.4247 - val_loss: 1284.1531\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1519.4524 - val_loss: 1276.3547\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1492.8652 - val_loss: 1268.8477\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1466.6602 - val_loss: 1261.6287\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1440.8333 - val_loss: 1254.6943\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1415.3821 - val_loss: 1248.0414\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1390.3025 - val_loss: 1241.6663\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1365.5909 - val_loss: 1235.5657\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1341.2449 - val_loss: 1229.7363\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1317.2604 - val_loss: 1224.1750\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1293.6349 - val_loss: 1218.8784\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1270.3644 - val_loss: 1213.8430\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1247.4459 - val_loss: 1209.0656\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1224.8766 - val_loss: 1204.5426\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1202.6526 - val_loss: 1200.2712\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1180.7708 - val_loss: 1196.2483\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1159.2285 - val_loss: 1192.4700\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1138.0222 - val_loss: 1188.9333\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1117.1483 - val_loss: 1185.6350\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1096.6046 - val_loss: 1182.5720\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1076.3873 - val_loss: 1179.7408\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1056.4935 - val_loss: 1177.1382\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1036.9202 - val_loss: 1174.7612\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1017.6639 - val_loss: 1172.6064\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 998.7217 - val_loss: 1170.6707\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 980.0907 - val_loss: 1168.9509\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 961.7678 - val_loss: 1167.4437\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 943.7495 - val_loss: 1166.1459\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 926.0333 - val_loss: 1165.0544\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 908.6158 - val_loss: 1164.1660\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 891.4946 - val_loss: 1163.4778\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 874.6657 - val_loss: 1162.9861\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 858.1271 - val_loss: 1162.6880\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 841.8752 - val_loss: 1162.5803\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 825.9070 - val_loss: 1162.6600\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 810.2198 - val_loss: 1162.9240\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 794.8106 - val_loss: 1163.3689\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 779.6764 - val_loss: 1163.9916\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 764.8140 - val_loss: 1164.7891\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 750.2206 - val_loss: 1165.7582\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 735.8937 - val_loss: 1166.8958\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 721.8300 - val_loss: 1168.1986\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 708.0265 - val_loss: 1169.6641\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 694.4805 - val_loss: 1171.2883\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 681.1891 - val_loss: 1173.0687\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 668.1493 - val_loss: 1175.0023\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 655.3582 - val_loss: 1177.0856\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 642.8132 - val_loss: 1179.3156\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 630.5109 - val_loss: 1181.6892\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 618.4492 - val_loss: 1184.2037\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 606.6245 - val_loss: 1186.8555\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 595.0344 - val_loss: 1189.6418\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 583.6761 - val_loss: 1192.5597\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 572.5463 - val_loss: 1195.6057\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 561.6429 - val_loss: 1198.7771\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 550.9626 - val_loss: 1202.0707\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 540.5027 - val_loss: 1205.4836\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 530.2604 - val_loss: 1209.0127\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 520.2330 - val_loss: 1212.6549\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 510.4177 - val_loss: 1216.4072\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 500.8118 - val_loss: 1220.2665\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 491.4124 - val_loss: 1224.2302\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 482.2166 - val_loss: 1228.2947\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 473.2219 - val_loss: 1232.4576\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 464.4255 - val_loss: 1236.7156\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 455.8249 - val_loss: 1241.0657\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 447.4169 - val_loss: 1245.5050\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 439.1991 - val_loss: 1250.0305\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 431.1689 - val_loss: 1254.6394\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 423.3233 - val_loss: 1259.3287\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 415.6599 - val_loss: 1264.0955\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 408.1758 - val_loss: 1268.9369\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 400.8685 - val_loss: 1273.8496\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 393.7352 - val_loss: 1278.8315\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 386.7734 - val_loss: 1283.8790\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 379.9803 - val_loss: 1288.9896\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 373.3535 - val_loss: 1294.1604\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 366.8901 - val_loss: 1299.3887\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 360.5877 - val_loss: 1304.6711\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 354.4439 - val_loss: 1310.0051\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 348.4558 - val_loss: 1315.3887\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 342.6206 - val_loss: 1320.8181\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 336.9362 - val_loss: 1326.2908\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 331.4000 - val_loss: 1331.8043\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 326.0092 - val_loss: 1337.3557\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 320.7615 - val_loss: 1342.9426\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 315.6544 - val_loss: 1348.5618\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 310.6852 - val_loss: 1354.2107\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 305.8516 - val_loss: 1359.8872\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 301.1512 - val_loss: 1365.5881\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 296.5814 - val_loss: 1371.3113\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 292.1396 - val_loss: 1377.0537\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 287.8237 - val_loss: 1382.8131\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 283.6313 - val_loss: 1388.5868\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 279.5597 - val_loss: 1394.3727\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 275.6067 - val_loss: 1400.1677\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 271.7699 - val_loss: 1405.9701\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 268.0470 - val_loss: 1411.7771\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 264.4356 - val_loss: 1417.5864\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 260.9334 - val_loss: 1423.3951\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 257.5384 - val_loss: 1429.2015\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 254.2479 - val_loss: 1435.0032\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 251.0600 - val_loss: 1440.7975\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 247.9724 - val_loss: 1446.5828\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 244.9825 - val_loss: 1452.3566\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 242.0886 - val_loss: 1458.1165\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 239.2883 - val_loss: 1463.8608\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 236.5794 - val_loss: 1469.5874\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 233.9600 - val_loss: 1475.2938\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 231.4277 - val_loss: 1480.9785\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 228.9807 - val_loss: 1486.6392\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 226.6168 - val_loss: 1492.2740\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 224.3339 - val_loss: 1497.8811\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 222.1300 - val_loss: 1503.4583\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 220.0033 - val_loss: 1509.0045\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 217.9515 - val_loss: 1514.5172\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 215.9730 - val_loss: 1519.9951\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 214.0656 - val_loss: 1525.4359\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 212.2277 - val_loss: 1530.8387\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 210.4572 - val_loss: 1536.2014\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 208.7523 - val_loss: 1541.5229\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 207.1112 - val_loss: 1546.8018\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 205.5322 - val_loss: 1552.0355\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 204.0135 - val_loss: 1557.2234\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 202.5532 - val_loss: 1562.3649\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 201.1498 - val_loss: 1567.4568\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 199.8016 - val_loss: 1572.4991\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 198.5068 - val_loss: 1577.4908\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 197.2640 - val_loss: 1582.4294\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 196.0713 - val_loss: 1587.3151\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 194.9275 - val_loss: 1592.1467\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 193.8307 - val_loss: 1596.9220\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 192.7798 - val_loss: 1601.6414\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 191.7729 - val_loss: 1606.3029\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 190.8090 - val_loss: 1610.9062\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 189.8863 - val_loss: 1615.4496\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 189.0036 - val_loss: 1619.9343\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 188.1593 - val_loss: 1624.3580\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 187.3523 - val_loss: 1628.7203\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 186.5813 - val_loss: 1633.0212\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 185.8449 - val_loss: 1637.2592\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 185.1419 - val_loss: 1641.4333\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 184.4711 - val_loss: 1645.5443\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 183.8315 - val_loss: 1649.5918\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 183.2215 - val_loss: 1653.5746\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 182.6404 - val_loss: 1657.4926\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 182.0869 - val_loss: 1661.3464\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 181.5600 - val_loss: 1665.1348\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 181.0586 - val_loss: 1668.8574\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 180.5817 - val_loss: 1672.5144\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 180.1284 - val_loss: 1676.1058\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 179.6976 - val_loss: 1679.6318\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 179.2885 - val_loss: 1683.0920\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 178.9001 - val_loss: 1686.4860\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 178.5317 - val_loss: 1689.8148\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 178.1822 - val_loss: 1693.0781\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 177.8510 - val_loss: 1696.2760\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 177.5371 - val_loss: 1699.4095\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 177.2399 - val_loss: 1702.4775\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 176.9586 - val_loss: 1705.4807\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 176.6925 - val_loss: 1708.4203\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 176.4408 - val_loss: 1711.2965\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 176.2030 - val_loss: 1714.1082\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 175.9783 - val_loss: 1716.8567\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 175.7661 - val_loss: 1719.5432\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 175.5660 - val_loss: 1722.1664\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 175.3132 - val_loss: 1722.6218\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 175.4409 - val_loss: 1726.7507\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 175.1231 - val_loss: 1730.0668\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 174.8963 - val_loss: 1733.0793\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 174.7035 - val_loss: 1735.8953\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 174.5327 - val_loss: 1738.5596\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 174.3789 - val_loss: 1741.0967\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 174.2390 - val_loss: 1743.5227\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 174.1110 - val_loss: 1745.8474\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 173.9937 - val_loss: 1748.0803\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 173.8857 - val_loss: 1750.2252\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 173.7863 - val_loss: 1752.2885\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 173.6946 - val_loss: 1754.2754\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 173.6100 - val_loss: 1756.1882\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 173.5318 - val_loss: 1758.0320\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 173.4595 - val_loss: 1759.8079\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 173.3927 - val_loss: 1761.5192\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 173.3310 - val_loss: 1763.1680\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 173.2739 - val_loss: 1764.7574\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 173.2210 - val_loss: 1766.2887\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 173.1723 - val_loss: 1767.7634\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 173.1272 - val_loss: 1769.1855\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 173.0854 - val_loss: 1770.5544\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 173.0469 - val_loss: 1771.8737\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 173.0113 - val_loss: 1773.1436\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.9784 - val_loss: 1774.3658\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.9480 - val_loss: 1775.5430\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 172.9198 - val_loss: 1776.6754\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.8940 - val_loss: 1777.7659\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.8700 - val_loss: 1778.8151\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.8479 - val_loss: 1779.8230\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.8275 - val_loss: 1780.7924\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 172.8087 - val_loss: 1781.7242\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.7914 - val_loss: 1782.6205\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.7754 - val_loss: 1783.4807\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.7607 - val_loss: 1784.3074\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.7471 - val_loss: 1785.1003\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.7346 - val_loss: 1785.8623\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.7232 - val_loss: 1786.5935\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.7126 - val_loss: 1787.2957\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.7028 - val_loss: 1787.9685\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6939 - val_loss: 1788.6143\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6856 - val_loss: 1789.2314\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6782 - val_loss: 1789.8242\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 172.6712 - val_loss: 1790.3923\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6649 - val_loss: 1790.9363\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 172.6590 - val_loss: 1791.4580\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6537 - val_loss: 1791.9564\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6487 - val_loss: 1792.4336\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6442 - val_loss: 1792.8900\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6400 - val_loss: 1793.3264\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6363 - val_loss: 1793.7429\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6329 - val_loss: 1794.1422\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6298 - val_loss: 1794.5234\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6269 - val_loss: 1794.8873\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6243 - val_loss: 1795.2354\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6219 - val_loss: 1795.5681\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6197 - val_loss: 1795.8844\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6177 - val_loss: 1796.1873\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6160 - val_loss: 1796.4756\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6143 - val_loss: 1796.7506\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6129 - val_loss: 1797.0131\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6116 - val_loss: 1797.2633\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6104 - val_loss: 1797.5013\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6093 - val_loss: 1797.7279\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6083 - val_loss: 1797.9431\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6076 - val_loss: 1798.1488\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6068 - val_loss: 1798.3450\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6061 - val_loss: 1798.5310\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 172.6055 - val_loss: 1798.7083\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 172.6050 - val_loss: 1798.8766\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6046 - val_loss: 1799.0359\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6042 - val_loss: 1799.1881\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6039 - val_loss: 1799.3330\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6036 - val_loss: 1799.4697\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6034 - val_loss: 1799.6008\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6032 - val_loss: 1799.7240\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6031 - val_loss: 1799.8411\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6030 - val_loss: 1799.9524\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6029 - val_loss: 1800.0579\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6029 - val_loss: 1800.1576\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6029 - val_loss: 1800.2522\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6030 - val_loss: 1800.3425\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6030 - val_loss: 1800.4283\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6031 - val_loss: 1800.5084\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6032 - val_loss: 1800.5847\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6033 - val_loss: 1800.6572\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6035 - val_loss: 1800.7262\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 172.6036 - val_loss: 1800.7910\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6038 - val_loss: 1800.8525\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6039 - val_loss: 1800.9094\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6042 - val_loss: 1800.9651\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 172.6044 - val_loss: 1801.0162\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6046 - val_loss: 1801.0648\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6048 - val_loss: 1801.1116\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6051 - val_loss: 1801.1555\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6053 - val_loss: 1801.1963\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6056 - val_loss: 1801.2354\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6058 - val_loss: 1801.2719\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6061 - val_loss: 1801.3059\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6063 - val_loss: 1801.3386\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6067 - val_loss: 1801.3701\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6069 - val_loss: 1801.3994\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6072 - val_loss: 1801.4260\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6075 - val_loss: 1801.4514\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6078 - val_loss: 1801.4766\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6081 - val_loss: 1801.4984\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6084 - val_loss: 1801.5201\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6087 - val_loss: 1801.5406\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6089 - val_loss: 1801.5590\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6093 - val_loss: 1801.5762\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 172.6095 - val_loss: 1801.5940\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6098 - val_loss: 1801.6094\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 172.6101 - val_loss: 1801.6240\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 172.6104 - val_loss: 1801.6381\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 172.6107 - val_loss: 1801.6514\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 172.6110 - val_loss: 1801.6638\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6113 - val_loss: 1801.6750\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6116 - val_loss: 1801.6862\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6119 - val_loss: 1801.6963\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6122 - val_loss: 1801.7053\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6125 - val_loss: 1801.7145\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6128 - val_loss: 1801.7233\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6130 - val_loss: 1801.7312\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6133 - val_loss: 1801.7386\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6136 - val_loss: 1801.7455\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6138 - val_loss: 1801.7520\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6142 - val_loss: 1801.7581\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6144 - val_loss: 1801.7633\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 172.6147 - val_loss: 1801.7683\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 172.6149 - val_loss: 1801.7737\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6152 - val_loss: 1801.7780\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6155 - val_loss: 1801.7826\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6157 - val_loss: 1801.7867\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6160 - val_loss: 1801.7903\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6162 - val_loss: 1801.7933\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 172.6165 - val_loss: 1801.7972\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6167 - val_loss: 1801.7998\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6170 - val_loss: 1801.8027\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6172 - val_loss: 1801.8053\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6175 - val_loss: 1801.8076\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6177 - val_loss: 1801.8103\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6179 - val_loss: 1801.8123\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6181 - val_loss: 1801.8138\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6184 - val_loss: 1801.8158\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6185 - val_loss: 1801.8176\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6188 - val_loss: 1801.8190\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6190 - val_loss: 1801.8197\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6193 - val_loss: 1801.8213\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6195 - val_loss: 1801.8230\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6196 - val_loss: 1801.8236\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6199 - val_loss: 1801.8252\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6201 - val_loss: 1801.8259\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6203 - val_loss: 1801.8275\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6204 - val_loss: 1801.8279\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6206 - val_loss: 1801.8289\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6208 - val_loss: 1801.8293\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 172.6210 - val_loss: 1801.8297\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6212 - val_loss: 1801.8297\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6214 - val_loss: 1801.8304\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6216 - val_loss: 1801.8304\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6218 - val_loss: 1801.8311\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6219 - val_loss: 1801.8314\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6222 - val_loss: 1801.8320\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6223 - val_loss: 1801.8320\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6224 - val_loss: 1801.8324\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6226 - val_loss: 1801.8324\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 172.6227 - val_loss: 1801.8323\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6230 - val_loss: 1801.8326\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6231 - val_loss: 1801.8324\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 172.6232 - val_loss: 1801.8324\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6234 - val_loss: 1801.8328\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6235 - val_loss: 1801.8334\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6236 - val_loss: 1801.8328\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6239 - val_loss: 1801.8330\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6240 - val_loss: 1801.8330\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6241 - val_loss: 1801.8336\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6242 - val_loss: 1801.8336\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 172.6243 - val_loss: 1801.8333\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6245 - val_loss: 1801.8337\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6246 - val_loss: 1801.8334\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 172.6248 - val_loss: 1801.8337\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6248 - val_loss: 1801.8337\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6250 - val_loss: 1801.8336\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6251 - val_loss: 1801.8336\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6252 - val_loss: 1801.8336\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 172.6253 - val_loss: 1801.8336\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 172.6254 - val_loss: 1801.8326\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6256 - val_loss: 1801.8326\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6257 - val_loss: 1801.8326\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6258 - val_loss: 1801.8324\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 172.6259 - val_loss: 1801.8324\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 172.6259 - val_loss: 1801.8323\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6261 - val_loss: 1801.8318\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6261 - val_loss: 1801.8318\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6263 - val_loss: 1801.8323\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6264 - val_loss: 1801.8324\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 172.6265 - val_loss: 1801.8318\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6265 - val_loss: 1801.8308\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6267 - val_loss: 1801.8308\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6268 - val_loss: 1801.8313\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6268 - val_loss: 1801.8308\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6269 - val_loss: 1801.8313\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 172.6270 - val_loss: 1801.8311\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6270 - val_loss: 1801.8307\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 172.6272 - val_loss: 1801.8307\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6272 - val_loss: 1801.8307\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6273 - val_loss: 1801.8307\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6275 - val_loss: 1801.8301\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6276 - val_loss: 1801.8307\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6275 - val_loss: 1801.8301\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6276 - val_loss: 1801.8298\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6277 - val_loss: 1801.8301\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6278 - val_loss: 1801.8301\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6279 - val_loss: 1801.8301\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6280 - val_loss: 1801.8303\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 172.6280 - val_loss: 1801.8301\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6281 - val_loss: 1801.8301\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 172.6282 - val_loss: 1801.8311\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6282 - val_loss: 1801.8311\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6282 - val_loss: 1801.8301\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6283 - val_loss: 1801.8293\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6283 - val_loss: 1801.8289\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6284 - val_loss: 1801.8293\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6284 - val_loss: 1801.8289\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6285 - val_loss: 1801.8289\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6286 - val_loss: 1801.8289\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6287 - val_loss: 1801.8301\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6287 - val_loss: 1801.8289\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6288 - val_loss: 1801.8289\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 172.6288 - val_loss: 1801.8284\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6288 - val_loss: 1801.8274\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 172.6289 - val_loss: 1801.8274\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6290 - val_loss: 1801.8274\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 172.6290 - val_loss: 1801.8269\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 172.6290 - val_loss: 1801.8265\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 172.6291 - val_loss: 1801.8265\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 172.6291 - val_loss: 1801.8274\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6292 - val_loss: 1801.8279\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6292 - val_loss: 1801.8279\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6292 - val_loss: 1801.8274\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6292 - val_loss: 1801.8274\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6293 - val_loss: 1801.8274\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6294 - val_loss: 1801.8274\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6294 - val_loss: 1801.8262\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6295 - val_loss: 1801.8262\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6295 - val_loss: 1801.8262\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6296 - val_loss: 1801.8274\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6296 - val_loss: 1801.8279\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6295 - val_loss: 1801.8279\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6295 - val_loss: 1801.8275\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6296 - val_loss: 1801.8256\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.6297 - val_loss: 1801.8254\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.6298 - val_loss: 1801.8262\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6298 - val_loss: 1801.8269\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.6298 - val_loss: 1801.8271\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 172.6298 - val_loss: 1801.8256\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.1552, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0026, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0004, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0102, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.8734, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 461ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.30453548e+01, 7.26643137e+01, 7.22407843e+01, 7.18172549e+01,\n",
       "        7.25410385e+01, 0.00000000e+00, 0.00000000e+00, 2.12277430e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.35334440e-01, 7.82640300e-02,\n",
       "        4.61028130e-01, 7.07828431e+01, 7.07576330e+01, 7.07324230e+01,\n",
       "        7.07072129e+01, 7.06820028e+01, 7.44114846e+01, 7.41013772e+01,\n",
       "        7.37736461e+01, 7.34459150e+01, 7.31181839e+01, 7.27584314e+01,\n",
       "        7.23349020e+01, 7.19113725e+01, 7.14878431e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.32517040e+01, 7.29239729e+01, 7.25074510e+01,\n",
       "        7.20839216e+01, 7.16603922e+01, 7.12368628e+01, 7.11425397e+01,\n",
       "        7.10618674e+01, 7.09811951e+01, 1.65300410e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.36403780e-01, 9.94302450e-01, 5.25311650e-01,\n",
       "        1.91368850e-01, 0.00000000e+00, 3.70619710e-01, 7.20054902e+01,\n",
       "        7.15819608e+01, 0.00000000e+00, 0.00000000e+00, 7.33245331e+01,\n",
       "        7.29968020e+01, 7.26015686e+01, 7.21780392e+01, 7.17545098e+01,\n",
       "        7.13309804e+01, 7.11604669e+01, 7.10797946e+01, 7.09991223e+01,\n",
       "        1.08551530e-02, 1.52217552e-01, 7.19270588e+01, 7.15035294e+01,\n",
       "        7.11933333e+01, 7.11126611e+01, 7.10319888e+01, 7.09513165e+01,\n",
       "        7.08724790e+01, 7.07968487e+01, 7.07212185e+01, 2.27639120e-02,\n",
       "        0.00000000e+00, 4.54919891e+01, 1.04988220e-02, 3.80814075e-01,\n",
       "        1.42019778e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.59078369e+01, 3.72164428e-01, 2.53180176e-01, 3.17293674e-01,\n",
       "        0.00000000e+00, 3.66555005e-01, 1.13219619e+00, 0.00000000e+00,\n",
       "        1.67774081e-01, 2.59423435e-01, 1.27596036e-02, 1.06054592e+00,\n",
       "        3.85792702e-02, 2.31640100e-01, 0.00000000e+00, 3.00421208e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60.01067927, 59.98406863, 59.95745798, 59.93084734, 59.90423669,\n",
       "       59.87762605, 59.85101541, 59.82440476, 59.79779412, 59.77118347,\n",
       "       59.74457283, 59.71796218, 59.69135154, 59.6647409 , 59.63813025,\n",
       "       59.61151961, 59.58490896, 59.55829832, 59.53168768, 59.50507703,\n",
       "       59.47846639, 59.45185574, 59.4252451 , 59.39863445, 59.37202381,\n",
       "       59.34541317, 59.31880252, 59.29219188, 59.26558123, 59.23897059,\n",
       "       59.21235994, 59.1857493 , 59.15913866, 59.13252801, 59.10591737,\n",
       "       59.07930672, 59.05269608, 59.02608543, 58.99947479, 58.97286415,\n",
       "       58.9462535 , 58.91964286, 58.89303221, 58.86642157, 58.83981092,\n",
       "       58.81320028, 58.78658964, 58.75997899, 58.73336835, 58.7067577 ,\n",
       "       58.68014706, 58.65353641, 58.62692577, 58.60031513, 58.57370448,\n",
       "       58.54709384, 58.52048319, 58.49387255, 58.4672619 , 58.44065126,\n",
       "       58.41404062, 58.38742997, 58.36081933, 58.33420868, 58.30759804,\n",
       "       58.28098739, 58.25437675, 58.22776611, 58.20115546, 58.17454482,\n",
       "       58.14793417, 58.12132353, 58.09471289, 58.06810224, 58.0414916 ,\n",
       "       58.01488095, 57.98827031, 57.96165966, 57.93504902, 57.90843838,\n",
       "       57.88182773, 57.85521709, 57.82860644, 57.8019958 , 57.78559131,\n",
       "       57.77001435, 57.75443738, 57.73886042, 57.72328346, 57.7077065 ,\n",
       "       57.69212953, 57.67655257, 57.66097561, 57.64539865, 57.62982168,\n",
       "       57.61424472, 57.59866776, 57.5830908 , 57.56751383, 57.55193687])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.17590060278566\n",
      "35.506276259010534\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
