{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "1645    67.357190\n",
       "1646    67.347852\n",
       "1647    67.338515\n",
       "1648    67.329178\n",
       "1649    67.319841\n",
       "Name: C2, Length: 1650, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c2_interpolated_1550_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "1545     0.525366\n",
       "1546     0.064448\n",
       "1547     0.292134\n",
       "1548     0.000000\n",
       "1549     0.000000\n",
       "Name: C2, Length: 1550, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1550)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.500000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.275910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.051821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.827731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.603641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     90.500000  0.000298\n",
       "1     90.275910  0.000298\n",
       "2     90.051821  0.000297\n",
       "3     89.827731  0.000297\n",
       "4     89.603641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.1552  # Value for C0\n",
    "K0 = -0.0026  # Value for K0\n",
    "K1 = -0.0004  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0102    # Value for b\n",
    "c = 2.8734    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    90.500000    90.275910    90.051821    89.827731    89.603641   \n",
      "351    90.275910    90.051821    89.827731    89.603641    89.379552   \n",
      "352    90.051821    89.827731    89.603641    89.379552    89.155462   \n",
      "353    89.827731    89.603641    89.379552    89.155462    88.931373   \n",
      "354    89.603641    89.379552    89.155462    88.931373    88.707283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.379552    89.155462    88.931373    88.707283    88.494958  ...   \n",
      "351    89.155462    88.931373    88.707283    88.494958    88.427731  ...   \n",
      "352    88.931373    88.707283    88.494958    88.427731    88.360504  ...   \n",
      "353    88.707283    88.494958    88.427731    88.360504    88.293277  ...   \n",
      "354    88.494958    88.427731    88.360504    88.293277    88.226050  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.071008    0.000263   79.054202    0.000263   79.037395    0.000263   \n",
      "351   79.054202    0.000263   79.037395    0.000263   79.020588    0.000262   \n",
      "352   79.037395    0.000263   79.020588    0.000262   79.003782    0.000262   \n",
      "353   79.020588    0.000262   79.003782    0.000262   78.986975    0.000262   \n",
      "354   79.003782    0.000262   78.986975    0.000262   78.970168    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.020588    0.000262   79.003782    0.000262  \n",
      "351   79.003782    0.000262   78.986975    0.000262  \n",
      "352   78.986975    0.000262   78.970168    0.000262  \n",
      "353   78.970168    0.000262   78.953361    0.000262  \n",
      "354   78.953361    0.000262   78.936555    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 1, 251) (1100, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "14/14 [==============================] - 2s 40ms/step - loss: 5555.3462 - val_loss: 4427.3379\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5457.9873 - val_loss: 4381.1016\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5397.6206 - val_loss: 4327.4248\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5340.4585 - val_loss: 4279.8862\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5285.1123 - val_loss: 4232.8804\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5230.3633 - val_loss: 4186.4175\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5176.1846 - val_loss: 4140.4556\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5122.5317 - val_loss: 4094.9634\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5069.3691 - val_loss: 4049.9155\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 5016.6758 - val_loss: 4005.2952\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4964.4341 - val_loss: 3961.0898\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4912.6328 - val_loss: 3917.2932\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4861.2627 - val_loss: 3873.8948\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4810.3149 - val_loss: 3830.8901\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4759.7837 - val_loss: 3788.2742\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4709.6641 - val_loss: 3746.0413\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4659.9512 - val_loss: 3704.1877\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4610.6406 - val_loss: 3662.7102\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4561.7285 - val_loss: 3621.6055\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4513.2119 - val_loss: 3580.8696\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4465.0864 - val_loss: 3540.5002\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4417.3496 - val_loss: 3500.4934\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4369.9980 - val_loss: 3460.8477\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4323.0293 - val_loss: 3421.5601\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4276.4399 - val_loss: 3382.6267\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4230.2280 - val_loss: 3344.0461\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4184.3901 - val_loss: 3305.8159\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4138.9248 - val_loss: 3267.9336\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4093.8284 - val_loss: 3230.3972\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4049.0984 - val_loss: 3192.0945\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4001.5784 - val_loss: 3151.4395\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3952.6677 - val_loss: 3110.9517\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3904.5740 - val_loss: 3071.4180\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 3857.5159 - val_loss: 3032.7131\n",
      "Epoch 35/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3811.3252 - val_loss: 2994.7000\n",
      "Epoch 36/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3765.8618 - val_loss: 2957.2869\n",
      "Epoch 37/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3721.0342 - val_loss: 2920.4114\n",
      "Epoch 38/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3676.7795 - val_loss: 2884.0317\n",
      "Epoch 39/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3633.0557 - val_loss: 2848.1177\n",
      "Epoch 40/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3589.8301 - val_loss: 2812.6455\n",
      "Epoch 41/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3547.0801 - val_loss: 2777.5979\n",
      "Epoch 42/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3504.7859 - val_loss: 2742.9602\n",
      "Epoch 43/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3462.9319 - val_loss: 2708.7209\n",
      "Epoch 44/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 3421.5054 - val_loss: 2674.8699\n",
      "Epoch 45/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3380.4968 - val_loss: 2641.3987\n",
      "Epoch 46/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3339.8948 - val_loss: 2608.2981\n",
      "Epoch 47/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3299.6929 - val_loss: 2575.5637\n",
      "Epoch 48/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3259.8826 - val_loss: 2543.1875\n",
      "Epoch 49/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3220.4580 - val_loss: 2511.1655\n",
      "Epoch 50/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3181.4136 - val_loss: 2479.4917\n",
      "Epoch 51/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3142.7437 - val_loss: 2448.1621\n",
      "Epoch 52/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3104.4431 - val_loss: 2417.1726\n",
      "Epoch 53/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3066.5073 - val_loss: 2386.5193\n",
      "Epoch 54/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3028.9326 - val_loss: 2356.1968\n",
      "Epoch 55/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2991.7136 - val_loss: 2326.2029\n",
      "Epoch 56/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2954.8474 - val_loss: 2296.5339\n",
      "Epoch 57/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2918.3306 - val_loss: 2267.1868\n",
      "Epoch 58/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2882.1597 - val_loss: 2238.1580\n",
      "Epoch 59/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2846.3301 - val_loss: 2209.4441\n",
      "Epoch 60/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2810.8403 - val_loss: 2181.0437\n",
      "Epoch 61/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2775.6858 - val_loss: 2152.9524\n",
      "Epoch 62/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2740.8647 - val_loss: 2125.1685\n",
      "Epoch 63/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2706.3738 - val_loss: 2097.6887\n",
      "Epoch 64/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2672.2104 - val_loss: 2070.5110\n",
      "Epoch 65/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2638.3718 - val_loss: 2043.6324\n",
      "Epoch 66/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2604.8555 - val_loss: 2017.0510\n",
      "Epoch 67/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2571.6582 - val_loss: 1990.7632\n",
      "Epoch 68/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2538.7781 - val_loss: 1964.7682\n",
      "Epoch 69/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2506.2124 - val_loss: 1939.0621\n",
      "Epoch 70/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2473.9590 - val_loss: 1913.6447\n",
      "Epoch 71/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2442.0156 - val_loss: 1888.5120\n",
      "Epoch 72/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2410.3796 - val_loss: 1863.6621\n",
      "Epoch 73/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2379.0488 - val_loss: 1839.0938\n",
      "Epoch 74/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2348.0210 - val_loss: 1814.8035\n",
      "Epoch 75/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2317.2937 - val_loss: 1790.7908\n",
      "Epoch 76/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2286.8655 - val_loss: 1767.0518\n",
      "Epoch 77/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2256.7339 - val_loss: 1743.5857\n",
      "Epoch 78/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2226.8960 - val_loss: 1720.3899\n",
      "Epoch 79/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2197.3508 - val_loss: 1697.4633\n",
      "Epoch 80/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 2168.0959 - val_loss: 1674.8024\n",
      "Epoch 81/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2139.1296 - val_loss: 1652.4072\n",
      "Epoch 82/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2110.4495 - val_loss: 1630.2740\n",
      "Epoch 83/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2082.0540 - val_loss: 1608.4016\n",
      "Epoch 84/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2053.9402 - val_loss: 1586.7881\n",
      "Epoch 85/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2026.1068 - val_loss: 1565.4315\n",
      "Epoch 86/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1998.5521 - val_loss: 1544.3298\n",
      "Epoch 87/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1971.2734 - val_loss: 1523.4817\n",
      "Epoch 88/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1944.2697 - val_loss: 1502.8845\n",
      "Epoch 89/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1917.5389 - val_loss: 1482.5372\n",
      "Epoch 90/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1891.0785 - val_loss: 1462.4375\n",
      "Epoch 91/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1864.8878 - val_loss: 1442.5840\n",
      "Epoch 92/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1838.9637 - val_loss: 1422.9746\n",
      "Epoch 93/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1813.3057 - val_loss: 1403.6071\n",
      "Epoch 94/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1787.9114 - val_loss: 1384.4810\n",
      "Epoch 95/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1762.7784 - val_loss: 1365.5927\n",
      "Epoch 96/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1737.9056 - val_loss: 1346.9421\n",
      "Epoch 97/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1713.2916 - val_loss: 1328.5270\n",
      "Epoch 98/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1688.9337 - val_loss: 1310.3456\n",
      "Epoch 99/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1664.8302 - val_loss: 1292.3960\n",
      "Epoch 100/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1640.9806 - val_loss: 1274.6771\n",
      "Epoch 101/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1617.3824 - val_loss: 1257.1864\n",
      "Epoch 102/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1594.0333 - val_loss: 1239.9227\n",
      "Epoch 103/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1570.9325 - val_loss: 1222.8839\n",
      "Epoch 104/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1548.0778 - val_loss: 1206.0691\n",
      "Epoch 105/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1525.4675 - val_loss: 1189.4755\n",
      "Epoch 106/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1503.1008 - val_loss: 1173.1022\n",
      "Epoch 107/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1480.9751 - val_loss: 1156.9481\n",
      "Epoch 108/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1459.0891 - val_loss: 1141.0110\n",
      "Epoch 109/500\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1437.4410 - val_loss: 1125.2888\n",
      "Epoch 110/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1416.0295 - val_loss: 1109.7808\n",
      "Epoch 111/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1394.8531 - val_loss: 1094.4845\n",
      "Epoch 112/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1373.9098 - val_loss: 1079.3988\n",
      "Epoch 113/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1353.1978 - val_loss: 1064.5221\n",
      "Epoch 114/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1332.7152 - val_loss: 1049.8522\n",
      "Epoch 115/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1312.4612 - val_loss: 1035.3887\n",
      "Epoch 116/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1292.4341 - val_loss: 1021.1289\n",
      "Epoch 117/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1272.6324 - val_loss: 1007.0717\n",
      "Epoch 118/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1253.0537 - val_loss: 993.2158\n",
      "Epoch 119/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1233.6980 - val_loss: 979.5590\n",
      "Epoch 120/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1214.5623 - val_loss: 966.1002\n",
      "Epoch 121/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1195.6458 - val_loss: 952.8380\n",
      "Epoch 122/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1176.9464 - val_loss: 939.7701\n",
      "Epoch 123/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1158.4626 - val_loss: 926.8954\n",
      "Epoch 124/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1140.1937 - val_loss: 914.2128\n",
      "Epoch 125/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1122.1373 - val_loss: 901.7200\n",
      "Epoch 126/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1104.2921 - val_loss: 889.4158\n",
      "Epoch 127/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1086.6566 - val_loss: 877.2993\n",
      "Epoch 128/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1069.2295 - val_loss: 865.3678\n",
      "Epoch 129/500\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1052.0093 - val_loss: 853.6211\n",
      "Epoch 130/500\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 1034.9941 - val_loss: 842.0563\n",
      "Epoch 131/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1018.1826 - val_loss: 830.6727\n",
      "Epoch 132/500\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1001.5735 - val_loss: 819.4689\n",
      "Epoch 133/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 985.1651 - val_loss: 808.4427\n",
      "Epoch 134/500\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 968.9563 - val_loss: 797.5936\n",
      "Epoch 135/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 952.9449 - val_loss: 786.9193\n",
      "Epoch 136/500\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 937.1298 - val_loss: 776.4186\n",
      "Epoch 137/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 921.5100 - val_loss: 766.0902\n",
      "Epoch 138/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 906.0831 - val_loss: 755.9324\n",
      "Epoch 139/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 890.8484 - val_loss: 745.9437\n",
      "Epoch 140/500\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 875.8041 - val_loss: 736.1229\n",
      "Epoch 141/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 860.9491 - val_loss: 726.4682\n",
      "Epoch 142/500\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 846.2816 - val_loss: 716.9785\n",
      "Epoch 143/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 831.8002 - val_loss: 707.6517\n",
      "Epoch 144/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 817.5036 - val_loss: 698.4872\n",
      "Epoch 145/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 803.3906 - val_loss: 689.4831\n",
      "Epoch 146/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 789.4589 - val_loss: 680.6379\n",
      "Epoch 147/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 775.7079 - val_loss: 671.9504\n",
      "Epoch 148/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 762.1363 - val_loss: 663.4188\n",
      "Epoch 149/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 748.7420 - val_loss: 655.0416\n",
      "Epoch 150/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 735.5239 - val_loss: 646.8183\n",
      "Epoch 151/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 722.4808 - val_loss: 638.7465\n",
      "Epoch 152/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 709.6110 - val_loss: 630.8251\n",
      "Epoch 153/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 696.9131 - val_loss: 623.0529\n",
      "Epoch 154/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 684.3861 - val_loss: 615.4277\n",
      "Epoch 155/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 672.0281 - val_loss: 607.9493\n",
      "Epoch 156/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 659.8381 - val_loss: 600.6151\n",
      "Epoch 157/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 647.8144 - val_loss: 593.4245\n",
      "Epoch 158/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 635.9558 - val_loss: 586.3756\n",
      "Epoch 159/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 624.2609 - val_loss: 579.4673\n",
      "Epoch 160/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 612.7283 - val_loss: 572.6981\n",
      "Epoch 161/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 601.3568 - val_loss: 566.0666\n",
      "Epoch 162/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 590.1447 - val_loss: 559.5714\n",
      "Epoch 163/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 579.0910 - val_loss: 553.2109\n",
      "Epoch 164/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 568.1939 - val_loss: 546.9840\n",
      "Epoch 165/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 557.4523 - val_loss: 540.8892\n",
      "Epoch 166/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 546.8649 - val_loss: 534.9252\n",
      "Epoch 167/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 536.4304 - val_loss: 529.0905\n",
      "Epoch 168/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 526.1472 - val_loss: 523.3839\n",
      "Epoch 169/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 516.0142 - val_loss: 517.8037\n",
      "Epoch 170/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 506.0298 - val_loss: 512.3489\n",
      "Epoch 171/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 496.1930 - val_loss: 507.0179\n",
      "Epoch 172/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 486.5022 - val_loss: 501.8093\n",
      "Epoch 173/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 476.9561 - val_loss: 496.7217\n",
      "Epoch 174/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 467.5533 - val_loss: 491.7543\n",
      "Epoch 175/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 458.2927 - val_loss: 486.9052\n",
      "Epoch 176/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 449.1730 - val_loss: 482.1729\n",
      "Epoch 177/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 440.1925 - val_loss: 477.5564\n",
      "Epoch 178/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 431.3501 - val_loss: 473.0542\n",
      "Epoch 179/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 422.6448 - val_loss: 468.6651\n",
      "Epoch 180/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 414.0747 - val_loss: 464.3875\n",
      "Epoch 181/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 405.6391 - val_loss: 460.2204\n",
      "Epoch 182/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 397.3363 - val_loss: 456.1624\n",
      "Epoch 183/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 389.1651 - val_loss: 452.2117\n",
      "Epoch 184/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 381.1244 - val_loss: 448.3676\n",
      "Epoch 185/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 373.2124 - val_loss: 444.6284\n",
      "Epoch 186/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 365.4282 - val_loss: 440.9927\n",
      "Epoch 187/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 357.7702 - val_loss: 437.4594\n",
      "Epoch 188/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 350.2375 - val_loss: 434.0274\n",
      "Epoch 189/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 342.8290 - val_loss: 430.6949\n",
      "Epoch 190/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 335.5429 - val_loss: 427.4607\n",
      "Epoch 191/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 328.3781 - val_loss: 424.3236\n",
      "Epoch 192/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 321.3333 - val_loss: 421.2824\n",
      "Epoch 193/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 314.4073 - val_loss: 418.3357\n",
      "Epoch 194/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 307.5988 - val_loss: 415.4822\n",
      "Epoch 195/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 300.9066 - val_loss: 412.7205\n",
      "Epoch 196/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 294.3294 - val_loss: 410.0493\n",
      "Epoch 197/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 287.8657 - val_loss: 407.4676\n",
      "Epoch 198/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 281.5146 - val_loss: 404.9738\n",
      "Epoch 199/500\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 275.2746 - val_loss: 402.5666\n",
      "Epoch 200/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 269.1446 - val_loss: 400.2451\n",
      "Epoch 201/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 263.1234 - val_loss: 398.0078\n",
      "Epoch 202/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 257.2099 - val_loss: 395.8533\n",
      "Epoch 203/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 251.4026 - val_loss: 393.7805\n",
      "Epoch 204/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 245.7004 - val_loss: 391.7881\n",
      "Epoch 205/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 240.1021 - val_loss: 389.8752\n",
      "Epoch 206/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 234.6065 - val_loss: 388.0399\n",
      "Epoch 207/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 229.2124 - val_loss: 386.2812\n",
      "Epoch 208/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 223.9183 - val_loss: 384.5981\n",
      "Epoch 209/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 218.7232 - val_loss: 382.9891\n",
      "Epoch 210/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 213.6259 - val_loss: 381.4531\n",
      "Epoch 211/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 208.6252 - val_loss: 379.9889\n",
      "Epoch 212/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 203.7200 - val_loss: 378.5952\n",
      "Epoch 213/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 198.9089 - val_loss: 377.2705\n",
      "Epoch 214/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 194.1907 - val_loss: 376.0142\n",
      "Epoch 215/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 189.5644 - val_loss: 374.8245\n",
      "Epoch 216/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 185.0289 - val_loss: 373.7007\n",
      "Epoch 217/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 180.5828 - val_loss: 372.6413\n",
      "Epoch 218/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 176.2254 - val_loss: 371.6454\n",
      "Epoch 219/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 171.9549 - val_loss: 370.7113\n",
      "Epoch 220/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 167.7704 - val_loss: 369.8384\n",
      "Epoch 221/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 163.6707 - val_loss: 369.0249\n",
      "Epoch 222/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 159.6548 - val_loss: 368.2703\n",
      "Epoch 223/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 155.7215 - val_loss: 367.5730\n",
      "Epoch 224/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 151.8697 - val_loss: 366.9319\n",
      "Epoch 225/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 148.0980 - val_loss: 366.3461\n",
      "Epoch 226/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 144.4055 - val_loss: 365.8142\n",
      "Epoch 227/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 140.7914 - val_loss: 365.3352\n",
      "Epoch 228/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 137.2542 - val_loss: 364.9079\n",
      "Epoch 229/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 133.7927 - val_loss: 364.5312\n",
      "Epoch 230/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 130.4060 - val_loss: 364.2038\n",
      "Epoch 231/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 127.0928 - val_loss: 363.9249\n",
      "Epoch 232/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 123.8523 - val_loss: 363.6933\n",
      "Epoch 233/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 120.6832 - val_loss: 363.5078\n",
      "Epoch 234/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 117.5844 - val_loss: 363.3675\n",
      "Epoch 235/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 114.5549 - val_loss: 363.2711\n",
      "Epoch 236/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 111.5939 - val_loss: 363.2178\n",
      "Epoch 237/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 108.6999 - val_loss: 363.2062\n",
      "Epoch 238/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 105.5872 - val_loss: 363.3454\n",
      "Epoch 239/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 100.7474 - val_loss: 363.5393\n",
      "Epoch 240/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 96.9498 - val_loss: 363.8016\n",
      "Epoch 241/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 93.4221 - val_loss: 364.1153\n",
      "Epoch 242/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 90.1504 - val_loss: 364.4748\n",
      "Epoch 243/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 87.0821 - val_loss: 364.8771\n",
      "Epoch 244/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 84.1798 - val_loss: 365.3194\n",
      "Epoch 245/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 81.4182 - val_loss: 365.7999\n",
      "Epoch 246/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 78.7799 - val_loss: 366.3165\n",
      "Epoch 247/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 76.2525 - val_loss: 366.8675\n",
      "Epoch 248/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 73.8265 - val_loss: 367.4508\n",
      "Epoch 249/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 71.4943 - val_loss: 368.0652\n",
      "Epoch 250/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 69.2496 - val_loss: 368.7088\n",
      "Epoch 251/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 67.0873 - val_loss: 369.3803\n",
      "Epoch 252/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 65.0030 - val_loss: 370.0782\n",
      "Epoch 253/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 62.9929 - val_loss: 370.8011\n",
      "Epoch 254/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 61.0532 - val_loss: 371.5476\n",
      "Epoch 255/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 59.1811 - val_loss: 372.3166\n",
      "Epoch 256/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 57.3737 - val_loss: 373.1067\n",
      "Epoch 257/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 55.6284 - val_loss: 373.9168\n",
      "Epoch 258/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 53.9429 - val_loss: 374.7457\n",
      "Epoch 259/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 52.3149 - val_loss: 375.5922\n",
      "Epoch 260/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 50.7425 - val_loss: 376.4555\n",
      "Epoch 261/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 49.2235 - val_loss: 377.3342\n",
      "Epoch 262/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 47.7562 - val_loss: 378.2274\n",
      "Epoch 263/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 46.3390 - val_loss: 379.1342\n",
      "Epoch 264/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 44.9702 - val_loss: 380.0533\n",
      "Epoch 265/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 43.6479 - val_loss: 380.9844\n",
      "Epoch 266/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 42.3710 - val_loss: 381.9260\n",
      "Epoch 267/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 41.1378 - val_loss: 382.8774\n",
      "Epoch 268/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 39.9470 - val_loss: 383.8376\n",
      "Epoch 269/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 38.7974 - val_loss: 384.8058\n",
      "Epoch 270/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 37.6876 - val_loss: 385.7814\n",
      "Epoch 271/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 36.6164 - val_loss: 386.7634\n",
      "Epoch 272/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 35.5827 - val_loss: 387.7510\n",
      "Epoch 273/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 34.5851 - val_loss: 388.7435\n",
      "Epoch 274/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 33.6227 - val_loss: 389.7402\n",
      "Epoch 275/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 32.6942 - val_loss: 390.7404\n",
      "Epoch 276/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 31.7988 - val_loss: 391.7434\n",
      "Epoch 277/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 30.9353 - val_loss: 392.7485\n",
      "Epoch 278/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 30.1028 - val_loss: 393.7551\n",
      "Epoch 279/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 29.3004 - val_loss: 394.7623\n",
      "Epoch 280/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 28.5270 - val_loss: 395.7701\n",
      "Epoch 281/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 27.7818 - val_loss: 396.7771\n",
      "Epoch 282/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 27.0640 - val_loss: 397.7833\n",
      "Epoch 283/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 26.3726 - val_loss: 398.7876\n",
      "Epoch 284/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 25.7069 - val_loss: 399.7900\n",
      "Epoch 285/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 25.0660 - val_loss: 400.7900\n",
      "Epoch 286/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 24.4491 - val_loss: 401.7867\n",
      "Epoch 287/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.8555 - val_loss: 402.7799\n",
      "Epoch 288/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.2844 - val_loss: 403.7689\n",
      "Epoch 289/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 22.7351 - val_loss: 404.7537\n",
      "Epoch 290/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 22.2068 - val_loss: 405.7333\n",
      "Epoch 291/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 21.6990 - val_loss: 406.7074\n",
      "Epoch 292/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 21.2110 - val_loss: 407.6759\n",
      "Epoch 293/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 20.7420 - val_loss: 408.6381\n",
      "Epoch 294/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 20.2915 - val_loss: 409.5939\n",
      "Epoch 295/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 19.8588 - val_loss: 410.5428\n",
      "Epoch 296/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 19.4433 - val_loss: 411.4842\n",
      "Epoch 297/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 19.0445 - val_loss: 412.4182\n",
      "Epoch 298/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.6618 - val_loss: 413.3441\n",
      "Epoch 299/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 18.2946 - val_loss: 414.2621\n",
      "Epoch 300/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.9424 - val_loss: 415.1714\n",
      "Epoch 301/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.6048 - val_loss: 416.0718\n",
      "Epoch 302/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.2811 - val_loss: 416.9631\n",
      "Epoch 303/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 16.9709 - val_loss: 417.8454\n",
      "Epoch 304/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 16.6737 - val_loss: 418.7183\n",
      "Epoch 305/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 16.3890 - val_loss: 419.5814\n",
      "Epoch 306/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 16.1164 - val_loss: 420.4347\n",
      "Epoch 307/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 15.8554 - val_loss: 421.2774\n",
      "Epoch 308/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 15.6057 - val_loss: 422.1105\n",
      "Epoch 309/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 15.3668 - val_loss: 422.9331\n",
      "Epoch 310/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 15.1382 - val_loss: 423.7448\n",
      "Epoch 311/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 14.9196 - val_loss: 424.5460\n",
      "Epoch 312/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 14.7107 - val_loss: 425.3362\n",
      "Epoch 313/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 14.5110 - val_loss: 426.1157\n",
      "Epoch 314/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 14.3203 - val_loss: 426.8839\n",
      "Epoch 315/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.1381 - val_loss: 427.6410\n",
      "Epoch 316/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.9641 - val_loss: 428.3868\n",
      "Epoch 317/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.7981 - val_loss: 429.1215\n",
      "Epoch 318/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.6397 - val_loss: 429.8445\n",
      "Epoch 319/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.4885 - val_loss: 430.5561\n",
      "Epoch 320/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.3444 - val_loss: 431.2563\n",
      "Epoch 321/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.2069 - val_loss: 431.9448\n",
      "Epoch 322/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.0760 - val_loss: 432.6216\n",
      "Epoch 323/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.9512 - val_loss: 433.2873\n",
      "Epoch 324/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.8322 - val_loss: 433.9414\n",
      "Epoch 325/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.7190 - val_loss: 434.5838\n",
      "Epoch 326/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.6112 - val_loss: 435.2144\n",
      "Epoch 327/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.5087 - val_loss: 435.8336\n",
      "Epoch 328/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.4111 - val_loss: 436.4418\n",
      "Epoch 329/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.3182 - val_loss: 437.0382\n",
      "Epoch 330/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.2299 - val_loss: 437.6231\n",
      "Epoch 331/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.1460 - val_loss: 438.1964\n",
      "Epoch 332/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.0662 - val_loss: 438.7585\n",
      "Epoch 333/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 11.9905 - val_loss: 439.3094\n",
      "Epoch 334/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 11.9185 - val_loss: 439.8491\n",
      "Epoch 335/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.8502 - val_loss: 440.3774\n",
      "Epoch 336/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 11.7853 - val_loss: 440.8948\n",
      "Epoch 337/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.7238 - val_loss: 441.4012\n",
      "Epoch 338/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 11.6653 - val_loss: 441.8968\n",
      "Epoch 339/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 11.6100 - val_loss: 442.3815\n",
      "Epoch 340/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.5575 - val_loss: 442.8552\n",
      "Epoch 341/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.5077 - val_loss: 443.3184\n",
      "Epoch 342/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 11.4605 - val_loss: 443.7711\n",
      "Epoch 343/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.4159 - val_loss: 444.2136\n",
      "Epoch 344/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 11.3736 - val_loss: 444.6456\n",
      "Epoch 345/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.3335 - val_loss: 445.0675\n",
      "Epoch 346/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.2956 - val_loss: 445.4792\n",
      "Epoch 347/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.2597 - val_loss: 445.8810\n",
      "Epoch 348/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.2257 - val_loss: 446.2731\n",
      "Epoch 349/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.1936 - val_loss: 446.6555\n",
      "Epoch 350/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 11.1633 - val_loss: 447.0281\n",
      "Epoch 351/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 11.1346 - val_loss: 447.3913\n",
      "Epoch 352/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 11.1074 - val_loss: 447.7453\n",
      "Epoch 353/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.0818 - val_loss: 448.0900\n",
      "Epoch 354/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.0576 - val_loss: 448.4264\n",
      "Epoch 355/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 11.0347 - val_loss: 448.7532\n",
      "Epoch 356/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 11.0131 - val_loss: 449.0713\n",
      "Epoch 357/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.9927 - val_loss: 449.3808\n",
      "Epoch 358/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.9735 - val_loss: 449.6821\n",
      "Epoch 359/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.9553 - val_loss: 449.9749\n",
      "Epoch 360/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.9382 - val_loss: 450.2598\n",
      "Epoch 361/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.9220 - val_loss: 450.5367\n",
      "Epoch 362/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.9068 - val_loss: 450.8051\n",
      "Epoch 363/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.8924 - val_loss: 451.0662\n",
      "Epoch 364/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.8789 - val_loss: 451.3203\n",
      "Epoch 365/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.8661 - val_loss: 451.5663\n",
      "Epoch 366/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.8540 - val_loss: 451.8049\n",
      "Epoch 367/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.8427 - val_loss: 452.0369\n",
      "Epoch 368/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.8320 - val_loss: 452.2619\n",
      "Epoch 369/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.8220 - val_loss: 452.4800\n",
      "Epoch 370/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.8125 - val_loss: 452.6912\n",
      "Epoch 371/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.8036 - val_loss: 452.8960\n",
      "Epoch 372/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.7952 - val_loss: 453.0947\n",
      "Epoch 373/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.7872 - val_loss: 453.2869\n",
      "Epoch 374/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 10.7798 - val_loss: 453.4729\n",
      "Epoch 375/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.7727 - val_loss: 453.6527\n",
      "Epoch 376/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.7662 - val_loss: 453.8268\n",
      "Epoch 377/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.7600 - val_loss: 453.9952\n",
      "Epoch 378/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.7541 - val_loss: 454.1584\n",
      "Epoch 379/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 10.7486 - val_loss: 454.3158\n",
      "Epoch 380/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.7435 - val_loss: 454.4680\n",
      "Epoch 381/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 10.7386 - val_loss: 454.6153\n",
      "Epoch 382/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 10.7340 - val_loss: 454.7573\n",
      "Epoch 383/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 10.7297 - val_loss: 454.8943\n",
      "Epoch 384/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.7257 - val_loss: 455.0270\n",
      "Epoch 385/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 10.7219 - val_loss: 455.1545\n",
      "Epoch 386/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 10.7183 - val_loss: 455.2780\n",
      "Epoch 387/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.7149 - val_loss: 455.3972\n",
      "Epoch 388/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.7118 - val_loss: 455.5113\n",
      "Epoch 389/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 10.7088 - val_loss: 455.6221\n",
      "Epoch 390/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.7060 - val_loss: 455.7287\n",
      "Epoch 391/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 10.7034 - val_loss: 455.8312\n",
      "Epoch 392/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.7009 - val_loss: 455.9297\n",
      "Epoch 393/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 10.6986 - val_loss: 456.0251\n",
      "Epoch 394/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6964 - val_loss: 456.1165\n",
      "Epoch 395/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6943 - val_loss: 456.2046\n",
      "Epoch 396/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 10.6924 - val_loss: 456.2893\n",
      "Epoch 397/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6906 - val_loss: 456.3704\n",
      "Epoch 398/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6889 - val_loss: 456.4487\n",
      "Epoch 399/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 10.6873 - val_loss: 456.5238\n",
      "Epoch 400/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 10.6858 - val_loss: 456.5959\n",
      "Epoch 401/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6844 - val_loss: 456.6651\n",
      "Epoch 402/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6831 - val_loss: 456.7317\n",
      "Epoch 403/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6818 - val_loss: 456.7956\n",
      "Epoch 404/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6807 - val_loss: 456.8568\n",
      "Epoch 405/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6796 - val_loss: 456.9156\n",
      "Epoch 406/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6786 - val_loss: 456.9719\n",
      "Epoch 407/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6776 - val_loss: 457.0256\n",
      "Epoch 408/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6767 - val_loss: 457.0773\n",
      "Epoch 409/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6759 - val_loss: 457.1271\n",
      "Epoch 410/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 10.6751 - val_loss: 457.1746\n",
      "Epoch 411/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6744 - val_loss: 457.2203\n",
      "Epoch 412/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6737 - val_loss: 457.2634\n",
      "Epoch 413/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6731 - val_loss: 457.3053\n",
      "Epoch 414/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6724 - val_loss: 457.3452\n",
      "Epoch 415/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6719 - val_loss: 457.3828\n",
      "Epoch 416/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6714 - val_loss: 457.4194\n",
      "Epoch 417/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6708 - val_loss: 457.4539\n",
      "Epoch 418/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6704 - val_loss: 457.4869\n",
      "Epoch 419/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 10.6700 - val_loss: 457.5183\n",
      "Epoch 420/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6697 - val_loss: 457.5484\n",
      "Epoch 421/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 10.6693 - val_loss: 457.5773\n",
      "Epoch 422/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 10.6690 - val_loss: 457.6044\n",
      "Epoch 423/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 10.6686 - val_loss: 457.6305\n",
      "Epoch 424/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 10.6684 - val_loss: 457.6552\n",
      "Epoch 425/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 10.6681 - val_loss: 457.6789\n",
      "Epoch 426/500\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 10.6679 - val_loss: 457.7014\n",
      "Epoch 427/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6677 - val_loss: 457.7229\n",
      "Epoch 428/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6675 - val_loss: 457.7438\n",
      "Epoch 429/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6673 - val_loss: 457.7627\n",
      "Epoch 430/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6672 - val_loss: 457.7813\n",
      "Epoch 431/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6670 - val_loss: 457.7988\n",
      "Epoch 432/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6669 - val_loss: 457.8150\n",
      "Epoch 433/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6668 - val_loss: 457.8307\n",
      "Epoch 434/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6667 - val_loss: 457.8456\n",
      "Epoch 435/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6666 - val_loss: 457.8600\n",
      "Epoch 436/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6665 - val_loss: 457.8735\n",
      "Epoch 437/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6665 - val_loss: 457.8865\n",
      "Epoch 438/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6664 - val_loss: 457.8984\n",
      "Epoch 439/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6664 - val_loss: 457.9098\n",
      "Epoch 440/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6664 - val_loss: 457.9208\n",
      "Epoch 441/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6663 - val_loss: 457.9312\n",
      "Epoch 442/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6664 - val_loss: 457.9409\n",
      "Epoch 443/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6663 - val_loss: 457.9496\n",
      "Epoch 444/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6663 - val_loss: 457.9583\n",
      "Epoch 445/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 10.6664 - val_loss: 457.9662\n",
      "Epoch 446/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6664 - val_loss: 457.9742\n",
      "Epoch 447/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 10.6664 - val_loss: 457.9813\n",
      "Epoch 448/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 10.6665 - val_loss: 457.9881\n",
      "Epoch 449/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 10.6666 - val_loss: 457.9944\n",
      "Epoch 450/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 10.6666 - val_loss: 458.0006\n",
      "Epoch 451/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6667 - val_loss: 458.0063\n",
      "Epoch 452/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6668 - val_loss: 458.0117\n",
      "Epoch 453/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6668 - val_loss: 458.0169\n",
      "Epoch 454/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6669 - val_loss: 458.0219\n",
      "Epoch 455/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6670 - val_loss: 458.0260\n",
      "Epoch 456/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6671 - val_loss: 458.0306\n",
      "Epoch 457/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6672 - val_loss: 458.0341\n",
      "Epoch 458/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6673 - val_loss: 458.0379\n",
      "Epoch 459/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6674 - val_loss: 458.0415\n",
      "Epoch 460/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6675 - val_loss: 458.0446\n",
      "Epoch 461/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6676 - val_loss: 458.0475\n",
      "Epoch 462/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 10.6677 - val_loss: 458.0501\n",
      "Epoch 463/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6678 - val_loss: 458.0527\n",
      "Epoch 464/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6679 - val_loss: 458.0549\n",
      "Epoch 465/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6680 - val_loss: 458.0567\n",
      "Epoch 466/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6682 - val_loss: 458.0589\n",
      "Epoch 467/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6683 - val_loss: 458.0602\n",
      "Epoch 468/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 10.6684 - val_loss: 458.0621\n",
      "Epoch 469/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6686 - val_loss: 458.0630\n",
      "Epoch 470/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6687 - val_loss: 458.0648\n",
      "Epoch 471/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6689 - val_loss: 458.0664\n",
      "Epoch 472/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6690 - val_loss: 458.0675\n",
      "Epoch 473/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6691 - val_loss: 458.0682\n",
      "Epoch 474/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6693 - val_loss: 458.0694\n",
      "Epoch 475/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6694 - val_loss: 458.0702\n",
      "Epoch 476/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6696 - val_loss: 458.0710\n",
      "Epoch 477/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6697 - val_loss: 458.0718\n",
      "Epoch 478/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6699 - val_loss: 458.0724\n",
      "Epoch 479/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6700 - val_loss: 458.0731\n",
      "Epoch 480/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6701 - val_loss: 458.0735\n",
      "Epoch 481/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 10.6703 - val_loss: 458.0737\n",
      "Epoch 482/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 10.6705 - val_loss: 458.0740\n",
      "Epoch 483/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 10.6706 - val_loss: 458.0744\n",
      "Epoch 484/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 10.6707 - val_loss: 458.0744\n",
      "Epoch 485/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6709 - val_loss: 458.0744\n",
      "Epoch 486/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6711 - val_loss: 458.0745\n",
      "Epoch 487/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6712 - val_loss: 458.0745\n",
      "Epoch 488/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6714 - val_loss: 458.0745\n",
      "Epoch 489/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6716 - val_loss: 458.0745\n",
      "Epoch 490/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6718 - val_loss: 458.0747\n",
      "Epoch 491/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6719 - val_loss: 458.0746\n",
      "Epoch 492/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6720 - val_loss: 458.0746\n",
      "Epoch 493/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6722 - val_loss: 458.0746\n",
      "Epoch 494/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6724 - val_loss: 458.0745\n",
      "Epoch 495/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6725 - val_loss: 458.0742\n",
      "Epoch 496/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6727 - val_loss: 458.0739\n",
      "Epoch 497/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6728 - val_loss: 458.0737\n",
      "Epoch 498/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 10.6730 - val_loss: 458.0736\n",
      "Epoch 499/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6732 - val_loss: 458.0733\n",
      "Epoch 500/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6733 - val_loss: 458.0731\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.1552, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0026, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0004, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0102, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.8734, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 413ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71.07381886, 71.06485528, 71.05589169, 71.0469281 , 71.03796452,\n",
       "        71.02900093, 71.02003735, 71.01107376, 71.00211018, 70.99314659,\n",
       "        70.98418301, 70.97521942, 70.96625584, 70.95729225, 70.94832866,\n",
       "        70.93936508, 70.93040149, 70.92143791, 70.91247432, 70.90351074,\n",
       "        70.89488796, 70.88648459, 70.87808123, 70.86967787, 70.86127451,\n",
       "        70.85287115, 70.84446779, 70.83606443, 70.82766106, 70.8192577 ,\n",
       "        70.81085434, 70.80245098, 70.79404762, 70.78564426, 70.7772409 ,\n",
       "        70.76883754, 70.76043417, 70.75203081, 70.74362745, 70.73522409,\n",
       "        70.72682073, 70.71841737, 70.71001401, 70.70161064, 70.69320728,\n",
       "        70.68480392, 70.67640056, 74.5459384 , 74.445098  , 74.3442577 ,\n",
       "        74.2434174 , 74.1377918 , 74.0285481 , 73.9193044 , 73.8100607 ,\n",
       "        73.700817  , 73.5915733 , 73.4823296 , 73.3730859 , 73.2638422 ,\n",
       "        73.1545985 , 73.0453548 , 72.9361111 , 72.8054902 , 72.6643137 ,\n",
       "        72.5231373 , 72.3819608 , 72.2407843 , 72.0996078 , 71.9584314 ,\n",
       "        71.8172549 , 71.6760784 , 71.534902  , 72.5410385 ,  0.10867026,\n",
       "         0.08385991,  0.        ,  0.21000062,  0.        ,  0.        ,\n",
       "        64.88282013,  0.        ,  0.21227743,  0.2956785 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.87252134,\n",
       "         0.        ,  0.23533444,  0.        ,  0.10760771,  0.07826403,\n",
       "         0.        ,  0.35342345,  0.46102813,  0.        ,  0.11627189]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68.02210551, 68.01743697, 68.01276844, 68.00809991, 68.00343137,\n",
       "       67.99876284, 67.9940943 , 67.98942577, 67.98475724, 67.9800887 ,\n",
       "       67.97542017, 67.97075163, 67.9660831 , 67.96141457, 67.95674603,\n",
       "       67.9520775 , 67.94740896, 67.94274043, 67.9380719 , 67.93340336,\n",
       "       67.92873483, 67.92406629, 67.91939776, 67.91472923, 67.91006069,\n",
       "       67.90539216, 67.90072362, 67.89605509, 67.89138655, 67.88671802,\n",
       "       67.88204949, 67.87738095, 67.87271242, 67.86804388, 67.86337535,\n",
       "       67.85870682, 67.85403828, 67.84936975, 67.84470121, 67.84003268,\n",
       "       67.83536415, 67.83069561, 67.82602708, 67.82135854, 67.81669001,\n",
       "       67.81202148, 67.80735294, 67.80268441, 67.79603175, 67.78669468,\n",
       "       67.77735761, 67.76802054, 67.75868347, 67.74934641, 67.74000934,\n",
       "       67.73067227, 67.7213352 , 67.71199813, 67.70266106, 67.693324  ,\n",
       "       67.68398693, 67.67464986, 67.66531279, 67.65597572, 67.64663866,\n",
       "       67.63730159, 67.62796452, 67.61862745, 67.60929038, 67.59995331,\n",
       "       67.59061625, 67.58127918, 67.57194211, 67.56260504, 67.55326797,\n",
       "       67.54393091, 67.53459384, 67.52525677, 67.5159197 , 67.50658263,\n",
       "       67.49724556, 67.4879085 , 67.47857143, 67.46923436, 67.45989729,\n",
       "       67.45056022, 67.44122316, 67.43188609, 67.42254902, 67.41321195,\n",
       "       67.40387488, 67.39453782, 67.38520075, 67.37586368, 67.36652661,\n",
       "       67.35718954, 67.34785247, 67.33851541, 67.32917834, 67.31984127])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.837424106498574\n",
      "19.711262452373713\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
