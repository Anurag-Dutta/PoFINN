{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "1345    70.150817\n",
       "1346    70.144281\n",
       "1347    70.137745\n",
       "1348    70.131209\n",
       "1349    70.124673\n",
       "Name: C1, Length: 1350, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c2_interpolated_1250_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "1245    70.687605\n",
       "1246    70.684804\n",
       "1247    70.682003\n",
       "1248    70.679202\n",
       "1249    70.676401\n",
       "Name: C1, Length: 1250, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1250)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.500000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.275910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.051821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.827731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.603641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     90.500000  0.000298\n",
       "1     90.275910  0.000298\n",
       "2     90.051821  0.000297\n",
       "3     89.827731  0.000297\n",
       "4     89.603641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.1552  # Value for C0\n",
    "K0 = -0.0026  # Value for K0\n",
    "K1 = -0.0004  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0102    # Value for b\n",
    "c = 2.8734    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    90.500000    90.275910    90.051821    89.827731    89.603641   \n",
      "351    90.275910    90.051821    89.827731    89.603641    89.379552   \n",
      "352    90.051821    89.827731    89.603641    89.379552    89.155462   \n",
      "353    89.827731    89.603641    89.379552    89.155462    88.931373   \n",
      "354    89.603641    89.379552    89.155462    88.931373    88.707283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.379552    89.155462    88.931373    88.707283    88.494958  ...   \n",
      "351    89.155462    88.931373    88.707283    88.494958    88.427731  ...   \n",
      "352    88.931373    88.707283    88.494958    88.427731    88.360504  ...   \n",
      "353    88.707283    88.494958    88.427731    88.360504    88.293277  ...   \n",
      "354    88.494958    88.427731    88.360504    88.293277    88.226050  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.071008    0.000263   79.054202    0.000263   79.037395    0.000263   \n",
      "351   79.054202    0.000263   79.037395    0.000263   79.020588    0.000262   \n",
      "352   79.037395    0.000263   79.020588    0.000262   79.003782    0.000262   \n",
      "353   79.020588    0.000262   79.003782    0.000262   78.986975    0.000262   \n",
      "354   79.003782    0.000262   78.986975    0.000262   78.970168    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.020588    0.000262   79.003782    0.000262  \n",
      "351   79.003782    0.000262   78.986975    0.000262  \n",
      "352   78.986975    0.000262   78.970168    0.000262  \n",
      "353   78.970168    0.000262   78.953361    0.000262  \n",
      "354   78.953361    0.000262   78.936555    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1, 251) (800, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 2s 56ms/step - loss: 5846.0146 - val_loss: 5045.0757\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 5770.9717 - val_loss: 5008.2383\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5741.6084 - val_loss: 4981.8296\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5700.3892 - val_loss: 4941.1704\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5669.1367 - val_loss: 4913.5234\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5639.5566 - val_loss: 4886.0234\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5610.1646 - val_loss: 4858.7236\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5580.9805 - val_loss: 4831.6177\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5551.9907 - val_loss: 4804.6885\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5523.1758 - val_loss: 4777.9185\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5494.5234 - val_loss: 4751.2983\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5466.0205 - val_loss: 4724.8193\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5437.6611 - val_loss: 4698.4751\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5409.4375 - val_loss: 4672.2583\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5381.3428 - val_loss: 4646.1655\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5353.3760 - val_loss: 4620.1953\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5325.5327 - val_loss: 4594.3438\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5297.8110 - val_loss: 4568.6084\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5270.2080 - val_loss: 4542.9873\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5242.7217 - val_loss: 4517.4795\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5215.3511 - val_loss: 4492.0830\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5188.0942 - val_loss: 4466.7969\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5160.9502 - val_loss: 4441.6206\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5133.9175 - val_loss: 4416.5522\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5106.9966 - val_loss: 4391.5913\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5080.1846 - val_loss: 4366.7373\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 5053.4814 - val_loss: 4341.9883\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5026.8862 - val_loss: 4317.3452\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5000.3994 - val_loss: 4292.8062\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4974.0186 - val_loss: 4268.3701\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4947.7437 - val_loss: 4244.0381\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4921.5752 - val_loss: 4219.8086\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4895.5107 - val_loss: 4195.6816\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4869.5518 - val_loss: 4171.6553\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4843.6948 - val_loss: 4147.7295\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4817.9429 - val_loss: 4123.9053\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4792.2930 - val_loss: 4100.1812\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4766.7451 - val_loss: 4076.5559\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4741.2993 - val_loss: 4053.0305\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4715.9561 - val_loss: 4029.6040\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4690.7119 - val_loss: 4006.2749\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4665.5693 - val_loss: 3983.0444\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4640.5273 - val_loss: 3959.9116\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4615.5845 - val_loss: 3936.8757\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4590.7412 - val_loss: 3913.9368\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4565.9971 - val_loss: 3891.0938\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4541.3516 - val_loss: 3868.3472\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4516.8037 - val_loss: 3845.6960\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4492.3545 - val_loss: 3823.1401\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4468.0024 - val_loss: 3800.6802\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4443.7476 - val_loss: 3778.3140\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4419.5898 - val_loss: 3756.0422\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4395.5278 - val_loss: 3733.8640\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4371.5625 - val_loss: 3711.7800\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4347.6929 - val_loss: 3689.7891\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4323.9185 - val_loss: 3667.8911\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4300.2393 - val_loss: 3646.0854\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4276.6548 - val_loss: 3624.3726\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4253.1655 - val_loss: 3602.7515\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4229.7695 - val_loss: 3581.2219\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4206.4678 - val_loss: 3559.7839\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4183.2588 - val_loss: 3538.4370\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4160.1436 - val_loss: 3517.1816\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4137.1216 - val_loss: 3496.0151\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4114.1919 - val_loss: 3474.9399\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4091.3542 - val_loss: 3453.9543\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4068.6082 - val_loss: 3433.0586\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4045.9543 - val_loss: 3396.2026\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4004.5298 - val_loss: 3372.1250\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3977.9363 - val_loss: 3347.5918\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3951.4719 - val_loss: 3323.5298\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3925.5488 - val_loss: 3299.9727\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3900.1360 - val_loss: 3276.8481\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3875.1499 - val_loss: 3254.0835\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3850.5200 - val_loss: 3231.6216\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3826.1921 - val_loss: 3209.4226\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3802.1289 - val_loss: 3187.4563\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3778.3008 - val_loss: 3165.7000\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3754.6860 - val_loss: 3144.1355\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 3731.2668 - val_loss: 3122.7500\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3708.0312 - val_loss: 3101.5325\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3684.9663 - val_loss: 3080.4731\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3662.0652 - val_loss: 3059.5649\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3639.3188 - val_loss: 3038.8020\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3616.7212 - val_loss: 3018.1772\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 3594.2671 - val_loss: 2997.6887\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3571.9519 - val_loss: 2977.3301\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3549.7715 - val_loss: 2957.0991\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3527.7214 - val_loss: 2936.9912\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3505.7993 - val_loss: 2917.0039\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3484.0015 - val_loss: 2897.1367\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3462.3257 - val_loss: 2877.3845\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3440.7700 - val_loss: 2857.7461\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3419.3313 - val_loss: 2838.2207\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3398.0090 - val_loss: 2818.8052\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3376.8000 - val_loss: 2799.4978\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3355.7026 - val_loss: 2780.2981\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3334.7156 - val_loss: 2761.2046\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3313.8384 - val_loss: 2742.2153\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3293.0684 - val_loss: 2723.3293\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3272.4045 - val_loss: 2704.5454\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3251.8462 - val_loss: 2685.8625\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3231.3921 - val_loss: 2667.2805\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3211.0410 - val_loss: 2648.7971\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3190.7915 - val_loss: 2630.4114\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3170.6436 - val_loss: 2612.1230\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3150.5959 - val_loss: 2593.9316\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3130.6472 - val_loss: 2575.8357\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3110.7976 - val_loss: 2557.8352\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3091.0452 - val_loss: 2539.9277\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3071.3901 - val_loss: 2522.1147\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3051.8308 - val_loss: 2504.3940\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3032.3677 - val_loss: 2486.7661\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3010.0403 - val_loss: 2459.2388\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 2980.9236 - val_loss: 2437.9536\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2957.4165 - val_loss: 2416.7700\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2934.3081 - val_loss: 2396.1152\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2911.7729 - val_loss: 2375.9626\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2889.7434 - val_loss: 2356.2300\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2868.1348 - val_loss: 2336.8484\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2846.8774 - val_loss: 2317.7651\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2825.9216 - val_loss: 2298.9414\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2805.2297 - val_loss: 2280.3481\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2784.7744 - val_loss: 2261.9648\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2764.5347 - val_loss: 2243.7732\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 2744.4922 - val_loss: 2225.7612\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2724.6353 - val_loss: 2207.9170\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2704.9529 - val_loss: 2190.2319\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2685.4346 - val_loss: 2172.6997\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2666.0742 - val_loss: 2155.3120\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2646.8647 - val_loss: 2138.0647\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2627.8000 - val_loss: 2120.9517\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2608.8760 - val_loss: 2103.9705\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2590.0876 - val_loss: 2087.1167\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2571.4321 - val_loss: 2070.3855\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2552.9043 - val_loss: 2053.7759\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2534.5022 - val_loss: 2037.2844\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2516.2227 - val_loss: 2020.9089\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2498.0630 - val_loss: 2004.6458\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2480.0215 - val_loss: 1988.4945\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2462.0952 - val_loss: 1972.4524\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2444.2825 - val_loss: 1956.5182\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 2426.5820 - val_loss: 1940.6902\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2408.9915 - val_loss: 1924.9668\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2391.5090 - val_loss: 1909.3455\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2374.1333 - val_loss: 1893.8268\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2356.8638 - val_loss: 1878.4089\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2339.6985 - val_loss: 1863.0898\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2322.6355 - val_loss: 1847.8682\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2305.6746 - val_loss: 1832.7445\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2288.8145 - val_loss: 1817.7168\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2272.0537 - val_loss: 1802.7838\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 2255.3921 - val_loss: 1787.9453\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2238.8276 - val_loss: 1773.2000\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2222.3599 - val_loss: 1758.5463\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2205.9878 - val_loss: 1743.9856\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2189.7112 - val_loss: 1729.5149\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2173.5286 - val_loss: 1715.1348\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2157.4390 - val_loss: 1700.8428\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2141.4419 - val_loss: 1686.6404\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2125.5366 - val_loss: 1672.5264\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2109.7231 - val_loss: 1658.4988\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 2093.9995 - val_loss: 1644.5586\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2078.3665 - val_loss: 1630.7041\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2062.8220 - val_loss: 1616.9348\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2047.3666 - val_loss: 1603.2512\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 2031.9987 - val_loss: 1589.6516\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2016.7188 - val_loss: 1576.1357\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2001.5258 - val_loss: 1562.7032\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1986.4186 - val_loss: 1549.3536\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1971.3975 - val_loss: 1536.0859\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1956.4615 - val_loss: 1522.9001\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1941.6101 - val_loss: 1509.7953\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1926.8434 - val_loss: 1496.7720\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1912.1599 - val_loss: 1483.8289\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1897.5596 - val_loss: 1470.9651\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1883.0426 - val_loss: 1458.1809\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1868.6077 - val_loss: 1445.4760\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1854.2545 - val_loss: 1432.8495\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1839.9828 - val_loss: 1420.3011\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1825.7920 - val_loss: 1407.8306\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1811.6819 - val_loss: 1395.4371\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1797.6521 - val_loss: 1383.1207\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1783.7019 - val_loss: 1370.8806\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1769.8313 - val_loss: 1358.7174\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1756.0393 - val_loss: 1346.6296\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1742.3262 - val_loss: 1334.6171\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1728.6910 - val_loss: 1322.6799\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1715.1340 - val_loss: 1310.8170\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1701.6543 - val_loss: 1299.0286\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1688.2520 - val_loss: 1287.3141\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1674.9260 - val_loss: 1275.6735\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1661.6761 - val_loss: 1264.1058\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1648.5027 - val_loss: 1252.6112\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1635.4047 - val_loss: 1241.1896\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1622.3822 - val_loss: 1229.8391\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1609.4347 - val_loss: 1218.5615\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1596.5615 - val_loss: 1207.3551\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1583.7632 - val_loss: 1196.2206\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1571.0382 - val_loss: 1185.1562\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1558.3875 - val_loss: 1174.1626\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1545.8098 - val_loss: 1163.2399\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1533.3049 - val_loss: 1152.3873\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1520.8728 - val_loss: 1141.6033\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1508.5134 - val_loss: 1130.8903\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1496.2266 - val_loss: 1120.2454\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1484.0106 - val_loss: 1109.6697\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1471.8668 - val_loss: 1099.1624\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1459.7939 - val_loss: 1088.7234\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1447.7922 - val_loss: 1078.3523\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1435.8608 - val_loss: 1068.0493\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1423.9998 - val_loss: 1057.8130\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1412.2087 - val_loss: 1047.6444\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1400.4875 - val_loss: 1037.5420\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1388.8362 - val_loss: 1027.5071\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1377.2537 - val_loss: 1017.5379\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1365.7402 - val_loss: 1007.6346\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1354.2953 - val_loss: 997.7971\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1342.9191 - val_loss: 988.0256\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1331.6106 - val_loss: 978.3182\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1320.3699 - val_loss: 968.6763\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1309.1970 - val_loss: 959.0999\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1298.0912 - val_loss: 949.5864\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1287.0527 - val_loss: 940.1383\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1276.0808 - val_loss: 930.7531\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1265.1753 - val_loss: 921.4325\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1254.3363 - val_loss: 912.1749\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1243.5634 - val_loss: 902.9800\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1232.8561 - val_loss: 893.8478\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1222.2141 - val_loss: 884.7790\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1211.6375 - val_loss: 875.7723\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1201.1260 - val_loss: 866.8276\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1190.6792 - val_loss: 857.9445\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1180.2969 - val_loss: 849.1237\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1169.9789 - val_loss: 840.3638\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1159.7246 - val_loss: 831.6647\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1149.5341 - val_loss: 823.0266\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1139.4071 - val_loss: 814.4493\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1129.3435 - val_loss: 805.9324\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1119.3428 - val_loss: 797.4756\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1109.4050 - val_loss: 789.0795\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1099.5297 - val_loss: 780.7415\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1089.7167 - val_loss: 772.4641\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1079.9658 - val_loss: 764.2456\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1070.2767 - val_loss: 756.0856\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1060.6493 - val_loss: 747.9850\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1051.0830 - val_loss: 739.9423\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1041.5779 - val_loss: 731.9579\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1032.1335 - val_loss: 724.0319\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1022.7502 - val_loss: 716.1635\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1013.4271 - val_loss: 708.3519\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1004.1639 - val_loss: 700.5991\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 994.9611 - val_loss: 692.9025\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 985.8180 - val_loss: 685.2625\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 976.7341 - val_loss: 677.6796\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 967.7097 - val_loss: 670.1527\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 958.7443 - val_loss: 662.6824\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 949.8377 - val_loss: 655.2677\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 940.9899 - val_loss: 647.9093\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 932.2007 - val_loss: 640.6056\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 923.4691 - val_loss: 633.3577\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 914.7961 - val_loss: 626.1647\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 906.1804 - val_loss: 619.0262\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 897.6224 - val_loss: 611.9429\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 889.1216 - val_loss: 604.9137\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 880.6779 - val_loss: 597.9388\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 872.2911 - val_loss: 591.0178\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 863.9611 - val_loss: 584.1506\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 855.6871 - val_loss: 577.3369\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 847.4696 - val_loss: 570.5759\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 839.3079 - val_loss: 563.8685\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 831.2020 - val_loss: 557.2140\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 823.1519 - val_loss: 550.6116\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 815.1566 - val_loss: 544.0624\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 807.2171 - val_loss: 537.5648\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 799.3319 - val_loss: 531.1190\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 791.5018 - val_loss: 524.7255\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 783.7261 - val_loss: 518.3833\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 776.0046 - val_loss: 512.0923\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 768.3374 - val_loss: 505.8525\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 760.7239 - val_loss: 499.6633\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 753.1639 - val_loss: 493.5254\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 745.6575 - val_loss: 487.4373\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 738.2041 - val_loss: 481.3999\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 730.8037 - val_loss: 475.4119\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 723.4562 - val_loss: 469.4747\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 716.1615 - val_loss: 463.5865\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 708.9188 - val_loss: 457.7472\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 701.7283 - val_loss: 451.9583\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 694.5903 - val_loss: 446.2172\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 687.5037 - val_loss: 440.5254\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 680.4686 - val_loss: 434.8820\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 673.4847 - val_loss: 429.2870\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 666.5521 - val_loss: 423.7403\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 659.6705 - val_loss: 418.2411\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 652.8395 - val_loss: 412.7896\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 646.0590 - val_loss: 407.3860\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 639.3290 - val_loss: 402.0292\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 632.6490 - val_loss: 396.7199\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 626.0185 - val_loss: 391.4566\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 619.4380 - val_loss: 386.2410\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 612.9069 - val_loss: 381.0711\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 606.4252 - val_loss: 375.9477\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 599.9924 - val_loss: 370.8702\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 593.6085 - val_loss: 365.8385\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 587.2734 - val_loss: 360.8522\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 580.9867 - val_loss: 355.9113\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 574.7484 - val_loss: 351.0162\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 568.5581 - val_loss: 346.1653\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 562.4154 - val_loss: 341.3597\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 556.3207 - val_loss: 336.5980\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 550.2731 - val_loss: 331.8809\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 544.2728 - val_loss: 327.2081\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 538.3198 - val_loss: 322.5795\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 532.4136 - val_loss: 317.9943\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 526.5540 - val_loss: 313.4524\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 520.7408 - val_loss: 308.9539\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 514.9738 - val_loss: 304.4983\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 509.2529 - val_loss: 300.0858\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 503.5775 - val_loss: 295.7157\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 497.9482 - val_loss: 291.3884\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 492.3639 - val_loss: 287.1033\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 486.8249 - val_loss: 282.8599\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 481.3309 - val_loss: 278.6580\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 475.8818 - val_loss: 274.4988\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 470.4774 - val_loss: 270.3802\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 465.1175 - val_loss: 266.3032\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 459.8017 - val_loss: 262.2672\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 454.5299 - val_loss: 258.2717\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 449.3018 - val_loss: 254.3171\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 444.1174 - val_loss: 250.4023\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 438.9764 - val_loss: 246.5280\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 433.8784 - val_loss: 242.6938\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 428.8236 - val_loss: 238.8990\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 423.8116 - val_loss: 235.1440\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 418.8423 - val_loss: 231.4284\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 413.9152 - val_loss: 227.7517\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 409.0306 - val_loss: 224.1143\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 404.1880 - val_loss: 220.5150\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 399.3871 - val_loss: 216.9551\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 394.6280 - val_loss: 213.4328\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 389.9102 - val_loss: 209.9488\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 385.2335 - val_loss: 206.5024\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 380.5978 - val_loss: 203.0942\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 376.0030 - val_loss: 199.7231\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 371.4487 - val_loss: 196.3894\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 366.9350 - val_loss: 193.0928\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 362.4616 - val_loss: 189.8328\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 358.0279 - val_loss: 186.6099\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 353.6341 - val_loss: 183.4231\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 349.2802 - val_loss: 180.2724\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 344.9655 - val_loss: 177.1581\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 340.6898 - val_loss: 174.0792\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 336.4533 - val_loss: 171.0360\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 332.2556 - val_loss: 168.0284\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 328.0965 - val_loss: 165.0558\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 323.9759 - val_loss: 162.1185\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 319.8934 - val_loss: 159.2153\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 315.8490 - val_loss: 156.3472\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 311.8423 - val_loss: 153.5136\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 307.8735 - val_loss: 150.7137\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 303.9420 - val_loss: 147.9480\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 300.0476 - val_loss: 145.2159\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 296.1905 - val_loss: 142.5174\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 292.3699 - val_loss: 139.8524\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 288.5861 - val_loss: 137.2200\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 284.8387 - val_loss: 134.6212\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 281.1276 - val_loss: 132.0550\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 277.4525 - val_loss: 129.5207\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 273.8131 - val_loss: 127.0193\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 270.2094 - val_loss: 124.5493\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 266.6411 - val_loss: 122.1119\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 263.1083 - val_loss: 119.7058\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 259.6103 - val_loss: 117.3313\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 256.1474 - val_loss: 114.9880\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 252.7189 - val_loss: 112.6758\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 249.3248 - val_loss: 110.3941\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 245.9649 - val_loss: 108.1435\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 242.6392 - val_loss: 105.9228\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 239.3472 - val_loss: 103.7327\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 236.0890 - val_loss: 101.5726\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 232.8641 - val_loss: 99.4420\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 229.6725 - val_loss: 97.3413\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 226.5140 - val_loss: 95.2698\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 223.3881 - val_loss: 93.2277\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 220.2951 - val_loss: 91.2142\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 217.2343 - val_loss: 89.2297\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 214.2060 - val_loss: 87.2740\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 211.2098 - val_loss: 85.3463\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 208.2454 - val_loss: 83.4470\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 205.3128 - val_loss: 81.5753\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 202.4116 - val_loss: 79.7317\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 199.5417 - val_loss: 77.9155\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 196.7028 - val_loss: 76.1268\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 193.8949 - val_loss: 74.3650\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 191.1176 - val_loss: 72.6301\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 188.3707 - val_loss: 70.9218\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 185.6540 - val_loss: 69.2402\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 182.9676 - val_loss: 67.5848\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 180.3109 - val_loss: 65.9553\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 177.6838 - val_loss: 64.3519\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 175.0863 - val_loss: 62.7741\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 172.5182 - val_loss: 61.2218\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 169.9790 - val_loss: 59.6947\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 167.4688 - val_loss: 58.1928\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 164.9873 - val_loss: 56.7156\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 162.5344 - val_loss: 55.2631\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 160.1097 - val_loss: 53.8349\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 157.7131 - val_loss: 52.4310\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 155.3445 - val_loss: 51.0512\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 153.0034 - val_loss: 49.6952\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 150.6900 - val_loss: 48.3627\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 148.4039 - val_loss: 47.0538\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 146.1450 - val_loss: 45.7680\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 143.9129 - val_loss: 44.5052\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 141.7076 - val_loss: 43.2654\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 139.5290 - val_loss: 42.0480\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 137.3767 - val_loss: 40.8531\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 135.2504 - val_loss: 39.6804\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 133.1502 - val_loss: 38.5296\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 131.0757 - val_loss: 37.4007\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 129.0269 - val_loss: 36.2933\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 127.0034 - val_loss: 35.2072\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 125.0049 - val_loss: 34.1424\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 123.0316 - val_loss: 33.0986\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 121.0831 - val_loss: 32.0756\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 119.1592 - val_loss: 31.0730\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 117.2595 - val_loss: 30.0910\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 115.3843 - val_loss: 29.1291\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 113.5329 - val_loss: 28.1870\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 111.7055 - val_loss: 27.2650\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 109.9017 - val_loss: 26.3624\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 108.1215 - val_loss: 25.4793\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 106.3645 - val_loss: 24.6152\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 104.6304 - val_loss: 23.7702\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 102.9193 - val_loss: 22.9440\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 101.2311 - val_loss: 22.1365\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 99.5651 - val_loss: 21.3471\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 97.9215 - val_loss: 20.5760\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 96.3001 - val_loss: 19.8231\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 94.7006 - val_loss: 19.0878\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 93.1228 - val_loss: 18.3702\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 91.5666 - val_loss: 17.6699\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 90.0317 - val_loss: 16.9869\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 88.5181 - val_loss: 16.3209\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 87.0255 - val_loss: 15.6718\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 85.5536 - val_loss: 15.0391\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 84.1024 - val_loss: 14.4230\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 82.6715 - val_loss: 13.8231\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 81.2610 - val_loss: 13.2394\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 79.8706 - val_loss: 12.6715\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 78.4999 - val_loss: 12.1192\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 77.1490 - val_loss: 11.5823\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 75.8176 - val_loss: 11.0608\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 74.5055 - val_loss: 10.5545\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 73.2124 - val_loss: 10.0629\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 71.9383 - val_loss: 9.5861\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 70.6830 - val_loss: 9.1238\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 69.4463 - val_loss: 8.6759\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 68.2281 - val_loss: 8.2422\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 67.0281 - val_loss: 7.8224\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 65.8461 - val_loss: 7.4165\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 64.6820 - val_loss: 7.0240\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 63.5356 - val_loss: 6.6451\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 62.4067 - val_loss: 6.2794\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 61.2952 - val_loss: 5.9268\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 60.2009 - val_loss: 5.5870\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 59.1234 - val_loss: 5.2599\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 58.0628 - val_loss: 4.9453\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 57.0187 - val_loss: 4.6431\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 55.9912 - val_loss: 4.3529\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 54.9799 - val_loss: 4.0748\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 53.9847 - val_loss: 3.8085\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 53.0055 - val_loss: 3.5538\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 52.0420 - val_loss: 3.3105\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 51.0942 - val_loss: 3.0785\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 50.1616 - val_loss: 2.8576\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 49.2443 - val_loss: 2.6476\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 48.3421 - val_loss: 2.4483\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 47.4548 - val_loss: 2.2597\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 46.5823 - val_loss: 2.0814\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 45.7243 - val_loss: 1.9134\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 44.8808 - val_loss: 1.7554\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 44.0514 - val_loss: 1.6073\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 43.2361 - val_loss: 1.4690\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 42.4348 - val_loss: 1.3402\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 41.6471 - val_loss: 1.2208\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 40.8730 - val_loss: 1.1106\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 40.1123 - val_loss: 1.0095\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 39.3649 - val_loss: 0.9173\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 38.6306 - val_loss: 0.8339\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 37.9093 - val_loss: 0.7590\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 37.2007 - val_loss: 0.6926\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 36.5046 - val_loss: 0.6344\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 35.8210 - val_loss: 0.5843\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 35.1497 - val_loss: 0.5422\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 34.4906 - val_loss: 0.5078\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 33.8434 - val_loss: 0.4811\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 33.2081 - val_loss: 0.4619\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 32.5845 - val_loss: 0.4500\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.1552, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0026, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0004, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0102, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.8734, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 438ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.46131653e+01, 7.45795518e+01, 7.45459384e+01, 7.45123249e+01,\n",
       "        7.44787115e+01, 7.44450980e+01, 7.44114846e+01, 7.43778712e+01,\n",
       "        7.43442577e+01, 7.43106443e+01, 7.42770308e+01, 7.42434174e+01,\n",
       "        7.42098039e+01, 7.41742064e+01, 7.41377918e+01, 7.41013772e+01,\n",
       "        7.40649626e+01, 7.40285481e+01, 7.39921335e+01, 7.39557190e+01,\n",
       "        7.39193044e+01, 7.38828898e+01, 7.38464753e+01, 7.38100607e+01,\n",
       "        7.37736461e+01, 7.37372316e+01, 7.37008170e+01, 7.36644024e+01,\n",
       "        7.36279879e+01, 7.35915733e+01, 7.35551587e+01, 7.35187442e+01,\n",
       "        7.34823296e+01, 7.34459150e+01, 7.34095005e+01, 7.33730859e+01,\n",
       "        7.33366713e+01, 7.33002568e+01, 7.32638422e+01, 7.32274276e+01,\n",
       "        7.31910131e+01, 7.31545985e+01, 7.31181839e+01, 7.30817694e+01,\n",
       "        7.30453548e+01, 7.30089402e+01, 7.29725257e+01, 7.29361111e+01,\n",
       "        7.28996078e+01, 7.28525490e+01, 7.28054902e+01, 7.27584314e+01,\n",
       "        7.27113725e+01, 7.26643137e+01, 7.26172549e+01, 7.25701961e+01,\n",
       "        7.25231373e+01, 7.24760784e+01, 7.24290196e+01, 7.23819608e+01,\n",
       "        7.23349020e+01, 7.22878431e+01, 7.22407843e+01, 7.21937255e+01,\n",
       "        7.21466667e+01, 7.20996078e+01, 7.20525490e+01, 7.20054902e+01,\n",
       "        7.19584314e+01, 7.19113725e+01, 7.18643137e+01, 7.18172549e+01,\n",
       "        7.17701961e+01, 7.17231372e+01, 7.16760784e+01, 7.16290196e+01,\n",
       "        7.15819608e+01, 7.15349020e+01, 7.14878431e+01, 7.14407843e+01,\n",
       "        7.25410385e+01, 0.00000000e+00, 5.20513415e-01, 1.08670257e-01,\n",
       "        3.73652935e-01, 0.00000000e+00, 8.38599131e-02, 0.00000000e+00,\n",
       "        3.64094079e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.10000619e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.95971560e-02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70.67359944, 70.67079832, 70.6679972 , 70.66519608, 70.66239496,\n",
       "       70.65959384, 70.65679272, 70.6539916 , 70.65119048, 70.64838936,\n",
       "       70.64558824, 70.64278711, 70.63998599, 70.63718487, 70.63438375,\n",
       "       70.63158263, 70.62878151, 70.62598039, 70.62317927, 70.62037815,\n",
       "       70.61757703, 70.61477591, 70.61197479, 70.60917367, 70.60637255,\n",
       "       70.60357143, 70.60077031, 70.59526144, 70.58872549, 70.58218954,\n",
       "       70.57565359, 70.56911765, 70.5625817 , 70.55604575, 70.5495098 ,\n",
       "       70.54297386, 70.53643791, 70.52990196, 70.52336601, 70.51683007,\n",
       "       70.51029412, 70.50375817, 70.49722222, 70.49068627, 70.48415033,\n",
       "       70.47761438, 70.47107843, 70.46454248, 70.45800654, 70.45147059,\n",
       "       70.44493464, 70.43839869, 70.43186275, 70.4253268 , 70.41879085,\n",
       "       70.4122549 , 70.40571895, 70.39918301, 70.39264706, 70.38611111,\n",
       "       70.37957516, 70.37303922, 70.36650327, 70.35996732, 70.35343137,\n",
       "       70.34689542, 70.34035948, 70.33382353, 70.32728758, 70.32075163,\n",
       "       70.31421569, 70.30767974, 70.30114379, 70.29460784, 70.2880719 ,\n",
       "       70.28153595, 70.275     , 70.26846405, 70.2619281 , 70.25539216,\n",
       "       70.24885621, 70.24232026, 70.23578431, 70.22924837, 70.22271242,\n",
       "       70.21617647, 70.20964052, 70.20310458, 70.19656863, 70.19003268,\n",
       "       70.18349673, 70.17696078, 70.17042484, 70.16388889, 70.15735294,\n",
       "       70.15081699, 70.14428105, 70.1377451 , 70.13120915, 70.1246732 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.659872056810396\n",
      "15.458257344295417\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
