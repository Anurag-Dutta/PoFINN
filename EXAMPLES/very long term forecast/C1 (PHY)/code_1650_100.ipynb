{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1745    60.186802\n",
       "1746    60.182507\n",
       "1747    60.178212\n",
       "1748    60.173917\n",
       "1749    60.169622\n",
       "Name: C1, Length: 1750, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_1650_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1645     0.000000\n",
       "1646     0.000000\n",
       "1647     0.000000\n",
       "1648     0.140473\n",
       "1649     0.747485\n",
       "Name: C1, Length: 1650, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1650)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 1, 251) (1200, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "15/15 [==============================] - 2s 34ms/step - loss: 4601.3911 - val_loss: 3372.6555\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4540.7202 - val_loss: 3341.5396\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4498.8926 - val_loss: 3310.4971\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4452.6216 - val_loss: 3265.2417\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4395.8496 - val_loss: 3232.9644\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4351.7100 - val_loss: 3199.2842\n",
      "Epoch 7/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4306.1548 - val_loss: 3165.5256\n",
      "Epoch 8/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4261.0947 - val_loss: 3132.3872\n",
      "Epoch 9/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4215.9053 - val_loss: 3088.3833\n",
      "Epoch 10/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4153.9038 - val_loss: 3052.9929\n",
      "Epoch 11/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4107.5879 - val_loss: 3019.1770\n",
      "Epoch 12/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4062.0798 - val_loss: 2986.0574\n",
      "Epoch 13/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4017.4141 - val_loss: 2953.5286\n",
      "Epoch 14/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3973.4480 - val_loss: 2921.5024\n",
      "Epoch 15/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3930.0791 - val_loss: 2889.9187\n",
      "Epoch 16/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3887.2405 - val_loss: 2858.7385\n",
      "Epoch 17/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3844.8860 - val_loss: 2827.9353\n",
      "Epoch 18/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3802.9832 - val_loss: 2797.4878\n",
      "Epoch 19/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3761.5083 - val_loss: 2767.3811\n",
      "Epoch 20/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3720.4426 - val_loss: 2737.6025\n",
      "Epoch 21/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3679.7732 - val_loss: 2708.1428\n",
      "Epoch 22/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3639.4858 - val_loss: 2678.9915\n",
      "Epoch 23/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3599.5718 - val_loss: 2650.1350\n",
      "Epoch 24/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3557.3750 - val_loss: 2608.3152\n",
      "Epoch 25/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3501.3843 - val_loss: 2576.5859\n",
      "Epoch 26/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3458.0413 - val_loss: 2545.4478\n",
      "Epoch 27/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3415.6965 - val_loss: 2515.1411\n",
      "Epoch 28/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3374.3140 - val_loss: 2485.5134\n",
      "Epoch 29/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3333.7097 - val_loss: 2456.4458\n",
      "Epoch 30/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3293.7551 - val_loss: 2427.8623\n",
      "Epoch 31/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3254.3701 - val_loss: 2399.7126\n",
      "Epoch 32/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3215.4988 - val_loss: 2371.9634\n",
      "Epoch 33/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3177.1028 - val_loss: 2344.5891\n",
      "Epoch 34/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3139.1550 - val_loss: 2317.5713\n",
      "Epoch 35/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3101.6333 - val_loss: 2290.8950\n",
      "Epoch 36/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3064.5198 - val_loss: 2264.5479\n",
      "Epoch 37/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3027.8010 - val_loss: 2238.5203\n",
      "Epoch 38/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2991.4648 - val_loss: 2212.8042\n",
      "Epoch 39/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2955.5012 - val_loss: 2187.3911\n",
      "Epoch 40/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2919.9023 - val_loss: 2162.2756\n",
      "Epoch 41/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2884.6592 - val_loss: 2137.4514\n",
      "Epoch 42/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2849.7664 - val_loss: 2112.9138\n",
      "Epoch 43/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2815.2161 - val_loss: 2088.6577\n",
      "Epoch 44/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2781.0046 - val_loss: 2064.6792\n",
      "Epoch 45/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2747.1260 - val_loss: 2040.9745\n",
      "Epoch 46/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2713.5752 - val_loss: 2017.5391\n",
      "Epoch 47/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2680.3489 - val_loss: 1994.3704\n",
      "Epoch 48/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2647.4417 - val_loss: 1971.4648\n",
      "Epoch 49/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2614.8511 - val_loss: 1948.8192\n",
      "Epoch 50/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2582.5720 - val_loss: 1926.4308\n",
      "Epoch 51/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2550.6030 - val_loss: 1904.2969\n",
      "Epoch 52/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2518.9397 - val_loss: 1882.4153\n",
      "Epoch 53/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2487.5784 - val_loss: 1860.7826\n",
      "Epoch 54/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2456.5173 - val_loss: 1839.3969\n",
      "Epoch 55/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2425.7534 - val_loss: 1818.2551\n",
      "Epoch 56/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2395.2827 - val_loss: 1797.3558\n",
      "Epoch 57/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2365.1042 - val_loss: 1776.6964\n",
      "Epoch 58/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2335.2144 - val_loss: 1756.2748\n",
      "Epoch 59/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2305.6108 - val_loss: 1736.0885\n",
      "Epoch 60/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2276.2915 - val_loss: 1716.1354\n",
      "Epoch 61/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2247.2532 - val_loss: 1696.4135\n",
      "Epoch 62/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2218.4946 - val_loss: 1676.9199\n",
      "Epoch 63/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2190.0127 - val_loss: 1657.6505\n",
      "Epoch 64/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2161.8059 - val_loss: 1638.5936\n",
      "Epoch 65/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2132.5671 - val_loss: 1614.2126\n",
      "Epoch 66/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2096.1350 - val_loss: 1592.0201\n",
      "Epoch 67/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 2063.7747 - val_loss: 1570.4246\n",
      "Epoch 68/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2032.4532 - val_loss: 1549.6432\n",
      "Epoch 69/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2002.1193 - val_loss: 1529.5138\n",
      "Epoch 70/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1972.5656 - val_loss: 1509.9117\n",
      "Epoch 71/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1943.6495 - val_loss: 1490.7589\n",
      "Epoch 72/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1915.2806 - val_loss: 1472.0037\n",
      "Epoch 73/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1887.3995 - val_loss: 1453.6095\n",
      "Epoch 74/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1859.9625 - val_loss: 1435.5511\n",
      "Epoch 75/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1832.9391 - val_loss: 1417.8091\n",
      "Epoch 76/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1806.3047 - val_loss: 1400.3669\n",
      "Epoch 77/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1780.0406 - val_loss: 1383.2130\n",
      "Epoch 78/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1754.1312 - val_loss: 1366.3363\n",
      "Epoch 79/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1728.5636 - val_loss: 1349.7284\n",
      "Epoch 80/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1703.3265 - val_loss: 1333.3809\n",
      "Epoch 81/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1678.4109 - val_loss: 1317.2882\n",
      "Epoch 82/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1653.8083 - val_loss: 1301.4435\n",
      "Epoch 83/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1629.5114 - val_loss: 1285.8416\n",
      "Epoch 84/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1605.5135 - val_loss: 1270.4777\n",
      "Epoch 85/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1581.8086 - val_loss: 1255.3474\n",
      "Epoch 86/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1558.3914 - val_loss: 1240.4468\n",
      "Epoch 87/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1535.2567 - val_loss: 1225.7716\n",
      "Epoch 88/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1512.4001 - val_loss: 1211.3190\n",
      "Epoch 89/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1489.8176 - val_loss: 1197.0851\n",
      "Epoch 90/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1467.5044 - val_loss: 1183.0671\n",
      "Epoch 91/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1445.4575 - val_loss: 1169.2620\n",
      "Epoch 92/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1423.6730 - val_loss: 1155.6665\n",
      "Epoch 93/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1402.1470 - val_loss: 1142.2786\n",
      "Epoch 94/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1380.8767 - val_loss: 1129.0948\n",
      "Epoch 95/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1359.8593 - val_loss: 1116.1138\n",
      "Epoch 96/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1339.0914 - val_loss: 1103.3322\n",
      "Epoch 97/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1318.5704 - val_loss: 1090.7477\n",
      "Epoch 98/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1298.2930 - val_loss: 1078.3589\n",
      "Epoch 99/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1278.2574 - val_loss: 1066.1626\n",
      "Epoch 100/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1258.4606 - val_loss: 1054.1575\n",
      "Epoch 101/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1238.9001 - val_loss: 1042.3411\n",
      "Epoch 102/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1219.5739 - val_loss: 1030.7113\n",
      "Epoch 103/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1200.4790 - val_loss: 1019.2666\n",
      "Epoch 104/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1181.6138 - val_loss: 1008.0048\n",
      "Epoch 105/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1162.9758 - val_loss: 996.9236\n",
      "Epoch 106/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1144.5625 - val_loss: 986.0214\n",
      "Epoch 107/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1126.3717 - val_loss: 975.2969\n",
      "Epoch 108/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1108.4019 - val_loss: 964.7477\n",
      "Epoch 109/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1090.6508 - val_loss: 954.3721\n",
      "Epoch 110/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1073.1158 - val_loss: 944.1686\n",
      "Epoch 111/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1055.7958 - val_loss: 934.1350\n",
      "Epoch 112/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1038.6884 - val_loss: 924.2704\n",
      "Epoch 113/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1021.7920 - val_loss: 914.5727\n",
      "Epoch 114/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1005.1044 - val_loss: 905.0403\n",
      "Epoch 115/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 988.6241 - val_loss: 895.6715\n",
      "Epoch 116/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 972.3488 - val_loss: 886.4647\n",
      "Epoch 117/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 956.2772 - val_loss: 877.4188\n",
      "Epoch 118/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 940.4071 - val_loss: 868.5312\n",
      "Epoch 119/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 924.7368 - val_loss: 859.8010\n",
      "Epoch 120/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 909.2650 - val_loss: 851.2268\n",
      "Epoch 121/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 893.9893 - val_loss: 842.8069\n",
      "Epoch 122/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 878.9083 - val_loss: 834.5395\n",
      "Epoch 123/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 864.0208 - val_loss: 826.4236\n",
      "Epoch 124/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 849.3245 - val_loss: 818.4575\n",
      "Epoch 125/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 834.8179 - val_loss: 810.6398\n",
      "Epoch 126/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 820.4995 - val_loss: 802.9690\n",
      "Epoch 127/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 806.3676 - val_loss: 795.4435\n",
      "Epoch 128/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 792.4205 - val_loss: 788.0617\n",
      "Epoch 129/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 778.6569 - val_loss: 780.8227\n",
      "Epoch 130/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 765.0750 - val_loss: 773.7247\n",
      "Epoch 131/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 751.6729 - val_loss: 766.7663\n",
      "Epoch 132/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 738.4496 - val_loss: 759.9462\n",
      "Epoch 133/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 725.4036 - val_loss: 753.2633\n",
      "Epoch 134/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 712.5331 - val_loss: 746.7157\n",
      "Epoch 135/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 699.8365 - val_loss: 740.3020\n",
      "Epoch 136/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 687.3123 - val_loss: 734.0212\n",
      "Epoch 137/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 674.9591 - val_loss: 727.8717\n",
      "Epoch 138/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 662.7754 - val_loss: 721.8523\n",
      "Epoch 139/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 650.7597 - val_loss: 715.9613\n",
      "Epoch 140/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 638.9105 - val_loss: 710.1981\n",
      "Epoch 141/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 627.2267 - val_loss: 704.5604\n",
      "Epoch 142/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 615.7062 - val_loss: 699.0475\n",
      "Epoch 143/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 604.3483 - val_loss: 693.6581\n",
      "Epoch 144/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 593.1508 - val_loss: 688.3904\n",
      "Epoch 145/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 582.1126 - val_loss: 683.2434\n",
      "Epoch 146/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 571.2322 - val_loss: 678.2158\n",
      "Epoch 147/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 560.5085 - val_loss: 673.3063\n",
      "Epoch 148/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 549.9396 - val_loss: 668.5134\n",
      "Epoch 149/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 539.5247 - val_loss: 663.8361\n",
      "Epoch 150/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 529.2618 - val_loss: 659.2729\n",
      "Epoch 151/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 519.1497 - val_loss: 654.8224\n",
      "Epoch 152/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 509.1870 - val_loss: 650.4835\n",
      "Epoch 153/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 499.3725 - val_loss: 646.2551\n",
      "Epoch 154/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 489.7047 - val_loss: 642.1356\n",
      "Epoch 155/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 480.1821 - val_loss: 638.1238\n",
      "Epoch 156/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 470.8036 - val_loss: 634.2185\n",
      "Epoch 157/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 461.5675 - val_loss: 630.4183\n",
      "Epoch 158/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 452.4728 - val_loss: 626.7225\n",
      "Epoch 159/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 443.5180 - val_loss: 623.1288\n",
      "Epoch 160/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 434.7016 - val_loss: 619.6370\n",
      "Epoch 161/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 426.0225 - val_loss: 616.2451\n",
      "Epoch 162/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 417.4792 - val_loss: 612.9522\n",
      "Epoch 163/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 409.0706 - val_loss: 609.7571\n",
      "Epoch 164/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 400.7951 - val_loss: 606.6586\n",
      "Epoch 165/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 392.6517 - val_loss: 603.6554\n",
      "Epoch 166/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 384.6387 - val_loss: 600.7461\n",
      "Epoch 167/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 376.7551 - val_loss: 597.9294\n",
      "Epoch 168/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 368.9992 - val_loss: 595.2044\n",
      "Epoch 169/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 361.3702 - val_loss: 592.5700\n",
      "Epoch 170/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 353.8666 - val_loss: 590.0246\n",
      "Epoch 171/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 346.4870 - val_loss: 587.5671\n",
      "Epoch 172/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 339.2303 - val_loss: 585.1965\n",
      "Epoch 173/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 332.0951 - val_loss: 582.9112\n",
      "Epoch 174/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 325.0801 - val_loss: 580.7103\n",
      "Epoch 175/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 318.1840 - val_loss: 578.5927\n",
      "Epoch 176/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 311.4057 - val_loss: 576.5569\n",
      "Epoch 177/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 304.7437 - val_loss: 574.6018\n",
      "Epoch 178/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 298.1971 - val_loss: 572.7264\n",
      "Epoch 179/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 291.7643 - val_loss: 570.9294\n",
      "Epoch 180/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 285.4441 - val_loss: 569.2097\n",
      "Epoch 181/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 279.2353 - val_loss: 567.5659\n",
      "Epoch 182/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 273.1367 - val_loss: 565.9970\n",
      "Epoch 183/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 267.1471 - val_loss: 564.5018\n",
      "Epoch 184/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 261.2650 - val_loss: 563.0793\n",
      "Epoch 185/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 255.4895 - val_loss: 561.7279\n",
      "Epoch 186/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 249.8191 - val_loss: 560.4468\n",
      "Epoch 187/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 244.2526 - val_loss: 559.2349\n",
      "Epoch 188/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 238.7891 - val_loss: 558.0909\n",
      "Epoch 189/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 233.4272 - val_loss: 557.0138\n",
      "Epoch 190/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 228.1656 - val_loss: 556.0022\n",
      "Epoch 191/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 223.0029 - val_loss: 555.0553\n",
      "Epoch 192/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 217.9382 - val_loss: 554.1716\n",
      "Epoch 193/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 212.9704 - val_loss: 553.3503\n",
      "Epoch 194/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 208.0982 - val_loss: 552.5901\n",
      "Epoch 195/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 203.3203 - val_loss: 551.8899\n",
      "Epoch 196/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 198.6356 - val_loss: 551.2487\n",
      "Epoch 197/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 194.0429 - val_loss: 550.6652\n",
      "Epoch 198/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 189.5411 - val_loss: 550.1385\n",
      "Epoch 199/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 185.1285 - val_loss: 549.6674\n",
      "Epoch 200/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 180.8048 - val_loss: 549.2508\n",
      "Epoch 201/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 176.5684 - val_loss: 548.8876\n",
      "Epoch 202/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 172.4181 - val_loss: 548.5769\n",
      "Epoch 203/500\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 168.3530 - val_loss: 548.3173\n",
      "Epoch 204/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 164.3717 - val_loss: 548.1080\n",
      "Epoch 205/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 160.4730 - val_loss: 547.9477\n",
      "Epoch 206/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 156.6559 - val_loss: 547.8357\n",
      "Epoch 207/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 152.9194 - val_loss: 547.7704\n",
      "Epoch 208/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 149.2621 - val_loss: 547.7513\n",
      "Epoch 209/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 145.6832 - val_loss: 547.7771\n",
      "Epoch 210/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 142.1813 - val_loss: 547.8467\n",
      "Epoch 211/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 138.7553 - val_loss: 547.9592\n",
      "Epoch 212/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 135.4042 - val_loss: 548.1134\n",
      "Epoch 213/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 132.1270 - val_loss: 548.3085\n",
      "Epoch 214/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 128.9226 - val_loss: 548.5433\n",
      "Epoch 215/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 125.7896 - val_loss: 548.8170\n",
      "Epoch 216/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 122.7272 - val_loss: 549.1284\n",
      "Epoch 217/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 119.7343 - val_loss: 549.4765\n",
      "Epoch 218/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 116.8098 - val_loss: 549.8605\n",
      "Epoch 219/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 113.9525 - val_loss: 550.2792\n",
      "Epoch 220/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 111.1614 - val_loss: 550.7318\n",
      "Epoch 221/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 108.4357 - val_loss: 551.2172\n",
      "Epoch 222/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 105.7741 - val_loss: 551.7346\n",
      "Epoch 223/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 103.1756 - val_loss: 552.2830\n",
      "Epoch 224/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 100.6392 - val_loss: 552.8612\n",
      "Epoch 225/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 98.1639 - val_loss: 553.4686\n",
      "Epoch 226/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 95.7486 - val_loss: 554.1041\n",
      "Epoch 227/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 93.3925 - val_loss: 554.7668\n",
      "Epoch 228/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 91.0943 - val_loss: 555.4559\n",
      "Epoch 229/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 88.8531 - val_loss: 556.1703\n",
      "Epoch 230/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 86.6680 - val_loss: 556.9092\n",
      "Epoch 231/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 84.5381 - val_loss: 557.6718\n",
      "Epoch 232/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 82.4622 - val_loss: 558.4571\n",
      "Epoch 233/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 80.4393 - val_loss: 559.2643\n",
      "Epoch 234/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 78.4687 - val_loss: 560.0925\n",
      "Epoch 235/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 76.5492 - val_loss: 560.9407\n",
      "Epoch 236/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 74.6801 - val_loss: 561.8083\n",
      "Epoch 237/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 72.8602 - val_loss: 562.6946\n",
      "Epoch 238/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 71.0888 - val_loss: 563.5983\n",
      "Epoch 239/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 69.3649 - val_loss: 564.5189\n",
      "Epoch 240/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 67.6875 - val_loss: 565.4556\n",
      "Epoch 241/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 66.0557 - val_loss: 566.4074\n",
      "Epoch 242/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 64.4688 - val_loss: 567.3736\n",
      "Epoch 243/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 62.9259 - val_loss: 568.3535\n",
      "Epoch 244/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 61.4258 - val_loss: 569.3464\n",
      "Epoch 245/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 59.9679 - val_loss: 570.3514\n",
      "Epoch 246/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 58.5512 - val_loss: 571.3679\n",
      "Epoch 247/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 57.1750 - val_loss: 572.3949\n",
      "Epoch 248/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 55.8384 - val_loss: 573.4319\n",
      "Epoch 249/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 54.5405 - val_loss: 574.4781\n",
      "Epoch 250/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 53.2805 - val_loss: 575.5330\n",
      "Epoch 251/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 52.0575 - val_loss: 576.5957\n",
      "Epoch 252/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 50.8709 - val_loss: 577.6654\n",
      "Epoch 253/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 49.7198 - val_loss: 578.7416\n",
      "Epoch 254/500\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 48.6034 - val_loss: 579.8239\n",
      "Epoch 255/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 47.5209 - val_loss: 580.9112\n",
      "Epoch 256/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 46.4715 - val_loss: 582.0031\n",
      "Epoch 257/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 45.4546 - val_loss: 583.0988\n",
      "Epoch 258/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 44.4693 - val_loss: 584.1978\n",
      "Epoch 259/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 43.5149 - val_loss: 585.2996\n",
      "Epoch 260/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 42.5907 - val_loss: 586.4034\n",
      "Epoch 261/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 41.6959 - val_loss: 587.5091\n",
      "Epoch 262/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 40.8298 - val_loss: 588.6155\n",
      "Epoch 263/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 39.9918 - val_loss: 589.7224\n",
      "Epoch 264/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 39.1812 - val_loss: 590.8291\n",
      "Epoch 265/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 38.3972 - val_loss: 591.9354\n",
      "Epoch 266/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 37.6391 - val_loss: 593.0403\n",
      "Epoch 267/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 36.9064 - val_loss: 594.1437\n",
      "Epoch 268/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 36.1984 - val_loss: 595.2449\n",
      "Epoch 269/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 35.5144 - val_loss: 596.3435\n",
      "Epoch 270/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 34.8538 - val_loss: 597.4389\n",
      "Epoch 271/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 34.2160 - val_loss: 598.5310\n",
      "Epoch 272/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 33.6003 - val_loss: 599.6188\n",
      "Epoch 273/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 33.0063 - val_loss: 600.7026\n",
      "Epoch 274/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 32.4331 - val_loss: 601.7815\n",
      "Epoch 275/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 31.8803 - val_loss: 602.8549\n",
      "Epoch 276/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 31.3474 - val_loss: 603.9227\n",
      "Epoch 277/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 30.8339 - val_loss: 604.9846\n",
      "Epoch 278/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 30.3390 - val_loss: 606.0399\n",
      "Epoch 279/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 29.8623 - val_loss: 607.0885\n",
      "Epoch 280/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 29.4033 - val_loss: 608.1301\n",
      "Epoch 281/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 28.9613 - val_loss: 609.1644\n",
      "Epoch 282/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 28.5360 - val_loss: 610.1910\n",
      "Epoch 283/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 28.1268 - val_loss: 611.2094\n",
      "Epoch 284/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 27.7332 - val_loss: 612.2193\n",
      "Epoch 285/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 27.3548 - val_loss: 613.2206\n",
      "Epoch 286/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 26.9912 - val_loss: 614.2133\n",
      "Epoch 287/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 26.6416 - val_loss: 615.1967\n",
      "Epoch 288/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 26.3058 - val_loss: 616.1707\n",
      "Epoch 289/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 25.9835 - val_loss: 617.1351\n",
      "Epoch 290/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 25.6740 - val_loss: 618.0896\n",
      "Epoch 291/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 25.3770 - val_loss: 619.0339\n",
      "Epoch 292/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 25.0921 - val_loss: 619.9681\n",
      "Epoch 293/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 24.8188 - val_loss: 620.8920\n",
      "Epoch 294/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 24.5568 - val_loss: 621.8048\n",
      "Epoch 295/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 24.3058 - val_loss: 622.7070\n",
      "Epoch 296/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 24.0652 - val_loss: 623.5980\n",
      "Epoch 297/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 23.8349 - val_loss: 624.4778\n",
      "Epoch 298/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 23.6144 - val_loss: 625.3467\n",
      "Epoch 299/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 23.4032 - val_loss: 626.2039\n",
      "Epoch 300/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 23.2013 - val_loss: 627.0497\n",
      "Epoch 301/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 23.0081 - val_loss: 627.8837\n",
      "Epoch 302/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 22.8235 - val_loss: 628.7060\n",
      "Epoch 303/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 22.6469 - val_loss: 629.5170\n",
      "Epoch 304/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 22.4783 - val_loss: 630.3157\n",
      "Epoch 305/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 22.3172 - val_loss: 631.1025\n",
      "Epoch 306/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 22.1634 - val_loss: 631.8775\n",
      "Epoch 307/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 22.0166 - val_loss: 632.6400\n",
      "Epoch 308/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 21.8766 - val_loss: 633.3904\n",
      "Epoch 309/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 21.7430 - val_loss: 634.1288\n",
      "Epoch 310/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 21.6157 - val_loss: 634.8551\n",
      "Epoch 311/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 21.4943 - val_loss: 635.5692\n",
      "Epoch 312/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 21.3787 - val_loss: 636.2711\n",
      "Epoch 313/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 21.2686 - val_loss: 636.9604\n",
      "Epoch 314/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 21.1638 - val_loss: 637.6380\n",
      "Epoch 315/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 21.0641 - val_loss: 638.3036\n",
      "Epoch 316/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 20.9691 - val_loss: 638.9567\n",
      "Epoch 317/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 20.8789 - val_loss: 639.5978\n",
      "Epoch 318/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 20.7932 - val_loss: 640.2267\n",
      "Epoch 319/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 20.7117 - val_loss: 640.8436\n",
      "Epoch 320/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 20.6343 - val_loss: 641.4487\n",
      "Epoch 321/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 20.5607 - val_loss: 642.0419\n",
      "Epoch 322/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 20.4909 - val_loss: 642.6228\n",
      "Epoch 323/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 20.4248 - val_loss: 643.1922\n",
      "Epoch 324/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 20.3620 - val_loss: 643.7504\n",
      "Epoch 325/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 20.3024 - val_loss: 644.2965\n",
      "Epoch 326/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 20.2460 - val_loss: 644.8312\n",
      "Epoch 327/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 20.1925 - val_loss: 645.3542\n",
      "Epoch 328/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 20.1419 - val_loss: 645.8660\n",
      "Epoch 329/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 20.0940 - val_loss: 646.3668\n",
      "Epoch 330/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 20.0486 - val_loss: 646.8561\n",
      "Epoch 331/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 20.0058 - val_loss: 647.3345\n",
      "Epoch 332/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.9652 - val_loss: 647.8024\n",
      "Epoch 333/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.9269 - val_loss: 648.2589\n",
      "Epoch 334/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 19.8906 - val_loss: 648.7048\n",
      "Epoch 335/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.8564 - val_loss: 649.1401\n",
      "Epoch 336/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.8241 - val_loss: 649.5650\n",
      "Epoch 337/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.7937 - val_loss: 649.9798\n",
      "Epoch 338/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.7649 - val_loss: 650.3841\n",
      "Epoch 339/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.7378 - val_loss: 650.7787\n",
      "Epoch 340/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.7122 - val_loss: 651.1633\n",
      "Epoch 341/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.6881 - val_loss: 651.5378\n",
      "Epoch 342/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.6655 - val_loss: 651.9027\n",
      "Epoch 343/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.6441 - val_loss: 652.2582\n",
      "Epoch 344/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.6241 - val_loss: 652.6046\n",
      "Epoch 345/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.6051 - val_loss: 652.9420\n",
      "Epoch 346/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.5874 - val_loss: 653.2699\n",
      "Epoch 347/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.5706 - val_loss: 653.5889\n",
      "Epoch 348/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 19.5549 - val_loss: 653.8992\n",
      "Epoch 349/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.5402 - val_loss: 654.2012\n",
      "Epoch 350/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.5264 - val_loss: 654.4948\n",
      "Epoch 351/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.5133 - val_loss: 654.7800\n",
      "Epoch 352/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.5011 - val_loss: 655.0568\n",
      "Epoch 353/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.4897 - val_loss: 655.3260\n",
      "Epoch 354/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.4789 - val_loss: 655.5871\n",
      "Epoch 355/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.4689 - val_loss: 655.8408\n",
      "Epoch 356/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.4595 - val_loss: 656.0866\n",
      "Epoch 357/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.4506 - val_loss: 656.3255\n",
      "Epoch 358/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.4424 - val_loss: 656.5569\n",
      "Epoch 359/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.4346 - val_loss: 656.7813\n",
      "Epoch 360/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.4274 - val_loss: 656.9989\n",
      "Epoch 361/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.4207 - val_loss: 657.2100\n",
      "Epoch 362/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.4143 - val_loss: 657.4139\n",
      "Epoch 363/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.4084 - val_loss: 657.6117\n",
      "Epoch 364/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.4029 - val_loss: 657.8030\n",
      "Epoch 365/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3978 - val_loss: 657.9883\n",
      "Epoch 366/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3930 - val_loss: 658.1677\n",
      "Epoch 367/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3885 - val_loss: 658.3409\n",
      "Epoch 368/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3843 - val_loss: 658.5085\n",
      "Epoch 369/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3804 - val_loss: 658.6701\n",
      "Epoch 370/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3768 - val_loss: 658.8266\n",
      "Epoch 371/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3734 - val_loss: 658.9780\n",
      "Epoch 372/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3703 - val_loss: 659.1240\n",
      "Epoch 373/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3674 - val_loss: 659.2651\n",
      "Epoch 374/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3647 - val_loss: 659.4014\n",
      "Epoch 375/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3621 - val_loss: 659.5330\n",
      "Epoch 376/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3597 - val_loss: 659.6595\n",
      "Epoch 377/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3576 - val_loss: 659.7818\n",
      "Epoch 378/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3556 - val_loss: 659.8996\n",
      "Epoch 379/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 19.3537 - val_loss: 660.0133\n",
      "Epoch 380/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3519 - val_loss: 660.1227\n",
      "Epoch 381/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 19.3503 - val_loss: 660.2277\n",
      "Epoch 382/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3489 - val_loss: 660.3294\n",
      "Epoch 383/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3475 - val_loss: 660.4272\n",
      "Epoch 384/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3462 - val_loss: 660.5207\n",
      "Epoch 385/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3451 - val_loss: 660.6115\n",
      "Epoch 386/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3439 - val_loss: 660.6982\n",
      "Epoch 387/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3430 - val_loss: 660.7820\n",
      "Epoch 388/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3421 - val_loss: 660.8622\n",
      "Epoch 389/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3412 - val_loss: 660.9395\n",
      "Epoch 390/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3404 - val_loss: 661.0135\n",
      "Epoch 391/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3397 - val_loss: 661.0847\n",
      "Epoch 392/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3391 - val_loss: 661.1530\n",
      "Epoch 393/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3385 - val_loss: 661.2186\n",
      "Epoch 394/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3379 - val_loss: 661.2814\n",
      "Epoch 395/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3375 - val_loss: 661.3420\n",
      "Epoch 396/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3370 - val_loss: 661.3997\n",
      "Epoch 397/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3366 - val_loss: 661.4553\n",
      "Epoch 398/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3362 - val_loss: 661.5085\n",
      "Epoch 399/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3359 - val_loss: 661.5593\n",
      "Epoch 400/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3356 - val_loss: 661.6081\n",
      "Epoch 401/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3354 - val_loss: 661.6547\n",
      "Epoch 402/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3352 - val_loss: 661.6995\n",
      "Epoch 403/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3349 - val_loss: 661.7419\n",
      "Epoch 404/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3348 - val_loss: 661.7831\n",
      "Epoch 405/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3346 - val_loss: 661.8219\n",
      "Epoch 406/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3345 - val_loss: 661.8592\n",
      "Epoch 407/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3344 - val_loss: 661.8949\n",
      "Epoch 408/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3343 - val_loss: 661.9289\n",
      "Epoch 409/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3343 - val_loss: 661.9614\n",
      "Epoch 410/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3342 - val_loss: 661.9922\n",
      "Epoch 411/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3342 - val_loss: 662.0221\n",
      "Epoch 412/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3342 - val_loss: 662.0499\n",
      "Epoch 413/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 19.3341 - val_loss: 662.0770\n",
      "Epoch 414/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 19.3342 - val_loss: 662.1024\n",
      "Epoch 415/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3342 - val_loss: 662.1270\n",
      "Epoch 416/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3342 - val_loss: 662.1500\n",
      "Epoch 417/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3343 - val_loss: 662.1719\n",
      "Epoch 418/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3344 - val_loss: 662.1932\n",
      "Epoch 419/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3344 - val_loss: 662.2133\n",
      "Epoch 420/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3345 - val_loss: 662.2323\n",
      "Epoch 421/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3346 - val_loss: 662.2504\n",
      "Epoch 422/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 19.3347 - val_loss: 662.2672\n",
      "Epoch 423/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3348 - val_loss: 662.2836\n",
      "Epoch 424/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3349 - val_loss: 662.2992\n",
      "Epoch 425/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 19.3350 - val_loss: 662.3138\n",
      "Epoch 426/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3351 - val_loss: 662.3275\n",
      "Epoch 427/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3353 - val_loss: 662.3410\n",
      "Epoch 428/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3354 - val_loss: 662.3537\n",
      "Epoch 429/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3355 - val_loss: 662.3652\n",
      "Epoch 430/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3357 - val_loss: 662.3766\n",
      "Epoch 431/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3358 - val_loss: 662.3871\n",
      "Epoch 432/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3360 - val_loss: 662.3972\n",
      "Epoch 433/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3361 - val_loss: 662.4066\n",
      "Epoch 434/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 19.3363 - val_loss: 662.4153\n",
      "Epoch 435/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3364 - val_loss: 662.4240\n",
      "Epoch 436/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3366 - val_loss: 662.4316\n",
      "Epoch 437/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3368 - val_loss: 662.4393\n",
      "Epoch 438/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3369 - val_loss: 662.4467\n",
      "Epoch 439/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3371 - val_loss: 662.4532\n",
      "Epoch 440/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 19.3373 - val_loss: 662.4594\n",
      "Epoch 441/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3375 - val_loss: 662.4655\n",
      "Epoch 442/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3377 - val_loss: 662.4708\n",
      "Epoch 443/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3379 - val_loss: 662.4762\n",
      "Epoch 444/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3380 - val_loss: 662.4811\n",
      "Epoch 445/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3382 - val_loss: 662.4855\n",
      "Epoch 446/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3384 - val_loss: 662.4899\n",
      "Epoch 447/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3386 - val_loss: 662.4943\n",
      "Epoch 448/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3387 - val_loss: 662.4979\n",
      "Epoch 449/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 19.3390 - val_loss: 662.5016\n",
      "Epoch 450/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3391 - val_loss: 662.5048\n",
      "Epoch 451/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3393 - val_loss: 662.5081\n",
      "Epoch 452/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3396 - val_loss: 662.5109\n",
      "Epoch 453/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3397 - val_loss: 662.5135\n",
      "Epoch 454/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3399 - val_loss: 662.5160\n",
      "Epoch 455/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3401 - val_loss: 662.5182\n",
      "Epoch 456/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3403 - val_loss: 662.5206\n",
      "Epoch 457/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3405 - val_loss: 662.5224\n",
      "Epoch 458/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 19.3407 - val_loss: 662.5242\n",
      "Epoch 459/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3409 - val_loss: 662.5261\n",
      "Epoch 460/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3411 - val_loss: 662.5275\n",
      "Epoch 461/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3413 - val_loss: 662.5290\n",
      "Epoch 462/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3415 - val_loss: 662.5303\n",
      "Epoch 463/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3417 - val_loss: 662.5313\n",
      "Epoch 464/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 19.3419 - val_loss: 662.5325\n",
      "Epoch 465/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3421 - val_loss: 662.5334\n",
      "Epoch 466/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3423 - val_loss: 662.5342\n",
      "Epoch 467/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3424 - val_loss: 662.5350\n",
      "Epoch 468/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3426 - val_loss: 662.5356\n",
      "Epoch 469/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3429 - val_loss: 662.5361\n",
      "Epoch 470/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3430 - val_loss: 662.5365\n",
      "Epoch 471/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3433 - val_loss: 662.5373\n",
      "Epoch 472/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3434 - val_loss: 662.5377\n",
      "Epoch 473/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3436 - val_loss: 662.5377\n",
      "Epoch 474/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3438 - val_loss: 662.5381\n",
      "Epoch 475/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3440 - val_loss: 662.5384\n",
      "Epoch 476/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3442 - val_loss: 662.5385\n",
      "Epoch 477/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3444 - val_loss: 662.5385\n",
      "Epoch 478/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3445 - val_loss: 662.5385\n",
      "Epoch 479/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3448 - val_loss: 662.5388\n",
      "Epoch 480/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3449 - val_loss: 662.5389\n",
      "Epoch 481/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3451 - val_loss: 662.5388\n",
      "Epoch 482/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3453 - val_loss: 662.5388\n",
      "Epoch 483/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3455 - val_loss: 662.5387\n",
      "Epoch 484/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3457 - val_loss: 662.5385\n",
      "Epoch 485/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3459 - val_loss: 662.5385\n",
      "Epoch 486/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3460 - val_loss: 662.5383\n",
      "Epoch 487/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3462 - val_loss: 662.5383\n",
      "Epoch 488/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3464 - val_loss: 662.5379\n",
      "Epoch 489/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 19.3466 - val_loss: 662.5377\n",
      "Epoch 490/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3468 - val_loss: 662.5374\n",
      "Epoch 491/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3470 - val_loss: 662.5370\n",
      "Epoch 492/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3471 - val_loss: 662.5367\n",
      "Epoch 493/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3473 - val_loss: 662.5365\n",
      "Epoch 494/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3475 - val_loss: 662.5363\n",
      "Epoch 495/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3476 - val_loss: 662.5362\n",
      "Epoch 496/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3478 - val_loss: 662.5359\n",
      "Epoch 497/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3480 - val_loss: 662.5354\n",
      "Epoch 498/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 19.3481 - val_loss: 662.5350\n",
      "Epoch 499/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3483 - val_loss: 662.5348\n",
      "Epoch 500/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.3485 - val_loss: 662.5342\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 0.1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 410ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.29485294e+01, 6.29233193e+01, 6.28981092e+01, 6.28728992e+01,\n",
       "        6.28476891e+01, 6.28224790e+01, 6.27972689e+01, 6.27720588e+01,\n",
       "        6.27468487e+01, 6.27216387e+01, 6.26964286e+01, 6.26712185e+01,\n",
       "        6.26460084e+01, 6.72410131e+01, 6.71821895e+01, 6.71233660e+01,\n",
       "        6.70645425e+01, 6.70057190e+01, 6.69241363e+01, 6.68401027e+01,\n",
       "        6.67560691e+01, 6.66720355e+01, 6.65880019e+01, 6.65039682e+01,\n",
       "        6.64199346e+01, 6.63359010e+01, 6.62518674e+01, 6.61678338e+01,\n",
       "        6.60838002e+01, 6.59995332e+01, 6.58314659e+01, 6.56633987e+01,\n",
       "        6.54953315e+01, 6.53272642e+01, 6.51591970e+01, 6.49911298e+01,\n",
       "        6.48230626e+01, 6.46549953e+01, 6.44869281e+01, 6.43188609e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.20769352e-01, 0.00000000e+00, 0.00000000e+00, 6.63545752e+01,\n",
       "        6.62705416e+01, 6.61865079e+01, 6.61024743e+01, 6.60184407e+01,\n",
       "        6.58688142e+01, 6.57007470e+01, 6.55326797e+01, 6.53646125e+01,\n",
       "        6.51965453e+01, 6.50284781e+01, 6.48604108e+01, 6.46923436e+01,\n",
       "        6.45242764e+01, 6.43562091e+01, 6.41881419e+01, 6.40200747e+01,\n",
       "        6.39482026e+01, 6.38893791e+01, 6.38305556e+01, 6.37717320e+01,\n",
       "        6.37129085e+01, 6.36540850e+01, 6.35952614e+01, 6.35364379e+01,\n",
       "        6.34776144e+01, 7.01576080e+01, 1.39298870e-01, 4.98692630e-01,\n",
       "        0.00000000e+00, 5.88601890e-01, 0.00000000e+00, 3.46430600e-01,\n",
       "        6.24517937e+01, 8.75539482e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        8.97975504e-01, 5.31670213e-01, 0.00000000e+00, 4.96764690e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.48790255e-02, 0.00000000e+00, 1.00005102e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.69428781e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60.81945378, 60.81105042, 60.80264706, 60.7942437 , 60.78584034,\n",
       "       60.77743697, 60.76903361, 60.76063025, 60.75222689, 60.74382353,\n",
       "       60.73542017, 60.72701681, 60.71861345, 60.71021008, 60.70180672,\n",
       "       60.69340336, 60.685     , 60.67659664, 60.66819328, 60.65978992,\n",
       "       60.65138655, 60.64298319, 60.63457983, 60.62617647, 60.61777311,\n",
       "       60.60936975, 60.60096639, 60.59256303, 60.58415966, 60.5757563 ,\n",
       "       60.56735294, 60.55894958, 60.55054622, 60.54214286, 60.5337395 ,\n",
       "       60.52533613, 60.51693277, 60.50852941, 60.50012605, 60.49172269,\n",
       "       60.48331933, 60.47491597, 60.46651261, 60.45810924, 60.44970588,\n",
       "       60.44130252, 60.43289916, 60.4244958 , 60.41609244, 60.40768908,\n",
       "       60.39928571, 60.39088235, 60.38247899, 60.37407563, 60.36567227,\n",
       "       60.35860411, 60.35430906, 60.35001401, 60.34571895, 60.3414239 ,\n",
       "       60.33712885, 60.3328338 , 60.32853875, 60.3242437 , 60.31994865,\n",
       "       60.31565359, 60.31135854, 60.30706349, 60.30276844, 60.29847339,\n",
       "       60.29417834, 60.28988329, 60.28558824, 60.28129318, 60.27699813,\n",
       "       60.27270308, 60.26840803, 60.26411298, 60.25981793, 60.25552288,\n",
       "       60.25122782, 60.24693277, 60.24263772, 60.23834267, 60.23404762,\n",
       "       60.22975257, 60.22545752, 60.22116246, 60.21686741, 60.21257236,\n",
       "       60.20827731, 60.20398226, 60.19968721, 60.19539216, 60.19109711,\n",
       "       60.18680205, 60.182507  , 60.17821195, 60.1739169 , 60.16962185])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.23132612658196\n",
      "22.247226213258934\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
