{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2245    54.421220\n",
       "2246    54.412475\n",
       "2247    54.403730\n",
       "2248    54.394985\n",
       "2249    54.386240\n",
       "Name: C1, Length: 2250, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_2150_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2145     0.000000\n",
       "2146     0.000000\n",
       "2147     0.000000\n",
       "2148     0.000000\n",
       "2149     0.000000\n",
       "Name: C1, Length: 2150, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2150)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAuMklEQVR4nO2deXQc1ZX/P0+7rcW2dsULsmXZeAEMyGBsFgcTzJIZYMIhDJngBAjzC3syWWCSzEzmZOZkmUDIBJiwE0JYYghLiNkXg40N8m7jVd5tyZJly4tsWZb6/f7oVruXanVVdXVXdet+zvFRdfVbbpWlb7267777lNYaQRAEIf3IctsAQRAEwR4i4IIgCGmKCLggCEKaIgIuCIKQpoiAC4IgpCk5qeysvLxc19bWprJLQRCEtGfJkiV7tdYVkedTKuC1tbU0NjamsktBEIS0Rym1zei8uFAEQRDSFBFwQRCENEUEXBAEIU0RARcEQUhTRMAFQRDSFBFwQRCENEUEXBAEIU1JCwF/Zfku/rjIMAxSEARhwJIWAv7mmhYefH8TkrtcEAThBGkh4OfUlbP7QBfb2o+4bYogCIJnSAsBn15XBsDCpnaXLREEQfAOaSHgY8oLqSrJZ2HTXrdNEQRB8AxpIeBKKabXlfNJU7v4wQVBEAKkhYCD343S3tnNO2tb3TZFEATBE6SNgF92Sg0Ta0q449llLNu+321zBEEQXCdtBLwwP4cnb5hKRXE+33zyMzbuOeS2SYIgCK6SNgIOUFlcwNM3nkVOVhZ//7sF3PvWeg4f63HbLEEQBFdIKwEHOKmskL/cMp1ZEyr57XubmPmr93n6k60c7/W5bZogCEJKSTsBBxhZOpjfXXcGL986gzEVRfzklTXMvm8+b6xuligVQRAGDGkp4H1MGTmU52+exqPXN5CVpfh/f1zK1x/7lN0dR902TRAEIemktYCDP0b8oolVvHHnefznFZNYun0/s++bz9wlO2U0LghCRpP2At5HTnYW159Tyxt3ns+EmhK+9+cVfOsPS2g91OW2aYIgCEkhYwS8j1Flg3n25mn8+PIJzN/YxuW//ZhNrYfdNksQBMFxMk7AAbKzFDedN4ZXb5uB1pqvPbqIrXs73TZLEATBUTJSwPs4ubqEZ26aRnePj+seWcSOfZKOVhCEzMGUgCulvqOUWqOUWq2UelYpVaCUGq2UWqyU2qSUel4plZdsY+0wvrqYp288m8PHerju0UUSoSIIQsYQV8CVUsOBO4AGrfVkIBu4FvgFcJ/WeiywH7gxmYYmwuThQ3j6xrPp6DzO1x5dTOtBmdgUBCH9MetCyQEGKaVygMFAM3AhMDfw/VPAlY5b5yCnjRzKkzdMZc/BLi7/34/56Wtr+GzrPnw+CTUUBCE9yYlXQGu9Syn1P8B24CjwFrAE6NBa9yUi2QkMT5qVDnHmSaU8c9PZPPD+Jp5ZtJ0nFmylojif2ZOquHRyDWePLiUnO6OnBQRByCDiCrhSahhwBTAa6AD+DFxitgOl1M3AzQCjRo2yZaSTnD5qGI/OmcqhruO8t66VN1a3MHfJTv64aDvDBudy8cRqLjmlmhl15eTliJgLguBd4go4cBGwRWvdBqCUegmYAQxVSuUERuEjgF1GlbXWDwMPAzQ0NHjGX1FckMsVU4ZzxZThHO3u5cMNrcxb3cLrq5p5vnEHxQU5XDShiksmV3PBuAoKcrPdNlkQBCEMMwK+HZimlBqM34UyC2gE3geuBp4D5gCvJMvIZDMoL5tLJtdwyeQajvX08vHGvcxb3cLbn+/hL8t2MTgvmy+eXMmlk6v54vhKCvPN3DZBEITkoszkC1FK/RT4KtADLANuwu/zfg4oDZz7J631sf7aaWho0I2NjYnanDKO9/pYtLmdeatbeGtNC3sPd5Ofk8X54yq4dHI1syZUMWRQrttmCoKQ4SillmitG6LOpzLhU7oJeCi9Ps1nW/fxxuoW3ljdQsvBLnKzFTPGlnPp5Gq+NLGa0kJPhsILgpDmiIA7iM+nWb6zgzdWtzBvdTM79h0lO0sxbUwpl0yuYfakKiqLC9w2UxCEDEEEPElorVmz+yDzVjczb3ULm9s6UQoaThoW8KtXM3zoILfNFAQhjREBTwFaaza2HmbeKv/IfF2Lf+Pl00YMYeb4Ss4fV85pI4ZKrLkgCJYQAXeBLXs7mbe6mTfX7GHlzg60huL8HKbVlXFefTnnji1ndHkhSim3TRUEwcOIgLtMx5FuFja189HGvXy8qY0d+/xJtYYPHcS5Y8s5t76cGWPLZSJUEIQoRMA9xrb2Tr+Yb9zLwqa9HOzqQSmY9IUSzh1bwVWnD2d8dbHbZgqC4AFEwD1MT6+PlbsO8HFA0Jdu30+PTzN7UhW3X1jP5OFD3DZREAQXEQFPIzqOdPP4gq08sWALh7p6mHVyJbfPqmfKyKFumyYIgguIgKchB7uO89SCrTy2YAsdR45zXn05d8yqZ2ptqdumCYKQQkTA05jDx3r446JtPDJ/M+2d3UwbU8odF9ZzTl2ZRLAIwgBABDwDONrdy58+3c7vP2yi9dAxzjxpGLdfOJYLxlWIkAtCBiMCnkF0He/lhcYd/N8HTew+0MVpI4Zw+4X1zJpQKUIuCBmICHgG0t3j48WlO3nwg03s2HeUiTUl3H7hWGZPqiYrS4RcEDIFEfAM5nivj1eW7+aB9zexZW8nw4cOYsbYMqbXlXNOXRlVJZJYSxDSGRHwAUCvT/PXlbt5fWUzi7fs48DR4wCMKS9kWl0Z0+vKmDamjPKifJctFQTBCiLgA4xen2Zt80E+aWrnk83tfLplH4eP+fegHldVxPS6cqaNKWPamFKGDpbl+5nC2uaDjK8q9rQLbV9nN8d6eqkZIlk6zSICPsDp6fWxatcBPtnczidN7TRu3c/R470oBROqS5heV8Y5dWWcNbqU4gLZZSgdWbJtH1956BN+fPkEbjpvjOl6Pp9m8n+8yU++PJF/PCv5G4/X3v06AFt/frmlek8s2ML9725k+b9dnAyzPE0sAZfNHQcIOdlZnD5qGKePGsYtM8fS3eNjxc4O/wi9qZ0/LNrGox9vIUvBKSOGMr2ujPPrKzjzpGHk5Uj623RgW/sRANbsPmipXnevjyPdvfz7q2tSIuB2+elrn7ttgucQAR+g5OVkMbW2lKm1pdwxq56u470s3b6fRU3tLGxq55H5m3nogyaK8nOYXlfGzPGVXDC+Qjan8DC9Pv/btNVI0r6XcA97XYQYiIALABTkZjO9rpzpdeV8FzjUdZyFTe18uKGND9e38dbnewCoryzignEVzBxfydTRw8jPyXbXcCFInxBnW1Tw3kDFLFlDkHaIgAuGFBfkMntSNbMnVaO1pqntMB+sb+OD9W384RO/u2VQbjbT68q4YHwFM8dVMqpssNtmD2h8NoW4r55V4RfcRwRciItSirGVxYytLOam88ZwpLuHTwKj8w/Wt/HuulZgDbVlgxlTUURVSQE1QwqoHuL/WTOkgKqSApkcNYnWmp37jzKy1NoD0dfnCrE4ZaF9gQOL+t16sIuSQbkU5GbGW9iOfUcs33O3EQEXLDM4L4dZE6qYNaEKrTVb24/wwfpWPmlqZ1fHUVbs6KC9szuqXlF+TlDUI0W+umQQ1UMKGDY4NyPTATz/2XZeX9XCJZOqueyU6n5DNx/7eAs/e30t8+48jwk1Jab76HOFWL1/GnMj91dX7GbN7gP8cPbJZGUpzvrvd7loQiWPzpkaLHOo6zj//PQSbpk5lnPryy3ZkQxeaNzBuKriflMx7+/s5nt/XsG761p58GtnsGDTXu65bAJF+bHl8b11eyguyHU9M6gIuJAQSilGlxcyunw035wxOnj+WE8vrQeP0Xygi+YDR2k50EXzgS72HPT/3LhnL62HuoKjxj7yc7IYXV7ImIpCxpQXUVfp/zmmojCtR/DvrWtl/oY25m9o499fXc3lp9Rw03ljDDfrWNjUDsCu/UctCbgOulCs2dY3+Rmv3v3vbKCprRM0/PCSkwF4Z21rWJnt+46wMDARbvUBlAx+MHcl0H/I4i/fXBd4i4Rfv7WeprZOCvNz+NfLJsSsc8OTjXHbTQUi4EJSyM/JZmTp4H5fSXt6fbQdPkbLga6gwO/uOMqWvZ2sbT7Em2v2BMUFoLI43y/sFUXUVfhFva68iOHDBpHt8RCKXh9MrCnhl1efytwlO3mhcQcvL9/NjLFlfOu8MWEZJY/3+n0aOdmK11bs5ufz1vHVqSOZc04tQwbHfoj5fPZ82UHXS5x6o8uLaGrr5PfzN9MQGHlGVvH5Thzf8sxSXr1tBjv3H+XHL6/m/munMGKY8e+D1ppZ937IlyZUcU8/wmmXYz29MSfcQ11AI0sH09TWycPzN9PTq/m3v5sYZmNnd2/YyPyOZ5fxs6smk5edxe3PLuN7F49P6VaIIuCCa+RkZ1EzZFDMFXndPT627+ukqa2TprbDbG7rZHPbYV5f2RxMEwD+kMjJXyjhgnGVzBxfwSnDh3huJWKvz0dOtmLy8CFMHj6E71w0jj99up0nF27hG098xlmjS/n9P53JsMK8oIDnZmexcc8hdnUc5d63N/Dw/M388upTueyUGsM++oTYsgvFpOvFpzX1lUUoBXc9t8xvY4TDvSeg4N+eWcfD8zfz67c2MKaikCXb9nPTU428cdf5hm33+jSb2zr5fdtmvnLmCMZVOSuCq3cd5MyThhl+Vx2SKygn5Pfm8QVbwgT8z0t28oO5K3nvXy4Innt1xW5KBuVw7dRRvP35Hrbu7eTt7574PtmIgAueJS8nKzh5GorWmn2d3TQFBL2p7TCfbt3Pb97dwH3vbKCsMI/zx1Uwc3wF59VXUFrofqqAXh0+wh0yOJdvz6zjxnNH8+clO/jpa5/zlYcW8uQ3zwq+dfSJSZaC1+84jx/9ZRW3PLOU788ezy0z66IE124USt87TrxnXo9PMzg/h3+99GS++vAiv43ZxjacM6aM3R1HeWnpzuCIel3LIbYHFhuFsnhze9icwB8XbeM/r5hs6Rri0dR2OKaA94S85UXe044j3UHbFm/eB8CnW/ZRXJDDoS5/aooNLYcpDIzKN7YedtTueIiAC2mHUoqyonzKivI5a/SJSaT2w8f4aONePljfyocb2vjLsl0oBaeNGMrM8f7Y9VNdGp33+nxho7s+8nKy+NrZJzGuqphv/aGRqx5cEHy7yMk+MbqdUFPCn741jR/MXcmv3lzPlr2d/PdVp4StkvWF+MC37u3k5/PW8f1LxlNXURTHNnPC7/NpshWBdAt+ATvS3cuBo8cZMsjv2unpDbhxshTXNIzkleW7eWtNS7CN5z7bHtVu38Ogj78s3cXdl55Mfk42f1q8jX84Y0RQII144P1NDB86iCtPHx6zzM590Q+O0OvqI/K/aGv7EaYEBHxkqf9Ncd7qFkoKcoMCvqW9k7+tag7WeW/dHi48uSpmf04ia6SFjKGsKJ8rTx/Ob649nc9+dBEv3zqDO2fVA3D/uxu58oEFNPzXO9z13DJeXraLfQaRMsmi16f79dNPrS3lxW9PZ3B+dnBEmJutCJ3jLcjN5v5rp3DnrHrmLtnJ1x9bTMeRE9dwIoxQsWJnB2+saeGqBxawcNPefm3zmZz87PH5yMnKQinFVSFief1ji09cpz4h4OeMKWP40EG8v74N8CdRe6FxZ799XDCugkPHenhtxW5W7TrAT15Zw61/WtpvnV+9uZ67nl9OT68v6ru+a9q5/2g/13XiLudmh0vitvbO4PEXAq6+Dze0BV1FAG2HjvGrN9cHP9/wZGPYQyGZiIALGUl2lmLKyKHcddE4Xr51Bkt+/CXuv3YKF4yr4KONe7nr+eWc+bO3ueKBBfz0tTU8PL+JV1fs5rOt+9ix7wjdPdFikAjxBBygrqKIl749I/g5UkzA//bxnS+N4zdfncKy7R1c9eBCXl62iwNHjgeFOHQgnZ+bzfWPf8qv31rPphiv99qk77zXp4Mx5t8KSZa1YueBsDLgd/9kZSkuO6U6+N11Z41i7+FjUe2GTgo2nDSMcVVFPL1oWzAs/YP1bXQd742qdzQw+u/jjZCRPvhH1n062mbQb6TNAIPzwic6t+49MXIPfXPrjSPQrYdi9+ck4kIRBgSlhXlcMWU4V0wZjs+nWbXrgH9l6YZWnv9sB0e6owWivCiP6mCMej41QwZRXeKPXe+LXx+cZ+5PqMenKciN77qpKM7n3mtO47svrAgKvpGwXnn6cIYPG8Sdzy7jrueXk52lDF0hj17fwIMfbOJ/3/P/q68s4tLJ1Vx6Sg0nVxejlDqRCyXL7/P9h4cWUldRxJdPrWHWhKqgwPb6dDCSY2TpYHKzFcd7w4UsaEPA9qL8E1EzF4yvpH7x9ig/cWlhXjDVsVJw07lj+MGLK/nO88uDZW56KjqL6T0vreTl5buDn38wdyXlRfmcVVvKDU99xqyTK2PdZgDuf2cjjdv2UVtWGDzXEyHMS7fvN6wbT8CXbNvP5acaTzY7iQi4MODIylKcNnIop40cyp0X1aO15tCxnmA4Y19IY8vBLloOHGXn/iM0bttHx5HjUW2VFOQEBH0QNSUFjCwdxMjSwYwKhFCWFeahlPL7j0363s3ml5laW8rHP7yQFTs7ePvzPTz4QRMAFSEbdhQV5PD7rzfQcqCLN9e0MG91M797fxO/fW8TtWWDufzUGs4aXea/L0qxu6OLzW2d7O44ytuf7yEvJ4uZ4yq4+swRHOvxUVxw4hoUCkKcPGubD7K7owvA0N+frRTPfOtszvqvd8POa8LF8JqpI2lqO8zv528G4NLJ1VGja39/h4LH54wpY+/hY3zjiU958GtnBNM+GLF61wHeW9fKip0dfLRxLx9tPOFiaosYOW/YcyiyOgD7DX4XQpm3ulkEXBBSgVKKkoJcSgpy+w1f6zreG7UgqeXA0eDnz3cfjHIRDM7LZlTpYHbsO8I5dWWWbYuXrj8rSwXTBF91+nC+dN98Kkvyo0aI1UMKmDO9ljnTa9l7+BhvrdnDvNXN/N+Hm3ngfb/wh47c77tmChXF+by+qpm/rmwOJjO7MMaottenuerBBXQd90W1FUplcQGXn1LD+hjC2MdpISsnv3LGCGZPquaukBE5+CcV+9qpLMnnf687neseWcTNf1jSb9tPLNjKi0v9vvjCvGw6Q96+QsU8Ed5f18rxXp+hG8xJRMAFwSQFudnUlhdSW14Ys8zR7l527j/C9n0n/u3Y559Am16XmqXl8US/vCif684exXVnj6LlQBdzl+zgf97awKQvnFg1qZSiobaUhtpSfnTZBN5b18pLS3fxxZMrDNv0aU3XcR+TvlBCaWFev/fIb6OxkUbuIqX8LqOfz1tHy8Gufq/rF185laseXAjAbV8cy+6Oo/x1ZXN4ueITIYsnlRUyZ/pJ/PbdTezqiD3R2Z/NRnR293KsRwRcENKKQXnZ1FcVU+/AQhSrm2UZDXrjOW2qhxRw24X1/M9bGxhTURTlzgB/OOPFk6q5eFK1QQvhXHZKDbd+cayhTcHjCKOUySxa10wdyW/f3Rj8bHR/QsMNiwpyuPerU9gaEkli1N9Xp46iqqSAbzzxGQCnjhjCypCJWSPysrPIzVZho3c3kCgUQfAYkUJsJ2o9JTslOhROb/TQcKK7WOWN+osVgZPCHSdtYUrAlVJDlVJzlVLrlFJrlVLnKKVKlVJvK6U2Bn4aL3MSBME2ZsXNaUwt5gwxzWmhC+3ejC1OLs0KbUuj+duqZsMY83ikYr9hsyPw+4E3tNYnA6cBa4G7gXe11vXAu4HPgiAIcUn1YymWlho+HEJO7jl4jFueWcrv3t8UbrNHUu3EFXCl1BDgfOAxAK11t9a6A7gCeCpQ7CngyuSYKAgDE7uj79BalhJbaZ3UkXR/56zQN7I1MtVYjxNX25YDsSdP3cTMCHw00AY8oZRappR6VClVCFRprfumd1sAw8X/SqmblVKNSqnGtjbjuExBEE4QKTfm9edEQavin6jGJeLqMfvQsGpjzPIG/XlkQG0ZMwKeA5wBPKS1Ph3oJMJdov2PRMP/Bq31w1rrBq11Q0WFcQiSIAjGuDWJ5raghUWvmLDGyV2cnGopFf91ZgR8J7BTa92XsWYufkHfo5SqAQj8bI1RXxAEIYzNbZ08/vEWx9uNpeOx3hAMQy9NjNzdfsD1EVfAtdYtwA6l1PjAqVnA58CrwJzAuTnAK0mxUBAGKHZH36HRD1aExokRY1QIpFEceID//Ovncesb0Xd5ZqM8vCK2ycDsQp7bgWeUUnnAZuCb+MX/BaXUjcA24JrkmCgIA4voOHBzEhRaz/IiIGvFo7DSX6S7w7QP3KKVscobTn6mqcqbEnCt9XKgweCrWY5aIwhCGG6tI3HSp2zTAsNDE6Wd7DkhUjF/ISsxBUHIIKytqDQapcdclRnyOHX9+RZABFwQPIoTIziLYeAJ9xkpiKFiaGZUb8ZNoiN+xm3TI2KbDETABcFz2EuGErYE3HIirNSpnN2enIoDN5r8tOpf9woi4ILgYSQO3KQtDhrsWFPiAxcEIZ1w210Re9RtvrzVNtxEBFwQPIrtXChhC06sKWoysx+ascSqz95cv26/TyQPEXBB8Bh284GH+rHtyHAq8plA9PVZTbuaaJpWo+puvznYRQRcEDxMqvKB20+glRzC84GrqHPR5fs3OOZSehttmSUV/3ci4IIgOIbbA1lH+o+ZT8V7iIALgkdJdRy4U33G6t/pnXVMm+r2UyWJiIALgsdI1J2h0bb8xImId0L+8ySVj72i0qCsRRu8ggi4IHgZK5ODCXTTXxZBpzEXjRKygjN4rr/y/bcX8+FkUNGpS7/s/o945/M9DrVmjAi4IAiO4frkpwOC7FQc+O4DXXxv7gqLvVtDBFwQhCB2HSFmkkWZ21nHSp9enFZMLSLgguAxIkeRlhfjaLtx4Pb7TATDuGwHysfcWCeFTvBkP2NEwAXBw1j5+0/EfZFKwbaaOKuveCIJtxZv2Uft3a+zu+NoeNtG/aXRlKYIuCAIQRJ1S7gtfoaCHHJyY+vh+G1Y3FfTTltOIQIuCB7FjThwu5gJ8jAXB54+o18vIAIuCB4j4ThwjS0nuA53gqcMo5Ftf9f8yvJdpspbGUmn64NDBFwQPIwVl0ZCIpRC/bIc1hdR4/tzV8Yu68CmD26HQlpBBFwQhCCJem1SKX4p383eg1GLIuCC4FGcyGaXqq3SYr0pqBjHsXDSXEthhGmKCLggeAy7+cBDSVT8U+lFcCI/d6I+7HRym4QiAi4IHsbOaNH2akpPJky1Jq7W3SX2+0vlRtCxEAEXhAwhsYU8flLiXrBpZ9ROPiYfOE7pbGRvXljKLwIuCB7FkTjwxJswhalkfykesHphhJxsRMAFwWNEp3a1LkSJin8qxc84NUl0Otn+SNTcdJV6EXBB8DC2klLZVW9HVn66vJTechy4QfpZk424fa0gAi4IAqHCZ0/FLe1Kb3O8G1nPdBy45YiWGHjA5x2JCLggeBQn5MLtQaL1fODOGRx7YwZnhFgmMQVBiIu9OPDU92mXuPm5zSTBStQH7vaTziYi4ILgMUJHqqmNA0+cdJNBiQMXBMETOLGhg22vQKwt1ZKYLCp5uVAMzilnHnBOIwIuCBmMl9KkmssHnlh9M23Zi+wxOhe/JdlSTRAGKEGBsKHBiceBJ1bfGkb5uUOPTUWCJ2RB+MYTJiZbPfJgNC3gSqlspdQypdRfA59HK6UWK6U2KaWeV0rlJc9MQRhAhGiDV/OTxMJtt7AT+cBjEfpQ1GhzQu+hLdXuBNaGfP4FcJ/WeiywH7jRScMEQbBJiNBYEyj7jws3HjTJyoWSyMRmJJ5woSilRgCXA48GPivgQmBuoMhTwJVJsE8QBJMkEhWRypGzXT+3ZRNjNGYrssemDzzZmB2B/wb4AeALfC4DOrTWPYHPO4HhRhWVUjcrpRqVUo1tbW2J2CoIA4o+eXAnH7jzim5lg4XQh5GpyU+7GQ4DVoX53B3cfNl1F4pS6stAq9Z6iZ0OtNYPa60btNYNFRUVdpoQhAFF6N+8BwZ5lnB7ai9ZsdlKhY+4zfrAk/3/l2OizAzg75VSlwEFQAlwPzBUKZUTGIWPAKK3ihYEIeWEjr6tyJnW9gUnVr1kCarWOoniGG2zVx+kcUfgWut7tNYjtNa1wLXAe1rrrwHvA1cHis0BXkmalYIgxCURqUzlyNmun9u5OPDU5UJx3YXSDz8EvquU2oTfJ/6YMyYJggAnRn3u5ANPrL5xmzEmFY3KxjiO2baFsjE76jvloA/cCy6UIFrrD4APAsebgbOcN0kQBjZeyLFhleCEa4psd1oY45kduZTe7wN3fx2k+xYIguAoYeJmJQ4c50PjkinnZi21+lAxKm33tnjZhSIIgodIKJlVROVk6k5/7gezYhupp1aSZjn1jJJcKIIg9IP/r9+OMHsxaCJ2HLhBLhSD3CTmNoRI3CYnfeDJRgRcEDxGeBy4F6U4mj4709B9H6B/w/1x4Cc+p2MuFEEQ0gwrI0WtnR+5J0vAtAVjrZpgdM+8+hwVAReEDMOO1kRJlttZBS1vwhBdPlYbHtViW4iAC4JHsZoOPEywPDhk7BuNR47KtUEZM/UM+7Aq/CYnPyPPiQ9cEARDQsXCezJsTCKJtxLpzynMPBwi48C9gAi4IGQwVn3Qji+Qcba5MOzmA493jUb3zOkcMU4hAi4IGYZtsQlLguWui8CJnXXSNyLGPCLgguBRrC5PT8j14pTY9WNrMPd2PyNiw7hsg3Oxsx/2b14sm+Kes+kDlzBCQRhghIpDqucirfh2Q8t6cM7UEvF01p9qNzwfuBnEhSIIgm3c9iIkM7mVWXE0iOq2WsGziIALQoZhN0IizJXh8nLyuCPiiGs063qxi+0t28SFIggDE+tx4NF1zeKYC9zUl+GldJwnx4k4cBNL1+OWMG7bahteyQcuAi4IHiN8MjLlTnALRa37hL1KvIdDpBB75XpFwAUhg3F7c4jk5UKJ/6yJNXKPHwfunNHiQhEEIeU46UZI3AAzWf/61Dop1tgWYnGhCMIAxW4q2ciQNzMkPOoM7t/ZXx/GZWxuIOQIyfaBJxsRcEHwGJGTkaa11QFNsSL7qfYDJ3eXoP7xPxRDPttcxu80IuCCkMG4PU5Mai6UOG8ZwZWfUfX6b9dJ0RUXiiAIKSFUEM2F7CUzDvxE21YE1QmbzGyzJi4UQRD6xe7gTSdQ1y4n0sn2lwslTmXMi7VTI9tkC7G4UARhoBGVlMpk4qQExKhPaKwIo10fuF0rkymG5vKBSy4UQRBSiOspVZOZCyVu38YmxBNft2PnrSACLghCFK7nQglp2jCdbGQuFAvbrsXqp7/+ost4Q+RFwAXBo9h+/dbaVt1E3va1qThw4y/D48C9IYyReDVdrgi4IHiMyHzgZkeVibz591W1mw/cUl92M/tF9u+gqJp5cNiJA082IuCCkMG4PaJNVu+R4m28s46xFXGFP422ZxMBFwQhCrf9wKEtW5lUdMIiM9fl9oOxDxFwQfAoibym26mZiEtCmwh4jPVd+AIi+zYMRETABcFjhIuYtjzWs6PDfaPc1MSBJ67STi9WMhcHHnosPnBBEBzEUINc3grMyRF1f64Uw3DAwMn+sh+abcuriIALgmCLyGgZcFL4Y01Bmq9nt7zb/n8riIALgldJxCdtw6GdbLdALG21kw/cbq70TCOugCulRiql3ldKfa6UWqOUujNwvlQp9bZSamPg57DkmysImY/tfOAhdez26eV84NEGpLb/dM0H3gP8i9Z6IjANuFUpNRG4G3hXa10PvBv4LAiCSxi6A2wLiDPKYxifnQS/vGEK2BjfDah84FrrZq310sDxIWAtMBy4AngqUOwp4Mok2SgIggcJ84EbnEuobWV8HNlftE0W+zE8Zy4O3AtecEs+cKVULXA6sBio0lo3B75qAaqcNU0QBjaZ5uWNJXmho9R0igAx8//jBRcKAEqpIuBF4C6t9cHQ77R/RsHwepRSNyulGpVSjW1tbQkZKwgDgVBXiNbWR7Wp2gzZbR+4/Q0vomtmdD5wpVQufvF+Rmv9UuD0HqVUTeD7GqDVqK7W+mGtdYPWuqGiosIJmwVBMKA/P3DcupFbhiUxDtz2hg4hx1G5UAzSyTqZYtarmIlCUcBjwFqt9b0hX70KzAkczwFecd48QRDSgeDI3SnhDztOTd7x/s5FlTFpVbIfBjkmyswAvg6sUkotD5z7V+DnwAtKqRuBbcA1SbFQEAYoCeUmSYF3wy9hiXcU6o7wxtSgOcxcebL/H+IKuNb6Y2I/V2c5a44gCKGjNo1O2Su91fwiVn3gjl6HTmTDi+hT9vKBu/+wkZWYgpBhhK1sNK2aqp9P9jH0y5uwybrfOpD3JDQLeJ8P3JHgQm8iAi4IGYKbk28Ou8DDCF5XEi7Q+AFjpp43nD0i4ILgURLLB558J7hTEhbmCjHZpNshjH4b3EcEXBA8RlQulBT1G3s1R4zyrseB28tHYlTLcr4ZT8i3CLggZBxhKxtN1omOA3d+SbzFmvZKh8aB23z0ecE1YhYRcEHIELzglXVK+A3bDjl2KjzPbgIw8YELgtAvbsSBW3ENOOYDD2szffCCE0UEXBA8RngceHJHteFYkyRX48Ax/5CK8oEbVFQmXC9e3ERCBFwQMozwOHB7bVitFkvbbPuhraaT7ScXSr/9xOnb64iAC0KmkIDwJHPhTlSZJGzo4AZeMEcEXBA8SiIv7LZXmVuo6Ng0Xlg+cC/Iojm84FARARcEzxGeD9yrWPaBOzhm1Vqb94FH9GsYBx66BD9mn+b6SyUi4IKQwVgRzUR2xokp5g744M1ucWanO+N0suZa8cK7ggi4IGQYdqIlkrmBQ1QZT0hfZiACLggexaoQh4Uf2o0Dd8FNYHpJvMEmym6hPbKYXgRcEDyGW/nAw2xIwijZblhfLOKFSwZdIVFx4EZlrfXnFUTABSGDsSL+Tqz8jMqpYrO9UD+0lWuwHsUiS+kFQUhzvCFH5vFiRIgbiIALgkexqlFhyZ5svvCnQhejl7bbq+cm4gMXBMGQMJ3S7ghXMvp0epVm6CSvivgZ6xzEigMPPY6VC8W8balCBFwQBCDRHYD8RIqf3ZWVYYJqmAvFGTU1nvw0Uc8jTicRcEHIMOyMFL3knhDMIwIuCF7FohCHjnbtx4GnYi/NiD5t1nMT8YELgmBImBCTHhEiZoTfjDvF9JtARHfBkG+DdLKR/cbPBx6rSy9Idjgi4IKQwaTaNeJcHHhoG6nZps2o79j1vPFYFQEXhAzDdgih9waYQhxEwAXBo2i0JZ90IiPCvrruxIGbzIUSsdWcXZy4RvGBC4JgSKQQp0McuBkxMxUHbjf9bTCdrDI4Z4bQpfsSBy4Iggdw21Nrf09Oe7lQLPdjFAdupp7rd9aPCLggCIA3s+3FwoujYTcQARcEj6K1PVHV2k4ucRWsm2yiwvqS32U4tjqMtFl84IIgGGA3FM9JV4NVB4EZ4TcVntdPmei9LUNyofQbB26xX8Py3hDsSETABSGDSX0ceGQuFLvthBwbfO9YLhSjfOAm9+AUH7ggCJ5B/Mrphwi4IHgUvy/bRj0SEePUq3iq9++0N3pXYR2KD1wQBEPspmQ1dgfYtMFyRWM5Uwbx1bZdD/1s2my4JL6f7/pp2vDa2w51mWgl9SQk4EqpS5RS65VSm5RSdztllCAI9vFpzdHjvbbqftLUbqved19YAVgX5yXb9sctYySodz63jI2th/ut1xtQ+R7fCbW/58WV/G1VS79tG13DO2tbeW1lc/Bz13GfqWs9cPQ47YePmShpD9sCrpTKBh4ALgUmAv+olJrolGGCMNBZvKWdV1fs5kh3j6V6v3xjPQ9+0GS5vxeX7uSpT7ZZrgewcucB02VfWrYrePyVhxaGfXesxxdV3mcwuP9sa7jwdxnU+2jDXgD+GiK8uw/EH0mv2mV8LVv2dsata8SZP3vHVj0zJDICPwvYpLXerLXuBp4DrnDGLEEQHvloCwB7DiZvBNfH0MG5YZ+L8nPi1qksLog6t3p3fCFvOxT7eg53+R9WvSGqvb+z24Qt+QDk55yQtH88exQAVSX5cevnZJ2ot639SNzyADVDo68/Fhfd+yHbTbZrhUQEfDiwI+TzzsC5MJRSNyulGpVSjW1tbQl0JwgDg/qqorDP35hea6reoLxszh1bHvx81enDyck29yf+7Zl11Ff6+x1fVcyIYYPi1nnqhqlR5248d3TY52ljyigpyOGs2tLguU/uuTB4fNqIIQDUVxZRmJfN9eecBMCEmpJgmTNPGgbAjLHlXDShMqz9G2aMDv4Dv5/9J1+eyP3XTmHKyKEAPHJ9g+H1Xn5qDddMHQnAyNJBTK8rA+CxOQ3cdVE9L357OgW5xvfv+7PH86urT+OGGaP5/uzxAPz7303kgevO4Kd/P4nsLL+DpaQgh+wsxbiqIvJynJ9yVHZ34FBKXQ1corW+KfD568DZWuvbYtVpaGjQjY2NtvoTBEEYqCillmito55EiTwSdgEjQz6PCJwTBEEQUkAiAv4ZUK+UGq2UygOuBV51xixBEAQhHvFnKmKgte5RSt0GvAlkA49rrdc4ZpkgCILQL7YFHEBr/Tfgbw7ZIgiCIFhAVmIKgiCkKSLggiAIaYoIuCAIQpoiAi4IgpCm2F7IY6szpdoAe8kWoBzY66A5mYTcm9jIvTFG7ktsvHhvTtJaV0SeTKmAJ4JSqtFoJZIg96Y/5N4YI/clNul0b8SFIgiCkKaIgAuCIKQp6STgD7ttgIeRexMbuTfGyH2JTdrcm7TxgQuCIAjhpNMIXBAEQQhBBFwQBCFNSQsBH+ibJyultiqlVimlliulGgPnSpVSbyulNgZ+DgucV0qp3wbu1Uql1BnuWu8sSqnHlVKtSqnVIecs3wul1JxA+Y1KqTluXIvTxLg3/6GU2hX43VmulLos5Lt7AvdmvVJqdsj5jPp7U0qNVEq9r5T6XCm1Ril1Z+B8+v/eaK09/Q9/qtomYAyQB6wAJrptV4rvwVagPOLcL4G7A8d3A78IHF8GzMO/ufY0YLHb9jt8L84HzgBW270XQCmwOfBzWOB4mNvXlqR78x/A9wzKTgz8LeUDowN/Y9mZ+PcG1ABnBI6LgQ2B60/735t0GIHL5snGXAE8FTh+Crgy5PwftJ9FwFClVI0L9iUFrfV8YF/Eaav3YjbwttZ6n9Z6P/A2cEnSjU8yMe5NLK4AntNaH9NabwE24f9by7i/N611s9Z6aeD4ELAW//69af97kw4Cbmrz5AxHA28ppZYopW4OnKvSWjcHjluAqsDxQLxfVu/FQLtHtwVcAY/3uQkYoPdGKVULnA4sJgN+b9JBwAU4V2t9BnApcKtS6vzQL7X//U7iQZF7YcBDQB0wBWgGfu2qNS6ilCoCXgTu0lofDP0uXX9v0kHAB/zmyVrrXYGfrcBf8L/m7ulzjQR+tgaKD8T7ZfVeDJh7pLXeo7Xu1Vr7gEfw/+7AALs3Sqlc/OL9jNb6pcDptP+9SQcBH9CbJyulCpVSxX3HwMXAavz3oG8WfA7wSuD4VeD6wEz6NOBAyGtipmL1XrwJXKyUGhZwKVwcOJdxRMx/XIX/dwf89+ZapVS+Umo0UA98Sgb+vSmlFPAYsFZrfW/IV+n/e+P2DLHJWeTL8M8cNwE/ctueFF/7GPyRACuANX3XD5QB7wIbgXeA0sB5BTwQuFergAa3r8Hh+/EsflfAcfw+yBvt3AvgBvwTd5uAb7p9XUm8N08Hrn0lfmGqCSn/o8C9WQ9cGnI+o/7egHPxu0dWAssD/y7LhN8bWUovCIKQpqSDC0UQBEEwQARcEAQhTREBFwRBSFNEwAVBENIUEXBBEIQ0RQRcEAQhTREBFwRBSFP+P24gZNiIbdwmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 1, 251) (1700, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/22 [==============================] - 3s 26ms/step - loss: 4275.7090 - val_loss: 2312.8928\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4019.9788 - val_loss: 2188.9194\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3885.5000 - val_loss: 2123.5107\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3774.2891 - val_loss: 2064.5554\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3672.4790 - val_loss: 2012.5955\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3578.8931 - val_loss: 1963.5273\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3488.9827 - val_loss: 1916.6901\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 3401.9810 - val_loss: 1871.7568\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 3317.4438 - val_loss: 1828.5331\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 3235.1040 - val_loss: 1786.8916\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 3154.7864 - val_loss: 1746.7417\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 3076.3640 - val_loss: 1708.0142\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 2999.7422 - val_loss: 1670.6533\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 2924.8464 - val_loss: 1634.6129\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 2851.6143 - val_loss: 1599.8528\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 2779.9951 - val_loss: 1566.3373\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 2709.9424 - val_loss: 1534.0344\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 2641.4172 - val_loss: 1502.9146\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 2574.3833 - val_loss: 1472.9504\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2508.8064 - val_loss: 1444.1158\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2444.6582 - val_loss: 1416.3866\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2381.9087 - val_loss: 1389.7391\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2320.5317 - val_loss: 1364.0959\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2260.5007 - val_loss: 1339.5996\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2201.7922 - val_loss: 1316.0646\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2144.3818 - val_loss: 1293.5244\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2088.2473 - val_loss: 1271.9430\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2033.3671 - val_loss: 1251.2368\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1979.8447 - val_loss: 1231.6819\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1927.2837 - val_loss: 1212.9279\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1876.0404 - val_loss: 1195.0728\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1825.9688 - val_loss: 1178.0988\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1777.0497 - val_loss: 1161.9868\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1729.2642 - val_loss: 1146.7200\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1682.5941 - val_loss: 1132.2803\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1637.0203 - val_loss: 1118.6503\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1592.5247 - val_loss: 1105.8129\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1549.0902 - val_loss: 1093.7512\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1506.6987 - val_loss: 1082.4485\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1465.3331 - val_loss: 1071.8878\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1424.9763 - val_loss: 1062.0532\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1385.6113 - val_loss: 1052.9280\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1347.2220 - val_loss: 1044.4961\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1309.7910 - val_loss: 1036.7416\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1273.3030 - val_loss: 1029.6484\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1237.7410 - val_loss: 1023.2011\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1203.0897 - val_loss: 1017.3840\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1169.3329 - val_loss: 1012.1817\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1136.4552 - val_loss: 1007.5788\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1104.4414 - val_loss: 1003.5601\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1073.2760 - val_loss: 1000.1107\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1042.9436 - val_loss: 997.2153\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1013.4291 - val_loss: 994.8595\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 984.7182 - val_loss: 993.0283\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 956.7958 - val_loss: 991.7073\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 929.6473 - val_loss: 990.8820\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 903.2583 - val_loss: 990.5380\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 877.6144 - val_loss: 990.6613\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 852.7015 - val_loss: 991.2376\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 828.5056 - val_loss: 992.2529\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 805.0125 - val_loss: 993.6935\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 782.2086 - val_loss: 995.5455\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 760.0799 - val_loss: 997.7954\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 738.6130 - val_loss: 1000.4297\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 717.7946 - val_loss: 1003.4349\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 697.6111 - val_loss: 1006.7982\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 678.0494 - val_loss: 1010.5057\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 659.0966 - val_loss: 1014.5450\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 640.7394 - val_loss: 1018.9031\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 622.9651 - val_loss: 1023.5676\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 605.7609 - val_loss: 1028.5253\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 589.1144 - val_loss: 1033.7638\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 573.0129 - val_loss: 1039.2714\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 557.4443 - val_loss: 1045.0350\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 542.3962 - val_loss: 1051.0433\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 527.8564 - val_loss: 1057.2841\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 513.8133 - val_loss: 1063.7454\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 500.2548 - val_loss: 1070.4161\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 487.1691 - val_loss: 1077.2842\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 474.5449 - val_loss: 1084.3389\n",
      "Epoch 81/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 462.3704 - val_loss: 1091.5686\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 450.6345 - val_loss: 1098.9628\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 439.3260 - val_loss: 1106.5101\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 428.4337 - val_loss: 1114.1998\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 417.9469 - val_loss: 1122.0219\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 407.8546 - val_loss: 1129.9664\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 398.1461 - val_loss: 1138.0217\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 388.8113 - val_loss: 1146.1793\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 379.8393 - val_loss: 1154.4281\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 371.2202 - val_loss: 1162.7598\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 362.9441 - val_loss: 1171.1637\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 355.0005 - val_loss: 1179.6312\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 347.3801 - val_loss: 1188.1537\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 340.0731 - val_loss: 1196.7214\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 333.0699 - val_loss: 1205.3259\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 326.3613 - val_loss: 1213.9592\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 319.9381 - val_loss: 1222.6128\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 313.7912 - val_loss: 1231.2784\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 307.9118 - val_loss: 1239.9482\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 302.2911 - val_loss: 1248.6146\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 296.9206 - val_loss: 1257.2705\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 291.7919 - val_loss: 1265.9076\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 286.8967 - val_loss: 1274.5206\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 282.2270 - val_loss: 1283.1013\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 277.7748 - val_loss: 1291.6439\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 273.5323 - val_loss: 1300.1416\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 269.4920 - val_loss: 1308.5887\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 265.6465 - val_loss: 1316.9785\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 261.9886 - val_loss: 1325.3065\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 258.5111 - val_loss: 1333.5667\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 255.2070 - val_loss: 1341.7535\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 252.0695 - val_loss: 1349.8628\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.0921 - val_loss: 1357.8888\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 246.2684 - val_loss: 1365.8281\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 243.5921 - val_loss: 1373.6752\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 241.0572 - val_loss: 1381.4279\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 238.6575 - val_loss: 1389.0800\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 236.3875 - val_loss: 1396.6290\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 234.2414 - val_loss: 1404.0718\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 232.2138 - val_loss: 1411.4054\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 230.2995 - val_loss: 1418.6265\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 228.4933 - val_loss: 1425.7321\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 226.7902 - val_loss: 1432.7194\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 225.1856 - val_loss: 1439.5869\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 223.6746 - val_loss: 1446.3320\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 222.2529 - val_loss: 1452.9535\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 220.9160 - val_loss: 1459.4490\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 219.6599 - val_loss: 1465.8181\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 218.4803 - val_loss: 1472.0579\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 217.3736 - val_loss: 1478.1691\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 216.3358 - val_loss: 1484.1494\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 215.3635 - val_loss: 1489.9993\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 214.4532 - val_loss: 1495.7173\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 213.6014 - val_loss: 1501.3032\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 212.8051 - val_loss: 1506.7570\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 212.0613 - val_loss: 1512.0796\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 211.3668 - val_loss: 1517.2698\n",
      "Epoch 138/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 210.7191 - val_loss: 1522.3284\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 210.1153 - val_loss: 1527.2565\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 209.5530 - val_loss: 1532.0537\n",
      "Epoch 141/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 209.0295 - val_loss: 1536.7217\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 208.5428 - val_loss: 1541.2610\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 208.0905 - val_loss: 1545.6726\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 207.6705 - val_loss: 1549.9575\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 207.2808 - val_loss: 1554.1177\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 206.9195 - val_loss: 1558.1531\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 206.5848 - val_loss: 1562.0664\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 206.2751 - val_loss: 1565.8586\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 205.9886 - val_loss: 1569.5320\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 205.7237 - val_loss: 1573.0883\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 205.4792 - val_loss: 1576.5284\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 205.2535 - val_loss: 1579.8547\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 205.0455 - val_loss: 1583.0698\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 204.8538 - val_loss: 1586.1743\n",
      "Epoch 155/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 204.6774 - val_loss: 1589.1716\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 204.5151 - val_loss: 1592.0640\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 204.3660 - val_loss: 1594.8522\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 204.2290 - val_loss: 1597.5396\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 204.1033 - val_loss: 1600.1279\n",
      "Epoch 160/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 203.9881 - val_loss: 1602.6199\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 203.8825 - val_loss: 1605.0177\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 203.7859 - val_loss: 1607.3220\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 203.6975 - val_loss: 1609.5382\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 203.6167 - val_loss: 1611.6665\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 203.5430 - val_loss: 1613.7103\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 203.4757 - val_loss: 1615.6705\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 203.4144 - val_loss: 1617.5508\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 203.3585 - val_loss: 1619.3525\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 203.3077 - val_loss: 1621.0784\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 203.2615 - val_loss: 1622.7319\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 203.2195 - val_loss: 1624.3136\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 203.1813 - val_loss: 1625.8260\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 203.1468 - val_loss: 1627.2728\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 203.1154 - val_loss: 1628.6541\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 203.0871 - val_loss: 1629.9730\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 203.0614 - val_loss: 1631.2323\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 203.0383 - val_loss: 1632.4331\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 203.0173 - val_loss: 1633.5785\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9985 - val_loss: 1634.6689\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9815 - val_loss: 1635.7081\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9663 - val_loss: 1636.6970\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9525 - val_loss: 1637.6377\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9402 - val_loss: 1638.5323\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9292 - val_loss: 1639.3829\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9193 - val_loss: 1640.1908\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9105 - val_loss: 1640.9575\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9027 - val_loss: 1641.6849\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8957 - val_loss: 1642.3750\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 202.8895 - val_loss: 1643.0298\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8840 - val_loss: 1643.6494\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8792 - val_loss: 1644.2368\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 202.8749 - val_loss: 1644.7915\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8712 - val_loss: 1645.3175\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 202.8679 - val_loss: 1645.8138\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 202.8651 - val_loss: 1646.2831\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8626 - val_loss: 1646.7267\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8605 - val_loss: 1647.1456\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8587 - val_loss: 1647.5400\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8572 - val_loss: 1647.9125\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8560 - val_loss: 1648.2639\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8550 - val_loss: 1648.5947\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8542 - val_loss: 1648.9060\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8536 - val_loss: 1649.1989\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 202.8531 - val_loss: 1649.4752\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 202.8528 - val_loss: 1649.7340\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8526 - val_loss: 1649.9775\n",
      "Epoch 207/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 202.8526 - val_loss: 1650.2063\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 202.8527 - val_loss: 1650.4213\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8529 - val_loss: 1650.6228\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8531 - val_loss: 1650.8112\n",
      "Epoch 211/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8535 - val_loss: 1650.9884\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8539 - val_loss: 1651.1538\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8544 - val_loss: 1651.3092\n",
      "Epoch 214/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8549 - val_loss: 1651.4545\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8555 - val_loss: 1651.5902\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8561 - val_loss: 1651.7173\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 202.8568 - val_loss: 1651.8362\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 202.8575 - val_loss: 1651.9467\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 202.8583 - val_loss: 1652.0504\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 202.8590 - val_loss: 1652.1471\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8599 - val_loss: 1652.2361\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8607 - val_loss: 1652.3206\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8616 - val_loss: 1652.3986\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8623 - val_loss: 1652.4706\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8633 - val_loss: 1652.5382\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8642 - val_loss: 1652.6010\n",
      "Epoch 227/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8651 - val_loss: 1652.6592\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8660 - val_loss: 1652.7129\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8669 - val_loss: 1652.7632\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8678 - val_loss: 1652.8096\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8687 - val_loss: 1652.8524\n",
      "Epoch 232/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 202.8697 - val_loss: 1652.8920\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 202.8706 - val_loss: 1652.9287\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8715 - val_loss: 1652.9626\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8725 - val_loss: 1652.9938\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8734 - val_loss: 1653.0226\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8744 - val_loss: 1653.0498\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8753 - val_loss: 1653.0737\n",
      "Epoch 239/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 202.8762 - val_loss: 1653.0967\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8771 - val_loss: 1653.1167\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8780 - val_loss: 1653.1359\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8790 - val_loss: 1653.1534\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8799 - val_loss: 1653.1691\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8807 - val_loss: 1653.1836\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8817 - val_loss: 1653.1965\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8826 - val_loss: 1653.2089\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8834 - val_loss: 1653.2202\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8843 - val_loss: 1653.2301\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 202.8851 - val_loss: 1653.2391\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 202.8860 - val_loss: 1653.2472\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8869 - val_loss: 1653.2544\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8877 - val_loss: 1653.2605\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8886 - val_loss: 1653.2666\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8893 - val_loss: 1653.2722\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8902 - val_loss: 1653.2769\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 202.8909 - val_loss: 1653.2810\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8918 - val_loss: 1653.2845\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8925 - val_loss: 1653.2875\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8933 - val_loss: 1653.2908\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8940 - val_loss: 1653.2926\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8948 - val_loss: 1653.2944\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8956 - val_loss: 1653.2963\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8963 - val_loss: 1653.2976\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8970 - val_loss: 1653.2991\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8978 - val_loss: 1653.3004\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8984 - val_loss: 1653.3008\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.8991 - val_loss: 1653.3011\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.8998 - val_loss: 1653.3011\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9005 - val_loss: 1653.3011\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9012 - val_loss: 1653.3011\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9018 - val_loss: 1653.3009\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9025 - val_loss: 1653.3008\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9031 - val_loss: 1653.3004\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9037 - val_loss: 1653.2997\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9044 - val_loss: 1653.2990\n",
      "Epoch 276/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9050 - val_loss: 1653.2975\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9056 - val_loss: 1653.2971\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9062 - val_loss: 1653.2954\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 202.9067 - val_loss: 1653.2948\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9073 - val_loss: 1653.2941\n",
      "Epoch 281/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9078 - val_loss: 1653.2928\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9084 - val_loss: 1653.2919\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9090 - val_loss: 1653.2908\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9095 - val_loss: 1653.2897\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9099 - val_loss: 1653.2875\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9105 - val_loss: 1653.2860\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9110 - val_loss: 1653.2853\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9115 - val_loss: 1653.2844\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9120 - val_loss: 1653.2830\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9125 - val_loss: 1653.2820\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9129 - val_loss: 1653.2802\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9135 - val_loss: 1653.2783\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9139 - val_loss: 1653.2773\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9143 - val_loss: 1653.2762\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9148 - val_loss: 1653.2750\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9152 - val_loss: 1653.2740\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9156 - val_loss: 1653.2733\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9160 - val_loss: 1653.2721\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9165 - val_loss: 1653.2695\n",
      "Epoch 300/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9169 - val_loss: 1653.2689\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9173 - val_loss: 1653.2681\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9176 - val_loss: 1653.2667\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9180 - val_loss: 1653.2659\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9184 - val_loss: 1653.2646\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9187 - val_loss: 1653.2635\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 202.9191 - val_loss: 1653.2612\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9194 - val_loss: 1653.2605\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9198 - val_loss: 1653.2599\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9201 - val_loss: 1653.2583\n",
      "Epoch 310/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9205 - val_loss: 1653.2570\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9208 - val_loss: 1653.2566\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9211 - val_loss: 1653.2554\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9215 - val_loss: 1653.2537\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9218 - val_loss: 1653.2529\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9221 - val_loss: 1653.2518\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9224 - val_loss: 1653.2507\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9226 - val_loss: 1653.2496\n",
      "Epoch 318/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9229 - val_loss: 1653.2490\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9232 - val_loss: 1653.2483\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9235 - val_loss: 1653.2476\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9237 - val_loss: 1653.2471\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9240 - val_loss: 1653.2452\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9242 - val_loss: 1653.2441\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9245 - val_loss: 1653.2432\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9248 - val_loss: 1653.2424\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9250 - val_loss: 1653.2417\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9252 - val_loss: 1653.2408\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9254 - val_loss: 1653.2401\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9257 - val_loss: 1653.2397\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9259 - val_loss: 1653.2391\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9261 - val_loss: 1653.2388\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 202.9263 - val_loss: 1653.2375\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9266 - val_loss: 1653.2368\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9267 - val_loss: 1653.2350\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9270 - val_loss: 1653.2347\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9272 - val_loss: 1653.2341\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9273 - val_loss: 1653.2333\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9276 - val_loss: 1653.2327\n",
      "Epoch 339/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9278 - val_loss: 1653.2319\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9279 - val_loss: 1653.2314\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9281 - val_loss: 1653.2305\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9283 - val_loss: 1653.2301\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9285 - val_loss: 1653.2297\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9286 - val_loss: 1653.2286\n",
      "Epoch 345/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9288 - val_loss: 1653.2283\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9290 - val_loss: 1653.2283\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9291 - val_loss: 1653.2268\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9293 - val_loss: 1653.2261\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9295 - val_loss: 1653.2257\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9296 - val_loss: 1653.2253\n",
      "Epoch 351/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9297 - val_loss: 1653.2250\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9298 - val_loss: 1653.2239\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9300 - val_loss: 1653.2234\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9300 - val_loss: 1653.2227\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9302 - val_loss: 1653.2220\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9304 - val_loss: 1653.2220\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 202.9305 - val_loss: 1653.2217\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9306 - val_loss: 1653.2216\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9307 - val_loss: 1653.2213\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9308 - val_loss: 1653.2212\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9310 - val_loss: 1653.2208\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9311 - val_loss: 1653.2202\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9312 - val_loss: 1653.2195\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9313 - val_loss: 1653.2191\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9315 - val_loss: 1653.2188\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9315 - val_loss: 1653.2184\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9317 - val_loss: 1653.2184\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9318 - val_loss: 1653.2178\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9319 - val_loss: 1653.2177\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9320 - val_loss: 1653.2174\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9320 - val_loss: 1653.2166\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9322 - val_loss: 1653.2163\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9322 - val_loss: 1653.2162\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9324 - val_loss: 1653.2159\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9325 - val_loss: 1653.2159\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9325 - val_loss: 1653.2156\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9326 - val_loss: 1653.2152\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9327 - val_loss: 1653.2151\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9328 - val_loss: 1653.2148\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9328 - val_loss: 1653.2144\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 202.9330 - val_loss: 1653.2141\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9330 - val_loss: 1653.2140\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 202.9330 - val_loss: 1653.2130\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9332 - val_loss: 1653.2126\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9332 - val_loss: 1653.2126\n",
      "Epoch 386/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9333 - val_loss: 1653.2125\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9334 - val_loss: 1653.2123\n",
      "Epoch 388/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9334 - val_loss: 1653.2123\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 202.9335 - val_loss: 1653.2119\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9335 - val_loss: 1653.2119\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9336 - val_loss: 1653.2118\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9337 - val_loss: 1653.2115\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9337 - val_loss: 1653.2112\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9337 - val_loss: 1653.2103\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9338 - val_loss: 1653.2103\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9339 - val_loss: 1653.2103\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 202.9340 - val_loss: 1653.2103\n",
      "Epoch 398/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9340 - val_loss: 1653.2101\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 202.9341 - val_loss: 1653.2100\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9342 - val_loss: 1653.2103\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9342 - val_loss: 1653.2096\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9342 - val_loss: 1653.2090\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9343 - val_loss: 1653.2086\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 202.9343 - val_loss: 1653.2083\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9344 - val_loss: 1653.2083\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9344 - val_loss: 1653.2083\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9345 - val_loss: 1653.2083\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9345 - val_loss: 1653.2083\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9345 - val_loss: 1653.2081\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9345 - val_loss: 1653.2081\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9346 - val_loss: 1653.2078\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9346 - val_loss: 1653.2078\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9347 - val_loss: 1653.2078\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9347 - val_loss: 1653.2078\n",
      "Epoch 415/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9347 - val_loss: 1653.2074\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9348 - val_loss: 1653.2078\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9348 - val_loss: 1653.2078\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9348 - val_loss: 1653.2074\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9348 - val_loss: 1653.2072\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9349 - val_loss: 1653.2072\n",
      "Epoch 421/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9349 - val_loss: 1653.2072\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9350 - val_loss: 1653.2074\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9350 - val_loss: 1653.2070\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9350 - val_loss: 1653.2070\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9350 - val_loss: 1653.2070\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9350 - val_loss: 1653.2064\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9351 - val_loss: 1653.2064\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9352 - val_loss: 1653.2070\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9352 - val_loss: 1653.2074\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 202.9352 - val_loss: 1653.2072\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9352 - val_loss: 1653.2072\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9352 - val_loss: 1653.2068\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9352 - val_loss: 1653.2061\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9353 - val_loss: 1653.2057\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9353 - val_loss: 1653.2057\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9354 - val_loss: 1653.2064\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9354 - val_loss: 1653.2068\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9354 - val_loss: 1653.2068\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9354 - val_loss: 1653.2068\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9354 - val_loss: 1653.2061\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9354 - val_loss: 1653.2053\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9354 - val_loss: 1653.2052\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9355 - val_loss: 1653.2052\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9355 - val_loss: 1653.2053\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9356 - val_loss: 1653.2053\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9356 - val_loss: 1653.2061\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9356 - val_loss: 1653.2061\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9356 - val_loss: 1653.2056\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9356 - val_loss: 1653.2052\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9356 - val_loss: 1653.2048\n",
      "Epoch 451/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9356 - val_loss: 1653.2048\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9356 - val_loss: 1653.2045\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9356 - val_loss: 1653.2041\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 202.9357 - val_loss: 1653.2041\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 202.9357 - val_loss: 1653.2037\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9358 - val_loss: 1653.2034\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9358 - val_loss: 1653.2037\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9358 - val_loss: 1653.2041\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9358 - val_loss: 1653.2041\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9358 - val_loss: 1653.2039\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9358 - val_loss: 1653.2039\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9358 - val_loss: 1653.2037\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 202.9358 - val_loss: 1653.2037\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9358 - val_loss: 1653.2037\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9358 - val_loss: 1653.2031\n",
      "Epoch 466/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9359 - val_loss: 1653.2031\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9359 - val_loss: 1653.2031\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9359 - val_loss: 1653.2028\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9359 - val_loss: 1653.2018\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9359 - val_loss: 1653.2018\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9359 - val_loss: 1653.2018\n",
      "Epoch 472/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9359 - val_loss: 1653.2018\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9359 - val_loss: 1653.2018\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9360 - val_loss: 1653.2018\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9360 - val_loss: 1653.2018\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9360 - val_loss: 1653.2018\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9360 - val_loss: 1653.2018\n",
      "Epoch 478/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 202.9360 - val_loss: 1653.2020\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9360 - val_loss: 1653.2020\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9360 - val_loss: 1653.2028\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9360 - val_loss: 1653.2029\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9360 - val_loss: 1653.2029\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9361 - val_loss: 1653.2031\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9361 - val_loss: 1653.2034\n",
      "Epoch 485/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9361 - val_loss: 1653.2037\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9361 - val_loss: 1653.2041\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9361 - val_loss: 1653.2041\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9361 - val_loss: 1653.2041\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9361 - val_loss: 1653.2041\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9361 - val_loss: 1653.2039\n",
      "Epoch 491/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9361 - val_loss: 1653.2039\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9361 - val_loss: 1653.2039\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9361 - val_loss: 1653.2041\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9361 - val_loss: 1653.2041\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9361 - val_loss: 1653.2041\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9362 - val_loss: 1653.2041\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9362 - val_loss: 1653.2041\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9362 - val_loss: 1653.2041\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 202.9361 - val_loss: 1653.2039\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.9361 - val_loss: 1653.2039\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 528ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.43562091e+01, 6.39482026e+01, 6.37717320e+01, 6.35952614e+01,\n",
       "        7.01576080e+01, 0.00000000e+00, 3.46430600e-01, 0.00000000e+00,\n",
       "        5.65112590e-01, 3.09912920e-01, 0.00000000e+00, 6.30238290e-01,\n",
       "        0.00000000e+00, 6.52712418e+01, 6.47670401e+01, 6.42628385e+01,\n",
       "        0.00000000e+00, 1.82196870e-01, 6.62425303e+01, 6.59808590e+01,\n",
       "        6.54766573e+01, 6.49724557e+01, 6.44682540e+01, 6.39874183e+01,\n",
       "        6.38109477e+01, 6.36344771e+01, 6.34580065e+01, 0.00000000e+00,\n",
       "        4.71156840e-01, 6.46736695e+01, 6.41694678e+01, 6.38828431e+01,\n",
       "        6.37063725e+01, 6.35299020e+01, 6.33534314e+01, 6.31418067e+01,\n",
       "        6.29149160e+01, 6.26880252e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.19523504e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.36736928e+01,\n",
       "        6.34972222e+01, 0.00000000e+00, 3.53158380e-01, 6.47857143e+01,\n",
       "        6.42815126e+01, 6.39220588e+01, 6.37455882e+01, 6.35691177e+01,\n",
       "        6.33926471e+01, 6.31922269e+01, 6.29653361e+01, 6.27384454e+01,\n",
       "        0.00000000e+00, 5.23700950e-01, 6.36410131e+01, 6.34645425e+01,\n",
       "        6.32846639e+01, 6.30577731e+01, 6.28308824e+01, 6.71429739e+01,\n",
       "        6.64479458e+01, 6.53832867e+01, 1.66747361e-01, 7.79817820e-01,\n",
       "        0.00000000e+00, 5.02027245e+01, 0.00000000e+00, 7.84876525e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.17062069e-01, 0.00000000e+00,\n",
       "        6.50290375e+01, 0.00000000e+00, 7.85096586e-02, 0.00000000e+00,\n",
       "        7.30025113e-01, 6.65228516e-02, 6.76276684e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.93823530e-02, 0.00000000e+00, 2.17627078e-01, 1.15207791e-01,\n",
       "        6.18553162e-01, 4.47264045e-01, 8.58413935e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55.25199153, 55.24324657, 55.23450161, 55.22575664, 55.21701168,\n",
       "       55.20826672, 55.19952176, 55.1907768 , 55.18203184, 55.17328688,\n",
       "       55.16454191, 55.15579695, 55.14705199, 55.13830703, 55.12956207,\n",
       "       55.12081711, 55.11207215, 55.10332718, 55.09458222, 55.08583726,\n",
       "       55.0770923 , 55.06834734, 55.05960238, 55.05085742, 55.04211245,\n",
       "       55.03336749, 55.02462253, 55.01587757, 55.00713261, 54.99838765,\n",
       "       54.98964269, 54.98089772, 54.97215276, 54.9634078 , 54.95466284,\n",
       "       54.94591788, 54.93717292, 54.92842796, 54.919683  , 54.91093803,\n",
       "       54.90219307, 54.89344811, 54.88470315, 54.87595819, 54.86721323,\n",
       "       54.85846827, 54.8497233 , 54.84097834, 54.83223338, 54.82348842,\n",
       "       54.81474346, 54.8059985 , 54.79725354, 54.78850857, 54.77976361,\n",
       "       54.77101865, 54.76227369, 54.75352873, 54.74478377, 54.73603881,\n",
       "       54.72729384, 54.71854888, 54.70980392, 54.70105896, 54.692314  ,\n",
       "       54.68356904, 54.67482408, 54.66607911, 54.65733415, 54.64858919,\n",
       "       54.63984423, 54.63109927, 54.62235431, 54.61360935, 54.60486438,\n",
       "       54.59611942, 54.58737446, 54.5786295 , 54.56988454, 54.56113958,\n",
       "       54.55239462, 54.54364965, 54.53490469, 54.52615973, 54.51741477,\n",
       "       54.50866981, 54.49992485, 54.49117989, 54.48243493, 54.47368996,\n",
       "       54.464945  , 54.45620004, 54.44745508, 54.43871012, 54.42996516,\n",
       "       54.4212202 , 54.41247523, 54.40373027, 54.39498531, 54.38624035])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.230595707367584\n",
      "33.239257417255814\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
