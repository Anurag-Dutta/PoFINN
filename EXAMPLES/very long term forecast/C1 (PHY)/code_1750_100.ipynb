{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1845    59.558754\n",
       "1846    59.548483\n",
       "1847    59.538212\n",
       "1848    59.527941\n",
       "1849    59.517670\n",
       "Name: C1, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_1750_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1745     0.000000\n",
       "1746     0.000000\n",
       "1747     0.000000\n",
       "1748     0.000000\n",
       "1749     0.169429\n",
       "Name: C1, Length: 1750, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1750)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 1, 251) (1300, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 2s 31ms/step - loss: 4550.1426 - val_loss: 3106.1228\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4495.0181 - val_loss: 3075.9758\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4445.3071 - val_loss: 3044.6973\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4394.8818 - val_loss: 3013.6465\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4344.8491 - val_loss: 2980.7551\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4284.8481 - val_loss: 2943.1267\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4229.3994 - val_loss: 2908.9026\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4175.1196 - val_loss: 2875.5847\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4122.0215 - val_loss: 2843.0007\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4069.8716 - val_loss: 2811.0110\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4018.5100 - val_loss: 2779.5325\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3967.8408 - val_loss: 2748.5115\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3917.8005 - val_loss: 2717.9138\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3868.3494 - val_loss: 2687.7146\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3819.4561 - val_loss: 2657.8962\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3771.0974 - val_loss: 2628.4441\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3723.2571 - val_loss: 2599.3479\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3675.9204 - val_loss: 2570.5977\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3629.0750 - val_loss: 2542.1858\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3582.7109 - val_loss: 2514.1057\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3536.8203 - val_loss: 2486.3521\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3491.3948 - val_loss: 2458.9194\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3446.4277 - val_loss: 2431.8025\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3401.9131 - val_loss: 2404.9976\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3357.8447 - val_loss: 2378.5007\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3314.2170 - val_loss: 2352.3074\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3271.0254 - val_loss: 2326.4155\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3228.2651 - val_loss: 2300.8208\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3185.9326 - val_loss: 2275.5205\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3144.0222 - val_loss: 2250.5115\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3102.5308 - val_loss: 2225.7905\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3061.4539 - val_loss: 2201.3560\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3020.7883 - val_loss: 2177.2041\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2980.5310 - val_loss: 2153.3325\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2940.6765 - val_loss: 2129.7393\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2901.2229 - val_loss: 2106.4209\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 2862.1665 - val_loss: 2083.3762\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2823.5044 - val_loss: 2060.6021\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2785.2327 - val_loss: 2038.0959\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2747.3484 - val_loss: 2015.8567\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2709.8499 - val_loss: 1993.8813\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2672.7319 - val_loss: 1972.1680\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2635.9927 - val_loss: 1950.7140\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2599.6294 - val_loss: 1929.5176\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2563.6389 - val_loss: 1908.5771\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2528.0188 - val_loss: 1887.8899\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2492.7659 - val_loss: 1867.4542\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2457.8770 - val_loss: 1847.2681\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2423.3506 - val_loss: 1827.3293\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2389.1824 - val_loss: 1807.6364\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2355.3713 - val_loss: 1788.1868\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2321.9138 - val_loss: 1768.9789\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2288.8074 - val_loss: 1750.0111\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2256.0498 - val_loss: 1731.2811\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2223.6382 - val_loss: 1712.7875\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2191.5706 - val_loss: 1694.5278\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2159.8433 - val_loss: 1676.5009\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2128.4551 - val_loss: 1658.7042\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2097.4031 - val_loss: 1641.1370\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2066.6846 - val_loss: 1623.7966\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2036.2979 - val_loss: 1606.6816\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2006.2396 - val_loss: 1589.7900\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1976.5078 - val_loss: 1573.1205\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1947.1001 - val_loss: 1556.6710\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1918.0142 - val_loss: 1540.4398\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1889.2479 - val_loss: 1524.4253\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1860.7987 - val_loss: 1508.6256\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1832.6637 - val_loss: 1493.0394\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1804.8420 - val_loss: 1477.6650\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1777.3309 - val_loss: 1462.5006\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1750.1273 - val_loss: 1447.5446\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1723.2301 - val_loss: 1432.7952\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1696.6360 - val_loss: 1418.2510\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1670.3441 - val_loss: 1403.9102\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1644.3507 - val_loss: 1389.7712\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1618.6545 - val_loss: 1375.8326\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1593.2537 - val_loss: 1362.0928\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1568.1454 - val_loss: 1348.5499\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1543.3275 - val_loss: 1335.2025\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1518.7986 - val_loss: 1322.0493\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1494.5554 - val_loss: 1309.0880\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1470.5968 - val_loss: 1296.3177\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1446.9200 - val_loss: 1283.7367\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1423.5234 - val_loss: 1271.3433\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1400.4050 - val_loss: 1259.1362\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1377.5624 - val_loss: 1247.1139\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1354.9941 - val_loss: 1235.2748\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1332.6979 - val_loss: 1223.6173\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1310.6709 - val_loss: 1212.1400\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1288.9121 - val_loss: 1200.8413\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1267.4194 - val_loss: 1189.7200\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1246.1907 - val_loss: 1178.7743\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1225.2231 - val_loss: 1168.0026\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1204.5159 - val_loss: 1157.4039\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1184.0667 - val_loss: 1146.9763\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1163.8730 - val_loss: 1136.7189\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1143.9336 - val_loss: 1126.6292\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1124.2461 - val_loss: 1116.7067\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1104.8083 - val_loss: 1106.9496\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1085.6191 - val_loss: 1097.3566\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1066.6760 - val_loss: 1087.9263\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1047.9775 - val_loss: 1078.6569\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1029.5212 - val_loss: 1069.5470\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1011.3052 - val_loss: 1060.5959\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 993.3281 - val_loss: 1051.8013\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 975.5876 - val_loss: 1043.1624\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 958.0825 - val_loss: 1034.6774\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 940.8102 - val_loss: 1026.3453\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 923.7692 - val_loss: 1018.1644\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 906.9570 - val_loss: 1010.1332\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 890.3728 - val_loss: 1002.2507\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 874.0137 - val_loss: 994.5151\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 857.8786 - val_loss: 986.9252\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 841.9656 - val_loss: 979.4797\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 826.2726 - val_loss: 972.1772\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 810.7980 - val_loss: 965.0161\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 795.5400 - val_loss: 957.9954\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 780.4965 - val_loss: 951.1135\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 765.6659 - val_loss: 944.3690\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 751.0462 - val_loss: 937.7604\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 736.6362 - val_loss: 931.2869\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 722.4335 - val_loss: 924.9467\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 708.4365 - val_loss: 918.7386\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 694.6434 - val_loss: 912.6610\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 681.0525 - val_loss: 906.7128\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 667.6619 - val_loss: 900.8928\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 654.4700 - val_loss: 895.1992\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 641.4752 - val_loss: 889.6312\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 628.6756 - val_loss: 884.1871\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 616.0692 - val_loss: 878.8657\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 603.6544 - val_loss: 873.6656\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 591.4298 - val_loss: 868.5858\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 579.3934 - val_loss: 863.6244\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 567.5432 - val_loss: 858.7803\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 555.8781 - val_loss: 854.0526\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 544.3956 - val_loss: 849.4394\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 533.0946 - val_loss: 844.9397\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 521.9732 - val_loss: 840.5521\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 511.0296 - val_loss: 836.2754\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 500.2623 - val_loss: 832.1080\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 489.6692 - val_loss: 828.0490\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 479.2491 - val_loss: 824.0969\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 469.0002 - val_loss: 820.2504\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 458.9205 - val_loss: 816.5082\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 449.0085 - val_loss: 812.8690\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 439.2625 - val_loss: 809.3316\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 429.6810 - val_loss: 805.8946\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 420.2623 - val_loss: 802.5566\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 411.0045 - val_loss: 799.3168\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 401.9061 - val_loss: 796.1735\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 392.9655 - val_loss: 793.1255\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 384.1809 - val_loss: 790.1715\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 375.5507 - val_loss: 787.3102\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 367.0732 - val_loss: 784.5405\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 358.7466 - val_loss: 781.8610\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 350.5696 - val_loss: 779.2706\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 342.5406 - val_loss: 776.7677\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 334.6577 - val_loss: 774.3514\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 326.9193 - val_loss: 772.0202\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 319.3238 - val_loss: 769.7729\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 311.8695 - val_loss: 767.6082\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 304.5547 - val_loss: 765.5250\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 297.3783 - val_loss: 763.5220\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 290.3384 - val_loss: 761.5978\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 283.4330 - val_loss: 759.7514\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 276.6611 - val_loss: 757.9816\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 270.0209 - val_loss: 756.2870\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 263.5108 - val_loss: 754.6662\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 257.1291 - val_loss: 753.1182\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 250.8742 - val_loss: 751.6418\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 244.7446 - val_loss: 750.2358\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 238.7388 - val_loss: 748.8988\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 232.8554 - val_loss: 747.6298\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 227.0924 - val_loss: 746.4273\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 221.4486 - val_loss: 745.2903\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 215.9222 - val_loss: 744.2177\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 210.5117 - val_loss: 743.2081\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 205.2155 - val_loss: 742.2604\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 200.0321 - val_loss: 741.3733\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 194.9598 - val_loss: 740.5457\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 189.9972 - val_loss: 739.7766\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 185.1432 - val_loss: 739.0645\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 180.3958 - val_loss: 738.4083\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 175.7534 - val_loss: 737.8071\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 171.2148 - val_loss: 737.2594\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 166.7785 - val_loss: 736.7643\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 162.4429 - val_loss: 736.3205\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 158.2061 - val_loss: 735.9269\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 154.0672 - val_loss: 735.5823\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 150.0246 - val_loss: 735.2858\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 146.0769 - val_loss: 735.0360\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 142.2225 - val_loss: 734.8318\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 138.4597 - val_loss: 734.6723\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 134.7874 - val_loss: 734.5561\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 131.2039 - val_loss: 734.4824\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 127.7080 - val_loss: 734.4499\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 124.2981 - val_loss: 734.4576\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 120.9727 - val_loss: 734.5043\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 117.7308 - val_loss: 734.5891\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 114.5706 - val_loss: 734.7109\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 111.4909 - val_loss: 734.8683\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 108.4902 - val_loss: 735.0609\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 105.5672 - val_loss: 735.2872\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 102.7204 - val_loss: 735.5462\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 99.9487 - val_loss: 735.8371\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 97.2505 - val_loss: 736.1586\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 94.6244 - val_loss: 736.5097\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 92.0692 - val_loss: 736.8896\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 89.5835 - val_loss: 737.2974\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 87.1664 - val_loss: 737.7318\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 84.8161 - val_loss: 738.1919\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 82.5313 - val_loss: 738.6769\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 80.3110 - val_loss: 739.1856\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 78.1537 - val_loss: 739.7174\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 76.0582 - val_loss: 740.2713\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 74.0233 - val_loss: 740.8460\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 72.0476 - val_loss: 741.4410\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 70.1302 - val_loss: 742.0554\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 68.2696 - val_loss: 742.6878\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 66.4647 - val_loss: 743.3379\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 64.7142 - val_loss: 744.0047\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 63.0170 - val_loss: 744.6871\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 61.3719 - val_loss: 745.3846\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 59.7777 - val_loss: 746.0961\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 58.2335 - val_loss: 746.8209\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 56.7378 - val_loss: 747.5582\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 55.2897 - val_loss: 748.3070\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 53.8880 - val_loss: 749.0670\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 52.5316 - val_loss: 749.8371\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 51.2194 - val_loss: 750.6164\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 49.9506 - val_loss: 751.4044\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 48.7238 - val_loss: 752.2004\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 47.5380 - val_loss: 753.0037\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 46.3923 - val_loss: 753.8134\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 45.2856 - val_loss: 754.6288\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 44.2171 - val_loss: 755.4494\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 43.1856 - val_loss: 756.2744\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 42.1902 - val_loss: 757.1033\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 41.2299 - val_loss: 757.9355\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 40.3038 - val_loss: 758.7701\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 39.4109 - val_loss: 759.6068\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 38.5503 - val_loss: 760.4448\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 37.7212 - val_loss: 761.2835\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 36.9227 - val_loss: 762.1228\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 36.1537 - val_loss: 762.9617\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 35.4136 - val_loss: 763.7997\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 34.7015 - val_loss: 764.6364\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 34.0166 - val_loss: 765.4712\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 33.3580 - val_loss: 766.3037\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 32.7250 - val_loss: 767.1336\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 32.1166 - val_loss: 767.9598\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 31.5325 - val_loss: 768.7827\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 30.9714 - val_loss: 769.6012\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 30.4330 - val_loss: 770.4151\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 29.9164 - val_loss: 771.2242\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 29.4209 - val_loss: 772.0281\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 28.9456 - val_loss: 772.8262\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 28.4902 - val_loss: 773.6183\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 28.0538 - val_loss: 774.4041\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 27.6359 - val_loss: 775.1830\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 27.2357 - val_loss: 775.9550\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 26.8528 - val_loss: 776.7194\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 26.4864 - val_loss: 777.4764\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 26.1361 - val_loss: 778.2255\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 25.8011 - val_loss: 778.9667\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 25.4810 - val_loss: 779.6991\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 25.1752 - val_loss: 780.4232\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 24.8832 - val_loss: 781.1385\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 24.6045 - val_loss: 781.8446\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 24.3385 - val_loss: 782.5414\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 24.0849 - val_loss: 783.2291\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 23.8431 - val_loss: 783.9070\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 23.6126 - val_loss: 784.5753\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 23.3930 - val_loss: 785.2339\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 23.1839 - val_loss: 785.8821\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.9849 - val_loss: 786.5208\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.7954 - val_loss: 787.1489\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.6153 - val_loss: 787.7668\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.4439 - val_loss: 788.3741\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 22.2812 - val_loss: 788.9714\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 22.1265 - val_loss: 789.5579\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.9796 - val_loss: 790.1341\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.8401 - val_loss: 790.6998\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.7077 - val_loss: 791.2545\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.5822 - val_loss: 791.7990\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.4632 - val_loss: 792.3326\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.3503 - val_loss: 792.8556\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.2434 - val_loss: 793.3682\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.1422 - val_loss: 793.8702\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.0463 - val_loss: 794.3616\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.9555 - val_loss: 794.8427\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.8697 - val_loss: 795.3129\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.7885 - val_loss: 795.7728\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 20.7118 - val_loss: 796.2224\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.6393 - val_loss: 796.6616\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.5708 - val_loss: 797.0908\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.5061 - val_loss: 797.5096\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.4450 - val_loss: 797.9184\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.3874 - val_loss: 798.3173\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.3331 - val_loss: 798.7063\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 20.2818 - val_loss: 799.0853\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 20.2335 - val_loss: 799.4549\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.1880 - val_loss: 799.8150\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 20.1451 - val_loss: 800.1653\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.1048 - val_loss: 800.5064\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.0668 - val_loss: 800.8382\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.0311 - val_loss: 801.1613\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.9974 - val_loss: 801.4751\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.9658 - val_loss: 801.7802\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.9360 - val_loss: 802.0764\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.9081 - val_loss: 802.3641\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.8819 - val_loss: 802.6436\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.8572 - val_loss: 802.9146\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.8341 - val_loss: 803.1777\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.8124 - val_loss: 803.4330\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.7920 - val_loss: 803.6800\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.7729 - val_loss: 803.9196\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.7549 - val_loss: 804.1517\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.7381 - val_loss: 804.3762\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 19.7224 - val_loss: 804.5938\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.7076 - val_loss: 804.8041\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.6937 - val_loss: 805.0076\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 19.6807 - val_loss: 805.2043\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.6686 - val_loss: 805.3945\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 19.6572 - val_loss: 805.5784\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.6465 - val_loss: 805.7557\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.6366 - val_loss: 805.9268\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.6272 - val_loss: 806.0921\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.6185 - val_loss: 806.2515\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.6104 - val_loss: 806.4048\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.6027 - val_loss: 806.5529\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5956 - val_loss: 806.6955\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5889 - val_loss: 806.8328\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5827 - val_loss: 806.9651\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5769 - val_loss: 807.0923\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5715 - val_loss: 807.2147\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5664 - val_loss: 807.3326\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5617 - val_loss: 807.4458\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5572 - val_loss: 807.5546\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5531 - val_loss: 807.6589\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5492 - val_loss: 807.7590\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 19.5457 - val_loss: 807.8554\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5423 - val_loss: 807.9478\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 19.5392 - val_loss: 808.0364\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 19.5363 - val_loss: 808.1210\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 19.5336 - val_loss: 808.2022\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5311 - val_loss: 808.2803\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5287 - val_loss: 808.3549\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5266 - val_loss: 808.4262\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5245 - val_loss: 808.4944\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5226 - val_loss: 808.5598\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5208 - val_loss: 808.6221\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5193 - val_loss: 808.6818\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5177 - val_loss: 808.7387\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5164 - val_loss: 808.7931\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5151 - val_loss: 808.8451\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5139 - val_loss: 808.8945\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5128 - val_loss: 808.9417\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5118 - val_loss: 808.9865\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5109 - val_loss: 809.0294\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5101 - val_loss: 809.0704\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5093 - val_loss: 809.1094\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5086 - val_loss: 809.1465\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 19.5079 - val_loss: 809.1816\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 19.5074 - val_loss: 809.2151\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5068 - val_loss: 809.2469\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5063 - val_loss: 809.2770\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5059 - val_loss: 809.3057\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5055 - val_loss: 809.3331\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5052 - val_loss: 809.3588\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5049 - val_loss: 809.3832\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5046 - val_loss: 809.4062\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5044 - val_loss: 809.4283\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5042 - val_loss: 809.4490\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5041 - val_loss: 809.4685\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5039 - val_loss: 809.4871\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5038 - val_loss: 809.5046\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5038 - val_loss: 809.5212\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5038 - val_loss: 809.5371\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5037 - val_loss: 809.5516\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5037 - val_loss: 809.5656\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5037 - val_loss: 809.5786\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5038 - val_loss: 809.5909\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5039 - val_loss: 809.6024\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 19.5039 - val_loss: 809.6133\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5040 - val_loss: 809.6235\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5041 - val_loss: 809.6332\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5043 - val_loss: 809.6422\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5044 - val_loss: 809.6506\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5046 - val_loss: 809.6585\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5048 - val_loss: 809.6662\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5049 - val_loss: 809.6732\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5051 - val_loss: 809.6796\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5053 - val_loss: 809.6854\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5055 - val_loss: 809.6911\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5058 - val_loss: 809.6965\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5060 - val_loss: 809.7014\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5062 - val_loss: 809.7061\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5065 - val_loss: 809.7106\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5067 - val_loss: 809.7145\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5069 - val_loss: 809.7181\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5072 - val_loss: 809.7215\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5074 - val_loss: 809.7247\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 19.5077 - val_loss: 809.7275\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 19.5080 - val_loss: 809.7302\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5082 - val_loss: 809.7325\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5085 - val_loss: 809.7347\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5088 - val_loss: 809.7365\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5091 - val_loss: 809.7383\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5094 - val_loss: 809.7400\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5097 - val_loss: 809.7415\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5100 - val_loss: 809.7429\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5103 - val_loss: 809.7440\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5106 - val_loss: 809.7453\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5109 - val_loss: 809.7462\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5112 - val_loss: 809.7471\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5115 - val_loss: 809.7475\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5118 - val_loss: 809.7483\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5121 - val_loss: 809.7490\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5124 - val_loss: 809.7498\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5127 - val_loss: 809.7502\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5130 - val_loss: 809.7505\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 19.5133 - val_loss: 809.7507\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 19.5136 - val_loss: 809.7509\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5139 - val_loss: 809.7510\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5142 - val_loss: 809.7510\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5145 - val_loss: 809.7510\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5148 - val_loss: 809.7509\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5151 - val_loss: 809.7509\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5154 - val_loss: 809.7506\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5157 - val_loss: 809.7505\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5160 - val_loss: 809.7502\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5163 - val_loss: 809.7499\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5166 - val_loss: 809.7495\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5169 - val_loss: 809.7491\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5172 - val_loss: 809.7488\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5175 - val_loss: 809.7484\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5178 - val_loss: 809.7480\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5181 - val_loss: 809.7475\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5184 - val_loss: 809.7473\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 19.5187 - val_loss: 809.7468\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 19.5189 - val_loss: 809.7464\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 19.5192 - val_loss: 809.7458\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5195 - val_loss: 809.7455\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5198 - val_loss: 809.7449\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5201 - val_loss: 809.7443\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5203 - val_loss: 809.7440\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5206 - val_loss: 809.7432\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5209 - val_loss: 809.7426\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5211 - val_loss: 809.7421\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5214 - val_loss: 809.7414\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5217 - val_loss: 809.7409\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5219 - val_loss: 809.7405\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5222 - val_loss: 809.7401\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5225 - val_loss: 809.7397\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5227 - val_loss: 809.7390\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5230 - val_loss: 809.7386\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 19.5232 - val_loss: 809.7379\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5235 - val_loss: 809.7371\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 19.5237 - val_loss: 809.7368\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5240 - val_loss: 809.7361\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5242 - val_loss: 809.7354\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5244 - val_loss: 809.7349\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5247 - val_loss: 809.7343\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5249 - val_loss: 809.7339\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5251 - val_loss: 809.7333\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5254 - val_loss: 809.7330\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5256 - val_loss: 809.7326\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5258 - val_loss: 809.7321\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5260 - val_loss: 809.7316\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5262 - val_loss: 809.7308\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5265 - val_loss: 809.7302\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5267 - val_loss: 809.7300\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 19.5269 - val_loss: 809.7292\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 19.5271 - val_loss: 809.7288\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5273 - val_loss: 809.7283\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 19.5275 - val_loss: 809.7278\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5278 - val_loss: 809.7274\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5280 - val_loss: 809.7267\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5282 - val_loss: 809.7264\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5283 - val_loss: 809.7258\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5286 - val_loss: 809.7253\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5288 - val_loss: 809.7248\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5290 - val_loss: 809.7246\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5291 - val_loss: 809.7239\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5293 - val_loss: 809.7233\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5295 - val_loss: 809.7230\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5297 - val_loss: 809.7226\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5299 - val_loss: 809.7220\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5300 - val_loss: 809.7213\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 19.5303 - val_loss: 809.7212\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5304 - val_loss: 809.7207\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5306 - val_loss: 809.7203\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5308 - val_loss: 809.7200\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 19.5310 - val_loss: 809.7197\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5311 - val_loss: 809.7195\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 19.5313 - val_loss: 809.7190\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5314 - val_loss: 809.7186\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5316 - val_loss: 809.7183\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.5317 - val_loss: 809.7179\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 486ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.52712418e+01, 6.51031746e+01, 6.49351074e+01, 6.47670401e+01,\n",
       "        6.45989729e+01, 6.44309057e+01, 6.42628385e+01, 4.79061900e-03,\n",
       "        1.77230373e-01, 0.00000000e+00, 0.00000000e+00, 3.30429226e-01,\n",
       "        1.82196870e-01, 6.64105976e+01, 6.63265640e+01, 6.62425303e+01,\n",
       "        6.61584967e+01, 6.60744631e+01, 6.59808590e+01, 6.58127918e+01,\n",
       "        6.56447246e+01, 6.54766573e+01, 6.53085901e+01, 6.51405229e+01,\n",
       "        6.49724557e+01, 6.48043884e+01, 6.46363212e+01, 6.44682540e+01,\n",
       "        6.43001867e+01, 6.41321195e+01, 6.39874183e+01, 6.39285948e+01,\n",
       "        6.38697712e+01, 6.38109477e+01, 6.37521242e+01, 6.36933006e+01,\n",
       "        6.36344771e+01, 6.35756536e+01, 6.35168301e+01, 6.34580065e+01,\n",
       "        0.00000000e+00, 1.33905920e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.71156840e-01, 0.00000000e+00, 6.48417367e+01,\n",
       "        6.46736695e+01, 6.45056022e+01, 6.43375350e+01, 6.41694678e+01,\n",
       "        6.40014006e+01, 6.39416667e+01, 6.38828431e+01, 6.38240196e+01,\n",
       "        6.37651961e+01, 6.37063725e+01, 6.36475490e+01, 6.35887255e+01,\n",
       "        6.35299020e+01, 6.34710784e+01, 6.34122549e+01, 6.33534314e+01,\n",
       "        6.32930672e+01, 6.32174370e+01, 6.31418067e+01, 6.30661765e+01,\n",
       "        6.29905462e+01, 6.29149160e+01, 6.28392857e+01, 6.27636555e+01,\n",
       "        6.26880252e+01, 6.99994965e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.17231407e+01, 1.04628420e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.00411081e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.13724285e-01, 0.00000000e+00,\n",
       "        2.23849684e-01, 3.74281198e-01, 5.50720692e-02, 0.00000000e+00,\n",
       "        4.39172894e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60.1653268 , 60.16103175, 60.15673669, 60.15244164, 60.14814659,\n",
       "       60.14385154, 60.13955649, 60.13526144, 60.13096639, 60.12667134,\n",
       "       60.12237628, 60.11808123, 60.11378618, 60.10949113, 60.10519608,\n",
       "       60.10090103, 60.09660598, 60.09231092, 60.08801587, 60.08372082,\n",
       "       60.07942577, 60.07513072, 60.07083567, 60.06654062, 60.06224556,\n",
       "       60.05795051, 60.05365546, 60.04936041, 60.04506536, 60.04077031,\n",
       "       60.03647526, 60.03218021, 60.02788515, 60.0235901 , 60.01929505,\n",
       "       60.015     , 60.01070495, 60.0064099 , 60.00211485, 59.99781979,\n",
       "       59.99352474, 59.98922969, 59.98493464, 59.98063959, 59.97634454,\n",
       "       59.97204949, 59.96775444, 59.96345938, 59.95916433, 59.95486928,\n",
       "       59.95057423, 59.94627918, 59.94198413, 59.93768908, 59.93339402,\n",
       "       59.92909897, 59.92480392, 59.92050887, 59.91621382, 59.91191877,\n",
       "       59.90762372, 59.90332866, 59.89768908, 59.8874183 , 59.87714753,\n",
       "       59.86687675, 59.85660598, 59.8463352 , 59.83606443, 59.82579365,\n",
       "       59.81552288, 59.8052521 , 59.79498133, 59.78471055, 59.77443978,\n",
       "       59.764169  , 59.75389823, 59.74362745, 59.73335668, 59.7230859 ,\n",
       "       59.71281513, 59.70254435, 59.69227358, 59.6820028 , 59.67173203,\n",
       "       59.66146125, 59.65119048, 59.6409197 , 59.63064893, 59.62037815,\n",
       "       59.61010738, 59.5998366 , 59.58956583, 59.57929505, 59.56902428,\n",
       "       59.5587535 , 59.54848273, 59.53821195, 59.52794118, 59.5176704 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.95942741730657\n",
      "25.417761006852917\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
