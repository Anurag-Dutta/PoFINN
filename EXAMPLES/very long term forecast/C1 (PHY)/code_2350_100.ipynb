{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2445    52.672228\n",
       "2446    52.663483\n",
       "2447    52.654738\n",
       "2448    52.645993\n",
       "2449    52.637248\n",
       "Name: C1, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_2350_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2345     0.247131\n",
       "2346     0.199062\n",
       "2347     0.000000\n",
       "2348     0.381435\n",
       "2349     0.125272\n",
       "Name: C1, Length: 2350, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2350)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtV0lEQVR4nO3deXxU9b3/8dc3C4QQlgSSAGGXRRAFIQJWQCtu1VaoWvXWurRYe/tT22qX2/XRRW9ve22v9bbWurbU3esC7iC4VwHDvhN2kkASliQQEsjy/f0xk2FmMss5Z86ZOWfyefZBM8tZvnNM3uc73/P9nq/SWiOEEMJ7MlJdACGEENZIgAshhEdJgAshhEdJgAshhEdJgAshhEdlJXNn/fv318OHD0/mLoUQwvNWrlx5UGtdGP56UgN8+PDhlJWVJXOXQgjheUqpPZFelyYUIYTwKAlwIYTwKAlwIYTwKAlwIYTwKAlwIYTwKAlwIYTwKAlwIYTwKE8E+MI1lTy1LGI3SCGE6LI8EeBvbzjAQ+/vSHUxhBDCVTwR4OcML6CyromquqZUF0UIIVzDMwEOULbnSIpLIoQQ7uGJAB83sBc9u2Xy2a7DqS6KEEK4hicCPCszg8nD8vlstwS4EEJ08ESAg68ZZWv1UbYeOJrqogghhCt4JsCvP2cIhXndmTf/Mw4dO5Hq4gghRMp5JsCLeufw6E2l1B49wb8/tZITrW2pLpIQQqSUZwIcYOKQvtz3lYl8tvsIX/rzxyzbeSjVRRJCiJTxVIADXDlxEI/dVMrxk21c/8gyvvPsaqobmlNdLCGESDrPBTjAReOLWXL3+Xxn9mje3niAC//wPo98uIOWtvZUF00IIZLGkwEOkJOdyd0Xj+Gdu2YxfWQ/fvvmFub85V/srD2W6qIJIURSeDbAOwzr15PHbzmHh2+cwv76Jr70549ZuKYy1cUSQgjHeT7AO1x6xgDe/O5Mxg/qzXefW8N/vLiOppPSU0UIkb7SJsABBvbpwbPfnM4dnx/FCyv3cf2jyzh+sjXVxRJCCEekVYCDb9j9Dy4dy0M3TGZ9RR23P72KVrm4KYRIQ2kX4B0umzCQe+ZO4L2ttfx8wQa01qkukhBC2MpQgCul7lJKbVRKbVBKPauUylFKjVBKLVdKbVdKPa+U6uZ0Yc26Ydow7rxwFM99to8HlpanujhCCGGruAGulCoBvgOUaq0nAJnA9cDvgfu11qOAI8A8Jwtq1d0Xj+GaKYP505Jynv9sb6qLI4QQtjHahJIF9FBKZQG5wH7gQuBF//vzgbm2l84GSin+66ozmTWmkJ++soHbn1nFO5uqOdkq7eJCCG/LireA1rpSKfUHYC/QBCwGVgJ1WuuOLh4VQIljpUxQdmYGD90wmfsWbeXVtVW8sW4/fXOzufzMgcydVELpsHwyMlSqiymEEKaoeBf3lFL5wEvAdUAd8H/4at6/8jefoJQaArzlb2IJX/824DaAoUOHTtmzJ7Wzy7e0tfNReS0L11SxeGM1TS1tlPTtwZWTBjF3UgljB/RKafmEECKcUmql1rq00+sGAvwrwGVa63n+5zcB5wJfAQZorVuVUufiC/RLY22rtLRUl5WVWf0Mtms80co7m6pZsKaSj8oP0tauOX1AL+aeXcKVEwcxqG+PVBdRCCESCvBpwBPAOfiaUP4BlAGzgJe01s8ppf4GrNNa/zXWttwW4MEOHjvBG+v2s2BNJav31gEwdUQBcyeVcPmZA+ib67pONkKILsJygPtX/jW+JpRWYDVwK7427+eAAv9rX9Nax5wqx80BHmzPoUYWrqliwZpKdtY2kp2puGBsEXMnlTB7XBE52ZmpLqIQogtJKMDt4pUA76C1ZmNVAwtWV/Lq2ipqjp4gr3sWl00YwNxJJZx7Wj8y5eKnEMJhEuAJamvXLNt5iAWrK3l7wwGOnmilsFd3vnTWIOaePYgzS/qglIS5EMJ+EuA2am5p490tNSxYXcn7W2s52dbOyMKezJlYwtyzBzGsX89UF1EIkUYkwB1Sf7yFtzb4Ln4u33UYrWHSkL5cckYxs08vZkxxntTMhRAJkQBPgqq6Jl5bW8Vr66rYUNkAQEnfHlx4ehEXnl7Euaf1kwugQgjTJMCTrLqhmfe21LB0Sw0flx+kqaWNnOwMZozqz+f9gT6wj/QzF0LEJwGeQs0tbSzfdZh3N1ezdEsNFUeaABg3sDezTy/iunOGMKQgN8WlFEK4lQS4S2it2V5zjKVbanh3Sw0r9xwhQ/lufXvHhaPon9c91UUUQriMBLhLHahv5oGl5bxQto+crAxunTmSb84aSV73uPcZE0J0ERLgLrej9hh/XLyVN9cfoF/Pbtxx4Si+Om0o3bPkoqcQXV20AE/bKdW85rTCPP56wxQW3n4eYwf04tevbWL2Hz/g5VUVtLXLdHBCiM4kwF1m4pC+PH3rNJ6cN5W+udnc/cJarvjfj1i6uVrm9RRChJAAdyGlFDNHF/Lq7TP487+dTXNLG/Pml3Htw5+ycs/hVBdPCOESEuAulpGh+NLEQbxz9/ncM3cCuw8d5+qHPuXW+WVsqz6a6uIJIVJMLmJ6yPGTrfz9X7v52/s7aDzZSunwAs4fU8j5YwoZP7C3TAsnRJqSXihp5EjjSf7+yW6Wbq5mY5VvyH7/vG7MHF3IrDH9mTm6UPqTC5FGJMDTVO3RE3xUXsuH22r5sPwghxtPAjChpDezRvtq55OH5ZOdKa1lbnaytZ29hxsZVeSuOVmbW9qorGvitMK8VBfFEfVNLRxtbmFwvrtHQkuAdwHt7b4JKD4sr+WDrbWs2nuE1nZNXvcszj2tX6C5RYbtu89PXl7Psyv2suKnsynqnWNonRdXVvCzV9az4deXOnaCvvPZ1by2tor1v7qEXjnZhtZ5ctkefv/WFtb/6hLX34lz2m+XUN1wgt2/u8LwOr9cuIF1lfW88v/Oc7BkoaIFuAz3SyMZGYozB/fhzMF9uP3zozja3MInOw7xwTZfDf2dTdUAjOjfk/PHFDJ7XBHTRvSjW5bUzlNt+c5DABw90UqRwXXueX0TJ1rbaTzR6ticrf/afhDwfUMw6hcLNjhSFidUN8ScBTKi+Z/ucaAk1kiAp7FeOdlcesYALj1jAFprdh1sDIT5c5/t5R+f7KZXThafH1vExeOLuWBsoeFalrBXu/+bcIaJGmvHOk7Wcq2USySPBHgXoZRiZGEeIwvz+Pp5I2huaePj8oMs3nSApZtreHVtFdmZinNP68/F44u5eFwxA/oY+yovEtcx2NZMRyJtYR2zOkYBS4C7kwR4F5WTnclF44u5aHwxbe2a1XuPsHhTNYs3HuAXCzbwiwUbmDi4DxePL+aSMwYwukhmFnKSlaBMRu04cJKQVjZXkgAXZGYoSocXUDq8gJ984XS21xzzhfmmav6weBt/WLyNoQW5jCnOY1DfHgzq24OSoJ9FvbpLH/Qg7e2aqvomUz0bdKA5xMR+TK7T3NJGQ3MLRb2Mf7NKpJlGa3OfJ559h4/LBfgwEuAihFKK0cW9GF3ci9s/P4rqhmaWbK7mg6217D18nBW7DtPQ3BqyTnamYkCfHAb16UFJfmi4+wI/h9xu3v9Ve+yjnSzbeZirJpcwe1xR1DtF/u+75fxpSTkf/PACwxNcd/QFM1ObNtKB7L5FWxhT3Is5k0q45e8rWLbzcEiPi4PHTnDnM6v50WVjOXtofqf125PQS+3JZXsoHZbPuIG9I75/srWdO59dxaKN1fz08tOpaTjBTy4fR2aUSsO/th9Ea5gxun/CZas4cpy3Nxzg1pkjoy7TeML399CzexZr9tXRLTOD8YMifxa7ef+vSjiquHcON0wbxg3ThgVeO9rcQlVdM1V1TVTUNVHl/1d5pIllOw5xoKGZ8Bso9s/rzpjiPMYU92K0/+eYol70yfXORdPFm6pZseswSzZXU9CzG/NmjODmzw3vdO/2D7fVAr4++kYD3EpziJFsffC9HQAM7NODZTs730dnR80xPt15iC//9RNW/vwi+oUNAEvGjTA7eq1E68r30qoKFm309aD67ZtbADh/bCEzRxdGXP6Gx5bH3J4Z//7USjZUNvCFMwdS0jfyFIhn/HIRWRmK7b+9nLkP/guA3111JtdPHZrw/uORABem9crJZuyAbMYOiDzopKWtneqGZqrqmqmsO05VXTO7DjZSXn2UF8r2cfxkW2DZol7dA6E+1l/zH12cR28X9oZpb9dMH1nAty8YxRMf7+K+RVt59KOd3OoP8o4ePB3t2VmZGfz0lfWsr6jnO7NHc9G4oqhNEW3+Xnpm2pqN1I4zMxRt7Zofvbg28n6DtnHvG5u5/7pJ3Pv6JnKyM/nBpWMj3gFze80x5vzlYx762hRmjYkcolZorSMen0iTm9z4+Aoe/OpkrjhrYOC1xhOt5HY79a3ojmdW8YevTGRjVT3/+GQPD1w3KWpT39sbDpDbLbPT52lp9X3+o80tQPQ5bFvDznQ/fnk9V5w10PFeXRLgwnbZmRkMzs/1twEXhLzX3q6prGuivOYo26qPsa36KOXVx3huxT6aWk4Fe0nfHlwwtpBLzhjAuSPd0Ve9TWt6ZGYGBkSt2VfHn5eW84fF23j84108fss5TB6aT0ubP8AzFBsr61lfWc83/1nGzNH9eehrUyIGUqANHPMXMWPpkZ3JkIJcNu9viLwN/4nj3JH9eGV1JVdPHsxjH+8C4IsTBwZq4MFBvudQI40n27jpiRXs+q/LE7q4Hbzd/fXNDIpQyw0epFTYqzu1R319t29/ZhVXnOWrZdc3tTDx14v53kWjA8u+vm4/k4b05alle9h96Dh3XTSakVFGlP77UyuBzrX2vBzff6tjYc2GRny2+zAXnl5sej0zJMBFUmVkKIYU5DKkIDfkl7u9XVNx5FSwr91XxyurK3l6+V7yumcFwvyCsYUpq523t+uQdtdJQ/ry+C3nsL6injueXcWNjy3n8VvOodWfilmZvmVnjPJ1zfzN65v46qPL+MfXp1LQM3TgjZWWilPhGn2Z1vZ2Zo7uz+D8HoGBXME6auDfmT2a7bXH+Oenuynu3Z3qhhM8t2Jfp5PEe1trOHjs1OCXVXvrmDKsc9s5GPtMwRXX3YcaIwZ48IQm0a6Vn/Cf/J/4eBclfXtQWeebOHznwUZG9O/J7kPHKa85FjXAA2UO+xbQ03+yPXrCfIC3tjnf/iQBLlwhI0MxtF8uQ/vlMnucL9ibW9r4ZMdBFm+sZsnmal5ftz/QV/2S8cVcPL6YYoPDzu3Q2q7JjFDbPHNwH1741rnc8Nhybn5iBSf8oxaz/O0hWZmKmz83nJK+Pbj9mVVc+/CnPDlvKgP7nAqr4KD8y7vlZGVm8K1ZIxPuutne7mtXnzupJBDg5dVHGV3sa/5q859senTL5ItnDeTpZXvpl+c7uby6tqrTyeHrf/8s5PlLqyqYMiyf97fWUNw7J+qFyP31Tfz2zS3cM+eMkFGjweFcVdcccd3gZp62KANCO45TQ3NryElg3+HjfFTuG036l3e3M2VYfswbvVUcaWJIQS5HGk+y+1Aj3fwnYTMjUU+V1fkAT/33UiGiyMnO5MLTi/nd1Wex/KcX8dK3z+Ub541g3+Hj/HzBBqb9dilzHvwXD763ne01Rx2fsaitXUdtQy3uncPzt00PuelTVtiyF40vZv43pnKgvplrHvqUXQcbQ7bdYeGaKn731hZ+sXBDwiHQpjWZGTB73KkB+hff/2HQfn0/M5XiyomDONnWzv76ZrpnZQRujBbN0IJcXl9bRXNLG7f8/TO+8MBHUZddsqma19ZW8ZvXN4WWLyTAmyKu2x60TPewprTjJzvXjLccOHWv/L2Hjwcer6+s56uPLotaRoCZ//0euw42ctuTZXz5r5/Q3BI9uC+5/wO++c/o93ZqkQAXwiczQzFlWAE/uXwc737/fJbcPYsfXjoWgPsWbeWi//mQ2X/8gF8s2MAjH+7g9XVVrNp7hJqG5pAASES71p1COVi/vO48+83pIWUO3/P0kf147rbpNLW08ZW/fcKLKytoaG7pVNPt2S2Tp5bt5VtPrmTlnsOWTk5aa9r83xpysiN3eQwMIMrwNQl11E5njSmkX8/Y91e5evJgGppbWRzUNLOhsr7TcgePnaCgp2+7L6+qDAnt4Np1tBNG8AXC4t6hteeKI5FDv0NwgANsqz4WeBx8Ag22bOch9hw6HnH98G1Fapbq0Brt64KNpAlFeI5SilFFvRhV5OurfqC+mXc2+0aRLlhd2am9MjtTMbBPcP/0HN/PfH8/9T496NEtcsAFi1UD79AnN5v//PIEfvZK9Bs6TSjxNbnc9s8yfvB/a+n2cgYn/X/s2h/5548tZPLQfO5btJUlm6sZWpDLnEmDmDOphFFFoe24Grjr+TXsOdTIl88u4YtnDSK/Z7dA+3KmvynnW7NG8vCHO0PW7Wi6ycrIQClFz+6ZHDzmO2ZfnTaUP7+7PbCPcOeN6sfCNT1Dbl51xzOrTpVLa7SG0nuXhKz3y1c3cM+cCfzoxXUU5EU/SazZV8cdz6xiZlB/7vBvJOsr6hlT3Ctw3MLFOu9F+0+5rqKOGv+F0o4AP1DfTHVDM0W9oje/rKuoC3keq/ZuFwlw4XkD+uRw4/Rh3Djd11e9obklpG96pb/PelVdE5/sOEh1hH7qBT27+QM+hyH5uQzr35MR/XoyvH8ug/r0ICND0a6J2AYermOAT0d4RFpjVFEeS79/Pqv31fHmuv2Bnh/Bbp05kuunDmXRhgMsWFPJg+9t58/vbmdCSW+umTw4ZNkVuw5Tc7SZVXvr+M3rm/j82CKunzoEgGh3mt1Ze4x9/oCKtMz3LhoTCPBIMjIU878xlUv8TTIj+vfkQH3kduwO548p5Klle8nP7cb/rayIutwDS8o5cvwkFUeaeHbFvsDr+8O2v732WPiqcXWM6IzW4+etDQc6vfbLVzfyy1c38todM6Ju967n15guS6IkwEXa6Z2TTe8B2Zw+IPIFtY5+6pVHmqiqb6KqrpmKI76A31HbyPtbawMXIgG6ZWUwrCCXqromJg3pG3f/Ri87KqWYPDSfyUPzGdYvl18s3AiE1nbzumdx9ZTBXD1lMDVHm3lt7X4WrK7kV69t6rS9KyeWMG/GCF5eVcGCNZWBpo3At4awgt30xIpAE0SkAUSZGYqfXzGOe9/YHPUzDCnIJS8ni6aWNs4e2pcrJw7ilrALncH+47LTGdA7J+aJ4fjJVu5fsi3iex0140S8u6WGG6ZFH2RTd7wl6nvZWdH/6+6ojdwk4yQJcNHlhPZT76y9XVN91Df4aPfB4+w51Miug41kZiimjyyIuE40RpuujfQ2KeqVw7wZI5g3YwRr9tUFRv0FGz+oN+MHjeeHl43ljXX7eW1tFdNH9ou4veMn2xjeL5cR/XtG7L5nlkJxwdgiTivsGTXMMjLgnrkTWLi2kuaWdq6cOIjMDMUrqysD7fzhx+zeuRO4b9FW6puiB6sZv3x1I/e+sYkld59vy/ZSSQJciDAZGb4284F9evC501JThngDeiYN6cvPLh/Hf74ZuXbcPSuTqyYP5qqwppZwM0cXcs/cCUH7Nbb/4GXDzZ1Uwh/f8dWgI53AumVl+LtYttO7Rxb3zj2T97bWxChjf0YX5XHdI74eJD2yM0MGffl2FLe4IVqS0Ec7Wru8naQXihAOM9WX28LffDKmRbSyi2RM1pjEGSFTsr94DAW4UqqvUupFpdQWpdRmpdS5SqkCpdQ7Sqly/8/Iw7GE6KLM1MCCM95oICd6q1Yj+zFy8glfwky5ItX0w0ulUFHLsevgMdZXdO666Ab3v1POgtWVju7DaA38AeBtrfXpwERgM/BjYKnWejSw1P9ciC4vVfNexNuvmfusOLH/eGUweroL3s+ijdV86S8fG1wzbH8O16YPHjvB9xzumRI3wJVSfYBZwOMAWuuTWus6YA4w37/YfGCuM0UUwruS0Q6aiJSdbOI8N8vdR9k5RmrgI4Ba4O9KqdVKqceUUj2BYq31fv8yB4CIt91SSt2mlCpTSpXV1tbaU2oh0lQgiEwmml3t4IGmivD9R9i8keaVdAtWL7aBZwGTgYe01mcDjYQ1l2jfb0/Ej6a1fkRrXaq1Li0stO/ewUK4XayBPLbux8H1Eim7kbCLdA4IPxnJVKzRGQnwCqBCa73c//xFfIFerZQaCOD/Gb0fkBBdiJXACW4bthrI8XabSBD+ftEWw9uNVTO3Wobg9STPT4kb4FrrA8A+pdRY/0uzgU3Aq8DN/tduBhY6UkIhPMxtX7nDGQ3DZ5bvtW1b0RZOepfA5O7OEUYH8twJPK2U6gbsBL6OL/xfUErNA/YA1zpTRCG6HrO1TLvCSIX9NLJsLMa7RCZWr3b7idIphgJca70GKI3w1mxbSyNEGjI1jsfSQB7z6ySDrwdO7A8f6V2XfhzAfb2KZCSmEA4x86ceEvIW759ithJr9SJjp2WS0Cot7d6RSYALYbNkBJoVTpfKWNiH/gxmtHabaHNLYH9u/epiggS4EA6ymhFmQ8q2/ZgZBm9gWcOjK43vNsp+vB/GVkiACyE6sauWa8d+3NQP3G2VdglwIRxy6iu68QTSVuqSgQFDZmvtdo3ejLZ9a9uLtJ6bQtxNJMCFsJm1gTzOr+N0uTpOILH2ExipH2Ehw5NfmChTLC6rTFsiAS6Eg9IhJBJhfEYiZ8uRriTAhXAh8wN5bGoOMbF/N/W2cVvbdLJIgAvhsGTVLk33A7drvzZtJyCsYMm6oOpFEuBCOMRKQGpt/uJi1+hCJ3ezikQCXAgHOTk9mtl1IjV5xJ3Fx8ROTt1KPNY60S90Jvs0lA7NLhLgQriQE8Pije3XfGDHYvzbQYI3s0pobRP7cVnoS4AL4TDXfuOPEUapbLcPD33XHj8XkAAXwiGW7iyI+dpkYOaflE2mnISbWUkTeEQS4ELYzEqgWemSZ8dAnnj7NfNRwpeNNaIy4s2skt484bL2EAskwIVwoVRP6JDQNoI2YmYgz7Mr9jL8x2/YUIKuQwJcCNFJspopIn0DCA99QxdLk1R9d1uXTQlwIRyWvB4lJm9mZXU3KSDt3pFJgAvhGPMRaaUmmUgQO3n98e2N+zvvL7Bf6zu2b0IHWzaTUhLgQtgsZHY0B7tBBweZoenRzO/C5DoqZJ27nl/r0H5EBwlwIVwoVff/iHW712jL2rG/YFZvQZAMbqu1S4AL4bBk3bXPfFu7sxM62MVNdz10GwlwIRxieUYaT11etMZ8H3YV9NieMqTDUZYAF8JmiQSMpdGbCcyaYGfd1tCs9HJrWFtJgAvhIKO16fBYMzShQshCdk3oED5LvYURohYH8niB22rtEuBCpAk7R2+amZEnkfCNPKQ+7GZWHgn3VJAAF8Jhqbo1rJuZv5d55MddnQS4EA5J2j2qE1jXztqtsVq7e6TDiVICXAibBbcjG28DDm97NrKfU+wayGOhGDEZvwbgpmiPLln3XDFKAlyILipmFhnqURJt1cRm9QkvlpGtuSxXk0YCXAiHJasN3OmLfdFqn8muPUtXxFMkwIVwiBdqhckOw1O7M3mXFQeKmQ4DpiTAhbBZ8gfyGLuQ6fiQ90jNIQ70A5f69ykS4EI4yOrNCA01SySYyEZqoFZ2YW4atvgTOhg5FMmqTbutzi4BLkSasLMt2sxMOdIknTqGA1wplamUWq2Uet3/fIRSarlSartS6nmlVDfniimEd7m5i1yqSmZ+II/9JfXCNYp4zNTAvwtsDnr+e+B+rfUo4Agwz86CCeF1ybxI5ob+yRFr7QaWEdYZCnCl1GDgCuAx/3MFXAi86F9kPjDXgfIJ4TmhA2zMBWtH6Jupodo5WCbpvVLCfoK7e4e44DwZwmgN/E/Aj4B2//N+QJ3WutX/vAIoibSiUuo2pVSZUqqstrY2kbIKkbYsXSxMcBuxwijQvh0j9AM3szK3W9OMnHjcFqzJEjfAlVJfBGq01iut7EBr/YjWulRrXVpYWGhlE0J4W4pmyjHEVE0/Jbv1La8iP+7qsgwscx5wpVLqciAH6A08APRVSmX5a+GDgUrniimE93S1WqGxCR2cL4dR6fDfJ24NXGv9E631YK31cOB64F2t9Q3Ae8A1/sVuBhY6VkohPMSWyX7NLGzjQB6789Xotwlzbe+pPAu4K/UT6Qf+H8DdSqnt+NrEH7enSEKkD7N/7mZqhYneOdC20Ld9RgfzZXBXrCaPkSaUAK31+8D7/sc7gan2F0mI9GLlNq6plshMOUYC3W2f16tkJKYQLpPM2mRX7pft5u6KRkmAC+GQZF4ks2tfDreG2CKVtXe3XfiUABfCdsHTsptbs2NxcwN5OtaJvVKnd10QRsZGb4poJMCFcAErTRlONn+cGshzSrRgtVIKu8vuhlsJpIIEuBAOM9tLI6njeMzU9I3e29taUWJv04kJHdIg8yXAhXBIl7uZlYF7e0fvuWJiPybKlO4kwIWwmT0DeeyPqfByRTrBJPsCoZFZfNw0B2bqT5OhJMCFcJD5gTzmIyJZle/wwFcJNILbncluC9ZkkQAXwmFmB/IYvj2sg0P2A3caDC6XA/NbisRIgAuRBrxSA7XaHNKVBxzFIgEuhEMSadpIVS3W9qCMcwwCrTAmvoHIQJ5TJMCFsFkiM/JYYXQWn/Dar22jN+3ZTELbd1uwJosEuBAuYiaH7AhOM936Ooek9RJIg4g9JMCFcJidU50lm7URotbei7lNGcgTkQS4EC5kOrDccDOrSLV2CxMuxwvWVF7QdMOAqWAS4EKkCbPBZrqPepQ1Ehlo47Vp2NxGAlwImwUHmpMz8iSyTodEarOJ1dZtn7zN5u15gwS4EA4zNpDHfOg7WTONNMoyla0HjrSBp0HoS4ALkQbcEEWnRm9Gb8+25WZWqewHnrpdRyQBLoRDEquxWuj9Ybq3S4SbWcVa3tzmDTE2oYM0gkcjAS6EzUIH8qSsGJ04VXN1Q7y66TgnkwS4EK6iTYdRItkVPdQj3dtbx1nCW9Ih9CXAhXCYkR4XiU5L5lT/ZDPlCkzDFmNKUKvNIdKMEpkEuBAulIwLdREjP8aOnZxh3sz9Y1IZ5W6rtUuAC+EQ7f9fssQLNqdqsVZONqbWkcp3VBLgQtgs2d3cEmk+iTqhg0x15gkS4EI4zEzM+ULS/PTvXgkwq5nvzEAe75MAF8IFwgMqGXXbSBX38P2qWFcko6xrpT071uCfTuuksObvttGbEuBCOCTZF7y8NIuPV0Zeup0EuBA2szIRcDJEDMI0SUc3HedkkgAXwmkOT+jgRHhFKnJ484HXo99t9/a2QgJcCBexOqWaU1lkZh+RJ3SIvj0jrxt9P2lclvkS4EK4QHg7srW+1YnHnC19ug2NPI0wbDPqsiIaCXAhHKJxV9tsxCbwpJdC2EkCXAibJTri0Q2Zb6g5xEXpb6V7nxuOc6LiBrhSaohS6j2l1Cal1Eal1Hf9rxcopd5RSpX7f+Y7X1whvMdMoFutsSejf7KVi36dVnHRQJ50YKQG3gp8X2s9HpgO3K6UGg/8GFiqtR4NLPU/F0JY0Hkgj4G24bCVzI34jDJBcZxyGSmPpducxOh62elzyow8AXEDXGu9X2u9yv/4KLAZKAHmAPP9i80H5jpURiE8yQvd1FI2+CehCZHtK4fXmWoDV0oNB84GlgPFWuv9/rcOAMX2Fk0Ij3JpwKRL8EU6L1o5V3rg/BqX4QBXSuUBLwHf01o3BL+nfVWNKLcXVrcppcqUUmW1tbUJFVYIL7JjrsrYy9sfRk7NVdmxjvnypsnZx2aGAlwplY0vvJ/WWr/sf7laKTXQ//5AoCbSulrrR7TWpVrr0sLCQjvKLETa6rgYaST0Oy1iIuOiBWisvuRxB/JEWidOq3HECR0MrpMKbqu1G+mFooDHgc1a6/8JeutV4Gb/45uBhfYXT4iuIVWZFK8WbehEYuEio6mLo52eS228Q5aBZc4DbgTWK6XW+F/7KfA74AWl1DxgD3CtIyUUwqN8A3ncU2VLvH+6Oz6LW8rhBnEDXGv9MdErCLPtLY4Q3pdo/dBKPNkdaRFryJ2691nfvt3nNWvb8/6JQEZiCuEwp7/wu2YUooXQ7/hWEG9Ch+D1UtmE4rbavwS4EC7SEV5GIsrK4J+42+z03JmbTSUyoUO6dIe0gwS4EA4x87XeCwNqjH4cuciYPBLgQtgspDkgheUIl+hJwi3XYyMO5LHSjOSSz5MICXAhHGZ+II+Fndg+kMceVu5lFemjuKVO77bQlwAXwkUCbeAmUv/UOmb2E+VmVglM6JDI5Max1rRjsot0JQEuhCs4O7O71b2GTNDskgYhye9TJMCFcIx23VfuZHC6hhzpkFq6mVXCJUk9CXAhbJbo0G9LEyfYHEeRmnA636c7/nbi3ds7kfIICXAhPK8jI01N6BDl9US6AEaehi3OjakirBt+Auvc3z113FZrlwAXwkXM1KRtGbhjQz/wZFeOpTZ+igS4EA7xwkAeJzh+64CueGEhCglwIWyWaM8NS93ADayUaM21c9NG/O25OWvdXDajJMCFcFiyatfm+oE7sP9I+4mzTKQ+5PEG8qSyCcVttX8JcCFcyI5BOcb2Y/wKYdRZfJJ8WTGNWpsSJgEuhIukW7u522qs6UYCXAiH+GbkMbZsMiaBsHbbV2dGiCaS67YN5EmDk4sEuBA2S/jeHUnIFTsmDjZ0Y6p4Ezoo1en1+BM6pI7bIl8CXAgXsnRjKAcmdAgWfSb70J+G9pPIsh5oOkoWCXAhPM5ttUKRPBLgQjgkDZpY3VnZtem4psF/HglwIewWOpDH6DqJzeJj5IJcwjPyED6QJ8p+gvt0h7eBW57SId4aSYpjl6W+BLgQjkvOvb7tGMgTa3KG6P3AY6xjQ+Ip//867VBIgAvhdYk01XihL3k4DxbZMRLgQriIuYE8EmWJSIdrFBLgQjhEa+Mz8gRHsbUJHcztwygr7fnBO7I2wCY566QDCXAhbBbthk2JbMOpdTpvo/PAmg6d7kZoYMBSp1ztNJCn42fs0rvly4Zb5gXtIAEuRBdmy42oHE7XaKM3hQS4EGnAXbXCYOlwvxE3kwAXwiE66P+Nr2NmSrWg9bpQTtp1UnBbc4gVEuBC2C3BPtyWYyVuO3L0ATZR14kx0UL0gTynxFsn0OYeY51O24+w42RFsdtOlBLgQjgs0d4fTurcvuz/GWHZ+AN5jK9jhtzLKjoJcCGE8CgJcCE8zm1f6z0jDY6bBLgQDtHafLiaWcdsM0toO7uxnYTuw9JttkK3F3P7/jVcPLuO206WEuBC2MzKjDx29HW2Y/BPrMkZOt9ZMGzZwOw6Fi6Wxii8Uip0Rp4Iyx4/2WZsR2kmoQBXSl2mlNqqlNqulPqxXYUSoqs60dpOW7u5at7hxpOAufrxtQ9/amofAB+VHzS9zsX3fxjx9dY2X2mPNrcAcPDYicB7l/4p8jqx3PDYctPrPPzhTtPr3PrPMtPrlO0+bHodoywHuFIqE3gQ+AIwHvg3pdR4uwomhNct2niAQ40nDdVCO5a59uFPOdnWzp5DjYb3c90jywDYVFVveJ0NlQ0AtMUp3P765sDj37y+KeIyDU2+EN5YaXz/lXVNADz43g4AqhtOxFo8xM5a48cmlg+21dqynXiu+dun3P3CGkeaeRKpgU8Ftmutd2qtTwLPAXPsKZYQ3tXxh/qPT3YDsLGqIe464aG0aGN13HX69MgOed43t1vM5SO9/8THu0KedzRFNDS1ArDv8PGo2+uenQnADn/Zl26piVNiyO2WFfL8j1+ZGHcdgKyMU1HVauAbSmGv7oa2mywvr6pk96Hox9KqRAK8BNgX9LzC/1oIpdRtSqkypVRZbW1yznhCpNJZQ/qGPL/r4jFx17lu6pCQ56/fOSPuOqXDCri2dHDg+fcuGh1z+csnDGBiWNnmf2NqyPOvnzcCgLln+/6Uf37FuMB7A/vkBB5fNK4ocAK5dYZvnZe+fS4AnzutH+eN6hey3RumDeWJW0rJzPA1YD96Uyk/vHQsV0/xlf+RG6eELD9tRAFXnV3CnReOIjNDUdy7O9NHFgDw1ndncuuMEVHD/6rJJfz1hsl8+4LTmDq8wF+2z3HbrJFcVzok4joAv7vqTH4z5wz8ReT7F4/h/11wGucMz4+4fGGv7vz3NWfxw0vHBl772vShPDVvGndeOIqsDMWoorzAe/m52ZE2kxBltVqvlLoGuExrfav/+Y3ANK31HdHWKS0t1WVl5tuQhBCiK1NKrdRal4a/nkgNvBIIPp0N9r8mhBAiCRIJ8M+A0UqpEUqpbsD1wKv2FEsIIUQ8WfEXiUxr3aqUugNYBGQCT2itN9pWMiGEEDFZDnAArfWbwJs2lUUIIYQJMhJTCCE8SgJcCCE8SgJcCCE8SgJcCCE8yvJAHks7U6oW2GNx9f6A+bvppBc5BnIMuvrnh655DIZprQvDX0xqgCdCKVUWaSRSVyLHQI5BV//8IMcgmDShCCGER0mACyGER3kpwB9JdQFcQI6BHIOu/vlBjkGAZ9rAhRBChPJSDVwIIUQQCXAhhPAoTwR4V5k8WSm1Wym1Xim1RilV5n+tQCn1jlKq3P8z3/+6Ukr9r/+YrFNKTU5t6a1RSj2hlKpRSm0Ies30Z1ZK3exfvlwpdXMqPotVUY7Br5RSlf7fhTVKqcuD3vuJ/xhsVUpdGvS6J/9OlFJDlFLvKaU2KaU2KqW+63+9S/0eWKK1dvU/fLeq3QGMBLoBa4HxqS6XQ591N9A/7LX/Bn7sf/xj4Pf+x5cDbwEKmA4sT3X5LX7mWcBkYIPVzwwUADv9P/P9j/NT/dkSPAa/An4QYdnx/r+B7sAI/99Gppf/ToCBwGT/417ANv/n7FK/B1b+eaEG3tUnT54DzPc/ng/MDXr9n9pnGdBXKTUwBeVLiNb6Q+Bw2MtmP/OlwDta68Na6yPAO8BljhfeJlGOQTRzgOe01ie01ruA7fj+Rjz7d6K13q+1XuV/fBTYjG9+3S71e2CFFwLc0OTJaUIDi5VSK5VSt/lfK9Za7/c/PgAU+x+n83Ex+5nT9Vjc4W8ieKKj+YA0PwZKqeHA2cBy5PcgLi8EeFcyQ2s9GfgCcLtSalbwm9r3PbFL9fvsip/Z7yHgNGASsB/4Y0pLkwRKqTzgJeB7WuuG4Pe68O9BTF4I8C4zebLWutL/swZ4Bd/X4uqOphH/zxr/4ul8XMx+5rQ7Flrraq11m9a6HXgU3+8CpOkxUEpl4wvvp7XWL/tf7vK/B/F4IcC7xOTJSqmeSqleHY+BS4AN+D5rx9X0m4GF/sevAjf5r8hPB+qDvm56ndnPvAi4RCmV729quMT/mmeFXc/4Mr7fBfAdg+uVUt2VUiOA0cAKPPx3opRSwOPAZq31/wS91eV/D+JK9VVUI//wXXXehu8q+89SXR6HPuNIfD0H1gIbOz4n0A9YCpQDS4AC/+sKeNB/TNYDpan+DBY/97P4mgha8LVZzrPymYFv4Lugtx34eqo/lw3H4En/Z1yHL7AGBi3/M/8x2Ap8Ieh1T/6dADPwNY+sA9b4/13e1X4PrPyTofRCCOFRXmhCEUIIEYEEuBBCeJQEuBBCeJQEuBBCeJQEuBBCeJQEuBBCeJQEuBBCeNT/B8RCNG4VjlRsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 1, 251) (1900, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 3s 24ms/step - loss: 4097.8726 - val_loss: 2153.1353\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3820.8694 - val_loss: 2022.5312\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3686.6731 - val_loss: 1959.2837\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3582.6433 - val_loss: 1907.2992\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3484.1516 - val_loss: 1855.1752\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3389.7964 - val_loss: 1807.2408\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3299.0295 - val_loss: 1761.6898\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3199.3521 - val_loss: 1708.9602\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 3104.7415 - val_loss: 1665.2797\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3017.8052 - val_loss: 1623.8315\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2933.8335 - val_loss: 1584.3453\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2852.4233 - val_loss: 1546.6511\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2773.3425 - val_loss: 1510.6415\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2696.4412 - val_loss: 1476.2373\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2621.6138 - val_loss: 1443.3755\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2548.7766 - val_loss: 1412.0034\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2477.8621 - val_loss: 1382.0739\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2408.8110 - val_loss: 1353.5447\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2341.5723 - val_loss: 1326.3763\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2276.0981 - val_loss: 1300.5321\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2212.3459 - val_loss: 1275.9769\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2150.2754 - val_loss: 1252.6776\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2089.8491 - val_loss: 1230.6014\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2031.0303 - val_loss: 1209.7172\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1973.7856 - val_loss: 1189.9928\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1918.0792 - val_loss: 1171.3727\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1863.8489 - val_loss: 1153.8354\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1810.8176 - val_loss: 1136.7695\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1759.2562 - val_loss: 1120.5706\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1710.0398 - val_loss: 1106.3597\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1660.5956 - val_loss: 1091.1306\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1613.0551 - val_loss: 1078.2721\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1568.4266 - val_loss: 1071.0024\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1516.8689 - val_loss: 1058.3219\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1469.4987 - val_loss: 1047.8365\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1424.7788 - val_loss: 1038.6113\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1381.8628 - val_loss: 1030.5339\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1340.5789 - val_loss: 1023.4216\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1300.7975 - val_loss: 1017.2076\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1262.4265 - val_loss: 1011.8476\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1225.3954 - val_loss: 1007.3030\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1189.6456 - val_loss: 1003.5394\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1155.1282 - val_loss: 1000.5245\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1121.7993 - val_loss: 998.2279\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1089.6199 - val_loss: 996.6205\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1058.5531 - val_loss: 995.6740\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1028.5654 - val_loss: 995.3615\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 999.6248 - val_loss: 995.6555\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 971.6969 - val_loss: 996.4391\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 944.7649 - val_loss: 997.9650\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 918.7884 - val_loss: 999.9257\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 893.7446 - val_loss: 1002.3911\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 869.6072 - val_loss: 1005.3372\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 846.3524 - val_loss: 1009.2309\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 823.9529 - val_loss: 1014.1253\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 802.3812 - val_loss: 1018.5137\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 781.5875 - val_loss: 1023.0800\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 761.5646 - val_loss: 1027.8357\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 742.1265 - val_loss: 1032.7452\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 723.6031 - val_loss: 1037.9982\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 705.8522 - val_loss: 1043.3448\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 689.0526 - val_loss: 1047.6536\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 671.2383 - val_loss: 1049.1562\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 653.8762 - val_loss: 1052.1017\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 637.1807 - val_loss: 1055.1218\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 621.4949 - val_loss: 1046.6803\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 667.3001 - val_loss: 1059.2290\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 623.9438 - val_loss: 1061.3118\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 585.2114 - val_loss: 1091.3217\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 567.3823 - val_loss: 1099.0265\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 556.2531 - val_loss: 1101.6078\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 580.0532 - val_loss: 1114.1870\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 568.1824 - val_loss: 1124.9623\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 556.6896 - val_loss: 1133.4583\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 545.7225 - val_loss: 1141.6372\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 535.2278 - val_loss: 1150.5701\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 525.2347 - val_loss: 1159.0371\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 515.6424 - val_loss: 1168.1415\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 515.1827 - val_loss: 1177.7327\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 498.0960 - val_loss: 1186.9618\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 489.7006 - val_loss: 1196.4651\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 481.8026 - val_loss: 1205.4764\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 474.2989 - val_loss: 1214.5457\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 467.1735 - val_loss: 1223.7023\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 460.4021 - val_loss: 1232.2451\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 453.6317 - val_loss: 1241.6017\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 448.0168 - val_loss: 1250.9880\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 441.8481 - val_loss: 1259.6665\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 445.4235 - val_loss: 1269.4764\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 437.8778 - val_loss: 1280.5840\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 426.7657 - val_loss: 1289.2352\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 421.3485 - val_loss: 1296.6564\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 416.8265 - val_loss: 1305.2926\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 412.6427 - val_loss: 1313.5465\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.6129 - val_loss: 1322.3917\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 404.9148 - val_loss: 1330.0787\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 409.6862 - val_loss: 1338.4819\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 405.8544 - val_loss: 1347.7859\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 402.1749 - val_loss: 1356.9583\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 398.7253 - val_loss: 1365.9554\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 395.4979 - val_loss: 1374.7854\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 392.4789 - val_loss: 1383.4386\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 389.6558 - val_loss: 1391.9222\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 387.0162 - val_loss: 1400.2272\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 384.5489 - val_loss: 1408.3541\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 382.2434 - val_loss: 1416.3003\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 380.0898 - val_loss: 1424.0609\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 378.0789 - val_loss: 1431.6350\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 376.2020 - val_loss: 1439.0114\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 374.4506 - val_loss: 1446.1606\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 372.8170 - val_loss: 1452.5811\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 368.9173 - val_loss: 1422.5715\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 381.7042 - val_loss: 1417.4568\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 379.6644 - val_loss: 1420.9337\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 377.6364 - val_loss: 1435.9666\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 375.7374 - val_loss: 1443.5853\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 373.9696 - val_loss: 1451.0027\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 372.3251 - val_loss: 1458.2267\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 370.7959 - val_loss: 1465.2472\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 369.3745 - val_loss: 1472.0754\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 368.0540 - val_loss: 1478.7168\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 366.8275 - val_loss: 1485.1577\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 365.6888 - val_loss: 1491.4073\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 364.6321 - val_loss: 1497.4741\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 363.6519 - val_loss: 1503.3536\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 362.7429 - val_loss: 1509.0472\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 361.9002 - val_loss: 1514.5576\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 361.1194 - val_loss: 1519.8878\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 360.3960 - val_loss: 1525.0459\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 359.7262 - val_loss: 1530.0219\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 359.1061 - val_loss: 1534.8239\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 358.5321 - val_loss: 1539.4672\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 358.0011 - val_loss: 1543.9357\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 357.5099 - val_loss: 1548.2527\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 357.0558 - val_loss: 1552.4133\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 356.6359 - val_loss: 1556.4064\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 356.2477 - val_loss: 1560.2694\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 355.8889 - val_loss: 1563.9764\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 355.5574 - val_loss: 1567.5408\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 355.2512 - val_loss: 1570.9703\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 354.9684 - val_loss: 1574.2676\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 354.7072 - val_loss: 1577.4268\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 354.4659 - val_loss: 1580.4585\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 354.2430 - val_loss: 1583.3740\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 354.0373 - val_loss: 1586.1605\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 353.8474 - val_loss: 1588.8372\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 353.6720 - val_loss: 1591.3955\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 353.5101 - val_loss: 1593.8381\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 353.3605 - val_loss: 1596.1902\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 353.2225 - val_loss: 1598.4447\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 353.0950 - val_loss: 1600.5873\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 352.9772 - val_loss: 1602.6216\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 352.8685 - val_loss: 1604.5696\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 352.7680 - val_loss: 1606.4418\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 352.6752 - val_loss: 1608.2264\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 352.5894 - val_loss: 1609.9176\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 352.5102 - val_loss: 1611.5380\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 352.4369 - val_loss: 1613.0759\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 352.3692 - val_loss: 1614.5299\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 352.3067 - val_loss: 1615.9321\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 352.2487 - val_loss: 1617.2617\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 352.1951 - val_loss: 1618.5297\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 352.1456 - val_loss: 1619.7306\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 352.0997 - val_loss: 1620.8734\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 352.0573 - val_loss: 1621.9703\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 352.0180 - val_loss: 1623.0085\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.9816 - val_loss: 1623.9999\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.9478 - val_loss: 1624.9332\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.9165 - val_loss: 1625.8257\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.8877 - val_loss: 1626.6718\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.8609 - val_loss: 1627.4749\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.8359 - val_loss: 1628.2428\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.8129 - val_loss: 1628.9692\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.7915 - val_loss: 1629.6482\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 351.7717 - val_loss: 1630.2845\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.7533 - val_loss: 1630.8929\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 351.7362 - val_loss: 1631.4679\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.7204 - val_loss: 1632.0120\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.7057 - val_loss: 1632.5184\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.6920 - val_loss: 1632.9989\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.6794 - val_loss: 1633.4740\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.6677 - val_loss: 1633.9025\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.6568 - val_loss: 1634.3273\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.6467 - val_loss: 1634.7148\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.6373 - val_loss: 1635.0873\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.6286 - val_loss: 1635.4414\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.6205 - val_loss: 1635.7892\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.6130 - val_loss: 1636.0823\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.6061 - val_loss: 1636.3859\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5997 - val_loss: 1636.6730\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5937 - val_loss: 1636.9431\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5882 - val_loss: 1637.1985\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5831 - val_loss: 1637.4484\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5784 - val_loss: 1637.6696\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5740 - val_loss: 1637.8510\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5700 - val_loss: 1638.0480\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5663 - val_loss: 1638.2366\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5628 - val_loss: 1638.4210\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5597 - val_loss: 1638.5865\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5567 - val_loss: 1638.7423\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5540 - val_loss: 1638.8877\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5516 - val_loss: 1639.0250\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5493 - val_loss: 1639.1420\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5472 - val_loss: 1639.2627\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 351.5453 - val_loss: 1639.3702\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 351.5435 - val_loss: 1639.4457\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5419 - val_loss: 1639.5820\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5405 - val_loss: 1639.7083\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 351.5392 - val_loss: 1639.7766\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5380 - val_loss: 1639.8882\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5369 - val_loss: 1639.9427\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5359 - val_loss: 1640.0446\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5350 - val_loss: 1640.0895\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5342 - val_loss: 1640.1781\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5335 - val_loss: 1640.1891\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5329 - val_loss: 1640.2831\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5323 - val_loss: 1640.3696\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5319 - val_loss: 1640.4102\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5315 - val_loss: 1640.4380\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5312 - val_loss: 1640.5070\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5309 - val_loss: 1640.5039\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5306 - val_loss: 1640.5759\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5304 - val_loss: 1640.6439\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5303 - val_loss: 1640.6316\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5301 - val_loss: 1640.6941\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5300 - val_loss: 1640.7500\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5300 - val_loss: 1640.7260\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5300 - val_loss: 1640.7828\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5300 - val_loss: 1640.8361\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5300 - val_loss: 1640.8362\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5300 - val_loss: 1640.8826\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5302 - val_loss: 1640.8912\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5303 - val_loss: 1640.9380\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 351.5303 - val_loss: 1640.9379\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 351.5305 - val_loss: 1640.9246\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5306 - val_loss: 1640.9734\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5308 - val_loss: 1641.0162\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5310 - val_loss: 1641.0085\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5312 - val_loss: 1641.0016\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5313 - val_loss: 1641.0394\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5315 - val_loss: 1641.0336\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5317 - val_loss: 1641.0676\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5320 - val_loss: 1641.0446\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5322 - val_loss: 1641.0858\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5324 - val_loss: 1641.1212\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5327 - val_loss: 1641.1095\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5329 - val_loss: 1641.1359\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5332 - val_loss: 1641.1047\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5334 - val_loss: 1641.1401\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5336 - val_loss: 1641.1709\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5338 - val_loss: 1641.1539\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5341 - val_loss: 1641.1746\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5343 - val_loss: 1641.0977\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5345 - val_loss: 1641.1299\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5349 - val_loss: 1641.1715\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5351 - val_loss: 1641.2004\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5353 - val_loss: 1641.1609\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5356 - val_loss: 1641.1917\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5358 - val_loss: 1641.2192\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5361 - val_loss: 1641.1924\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5363 - val_loss: 1641.2250\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5364 - val_loss: 1641.2472\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5367 - val_loss: 1641.1964\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5369 - val_loss: 1641.2250\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 351.5372 - val_loss: 1641.2496\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5374 - val_loss: 1641.1949\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5376 - val_loss: 1641.2253\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5378 - val_loss: 1641.2609\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5380 - val_loss: 1641.2860\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5381 - val_loss: 1641.2527\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5384 - val_loss: 1641.2797\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5386 - val_loss: 1641.3033\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5388 - val_loss: 1641.2633\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5390 - val_loss: 1641.2882\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5392 - val_loss: 1641.3033\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5393 - val_loss: 1641.1913\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5395 - val_loss: 1641.2188\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5397 - val_loss: 1641.2524\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5400 - val_loss: 1641.2826\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5400 - val_loss: 1641.3148\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5402 - val_loss: 1641.3309\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5404 - val_loss: 1641.2603\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5406 - val_loss: 1641.2828\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5408 - val_loss: 1641.3115\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5409 - val_loss: 1641.3300\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5410 - val_loss: 1641.2828\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5412 - val_loss: 1641.3087\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5413 - val_loss: 1641.3357\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5415 - val_loss: 1641.3411\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5416 - val_loss: 1641.2053\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5417 - val_loss: 1641.2319\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5419 - val_loss: 1641.2678\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5420 - val_loss: 1641.3018\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 351.5422 - val_loss: 1641.3329\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 351.5422 - val_loss: 1641.3628\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5424 - val_loss: 1641.3820\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5425 - val_loss: 1641.3250\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5427 - val_loss: 1641.3484\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5427 - val_loss: 1641.3706\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5428 - val_loss: 1641.3798\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5429 - val_loss: 1641.2837\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5430 - val_loss: 1641.3033\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5431 - val_loss: 1641.3304\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5432 - val_loss: 1641.3616\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5433 - val_loss: 1641.3888\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5434 - val_loss: 1641.4020\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5435 - val_loss: 1641.3325\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5437 - val_loss: 1641.3491\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5436 - val_loss: 1641.3717\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5438 - val_loss: 1641.3954\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5439 - val_loss: 1641.4034\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5439 - val_loss: 1641.2930\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5439 - val_loss: 1641.3083\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5441 - val_loss: 1641.3357\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5442 - val_loss: 1641.3618\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5442 - val_loss: 1641.3870\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5443 - val_loss: 1641.4076\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5444 - val_loss: 1641.4110\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5444 - val_loss: 1641.2883\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5444 - val_loss: 1641.3109\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5446 - val_loss: 1641.3441\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 351.5446 - val_loss: 1641.3756\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 351.5446 - val_loss: 1641.3993\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 351.5447 - val_loss: 1641.4215\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5448 - val_loss: 1641.4281\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5448 - val_loss: 1641.3356\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5449 - val_loss: 1641.3513\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5449 - val_loss: 1641.3744\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5450 - val_loss: 1641.4003\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5450 - val_loss: 1641.4263\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5452 - val_loss: 1641.4388\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5451 - val_loss: 1641.3442\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5451 - val_loss: 1641.3663\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5451 - val_loss: 1641.3895\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5453 - val_loss: 1641.4147\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 351.5453 - val_loss: 1641.4379\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5453 - val_loss: 1641.4429\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5453 - val_loss: 1641.3295\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5454 - val_loss: 1641.3441\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5454 - val_loss: 1641.3696\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5454 - val_loss: 1641.3971\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5455 - val_loss: 1641.4241\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5455 - val_loss: 1641.4485\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5455 - val_loss: 1641.4622\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5456 - val_loss: 1641.4369\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5455 - val_loss: 1641.1578\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 351.5455 - val_loss: 1641.1803\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 351.5456 - val_loss: 1641.2174\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5456 - val_loss: 1641.2556\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5457 - val_loss: 1641.2911\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5456 - val_loss: 1641.3252\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5457 - val_loss: 1641.3470\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5457 - val_loss: 1641.3788\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5457 - val_loss: 1641.4023\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5457 - val_loss: 1641.4095\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.4233\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.4332\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5458 - val_loss: 1641.4329\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.4318\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5457 - val_loss: 1641.4303\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5457 - val_loss: 1641.4283\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.4261\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5459 - val_loss: 1641.4248\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5460 - val_loss: 1641.4238\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.4235\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5459 - val_loss: 1641.4218\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5461 - val_loss: 1641.4208\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5459 - val_loss: 1641.4196\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5458 - val_loss: 1641.4191\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5459 - val_loss: 1641.4176\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5460 - val_loss: 1641.4163\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5459 - val_loss: 1641.4154\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5459 - val_loss: 1641.4147\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 351.5460 - val_loss: 1641.4135\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5460 - val_loss: 1641.4128\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5459 - val_loss: 1641.4125\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5459 - val_loss: 1641.4105\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5460 - val_loss: 1641.4089\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5459 - val_loss: 1641.4071\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.4059\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5458 - val_loss: 1641.4048\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5459 - val_loss: 1641.4026\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5460 - val_loss: 1641.4016\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5459 - val_loss: 1641.4006\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5458 - val_loss: 1641.4001\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5459 - val_loss: 1641.3982\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5460 - val_loss: 1641.3973\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5460 - val_loss: 1641.3971\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5459 - val_loss: 1641.3955\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5460 - val_loss: 1641.3944\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5459 - val_loss: 1641.3934\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5459 - val_loss: 1641.3928\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.3906\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5459 - val_loss: 1641.3888\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.3875\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5458 - val_loss: 1641.3860\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.3845\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5457 - val_loss: 1641.3822\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.3802\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.3784\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.3763\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5459 - val_loss: 1641.3759\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 351.5458 - val_loss: 1641.3740\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5459 - val_loss: 1641.3728\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5459 - val_loss: 1641.3713\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.3713\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.3698\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5459 - val_loss: 1641.3690\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5459 - val_loss: 1641.3689\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.3680\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.3671\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.3669\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5458 - val_loss: 1641.3661\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5457 - val_loss: 1641.3646\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5457 - val_loss: 1641.3632\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5457 - val_loss: 1641.3623\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5456 - val_loss: 1641.3607\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5456 - val_loss: 1641.3588\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5457 - val_loss: 1641.3572\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5457 - val_loss: 1641.3557\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5456 - val_loss: 1641.3545\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5455 - val_loss: 1641.3524\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5455 - val_loss: 1641.3503\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5456 - val_loss: 1641.3489\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5456 - val_loss: 1641.3475\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5456 - val_loss: 1641.3461\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 351.5455 - val_loss: 1641.3441\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5456 - val_loss: 1641.3422\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5455 - val_loss: 1641.3406\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5455 - val_loss: 1641.3391\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5456 - val_loss: 1641.3384\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5454 - val_loss: 1641.3361\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5455 - val_loss: 1641.3342\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5455 - val_loss: 1641.3328\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5454 - val_loss: 1641.3313\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5454 - val_loss: 1641.3303\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5454 - val_loss: 1641.3276\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5455 - val_loss: 1641.3267\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5455 - val_loss: 1641.3253\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5455 - val_loss: 1641.3243\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5453 - val_loss: 1641.3221\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5454 - val_loss: 1641.3204\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5454 - val_loss: 1641.3191\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5454 - val_loss: 1641.3181\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5454 - val_loss: 1641.3171\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5453 - val_loss: 1641.3154\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5454 - val_loss: 1641.3143\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5454 - val_loss: 1641.3140\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5453 - val_loss: 1641.3119\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5453 - val_loss: 1641.3105\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5453 - val_loss: 1641.3093\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 351.5453 - val_loss: 1641.3088\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5451 - val_loss: 1641.3065\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5452 - val_loss: 1641.3055\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5452 - val_loss: 1641.3046\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5452 - val_loss: 1641.3040\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5451 - val_loss: 1641.3021\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5451 - val_loss: 1641.3013\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5451 - val_loss: 1641.3003\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5451 - val_loss: 1641.2987\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5451 - val_loss: 1641.2970\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5451 - val_loss: 1641.2959\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5450 - val_loss: 1641.2954\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5450 - val_loss: 1641.2930\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5450 - val_loss: 1641.2911\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5450 - val_loss: 1641.2899\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5449 - val_loss: 1641.2887\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5449 - val_loss: 1641.2869\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5449 - val_loss: 1641.2850\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5449 - val_loss: 1641.2836\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5449 - val_loss: 1641.2822\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5449 - val_loss: 1641.2806\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5448 - val_loss: 1641.2783\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5448 - val_loss: 1641.2769\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5449 - val_loss: 1641.2756\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 351.5448 - val_loss: 1641.2740\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5447 - val_loss: 1641.2717\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5447 - val_loss: 1641.2699\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5447 - val_loss: 1641.2683\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5447 - val_loss: 1641.2671\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 351.5446 - val_loss: 1641.2643\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5446 - val_loss: 1641.2625\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5446 - val_loss: 1641.2605\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5446 - val_loss: 1641.2589\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5446 - val_loss: 1641.2567\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5445 - val_loss: 1641.2542\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5446 - val_loss: 1641.2522\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5446 - val_loss: 1641.2499\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5446 - val_loss: 1641.2487\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5445 - val_loss: 1641.2457\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5445 - val_loss: 1641.2430\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5445 - val_loss: 1641.2408\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5445 - val_loss: 1641.2386\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5445 - val_loss: 1641.2366\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5445 - val_loss: 1641.2330\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.5445 - val_loss: 1641.2302\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5445 - val_loss: 1641.2277\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.5445 - val_loss: 1641.2250\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 351.5445 - val_loss: 1641.2220\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 351.5444 - val_loss: 1641.2184\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1.5\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 421ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.26796218e+01, 6.67000467e+01, 6.58874883e+01, 6.43748833e+01,\n",
       "        0.00000000e+00, 7.77567625e-01, 2.24165514e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.73955500e-02, 9.40269887e-01,\n",
       "        0.00000000e+00, 6.30913866e+01, 6.28644958e+01, 6.26376050e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.35625817e+01, 6.33861111e+01,\n",
       "        6.31838235e+01, 6.29569328e+01, 6.27300420e+01, 6.68681139e+01,\n",
       "        6.61118114e+01, 6.47110177e+01, 0.00000000e+00, 5.33040600e-03,\n",
       "        3.75749886e-01, 6.28224790e+01, 6.71821895e+01, 6.65039682e+01,\n",
       "        6.54953315e+01, 0.00000000e+00, 6.61024743e+01, 6.46923436e+01,\n",
       "        6.37129085e+01, 5.88601890e-01, 1.25890970e-01, 3.38448170e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.07296932e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.50471522e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.07869007e-01, 6.28728992e+01,\n",
       "        6.26460084e+01, 6.66720355e+01, 6.58314659e+01, 6.43188609e+01,\n",
       "        6.62705416e+01, 6.50284781e+01, 6.38305556e+01, 4.98692630e-01,\n",
       "        1.79073750e-01, 5.79469680e-01, 6.49351074e+01, 3.30429226e-01,\n",
       "        6.56447246e+01, 6.41321195e+01, 6.35168301e+01, 6.48417367e+01,\n",
       "        6.37651961e+01, 6.32174370e+01, 0.00000000e+00, 3.13404799e-01,\n",
       "        9.37583506e-01, 6.24092255e+01, 4.13899481e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.63043845e-01, 7.33780205e-01,\n",
       "        6.18610115e+01, 8.37967932e-01, 4.07031417e-01, 2.19893903e-01,\n",
       "        0.00000000e+00, 3.90545547e-01, 8.58127698e-02, 0.00000000e+00,\n",
       "        2.23327562e-01, 1.85593998e+00, 9.63781238e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.67599946e-01, 0.00000000e+00,\n",
       "        8.93679619e-01, 0.00000000e+00, 2.47046500e-01, 1.65574551e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53.50299925, 53.49425429, 53.48550933, 53.47676436, 53.4680194 ,\n",
       "       53.45927444, 53.45052948, 53.44178452, 53.43303956, 53.4242946 ,\n",
       "       53.41554963, 53.40680467, 53.39805971, 53.38931475, 53.38056979,\n",
       "       53.37182483, 53.36307987, 53.3543349 , 53.34558994, 53.33684498,\n",
       "       53.32810002, 53.31935506, 53.3106101 , 53.30186514, 53.29312017,\n",
       "       53.28437521, 53.27563025, 53.26688529, 53.25814033, 53.24939537,\n",
       "       53.24065041, 53.23190545, 53.22316048, 53.21441552, 53.20567056,\n",
       "       53.1969256 , 53.18818064, 53.17943568, 53.17069072, 53.16194575,\n",
       "       53.15320079, 53.14445583, 53.13571087, 53.12696591, 53.11822095,\n",
       "       53.10947599, 53.10073102, 53.09198606, 53.0832411 , 53.07449614,\n",
       "       53.06575118, 53.05700622, 53.04826126, 53.03951629, 53.03077133,\n",
       "       53.02202637, 53.01328141, 53.00453645, 52.99579149, 52.98704653,\n",
       "       52.97830156, 52.9695566 , 52.96081164, 52.95206668, 52.94332172,\n",
       "       52.93457676, 52.9258318 , 52.91708683, 52.90834187, 52.89959691,\n",
       "       52.89085195, 52.88210699, 52.87336203, 52.86461707, 52.8558721 ,\n",
       "       52.84712714, 52.83838218, 52.82963722, 52.82089226, 52.8121473 ,\n",
       "       52.80340234, 52.79465738, 52.78591241, 52.77716745, 52.76842249,\n",
       "       52.75967753, 52.75093257, 52.74218761, 52.73344265, 52.72469768,\n",
       "       52.71595272, 52.70720776, 52.6984628 , 52.68971784, 52.68097288,\n",
       "       52.67222792, 52.66348295, 52.65473799, 52.64599303, 52.63724807])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.48291450868057\n",
      "36.134840725093255\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
