{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2345    53.546724\n",
       "2346    53.537979\n",
       "2347    53.529234\n",
       "2348    53.520489\n",
       "2349    53.511744\n",
       "Name: C1, Length: 2350, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_2250_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2245     0.217627\n",
       "2246     0.115208\n",
       "2247     0.618553\n",
       "2248     0.447264\n",
       "2249     0.858414\n",
       "Name: C1, Length: 2250, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2250)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 1, 251) (1800, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "23/23 [==============================] - 2s 24ms/step - loss: 4197.2495 - val_loss: 2205.3530\n",
      "Epoch 2/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3947.0962 - val_loss: 2100.5256\n",
      "Epoch 3/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3832.6318 - val_loss: 2041.0835\n",
      "Epoch 4/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 3728.5647 - val_loss: 1987.5247\n",
      "Epoch 5/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3632.6338 - val_loss: 1938.0210\n",
      "Epoch 6/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3542.3132 - val_loss: 1892.3503\n",
      "Epoch 7/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3456.1362 - val_loss: 1849.0247\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 3372.8652 - val_loss: 1807.5271\n",
      "Epoch 9/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3291.9937 - val_loss: 1767.6484\n",
      "Epoch 10/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3213.2275 - val_loss: 1729.2577\n",
      "Epoch 11/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 3136.3826 - val_loss: 1692.2645\n",
      "Epoch 12/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 3061.3333 - val_loss: 1656.6027\n",
      "Epoch 13/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2987.9841 - val_loss: 1622.2183\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2916.2646 - val_loss: 1589.0636\n",
      "Epoch 15/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2846.1086 - val_loss: 1556.9528\n",
      "Epoch 16/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2777.3987 - val_loss: 1526.3499\n",
      "Epoch 17/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2710.4143 - val_loss: 1496.6460\n",
      "Epoch 18/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2644.6284 - val_loss: 1468.0959\n",
      "Epoch 19/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2580.3271 - val_loss: 1440.6268\n",
      "Epoch 20/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2517.4009 - val_loss: 1414.2150\n",
      "Epoch 21/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2455.8235 - val_loss: 1388.8373\n",
      "Epoch 22/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2395.5669 - val_loss: 1364.4724\n",
      "Epoch 23/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 2336.6072 - val_loss: 1341.0990\n",
      "Epoch 24/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2278.9197 - val_loss: 1318.6974\n",
      "Epoch 25/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2222.4822 - val_loss: 1297.2474\n",
      "Epoch 26/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2167.2725 - val_loss: 1276.7305\n",
      "Epoch 27/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2113.2700 - val_loss: 1257.2069\n",
      "Epoch 28/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2060.4534 - val_loss: 1238.3870\n",
      "Epoch 29/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2008.8035 - val_loss: 1220.5662\n",
      "Epoch 30/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1958.3018 - val_loss: 1203.6058\n",
      "Epoch 31/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1908.9272 - val_loss: 1187.4885\n",
      "Epoch 32/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1860.6630 - val_loss: 1172.1970\n",
      "Epoch 33/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1813.4913 - val_loss: 1157.7150\n",
      "Epoch 34/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1767.3938 - val_loss: 1144.0254\n",
      "Epoch 35/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1722.3528 - val_loss: 1131.1123\n",
      "Epoch 36/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1678.3516 - val_loss: 1118.9592\n",
      "Epoch 37/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1635.3738 - val_loss: 1107.5503\n",
      "Epoch 38/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1593.4021 - val_loss: 1096.8698\n",
      "Epoch 39/500\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1552.4203 - val_loss: 1086.9017\n",
      "Epoch 40/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1512.4124 - val_loss: 1077.6311\n",
      "Epoch 41/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1473.3627 - val_loss: 1069.0421\n",
      "Epoch 42/500\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1435.2556 - val_loss: 1061.1201\n",
      "Epoch 43/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 1398.0743 - val_loss: 1053.8499\n",
      "Epoch 44/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1361.8052 - val_loss: 1047.2164\n",
      "Epoch 45/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1326.4319 - val_loss: 1041.2051\n",
      "Epoch 46/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 1291.9399 - val_loss: 1035.8009\n",
      "Epoch 47/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 1258.3142 - val_loss: 1030.9896\n",
      "Epoch 48/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1225.5402 - val_loss: 1026.7570\n",
      "Epoch 49/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1193.6031 - val_loss: 1023.0884\n",
      "Epoch 50/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1162.4890 - val_loss: 1019.9698\n",
      "Epoch 51/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 1132.1831 - val_loss: 1017.3870\n",
      "Epoch 52/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1102.6718 - val_loss: 1015.3261\n",
      "Epoch 53/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1073.9407 - val_loss: 1013.7736\n",
      "Epoch 54/500\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 1045.9758 - val_loss: 1012.7153\n",
      "Epoch 55/500\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1018.7639 - val_loss: 1012.1379\n",
      "Epoch 56/500\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 992.2903 - val_loss: 1012.0280\n",
      "Epoch 57/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 966.5428 - val_loss: 1012.3718\n",
      "Epoch 58/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 941.5074 - val_loss: 1013.1562\n",
      "Epoch 59/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 917.1707 - val_loss: 1014.3680\n",
      "Epoch 60/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 893.5200 - val_loss: 1015.9942\n",
      "Epoch 61/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 870.5417 - val_loss: 1018.0217\n",
      "Epoch 62/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 848.2236 - val_loss: 1020.4376\n",
      "Epoch 63/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 826.5522 - val_loss: 1023.2290\n",
      "Epoch 64/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 805.5153 - val_loss: 1026.3834\n",
      "Epoch 65/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 785.1001 - val_loss: 1029.8884\n",
      "Epoch 66/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 765.2941 - val_loss: 1033.7313\n",
      "Epoch 67/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 746.0853 - val_loss: 1037.9000\n",
      "Epoch 68/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 727.4610 - val_loss: 1042.3823\n",
      "Epoch 69/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 709.4093 - val_loss: 1047.1660\n",
      "Epoch 70/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 691.9183 - val_loss: 1052.2394\n",
      "Epoch 71/500\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 674.9758 - val_loss: 1057.5901\n",
      "Epoch 72/500\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 658.5703 - val_loss: 1063.2065\n",
      "Epoch 73/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 642.6897 - val_loss: 1069.0773\n",
      "Epoch 74/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 627.3228 - val_loss: 1075.1907\n",
      "Epoch 75/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 612.4581 - val_loss: 1081.5354\n",
      "Epoch 76/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 598.0842 - val_loss: 1088.1005\n",
      "Epoch 77/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 584.1897 - val_loss: 1094.8743\n",
      "Epoch 78/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 570.7637 - val_loss: 1101.8463\n",
      "Epoch 79/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 557.7951 - val_loss: 1109.0056\n",
      "Epoch 80/500\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 545.2729 - val_loss: 1116.3412\n",
      "Epoch 81/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 533.1864 - val_loss: 1123.8425\n",
      "Epoch 82/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 521.5251 - val_loss: 1131.4994\n",
      "Epoch 83/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 510.2783 - val_loss: 1139.3010\n",
      "Epoch 84/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 499.4354 - val_loss: 1147.2378\n",
      "Epoch 85/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 488.9865 - val_loss: 1155.2991\n",
      "Epoch 86/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 478.9212 - val_loss: 1163.4758\n",
      "Epoch 87/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 469.2295 - val_loss: 1171.7582\n",
      "Epoch 88/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 459.9014 - val_loss: 1180.1362\n",
      "Epoch 89/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 450.9272 - val_loss: 1188.6008\n",
      "Epoch 90/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 442.2971 - val_loss: 1197.1428\n",
      "Epoch 91/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 434.0017 - val_loss: 1205.7532\n",
      "Epoch 92/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 426.0315 - val_loss: 1214.4230\n",
      "Epoch 93/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 418.3773 - val_loss: 1223.1436\n",
      "Epoch 94/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 411.0296 - val_loss: 1231.9066\n",
      "Epoch 95/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 403.9798 - val_loss: 1240.7030\n",
      "Epoch 96/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 397.2189 - val_loss: 1249.5256\n",
      "Epoch 97/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 390.7382 - val_loss: 1258.3658\n",
      "Epoch 98/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 384.5289 - val_loss: 1267.2166\n",
      "Epoch 99/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 378.5829 - val_loss: 1276.0692\n",
      "Epoch 100/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 372.8914 - val_loss: 1284.9172\n",
      "Epoch 101/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 367.4467 - val_loss: 1293.7531\n",
      "Epoch 102/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 362.2404 - val_loss: 1302.5699\n",
      "Epoch 103/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 357.2648 - val_loss: 1311.3611\n",
      "Epoch 104/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 352.5121 - val_loss: 1320.1200\n",
      "Epoch 105/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 347.9746 - val_loss: 1328.8397\n",
      "Epoch 106/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 343.6451 - val_loss: 1337.5146\n",
      "Epoch 107/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 339.5162 - val_loss: 1346.1387\n",
      "Epoch 108/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 335.5807 - val_loss: 1354.7061\n",
      "Epoch 109/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 331.8317 - val_loss: 1363.2117\n",
      "Epoch 110/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 328.2621 - val_loss: 1371.6495\n",
      "Epoch 111/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 324.8656 - val_loss: 1380.0143\n",
      "Epoch 112/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 321.6353 - val_loss: 1388.3016\n",
      "Epoch 113/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 318.5651 - val_loss: 1396.5071\n",
      "Epoch 114/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 315.6487 - val_loss: 1404.6261\n",
      "Epoch 115/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 312.8799 - val_loss: 1412.6539\n",
      "Epoch 116/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 310.2528 - val_loss: 1420.5864\n",
      "Epoch 117/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.7618 - val_loss: 1428.4205\n",
      "Epoch 118/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 305.4011 - val_loss: 1436.1519\n",
      "Epoch 119/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 303.1652 - val_loss: 1443.7780\n",
      "Epoch 120/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 301.0490 - val_loss: 1451.2950\n",
      "Epoch 121/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 299.0471 - val_loss: 1458.7003\n",
      "Epoch 122/500\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 297.1548 - val_loss: 1465.9911\n",
      "Epoch 123/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 295.3669 - val_loss: 1473.1646\n",
      "Epoch 124/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 293.6789 - val_loss: 1480.2188\n",
      "Epoch 125/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 292.0862 - val_loss: 1487.1517\n",
      "Epoch 126/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 290.5842 - val_loss: 1493.9611\n",
      "Epoch 127/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 289.1690 - val_loss: 1500.6455\n",
      "Epoch 128/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 287.8361 - val_loss: 1507.2031\n",
      "Epoch 129/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 286.5817 - val_loss: 1513.6328\n",
      "Epoch 130/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 285.4019 - val_loss: 1519.9337\n",
      "Epoch 131/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 284.2931 - val_loss: 1526.1041\n",
      "Epoch 132/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 283.2516 - val_loss: 1532.1443\n",
      "Epoch 133/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 282.2739 - val_loss: 1538.0522\n",
      "Epoch 134/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 281.3569 - val_loss: 1543.8289\n",
      "Epoch 135/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 280.4972 - val_loss: 1549.4734\n",
      "Epoch 136/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 279.6919 - val_loss: 1554.9863\n",
      "Epoch 137/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 278.9379 - val_loss: 1560.3671\n",
      "Epoch 138/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 278.2326 - val_loss: 1565.6161\n",
      "Epoch 139/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 277.5732 - val_loss: 1570.7333\n",
      "Epoch 140/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 276.9572 - val_loss: 1575.7196\n",
      "Epoch 141/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 276.3820 - val_loss: 1580.5760\n",
      "Epoch 142/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 275.8454 - val_loss: 1585.3038\n",
      "Epoch 143/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 275.3450 - val_loss: 1589.9025\n",
      "Epoch 144/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 274.8788 - val_loss: 1594.3741\n",
      "Epoch 145/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 274.4447 - val_loss: 1598.7198\n",
      "Epoch 146/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 274.0408 - val_loss: 1602.9407\n",
      "Epoch 147/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 273.6652 - val_loss: 1607.0378\n",
      "Epoch 148/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 273.3161 - val_loss: 1611.0125\n",
      "Epoch 149/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 272.9919 - val_loss: 1614.8676\n",
      "Epoch 150/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 272.6912 - val_loss: 1618.6035\n",
      "Epoch 151/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 272.4122 - val_loss: 1622.2228\n",
      "Epoch 152/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 272.1537 - val_loss: 1625.7266\n",
      "Epoch 153/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 271.9142 - val_loss: 1629.1173\n",
      "Epoch 154/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 271.6925 - val_loss: 1632.3969\n",
      "Epoch 155/500\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 271.4876 - val_loss: 1635.5665\n",
      "Epoch 156/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 271.2980 - val_loss: 1638.6295\n",
      "Epoch 157/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 271.1230 - val_loss: 1641.5867\n",
      "Epoch 158/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 270.9614 - val_loss: 1644.4419\n",
      "Epoch 159/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 270.8122 - val_loss: 1647.1953\n",
      "Epoch 160/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 270.6747 - val_loss: 1649.8499\n",
      "Epoch 161/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 270.5480 - val_loss: 1652.4091\n",
      "Epoch 162/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 270.4313 - val_loss: 1654.8733\n",
      "Epoch 163/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 270.3239 - val_loss: 1657.2463\n",
      "Epoch 164/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 270.2252 - val_loss: 1659.5288\n",
      "Epoch 165/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 270.1343 - val_loss: 1661.7249\n",
      "Epoch 166/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 270.0509 - val_loss: 1663.8361\n",
      "Epoch 167/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.9743 - val_loss: 1665.8638\n",
      "Epoch 168/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.9040 - val_loss: 1667.8109\n",
      "Epoch 169/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.8396 - val_loss: 1669.6802\n",
      "Epoch 170/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.7805 - val_loss: 1671.4738\n",
      "Epoch 171/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.7264 - val_loss: 1673.1942\n",
      "Epoch 172/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.6768 - val_loss: 1674.8420\n",
      "Epoch 173/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.6315 - val_loss: 1676.4215\n",
      "Epoch 174/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.5900 - val_loss: 1677.9346\n",
      "Epoch 175/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.5520 - val_loss: 1679.3817\n",
      "Epoch 176/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.5175 - val_loss: 1680.7668\n",
      "Epoch 177/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.4858 - val_loss: 1682.0909\n",
      "Epoch 178/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.4570 - val_loss: 1683.3566\n",
      "Epoch 179/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.4306 - val_loss: 1684.5658\n",
      "Epoch 180/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.4066 - val_loss: 1685.7200\n",
      "Epoch 181/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.3848 - val_loss: 1686.8225\n",
      "Epoch 182/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.3649 - val_loss: 1687.8739\n",
      "Epoch 183/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.3468 - val_loss: 1688.8763\n",
      "Epoch 184/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.3304 - val_loss: 1689.8323\n",
      "Epoch 185/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.3154 - val_loss: 1690.7429\n",
      "Epoch 186/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.3018 - val_loss: 1691.6099\n",
      "Epoch 187/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2895 - val_loss: 1692.4362\n",
      "Epoch 188/500\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 269.2783 - val_loss: 1693.2209\n",
      "Epoch 189/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2682 - val_loss: 1693.9683\n",
      "Epoch 190/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2591 - val_loss: 1694.6785\n",
      "Epoch 191/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2507 - val_loss: 1695.3541\n",
      "Epoch 192/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2433 - val_loss: 1695.9948\n",
      "Epoch 193/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2365 - val_loss: 1696.6033\n",
      "Epoch 194/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2304 - val_loss: 1697.1805\n",
      "Epoch 195/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2249 - val_loss: 1697.7285\n",
      "Epoch 196/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2200 - val_loss: 1698.2483\n",
      "Epoch 197/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2156 - val_loss: 1698.7410\n",
      "Epoch 198/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2117 - val_loss: 1699.2073\n",
      "Epoch 199/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2082 - val_loss: 1699.6498\n",
      "Epoch 200/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2050 - val_loss: 1700.0684\n",
      "Epoch 201/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2022 - val_loss: 1700.4641\n",
      "Epoch 202/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1998 - val_loss: 1700.8389\n",
      "Epoch 203/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1976 - val_loss: 1701.1927\n",
      "Epoch 204/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1956 - val_loss: 1701.5275\n",
      "Epoch 205/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1941 - val_loss: 1701.8442\n",
      "Epoch 206/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1926 - val_loss: 1702.1426\n",
      "Epoch 207/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1913 - val_loss: 1702.4252\n",
      "Epoch 208/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1902 - val_loss: 1702.6909\n",
      "Epoch 209/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1894 - val_loss: 1702.9421\n",
      "Epoch 210/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1887 - val_loss: 1703.1786\n",
      "Epoch 211/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1880 - val_loss: 1703.4017\n",
      "Epoch 212/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1877 - val_loss: 1703.6119\n",
      "Epoch 213/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1873 - val_loss: 1703.8108\n",
      "Epoch 214/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1870 - val_loss: 1703.9967\n",
      "Epoch 215/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1869 - val_loss: 1704.1724\n",
      "Epoch 216/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1868 - val_loss: 1704.3373\n",
      "Epoch 217/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1869 - val_loss: 1704.4934\n",
      "Epoch 218/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.1869 - val_loss: 1704.6385\n",
      "Epoch 219/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1871 - val_loss: 1704.7762\n",
      "Epoch 220/500\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 269.1873 - val_loss: 1704.9047\n",
      "Epoch 221/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 269.1875 - val_loss: 1705.0254\n",
      "Epoch 222/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.1879 - val_loss: 1705.1382\n",
      "Epoch 223/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1883 - val_loss: 1705.2451\n",
      "Epoch 224/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1886 - val_loss: 1705.3450\n",
      "Epoch 225/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1891 - val_loss: 1705.4388\n",
      "Epoch 226/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1896 - val_loss: 1705.5264\n",
      "Epoch 227/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1900 - val_loss: 1705.6083\n",
      "Epoch 228/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1906 - val_loss: 1705.6853\n",
      "Epoch 229/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1911 - val_loss: 1705.7567\n",
      "Epoch 230/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1917 - val_loss: 1705.8241\n",
      "Epoch 231/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1923 - val_loss: 1705.8866\n",
      "Epoch 232/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1929 - val_loss: 1705.9449\n",
      "Epoch 233/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1935 - val_loss: 1706.0001\n",
      "Epoch 234/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1942 - val_loss: 1706.0509\n",
      "Epoch 235/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1948 - val_loss: 1706.0986\n",
      "Epoch 236/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1954 - val_loss: 1706.1431\n",
      "Epoch 237/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1961 - val_loss: 1706.1841\n",
      "Epoch 238/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1968 - val_loss: 1706.2225\n",
      "Epoch 239/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1974 - val_loss: 1706.2582\n",
      "Epoch 240/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1981 - val_loss: 1706.2920\n",
      "Epoch 241/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1988 - val_loss: 1706.3229\n",
      "Epoch 242/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.1995 - val_loss: 1706.3519\n",
      "Epoch 243/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2001 - val_loss: 1706.3778\n",
      "Epoch 244/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2008 - val_loss: 1706.4025\n",
      "Epoch 245/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2015 - val_loss: 1706.4253\n",
      "Epoch 246/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2022 - val_loss: 1706.4465\n",
      "Epoch 247/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.2028 - val_loss: 1706.4663\n",
      "Epoch 248/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2035 - val_loss: 1706.4844\n",
      "Epoch 249/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2041 - val_loss: 1706.5004\n",
      "Epoch 250/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2049 - val_loss: 1706.5160\n",
      "Epoch 251/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2055 - val_loss: 1706.5302\n",
      "Epoch 252/500\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 269.2061 - val_loss: 1706.5432\n",
      "Epoch 253/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2068 - val_loss: 1706.5543\n",
      "Epoch 254/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2075 - val_loss: 1706.5657\n",
      "Epoch 255/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2080 - val_loss: 1706.5748\n",
      "Epoch 256/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2086 - val_loss: 1706.5830\n",
      "Epoch 257/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2093 - val_loss: 1706.5913\n",
      "Epoch 258/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2099 - val_loss: 1706.5984\n",
      "Epoch 259/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2105 - val_loss: 1706.6052\n",
      "Epoch 260/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2111 - val_loss: 1706.6101\n",
      "Epoch 261/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2116 - val_loss: 1706.6147\n",
      "Epoch 262/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2123 - val_loss: 1706.6193\n",
      "Epoch 263/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2129 - val_loss: 1706.6238\n",
      "Epoch 264/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2134 - val_loss: 1706.6271\n",
      "Epoch 265/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2140 - val_loss: 1706.6296\n",
      "Epoch 266/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2145 - val_loss: 1706.6327\n",
      "Epoch 267/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2150 - val_loss: 1706.6344\n",
      "Epoch 268/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2156 - val_loss: 1706.6362\n",
      "Epoch 269/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2161 - val_loss: 1706.6368\n",
      "Epoch 270/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2166 - val_loss: 1706.6384\n",
      "Epoch 271/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2172 - val_loss: 1706.6387\n",
      "Epoch 272/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2177 - val_loss: 1706.6387\n",
      "Epoch 273/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2182 - val_loss: 1706.6394\n",
      "Epoch 274/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2187 - val_loss: 1706.6390\n",
      "Epoch 275/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2191 - val_loss: 1706.6381\n",
      "Epoch 276/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2196 - val_loss: 1706.6375\n",
      "Epoch 277/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2201 - val_loss: 1706.6366\n",
      "Epoch 278/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2205 - val_loss: 1706.6354\n",
      "Epoch 279/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2210 - val_loss: 1706.6345\n",
      "Epoch 280/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2214 - val_loss: 1706.6324\n",
      "Epoch 281/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2218 - val_loss: 1706.6311\n",
      "Epoch 282/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2223 - val_loss: 1706.6292\n",
      "Epoch 283/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2227 - val_loss: 1706.6271\n",
      "Epoch 284/500\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 269.2231 - val_loss: 1706.6251\n",
      "Epoch 285/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2235 - val_loss: 1706.6228\n",
      "Epoch 286/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2239 - val_loss: 1706.6206\n",
      "Epoch 287/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2243 - val_loss: 1706.6184\n",
      "Epoch 288/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2246 - val_loss: 1706.6150\n",
      "Epoch 289/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2250 - val_loss: 1706.6122\n",
      "Epoch 290/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2254 - val_loss: 1706.6086\n",
      "Epoch 291/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2257 - val_loss: 1706.6056\n",
      "Epoch 292/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2261 - val_loss: 1706.6023\n",
      "Epoch 293/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2264 - val_loss: 1706.5990\n",
      "Epoch 294/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2267 - val_loss: 1706.5951\n",
      "Epoch 295/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2271 - val_loss: 1706.5916\n",
      "Epoch 296/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2274 - val_loss: 1706.5876\n",
      "Epoch 297/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2278 - val_loss: 1706.5837\n",
      "Epoch 298/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2281 - val_loss: 1706.5797\n",
      "Epoch 299/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2284 - val_loss: 1706.5759\n",
      "Epoch 300/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2286 - val_loss: 1706.5719\n",
      "Epoch 301/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2289 - val_loss: 1706.5677\n",
      "Epoch 302/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2292 - val_loss: 1706.5636\n",
      "Epoch 303/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2295 - val_loss: 1706.5596\n",
      "Epoch 304/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2298 - val_loss: 1706.5548\n",
      "Epoch 305/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2300 - val_loss: 1706.5502\n",
      "Epoch 306/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2303 - val_loss: 1706.5448\n",
      "Epoch 307/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2306 - val_loss: 1706.5399\n",
      "Epoch 308/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2308 - val_loss: 1706.5344\n",
      "Epoch 309/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2310 - val_loss: 1706.5292\n",
      "Epoch 310/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2313 - val_loss: 1706.5231\n",
      "Epoch 311/500\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 269.2316 - val_loss: 1706.5177\n",
      "Epoch 312/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2318 - val_loss: 1706.5125\n",
      "Epoch 313/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2320 - val_loss: 1706.5070\n",
      "Epoch 314/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2322 - val_loss: 1706.5011\n",
      "Epoch 315/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2325 - val_loss: 1706.4956\n",
      "Epoch 316/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2327 - val_loss: 1706.4902\n",
      "Epoch 317/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2329 - val_loss: 1706.4843\n",
      "Epoch 318/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2332 - val_loss: 1706.4786\n",
      "Epoch 319/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2333 - val_loss: 1706.4720\n",
      "Epoch 320/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2335 - val_loss: 1706.4656\n",
      "Epoch 321/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2337 - val_loss: 1706.4589\n",
      "Epoch 322/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2339 - val_loss: 1706.4523\n",
      "Epoch 323/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2340 - val_loss: 1706.4453\n",
      "Epoch 324/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2343 - val_loss: 1706.4392\n",
      "Epoch 325/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.2344 - val_loss: 1706.4318\n",
      "Epoch 326/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2346 - val_loss: 1706.4248\n",
      "Epoch 327/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2348 - val_loss: 1706.4175\n",
      "Epoch 328/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2349 - val_loss: 1706.4095\n",
      "Epoch 329/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2352 - val_loss: 1706.4016\n",
      "Epoch 330/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2353 - val_loss: 1706.3938\n",
      "Epoch 331/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2354 - val_loss: 1706.3857\n",
      "Epoch 332/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2356 - val_loss: 1706.3782\n",
      "Epoch 333/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2357 - val_loss: 1706.3698\n",
      "Epoch 334/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2358 - val_loss: 1706.3611\n",
      "Epoch 335/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2360 - val_loss: 1706.3527\n",
      "Epoch 336/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2361 - val_loss: 1706.3434\n",
      "Epoch 337/500\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 269.2362 - val_loss: 1706.3306\n",
      "Epoch 338/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2364 - val_loss: 1706.2195\n",
      "Epoch 339/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2360 - val_loss: 1706.2378\n",
      "Epoch 340/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2370 - val_loss: 1706.2299\n",
      "Epoch 341/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2368 - val_loss: 1706.2175\n",
      "Epoch 342/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2369 - val_loss: 1706.2036\n",
      "Epoch 343/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2370 - val_loss: 1706.1901\n",
      "Epoch 344/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2372 - val_loss: 1706.1764\n",
      "Epoch 345/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2373 - val_loss: 1706.1619\n",
      "Epoch 346/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2374 - val_loss: 1706.1472\n",
      "Epoch 347/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2375 - val_loss: 1706.1323\n",
      "Epoch 348/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2375 - val_loss: 1706.1160\n",
      "Epoch 349/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2377 - val_loss: 1706.0983\n",
      "Epoch 350/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2378 - val_loss: 1706.0806\n",
      "Epoch 351/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2379 - val_loss: 1706.0625\n",
      "Epoch 352/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2380 - val_loss: 1706.0444\n",
      "Epoch 353/500\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 269.2381 - val_loss: 1706.0259\n",
      "Epoch 354/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2382 - val_loss: 1706.0059\n",
      "Epoch 355/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2383 - val_loss: 1705.9840\n",
      "Epoch 356/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2384 - val_loss: 1705.9614\n",
      "Epoch 357/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 269.2385 - val_loss: 1705.9387\n",
      "Epoch 358/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2386 - val_loss: 1705.9153\n",
      "Epoch 359/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2386 - val_loss: 1705.8901\n",
      "Epoch 360/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2387 - val_loss: 1705.8632\n",
      "Epoch 361/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2388 - val_loss: 1705.8347\n",
      "Epoch 362/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2388 - val_loss: 1705.8052\n",
      "Epoch 363/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2389 - val_loss: 1705.7729\n",
      "Epoch 364/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2390 - val_loss: 1705.7389\n",
      "Epoch 365/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.2391 - val_loss: 1705.7026\n",
      "Epoch 366/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2392 - val_loss: 1705.6633\n",
      "Epoch 367/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2392 - val_loss: 1705.6210\n",
      "Epoch 368/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2393 - val_loss: 1705.5747\n",
      "Epoch 369/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2394 - val_loss: 1705.5234\n",
      "Epoch 370/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.2394 - val_loss: 1705.4662\n",
      "Epoch 371/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2395 - val_loss: 1705.4014\n",
      "Epoch 372/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2396 - val_loss: 1705.3276\n",
      "Epoch 373/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2396 - val_loss: 1705.2406\n",
      "Epoch 374/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2396 - val_loss: 1705.1337\n",
      "Epoch 375/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2397 - val_loss: 1704.9941\n",
      "Epoch 376/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2397 - val_loss: 1704.7925\n",
      "Epoch 377/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2398 - val_loss: 1704.4326\n",
      "Epoch 378/500\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 269.2399 - val_loss: 1703.2257\n",
      "Epoch 379/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 268.7018 - val_loss: 1630.4674\n",
      "Epoch 380/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 272.0495 - val_loss: 1633.9531\n",
      "Epoch 381/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 271.8784 - val_loss: 1639.2020\n",
      "Epoch 382/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 271.5600 - val_loss: 1644.2454\n",
      "Epoch 383/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 271.2681 - val_loss: 1648.9542\n",
      "Epoch 384/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 271.0132 - val_loss: 1653.3358\n",
      "Epoch 385/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 270.7917 - val_loss: 1657.4113\n",
      "Epoch 386/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 270.5992 - val_loss: 1661.2007\n",
      "Epoch 387/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 270.4319 - val_loss: 1664.7238\n",
      "Epoch 388/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 270.2862 - val_loss: 1667.9984\n",
      "Epoch 389/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 270.1594 - val_loss: 1671.0415\n",
      "Epoch 390/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 270.0487 - val_loss: 1673.8693\n",
      "Epoch 391/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.9522 - val_loss: 1676.4962\n",
      "Epoch 392/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.8679 - val_loss: 1678.9358\n",
      "Epoch 393/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.7942 - val_loss: 1681.2014\n",
      "Epoch 394/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.7297 - val_loss: 1683.3058\n",
      "Epoch 395/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.6731 - val_loss: 1685.2587\n",
      "Epoch 396/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.6237 - val_loss: 1687.0725\n",
      "Epoch 397/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.5801 - val_loss: 1688.7554\n",
      "Epoch 398/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.5419 - val_loss: 1690.3177\n",
      "Epoch 399/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.5082 - val_loss: 1691.7665\n",
      "Epoch 400/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.4786 - val_loss: 1693.1122\n",
      "Epoch 401/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.4524 - val_loss: 1694.3607\n",
      "Epoch 402/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.4292 - val_loss: 1695.5181\n",
      "Epoch 403/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.4089 - val_loss: 1696.5929\n",
      "Epoch 404/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.3907 - val_loss: 1697.5900\n",
      "Epoch 405/500\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 269.3746 - val_loss: 1698.5144\n",
      "Epoch 406/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.3604 - val_loss: 1699.3724\n",
      "Epoch 407/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.3477 - val_loss: 1700.1691\n",
      "Epoch 408/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.3364 - val_loss: 1700.9059\n",
      "Epoch 409/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.3263 - val_loss: 1701.5912\n",
      "Epoch 410/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.3173 - val_loss: 1702.2253\n",
      "Epoch 411/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.3091 - val_loss: 1702.8145\n",
      "Epoch 412/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.3019 - val_loss: 1703.3593\n",
      "Epoch 413/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2955 - val_loss: 1703.8652\n",
      "Epoch 414/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.2897 - val_loss: 1704.3348\n",
      "Epoch 415/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2845 - val_loss: 1704.7705\n",
      "Epoch 416/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2797 - val_loss: 1705.1730\n",
      "Epoch 417/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2756 - val_loss: 1705.5476\n",
      "Epoch 418/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2717 - val_loss: 1705.8951\n",
      "Epoch 419/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2682 - val_loss: 1706.2162\n",
      "Epoch 420/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.2650 - val_loss: 1706.5139\n",
      "Epoch 421/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2621 - val_loss: 1706.7902\n",
      "Epoch 422/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2596 - val_loss: 1707.0461\n",
      "Epoch 423/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2573 - val_loss: 1707.2833\n",
      "Epoch 424/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2552 - val_loss: 1707.5038\n",
      "Epoch 425/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2531 - val_loss: 1707.7073\n",
      "Epoch 426/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2514 - val_loss: 1707.8962\n",
      "Epoch 427/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2498 - val_loss: 1708.0710\n",
      "Epoch 428/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2483 - val_loss: 1708.2340\n",
      "Epoch 429/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2470 - val_loss: 1708.3839\n",
      "Epoch 430/500\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 269.2458 - val_loss: 1708.5234\n",
      "Epoch 431/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 269.2447 - val_loss: 1708.6530\n",
      "Epoch 432/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2436 - val_loss: 1708.7722\n",
      "Epoch 433/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2427 - val_loss: 1708.8824\n",
      "Epoch 434/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2418 - val_loss: 1708.9852\n",
      "Epoch 435/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2411 - val_loss: 1709.0809\n",
      "Epoch 436/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2404 - val_loss: 1709.1694\n",
      "Epoch 437/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2397 - val_loss: 1709.2517\n",
      "Epoch 438/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2390 - val_loss: 1709.3273\n",
      "Epoch 439/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2386 - val_loss: 1709.3983\n",
      "Epoch 440/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2380 - val_loss: 1709.4637\n",
      "Epoch 441/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2375 - val_loss: 1709.5239\n",
      "Epoch 442/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2371 - val_loss: 1709.5798\n",
      "Epoch 443/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2367 - val_loss: 1709.6316\n",
      "Epoch 444/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2363 - val_loss: 1709.6802\n",
      "Epoch 445/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2360 - val_loss: 1709.7246\n",
      "Epoch 446/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2357 - val_loss: 1709.7661\n",
      "Epoch 447/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2354 - val_loss: 1709.8048\n",
      "Epoch 448/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2351 - val_loss: 1709.8403\n",
      "Epoch 449/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2349 - val_loss: 1709.8733\n",
      "Epoch 450/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2346 - val_loss: 1709.9038\n",
      "Epoch 451/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2345 - val_loss: 1709.9323\n",
      "Epoch 452/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2343 - val_loss: 1709.9581\n",
      "Epoch 453/500\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 269.2341 - val_loss: 1709.9822\n",
      "Epoch 454/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2339 - val_loss: 1710.0045\n",
      "Epoch 455/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2338 - val_loss: 1710.0259\n",
      "Epoch 456/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2336 - val_loss: 1710.0447\n",
      "Epoch 457/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2335 - val_loss: 1710.0624\n",
      "Epoch 458/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2334 - val_loss: 1710.0785\n",
      "Epoch 459/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2333 - val_loss: 1710.0939\n",
      "Epoch 460/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.2332 - val_loss: 1710.1082\n",
      "Epoch 461/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2331 - val_loss: 1710.1208\n",
      "Epoch 462/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2331 - val_loss: 1710.1337\n",
      "Epoch 463/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2330 - val_loss: 1710.1447\n",
      "Epoch 464/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2328 - val_loss: 1710.1554\n",
      "Epoch 465/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2328 - val_loss: 1710.1652\n",
      "Epoch 466/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2328 - val_loss: 1710.1743\n",
      "Epoch 467/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2328 - val_loss: 1710.1821\n",
      "Epoch 468/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2327 - val_loss: 1710.1896\n",
      "Epoch 469/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2326 - val_loss: 1710.1969\n",
      "Epoch 470/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2326 - val_loss: 1710.2028\n",
      "Epoch 471/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2325 - val_loss: 1710.2087\n",
      "Epoch 472/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2325 - val_loss: 1710.2144\n",
      "Epoch 473/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2325 - val_loss: 1710.2198\n",
      "Epoch 474/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2324 - val_loss: 1710.2234\n",
      "Epoch 475/500\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 269.2325 - val_loss: 1710.2290\n",
      "Epoch 476/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2325 - val_loss: 1710.2322\n",
      "Epoch 477/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 269.2324 - val_loss: 1710.2368\n",
      "Epoch 478/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2323 - val_loss: 1710.2393\n",
      "Epoch 479/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2324 - val_loss: 1710.2417\n",
      "Epoch 480/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2324 - val_loss: 1710.2456\n",
      "Epoch 481/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2324 - val_loss: 1710.2483\n",
      "Epoch 482/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2324 - val_loss: 1710.2512\n",
      "Epoch 483/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2324 - val_loss: 1710.2532\n",
      "Epoch 484/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2323 - val_loss: 1710.2559\n",
      "Epoch 485/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2323 - val_loss: 1710.2578\n",
      "Epoch 486/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 269.2324 - val_loss: 1710.2592\n",
      "Epoch 487/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2323 - val_loss: 1710.2612\n",
      "Epoch 488/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2323 - val_loss: 1710.2631\n",
      "Epoch 489/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2323 - val_loss: 1710.2648\n",
      "Epoch 490/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2323 - val_loss: 1710.2672\n",
      "Epoch 491/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2323 - val_loss: 1710.2682\n",
      "Epoch 492/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2322 - val_loss: 1710.2682\n",
      "Epoch 493/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2323 - val_loss: 1710.2689\n",
      "Epoch 494/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2323 - val_loss: 1710.2689\n",
      "Epoch 495/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2324 - val_loss: 1710.2698\n",
      "Epoch 496/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2323 - val_loss: 1710.2697\n",
      "Epoch 497/500\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 269.2322 - val_loss: 1710.2694\n",
      "Epoch 498/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2322 - val_loss: 1710.2694\n",
      "Epoch 499/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2323 - val_loss: 1710.2693\n",
      "Epoch 500/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.2323 - val_loss: 1710.2688\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1.5\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 422ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[63.4710784 , 63.2930672 , 63.0661765 , 62.8392857 , 69.9994965 ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.24030374,\n",
       "         0.        ,  0.19137293,  0.28250539, 63.7913399 , 63.6148693 ,\n",
       "        63.4383987 ,  0.        ,  0.35284084, 64.6176471 , 64.1134454 ,\n",
       "        63.8632353 , 63.6867647 , 63.5102941 , 63.3338235 , 63.1165966 ,\n",
       "        62.8897059 , 62.6628151 ,  0.        ,  0.78689283, 63.5821895 ,\n",
       "        63.405719  , 63.2090336 , 62.9821429 , 62.7552521 , 66.9521475 ,\n",
       "        66.195845  , 64.879085  ,  0.        ,  0.21814112,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.44305944,  0.60964227,\n",
       "         0.        ,  0.14570689, 62.9401261 , 62.7132353 ,  0.        ,\n",
       "         0.        , 63.6214052 , 63.4449346 , 63.2594538 , 63.032563  ,\n",
       "        62.8056723 , 67.0841503 , 66.3639122 , 65.2152194 ,  0.11628367,\n",
       "         0.26059347,  0.59191072, 62.8981092 , 62.6712185 , 66.7560691 ,\n",
       "        65.9995332 , 64.4869281 , 66.3545752 , 65.1965453 , 63.8893791 ,\n",
       "         0.13929887,  0.        ,  0.        , 60.7500458 ,  0.62970763,\n",
       "         0.        ,  0.10410842,  0.4728424 ,  0.53572208,  0.35683295,\n",
       "        60.84694672,  0.13448396,  0.58657598,  1.079862  ,  0.37532416,\n",
       "         0.40369707,  0.        ,  0.3264246 ,  0.34291732,  0.        ,\n",
       "         0.        ,  0.        ,  0.20774302,  0.        ,  0.24713057,\n",
       "         0.19906227,  0.        ,  0.38143501,  0.1252715 ,  0.16226204]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54.37749539, 54.36875043, 54.36000547, 54.3512605 , 54.34251554,\n",
       "       54.33377058, 54.32502562, 54.31628066, 54.3075357 , 54.29879074,\n",
       "       54.29004577, 54.28130081, 54.27255585, 54.26381089, 54.25506593,\n",
       "       54.24632097, 54.23757601, 54.22883104, 54.22008608, 54.21134112,\n",
       "       54.20259616, 54.1938512 , 54.18510624, 54.17636128, 54.16761631,\n",
       "       54.15887135, 54.15012639, 54.14138143, 54.13263647, 54.12389151,\n",
       "       54.11514655, 54.10640159, 54.09765662, 54.08891166, 54.0801667 ,\n",
       "       54.07142174, 54.06267678, 54.05393182, 54.04518686, 54.03644189,\n",
       "       54.02769693, 54.01895197, 54.01020701, 54.00146205, 53.99271709,\n",
       "       53.98397213, 53.97522716, 53.9664822 , 53.95773724, 53.94899228,\n",
       "       53.94024732, 53.93150236, 53.9227574 , 53.91401243, 53.90526747,\n",
       "       53.89652251, 53.88777755, 53.87903259, 53.87028763, 53.86154267,\n",
       "       53.8527977 , 53.84405274, 53.83530778, 53.82656282, 53.81781786,\n",
       "       53.8090729 , 53.80032794, 53.79158297, 53.78283801, 53.77409305,\n",
       "       53.76534809, 53.75660313, 53.74785817, 53.73911321, 53.73036824,\n",
       "       53.72162328, 53.71287832, 53.70413336, 53.6953884 , 53.68664344,\n",
       "       53.67789848, 53.66915352, 53.66040855, 53.65166359, 53.64291863,\n",
       "       53.63417367, 53.62542871, 53.61668375, 53.60793879, 53.59919382,\n",
       "       53.59044886, 53.5817039 , 53.57295894, 53.56421398, 53.55546902,\n",
       "       53.54672406, 53.53797909, 53.52923413, 53.52048917, 53.51174421])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.369902050330566\n",
      "33.990846040514406\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
