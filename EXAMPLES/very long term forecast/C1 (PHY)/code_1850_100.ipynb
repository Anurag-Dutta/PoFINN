{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1945    58.385317\n",
       "1946    58.369444\n",
       "1947    58.353571\n",
       "1948    58.337698\n",
       "1949    58.321825\n",
       "Name: C1, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_1850_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1845     0.000000\n",
       "1846     0.439173\n",
       "1847     0.000000\n",
       "1848     0.000000\n",
       "1849     0.000000\n",
       "Name: C1, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1850)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 1, 251) (1400, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "18/18 [==============================] - 2s 36ms/step - loss: 4500.8672 - val_loss: 3061.6035\n",
      "Epoch 2/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 4379.6841 - val_loss: 2946.9136\n",
      "Epoch 3/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 4285.0796 - val_loss: 2894.7588\n",
      "Epoch 4/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 4229.4302 - val_loss: 2856.3718\n",
      "Epoch 5/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4168.0669 - val_loss: 2814.5120\n",
      "Epoch 6/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4107.4316 - val_loss: 2773.7317\n",
      "Epoch 7/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 4047.9026 - val_loss: 2733.7627\n",
      "Epoch 8/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3989.3513 - val_loss: 2694.5088\n",
      "Epoch 9/500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 3931.6687 - val_loss: 2655.9077\n",
      "Epoch 10/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 3874.7822 - val_loss: 2617.9329\n",
      "Epoch 11/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 3818.6433 - val_loss: 2580.9648\n",
      "Epoch 12/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3763.2183 - val_loss: 2543.5627\n",
      "Epoch 13/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3708.4827 - val_loss: 2507.2341\n",
      "Epoch 14/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3654.4153 - val_loss: 2471.4312\n",
      "Epoch 15/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3601.0012 - val_loss: 2436.1431\n",
      "Epoch 16/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3548.2258 - val_loss: 2401.3599\n",
      "Epoch 17/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3496.0793 - val_loss: 2367.0735\n",
      "Epoch 18/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3444.5508 - val_loss: 2333.2754\n",
      "Epoch 19/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3393.6301 - val_loss: 2299.9597\n",
      "Epoch 20/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3343.3103 - val_loss: 2267.1196\n",
      "Epoch 21/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3293.5828 - val_loss: 2234.7488\n",
      "Epoch 22/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3244.4412 - val_loss: 2202.8423\n",
      "Epoch 23/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3195.8779 - val_loss: 2171.3936\n",
      "Epoch 24/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3147.8875 - val_loss: 2140.3984\n",
      "Epoch 25/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3100.4631 - val_loss: 2109.8513\n",
      "Epoch 26/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3053.5991 - val_loss: 2079.7478\n",
      "Epoch 27/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3007.2898 - val_loss: 2050.0833\n",
      "Epoch 28/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2961.5295 - val_loss: 2020.8527\n",
      "Epoch 29/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2916.3132 - val_loss: 1992.0522\n",
      "Epoch 30/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2871.6353 - val_loss: 1963.6775\n",
      "Epoch 31/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2827.4917 - val_loss: 1935.7244\n",
      "Epoch 32/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2783.8762 - val_loss: 1908.1880\n",
      "Epoch 33/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2740.7852 - val_loss: 1881.0649\n",
      "Epoch 34/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2698.2126 - val_loss: 1854.3510\n",
      "Epoch 35/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2656.1553 - val_loss: 1828.0422\n",
      "Epoch 36/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2614.6069 - val_loss: 1802.1348\n",
      "Epoch 37/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2573.5642 - val_loss: 1776.6250\n",
      "Epoch 38/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2533.0222 - val_loss: 1751.5085\n",
      "Epoch 39/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2492.9768 - val_loss: 1726.7822\n",
      "Epoch 40/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2453.4236 - val_loss: 1702.4421\n",
      "Epoch 41/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2414.3577 - val_loss: 1678.4847\n",
      "Epoch 42/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2375.7751 - val_loss: 1654.9059\n",
      "Epoch 43/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2337.6724 - val_loss: 1631.7029\n",
      "Epoch 44/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2300.0444 - val_loss: 1608.8715\n",
      "Epoch 45/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2262.8877 - val_loss: 1586.4084\n",
      "Epoch 46/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2226.1975 - val_loss: 1564.3102\n",
      "Epoch 47/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2189.9702 - val_loss: 1542.5732\n",
      "Epoch 48/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2154.2019 - val_loss: 1521.1940\n",
      "Epoch 49/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2118.8889 - val_loss: 1500.1699\n",
      "Epoch 50/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2084.0264 - val_loss: 1479.4965\n",
      "Epoch 51/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2049.6106 - val_loss: 1459.1710\n",
      "Epoch 52/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2015.6384 - val_loss: 1439.1904\n",
      "Epoch 53/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1982.1058 - val_loss: 1419.5510\n",
      "Epoch 54/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1949.0087 - val_loss: 1400.2499\n",
      "Epoch 55/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1916.3431 - val_loss: 1381.2843\n",
      "Epoch 56/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1884.1056 - val_loss: 1362.6510\n",
      "Epoch 57/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1852.2924 - val_loss: 1344.3479\n",
      "Epoch 58/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1820.8999 - val_loss: 1326.3734\n",
      "Epoch 59/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1789.9243 - val_loss: 1308.7323\n",
      "Epoch 60/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1759.3619 - val_loss: 1291.4492\n",
      "Epoch 61/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1725.6938 - val_loss: 1268.2217\n",
      "Epoch 62/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1687.3928 - val_loss: 1248.3368\n",
      "Epoch 63/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1653.1542 - val_loss: 1229.4634\n",
      "Epoch 64/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1620.3666 - val_loss: 1211.4341\n",
      "Epoch 65/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1588.7081 - val_loss: 1194.0692\n",
      "Epoch 66/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1557.9427 - val_loss: 1177.2632\n",
      "Epoch 67/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1527.9320 - val_loss: 1160.9517\n",
      "Epoch 68/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1498.5892 - val_loss: 1145.0922\n",
      "Epoch 69/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1469.8561 - val_loss: 1129.6537\n",
      "Epoch 70/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1441.6912 - val_loss: 1114.6135\n",
      "Epoch 71/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1414.0621 - val_loss: 1099.9541\n",
      "Epoch 72/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1386.9447 - val_loss: 1085.6604\n",
      "Epoch 73/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1360.3182 - val_loss: 1071.7198\n",
      "Epoch 74/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1334.1656 - val_loss: 1058.1218\n",
      "Epoch 75/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1308.4727 - val_loss: 1044.8574\n",
      "Epoch 76/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1283.2264 - val_loss: 1031.9176\n",
      "Epoch 77/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1258.4159 - val_loss: 1019.2953\n",
      "Epoch 78/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1234.0309 - val_loss: 1006.9837\n",
      "Epoch 79/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1210.0621 - val_loss: 994.9753\n",
      "Epoch 80/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1186.5013 - val_loss: 983.2653\n",
      "Epoch 81/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1163.3408 - val_loss: 971.8477\n",
      "Epoch 82/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1140.5735 - val_loss: 960.7167\n",
      "Epoch 83/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1118.1920 - val_loss: 949.8676\n",
      "Epoch 84/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1096.1908 - val_loss: 939.2960\n",
      "Epoch 85/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1074.5631 - val_loss: 928.9963\n",
      "Epoch 86/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1053.3031 - val_loss: 918.9645\n",
      "Epoch 87/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1032.4058 - val_loss: 909.1962\n",
      "Epoch 88/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1011.8651 - val_loss: 899.6870\n",
      "Epoch 89/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 991.6761 - val_loss: 890.4331\n",
      "Epoch 90/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 971.8345 - val_loss: 881.4303\n",
      "Epoch 91/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 952.3347 - val_loss: 872.6747\n",
      "Epoch 92/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 933.1726 - val_loss: 864.1624\n",
      "Epoch 93/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 914.3427 - val_loss: 855.8898\n",
      "Epoch 94/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 895.8414 - val_loss: 847.8531\n",
      "Epoch 95/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 877.6643 - val_loss: 840.0486\n",
      "Epoch 96/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 859.8068 - val_loss: 832.4732\n",
      "Epoch 97/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 842.2646 - val_loss: 825.1230\n",
      "Epoch 98/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 825.0342 - val_loss: 817.9944\n",
      "Epoch 99/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 808.1112 - val_loss: 811.0845\n",
      "Epoch 100/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 791.4913 - val_loss: 804.3896\n",
      "Epoch 101/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 775.1713 - val_loss: 797.9062\n",
      "Epoch 102/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 759.1469 - val_loss: 791.6315\n",
      "Epoch 103/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 743.4148 - val_loss: 785.5617\n",
      "Epoch 104/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 727.9705 - val_loss: 779.6943\n",
      "Epoch 105/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 712.8110 - val_loss: 774.0252\n",
      "Epoch 106/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 697.9325 - val_loss: 768.5521\n",
      "Epoch 107/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 683.3314 - val_loss: 763.2715\n",
      "Epoch 108/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 669.0039 - val_loss: 758.1802\n",
      "Epoch 109/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 654.9465 - val_loss: 753.2751\n",
      "Epoch 110/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 641.1560 - val_loss: 748.5536\n",
      "Epoch 111/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 627.6290 - val_loss: 744.0120\n",
      "Epoch 112/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 614.3615 - val_loss: 739.6479\n",
      "Epoch 113/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 601.3507 - val_loss: 735.4578\n",
      "Epoch 114/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 588.5930 - val_loss: 731.4395\n",
      "Epoch 115/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 576.0851 - val_loss: 727.5892\n",
      "Epoch 116/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 563.8239 - val_loss: 723.9045\n",
      "Epoch 117/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 551.8060 - val_loss: 720.3826\n",
      "Epoch 118/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 540.0281 - val_loss: 717.0200\n",
      "Epoch 119/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 528.4871 - val_loss: 713.8144\n",
      "Epoch 120/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 517.1797 - val_loss: 710.7629\n",
      "Epoch 121/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 506.1027 - val_loss: 707.8624\n",
      "Epoch 122/500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 495.2528 - val_loss: 705.1105\n",
      "Epoch 123/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 484.6275 - val_loss: 702.5040\n",
      "Epoch 124/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 474.2231 - val_loss: 700.0405\n",
      "Epoch 125/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 464.0367 - val_loss: 697.7169\n",
      "Epoch 126/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 454.0654 - val_loss: 695.5307\n",
      "Epoch 127/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 444.3059 - val_loss: 693.4791\n",
      "Epoch 128/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 434.7554 - val_loss: 691.5594\n",
      "Epoch 129/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 425.4107 - val_loss: 689.7690\n",
      "Epoch 130/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 416.2690 - val_loss: 688.1049\n",
      "Epoch 131/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 407.3273 - val_loss: 686.5649\n",
      "Epoch 132/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 398.5826 - val_loss: 685.1462\n",
      "Epoch 133/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 390.0319 - val_loss: 683.8459\n",
      "Epoch 134/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 381.6725 - val_loss: 682.6616\n",
      "Epoch 135/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 373.5013 - val_loss: 681.5909\n",
      "Epoch 136/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 365.5157 - val_loss: 680.6311\n",
      "Epoch 137/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 357.7126 - val_loss: 679.7796\n",
      "Epoch 138/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 350.0892 - val_loss: 679.0337\n",
      "Epoch 139/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 342.6428 - val_loss: 678.3912\n",
      "Epoch 140/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 335.3705 - val_loss: 677.8493\n",
      "Epoch 141/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 328.2697 - val_loss: 677.4058\n",
      "Epoch 142/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 321.3374 - val_loss: 677.0579\n",
      "Epoch 143/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 314.5711 - val_loss: 676.8035\n",
      "Epoch 144/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 307.9679 - val_loss: 676.6398\n",
      "Epoch 145/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 301.5251 - val_loss: 676.5648\n",
      "Epoch 146/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 295.2402 - val_loss: 676.5756\n",
      "Epoch 147/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 289.1105 - val_loss: 676.6703\n",
      "Epoch 148/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 283.1332 - val_loss: 676.8463\n",
      "Epoch 149/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 277.3058 - val_loss: 677.1013\n",
      "Epoch 150/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 271.6255 - val_loss: 677.4328\n",
      "Epoch 151/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 266.0901 - val_loss: 677.8388\n",
      "Epoch 152/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 260.6966 - val_loss: 678.3168\n",
      "Epoch 153/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 255.4426 - val_loss: 678.8647\n",
      "Epoch 154/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 250.3258 - val_loss: 679.4800\n",
      "Epoch 155/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 245.3434 - val_loss: 680.1608\n",
      "Epoch 156/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 240.4929 - val_loss: 680.9047\n",
      "Epoch 157/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 235.7720 - val_loss: 681.7097\n",
      "Epoch 158/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 231.1782 - val_loss: 682.5733\n",
      "Epoch 159/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 226.7092 - val_loss: 683.4936\n",
      "Epoch 160/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 222.3624 - val_loss: 684.4685\n",
      "Epoch 161/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 218.1354 - val_loss: 685.4958\n",
      "Epoch 162/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 214.0259 - val_loss: 686.5735\n",
      "Epoch 163/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 210.0316 - val_loss: 687.6996\n",
      "Epoch 164/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 206.1500 - val_loss: 688.8719\n",
      "Epoch 165/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 202.3790 - val_loss: 690.0887\n",
      "Epoch 166/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 198.7162 - val_loss: 691.3476\n",
      "Epoch 167/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 195.1594 - val_loss: 692.6472\n",
      "Epoch 168/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 191.7063 - val_loss: 693.9852\n",
      "Epoch 169/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 188.3547 - val_loss: 695.3597\n",
      "Epoch 170/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 185.1024 - val_loss: 696.7692\n",
      "Epoch 171/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 181.9472 - val_loss: 698.2114\n",
      "Epoch 172/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 178.8871 - val_loss: 699.6846\n",
      "Epoch 173/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 175.9199 - val_loss: 701.1871\n",
      "Epoch 174/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 173.0436 - val_loss: 702.7171\n",
      "Epoch 175/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 170.2560 - val_loss: 704.2730\n",
      "Epoch 176/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 167.5552 - val_loss: 705.8528\n",
      "Epoch 177/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 164.9388 - val_loss: 707.4553\n",
      "Epoch 178/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 162.4051 - val_loss: 709.0781\n",
      "Epoch 179/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 159.9521 - val_loss: 710.7205\n",
      "Epoch 180/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 157.5778 - val_loss: 712.3806\n",
      "Epoch 181/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 155.2802 - val_loss: 714.0563\n",
      "Epoch 182/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 153.0578 - val_loss: 715.7464\n",
      "Epoch 183/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 150.9085 - val_loss: 717.4495\n",
      "Epoch 184/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 148.8303 - val_loss: 719.1642\n",
      "Epoch 185/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 146.8216 - val_loss: 720.8888\n",
      "Epoch 186/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 144.8804 - val_loss: 722.6221\n",
      "Epoch 187/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 143.0052 - val_loss: 724.3626\n",
      "Epoch 188/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 141.1939 - val_loss: 726.1091\n",
      "Epoch 189/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 139.4450 - val_loss: 727.8604\n",
      "Epoch 190/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 137.7569 - val_loss: 729.6146\n",
      "Epoch 191/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 136.1279 - val_loss: 731.3712\n",
      "Epoch 192/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 134.5562 - val_loss: 733.1287\n",
      "Epoch 193/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 133.0403 - val_loss: 734.8855\n",
      "Epoch 194/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 131.5788 - val_loss: 736.6410\n",
      "Epoch 195/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 130.1699 - val_loss: 738.3940\n",
      "Epoch 196/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 128.8121 - val_loss: 740.1432\n",
      "Epoch 197/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 127.5041 - val_loss: 741.8879\n",
      "Epoch 198/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 126.2442 - val_loss: 743.6268\n",
      "Epoch 199/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 125.0312 - val_loss: 745.3589\n",
      "Epoch 200/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 123.8635 - val_loss: 747.0833\n",
      "Epoch 201/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 122.7397 - val_loss: 748.7990\n",
      "Epoch 202/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 121.6587 - val_loss: 750.5049\n",
      "Epoch 203/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 120.6191 - val_loss: 752.2008\n",
      "Epoch 204/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 119.6194 - val_loss: 753.8854\n",
      "Epoch 205/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 118.6583 - val_loss: 755.5582\n",
      "Epoch 206/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 117.7348 - val_loss: 757.2180\n",
      "Epoch 207/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 116.8477 - val_loss: 758.8646\n",
      "Epoch 208/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 115.9955 - val_loss: 760.4968\n",
      "Epoch 209/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 115.1773 - val_loss: 762.1141\n",
      "Epoch 210/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 114.3920 - val_loss: 763.7158\n",
      "Epoch 211/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 113.6383 - val_loss: 765.3015\n",
      "Epoch 212/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 112.9154 - val_loss: 766.8705\n",
      "Epoch 213/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 112.2219 - val_loss: 768.4221\n",
      "Epoch 214/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 111.5570 - val_loss: 769.9566\n",
      "Epoch 215/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 110.9194 - val_loss: 771.4725\n",
      "Epoch 216/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 110.3085 - val_loss: 772.9697\n",
      "Epoch 217/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.7232 - val_loss: 774.4478\n",
      "Epoch 218/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.1626 - val_loss: 775.9067\n",
      "Epoch 219/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 108.6257 - val_loss: 777.3454\n",
      "Epoch 220/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 108.1118 - val_loss: 778.7646\n",
      "Epoch 221/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 107.6198 - val_loss: 780.1627\n",
      "Epoch 222/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 107.1491 - val_loss: 781.5400\n",
      "Epoch 223/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.6988 - val_loss: 782.8963\n",
      "Epoch 224/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.2681 - val_loss: 784.2314\n",
      "Epoch 225/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 105.8563 - val_loss: 785.5453\n",
      "Epoch 226/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 105.4627 - val_loss: 786.8371\n",
      "Epoch 227/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 105.0865 - val_loss: 788.1071\n",
      "Epoch 228/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.7270 - val_loss: 789.3557\n",
      "Epoch 229/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.3836 - val_loss: 790.5814\n",
      "Epoch 230/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.0557 - val_loss: 791.7855\n",
      "Epoch 231/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 103.7425 - val_loss: 792.9675\n",
      "Epoch 232/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 103.4435 - val_loss: 794.1265\n",
      "Epoch 233/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 103.1582 - val_loss: 795.2638\n",
      "Epoch 234/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 102.8859 - val_loss: 796.3788\n",
      "Epoch 235/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 102.6261 - val_loss: 797.4713\n",
      "Epoch 236/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 102.3783 - val_loss: 798.5419\n",
      "Epoch 237/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 102.1419 - val_loss: 799.5897\n",
      "Epoch 238/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.9166 - val_loss: 800.6156\n",
      "Epoch 239/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.7017 - val_loss: 801.6194\n",
      "Epoch 240/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 101.4969 - val_loss: 802.6015\n",
      "Epoch 241/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.3017 - val_loss: 803.5618\n",
      "Epoch 242/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.1157 - val_loss: 804.5005\n",
      "Epoch 243/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 100.9384 - val_loss: 805.4174\n",
      "Epoch 244/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 100.7696 - val_loss: 806.3129\n",
      "Epoch 245/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 100.6088 - val_loss: 807.1876\n",
      "Epoch 246/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 100.4556 - val_loss: 808.0412\n",
      "Epoch 247/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 100.3098 - val_loss: 808.8738\n",
      "Epoch 248/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 100.1709 - val_loss: 809.6863\n",
      "Epoch 249/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 100.0386 - val_loss: 810.4782\n",
      "Epoch 250/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 99.9128 - val_loss: 811.2501\n",
      "Epoch 251/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 99.7929 - val_loss: 812.0020\n",
      "Epoch 252/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 99.6789 - val_loss: 812.7339\n",
      "Epoch 253/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 99.5704 - val_loss: 813.4469\n",
      "Epoch 254/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 99.4671 - val_loss: 814.1407\n",
      "Epoch 255/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 99.3689 - val_loss: 814.8161\n",
      "Epoch 256/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 99.2753 - val_loss: 815.4725\n",
      "Epoch 257/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 99.1864 - val_loss: 816.1110\n",
      "Epoch 258/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 99.1017 - val_loss: 816.7313\n",
      "Epoch 259/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 99.0212 - val_loss: 817.3337\n",
      "Epoch 260/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 98.9446 - val_loss: 817.9193\n",
      "Epoch 261/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 98.8717 - val_loss: 818.4877\n",
      "Epoch 262/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 98.8024 - val_loss: 819.0389\n",
      "Epoch 263/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 98.7364 - val_loss: 819.5739\n",
      "Epoch 264/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 98.6737 - val_loss: 820.0928\n",
      "Epoch 265/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 98.6141 - val_loss: 820.5963\n",
      "Epoch 266/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 98.5573 - val_loss: 821.0840\n",
      "Epoch 267/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 98.5034 - val_loss: 821.5568\n",
      "Epoch 268/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 98.4520 - val_loss: 822.0150\n",
      "Epoch 269/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 98.4031 - val_loss: 822.4583\n",
      "Epoch 270/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 98.3566 - val_loss: 822.8871\n",
      "Epoch 271/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 98.3125 - val_loss: 823.3026\n",
      "Epoch 272/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 98.2704 - val_loss: 823.7042\n",
      "Epoch 273/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 98.2304 - val_loss: 824.0924\n",
      "Epoch 274/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 98.1925 - val_loss: 824.4679\n",
      "Epoch 275/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 98.1563 - val_loss: 824.8308\n",
      "Epoch 276/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 98.1219 - val_loss: 825.1815\n",
      "Epoch 277/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 98.0891 - val_loss: 825.5201\n",
      "Epoch 278/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 98.0580 - val_loss: 825.8471\n",
      "Epoch 279/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 98.0283 - val_loss: 826.1630\n",
      "Epoch 280/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 98.0001 - val_loss: 826.4677\n",
      "Epoch 281/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.9733 - val_loss: 826.7613\n",
      "Epoch 282/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.9478 - val_loss: 827.0447\n",
      "Epoch 283/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.9235 - val_loss: 827.3176\n",
      "Epoch 284/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.9004 - val_loss: 827.5807\n",
      "Epoch 285/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.8784 - val_loss: 827.8342\n",
      "Epoch 286/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.8576 - val_loss: 828.0784\n",
      "Epoch 287/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.8377 - val_loss: 828.3135\n",
      "Epoch 288/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.8187 - val_loss: 828.5402\n",
      "Epoch 289/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 97.8007 - val_loss: 828.7574\n",
      "Epoch 290/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.7836 - val_loss: 828.9669\n",
      "Epoch 291/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.7673 - val_loss: 829.1685\n",
      "Epoch 292/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.7518 - val_loss: 829.3622\n",
      "Epoch 293/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.7370 - val_loss: 829.5481\n",
      "Epoch 294/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.7230 - val_loss: 829.7271\n",
      "Epoch 295/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.7097 - val_loss: 829.8989\n",
      "Epoch 296/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.6970 - val_loss: 830.0637\n",
      "Epoch 297/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.6849 - val_loss: 830.2224\n",
      "Epoch 298/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.6734 - val_loss: 830.3741\n",
      "Epoch 299/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.6625 - val_loss: 830.5201\n",
      "Epoch 300/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.6521 - val_loss: 830.6599\n",
      "Epoch 301/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.6422 - val_loss: 830.7939\n",
      "Epoch 302/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.6328 - val_loss: 830.9224\n",
      "Epoch 303/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.6239 - val_loss: 831.0458\n",
      "Epoch 304/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.6153 - val_loss: 831.1638\n",
      "Epoch 305/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.6073 - val_loss: 831.2769\n",
      "Epoch 306/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.5996 - val_loss: 831.3854\n",
      "Epoch 307/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.5923 - val_loss: 831.4891\n",
      "Epoch 308/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.5853 - val_loss: 831.5884\n",
      "Epoch 309/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.5787 - val_loss: 831.6833\n",
      "Epoch 310/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.5725 - val_loss: 831.7740\n",
      "Epoch 311/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.5665 - val_loss: 831.8605\n",
      "Epoch 312/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.5609 - val_loss: 831.9438\n",
      "Epoch 313/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.5555 - val_loss: 832.0230\n",
      "Epoch 314/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.5504 - val_loss: 832.0986\n",
      "Epoch 315/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 97.5456 - val_loss: 832.1709\n",
      "Epoch 316/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 97.5410 - val_loss: 832.2397\n",
      "Epoch 317/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.5367 - val_loss: 832.3055\n",
      "Epoch 318/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.5326 - val_loss: 832.3688\n",
      "Epoch 319/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.5286 - val_loss: 832.4287\n",
      "Epoch 320/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.5249 - val_loss: 832.4865\n",
      "Epoch 321/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.5214 - val_loss: 832.5408\n",
      "Epoch 322/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.5181 - val_loss: 832.5931\n",
      "Epoch 323/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.5149 - val_loss: 832.6428\n",
      "Epoch 324/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.5119 - val_loss: 832.6905\n",
      "Epoch 325/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.5091 - val_loss: 832.7358\n",
      "Epoch 326/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.5063 - val_loss: 832.7784\n",
      "Epoch 327/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.5039 - val_loss: 832.8195\n",
      "Epoch 328/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.5015 - val_loss: 832.8588\n",
      "Epoch 329/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4991 - val_loss: 832.8959\n",
      "Epoch 330/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4970 - val_loss: 832.9312\n",
      "Epoch 331/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4950 - val_loss: 832.9647\n",
      "Epoch 332/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4931 - val_loss: 832.9967\n",
      "Epoch 333/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4913 - val_loss: 833.0271\n",
      "Epoch 334/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4896 - val_loss: 833.0557\n",
      "Epoch 335/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4880 - val_loss: 833.0836\n",
      "Epoch 336/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4865 - val_loss: 833.1095\n",
      "Epoch 337/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4851 - val_loss: 833.1345\n",
      "Epoch 338/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4837 - val_loss: 833.1576\n",
      "Epoch 339/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4825 - val_loss: 833.1801\n",
      "Epoch 340/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4813 - val_loss: 833.2015\n",
      "Epoch 341/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4802 - val_loss: 833.2217\n",
      "Epoch 342/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 97.4792 - val_loss: 833.2413\n",
      "Epoch 343/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4781 - val_loss: 833.2595\n",
      "Epoch 344/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4772 - val_loss: 833.2768\n",
      "Epoch 345/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4763 - val_loss: 833.2930\n",
      "Epoch 346/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4755 - val_loss: 833.3085\n",
      "Epoch 347/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4748 - val_loss: 833.3232\n",
      "Epoch 348/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4740 - val_loss: 833.3370\n",
      "Epoch 349/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4734 - val_loss: 833.3505\n",
      "Epoch 350/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4727 - val_loss: 833.3629\n",
      "Epoch 351/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4722 - val_loss: 833.3749\n",
      "Epoch 352/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4716 - val_loss: 833.3858\n",
      "Epoch 353/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4712 - val_loss: 833.3967\n",
      "Epoch 354/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4707 - val_loss: 833.4066\n",
      "Epoch 355/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4703 - val_loss: 833.4160\n",
      "Epoch 356/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4699 - val_loss: 833.4248\n",
      "Epoch 357/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4696 - val_loss: 833.4335\n",
      "Epoch 358/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4693 - val_loss: 833.4414\n",
      "Epoch 359/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4690 - val_loss: 833.4492\n",
      "Epoch 360/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 97.4687 - val_loss: 833.4566\n",
      "Epoch 361/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4684 - val_loss: 833.4630\n",
      "Epoch 362/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4681 - val_loss: 833.4694\n",
      "Epoch 363/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4680 - val_loss: 833.4755\n",
      "Epoch 364/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4678 - val_loss: 833.4810\n",
      "Epoch 365/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4677 - val_loss: 833.4865\n",
      "Epoch 366/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4674 - val_loss: 833.4914\n",
      "Epoch 367/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4673 - val_loss: 833.4962\n",
      "Epoch 368/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4672 - val_loss: 833.5009\n",
      "Epoch 369/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4671 - val_loss: 833.5050\n",
      "Epoch 370/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4670 - val_loss: 833.5090\n",
      "Epoch 371/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4669 - val_loss: 833.5127\n",
      "Epoch 372/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4669 - val_loss: 833.5166\n",
      "Epoch 373/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 97.4668 - val_loss: 833.5198\n",
      "Epoch 374/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4668 - val_loss: 833.5231\n",
      "Epoch 375/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4668 - val_loss: 833.5260\n",
      "Epoch 376/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4668 - val_loss: 833.5290\n",
      "Epoch 377/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4668 - val_loss: 833.5315\n",
      "Epoch 378/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4667 - val_loss: 833.5341\n",
      "Epoch 379/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4668 - val_loss: 833.5365\n",
      "Epoch 380/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4667 - val_loss: 833.5388\n",
      "Epoch 381/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4667 - val_loss: 833.5404\n",
      "Epoch 382/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4668 - val_loss: 833.5424\n",
      "Epoch 383/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4668 - val_loss: 833.5443\n",
      "Epoch 384/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4669 - val_loss: 833.5457\n",
      "Epoch 385/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4669 - val_loss: 833.5471\n",
      "Epoch 386/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4670 - val_loss: 833.5485\n",
      "Epoch 387/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4670 - val_loss: 833.5498\n",
      "Epoch 388/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4671 - val_loss: 833.5508\n",
      "Epoch 389/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4672 - val_loss: 833.5521\n",
      "Epoch 390/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4673 - val_loss: 833.5535\n",
      "Epoch 391/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4673 - val_loss: 833.5544\n",
      "Epoch 392/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4674 - val_loss: 833.5555\n",
      "Epoch 393/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4675 - val_loss: 833.5565\n",
      "Epoch 394/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4675 - val_loss: 833.5573\n",
      "Epoch 395/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4676 - val_loss: 833.5583\n",
      "Epoch 396/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 97.4677 - val_loss: 833.5593\n",
      "Epoch 397/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4678 - val_loss: 833.5599\n",
      "Epoch 398/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 97.4679 - val_loss: 833.5606\n",
      "Epoch 399/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 97.4679 - val_loss: 833.5615\n",
      "Epoch 400/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4680 - val_loss: 833.5621\n",
      "Epoch 401/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4680 - val_loss: 833.5623\n",
      "Epoch 402/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4681 - val_loss: 833.5627\n",
      "Epoch 403/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 97.4683 - val_loss: 833.5632\n",
      "Epoch 404/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4683 - val_loss: 833.5637\n",
      "Epoch 405/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4684 - val_loss: 833.5641\n",
      "Epoch 406/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4685 - val_loss: 833.5643\n",
      "Epoch 407/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4687 - val_loss: 833.5649\n",
      "Epoch 408/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4687 - val_loss: 833.5655\n",
      "Epoch 409/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4688 - val_loss: 833.5659\n",
      "Epoch 410/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4689 - val_loss: 833.5663\n",
      "Epoch 411/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4689 - val_loss: 833.5663\n",
      "Epoch 412/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 97.4691 - val_loss: 833.5664\n",
      "Epoch 413/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4692 - val_loss: 833.5667\n",
      "Epoch 414/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4692 - val_loss: 833.5668\n",
      "Epoch 415/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4693 - val_loss: 833.5671\n",
      "Epoch 416/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4694 - val_loss: 833.5672\n",
      "Epoch 417/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4695 - val_loss: 833.5674\n",
      "Epoch 418/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4696 - val_loss: 833.5674\n",
      "Epoch 419/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4697 - val_loss: 833.5680\n",
      "Epoch 420/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4697 - val_loss: 833.5681\n",
      "Epoch 421/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4698 - val_loss: 833.5682\n",
      "Epoch 422/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4699 - val_loss: 833.5681\n",
      "Epoch 423/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4700 - val_loss: 833.5682\n",
      "Epoch 424/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4700 - val_loss: 833.5684\n",
      "Epoch 425/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4701 - val_loss: 833.5685\n",
      "Epoch 426/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4702 - val_loss: 833.5685\n",
      "Epoch 427/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4703 - val_loss: 833.5687\n",
      "Epoch 428/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 97.4704 - val_loss: 833.5687\n",
      "Epoch 429/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4705 - val_loss: 833.5688\n",
      "Epoch 430/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4705 - val_loss: 833.5688\n",
      "Epoch 431/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 97.4706 - val_loss: 833.5692\n",
      "Epoch 432/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4706 - val_loss: 833.5690\n",
      "Epoch 433/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4707 - val_loss: 833.5692\n",
      "Epoch 434/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4708 - val_loss: 833.5690\n",
      "Epoch 435/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4709 - val_loss: 833.5690\n",
      "Epoch 436/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4709 - val_loss: 833.5693\n",
      "Epoch 437/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4710 - val_loss: 833.5693\n",
      "Epoch 438/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4711 - val_loss: 833.5695\n",
      "Epoch 439/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4711 - val_loss: 833.5693\n",
      "Epoch 440/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4712 - val_loss: 833.5691\n",
      "Epoch 441/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4713 - val_loss: 833.5690\n",
      "Epoch 442/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4714 - val_loss: 833.5690\n",
      "Epoch 443/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4714 - val_loss: 833.5688\n",
      "Epoch 444/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4715 - val_loss: 833.5685\n",
      "Epoch 445/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4716 - val_loss: 833.5685\n",
      "Epoch 446/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4717 - val_loss: 833.5685\n",
      "Epoch 447/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4717 - val_loss: 833.5685\n",
      "Epoch 448/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4717 - val_loss: 833.5685\n",
      "Epoch 449/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4718 - val_loss: 833.5682\n",
      "Epoch 450/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4719 - val_loss: 833.5682\n",
      "Epoch 451/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4720 - val_loss: 833.5682\n",
      "Epoch 452/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4720 - val_loss: 833.5682\n",
      "Epoch 453/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4721 - val_loss: 833.5683\n",
      "Epoch 454/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4721 - val_loss: 833.5682\n",
      "Epoch 455/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4722 - val_loss: 833.5683\n",
      "Epoch 456/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 97.4722 - val_loss: 833.5682\n",
      "Epoch 457/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4723 - val_loss: 833.5682\n",
      "Epoch 458/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4723 - val_loss: 833.5683\n",
      "Epoch 459/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4723 - val_loss: 833.5684\n",
      "Epoch 460/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4724 - val_loss: 833.5682\n",
      "Epoch 461/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4724 - val_loss: 833.5681\n",
      "Epoch 462/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4725 - val_loss: 833.5681\n",
      "Epoch 463/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4725 - val_loss: 833.5679\n",
      "Epoch 464/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4726 - val_loss: 833.5677\n",
      "Epoch 465/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4727 - val_loss: 833.5675\n",
      "Epoch 466/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4728 - val_loss: 833.5675\n",
      "Epoch 467/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4728 - val_loss: 833.5679\n",
      "Epoch 468/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4728 - val_loss: 833.5675\n",
      "Epoch 469/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4729 - val_loss: 833.5672\n",
      "Epoch 470/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4729 - val_loss: 833.5672\n",
      "Epoch 471/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4730 - val_loss: 833.5671\n",
      "Epoch 472/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4730 - val_loss: 833.5672\n",
      "Epoch 473/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4730 - val_loss: 833.5672\n",
      "Epoch 474/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4731 - val_loss: 833.5672\n",
      "Epoch 475/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 97.4731 - val_loss: 833.5673\n",
      "Epoch 476/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4731 - val_loss: 833.5673\n",
      "Epoch 477/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4732 - val_loss: 833.5670\n",
      "Epoch 478/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4733 - val_loss: 833.5670\n",
      "Epoch 479/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4733 - val_loss: 833.5668\n",
      "Epoch 480/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4733 - val_loss: 833.5668\n",
      "Epoch 481/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4733 - val_loss: 833.5667\n",
      "Epoch 482/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4734 - val_loss: 833.5667\n",
      "Epoch 483/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4735 - val_loss: 833.5668\n",
      "Epoch 484/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 97.4735 - val_loss: 833.5671\n",
      "Epoch 485/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4735 - val_loss: 833.5670\n",
      "Epoch 486/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4735 - val_loss: 833.5667\n",
      "Epoch 487/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4736 - val_loss: 833.5667\n",
      "Epoch 488/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4736 - val_loss: 833.5670\n",
      "Epoch 489/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4736 - val_loss: 833.5671\n",
      "Epoch 490/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4736 - val_loss: 833.5671\n",
      "Epoch 491/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4737 - val_loss: 833.5671\n",
      "Epoch 492/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4737 - val_loss: 833.5668\n",
      "Epoch 493/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4737 - val_loss: 833.5667\n",
      "Epoch 494/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4738 - val_loss: 833.5665\n",
      "Epoch 495/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 97.4738 - val_loss: 833.5667\n",
      "Epoch 496/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4739 - val_loss: 833.5668\n",
      "Epoch 497/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4738 - val_loss: 833.5668\n",
      "Epoch 498/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4739 - val_loss: 833.5667\n",
      "Epoch 499/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 97.4739 - val_loss: 833.5664\n",
      "Epoch 500/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 97.4739 - val_loss: 833.5661\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 358ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.37913399e+01, 6.37325163e+01, 6.36736928e+01, 6.36148693e+01,\n",
       "        6.35560458e+01, 6.34972222e+01, 6.34383987e+01, 2.75919200e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.65901290e-01, 3.53158380e-01,\n",
       "        3.52840840e-01, 6.49537815e+01, 6.47857143e+01, 6.46176471e+01,\n",
       "        6.44495798e+01, 6.42815126e+01, 6.41134454e+01, 6.39808824e+01,\n",
       "        6.39220588e+01, 6.38632353e+01, 6.38044118e+01, 6.37455882e+01,\n",
       "        6.36867647e+01, 6.36279412e+01, 6.35691177e+01, 6.35102941e+01,\n",
       "        6.34514706e+01, 6.33926471e+01, 6.33338235e+01, 6.32678571e+01,\n",
       "        6.31922269e+01, 6.31165966e+01, 6.30409664e+01, 6.29653361e+01,\n",
       "        6.28897059e+01, 6.28140756e+01, 6.27384454e+01, 6.26628151e+01,\n",
       "        4.21224950e-01, 0.00000000e+00, 0.00000000e+00, 5.66405830e-01,\n",
       "        5.23700950e-01, 7.86892830e-01, 3.11467650e-01, 6.36410131e+01,\n",
       "        6.35821895e+01, 6.35233660e+01, 6.34645425e+01, 6.34057190e+01,\n",
       "        6.33468954e+01, 6.32846639e+01, 6.32090336e+01, 6.31334034e+01,\n",
       "        6.30577731e+01, 6.29821429e+01, 6.29065126e+01, 6.28308824e+01,\n",
       "        6.27552521e+01, 6.26796218e+01, 6.71429739e+01, 6.69521475e+01,\n",
       "        6.67000467e+01, 6.64479458e+01, 6.61958450e+01, 6.58874883e+01,\n",
       "        6.53832867e+01, 6.48790850e+01, 6.43748833e+01, 1.66747361e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.79817820e-01, 2.18141124e-01,\n",
       "        7.77567625e-01, 0.00000000e+00, 0.00000000e+00, 2.24165514e-01,\n",
       "        6.19704742e+01, 4.85271513e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.19236487e-01, 5.64520717e-01, 2.30973251e-02, 2.62026906e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.40347481e-01, 8.91074359e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59.50739963, 59.49712885, 59.48685808, 59.4765873 , 59.46631653,\n",
       "       59.45604575, 59.44577498, 59.4355042 , 59.42523343, 59.41496265,\n",
       "       59.40469188, 59.3944211 , 59.38415033, 59.37387955, 59.36360878,\n",
       "       59.353338  , 59.34306723, 59.33279645, 59.32252568, 59.3122549 ,\n",
       "       59.30198413, 59.29171335, 59.28144258, 59.2711718 , 59.26090103,\n",
       "       59.25063025, 59.24035948, 59.2300887 , 59.21981793, 59.20954715,\n",
       "       59.19927638, 59.1890056 , 59.17873483, 59.16846405, 59.15819328,\n",
       "       59.1479225 , 59.13765173, 59.12738095, 59.11711018, 59.1068394 ,\n",
       "       59.09656863, 59.08629785, 59.07602708, 59.0657563 , 59.05548553,\n",
       "       59.04521475, 59.03494398, 59.0246732 , 59.01440243, 59.00413165,\n",
       "       58.99386088, 58.9835901 , 58.97331933, 58.96304855, 58.95277778,\n",
       "       58.942507  , 58.93223623, 58.92196545, 58.91169468, 58.9014239 ,\n",
       "       58.89115313, 58.88088235, 58.87061158, 58.8603408 , 58.85007003,\n",
       "       58.83979925, 58.82952848, 58.8192577 , 58.80898693, 58.79801587,\n",
       "       58.78214286, 58.76626984, 58.75039683, 58.73452381, 58.71865079,\n",
       "       58.70277778, 58.68690476, 58.67103175, 58.65515873, 58.63928571,\n",
       "       58.6234127 , 58.60753968, 58.59166667, 58.57579365, 58.55992063,\n",
       "       58.54404762, 58.5281746 , 58.51230159, 58.49642857, 58.48055556,\n",
       "       58.46468254, 58.44880952, 58.43293651, 58.41706349, 58.40119048,\n",
       "       58.38531746, 58.36944444, 58.35357143, 58.33769841, 58.3218254 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.677617818925\n",
      "26.79220008192679\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
