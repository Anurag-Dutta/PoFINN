{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2495    52.234980\n",
       "2496    52.226235\n",
       "2497    52.217490\n",
       "2498    52.208745\n",
       "2499    52.200000\n",
       "Name: C1, Length: 2500, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_2450_50.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2445     0.000000\n",
       "2446     0.000000\n",
       "2447     0.167600\n",
       "2448     0.000000\n",
       "2449     0.893680\n",
       "Name: C1, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(50)\n",
    "test\n",
    "training_set = training_set.head(2450)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-175)  var1(t-174)  var1(t-173)  var1(t-172)  var1(t-171)  \\\n",
      "175    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "176    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "177    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "178    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "179    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-170)  var1(t-169)  var1(t-168)  var1(t-167)  var1(t-166)  ...  \\\n",
      "175    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "176    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "177    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "178    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "179    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+45)  var2(t+45)  var1(t+46)  var2(t+46)  var1(t+47)  var2(t+47)  \\\n",
      "175   78.583777    0.000280   78.562302    0.000280   78.540826    0.000280   \n",
      "176   78.562302    0.000280   78.540826    0.000280   78.519351    0.000280   \n",
      "177   78.540826    0.000280   78.519351    0.000280   78.497876    0.000279   \n",
      "178   78.519351    0.000280   78.497876    0.000279   78.476401    0.000279   \n",
      "179   78.497876    0.000279   78.476401    0.000279   78.454925    0.000279   \n",
      "\n",
      "     var1(t+48)  var2(t+48)  var1(t+49)  var2(t+49)  \n",
      "175   78.519351    0.000280   78.497876    0.000279  \n",
      "176   78.497876    0.000279   78.476401    0.000279  \n",
      "177   78.476401    0.000279   78.454925    0.000279  \n",
      "178   78.454925    0.000279   78.433450    0.000279  \n",
      "179   78.433450    0.000279   78.411975    0.000279  \n",
      "\n",
      "[5 rows x 276 columns]\n",
      "Index(['var1(t-175)', 'var1(t-174)', 'var1(t-173)', 'var1(t-172)',\n",
      "       'var1(t-171)', 'var1(t-170)', 'var1(t-169)', 'var1(t-168)',\n",
      "       'var1(t-167)', 'var1(t-166)',\n",
      "       ...\n",
      "       'var1(t+45)', 'var2(t+45)', 'var1(t+46)', 'var2(t+46)', 'var1(t+47)',\n",
      "       'var2(t+47)', 'var1(t+48)', 'var2(t+48)', 'var1(t+49)', 'var2(t+49)'],\n",
      "      dtype='object', length=276)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 175, n_out = 50)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 176):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-150:]\n",
    "trainX = train[:,:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-150:]\n",
    "forecastX = forecast[:,:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 1, 126) (2225, 150) (1, 1, 126)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28/28 [==============================] - 3s 23ms/step - loss: 4115.7036 - val_loss: 1855.7629\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3760.2446 - val_loss: 1697.7341\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3512.8501 - val_loss: 1604.4830\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3340.0112 - val_loss: 1529.7628\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3180.6846 - val_loss: 1462.4877\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 3028.2717 - val_loss: 1402.4806\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 2890.0276 - val_loss: 1347.3933\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2758.5042 - val_loss: 1295.9573\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 2622.2236 - val_loss: 1246.8405\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 2495.3962 - val_loss: 1200.4584\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2374.5471 - val_loss: 1157.9194\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2262.7258 - val_loss: 1121.7941\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 2152.6375 - val_loss: 1078.0565\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 2051.6648 - val_loss: 1047.0297\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1946.8597 - val_loss: 1010.1339\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1842.6653 - val_loss: 978.7379\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1753.3508 - val_loss: 950.2209\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 1653.2559 - val_loss: 922.8981\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1564.7222 - val_loss: 892.7189\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1481.2633 - val_loss: 866.3590\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1403.3995 - val_loss: 844.1777\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1330.1190 - val_loss: 828.3615\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1260.7629 - val_loss: 804.5861\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1192.4056 - val_loss: 790.8828\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 1131.0820 - val_loss: 774.9792\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1099.0629 - val_loss: 760.9617\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1059.3018 - val_loss: 750.8607\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 980.0410 - val_loss: 739.8941\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 915.2334 - val_loss: 742.6578\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 864.0425 - val_loss: 733.9926\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 818.3782 - val_loss: 721.9268\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 777.6402 - val_loss: 727.2256\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 737.0098 - val_loss: 724.9153\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 695.8070 - val_loss: 722.8298\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 655.0817 - val_loss: 714.6328\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 641.5344 - val_loss: 709.4822\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 668.6331 - val_loss: 782.9105\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 593.1967 - val_loss: 784.3264\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 688.8460 - val_loss: 775.2187\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 582.9750 - val_loss: 779.6698\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 549.2748 - val_loss: 792.6165\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 524.3885 - val_loss: 800.9175\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 575.1900 - val_loss: 839.3444\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 517.5277 - val_loss: 826.9838\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 473.8054 - val_loss: 865.5027\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 467.2908 - val_loss: 909.5695\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 435.1131 - val_loss: 887.4568\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 436.9540 - val_loss: 896.9039\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 413.2632 - val_loss: 897.7184\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 384.4363 - val_loss: 921.0662\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 381.1919 - val_loss: 966.4562\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 378.2021 - val_loss: 1020.1124\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 362.7216 - val_loss: 1009.8813\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 348.8586 - val_loss: 997.8210\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 355.3334 - val_loss: 994.8003\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 343.8766 - val_loss: 1000.3065\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 392.5555 - val_loss: 999.2629\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 357.0406 - val_loss: 1007.1139\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 312.6077 - val_loss: 987.2944\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 305.8351 - val_loss: 972.1046\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 299.9935 - val_loss: 974.9120\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 281.2830 - val_loss: 996.7239\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 288.2414 - val_loss: 984.2408\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 318.4102 - val_loss: 1025.9578\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 292.5880 - val_loss: 1026.4381\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 272.7968 - val_loss: 1066.7113\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 259.7498 - val_loss: 1063.7515\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 262.2016 - val_loss: 1093.1967\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 258.7020 - val_loss: 1073.8665\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 279.4475 - val_loss: 1028.1975\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 287.5009 - val_loss: 991.1320\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 294.6597 - val_loss: 1020.4834\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 284.2728 - val_loss: 1016.5933\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.1156 - val_loss: 1013.4042\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 278.4354 - val_loss: 1078.5292\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 269.3703 - val_loss: 1072.4690\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 260.3721 - val_loss: 1158.8918\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 250.9120 - val_loss: 1114.3307\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 269.4719 - val_loss: 1117.7402\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 265.4593 - val_loss: 1121.5116\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 271.1306 - val_loss: 1163.6025\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 282.4009 - val_loss: 1156.6537\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.7728 - val_loss: 1146.3695\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 268.5082 - val_loss: 1134.9641\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 263.9391 - val_loss: 1114.2086\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 310.9317 - val_loss: 1121.3915\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 295.1413 - val_loss: 1140.0814\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 286.0121 - val_loss: 1152.6516\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 255.9153 - val_loss: 1150.9597\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.2647 - val_loss: 1144.3103\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 258.5892 - val_loss: 1180.3944\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 256.0814 - val_loss: 1182.2235\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 254.6743 - val_loss: 1186.7665\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 253.4772 - val_loss: 1184.0326\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 254.9935 - val_loss: 1199.0974\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 253.6332 - val_loss: 1198.7865\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 252.3640 - val_loss: 1191.3890\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 257.5719 - val_loss: 1204.6305\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 249.2898 - val_loss: 1137.2559\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 255.0887 - val_loss: 1124.1726\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 252.1590 - val_loss: 1125.7079\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 249.0110 - val_loss: 1128.1790\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 251.6613 - val_loss: 1146.3495\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 244.9538 - val_loss: 1126.4910\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 251.5878 - val_loss: 1154.8224\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 242.5454 - val_loss: 1135.8339\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 236.7040 - val_loss: 1124.3959\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 233.9447 - val_loss: 1118.3915\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 241.5493 - val_loss: 1149.8337\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 239.2952 - val_loss: 1150.0234\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 237.0456 - val_loss: 1146.1049\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 232.8659 - val_loss: 1137.8673\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 242.9254 - val_loss: 1172.7587\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 238.1349 - val_loss: 1152.2247\n",
      "Epoch 115/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 232.5632 - val_loss: 1138.2968\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 224.4619 - val_loss: 1102.0171\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 223.7282 - val_loss: 1106.2834\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 217.9616 - val_loss: 1091.5369\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 215.9235 - val_loss: 1068.7112\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 222.1792 - val_loss: 1063.6851\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 221.3378 - val_loss: 1063.0128\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 224.7070 - val_loss: 1083.5459\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 229.3601 - val_loss: 1105.9102\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 221.0236 - val_loss: 1076.9775\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 215.8904 - val_loss: 1060.6323\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 213.5471 - val_loss: 1054.3445\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 235.2372 - val_loss: 1056.9556\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 233.0927 - val_loss: 1058.4327\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 230.4016 - val_loss: 1047.6838\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.8081 - val_loss: 1033.6487\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 257.4710 - val_loss: 1042.2465\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.2844 - val_loss: 1048.1964\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.9846 - val_loss: 1088.5476\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 238.3307 - val_loss: 1092.1890\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.5251 - val_loss: 1112.9944\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 237.7567 - val_loss: 1109.5365\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 235.2167 - val_loss: 1107.5150\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 233.4214 - val_loss: 1108.3755\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 230.0631 - val_loss: 1074.2261\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 233.7295 - val_loss: 1074.7660\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 231.3135 - val_loss: 1074.2115\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 228.3356 - val_loss: 1075.0839\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 225.9254 - val_loss: 1073.0146\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 223.1331 - val_loss: 1069.7179\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 224.8932 - val_loss: 1076.8318\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 229.8263 - val_loss: 1077.1923\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 228.0334 - val_loss: 1069.5048\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 224.6617 - val_loss: 1079.9685\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 220.9741 - val_loss: 1069.2036\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 225.2514 - val_loss: 1090.1377\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 221.7990 - val_loss: 1055.2435\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 223.2052 - val_loss: 1047.6527\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 229.6350 - val_loss: 1086.3030\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 226.1666 - val_loss: 1061.2858\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 239.6692 - val_loss: 1073.1223\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 236.3736 - val_loss: 1070.7410\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 231.9106 - val_loss: 1066.8706\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 227.6784 - val_loss: 1063.0193\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 222.6506 - val_loss: 1060.1500\n",
      "Epoch 160/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 220.3429 - val_loss: 1057.3663\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 218.0786 - val_loss: 1055.5496\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 215.8247 - val_loss: 1050.6243\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 213.5857 - val_loss: 1046.5565\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 214.5015 - val_loss: 1054.6931\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 212.1789 - val_loss: 1060.2733\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 210.9760 - val_loss: 1054.8431\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 209.6152 - val_loss: 1057.6105\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 208.9222 - val_loss: 1052.6978\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 210.5237 - val_loss: 1060.8884\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 208.5289 - val_loss: 1053.3142\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 206.3313 - val_loss: 1045.7422\n",
      "Epoch 172/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 205.5187 - val_loss: 1047.9684\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 212.9807 - val_loss: 1052.2239\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.1592 - val_loss: 1054.0836\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 212.4968 - val_loss: 1061.3765\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 210.6167 - val_loss: 1058.0442\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 209.0149 - val_loss: 1053.4894\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 207.5456 - val_loss: 1045.8241\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 216.2311 - val_loss: 1009.8914\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 209.5633 - val_loss: 1001.7036\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 208.2982 - val_loss: 1011.4182\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 204.6170 - val_loss: 1009.5594\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 202.4053 - val_loss: 1005.0509\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 200.0506 - val_loss: 977.2234\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 210.6798 - val_loss: 992.1747\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 207.2648 - val_loss: 1008.7488\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 204.9641 - val_loss: 1009.5760\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 213.0878 - val_loss: 1054.3552\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 207.5037 - val_loss: 1032.3618\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 204.1031 - val_loss: 1024.1711\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 212.0375 - val_loss: 1022.3114\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 210.2263 - val_loss: 1025.2319\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 208.6185 - val_loss: 1026.9368\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 205.5428 - val_loss: 1025.3910\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 203.2900 - val_loss: 1023.8614\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 201.7896 - val_loss: 1028.6626\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 200.2271 - val_loss: 1027.6027\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 199.3185 - val_loss: 1023.5095\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 198.2509 - val_loss: 1026.1654\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 197.3862 - val_loss: 1023.1746\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 196.7667 - val_loss: 1019.4646\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 196.0357 - val_loss: 1018.7709\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 195.3362 - val_loss: 1022.3763\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 195.5303 - val_loss: 1027.4844\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 194.3855 - val_loss: 1022.0826\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 193.9042 - val_loss: 1015.1520\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 192.2553 - val_loss: 1016.9339\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 190.8645 - val_loss: 1016.3635\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 189.7943 - val_loss: 1012.6202\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 196.5384 - val_loss: 1045.6302\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 194.7493 - val_loss: 1042.6115\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 192.8260 - val_loss: 1029.7471\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 207.0995 - val_loss: 1028.6072\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 205.9029 - val_loss: 1029.6461\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 204.5166 - val_loss: 1030.7758\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 203.3961 - val_loss: 1031.1892\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 202.3786 - val_loss: 1032.4178\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 201.3563 - val_loss: 1031.0477\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 200.1344 - val_loss: 1028.2834\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 199.1730 - val_loss: 1019.9216\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 208.7528 - val_loss: 1051.9761\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 203.7929 - val_loss: 1038.0737\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 201.2853 - val_loss: 1032.5833\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 200.2959 - val_loss: 1028.0308\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 199.4306 - val_loss: 1022.2886\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 198.6871 - val_loss: 1017.6068\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 188.6751 - val_loss: 942.5709\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 199.2883 - val_loss: 946.1482\n",
      "Epoch 229/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 197.7068 - val_loss: 949.9001\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 195.2111 - val_loss: 953.0550\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 193.5758 - val_loss: 957.0983\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 192.5117 - val_loss: 957.5763\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 215.3223 - val_loss: 993.2790\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 192.4271 - val_loss: 959.8144\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 197.4177 - val_loss: 943.7371\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 191.9101 - val_loss: 937.2240\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 189.7300 - val_loss: 938.9249\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 186.2798 - val_loss: 933.0247\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 183.8922 - val_loss: 932.5685\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 182.4756 - val_loss: 932.1179\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 189.3611 - val_loss: 964.2313\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 190.4956 - val_loss: 1007.3932\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 185.0444 - val_loss: 944.4749\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 171.5673 - val_loss: 904.6388\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 179.5456 - val_loss: 950.3071\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 179.0242 - val_loss: 946.6939\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 179.6479 - val_loss: 951.8288\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 178.8188 - val_loss: 929.4221\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 198.4025 - val_loss: 923.9752\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 195.8971 - val_loss: 929.7329\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 194.2013 - val_loss: 936.0401\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 192.3118 - val_loss: 939.1871\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 190.8796 - val_loss: 943.9595\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 189.6168 - val_loss: 949.0149\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 188.5330 - val_loss: 951.7573\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 187.5551 - val_loss: 955.1530\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 187.6050 - val_loss: 946.6606\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 242.3431 - val_loss: 1146.1732\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 216.1336 - val_loss: 1034.0796\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 333.5884 - val_loss: 1005.9037\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 319.6316 - val_loss: 1035.9840\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 306.3346 - val_loss: 1064.9542\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 296.2180 - val_loss: 1093.3701\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 288.5788 - val_loss: 1116.1537\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 281.7427 - val_loss: 1140.5796\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.4627 - val_loss: 1159.1794\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 272.0999 - val_loss: 1177.3270\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 269.1318 - val_loss: 1192.5870\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 266.7537 - val_loss: 1207.2847\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 264.0100 - val_loss: 1204.1046\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 262.1418 - val_loss: 1214.7612\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 260.4771 - val_loss: 1223.9045\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 259.1119 - val_loss: 1232.0494\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 257.9305 - val_loss: 1236.9646\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 256.9928 - val_loss: 1242.6270\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 274.0314 - val_loss: 1303.2037\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 265.2491 - val_loss: 1278.4620\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 258.6948 - val_loss: 1262.8969\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 256.0399 - val_loss: 1248.8293\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.2917 - val_loss: 1234.8331\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 246.4875 - val_loss: 1218.7079\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 271.4808 - val_loss: 1228.3265\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 269.6124 - val_loss: 1236.8711\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 267.4746 - val_loss: 1237.7723\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 265.9746 - val_loss: 1244.9918\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 264.7922 - val_loss: 1249.3784\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 263.7798 - val_loss: 1256.7037\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 262.7020 - val_loss: 1258.1526\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 261.1512 - val_loss: 1258.0616\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 261.3257 - val_loss: 1258.6401\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 269.0171 - val_loss: 1289.2325\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 265.9510 - val_loss: 1275.8342\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 262.8868 - val_loss: 1212.9329\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 262.0985 - val_loss: 1246.3043\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 284.5363 - val_loss: 1243.4756\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 280.3936 - val_loss: 1253.9451\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 278.3687 - val_loss: 1264.0278\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.1880 - val_loss: 1273.5056\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 274.7226 - val_loss: 1281.6925\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 273.2759 - val_loss: 1288.7804\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 272.0130 - val_loss: 1297.5907\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 270.9679 - val_loss: 1302.7629\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 270.1699 - val_loss: 1304.4495\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 269.3025 - val_loss: 1309.1819\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 268.5181 - val_loss: 1313.5326\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 267.6437 - val_loss: 1315.5208\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 267.0807 - val_loss: 1294.9275\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 266.6170 - val_loss: 1298.7941\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 265.9284 - val_loss: 1302.7500\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 265.2373 - val_loss: 1305.8542\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 264.5934 - val_loss: 1307.0540\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 263.9932 - val_loss: 1310.8179\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 263.4227 - val_loss: 1312.6031\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 262.8802 - val_loss: 1313.9707\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 262.3601 - val_loss: 1315.0343\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 261.8577 - val_loss: 1315.8855\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 261.3699 - val_loss: 1316.4226\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 260.8944 - val_loss: 1316.7957\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 260.4288 - val_loss: 1316.9060\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 259.9719 - val_loss: 1316.8701\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 259.5215 - val_loss: 1316.6326\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 259.0763 - val_loss: 1316.2258\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 258.6351 - val_loss: 1315.6958\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 258.1988 - val_loss: 1315.1333\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 257.7661 - val_loss: 1314.4224\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 257.3367 - val_loss: 1313.6652\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 256.9099 - val_loss: 1312.8234\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 256.4849 - val_loss: 1311.9170\n",
      "Epoch 329/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 256.0618 - val_loss: 1310.9535\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 255.6400 - val_loss: 1309.9293\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 255.2195 - val_loss: 1308.8370\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 254.7998 - val_loss: 1307.6818\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 254.3810 - val_loss: 1306.4658\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 253.9628 - val_loss: 1305.2090\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 253.5452 - val_loss: 1303.8986\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 253.1277 - val_loss: 1302.5269\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 252.7111 - val_loss: 1300.9850\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.2950 - val_loss: 1299.3103\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.8850 - val_loss: 1295.6874\n",
      "Epoch 340/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.5075 - val_loss: 1290.0712\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.4463 - val_loss: 1276.3778\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 290.4689 - val_loss: 1286.6246\n",
      "Epoch 343/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 288.3076 - val_loss: 1314.2429\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 259.4832 - val_loss: 1332.5708\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 264.7879 - val_loss: 1343.2694\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 248.5060 - val_loss: 1296.4156\n",
      "Epoch 347/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 251.1460 - val_loss: 1305.7683\n",
      "Epoch 348/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 248.5901 - val_loss: 1291.8354\n",
      "Epoch 349/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 246.6783 - val_loss: 1286.3169\n",
      "Epoch 350/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 246.2754 - val_loss: 1283.8309\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 245.9487 - val_loss: 1280.7445\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 245.6521 - val_loss: 1276.8180\n",
      "Epoch 353/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 278.2423 - val_loss: 1321.7079\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 254.9988 - val_loss: 1320.8535\n",
      "Epoch 355/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 248.2454 - val_loss: 1273.0641\n",
      "Epoch 356/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 261.1643 - val_loss: 1351.4927\n",
      "Epoch 357/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 257.3279 - val_loss: 1342.2683\n",
      "Epoch 358/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 256.5754 - val_loss: 1328.8364\n",
      "Epoch 359/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 244.4727 - val_loss: 1237.5208\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.8301 - val_loss: 1230.9197\n",
      "Epoch 361/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 252.0899 - val_loss: 1227.1705\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 271.2116 - val_loss: 1282.6051\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 255.5501 - val_loss: 1251.5265\n",
      "Epoch 364/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 249.0209 - val_loss: 1234.8556\n",
      "Epoch 365/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 246.0200 - val_loss: 1224.7288\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 242.5133 - val_loss: 1216.5577\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 240.3503 - val_loss: 1212.7791\n",
      "Epoch 368/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 238.9924 - val_loss: 1211.5757\n",
      "Epoch 369/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 238.4928 - val_loss: 1212.4302\n",
      "Epoch 370/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.9954 - val_loss: 1212.8732\n",
      "Epoch 371/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.5381 - val_loss: 1213.3562\n",
      "Epoch 372/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 237.0366 - val_loss: 1214.3256\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 236.5545 - val_loss: 1214.9502\n",
      "Epoch 374/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 236.1291 - val_loss: 1214.4309\n",
      "Epoch 375/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 235.6612 - val_loss: 1215.0232\n",
      "Epoch 376/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 235.2242 - val_loss: 1214.5959\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 234.8117 - val_loss: 1213.1924\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 234.3661 - val_loss: 1213.5637\n",
      "Epoch 379/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 233.9540 - val_loss: 1211.8704\n",
      "Epoch 380/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 233.5238 - val_loss: 1211.9292\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 233.1204 - val_loss: 1210.9000\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 232.7075 - val_loss: 1211.4857\n",
      "Epoch 383/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 232.2974 - val_loss: 1210.1395\n",
      "Epoch 384/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 231.8839 - val_loss: 1209.2650\n",
      "Epoch 385/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 231.4559 - val_loss: 1208.6571\n",
      "Epoch 386/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 231.0464 - val_loss: 1207.9039\n",
      "Epoch 387/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 230.4932 - val_loss: 1205.8485\n",
      "Epoch 388/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 230.1673 - val_loss: 1204.3407\n",
      "Epoch 389/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 229.6649 - val_loss: 1205.0563\n",
      "Epoch 390/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 229.1682 - val_loss: 1203.1901\n",
      "Epoch 391/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 228.7897 - val_loss: 1202.4919\n",
      "Epoch 392/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 228.3844 - val_loss: 1200.3823\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 228.1120 - val_loss: 1198.8340\n",
      "Epoch 394/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.5816 - val_loss: 1197.8389\n",
      "Epoch 395/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 227.2301 - val_loss: 1197.3065\n",
      "Epoch 396/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 227.4197 - val_loss: 1183.4192\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 276.7132 - val_loss: 1367.8617\n",
      "Epoch 398/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 263.7706 - val_loss: 1365.3254\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 263.3858 - val_loss: 1361.5601\n",
      "Epoch 400/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 262.9477 - val_loss: 1357.8225\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 262.7209 - val_loss: 1353.4148\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 262.1676 - val_loss: 1351.5986\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 261.7806 - val_loss: 1348.5509\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 261.4076 - val_loss: 1345.5496\n",
      "Epoch 405/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 261.0315 - val_loss: 1342.9655\n",
      "Epoch 406/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 260.6591 - val_loss: 1340.2228\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 260.2883 - val_loss: 1337.8131\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 259.9182 - val_loss: 1335.3193\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 259.5487 - val_loss: 1332.7186\n",
      "Epoch 410/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 259.1791 - val_loss: 1330.8685\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 258.8093 - val_loss: 1328.8385\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 258.4397 - val_loss: 1326.8054\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 258.0703 - val_loss: 1324.7394\n",
      "Epoch 414/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 257.7010 - val_loss: 1322.7899\n",
      "Epoch 415/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 257.3318 - val_loss: 1320.9817\n",
      "Epoch 416/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 256.9629 - val_loss: 1319.3213\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 256.5941 - val_loss: 1317.4108\n",
      "Epoch 418/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 256.2258 - val_loss: 1316.0850\n",
      "Epoch 419/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 255.8576 - val_loss: 1314.0414\n",
      "Epoch 420/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 255.4900 - val_loss: 1312.3562\n",
      "Epoch 421/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 255.1227 - val_loss: 1310.7025\n",
      "Epoch 422/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 254.7558 - val_loss: 1309.0328\n",
      "Epoch 423/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 254.3892 - val_loss: 1307.3301\n",
      "Epoch 424/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 254.0234 - val_loss: 1305.7791\n",
      "Epoch 425/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 253.6580 - val_loss: 1304.4658\n",
      "Epoch 426/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 253.2931 - val_loss: 1303.1425\n",
      "Epoch 427/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.9288 - val_loss: 1301.6858\n",
      "Epoch 428/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.5646 - val_loss: 1299.6477\n",
      "Epoch 429/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 252.2012 - val_loss: 1298.7502\n",
      "Epoch 430/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 251.8375 - val_loss: 1297.1594\n",
      "Epoch 431/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.4756 - val_loss: 1294.7256\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.1123 - val_loss: 1292.9238\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 250.7523 - val_loss: 1291.3217\n",
      "Epoch 434/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 250.3907 - val_loss: 1289.9596\n",
      "Epoch 435/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 250.0302 - val_loss: 1288.5146\n",
      "Epoch 436/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 249.6705 - val_loss: 1287.0184\n",
      "Epoch 437/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 249.3116 - val_loss: 1285.5066\n",
      "Epoch 438/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 248.9533 - val_loss: 1284.0315\n",
      "Epoch 439/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 248.5955 - val_loss: 1282.5812\n",
      "Epoch 440/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 248.2382 - val_loss: 1281.1266\n",
      "Epoch 441/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.8816 - val_loss: 1279.6831\n",
      "Epoch 442/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.5255 - val_loss: 1278.2461\n",
      "Epoch 443/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.1701 - val_loss: 1276.8240\n",
      "Epoch 444/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 246.8152 - val_loss: 1275.3862\n",
      "Epoch 445/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 246.4610 - val_loss: 1273.9061\n",
      "Epoch 446/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 246.1076 - val_loss: 1272.4803\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 245.7546 - val_loss: 1271.0654\n",
      "Epoch 448/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 245.4021 - val_loss: 1269.6604\n",
      "Epoch 449/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 245.0503 - val_loss: 1268.2286\n",
      "Epoch 450/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 244.6991 - val_loss: 1266.7959\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 244.3486 - val_loss: 1265.3754\n",
      "Epoch 452/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 243.9986 - val_loss: 1263.9185\n",
      "Epoch 453/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 243.6493 - val_loss: 1262.5081\n",
      "Epoch 454/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 243.3006 - val_loss: 1261.1136\n",
      "Epoch 455/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 242.9522 - val_loss: 1259.7249\n",
      "Epoch 456/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 242.6046 - val_loss: 1258.3048\n",
      "Epoch 457/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 242.2576 - val_loss: 1256.8436\n",
      "Epoch 458/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.9114 - val_loss: 1255.4441\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.5657 - val_loss: 1254.0447\n",
      "Epoch 460/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.2204 - val_loss: 1252.6522\n",
      "Epoch 461/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.8757 - val_loss: 1251.2620\n",
      "Epoch 462/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.5316 - val_loss: 1249.8771\n",
      "Epoch 463/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.1881 - val_loss: 1248.5074\n",
      "Epoch 464/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 239.8451 - val_loss: 1247.0955\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 239.5029 - val_loss: 1245.6410\n",
      "Epoch 466/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 239.1612 - val_loss: 1244.2330\n",
      "Epoch 467/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 238.8202 - val_loss: 1242.8621\n",
      "Epoch 468/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 238.4794 - val_loss: 1241.4427\n",
      "Epoch 469/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 238.1397 - val_loss: 1240.0922\n",
      "Epoch 470/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.7998 - val_loss: 1238.6415\n",
      "Epoch 471/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.4616 - val_loss: 1237.3267\n",
      "Epoch 472/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.1226 - val_loss: 1235.8115\n",
      "Epoch 473/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 236.7860 - val_loss: 1234.5548\n",
      "Epoch 474/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 236.4475 - val_loss: 1232.9169\n",
      "Epoch 475/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 236.1130 - val_loss: 1231.7087\n",
      "Epoch 476/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 235.7755 - val_loss: 1230.1400\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 235.4417 - val_loss: 1229.0044\n",
      "Epoch 478/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 235.1055 - val_loss: 1227.5649\n",
      "Epoch 479/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 234.7719 - val_loss: 1226.0907\n",
      "Epoch 480/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 234.4701 - val_loss: 1220.3688\n",
      "Epoch 481/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.7570 - val_loss: 1235.7671\n",
      "Epoch 482/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 248.8109 - val_loss: 1264.7263\n",
      "Epoch 483/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 242.5053 - val_loss: 1247.9163\n",
      "Epoch 484/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 239.9631 - val_loss: 1233.7433\n",
      "Epoch 485/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 234.5322 - val_loss: 1209.7645\n",
      "Epoch 486/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 248.1660 - val_loss: 1215.5524\n",
      "Epoch 487/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 307.9590 - val_loss: 1209.3759\n",
      "Epoch 488/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 303.6506 - val_loss: 1284.7781\n",
      "Epoch 489/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 258.3307 - val_loss: 1242.6960\n",
      "Epoch 490/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 294.3357 - val_loss: 1254.4933\n",
      "Epoch 491/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 280.7318 - val_loss: 1272.6633\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 259.7932 - val_loss: 1251.3206\n",
      "Epoch 493/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 289.3672 - val_loss: 1259.9351\n",
      "Epoch 494/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 370.4266 - val_loss: 1272.0052\n",
      "Epoch 495/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 358.8796 - val_loss: 1313.5565\n",
      "Epoch 496/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 313.5382 - val_loss: 1430.4526\n",
      "Epoch 497/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 277.4836 - val_loss: 1376.2261\n",
      "Epoch 498/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 268.6517 - val_loss: 1349.0842\n",
      "Epoch 499/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 264.7339 - val_loss: 1334.7585\n",
      "Epoch 500/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 257.8221 - val_loss: 1314.3984\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1.5\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 414ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 126)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 126)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 186)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:150:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.91372931e-01, 6.36148693e+01, 3.52840840e-01, 6.38632353e+01,\n",
       "        6.33338235e+01, 6.26628151e+01, 6.35821895e+01, 6.29821429e+01,\n",
       "        6.61958450e+01, 2.18141124e-01, 0.00000000e+00, 6.09642267e-01,\n",
       "        6.29401261e+01, 0.00000000e+00, 6.32594538e+01, 6.70841503e+01,\n",
       "        1.16283670e-01, 6.28981092e+01, 6.59995332e+01, 6.51965453e+01,\n",
       "        0.00000000e+00, 6.29707634e-01, 4.72842395e-01, 6.11293449e+01,\n",
       "        5.11414289e-01, 0.00000000e+00, 1.14511445e-01, 0.00000000e+00,\n",
       "        6.39725149e-01, 0.00000000e+00, 6.53355255e+01, 0.00000000e+00,\n",
       "        6.64865434e-01, 8.29325318e-02, 2.93089747e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.36826524e-01, 5.58850646e-01, 1.12211037e+00,\n",
       "        7.26901472e-01, 0.00000000e+00, 3.54576170e-01, 6.38848767e-02,\n",
       "        0.00000000e+00, 3.65966231e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        8.96569669e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52.62850311, 52.61975815, 52.61101319, 52.60226822, 52.59352326,\n",
       "       52.5847783 , 52.57603334, 52.56728838, 52.55854342, 52.54979846,\n",
       "       52.54105349, 52.53230853, 52.52356357, 52.51481861, 52.50607365,\n",
       "       52.49732869, 52.48858373, 52.47983876, 52.4710938 , 52.46234884,\n",
       "       52.45360388, 52.44485892, 52.43611396, 52.427369  , 52.41862403,\n",
       "       52.40987907, 52.40113411, 52.39238915, 52.38364419, 52.37489923,\n",
       "       52.36615427, 52.35740931, 52.34866434, 52.33991938, 52.33117442,\n",
       "       52.32242946, 52.3136845 , 52.30493954, 52.29619458, 52.28744961,\n",
       "       52.27870465, 52.26995969, 52.26121473, 52.25246977, 52.24372481,\n",
       "       52.23497985, 52.22623488, 52.21748992, 52.20874496, 52.2       ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.05427126957838\n",
      "39.91790607819358\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
