{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1645    60.861471\n",
       "1646    60.853067\n",
       "1647    60.844664\n",
       "1648    60.836261\n",
       "1649    60.827857\n",
       "Name: C1, Length: 1650, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_1550_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1545     0.000000\n",
       "1546     0.000000\n",
       "1547     0.459561\n",
       "1548     0.066400\n",
       "1549     0.012577\n",
       "Name: C1, Length: 1550, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1550)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 1, 251) (1100, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "14/14 [==============================] - 2s 37ms/step - loss: 4686.2974 - val_loss: 3581.3215\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4606.5112 - val_loss: 3539.9167\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4560.5479 - val_loss: 3501.8630\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4515.3062 - val_loss: 3464.1538\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4470.4844 - val_loss: 3426.8511\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4426.0962 - val_loss: 3389.9343\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4382.1157 - val_loss: 3353.3816\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4338.5186 - val_loss: 3317.1741\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4295.2876 - val_loss: 3281.3015\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4252.4102 - val_loss: 3245.7539\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4209.8774 - val_loss: 3210.5247\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4167.6816 - val_loss: 3175.6079\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4125.8198 - val_loss: 3141.0005\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4084.2842 - val_loss: 3106.6985\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4042.6316 - val_loss: 3053.3191\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3970.9358 - val_loss: 3007.5320\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3918.7783 - val_loss: 2965.3337\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3868.5103 - val_loss: 2924.7102\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3819.9885 - val_loss: 2885.4216\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3772.8601 - val_loss: 2847.1785\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3726.8289 - val_loss: 2809.7842\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3681.6978 - val_loss: 2773.1101\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3637.3364 - val_loss: 2737.0706\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3593.6562 - val_loss: 2701.6030\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3550.5935 - val_loss: 2666.6631\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3508.1003 - val_loss: 2632.2166\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3466.1409 - val_loss: 2598.2363\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3424.6846 - val_loss: 2564.7007\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3383.7097 - val_loss: 2531.5918\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3343.1965 - val_loss: 2498.8948\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3303.1279 - val_loss: 2466.5967\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3263.4907 - val_loss: 2434.6870\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3224.2725 - val_loss: 2403.1558\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3185.4622 - val_loss: 2371.9939\n",
      "Epoch 35/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3147.0518 - val_loss: 2341.1946\n",
      "Epoch 36/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3109.0327 - val_loss: 2310.7507\n",
      "Epoch 37/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3071.3965 - val_loss: 2280.6562\n",
      "Epoch 38/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3034.1367 - val_loss: 2250.9050\n",
      "Epoch 39/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2997.2466 - val_loss: 2221.4924\n",
      "Epoch 40/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2960.7219 - val_loss: 2192.4126\n",
      "Epoch 41/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2924.5559 - val_loss: 2163.6611\n",
      "Epoch 42/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2888.7449 - val_loss: 2135.2349\n",
      "Epoch 43/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2853.2834 - val_loss: 2107.1287\n",
      "Epoch 44/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2818.1670 - val_loss: 2079.3389\n",
      "Epoch 45/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2783.3918 - val_loss: 2051.8618\n",
      "Epoch 46/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2748.9539 - val_loss: 2024.6943\n",
      "Epoch 47/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2714.8494 - val_loss: 1997.8334\n",
      "Epoch 48/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2681.0752 - val_loss: 1971.2749\n",
      "Epoch 49/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2647.6274 - val_loss: 1945.0164\n",
      "Epoch 50/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2614.5024 - val_loss: 1919.0548\n",
      "Epoch 51/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2581.6982 - val_loss: 1893.3870\n",
      "Epoch 52/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2549.2114 - val_loss: 1868.0103\n",
      "Epoch 53/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2517.0383 - val_loss: 1842.9225\n",
      "Epoch 54/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2485.1768 - val_loss: 1818.1208\n",
      "Epoch 55/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2453.6245 - val_loss: 1793.6028\n",
      "Epoch 56/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2422.3774 - val_loss: 1769.3651\n",
      "Epoch 57/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 2391.4341 - val_loss: 1745.4064\n",
      "Epoch 58/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2360.7913 - val_loss: 1721.7231\n",
      "Epoch 59/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2330.4473 - val_loss: 1698.3136\n",
      "Epoch 60/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2300.3982 - val_loss: 1675.1755\n",
      "Epoch 61/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2270.6433 - val_loss: 1652.3071\n",
      "Epoch 62/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2241.1792 - val_loss: 1629.7054\n",
      "Epoch 63/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2212.0042 - val_loss: 1607.3690\n",
      "Epoch 64/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2183.1160 - val_loss: 1585.2950\n",
      "Epoch 65/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2147.0701 - val_loss: 1554.3698\n",
      "Epoch 66/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2112.2451 - val_loss: 1529.3380\n",
      "Epoch 67/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2079.9404 - val_loss: 1505.1487\n",
      "Epoch 68/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2048.6362 - val_loss: 1481.7118\n",
      "Epoch 69/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2018.1666 - val_loss: 1458.8899\n",
      "Epoch 70/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1988.3790 - val_loss: 1436.5879\n",
      "Epoch 71/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1959.1700 - val_loss: 1414.7434\n",
      "Epoch 72/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1930.4722 - val_loss: 1393.3143\n",
      "Epoch 73/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1902.2386 - val_loss: 1372.2693\n",
      "Epoch 74/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1874.4352 - val_loss: 1351.5859\n",
      "Epoch 75/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1847.0359 - val_loss: 1331.2463\n",
      "Epoch 76/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1820.0208 - val_loss: 1311.2361\n",
      "Epoch 77/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1793.3733 - val_loss: 1291.5435\n",
      "Epoch 78/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1767.0797 - val_loss: 1272.1589\n",
      "Epoch 79/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1741.1293 - val_loss: 1253.0730\n",
      "Epoch 80/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1715.5114 - val_loss: 1234.2784\n",
      "Epoch 81/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1690.2179 - val_loss: 1215.7686\n",
      "Epoch 82/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1665.2412 - val_loss: 1197.5385\n",
      "Epoch 83/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1640.5745 - val_loss: 1179.5804\n",
      "Epoch 84/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1616.2111 - val_loss: 1161.8921\n",
      "Epoch 85/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1592.1461 - val_loss: 1144.4672\n",
      "Epoch 86/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1568.3750 - val_loss: 1127.3020\n",
      "Epoch 87/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1544.8917 - val_loss: 1110.3925\n",
      "Epoch 88/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1521.6921 - val_loss: 1093.7351\n",
      "Epoch 89/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1498.7726 - val_loss: 1077.3257\n",
      "Epoch 90/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1476.1292 - val_loss: 1061.1621\n",
      "Epoch 91/500\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1453.7576 - val_loss: 1045.2397\n",
      "Epoch 92/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1431.6547 - val_loss: 1029.5559\n",
      "Epoch 93/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1409.8171 - val_loss: 1014.1086\n",
      "Epoch 94/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1388.2418 - val_loss: 998.8936\n",
      "Epoch 95/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1366.9247 - val_loss: 983.9094\n",
      "Epoch 96/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1345.8647 - val_loss: 969.1524\n",
      "Epoch 97/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1325.0580 - val_loss: 954.6207\n",
      "Epoch 98/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1304.5015 - val_loss: 940.3113\n",
      "Epoch 99/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1284.1927 - val_loss: 926.2226\n",
      "Epoch 100/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1264.1295 - val_loss: 912.3510\n",
      "Epoch 101/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1244.3087 - val_loss: 898.6948\n",
      "Epoch 102/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1224.7284 - val_loss: 885.2521\n",
      "Epoch 103/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1205.3860 - val_loss: 872.0206\n",
      "Epoch 104/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1186.2794 - val_loss: 858.9976\n",
      "Epoch 105/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1167.4060 - val_loss: 846.1807\n",
      "Epoch 106/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1148.7637 - val_loss: 833.5690\n",
      "Epoch 107/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1130.3505 - val_loss: 821.1589\n",
      "Epoch 108/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1112.1638 - val_loss: 808.9502\n",
      "Epoch 109/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1094.2021 - val_loss: 796.9395\n",
      "Epoch 110/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1076.4626 - val_loss: 785.1250\n",
      "Epoch 111/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1058.9437 - val_loss: 773.5049\n",
      "Epoch 112/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1041.6434 - val_loss: 762.0774\n",
      "Epoch 113/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1024.5594 - val_loss: 750.8403\n",
      "Epoch 114/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1007.6898 - val_loss: 739.7925\n",
      "Epoch 115/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 991.0333 - val_loss: 728.9313\n",
      "Epoch 116/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 974.5874 - val_loss: 718.2549\n",
      "Epoch 117/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 958.3503 - val_loss: 707.7618\n",
      "Epoch 118/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 942.3203 - val_loss: 697.4501\n",
      "Epoch 119/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 926.4952 - val_loss: 687.3177\n",
      "Epoch 120/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 910.8736 - val_loss: 677.3634\n",
      "Epoch 121/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 895.4536 - val_loss: 667.5853\n",
      "Epoch 122/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 880.2334 - val_loss: 657.9807\n",
      "Epoch 123/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 865.2106 - val_loss: 648.5499\n",
      "Epoch 124/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 850.3846 - val_loss: 639.2891\n",
      "Epoch 125/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 835.7531 - val_loss: 630.1973\n",
      "Epoch 126/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 821.3144 - val_loss: 621.2733\n",
      "Epoch 127/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 807.0668 - val_loss: 612.5150\n",
      "Epoch 128/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 793.0085 - val_loss: 603.9210\n",
      "Epoch 129/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 779.1381 - val_loss: 595.4888\n",
      "Epoch 130/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 765.4535 - val_loss: 587.2183\n",
      "Epoch 131/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 751.9539 - val_loss: 579.1063\n",
      "Epoch 132/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 738.6365 - val_loss: 571.1522\n",
      "Epoch 133/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 725.5006 - val_loss: 563.3534\n",
      "Epoch 134/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 712.5442 - val_loss: 555.7092\n",
      "Epoch 135/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 699.7657 - val_loss: 548.2175\n",
      "Epoch 136/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 687.1633 - val_loss: 540.8766\n",
      "Epoch 137/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 674.7357 - val_loss: 533.6859\n",
      "Epoch 138/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 662.4815 - val_loss: 526.6429\n",
      "Epoch 139/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 650.3989 - val_loss: 519.7458\n",
      "Epoch 140/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 638.4863 - val_loss: 512.9933\n",
      "Epoch 141/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 626.7420 - val_loss: 506.3843\n",
      "Epoch 142/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 615.1649 - val_loss: 499.9175\n",
      "Epoch 143/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 603.7532 - val_loss: 493.5900\n",
      "Epoch 144/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 592.5053 - val_loss: 487.4013\n",
      "Epoch 145/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 581.4200 - val_loss: 481.3499\n",
      "Epoch 146/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 570.4954 - val_loss: 475.4333\n",
      "Epoch 147/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 559.7303 - val_loss: 469.6514\n",
      "Epoch 148/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 549.1229 - val_loss: 464.0017\n",
      "Epoch 149/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 538.6721 - val_loss: 458.4831\n",
      "Epoch 150/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 528.3764 - val_loss: 453.0940\n",
      "Epoch 151/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 518.2339 - val_loss: 447.8327\n",
      "Epoch 152/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 508.2436 - val_loss: 442.6983\n",
      "Epoch 153/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 498.4040 - val_loss: 437.6884\n",
      "Epoch 154/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 488.7131 - val_loss: 432.8026\n",
      "Epoch 155/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 479.1701 - val_loss: 428.0383\n",
      "Epoch 156/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 469.7733 - val_loss: 423.3949\n",
      "Epoch 157/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 460.5212 - val_loss: 418.8707\n",
      "Epoch 158/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 451.4124 - val_loss: 414.4643\n",
      "Epoch 159/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 442.4457 - val_loss: 410.1736\n",
      "Epoch 160/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 433.6194 - val_loss: 405.9984\n",
      "Epoch 161/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 424.9322 - val_loss: 401.9362\n",
      "Epoch 162/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 416.3827 - val_loss: 397.9860\n",
      "Epoch 163/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 407.9694 - val_loss: 394.1460\n",
      "Epoch 164/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 399.6909 - val_loss: 390.4152\n",
      "Epoch 165/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 391.5460 - val_loss: 386.7922\n",
      "Epoch 166/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 383.5332 - val_loss: 383.2756\n",
      "Epoch 167/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 375.6514 - val_loss: 379.8636\n",
      "Epoch 168/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 367.8990 - val_loss: 376.5552\n",
      "Epoch 169/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 360.2744 - val_loss: 373.3487\n",
      "Epoch 170/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 352.7766 - val_loss: 370.2429\n",
      "Epoch 171/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 345.4042 - val_loss: 367.2363\n",
      "Epoch 172/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 338.1556 - val_loss: 364.3278\n",
      "Epoch 173/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 331.0298 - val_loss: 361.5158\n",
      "Epoch 174/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 324.0253 - val_loss: 358.7989\n",
      "Epoch 175/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 317.1407 - val_loss: 356.1754\n",
      "Epoch 176/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 310.3745 - val_loss: 353.6446\n",
      "Epoch 177/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 303.7258 - val_loss: 351.2049\n",
      "Epoch 178/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 297.1930 - val_loss: 348.8549\n",
      "Epoch 179/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 290.7749 - val_loss: 346.5931\n",
      "Epoch 180/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 284.4700 - val_loss: 344.4183\n",
      "Epoch 181/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 278.2772 - val_loss: 342.3293\n",
      "Epoch 182/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 272.1953 - val_loss: 340.3246\n",
      "Epoch 183/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 266.2227 - val_loss: 338.4028\n",
      "Epoch 184/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 260.3584 - val_loss: 336.5628\n",
      "Epoch 185/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 254.6009 - val_loss: 334.8033\n",
      "Epoch 186/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 248.9491 - val_loss: 333.1228\n",
      "Epoch 187/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 243.4017 - val_loss: 331.5200\n",
      "Epoch 188/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 237.9574 - val_loss: 329.9937\n",
      "Epoch 189/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 232.6148 - val_loss: 328.5425\n",
      "Epoch 190/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 227.3729 - val_loss: 327.1654\n",
      "Epoch 191/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 222.2303 - val_loss: 325.8607\n",
      "Epoch 192/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 217.1856 - val_loss: 324.6274\n",
      "Epoch 193/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 212.2379 - val_loss: 323.4642\n",
      "Epoch 194/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 207.3856 - val_loss: 322.3699\n",
      "Epoch 195/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 202.6279 - val_loss: 321.3431\n",
      "Epoch 196/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 197.9632 - val_loss: 320.3826\n",
      "Epoch 197/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 193.3906 - val_loss: 319.4872\n",
      "Epoch 198/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 188.9087 - val_loss: 318.6555\n",
      "Epoch 199/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 184.5163 - val_loss: 317.8865\n",
      "Epoch 200/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 180.2121 - val_loss: 317.1788\n",
      "Epoch 201/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 175.9952 - val_loss: 316.5313\n",
      "Epoch 202/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 171.8641 - val_loss: 315.9428\n",
      "Epoch 203/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 167.8178 - val_loss: 315.4120\n",
      "Epoch 204/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 163.8552 - val_loss: 314.9377\n",
      "Epoch 205/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 159.9749 - val_loss: 314.5188\n",
      "Epoch 206/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 156.1759 - val_loss: 314.1540\n",
      "Epoch 207/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 152.4569 - val_loss: 313.8423\n",
      "Epoch 208/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 148.8170 - val_loss: 313.5823\n",
      "Epoch 209/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 145.2550 - val_loss: 313.3731\n",
      "Epoch 210/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 141.7694 - val_loss: 313.2133\n",
      "Epoch 211/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 138.3594 - val_loss: 313.1020\n",
      "Epoch 212/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 135.0239 - val_loss: 313.0378\n",
      "Epoch 213/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 131.7617 - val_loss: 313.0198\n",
      "Epoch 214/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 128.5716 - val_loss: 313.0467\n",
      "Epoch 215/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 125.4525 - val_loss: 313.1176\n",
      "Epoch 216/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 122.4036 - val_loss: 313.2311\n",
      "Epoch 217/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 119.4235 - val_loss: 313.3864\n",
      "Epoch 218/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 116.5113 - val_loss: 313.5822\n",
      "Epoch 219/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 113.6658 - val_loss: 313.8176\n",
      "Epoch 220/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 110.8858 - val_loss: 314.0914\n",
      "Epoch 221/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 108.1704 - val_loss: 314.4025\n",
      "Epoch 222/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 105.5188 - val_loss: 314.7499\n",
      "Epoch 223/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 102.9295 - val_loss: 315.1327\n",
      "Epoch 224/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 100.4018 - val_loss: 315.5497\n",
      "Epoch 225/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 97.9345 - val_loss: 315.9998\n",
      "Epoch 226/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 95.5267 - val_loss: 316.4822\n",
      "Epoch 227/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 93.1772 - val_loss: 316.9958\n",
      "Epoch 228/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 90.8851 - val_loss: 317.5396\n",
      "Epoch 229/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 88.6493 - val_loss: 318.1126\n",
      "Epoch 230/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 86.4689 - val_loss: 318.7138\n",
      "Epoch 231/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 84.3431 - val_loss: 319.3423\n",
      "Epoch 232/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 82.2707 - val_loss: 319.9970\n",
      "Epoch 233/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 80.2506 - val_loss: 320.6773\n",
      "Epoch 234/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 78.2821 - val_loss: 321.3819\n",
      "Epoch 235/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 76.3641 - val_loss: 322.1100\n",
      "Epoch 236/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 74.4957 - val_loss: 322.8608\n",
      "Epoch 237/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 72.6761 - val_loss: 323.6332\n",
      "Epoch 238/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 70.9042 - val_loss: 324.4264\n",
      "Epoch 239/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 69.1793 - val_loss: 325.2396\n",
      "Epoch 240/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 67.5002 - val_loss: 326.0718\n",
      "Epoch 241/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 65.8662 - val_loss: 326.9222\n",
      "Epoch 242/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 64.2763 - val_loss: 327.7897\n",
      "Epoch 243/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 62.7298 - val_loss: 328.6740\n",
      "Epoch 244/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 61.2256 - val_loss: 329.5739\n",
      "Epoch 245/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 59.7630 - val_loss: 330.4889\n",
      "Epoch 246/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 58.3410 - val_loss: 331.4177\n",
      "Epoch 247/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 56.9588 - val_loss: 332.3598\n",
      "Epoch 248/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 55.6157 - val_loss: 333.3147\n",
      "Epoch 249/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 54.3106 - val_loss: 334.2811\n",
      "Epoch 250/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 53.0430 - val_loss: 335.2584\n",
      "Epoch 251/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 51.8120 - val_loss: 336.2462\n",
      "Epoch 252/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 50.6167 - val_loss: 337.2434\n",
      "Epoch 253/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 49.4564 - val_loss: 338.2495\n",
      "Epoch 254/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 48.3304 - val_loss: 339.2636\n",
      "Epoch 255/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 47.2378 - val_loss: 340.2852\n",
      "Epoch 256/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 46.1780 - val_loss: 341.3134\n",
      "Epoch 257/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 45.1499 - val_loss: 342.3479\n",
      "Epoch 258/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 44.1532 - val_loss: 343.3876\n",
      "Epoch 259/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 43.1869 - val_loss: 344.4323\n",
      "Epoch 260/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 42.2504 - val_loss: 345.4809\n",
      "Epoch 261/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 41.3430 - val_loss: 346.5331\n",
      "Epoch 262/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 40.4639 - val_loss: 347.5884\n",
      "Epoch 263/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 39.6124 - val_loss: 348.6460\n",
      "Epoch 264/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 38.7880 - val_loss: 349.7051\n",
      "Epoch 265/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 37.9900 - val_loss: 350.7656\n",
      "Epoch 266/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 37.2177 - val_loss: 351.8266\n",
      "Epoch 267/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 36.4704 - val_loss: 352.8880\n",
      "Epoch 268/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 35.7474 - val_loss: 353.9489\n",
      "Epoch 269/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 35.0482 - val_loss: 355.0087\n",
      "Epoch 270/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 34.3722 - val_loss: 356.0671\n",
      "Epoch 271/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 33.7188 - val_loss: 357.1237\n",
      "Epoch 272/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 33.0873 - val_loss: 358.1781\n",
      "Epoch 273/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 32.4771 - val_loss: 359.2295\n",
      "Epoch 274/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 31.8878 - val_loss: 360.2774\n",
      "Epoch 275/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 31.3187 - val_loss: 361.3218\n",
      "Epoch 276/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 30.7694 - val_loss: 362.3620\n",
      "Epoch 277/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 30.2392 - val_loss: 363.3976\n",
      "Epoch 278/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 29.7275 - val_loss: 364.4284\n",
      "Epoch 279/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 29.2339 - val_loss: 365.4538\n",
      "Epoch 280/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 28.7580 - val_loss: 366.4733\n",
      "Epoch 281/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 28.2990 - val_loss: 367.4868\n",
      "Epoch 282/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 27.8567 - val_loss: 368.4941\n",
      "Epoch 283/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 27.4304 - val_loss: 369.4946\n",
      "Epoch 284/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 27.0197 - val_loss: 370.4879\n",
      "Epoch 285/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 26.6242 - val_loss: 371.4739\n",
      "Epoch 286/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 26.2433 - val_loss: 372.4523\n",
      "Epoch 287/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 25.8767 - val_loss: 373.4226\n",
      "Epoch 288/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 25.5239 - val_loss: 374.3848\n",
      "Epoch 289/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 25.1844 - val_loss: 375.3386\n",
      "Epoch 290/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 24.8579 - val_loss: 376.2833\n",
      "Epoch 291/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 24.5440 - val_loss: 377.2192\n",
      "Epoch 292/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 24.2423 - val_loss: 378.1461\n",
      "Epoch 293/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 23.9522 - val_loss: 379.0634\n",
      "Epoch 294/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.6735 - val_loss: 379.9710\n",
      "Epoch 295/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.4059 - val_loss: 380.8688\n",
      "Epoch 296/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 23.1490 - val_loss: 381.7568\n",
      "Epoch 297/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 22.9022 - val_loss: 382.6344\n",
      "Epoch 298/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 22.6655 - val_loss: 383.5018\n",
      "Epoch 299/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 22.4383 - val_loss: 384.3589\n",
      "Epoch 300/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 22.2205 - val_loss: 385.2050\n",
      "Epoch 301/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 22.0116 - val_loss: 386.0406\n",
      "Epoch 302/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 21.8113 - val_loss: 386.8651\n",
      "Epoch 303/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 21.6194 - val_loss: 387.6790\n",
      "Epoch 304/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 21.4355 - val_loss: 388.4813\n",
      "Epoch 305/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 21.2595 - val_loss: 389.2730\n",
      "Epoch 306/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 21.0908 - val_loss: 390.0534\n",
      "Epoch 307/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 20.9294 - val_loss: 390.8223\n",
      "Epoch 308/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 20.7749 - val_loss: 391.5797\n",
      "Epoch 309/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 20.6271 - val_loss: 392.3260\n",
      "Epoch 310/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 20.4857 - val_loss: 393.0606\n",
      "Epoch 311/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 20.3506 - val_loss: 393.7842\n",
      "Epoch 312/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 20.2214 - val_loss: 394.4952\n",
      "Epoch 313/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 20.0980 - val_loss: 395.1955\n",
      "Epoch 314/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 19.9800 - val_loss: 395.8839\n",
      "Epoch 315/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 19.8674 - val_loss: 396.5606\n",
      "Epoch 316/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 19.7599 - val_loss: 397.2260\n",
      "Epoch 317/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 19.6572 - val_loss: 397.8800\n",
      "Epoch 318/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 19.5592 - val_loss: 398.5221\n",
      "Epoch 319/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 19.4658 - val_loss: 399.1528\n",
      "Epoch 320/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 19.3767 - val_loss: 399.7718\n",
      "Epoch 321/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 19.2917 - val_loss: 400.3795\n",
      "Epoch 322/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 19.2107 - val_loss: 400.9760\n",
      "Epoch 323/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 19.1335 - val_loss: 401.5609\n",
      "Epoch 324/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 19.0600 - val_loss: 402.1347\n",
      "Epoch 325/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.9899 - val_loss: 402.6969\n",
      "Epoch 326/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.9232 - val_loss: 403.2483\n",
      "Epoch 327/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.8597 - val_loss: 403.7881\n",
      "Epoch 328/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.7993 - val_loss: 404.3172\n",
      "Epoch 329/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.7419 - val_loss: 404.8355\n",
      "Epoch 330/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.6872 - val_loss: 405.3427\n",
      "Epoch 331/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.6352 - val_loss: 405.8391\n",
      "Epoch 332/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.5858 - val_loss: 406.3248\n",
      "Epoch 333/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.5389 - val_loss: 406.8002\n",
      "Epoch 334/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.4942 - val_loss: 407.2648\n",
      "Epoch 335/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.4519 - val_loss: 407.7194\n",
      "Epoch 336/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.4116 - val_loss: 408.1636\n",
      "Epoch 337/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.3734 - val_loss: 408.5975\n",
      "Epoch 338/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.3371 - val_loss: 409.0212\n",
      "Epoch 339/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 18.3027 - val_loss: 409.4353\n",
      "Epoch 340/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.2700 - val_loss: 409.8394\n",
      "Epoch 341/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 18.2390 - val_loss: 410.2339\n",
      "Epoch 342/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.2097 - val_loss: 410.6189\n",
      "Epoch 343/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.1818 - val_loss: 410.9944\n",
      "Epoch 344/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.1554 - val_loss: 411.3608\n",
      "Epoch 345/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.1304 - val_loss: 411.7177\n",
      "Epoch 346/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.1067 - val_loss: 412.0659\n",
      "Epoch 347/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 18.0842 - val_loss: 412.4049\n",
      "Epoch 348/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 18.0629 - val_loss: 412.7355\n",
      "Epoch 349/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.0427 - val_loss: 413.0569\n",
      "Epoch 350/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.0237 - val_loss: 413.3704\n",
      "Epoch 351/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.0057 - val_loss: 413.6755\n",
      "Epoch 352/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.9886 - val_loss: 413.9726\n",
      "Epoch 353/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.9724 - val_loss: 414.2612\n",
      "Epoch 354/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.9571 - val_loss: 414.5420\n",
      "Epoch 355/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.9426 - val_loss: 414.8151\n",
      "Epoch 356/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.9289 - val_loss: 415.0805\n",
      "Epoch 357/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.9160 - val_loss: 415.3384\n",
      "Epoch 358/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.9037 - val_loss: 415.5889\n",
      "Epoch 359/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.8921 - val_loss: 415.8321\n",
      "Epoch 360/500\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 17.8812 - val_loss: 416.0685\n",
      "Epoch 361/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.8709 - val_loss: 416.2981\n",
      "Epoch 362/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.8611 - val_loss: 416.5208\n",
      "Epoch 363/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 17.8519 - val_loss: 416.7368\n",
      "Epoch 364/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.8432 - val_loss: 416.9463\n",
      "Epoch 365/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.8349 - val_loss: 417.1491\n",
      "Epoch 366/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.8272 - val_loss: 417.3459\n",
      "Epoch 367/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.8198 - val_loss: 417.5368\n",
      "Epoch 368/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.8129 - val_loss: 417.7218\n",
      "Epoch 369/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.8063 - val_loss: 417.9009\n",
      "Epoch 370/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.8002 - val_loss: 418.0746\n",
      "Epoch 371/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7943 - val_loss: 418.2424\n",
      "Epoch 372/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.7888 - val_loss: 418.4051\n",
      "Epoch 373/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7836 - val_loss: 418.5621\n",
      "Epoch 374/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7787 - val_loss: 418.7141\n",
      "Epoch 375/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7740 - val_loss: 418.8607\n",
      "Epoch 376/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7697 - val_loss: 419.0028\n",
      "Epoch 377/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7656 - val_loss: 419.1405\n",
      "Epoch 378/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7616 - val_loss: 419.2727\n",
      "Epoch 379/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7580 - val_loss: 419.4008\n",
      "Epoch 380/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 17.7545 - val_loss: 419.5245\n",
      "Epoch 381/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7513 - val_loss: 419.6442\n",
      "Epoch 382/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7482 - val_loss: 419.7593\n",
      "Epoch 383/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7453 - val_loss: 419.8706\n",
      "Epoch 384/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7425 - val_loss: 419.9776\n",
      "Epoch 385/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 17.7400 - val_loss: 420.0811\n",
      "Epoch 386/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 17.7375 - val_loss: 420.1808\n",
      "Epoch 387/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 17.7352 - val_loss: 420.2768\n",
      "Epoch 388/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7331 - val_loss: 420.3692\n",
      "Epoch 389/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 17.7311 - val_loss: 420.4583\n",
      "Epoch 390/500\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 17.7292 - val_loss: 420.5443\n",
      "Epoch 391/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7273 - val_loss: 420.6269\n",
      "Epoch 392/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 17.7256 - val_loss: 420.7062\n",
      "Epoch 393/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 17.7240 - val_loss: 420.7827\n",
      "Epoch 394/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7225 - val_loss: 420.8568\n",
      "Epoch 395/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7211 - val_loss: 420.9271\n",
      "Epoch 396/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 17.7198 - val_loss: 420.9949\n",
      "Epoch 397/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7185 - val_loss: 421.0599\n",
      "Epoch 398/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.7173 - val_loss: 421.1226\n",
      "Epoch 399/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7162 - val_loss: 421.1830\n",
      "Epoch 400/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 17.7152 - val_loss: 421.2407\n",
      "Epoch 401/500\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 17.7142 - val_loss: 421.2958\n",
      "Epoch 402/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 17.7133 - val_loss: 421.3494\n",
      "Epoch 403/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.7125 - val_loss: 421.4003\n",
      "Epoch 404/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.7117 - val_loss: 421.4497\n",
      "Epoch 405/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.7109 - val_loss: 421.4967\n",
      "Epoch 406/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7102 - val_loss: 421.5415\n",
      "Epoch 407/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7095 - val_loss: 421.5848\n",
      "Epoch 408/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7089 - val_loss: 421.6259\n",
      "Epoch 409/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 17.7084 - val_loss: 421.6654\n",
      "Epoch 410/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.7078 - val_loss: 421.7035\n",
      "Epoch 411/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.7073 - val_loss: 421.7398\n",
      "Epoch 412/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 17.7069 - val_loss: 421.7741\n",
      "Epoch 413/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.7064 - val_loss: 421.8072\n",
      "Epoch 414/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7060 - val_loss: 421.8390\n",
      "Epoch 415/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7057 - val_loss: 421.8687\n",
      "Epoch 416/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7053 - val_loss: 421.8976\n",
      "Epoch 417/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7050 - val_loss: 421.9252\n",
      "Epoch 418/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7048 - val_loss: 421.9514\n",
      "Epoch 419/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.7045 - val_loss: 421.9761\n",
      "Epoch 420/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7043 - val_loss: 422.0000\n",
      "Epoch 421/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7041 - val_loss: 422.0227\n",
      "Epoch 422/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7039 - val_loss: 422.0446\n",
      "Epoch 423/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7037 - val_loss: 422.0651\n",
      "Epoch 424/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7036 - val_loss: 422.0849\n",
      "Epoch 425/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7034 - val_loss: 422.1037\n",
      "Epoch 426/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.7033 - val_loss: 422.1216\n",
      "Epoch 427/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7032 - val_loss: 422.1384\n",
      "Epoch 428/500\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 17.7031 - val_loss: 422.1550\n",
      "Epoch 429/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7030 - val_loss: 422.1699\n",
      "Epoch 430/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7030 - val_loss: 422.1848\n",
      "Epoch 431/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7030 - val_loss: 422.1985\n",
      "Epoch 432/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 17.7029 - val_loss: 422.2118\n",
      "Epoch 433/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7029 - val_loss: 422.2242\n",
      "Epoch 434/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7029 - val_loss: 422.2361\n",
      "Epoch 435/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.7029 - val_loss: 422.2473\n",
      "Epoch 436/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7029 - val_loss: 422.2580\n",
      "Epoch 437/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 17.7030 - val_loss: 422.2682\n",
      "Epoch 438/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7030 - val_loss: 422.2776\n",
      "Epoch 439/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7030 - val_loss: 422.2864\n",
      "Epoch 440/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7031 - val_loss: 422.2947\n",
      "Epoch 441/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7032 - val_loss: 422.3033\n",
      "Epoch 442/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.7032 - val_loss: 422.3107\n",
      "Epoch 443/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.7033 - val_loss: 422.3178\n",
      "Epoch 444/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7034 - val_loss: 422.3246\n",
      "Epoch 445/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7035 - val_loss: 422.3311\n",
      "Epoch 446/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7036 - val_loss: 422.3372\n",
      "Epoch 447/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7037 - val_loss: 422.3429\n",
      "Epoch 448/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7038 - val_loss: 422.3483\n",
      "Epoch 449/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7039 - val_loss: 422.3531\n",
      "Epoch 450/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7040 - val_loss: 422.3579\n",
      "Epoch 451/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7041 - val_loss: 422.3622\n",
      "Epoch 452/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7043 - val_loss: 422.3663\n",
      "Epoch 453/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7044 - val_loss: 422.3700\n",
      "Epoch 454/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7045 - val_loss: 422.3737\n",
      "Epoch 455/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.7047 - val_loss: 422.3772\n",
      "Epoch 456/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7048 - val_loss: 422.3806\n",
      "Epoch 457/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7049 - val_loss: 422.3835\n",
      "Epoch 458/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7051 - val_loss: 422.3864\n",
      "Epoch 459/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7052 - val_loss: 422.3889\n",
      "Epoch 460/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7054 - val_loss: 422.3912\n",
      "Epoch 461/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7056 - val_loss: 422.3936\n",
      "Epoch 462/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7057 - val_loss: 422.3955\n",
      "Epoch 463/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.7059 - val_loss: 422.3979\n",
      "Epoch 464/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7060 - val_loss: 422.3993\n",
      "Epoch 465/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7062 - val_loss: 422.4009\n",
      "Epoch 466/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7064 - val_loss: 422.4025\n",
      "Epoch 467/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.7065 - val_loss: 422.4039\n",
      "Epoch 468/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7067 - val_loss: 422.4052\n",
      "Epoch 469/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7068 - val_loss: 422.4065\n",
      "Epoch 470/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.7070 - val_loss: 422.4073\n",
      "Epoch 471/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.7072 - val_loss: 422.4085\n",
      "Epoch 472/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7073 - val_loss: 422.4093\n",
      "Epoch 473/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7076 - val_loss: 422.4101\n",
      "Epoch 474/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7077 - val_loss: 422.4108\n",
      "Epoch 475/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7078 - val_loss: 422.4112\n",
      "Epoch 476/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7081 - val_loss: 422.4117\n",
      "Epoch 477/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.7082 - val_loss: 422.4120\n",
      "Epoch 478/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7084 - val_loss: 422.4123\n",
      "Epoch 479/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7086 - val_loss: 422.4125\n",
      "Epoch 480/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7088 - val_loss: 422.4127\n",
      "Epoch 481/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.7090 - val_loss: 422.4131\n",
      "Epoch 482/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7092 - val_loss: 422.4132\n",
      "Epoch 483/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7093 - val_loss: 422.4135\n",
      "Epoch 484/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7095 - val_loss: 422.4133\n",
      "Epoch 485/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.7097 - val_loss: 422.4135\n",
      "Epoch 486/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.7099 - val_loss: 422.4135\n",
      "Epoch 487/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7100 - val_loss: 422.4134\n",
      "Epoch 488/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7102 - val_loss: 422.4134\n",
      "Epoch 489/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.7104 - val_loss: 422.4134\n",
      "Epoch 490/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.7106 - val_loss: 422.4133\n",
      "Epoch 491/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 17.7107 - val_loss: 422.4129\n",
      "Epoch 492/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7109 - val_loss: 422.4127\n",
      "Epoch 493/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7111 - val_loss: 422.4125\n",
      "Epoch 494/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7113 - val_loss: 422.4125\n",
      "Epoch 495/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7115 - val_loss: 422.4124\n",
      "Epoch 496/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.7116 - val_loss: 422.4123\n",
      "Epoch 497/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7118 - val_loss: 422.4121\n",
      "Epoch 498/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7120 - val_loss: 422.4117\n",
      "Epoch 499/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.7121 - val_loss: 422.4112\n",
      "Epoch 500/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7123 - val_loss: 422.4110\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 0.1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 424ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.36802288e+01, 6.36606209e+01, 6.36410131e+01, 6.36214052e+01,\n",
       "        6.36017974e+01, 6.35821895e+01, 6.35625817e+01, 6.35429739e+01,\n",
       "        6.35233660e+01, 6.35037582e+01, 6.34841503e+01, 6.34645425e+01,\n",
       "        6.34449346e+01, 6.34253268e+01, 6.34057190e+01, 6.33861111e+01,\n",
       "        6.33665033e+01, 6.33468954e+01, 6.33272876e+01, 6.33076797e+01,\n",
       "        6.32846639e+01, 6.32594538e+01, 6.32342437e+01, 6.32090336e+01,\n",
       "        6.31838235e+01, 6.31586134e+01, 6.31334034e+01, 6.31081933e+01,\n",
       "        6.30829832e+01, 6.30577731e+01, 6.30325630e+01, 6.30073529e+01,\n",
       "        6.29821429e+01, 6.29569328e+01, 6.29317227e+01, 6.29065126e+01,\n",
       "        6.28813025e+01, 6.28560924e+01, 6.28308824e+01, 6.28056723e+01,\n",
       "        6.27804622e+01, 6.27552521e+01, 6.27300420e+01, 6.27048319e+01,\n",
       "        6.26796218e+01, 6.26544118e+01, 6.26292017e+01, 6.72017974e+01,\n",
       "        6.71429739e+01, 6.70841503e+01, 6.70253268e+01, 6.69521475e+01,\n",
       "        6.68681139e+01, 6.67840803e+01, 6.67000467e+01, 6.66160131e+01,\n",
       "        6.65319795e+01, 6.64479458e+01, 6.63639122e+01, 6.62798786e+01,\n",
       "        6.61958450e+01, 6.61118114e+01, 6.60277778e+01, 6.58874883e+01,\n",
       "        6.57194211e+01, 6.55513539e+01, 6.53832867e+01, 6.52152194e+01,\n",
       "        6.50471522e+01, 6.48790850e+01, 6.47110177e+01, 6.45429505e+01,\n",
       "        6.43748833e+01, 6.74232635e+01, 2.12059259e-01, 1.66747361e-01,\n",
       "        1.16283670e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.27011719e+01, 2.98267365e-01, 3.46237719e-02, 0.00000000e+00,\n",
       "        4.32953984e-01, 1.54909641e-01, 3.49422038e-01, 0.00000000e+00,\n",
       "        2.84607410e-01, 7.14462042e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.40472516e-01, 7.47485161e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61.41103175, 61.40785714, 61.40468254, 61.40150794, 61.39833333,\n",
       "       61.39515873, 61.39198413, 61.38880952, 61.38563492, 61.38246032,\n",
       "       61.37928571, 61.37611111, 61.37293651, 61.3697619 , 61.3665873 ,\n",
       "       61.3634127 , 61.3602381 , 61.35706349, 61.35388889, 61.35071429,\n",
       "       61.34753968, 61.34436508, 61.34119048, 61.33801587, 61.33484127,\n",
       "       61.33166667, 61.32849206, 61.32531746, 61.32214286, 61.31896825,\n",
       "       61.31579365, 61.31261905, 61.30944444, 61.30626984, 61.30309524,\n",
       "       61.29992063, 61.29674603, 61.29357143, 61.29039683, 61.28722222,\n",
       "       61.28404762, 61.28087302, 61.27769841, 61.27452381, 61.27134921,\n",
       "       61.2681746 , 61.265     , 61.2618254 , 61.25642857, 61.24802521,\n",
       "       61.23962185, 61.23121849, 61.22281513, 61.21441176, 61.2060084 ,\n",
       "       61.19760504, 61.18920168, 61.18079832, 61.17239496, 61.1639916 ,\n",
       "       61.15558824, 61.14718487, 61.13878151, 61.13037815, 61.12197479,\n",
       "       61.11357143, 61.10516807, 61.09676471, 61.08836134, 61.07995798,\n",
       "       61.07155462, 61.06315126, 61.0547479 , 61.04634454, 61.03794118,\n",
       "       61.02953782, 61.02113445, 61.01273109, 61.00432773, 60.99592437,\n",
       "       60.98752101, 60.97911765, 60.97071429, 60.96231092, 60.95390756,\n",
       "       60.9455042 , 60.93710084, 60.92869748, 60.92029412, 60.91189076,\n",
       "       60.90348739, 60.89508403, 60.88668067, 60.87827731, 60.86987395,\n",
       "       60.86147059, 60.85306723, 60.84466387, 60.8362605 , 60.82785714])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.53182111095756\n",
      "17.42029783587364\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
