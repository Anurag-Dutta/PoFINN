{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1345    62.335831\n",
       "1346    62.334897\n",
       "1347    62.333964\n",
       "1348    62.333030\n",
       "1349    62.332096\n",
       "Name: C1, Length: 1350, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_1250_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1245    62.662815\n",
       "1246    62.654412\n",
       "1247    62.646008\n",
       "1248    62.637605\n",
       "1249    62.629202\n",
       "Name: C1, Length: 1250, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1250)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1, 251) (800, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 2s 54ms/step - loss: 4856.1772 - val_loss: 4034.8145\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4784.3267 - val_loss: 3962.2415\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4719.0278 - val_loss: 3926.0559\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 4684.7490 - val_loss: 3895.6250\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4651.5420 - val_loss: 3865.3450\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4618.5566 - val_loss: 3835.3250\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4585.8525 - val_loss: 3805.5691\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4553.4185 - val_loss: 3776.0610\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4521.2354 - val_loss: 3732.5122\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4472.9873 - val_loss: 3701.9204\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4439.3989 - val_loss: 3671.2847\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4405.9692 - val_loss: 3640.9583\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4372.8896 - val_loss: 3610.9663\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4340.1533 - val_loss: 3581.2832\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4307.7280 - val_loss: 3551.8774\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4275.5850 - val_loss: 3522.7266\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4243.6987 - val_loss: 3493.8118\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4212.0547 - val_loss: 3465.1191\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4180.6377 - val_loss: 3436.6392\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4149.4385 - val_loss: 3408.3638\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4118.4502 - val_loss: 3380.2864\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4087.6646 - val_loss: 3352.4016\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4057.0769 - val_loss: 3324.7056\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4026.6841 - val_loss: 3297.1938\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3996.4805 - val_loss: 3269.8633\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3966.0039 - val_loss: 3241.0972\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3933.6099 - val_loss: 3211.4690\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3901.0024 - val_loss: 3182.0559\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3868.7769 - val_loss: 3153.0894\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3837.0273 - val_loss: 3124.5479\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3805.7095 - val_loss: 3096.3809\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3774.7688 - val_loss: 3066.7883\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3741.1929 - val_loss: 3036.8296\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3707.8735 - val_loss: 3006.7388\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3674.8364 - val_loss: 2977.1602\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3642.3726 - val_loss: 2948.1113\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3610.4536 - val_loss: 2919.5325\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3579.0090 - val_loss: 2891.3633\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3547.9812 - val_loss: 2863.5586\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 3517.3247 - val_loss: 2836.0835\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3487.0059 - val_loss: 2808.9116\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3456.9993 - val_loss: 2782.0227\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3427.2844 - val_loss: 2755.4009\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3397.8450 - val_loss: 2729.0332\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3368.6687 - val_loss: 2702.9094\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3339.7437 - val_loss: 2677.0190\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3311.0625 - val_loss: 2651.3555\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3282.6157 - val_loss: 2625.9124\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3254.3972 - val_loss: 2600.6836\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3226.4009 - val_loss: 2575.6636\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3198.6221 - val_loss: 2550.8484\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3171.0552 - val_loss: 2526.2349\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3143.6968 - val_loss: 2501.8176\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3116.5430 - val_loss: 2477.5938\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3089.5896 - val_loss: 2453.5610\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3062.8347 - val_loss: 2429.7153\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3036.2734 - val_loss: 2406.0552\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3009.9050 - val_loss: 2382.5779\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2983.7261 - val_loss: 2359.2808\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2957.7341 - val_loss: 2336.1614\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2931.9272 - val_loss: 2313.2190\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2906.3035 - val_loss: 2290.4507\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2880.8599 - val_loss: 2267.8547\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2855.5957 - val_loss: 2245.4297\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2830.5085 - val_loss: 2223.1733\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2805.5969 - val_loss: 2201.0854\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2780.8594 - val_loss: 2179.1633\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2756.2942 - val_loss: 2157.4055\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2731.8997 - val_loss: 2135.8110\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2707.6750 - val_loss: 2114.3787\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2683.6177 - val_loss: 2093.1069\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2659.7280 - val_loss: 2071.9939\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2636.0032 - val_loss: 2051.0405\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 2612.4426 - val_loss: 2030.2429\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2589.0447 - val_loss: 2009.6022\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2565.8091 - val_loss: 1989.1152\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2542.7341 - val_loss: 1968.7822\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2519.8186 - val_loss: 1948.6023\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2497.0618 - val_loss: 1928.5736\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2474.4624 - val_loss: 1908.6957\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2452.0190 - val_loss: 1888.9672\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2429.7317 - val_loss: 1869.3877\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2407.5981 - val_loss: 1849.9551\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2385.6177 - val_loss: 1830.6699\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2363.7905 - val_loss: 1811.5309\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2342.1147 - val_loss: 1792.5359\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2320.5894 - val_loss: 1773.6858\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2299.2141 - val_loss: 1754.9785\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2277.9873 - val_loss: 1736.4137\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2256.9089 - val_loss: 1717.9905\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2235.9771 - val_loss: 1699.7074\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2215.1917 - val_loss: 1681.5645\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2194.5515 - val_loss: 1663.5608\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2174.0562 - val_loss: 1645.6953\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2153.7051 - val_loss: 1627.9680\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2133.4966 - val_loss: 1610.3763\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2113.4312 - val_loss: 1592.9209\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2093.5063 - val_loss: 1575.6012\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2073.7219 - val_loss: 1558.4153\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2054.0781 - val_loss: 1541.3632\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2034.5729 - val_loss: 1524.4437\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2015.2067 - val_loss: 1507.6572\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1995.9781 - val_loss: 1491.0013\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1976.8864 - val_loss: 1474.4773\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1957.9307 - val_loss: 1458.0823\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1939.1106 - val_loss: 1441.8176\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1920.4252 - val_loss: 1425.6804\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1901.8740 - val_loss: 1409.6721\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1883.4563 - val_loss: 1393.7908\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1865.1711 - val_loss: 1378.0365\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1847.0182 - val_loss: 1362.4076\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1828.9965 - val_loss: 1346.9045\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1811.1061 - val_loss: 1331.5250\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1793.3450 - val_loss: 1316.2711\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1775.7133 - val_loss: 1301.1393\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1758.2103 - val_loss: 1286.1301\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1740.8356 - val_loss: 1271.2428\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1723.5879 - val_loss: 1256.4773\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1706.4672 - val_loss: 1241.8324\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1689.4723 - val_loss: 1227.3073\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1672.6031 - val_loss: 1212.9021\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1655.8590 - val_loss: 1198.6156\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1639.2389 - val_loss: 1184.4470\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1622.7423 - val_loss: 1170.3965\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1606.3683 - val_loss: 1156.4629\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1590.1169 - val_loss: 1142.6449\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1573.9873 - val_loss: 1128.9441\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1557.9790 - val_loss: 1115.3566\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1542.0909 - val_loss: 1101.8845\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1526.3229 - val_loss: 1088.5270\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1510.6740 - val_loss: 1075.2819\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1495.1437 - val_loss: 1062.1497\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1479.7316 - val_loss: 1049.1290\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1464.4369 - val_loss: 1036.2213\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1449.2594 - val_loss: 1023.4230\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1434.1979 - val_loss: 1010.7365\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1419.2523 - val_loss: 998.1590\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1404.4218 - val_loss: 985.6910\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1389.7062 - val_loss: 973.3320\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1375.1044 - val_loss: 961.0804\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1360.6160 - val_loss: 948.9364\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1346.2405 - val_loss: 936.8994\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1331.9773 - val_loss: 924.9688\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1317.8258 - val_loss: 913.1443\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1303.7853 - val_loss: 901.4246\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1289.8557 - val_loss: 889.8097\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1276.0361 - val_loss: 878.2988\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1262.3259 - val_loss: 866.8915\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1248.7249 - val_loss: 855.5869\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1235.2319 - val_loss: 844.3856\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1221.8472 - val_loss: 833.2861\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1208.5699 - val_loss: 822.2877\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1195.3992 - val_loss: 811.3901\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1182.3344 - val_loss: 800.5929\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1169.3757 - val_loss: 789.8950\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1156.5219 - val_loss: 779.2970\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1143.7729 - val_loss: 768.7969\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1131.1276 - val_loss: 758.3950\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1118.5861 - val_loss: 748.0914\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1106.1476 - val_loss: 737.8845\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1093.8113 - val_loss: 727.7736\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1081.5769 - val_loss: 717.7589\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1069.4441 - val_loss: 707.8396\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1057.4120 - val_loss: 698.0150\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1045.4802 - val_loss: 688.2853\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1033.6484 - val_loss: 678.6488\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1021.9159 - val_loss: 669.1066\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1010.2821 - val_loss: 659.6564\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 998.7469 - val_loss: 650.2990\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 987.3092 - val_loss: 641.0332\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 975.9689 - val_loss: 631.8586\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 964.7254 - val_loss: 622.7750\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 953.5779 - val_loss: 613.7812\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 942.5265 - val_loss: 604.8777\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 931.5701 - val_loss: 596.0629\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 920.7085 - val_loss: 587.3373\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 909.9411 - val_loss: 578.6996\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 899.2673 - val_loss: 570.1498\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 888.6867 - val_loss: 561.6868\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 878.1989 - val_loss: 553.3108\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 867.8031 - val_loss: 545.0204\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 857.4992 - val_loss: 536.8165\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 847.2864 - val_loss: 528.6967\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 837.1642 - val_loss: 520.6627\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 827.1323 - val_loss: 512.7120\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 817.1902 - val_loss: 504.8450\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 807.3373 - val_loss: 497.0614\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 797.5731 - val_loss: 489.3603\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 787.8970 - val_loss: 481.7414\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 778.3088 - val_loss: 474.2040\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 768.8078 - val_loss: 466.7482\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 759.3937 - val_loss: 459.3736\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 750.0660 - val_loss: 452.0778\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 740.8239 - val_loss: 444.8625\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 731.6670 - val_loss: 437.7265\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 722.5952 - val_loss: 430.6691\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 713.6078 - val_loss: 423.6895\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 704.7041 - val_loss: 416.7886\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 695.8839 - val_loss: 409.9643\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 687.1467 - val_loss: 403.2166\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 678.4918 - val_loss: 396.5454\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 669.9190 - val_loss: 389.9500\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 661.4274 - val_loss: 383.4298\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 653.0171 - val_loss: 376.9847\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 644.6874 - val_loss: 370.6138\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 636.4378 - val_loss: 364.3169\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 628.2675 - val_loss: 358.0934\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 620.1766 - val_loss: 351.9429\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 612.1644 - val_loss: 345.8643\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 604.2306 - val_loss: 339.8587\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 596.3742 - val_loss: 333.9237\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 588.5953 - val_loss: 328.0602\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 580.8929 - val_loss: 322.2669\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 573.2670 - val_loss: 316.5446\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 565.7175 - val_loss: 310.8914\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 558.2430 - val_loss: 305.3068\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 550.8434 - val_loss: 299.7913\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 543.5184 - val_loss: 294.3438\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 536.2673 - val_loss: 288.9644\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 529.0899 - val_loss: 283.6520\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 521.9855 - val_loss: 278.4067\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 514.9540 - val_loss: 273.2274\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 507.9945 - val_loss: 268.1142\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 501.1068 - val_loss: 263.0662\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 494.2905 - val_loss: 258.0835\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 487.5449 - val_loss: 253.1651\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 480.8698 - val_loss: 248.3109\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 474.2647 - val_loss: 243.5199\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 467.7291 - val_loss: 238.7920\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 461.2626 - val_loss: 234.1270\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 454.8647 - val_loss: 229.5244\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 448.5349 - val_loss: 224.9830\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 442.2726 - val_loss: 220.5031\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 436.0779 - val_loss: 216.0840\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 429.9497 - val_loss: 211.7254\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 423.8882 - val_loss: 207.4267\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 417.8923 - val_loss: 203.1875\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 411.9622 - val_loss: 199.0072\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 406.0970 - val_loss: 194.8857\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 400.2963 - val_loss: 190.8218\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 394.5598 - val_loss: 186.8160\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 388.8872 - val_loss: 182.8672\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 383.2778 - val_loss: 178.9753\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 377.7312 - val_loss: 175.1399\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 372.2470 - val_loss: 171.3597\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 366.8247 - val_loss: 167.6355\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 361.4641 - val_loss: 163.9658\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 356.1643 - val_loss: 160.3511\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 350.9254 - val_loss: 156.7903\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 345.7468 - val_loss: 153.2831\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 340.6279 - val_loss: 149.8291\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 335.5684 - val_loss: 146.4279\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 330.5678 - val_loss: 143.0791\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 325.6257 - val_loss: 139.7821\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 320.7417 - val_loss: 136.5366\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 315.9154 - val_loss: 133.3420\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 311.1462 - val_loss: 130.1978\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 306.4339 - val_loss: 127.1041\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 301.7779 - val_loss: 124.0599\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 297.1779 - val_loss: 121.0651\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 292.6334 - val_loss: 118.1190\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 288.1441 - val_loss: 115.2214\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 283.7096 - val_loss: 112.3716\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 279.3292 - val_loss: 109.5694\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 275.0026 - val_loss: 106.8144\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 270.7293 - val_loss: 104.1058\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 266.5091 - val_loss: 101.4437\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 262.3414 - val_loss: 98.8274\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 258.2259 - val_loss: 96.2563\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 254.1621 - val_loss: 93.7303\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 250.1499 - val_loss: 91.2490\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 246.1886 - val_loss: 88.8116\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 242.2776 - val_loss: 86.4182\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 238.4169 - val_loss: 84.0677\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 234.6057 - val_loss: 81.7602\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 230.8437 - val_loss: 79.4950\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 227.1308 - val_loss: 77.2721\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 223.4662 - val_loss: 75.0906\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 219.8498 - val_loss: 72.9503\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 216.2809 - val_loss: 70.8509\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 212.7593 - val_loss: 68.7917\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 209.2844 - val_loss: 66.7724\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 205.8560 - val_loss: 64.7928\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 202.4737 - val_loss: 62.8523\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 199.1371 - val_loss: 60.9505\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 195.8456 - val_loss: 59.0869\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 192.5990 - val_loss: 57.2614\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 189.3967 - val_loss: 55.4732\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 186.2387 - val_loss: 53.7221\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 183.1241 - val_loss: 52.0078\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 180.0529 - val_loss: 50.3299\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 177.0245 - val_loss: 48.6877\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 174.0384 - val_loss: 47.0809\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 171.0945 - val_loss: 45.5092\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 168.1923 - val_loss: 43.9723\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 165.3314 - val_loss: 42.4695\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 162.5112 - val_loss: 41.0008\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 159.7316 - val_loss: 39.5653\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 156.9921 - val_loss: 38.1630\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 154.2924 - val_loss: 36.7936\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 151.6322 - val_loss: 35.4563\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 149.0108 - val_loss: 34.1513\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 146.4281 - val_loss: 32.8776\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 143.8837 - val_loss: 31.6351\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 141.3771 - val_loss: 30.4235\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 138.9079 - val_loss: 29.2421\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 136.4759 - val_loss: 28.0909\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 134.0806 - val_loss: 26.9692\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 131.7217 - val_loss: 25.8769\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 129.3987 - val_loss: 24.8135\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 127.1114 - val_loss: 23.7784\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 124.8591 - val_loss: 22.7716\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 122.6419 - val_loss: 21.7925\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 120.4592 - val_loss: 20.8408\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 118.3105 - val_loss: 19.9162\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 116.1957 - val_loss: 19.0181\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 114.1143 - val_loss: 18.1463\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 112.0658 - val_loss: 17.3004\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 110.0501 - val_loss: 16.4802\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 108.0668 - val_loss: 15.6852\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 106.1156 - val_loss: 14.9150\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 104.1959 - val_loss: 14.1693\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 102.3075 - val_loss: 13.4478\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 100.4500 - val_loss: 12.7500\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 98.6230 - val_loss: 12.0755\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 96.8263 - val_loss: 11.4242\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 95.0595 - val_loss: 10.7956\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 93.3223 - val_loss: 10.1895\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 91.6143 - val_loss: 9.6053\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 89.9351 - val_loss: 9.0429\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 88.2843 - val_loss: 8.5018\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 86.6617 - val_loss: 7.9816\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 85.0669 - val_loss: 7.4822\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 83.4997 - val_loss: 7.0031\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 81.9597 - val_loss: 6.5441\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 80.4466 - val_loss: 6.1048\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 78.9600 - val_loss: 5.6846\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 77.4995 - val_loss: 5.2837\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 76.0650 - val_loss: 4.9014\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 74.6560 - val_loss: 4.5375\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 73.2721 - val_loss: 4.1916\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 71.9131 - val_loss: 3.8635\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 70.5788 - val_loss: 3.5527\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 69.2687 - val_loss: 3.2592\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 67.9826 - val_loss: 2.9824\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 66.7202 - val_loss: 2.7221\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 65.4809 - val_loss: 2.4779\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 64.2648 - val_loss: 2.2497\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 63.0713 - val_loss: 2.0370\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 61.9002 - val_loss: 1.8395\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 60.7512 - val_loss: 1.6571\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 59.6241 - val_loss: 1.4893\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 58.5184 - val_loss: 1.3359\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 57.4340 - val_loss: 1.1966\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 56.3705 - val_loss: 1.0711\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 55.3276 - val_loss: 0.9591\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 54.3050 - val_loss: 0.8603\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 53.3024 - val_loss: 0.7745\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 52.3196 - val_loss: 0.7014\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 51.3562 - val_loss: 0.6406\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 50.4122 - val_loss: 0.5920\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 49.4869 - val_loss: 0.5552\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 48.5803 - val_loss: 0.5299\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 47.6920 - val_loss: 0.5160\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 46.8218 - val_loss: 0.5131\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 45.9694 - val_loss: 0.5210\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.1345 - val_loss: 0.5395\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3169 - val_loss: 0.5681\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 43.5162 - val_loss: 0.6068\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 42.7324 - val_loss: 0.6553\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 41.9650 - val_loss: 0.7132\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 41.2138 - val_loss: 0.7804\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 40.4785 - val_loss: 0.8567\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 39.7590 - val_loss: 0.9417\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 39.0549 - val_loss: 1.0352\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 38.3659 - val_loss: 1.1370\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 37.6920 - val_loss: 1.2469\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 37.0328 - val_loss: 1.3647\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 36.3881 - val_loss: 1.4900\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 35.7576 - val_loss: 1.6227\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 35.1411 - val_loss: 1.7626\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 34.5384 - val_loss: 1.9094\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 33.9491 - val_loss: 2.0629\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 33.3732 - val_loss: 2.2230\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 32.8103 - val_loss: 2.3893\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 32.2603 - val_loss: 2.5616\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 31.7229 - val_loss: 2.7399\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 31.1979 - val_loss: 2.9239\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 30.6850 - val_loss: 3.1133\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 30.1841 - val_loss: 3.3080\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 29.6950 - val_loss: 3.5077\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 29.2173 - val_loss: 3.7124\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 28.7510 - val_loss: 3.9218\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 28.2957 - val_loss: 4.1357\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 27.8514 - val_loss: 4.3538\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 27.4178 - val_loss: 4.5760\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 26.9948 - val_loss: 4.8024\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 26.5819 - val_loss: 5.0324\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 26.1793 - val_loss: 5.2660\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 25.7865 - val_loss: 5.5031\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 25.4034 - val_loss: 5.7435\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 25.0299 - val_loss: 5.9870\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 24.6657 - val_loss: 6.2334\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 24.3107 - val_loss: 6.4826\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23.9647 - val_loss: 6.7344\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23.6275 - val_loss: 6.9887\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23.2988 - val_loss: 7.2454\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22.9786 - val_loss: 7.5042\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22.6667 - val_loss: 7.7650\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22.3630 - val_loss: 8.0277\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22.0671 - val_loss: 8.2922\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21.7791 - val_loss: 8.5581\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21.4986 - val_loss: 8.8256\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 21.2256 - val_loss: 9.0945\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 20.9599 - val_loss: 9.3645\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 20.7013 - val_loss: 9.6356\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20.4498 - val_loss: 9.9076\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20.2050 - val_loss: 10.1805\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 19.9669 - val_loss: 10.4542\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 19.7353 - val_loss: 10.7284\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 19.5102 - val_loss: 11.0030\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 19.2913 - val_loss: 11.2781\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 19.0786 - val_loss: 11.5533\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 18.8717 - val_loss: 11.8287\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 18.6707 - val_loss: 12.1042\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 18.4755 - val_loss: 12.3796\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 18.2857 - val_loss: 12.6548\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 18.1015 - val_loss: 12.9297\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 17.9225 - val_loss: 13.2044\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 17.7487 - val_loss: 13.4785\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 17.5800 - val_loss: 13.7521\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 17.4163 - val_loss: 14.0252\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 17.2573 - val_loss: 14.2975\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 17.1031 - val_loss: 14.5690\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 16.9534 - val_loss: 14.8398\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 16.8082 - val_loss: 15.1095\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 16.6674 - val_loss: 15.3783\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 16.5308 - val_loss: 15.6459\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 16.3985 - val_loss: 15.9121\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 16.2701 - val_loss: 16.1774\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 16.1458 - val_loss: 16.4412\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 16.0252 - val_loss: 16.7039\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.9084 - val_loss: 16.9651\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.7952 - val_loss: 17.2247\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.6856 - val_loss: 17.4828\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.5794 - val_loss: 17.7392\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 15.4766 - val_loss: 17.9941\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.3771 - val_loss: 18.2473\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.2807 - val_loss: 18.4985\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.1876 - val_loss: 18.7482\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.0974 - val_loss: 18.9959\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.0102 - val_loss: 19.2418\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 14.9257 - val_loss: 19.4858\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 14.8441 - val_loss: 19.7277\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 14.7652 - val_loss: 19.9675\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 14.6889 - val_loss: 20.2056\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 14.6151 - val_loss: 20.4414\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 14.5439 - val_loss: 20.6748\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 14.4750 - val_loss: 20.9063\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 14.4085 - val_loss: 21.1358\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 14.3443 - val_loss: 21.3629\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 14.2822 - val_loss: 21.5879\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 14.2223 - val_loss: 21.8104\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 14.1645 - val_loss: 22.0309\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 14.1086 - val_loss: 22.2488\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 14.0548 - val_loss: 22.4646\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 14.0029 - val_loss: 22.6781\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 13.9527 - val_loss: 22.8891\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.9044 - val_loss: 23.0978\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.8578 - val_loss: 23.3041\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 13.8128 - val_loss: 23.5078\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.7695 - val_loss: 23.7095\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.7278 - val_loss: 23.9086\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 13.6876 - val_loss: 24.1051\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 13.6489 - val_loss: 24.2994\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.6115 - val_loss: 24.4913\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.5756 - val_loss: 24.6807\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 13.5409 - val_loss: 24.8675\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.5077 - val_loss: 25.0518\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.4756 - val_loss: 25.2340\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.4448 - val_loss: 25.4135\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.4151 - val_loss: 25.5905\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.3866 - val_loss: 25.7651\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 13.3591 - val_loss: 25.9373\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.3327 - val_loss: 26.1071\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.3073 - val_loss: 26.2744\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.2830 - val_loss: 26.4393\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.2595 - val_loss: 26.6017\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.2371 - val_loss: 26.7618\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.2154 - val_loss: 26.9195\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 13.1946 - val_loss: 27.0747\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 13.1747 - val_loss: 27.2275\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.1556 - val_loss: 27.3781\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.1372 - val_loss: 27.5259\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.1196 - val_loss: 27.6718\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.1027 - val_loss: 27.8152\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.0865 - val_loss: 27.9561\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.0709 - val_loss: 28.0950\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.0560 - val_loss: 28.2314\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.0417 - val_loss: 28.3656\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1e-10\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 432ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.72410131e+01, 6.72214052e+01, 6.72017974e+01, 6.71821895e+01,\n",
       "        6.71625817e+01, 6.71429739e+01, 6.71233660e+01, 6.71037582e+01,\n",
       "        6.70841503e+01, 6.70645425e+01, 6.70449346e+01, 6.70253268e+01,\n",
       "        6.70057190e+01, 6.69801587e+01, 6.69521475e+01, 6.69241363e+01,\n",
       "        6.68961251e+01, 6.68681139e+01, 6.68401027e+01, 6.68120915e+01,\n",
       "        6.67840803e+01, 6.67560691e+01, 6.67280579e+01, 6.67000467e+01,\n",
       "        6.66720355e+01, 6.66440243e+01, 6.66160131e+01, 6.65880019e+01,\n",
       "        6.65599907e+01, 6.65319795e+01, 6.65039682e+01, 6.64759571e+01,\n",
       "        6.64479458e+01, 6.64199346e+01, 6.63919234e+01, 6.63639122e+01,\n",
       "        6.63359010e+01, 6.63078898e+01, 6.62798786e+01, 6.62518674e+01,\n",
       "        6.62238562e+01, 6.61958450e+01, 6.61678338e+01, 6.61398226e+01,\n",
       "        6.61118114e+01, 6.60838002e+01, 6.60557890e+01, 6.60277778e+01,\n",
       "        6.59995332e+01, 6.59435107e+01, 6.58874883e+01, 6.58314659e+01,\n",
       "        6.57754435e+01, 6.57194211e+01, 6.56633987e+01, 6.56073763e+01,\n",
       "        6.55513539e+01, 6.54953315e+01, 6.54393091e+01, 6.53832867e+01,\n",
       "        6.53272642e+01, 6.52712418e+01, 6.52152194e+01, 6.51591970e+01,\n",
       "        6.51031746e+01, 6.50471522e+01, 6.49911298e+01, 6.49351074e+01,\n",
       "        6.48790850e+01, 6.48230626e+01, 6.47670401e+01, 6.47110177e+01,\n",
       "        6.46549953e+01, 6.45989729e+01, 6.45429505e+01, 6.44869281e+01,\n",
       "        6.44309057e+01, 6.43748833e+01, 6.43188609e+01, 6.42628385e+01,\n",
       "        7.08663635e+01, 0.00000000e+00, 3.43512982e-01, 0.00000000e+00,\n",
       "        5.31589627e-01, 0.00000000e+00, 9.99319851e-02, 5.06476998e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 8.14416051e-01, 0.00000000e+00, 7.59479761e-01,\n",
       "        0.00000000e+00, 7.14415133e-01, 1.12784910e+00, 2.57744417e-02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([62.62079832, 62.61239496, 62.6039916 , 62.59558824, 62.58718487,\n",
       "       62.57878151, 62.57037815, 62.56197479, 62.55357143, 62.54516807,\n",
       "       62.53676471, 62.52836134, 62.51995798, 62.51155462, 62.50315126,\n",
       "       62.4947479 , 62.48634454, 62.47794118, 62.46953782, 62.46113445,\n",
       "       62.45273109, 62.44432773, 62.43592437, 62.42752101, 62.41911765,\n",
       "       62.41071429, 62.40231092, 62.39932306, 62.39838936, 62.39745565,\n",
       "       62.39652194, 62.39558824, 62.39465453, 62.39372082, 62.39278711,\n",
       "       62.39185341, 62.3909197 , 62.38998599, 62.38905229, 62.38811858,\n",
       "       62.38718487, 62.38625117, 62.38531746, 62.38438375, 62.38345005,\n",
       "       62.38251634, 62.38158263, 62.38064893, 62.37971522, 62.37878151,\n",
       "       62.37784781, 62.3769141 , 62.37598039, 62.37504669, 62.37411298,\n",
       "       62.37317927, 62.37224556, 62.37131186, 62.37037815, 62.36944444,\n",
       "       62.36851074, 62.36757703, 62.36664332, 62.36570962, 62.36477591,\n",
       "       62.3638422 , 62.3629085 , 62.36197479, 62.36104108, 62.36010738,\n",
       "       62.35917367, 62.35823996, 62.35730626, 62.35637255, 62.35543884,\n",
       "       62.35450514, 62.35357143, 62.35263772, 62.35170401, 62.35077031,\n",
       "       62.3498366 , 62.34890289, 62.34796919, 62.34703548, 62.34610177,\n",
       "       62.34516807, 62.34423436, 62.34330065, 62.34236695, 62.34143324,\n",
       "       62.34049953, 62.33956583, 62.33863212, 62.33769841, 62.33676471,\n",
       "       62.335831  , 62.33489729, 62.33396359, 62.33302988, 62.33209617])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.27860828805677\n",
      "14.788137157738115\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
