{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2045    56.798016\n",
       "2046    56.782143\n",
       "2047    56.766270\n",
       "2048    56.750397\n",
       "2049    56.734524\n",
       "Name: C1, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_1950_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1945     0.000000\n",
       "1946     0.000000\n",
       "1947     0.000000\n",
       "1948     0.000000\n",
       "1949     0.000000\n",
       "Name: C1, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1950)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1, 251) (1500, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 3s 32ms/step - loss: 4291.8706 - val_loss: 2874.4358\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4117.5957 - val_loss: 2717.0605\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3988.5767 - val_loss: 2647.2388\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3903.3232 - val_loss: 2591.0513\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3822.5146 - val_loss: 2536.9990\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3744.1621 - val_loss: 2484.6904\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3667.8062 - val_loss: 2433.8416\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3593.1528 - val_loss: 2384.2932\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3520.0259 - val_loss: 2335.9468\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3448.3118 - val_loss: 2288.7351\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3377.9324 - val_loss: 2242.6089\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3308.8286 - val_loss: 2197.5317\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3240.9568 - val_loss: 2153.4746\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3174.2798 - val_loss: 2110.4304\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 3108.7676 - val_loss: 2068.8345\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3044.5605 - val_loss: 2026.9740\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2981.1306 - val_loss: 1986.7411\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2918.9644 - val_loss: 1947.4200\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2857.8721 - val_loss: 1908.9935\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2797.8354 - val_loss: 1871.4479\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2738.8391 - val_loss: 1834.7681\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2680.8660 - val_loss: 1798.9408\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2623.9021 - val_loss: 1763.9525\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2567.9314 - val_loss: 1729.7904\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2512.9407 - val_loss: 1696.4421\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2458.9170 - val_loss: 1663.8956\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2405.8467 - val_loss: 1632.1389\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2353.7166 - val_loss: 1601.1602\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2302.5146 - val_loss: 1570.9485\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2252.2285 - val_loss: 1541.4924\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2202.8469 - val_loss: 1512.7808\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2154.3572 - val_loss: 1484.8025\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2106.7478 - val_loss: 1457.5474\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2060.0081 - val_loss: 1431.0045\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2014.1262 - val_loss: 1405.1638\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1969.0917 - val_loss: 1380.0142\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1924.8929 - val_loss: 1355.5461\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1881.5189 - val_loss: 1331.7490\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1838.9604 - val_loss: 1308.6133\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1797.2061 - val_loss: 1286.1285\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1756.2454 - val_loss: 1264.2852\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1716.0684 - val_loss: 1243.0735\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1676.6644 - val_loss: 1222.4834\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1638.0232 - val_loss: 1202.5059\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1600.1355 - val_loss: 1183.1310\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1562.9912 - val_loss: 1164.3491\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1526.5801 - val_loss: 1146.1515\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1490.8931 - val_loss: 1128.5284\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1455.9199 - val_loss: 1111.4711\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1421.6515 - val_loss: 1094.9695\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1388.0778 - val_loss: 1079.0150\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1355.1897 - val_loss: 1063.5990\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1322.9777 - val_loss: 1048.7118\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1291.4329 - val_loss: 1034.3448\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1260.5452 - val_loss: 1020.4894\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1230.3066 - val_loss: 1007.1360\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1200.7076 - val_loss: 994.2764\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1171.7389 - val_loss: 981.9024\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1143.3917 - val_loss: 970.0045\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1115.6573 - val_loss: 958.5745\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1088.5267 - val_loss: 947.6039\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1061.9911 - val_loss: 937.0843\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1036.0424 - val_loss: 927.0071\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1010.6713 - val_loss: 917.3641\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 985.8695 - val_loss: 908.1467\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 961.6280 - val_loss: 899.3472\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 937.9394 - val_loss: 890.9568\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 914.7943 - val_loss: 882.9679\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 892.1850 - val_loss: 875.3721\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 870.1025 - val_loss: 868.1614\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 848.5394 - val_loss: 861.3278\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 827.4869 - val_loss: 854.8635\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 806.9373 - val_loss: 848.7606\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 786.8824 - val_loss: 843.0110\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 767.3140 - val_loss: 837.6073\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 748.2245 - val_loss: 832.5414\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 729.6058 - val_loss: 827.8063\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 711.4504 - val_loss: 823.3937\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 693.7499 - val_loss: 819.2961\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 676.4969 - val_loss: 815.5064\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 659.6838 - val_loss: 812.0171\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 643.3030 - val_loss: 808.8205\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 627.3468 - val_loss: 805.9095\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 611.8079 - val_loss: 803.2768\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 596.6788 - val_loss: 800.9150\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 581.9520 - val_loss: 798.8173\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 567.6201 - val_loss: 796.9763\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 553.6761 - val_loss: 795.3850\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 540.1128 - val_loss: 794.0364\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 526.9225 - val_loss: 792.9238\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 514.0988 - val_loss: 792.0400\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 501.6342 - val_loss: 791.3785\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 489.5218 - val_loss: 790.9324\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 477.7546 - val_loss: 790.6952\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 466.3260 - val_loss: 790.6600\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 455.2289 - val_loss: 790.8206\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 444.4568 - val_loss: 791.1702\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 434.0027 - val_loss: 791.7026\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 423.8604 - val_loss: 792.4114\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 414.0230 - val_loss: 793.2904\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 404.4842 - val_loss: 794.3333\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 395.2374 - val_loss: 795.5342\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 386.2763 - val_loss: 796.8868\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 377.5947 - val_loss: 798.3851\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 369.1862 - val_loss: 800.0234\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 361.0446 - val_loss: 801.7958\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 353.1641 - val_loss: 803.6965\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 345.5384 - val_loss: 805.7199\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 338.1614 - val_loss: 807.8604\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 331.0274 - val_loss: 810.1124\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 324.1305 - val_loss: 812.4705\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 317.4651 - val_loss: 814.9295\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 311.0254 - val_loss: 817.4839\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 304.8057 - val_loss: 820.1287\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 298.8005 - val_loss: 822.8588\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 293.0043 - val_loss: 825.6693\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 287.4117 - val_loss: 828.5549\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 282.0174 - val_loss: 831.5112\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 276.8162 - val_loss: 834.5331\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 271.8028 - val_loss: 837.6161\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 266.9721 - val_loss: 840.7559\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 262.3192 - val_loss: 843.9477\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 257.8390 - val_loss: 847.1873\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 253.5266 - val_loss: 850.4703\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 249.3774 - val_loss: 853.7925\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 245.3865 - val_loss: 857.1500\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 241.5494 - val_loss: 860.5387\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 237.8615 - val_loss: 863.9546\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 234.3183 - val_loss: 867.3943\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 230.9154 - val_loss: 870.8531\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 227.6484 - val_loss: 874.3290\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 224.5132 - val_loss: 877.8173\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 221.5056 - val_loss: 881.3151\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 218.6214 - val_loss: 884.8184\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 215.8568 - val_loss: 888.3249\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 213.2077 - val_loss: 891.8314\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 210.6704 - val_loss: 895.3340\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 208.2410 - val_loss: 898.8307\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 205.9161 - val_loss: 902.3185\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 203.6919 - val_loss: 905.7942\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 201.5648 - val_loss: 909.2562\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 199.5315 - val_loss: 912.7012\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 197.5886 - val_loss: 916.1275\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 195.7330 - val_loss: 919.5316\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 193.9614 - val_loss: 922.9122\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 192.2706 - val_loss: 926.2671\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 190.6576 - val_loss: 929.5939\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 189.1195 - val_loss: 932.8912\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 187.6535 - val_loss: 936.1568\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 186.2567 - val_loss: 939.3893\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 184.9264 - val_loss: 942.5869\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 183.6599 - val_loss: 945.7480\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 182.4547 - val_loss: 948.8712\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.3083 - val_loss: 951.9552\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 180.2183 - val_loss: 954.9982\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 179.1824 - val_loss: 957.9999\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 178.1981 - val_loss: 960.9586\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 177.2634 - val_loss: 963.8737\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 176.3762 - val_loss: 966.7441\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 175.5343 - val_loss: 969.5688\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 174.7357 - val_loss: 972.3467\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 173.9787 - val_loss: 975.0780\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 173.2612 - val_loss: 977.7612\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 172.5814 - val_loss: 980.3965\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 171.9377 - val_loss: 982.9830\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 171.3284 - val_loss: 985.5206\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 170.7518 - val_loss: 988.0085\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 170.2065 - val_loss: 990.4467\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 169.6909 - val_loss: 992.8350\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 169.2035 - val_loss: 995.1735\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.7430 - val_loss: 997.4617\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 168.3082 - val_loss: 999.6998\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 167.8976 - val_loss: 1001.8881\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 167.5101 - val_loss: 1004.0264\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 167.1445 - val_loss: 1006.1148\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 166.7997 - val_loss: 1008.1533\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 166.4746 - val_loss: 1010.1427\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 166.1683 - val_loss: 1012.0828\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 165.8796 - val_loss: 1013.9739\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 165.6077 - val_loss: 1015.8173\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 165.3517 - val_loss: 1017.6126\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 165.1107 - val_loss: 1019.3602\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 164.8840 - val_loss: 1021.0606\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 164.6706 - val_loss: 1022.7149\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 164.4700 - val_loss: 1024.3226\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 164.2813 - val_loss: 1025.8857\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 164.1039 - val_loss: 1027.4031\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 163.9372 - val_loss: 1028.8772\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 163.7806 - val_loss: 1030.3079\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 163.6334 - val_loss: 1031.6952\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 163.4953 - val_loss: 1033.0409\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 163.3655 - val_loss: 1034.3450\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 163.2437 - val_loss: 1035.6088\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 163.1293 - val_loss: 1036.8323\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 163.0220 - val_loss: 1038.0168\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 162.9213 - val_loss: 1039.1631\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 162.8268 - val_loss: 1040.2711\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 162.7381 - val_loss: 1041.3430\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 162.6549 - val_loss: 1042.3785\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 162.5770 - val_loss: 1043.3795\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 162.5038 - val_loss: 1044.3453\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 162.4352 - val_loss: 1045.2778\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 162.3709 - val_loss: 1046.1772\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 162.3105 - val_loss: 1047.0449\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 162.2540 - val_loss: 1047.8812\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 162.2009 - val_loss: 1048.6874\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 162.1512 - val_loss: 1049.4637\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 162.1045 - val_loss: 1050.2114\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 162.0609 - val_loss: 1050.9310\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 162.0199 - val_loss: 1051.6227\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.9815 - val_loss: 1052.2887\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.9454 - val_loss: 1052.9285\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.9117 - val_loss: 1053.5437\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.8799 - val_loss: 1054.1348\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.8503 - val_loss: 1054.7020\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.8224 - val_loss: 1055.2466\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.7962 - val_loss: 1055.7692\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.7717 - val_loss: 1056.2704\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.7487 - val_loss: 1056.7512\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.7271 - val_loss: 1057.2117\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.7069 - val_loss: 1057.6528\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.6879 - val_loss: 1058.0753\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.6702 - val_loss: 1058.4799\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.6534 - val_loss: 1058.8673\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.6378 - val_loss: 1059.2371\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.6230 - val_loss: 1059.5913\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.6093 - val_loss: 1059.9303\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.5963 - val_loss: 1060.2535\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.5842 - val_loss: 1060.5629\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.5728 - val_loss: 1060.8579\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.5621 - val_loss: 1061.1399\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.5521 - val_loss: 1061.4091\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.5426 - val_loss: 1061.6650\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.5338 - val_loss: 1061.9097\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.5255 - val_loss: 1062.1431\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.5177 - val_loss: 1062.3651\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.5104 - val_loss: 1062.5769\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.5036 - val_loss: 1062.7784\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4971 - val_loss: 1062.9700\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 161.4911 - val_loss: 1063.1531\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4855 - val_loss: 1063.3265\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4801 - val_loss: 1063.4915\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4752 - val_loss: 1063.6487\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4706 - val_loss: 1063.7980\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4663 - val_loss: 1063.9399\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4622 - val_loss: 1064.0742\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4584 - val_loss: 1064.2023\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4548 - val_loss: 1064.3235\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4515 - val_loss: 1064.4386\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4484 - val_loss: 1064.5479\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.4454 - val_loss: 1064.6514\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4428 - val_loss: 1064.7496\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.4402 - val_loss: 1064.8423\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4379 - val_loss: 1064.9304\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4356 - val_loss: 1065.0139\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4335 - val_loss: 1065.0931\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4317 - val_loss: 1065.1674\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4300 - val_loss: 1065.2383\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4283 - val_loss: 1065.3051\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4268 - val_loss: 1065.3688\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4254 - val_loss: 1065.4285\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4240 - val_loss: 1065.4847\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4228 - val_loss: 1065.5383\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4218 - val_loss: 1065.5885\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4208 - val_loss: 1065.6364\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4198 - val_loss: 1065.6812\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4189 - val_loss: 1065.7236\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4182 - val_loss: 1065.7633\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4175 - val_loss: 1065.8011\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 161.4169 - val_loss: 1065.8362\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 161.4163 - val_loss: 1065.8700\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 161.4158 - val_loss: 1065.9015\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 161.4153 - val_loss: 1065.9315\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 161.4149 - val_loss: 1065.9596\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4145 - val_loss: 1065.9856\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 161.4142 - val_loss: 1066.0103\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 161.4139 - val_loss: 1066.0336\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 161.4137 - val_loss: 1066.0557\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 161.4135 - val_loss: 1066.0760\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 161.4133 - val_loss: 1066.0956\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 161.4132 - val_loss: 1066.1139\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 161.4131 - val_loss: 1066.1309\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 161.4130 - val_loss: 1066.1471\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 161.4129 - val_loss: 1066.1620\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 161.4129 - val_loss: 1066.1765\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 161.4129 - val_loss: 1066.1896\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 161.4129 - val_loss: 1066.2021\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 161.4130 - val_loss: 1066.2137\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 161.4130 - val_loss: 1066.2247\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 161.4131 - val_loss: 1066.2349\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 161.4131 - val_loss: 1066.2446\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 161.4133 - val_loss: 1066.2539\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 161.4134 - val_loss: 1066.2621\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 161.4136 - val_loss: 1066.2703\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 161.4137 - val_loss: 1066.2775\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 161.4138 - val_loss: 1066.2844\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 161.4140 - val_loss: 1066.2909\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 161.4142 - val_loss: 1066.2972\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 161.4143 - val_loss: 1066.3029\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 161.4145 - val_loss: 1066.3083\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 161.4147 - val_loss: 1066.3127\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 161.4149 - val_loss: 1066.3174\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 161.4151 - val_loss: 1066.3221\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 161.4153 - val_loss: 1066.3259\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 161.4155 - val_loss: 1066.3296\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 161.4157 - val_loss: 1066.3333\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 161.4160 - val_loss: 1066.3364\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 161.4162 - val_loss: 1066.3395\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 161.4164 - val_loss: 1066.3422\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 161.4167 - val_loss: 1066.3451\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 161.4169 - val_loss: 1066.3474\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 161.4171 - val_loss: 1066.3497\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 161.4173 - val_loss: 1066.3514\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 161.4175 - val_loss: 1066.3533\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 161.4178 - val_loss: 1066.3552\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 161.4180 - val_loss: 1066.3572\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 161.4182 - val_loss: 1066.3582\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 161.4185 - val_loss: 1066.3597\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 1s 44ms/step - loss: 161.4187 - val_loss: 1066.3611\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 161.4190 - val_loss: 1066.3625\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 1s 54ms/step - loss: 161.4192 - val_loss: 1066.3633\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 161.4194 - val_loss: 1066.3644\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 161.4197 - val_loss: 1066.3657\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 161.4199 - val_loss: 1066.3665\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 161.4201 - val_loss: 1066.3674\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 161.4204 - val_loss: 1066.3683\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 161.4205 - val_loss: 1066.3688\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4208 - val_loss: 1066.3694\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4210 - val_loss: 1066.3702\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4212 - val_loss: 1066.3705\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4214 - val_loss: 1066.3711\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4216 - val_loss: 1066.3715\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4218 - val_loss: 1066.3717\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4221 - val_loss: 1066.3719\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4223 - val_loss: 1066.3723\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4225 - val_loss: 1066.3732\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4227 - val_loss: 1066.3734\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4229 - val_loss: 1066.3739\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4230 - val_loss: 1066.3739\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4232 - val_loss: 1066.3739\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 161.4235 - val_loss: 1066.3741\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 161.4236 - val_loss: 1066.3741\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4238 - val_loss: 1066.3741\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 161.4240 - val_loss: 1066.3744\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 161.4242 - val_loss: 1066.3746\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 161.4244 - val_loss: 1066.3749\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 161.4245 - val_loss: 1066.3746\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4247 - val_loss: 1066.3746\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4249 - val_loss: 1066.3748\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4250 - val_loss: 1066.3748\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4252 - val_loss: 1066.3748\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4254 - val_loss: 1066.3748\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4256 - val_loss: 1066.3749\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4257 - val_loss: 1066.3746\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4259 - val_loss: 1066.3746\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4260 - val_loss: 1066.3746\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4262 - val_loss: 1066.3748\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4264 - val_loss: 1066.3748\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4265 - val_loss: 1066.3748\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4266 - val_loss: 1066.3748\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4267 - val_loss: 1066.3746\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 161.4269 - val_loss: 1066.3746\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4270 - val_loss: 1066.3746\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4272 - val_loss: 1066.3744\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4274 - val_loss: 1066.3744\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4275 - val_loss: 1066.3745\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4276 - val_loss: 1066.3744\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4277 - val_loss: 1066.3744\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4278 - val_loss: 1066.3745\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4279 - val_loss: 1066.3744\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4281 - val_loss: 1066.3744\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4282 - val_loss: 1066.3743\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4284 - val_loss: 1066.3743\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4284 - val_loss: 1066.3741\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4285 - val_loss: 1066.3739\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4287 - val_loss: 1066.3738\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4288 - val_loss: 1066.3738\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4290 - val_loss: 1066.3737\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4290 - val_loss: 1066.3734\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4291 - val_loss: 1066.3735\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4293 - val_loss: 1066.3738\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4293 - val_loss: 1066.3735\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4295 - val_loss: 1066.3738\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 161.4296 - val_loss: 1066.3732\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4297 - val_loss: 1066.3732\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4297 - val_loss: 1066.3732\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4298 - val_loss: 1066.3733\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4299 - val_loss: 1066.3733\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4300 - val_loss: 1066.3732\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4301 - val_loss: 1066.3732\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4302 - val_loss: 1066.3732\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4303 - val_loss: 1066.3732\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4304 - val_loss: 1066.3732\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4305 - val_loss: 1066.3732\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4305 - val_loss: 1066.3728\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4306 - val_loss: 1066.3729\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4307 - val_loss: 1066.3730\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 161.4308 - val_loss: 1066.3732\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4308 - val_loss: 1066.3730\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4309 - val_loss: 1066.3728\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4310 - val_loss: 1066.3726\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4310 - val_loss: 1066.3726\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4311 - val_loss: 1066.3726\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 161.4312 - val_loss: 1066.3726\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4312 - val_loss: 1066.3726\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4313 - val_loss: 1066.3726\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4314 - val_loss: 1066.3723\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 161.4314 - val_loss: 1066.3721\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4315 - val_loss: 1066.3719\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4316 - val_loss: 1066.3721\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4317 - val_loss: 1066.3718\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4317 - val_loss: 1066.3721\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 161.4318 - val_loss: 1066.3724\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4318 - val_loss: 1066.3723\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 161.4318 - val_loss: 1066.3723\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 161.4319 - val_loss: 1066.3719\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 161.4320 - val_loss: 1066.3719\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4321 - val_loss: 1066.3722\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4321 - val_loss: 1066.3719\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4321 - val_loss: 1066.3718\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4322 - val_loss: 1066.3715\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4323 - val_loss: 1066.3716\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4323 - val_loss: 1066.3711\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4324 - val_loss: 1066.3712\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4324 - val_loss: 1066.3710\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4324 - val_loss: 1066.3708\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4325 - val_loss: 1066.3710\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4326 - val_loss: 1066.3711\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4326 - val_loss: 1066.3710\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4326 - val_loss: 1066.3707\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4327 - val_loss: 1066.3710\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4328 - val_loss: 1066.3710\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4328 - val_loss: 1066.3712\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 161.4328 - val_loss: 1066.3710\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 161.4328 - val_loss: 1066.3708\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4329 - val_loss: 1066.3706\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4329 - val_loss: 1066.3706\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4330 - val_loss: 1066.3706\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4330 - val_loss: 1066.3707\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4330 - val_loss: 1066.3706\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4331 - val_loss: 1066.3708\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4331 - val_loss: 1066.3706\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4332 - val_loss: 1066.3706\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4332 - val_loss: 1066.3705\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4333 - val_loss: 1066.3706\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4333 - val_loss: 1066.3711\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.4333 - val_loss: 1066.3708\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.4333 - val_loss: 1066.3706\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4334 - val_loss: 1066.3707\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4334 - val_loss: 1066.3706\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.4334 - val_loss: 1066.3706\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4334 - val_loss: 1066.3706\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4334 - val_loss: 1066.3704\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4335 - val_loss: 1066.3702\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4335 - val_loss: 1066.3704\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4336 - val_loss: 1066.3704\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4336 - val_loss: 1066.3704\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4336 - val_loss: 1066.3704\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4336 - val_loss: 1066.3704\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4336 - val_loss: 1066.3704\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4337 - val_loss: 1066.3704\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4337 - val_loss: 1066.3702\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.4337 - val_loss: 1066.3698\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4337 - val_loss: 1066.3698\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4337 - val_loss: 1066.3698\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4337 - val_loss: 1066.3698\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4338 - val_loss: 1066.3698\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4338 - val_loss: 1066.3696\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4338 - val_loss: 1066.3696\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4338 - val_loss: 1066.3695\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4339 - val_loss: 1066.3695\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4339 - val_loss: 1066.3694\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.4339 - val_loss: 1066.3695\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4339 - val_loss: 1066.3694\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4339 - val_loss: 1066.3694\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4340 - val_loss: 1066.3694\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4340 - val_loss: 1066.3694\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 161.4340 - val_loss: 1066.3694\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4340 - val_loss: 1066.3694\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4340 - val_loss: 1066.3694\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4340 - val_loss: 1066.3693\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4341 - val_loss: 1066.3691\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4341 - val_loss: 1066.3694\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4341 - val_loss: 1066.3694\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.4341 - val_loss: 1066.3694\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4342 - val_loss: 1066.3694\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4342 - val_loss: 1066.3694\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4342 - val_loss: 1066.3694\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 161.4342 - val_loss: 1066.3694\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4342 - val_loss: 1066.3694\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.4342 - val_loss: 1066.3691\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4342 - val_loss: 1066.3690\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4342 - val_loss: 1066.3688\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4342 - val_loss: 1066.3684\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4343 - val_loss: 1066.3684\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4343 - val_loss: 1066.3684\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 161.4343 - val_loss: 1066.3683\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.4344 - val_loss: 1066.3684\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 161.4344 - val_loss: 1066.3683\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.4344 - val_loss: 1066.3684\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 533ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.30913866e+01, 6.30157563e+01, 6.29401261e+01, 6.28644958e+01,\n",
       "        6.27888655e+01, 6.27132353e+01, 6.26376050e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.36802288e+01, 6.36214052e+01, 6.35625817e+01,\n",
       "        6.35037582e+01, 6.34449346e+01, 6.33861111e+01, 6.33272876e+01,\n",
       "        6.32594538e+01, 6.31838235e+01, 6.31081933e+01, 6.30325630e+01,\n",
       "        6.29569328e+01, 6.28813025e+01, 6.28056723e+01, 6.27300420e+01,\n",
       "        6.26544118e+01, 6.70841503e+01, 6.68681139e+01, 6.66160131e+01,\n",
       "        6.63639122e+01, 6.61118114e+01, 6.57194211e+01, 6.52152194e+01,\n",
       "        6.47110177e+01, 6.74232635e+01, 1.16283670e-01, 0.00000000e+00,\n",
       "        1.64812088e-01, 2.60593474e-01, 5.33040600e-03, 3.57712686e-01,\n",
       "        5.91910720e-01, 3.75749886e-01, 0.00000000e+00, 6.28981092e+01,\n",
       "        6.28224790e+01, 6.27468487e+01, 6.26712185e+01, 6.71821895e+01,\n",
       "        6.70057190e+01, 6.67560691e+01, 6.65039682e+01, 6.62518674e+01,\n",
       "        6.59995332e+01, 6.54953315e+01, 6.49911298e+01, 6.44869281e+01,\n",
       "        0.00000000e+00, 1.20769350e-01, 6.63545752e+01, 6.61024743e+01,\n",
       "        6.57007470e+01, 6.51965453e+01, 6.46923436e+01, 6.41881419e+01,\n",
       "        6.38893791e+01, 6.37129085e+01, 6.35364379e+01, 1.39298870e-01,\n",
       "        5.88601890e-01, 5.86315537e+01, 0.00000000e+00, 1.25890970e-01,\n",
       "        1.78509590e-01, 0.00000000e+00, 3.38448170e-01, 7.85693410e-01,\n",
       "        6.28734245e+01, 1.86294273e-01, 1.93479389e-01, 3.54445040e-01,\n",
       "        2.84742951e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.78205246e-02,\n",
       "        1.98835447e-01, 6.84436738e-01, 3.81852597e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.97031599e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58.30595238, 58.29007937, 58.27420635, 58.25833333, 58.24246032,\n",
       "       58.2265873 , 58.21071429, 58.19484127, 58.17896825, 58.16309524,\n",
       "       58.14722222, 58.13134921, 58.11547619, 58.09960317, 58.08373016,\n",
       "       58.06785714, 58.05198413, 58.03611111, 58.0202381 , 58.00436508,\n",
       "       57.98849206, 57.97261905, 57.95674603, 57.94087302, 57.925     ,\n",
       "       57.90912698, 57.89325397, 57.87738095, 57.86150794, 57.84563492,\n",
       "       57.8297619 , 57.81388889, 57.79801587, 57.78214286, 57.76626984,\n",
       "       57.75039683, 57.73452381, 57.71865079, 57.70277778, 57.68690476,\n",
       "       57.67103175, 57.65515873, 57.63928571, 57.6234127 , 57.60753968,\n",
       "       57.59166667, 57.57579365, 57.55992063, 57.54404762, 57.5281746 ,\n",
       "       57.51230159, 57.49642857, 57.48055556, 57.46468254, 57.44880952,\n",
       "       57.43293651, 57.41706349, 57.40119048, 57.38531746, 57.36944444,\n",
       "       57.35357143, 57.33769841, 57.3218254 , 57.30595238, 57.29007937,\n",
       "       57.27420635, 57.25833333, 57.24246032, 57.2265873 , 57.21071429,\n",
       "       57.19484127, 57.17896825, 57.16309524, 57.14722222, 57.13134921,\n",
       "       57.11547619, 57.09960317, 57.08373016, 57.06785714, 57.05198413,\n",
       "       57.03611111, 57.0202381 , 57.00436508, 56.98849206, 56.97261905,\n",
       "       56.95674603, 56.94087302, 56.925     , 56.90912698, 56.89325397,\n",
       "       56.87738095, 56.86150794, 56.84563492, 56.8297619 , 56.81388889,\n",
       "       56.79801587, 56.78214286, 56.76626984, 56.75039683, 56.73452381])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.22473073182488\n",
      "28.7883685477014\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
