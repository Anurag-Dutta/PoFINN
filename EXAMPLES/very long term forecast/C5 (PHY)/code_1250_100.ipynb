{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "1345    68.594141\n",
       "1346    68.583870\n",
       "1347    68.573599\n",
       "1348    68.563329\n",
       "1349    68.553058\n",
       "Name: C5, Length: 1350, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_1250_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "1245    69.416807\n",
       "1246    69.413072\n",
       "1247    69.409337\n",
       "1248    69.405602\n",
       "1249    69.401867\n",
       "Name: C5, Length: 1250, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1250)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1, 251) (800, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 2s 68ms/step - loss: 5853.1860 - val_loss: 4961.2773\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5772.8862 - val_loss: 4929.0220\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5730.8936 - val_loss: 4879.5503\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5683.9014 - val_loss: 4845.8970\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5647.5513 - val_loss: 4812.3208\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5608.7900 - val_loss: 4767.0088\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5561.7969 - val_loss: 4732.3291\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5523.3604 - val_loss: 4685.1621\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5472.6787 - val_loss: 4649.1973\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5433.7310 - val_loss: 4613.3184\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 5384.7646 - val_loss: 4557.6768\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5334.0776 - val_loss: 4520.5747\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5294.0552 - val_loss: 4483.8838\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5254.5474 - val_loss: 4447.7129\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5215.5718 - val_loss: 4412.0151\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5177.0708 - val_loss: 4376.7344\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5138.9839 - val_loss: 4341.8203\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5101.2676 - val_loss: 4307.2397\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5063.8853 - val_loss: 4272.9644\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5026.8135 - val_loss: 4238.9741\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4990.0303 - val_loss: 4205.2520\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4953.5220 - val_loss: 4171.7866\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4917.2749 - val_loss: 4138.5674\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4881.2803 - val_loss: 4105.5850\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4845.5283 - val_loss: 4072.8347\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4810.0142 - val_loss: 4040.3086\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4774.7295 - val_loss: 4008.0024\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4739.6709 - val_loss: 3975.9106\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4704.8330 - val_loss: 3944.0300\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4670.2119 - val_loss: 3912.3579\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4635.8022 - val_loss: 3880.8894\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4601.6045 - val_loss: 3849.6226\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4567.6128 - val_loss: 3818.5542\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4533.8257 - val_loss: 3787.6829\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4500.2412 - val_loss: 3757.0059\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4466.8550 - val_loss: 3726.5215\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4433.6670 - val_loss: 3696.2273\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4400.6748 - val_loss: 3666.1216\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4367.8765 - val_loss: 3636.2026\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4335.2695 - val_loss: 3606.4688\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4302.8545 - val_loss: 3576.9192\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4270.6270 - val_loss: 3547.5515\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4238.5869 - val_loss: 3518.3647\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4206.7334 - val_loss: 3489.3586\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4175.0645 - val_loss: 3460.5305\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4143.5786 - val_loss: 3431.8794\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4112.2749 - val_loss: 3403.4043\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4081.1536 - val_loss: 3375.1035\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4050.2104 - val_loss: 3346.9773\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4019.4465 - val_loss: 3319.0242\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3988.8608 - val_loss: 3291.2415\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3958.4507 - val_loss: 3263.6304\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 3928.2168 - val_loss: 3236.1890\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3898.1570 - val_loss: 3208.9167\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3868.2715 - val_loss: 3181.8110\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3838.5579 - val_loss: 3154.8735\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3809.0164 - val_loss: 3128.1021\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3779.6453 - val_loss: 3101.4946\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3750.4438 - val_loss: 3075.0522\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3721.4121 - val_loss: 3048.7729\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3692.5476 - val_loss: 3022.6567\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3663.8516 - val_loss: 2996.7019\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3635.3215 - val_loss: 2970.9082\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3606.9565 - val_loss: 2945.2747\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3578.7571 - val_loss: 2919.8003\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3550.7214 - val_loss: 2894.4846\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3522.8489 - val_loss: 2869.3269\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 3495.1392 - val_loss: 2844.3267\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3467.5906 - val_loss: 2819.4824\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3440.2031 - val_loss: 2794.7932\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3412.9758 - val_loss: 2770.2590\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3385.9082 - val_loss: 2745.8792\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3358.9988 - val_loss: 2721.6533\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 3332.2488 - val_loss: 2697.5796\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3305.6550 - val_loss: 2673.6575\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3279.2180 - val_loss: 2649.8877\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3252.9370 - val_loss: 2626.2681\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3226.8105 - val_loss: 2602.7986\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3200.8391 - val_loss: 2579.4778\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3175.0215 - val_loss: 2556.3062\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3149.3569 - val_loss: 2533.2820\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3123.8447 - val_loss: 2510.4055\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3098.4844 - val_loss: 2487.6763\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3073.2756 - val_loss: 2465.0918\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3048.2166 - val_loss: 2442.6528\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3023.3074 - val_loss: 2420.3582\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2998.5479 - val_loss: 2398.2085\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2973.9368 - val_loss: 2376.2017\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2949.4731 - val_loss: 2354.3379\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2925.1572 - val_loss: 2332.6165\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2900.9875 - val_loss: 2311.0359\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2876.9644 - val_loss: 2289.5969\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 2853.0864 - val_loss: 2268.2979\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2829.3530 - val_loss: 2247.1384\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2805.7637 - val_loss: 2226.1184\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 2782.3181 - val_loss: 2205.2368\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2759.0156 - val_loss: 2184.4934\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2735.8550 - val_loss: 2163.8862\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2712.8364 - val_loss: 2143.4163\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 2689.9592 - val_loss: 2123.0828\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 2667.2224 - val_loss: 2102.8845\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 2644.6255 - val_loss: 2082.8213\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2622.1680 - val_loss: 2062.8921\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2599.8491 - val_loss: 2043.0973\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2577.6687 - val_loss: 2023.4355\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2555.6260 - val_loss: 2003.9055\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2533.7200 - val_loss: 1984.5084\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2511.9504 - val_loss: 1965.2424\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2490.3176 - val_loss: 1946.1074\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2468.8191 - val_loss: 1927.1029\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 2447.4556 - val_loss: 1908.2285\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2426.2268 - val_loss: 1889.4827\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2405.1309 - val_loss: 1870.8656\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 2384.1687 - val_loss: 1852.3772\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 2363.3391 - val_loss: 1834.0154\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2342.6414 - val_loss: 1815.7819\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 2322.0754 - val_loss: 1797.6746\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 2301.6401 - val_loss: 1779.6930\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 2281.3352 - val_loss: 1761.8365\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 2261.1597 - val_loss: 1744.1045\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 2241.1138 - val_loss: 1726.4977\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2221.1965 - val_loss: 1709.0140\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2201.4075 - val_loss: 1691.6536\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2181.7458 - val_loss: 1674.4164\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2162.2114 - val_loss: 1657.3011\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2142.8040 - val_loss: 1640.3070\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2123.5225 - val_loss: 1623.4348\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2104.3665 - val_loss: 1606.6829\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2085.3352 - val_loss: 1590.0511\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 2066.4292 - val_loss: 1573.5388\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2047.6465 - val_loss: 1557.1458\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2028.9879 - val_loss: 1540.8713\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2010.4519 - val_loss: 1524.7150\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1992.0385 - val_loss: 1508.6760\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1973.7468 - val_loss: 1492.7537\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1955.5769 - val_loss: 1476.9480\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1937.5277 - val_loss: 1461.2582\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1919.5986 - val_loss: 1445.6843\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1901.7894 - val_loss: 1430.2252\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1884.1000 - val_loss: 1414.8801\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1866.5299 - val_loss: 1399.6497\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1849.0778 - val_loss: 1384.5322\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1831.7432 - val_loss: 1369.5278\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1814.5261 - val_loss: 1354.6365\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1797.4265 - val_loss: 1339.8562\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1780.4430 - val_loss: 1325.1881\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1763.5756 - val_loss: 1310.6307\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1746.8236 - val_loss: 1296.1838\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1730.1862 - val_loss: 1281.8469\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1713.6637 - val_loss: 1267.6198\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1697.2549 - val_loss: 1253.5016\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1680.9596 - val_loss: 1239.4917\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1664.7776 - val_loss: 1225.5897\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1648.7078 - val_loss: 1211.7957\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1632.7501 - val_loss: 1198.1086\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1616.9043 - val_loss: 1184.5283\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1601.1697 - val_loss: 1171.0540\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1585.5453 - val_loss: 1157.6859\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1570.0312 - val_loss: 1144.4225\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1554.6266 - val_loss: 1131.2639\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1539.3313 - val_loss: 1118.2094\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1524.1451 - val_loss: 1105.2587\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1509.0671 - val_loss: 1092.4111\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1494.0964 - val_loss: 1079.6667\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1479.2335 - val_loss: 1067.0250\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1464.4773 - val_loss: 1054.4841\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1449.8278 - val_loss: 1042.0458\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1435.2839 - val_loss: 1029.7074\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1420.8455 - val_loss: 1017.4706\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1406.5122 - val_loss: 1005.3330\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1392.2837 - val_loss: 993.2957\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1378.1589 - val_loss: 981.3573\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1364.1383 - val_loss: 969.5169\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1350.2203 - val_loss: 957.7752\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1336.4053 - val_loss: 946.1307\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1322.6924 - val_loss: 934.5836\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1309.0813 - val_loss: 923.1336\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1295.5720 - val_loss: 911.7802\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1282.1631 - val_loss: 900.5223\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1268.8549 - val_loss: 889.3600\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1255.6467 - val_loss: 878.2922\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1242.5381 - val_loss: 867.3198\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1229.5287 - val_loss: 856.4412\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1216.6177 - val_loss: 845.6556\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1203.8053 - val_loss: 834.9641\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1191.0906 - val_loss: 824.3646\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1178.4729 - val_loss: 813.8583\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1165.9525 - val_loss: 803.4430\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1153.5286 - val_loss: 793.1192\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1141.2004 - val_loss: 782.8867\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1128.9680 - val_loss: 772.7440\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1116.8307 - val_loss: 762.6921\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1104.7883 - val_loss: 752.7291\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1092.8397 - val_loss: 742.8560\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1080.9856 - val_loss: 733.0712\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1069.2242 - val_loss: 723.3750\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1057.5564 - val_loss: 713.7667\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1045.9810 - val_loss: 704.2454\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1034.4974 - val_loss: 694.8116\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1023.1058 - val_loss: 685.4641\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1011.8052 - val_loss: 676.2027\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1000.5955 - val_loss: 667.0272\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 989.4763 - val_loss: 657.9365\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 978.4470 - val_loss: 648.9307\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 967.5071 - val_loss: 640.0093\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 956.6564 - val_loss: 631.1720\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 945.8944 - val_loss: 622.4181\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 935.2206 - val_loss: 613.7475\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 924.6348 - val_loss: 605.1592\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 914.1362 - val_loss: 596.6531\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 903.7246 - val_loss: 588.2293\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 893.3996 - val_loss: 579.8860\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 883.1605 - val_loss: 571.6240\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 873.0073 - val_loss: 563.4422\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 862.9391 - val_loss: 555.3409\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 852.9559 - val_loss: 547.3190\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 843.0571 - val_loss: 539.3762\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 833.2426 - val_loss: 531.5123\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 823.5114 - val_loss: 523.7269\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 813.8636 - val_loss: 516.0192\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 804.2986 - val_loss: 508.3890\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 794.8158 - val_loss: 500.8360\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 785.4153 - val_loss: 493.3598\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 776.0960 - val_loss: 485.9597\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 766.8580 - val_loss: 478.6354\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 757.7006 - val_loss: 471.3866\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 748.6234 - val_loss: 464.2128\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 739.6263 - val_loss: 457.1131\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 730.7085 - val_loss: 450.0883\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 721.8698 - val_loss: 443.1362\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 713.1095 - val_loss: 436.2583\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 704.4279 - val_loss: 429.4523\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 695.8237 - val_loss: 422.7194\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 687.2971 - val_loss: 416.0589\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 678.8475 - val_loss: 409.4691\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 670.4742 - val_loss: 402.9512\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 662.1774 - val_loss: 396.5039\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 653.9562 - val_loss: 390.1269\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 645.8105 - val_loss: 383.8196\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 637.7398 - val_loss: 377.5820\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 629.7437 - val_loss: 371.4138\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 621.8217 - val_loss: 365.3138\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 613.9731 - val_loss: 359.2829\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 606.1984 - val_loss: 353.3191\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 598.4964 - val_loss: 347.4233\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 590.8669 - val_loss: 341.5943\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 583.3096 - val_loss: 335.8316\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 575.8239 - val_loss: 330.1357\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 568.4097 - val_loss: 324.5055\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 561.0666 - val_loss: 318.9403\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 553.7938 - val_loss: 313.4407\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 546.5910 - val_loss: 308.0051\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 539.4581 - val_loss: 302.6338\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 532.3946 - val_loss: 297.3267\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 525.4000 - val_loss: 292.0829\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 518.4738 - val_loss: 286.9015\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 511.6155 - val_loss: 281.7831\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 504.8253 - val_loss: 276.7267\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 498.1022 - val_loss: 271.7318\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 491.4463 - val_loss: 266.7985\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 484.8568 - val_loss: 261.9262\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 478.3334 - val_loss: 257.1141\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 471.8756 - val_loss: 252.3623\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 465.4834 - val_loss: 247.6699\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 459.1562 - val_loss: 243.0374\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 452.8936 - val_loss: 238.4635\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 446.6952 - val_loss: 233.9481\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 440.5603 - val_loss: 229.4904\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 434.4889 - val_loss: 225.0910\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 428.4806 - val_loss: 220.7487\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 422.5349 - val_loss: 216.4630\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 416.6514 - val_loss: 212.2338\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 410.8297 - val_loss: 208.0608\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 405.0693 - val_loss: 203.9435\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 399.3702 - val_loss: 199.8815\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 393.7318 - val_loss: 195.8743\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 388.1535 - val_loss: 191.9215\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 382.6352 - val_loss: 188.0232\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 377.1763 - val_loss: 184.1785\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 371.7767 - val_loss: 180.3867\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 366.4355 - val_loss: 176.6481\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 361.1530 - val_loss: 172.9616\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 355.9281 - val_loss: 169.3275\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 350.7612 - val_loss: 165.7451\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 345.6510 - val_loss: 162.2139\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 340.5977 - val_loss: 158.7337\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 335.6007 - val_loss: 155.3037\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 330.6600 - val_loss: 151.9242\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 325.7748 - val_loss: 148.5940\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 320.9449 - val_loss: 145.3138\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 316.1699 - val_loss: 142.0818\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 311.4494 - val_loss: 138.8986\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 306.7828 - val_loss: 135.7639\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 302.1701 - val_loss: 132.6765\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 297.6110 - val_loss: 129.6369\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 293.1048 - val_loss: 126.6443\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 288.6513 - val_loss: 123.6982\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 284.2499 - val_loss: 120.7983\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 279.9005 - val_loss: 117.9441\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 275.6023 - val_loss: 115.1354\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 271.3553 - val_loss: 112.3715\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 267.1590 - val_loss: 109.6526\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 263.0130 - val_loss: 106.9780\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 258.9172 - val_loss: 104.3470\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 254.8708 - val_loss: 101.7597\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 250.8736 - val_loss: 99.2155\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 246.9253 - val_loss: 96.7140\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 243.0255 - val_loss: 94.2548\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 239.1738 - val_loss: 91.8374\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 235.3696 - val_loss: 89.4618\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 231.6129 - val_loss: 87.1274\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 227.9033 - val_loss: 84.8339\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 224.2403 - val_loss: 82.5809\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 220.6236 - val_loss: 80.3676\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 217.0525 - val_loss: 78.1942\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 213.5270 - val_loss: 76.0602\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 210.0469 - val_loss: 73.9651\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 206.6114 - val_loss: 71.9085\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 203.2203 - val_loss: 69.8902\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 199.8733 - val_loss: 67.9096\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 196.5700 - val_loss: 65.9664\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 193.3099 - val_loss: 64.0604\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 190.0929 - val_loss: 62.1912\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 186.9186 - val_loss: 60.3580\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 183.7863 - val_loss: 58.5610\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 180.6960 - val_loss: 56.7993\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 177.6473 - val_loss: 55.0731\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 174.6396 - val_loss: 53.3817\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 171.6729 - val_loss: 51.7248\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 168.7466 - val_loss: 50.1018\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 165.8602 - val_loss: 48.5129\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 163.0138 - val_loss: 46.9573\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 160.2067 - val_loss: 45.4344\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 157.4385 - val_loss: 43.9446\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 154.7092 - val_loss: 42.4868\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 152.0181 - val_loss: 41.0611\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 149.3650 - val_loss: 39.6670\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 146.7495 - val_loss: 38.3040\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 144.1714 - val_loss: 36.9719\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 141.6301 - val_loss: 35.6704\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 139.1255 - val_loss: 34.3992\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 136.6571 - val_loss: 33.1575\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 134.2246 - val_loss: 31.9454\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 131.8276 - val_loss: 30.7624\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 129.4659 - val_loss: 29.6082\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 127.1389 - val_loss: 28.4823\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 124.8466 - val_loss: 27.3845\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 122.5884 - val_loss: 26.3143\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 120.3640 - val_loss: 25.2716\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 118.1731 - val_loss: 24.2560\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 116.0155 - val_loss: 23.2668\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 113.8906 - val_loss: 22.3041\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 111.7984 - val_loss: 21.3675\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 109.7382 - val_loss: 20.4565\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 107.7098 - val_loss: 19.5708\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 105.7131 - val_loss: 18.7100\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 103.7474 - val_loss: 17.8739\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 101.8126 - val_loss: 17.0621\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 99.9083 - val_loss: 16.2743\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 98.0342 - val_loss: 15.5103\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 96.1901 - val_loss: 14.7694\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 94.3754 - val_loss: 14.0517\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 92.5900 - val_loss: 13.3565\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 90.8333 - val_loss: 12.6837\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 89.1054 - val_loss: 12.0328\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 87.4057 - val_loss: 11.4039\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 85.7339 - val_loss: 10.7962\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 84.0899 - val_loss: 10.2095\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 82.4731 - val_loss: 9.6436\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 80.8833 - val_loss: 9.0982\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 79.3202 - val_loss: 8.5729\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 77.7835 - val_loss: 8.0673\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 76.2728 - val_loss: 7.5813\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 74.7879 - val_loss: 7.1144\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 73.3285 - val_loss: 6.6664\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 71.8943 - val_loss: 6.2370\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 70.4848 - val_loss: 5.8260\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 69.1002 - val_loss: 5.4328\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 67.7397 - val_loss: 5.0573\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 66.4030 - val_loss: 4.6992\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 65.0901 - val_loss: 4.3581\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 63.8004 - val_loss: 4.0338\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 62.5339 - val_loss: 3.7260\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 61.2902 - val_loss: 3.4344\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 60.0691 - val_loss: 3.1588\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 58.8701 - val_loss: 2.8987\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 57.6930 - val_loss: 2.6540\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 56.5375 - val_loss: 2.4243\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 55.4035 - val_loss: 2.2094\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 54.2904 - val_loss: 2.0091\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 53.1983 - val_loss: 1.8229\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 52.1266 - val_loss: 1.6506\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 51.0752 - val_loss: 1.4920\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 50.0436 - val_loss: 1.3468\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 49.0318 - val_loss: 1.2148\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 48.0395 - val_loss: 1.0956\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 47.0661 - val_loss: 0.9890\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 46.1116 - val_loss: 0.8947\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 45.1758 - val_loss: 0.8126\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 44.2583 - val_loss: 0.7422\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 43.3590 - val_loss: 0.6834\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 42.4775 - val_loss: 0.6359\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 41.6135 - val_loss: 0.5995\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 40.7669 - val_loss: 0.5738\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 39.9374 - val_loss: 0.5587\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 39.1245 - val_loss: 0.5540\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 38.3283 - val_loss: 0.5593\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 37.5484 - val_loss: 0.5744\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 36.7845 - val_loss: 0.5992\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 36.0366 - val_loss: 0.6333\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 35.3041 - val_loss: 0.6765\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 34.5869 - val_loss: 0.7286\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 33.8849 - val_loss: 0.7894\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 33.1978 - val_loss: 0.8586\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 32.5253 - val_loss: 0.9361\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 31.8672 - val_loss: 1.0215\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 31.2233 - val_loss: 1.1147\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 30.5932 - val_loss: 1.2155\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 29.9769 - val_loss: 1.3236\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 29.3740 - val_loss: 1.4388\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 28.7845 - val_loss: 1.5610\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 28.2080 - val_loss: 1.6899\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 27.6443 - val_loss: 1.8253\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 27.0931 - val_loss: 1.9669\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 26.5544 - val_loss: 2.1148\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 26.0279 - val_loss: 2.2685\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 25.5133 - val_loss: 2.4280\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 25.0105 - val_loss: 2.5929\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 24.5193 - val_loss: 2.7632\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 24.0395 - val_loss: 2.9386\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 23.5708 - val_loss: 3.1191\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 23.1130 - val_loss: 3.3043\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 22.6660 - val_loss: 3.4941\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 22.2296 - val_loss: 3.6883\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 21.8035 - val_loss: 3.8868\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 21.3877 - val_loss: 4.0893\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 20.9818 - val_loss: 4.2959\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 20.5857 - val_loss: 4.5060\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 20.1993 - val_loss: 4.7198\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 19.8223 - val_loss: 4.9370\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 19.4545 - val_loss: 5.1575\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 19.0959 - val_loss: 5.3811\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 18.7461 - val_loss: 5.6076\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 18.4051 - val_loss: 5.8369\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 18.0726 - val_loss: 6.0688\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 17.7486 - val_loss: 6.3032\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 17.4328 - val_loss: 6.5400\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 17.1251 - val_loss: 6.7789\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 16.8252 - val_loss: 7.0200\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 16.5332 - val_loss: 7.2630\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 16.2486 - val_loss: 7.5078\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 15.9716 - val_loss: 7.7543\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 15.7017 - val_loss: 8.0023\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.4390 - val_loss: 8.2517\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.1833 - val_loss: 8.5024\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 14.9345 - val_loss: 8.7542\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 14.6923 - val_loss: 9.0070\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 14.4567 - val_loss: 9.2609\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 14.2274 - val_loss: 9.5155\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 14.0044 - val_loss: 9.7708\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 13.7875 - val_loss: 10.0268\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 13.5766 - val_loss: 10.2832\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 13.3716 - val_loss: 10.5399\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 13.1722 - val_loss: 10.7969\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 12.9785 - val_loss: 11.0541\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 12.7903 - val_loss: 11.3114\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 12.6074 - val_loss: 11.5687\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 12.4297 - val_loss: 11.8259\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 12.2570 - val_loss: 12.0828\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 12.0894 - val_loss: 12.3395\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 11.9266 - val_loss: 12.5957\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 11.7687 - val_loss: 12.8516\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 11.6152 - val_loss: 13.1068\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 11.4664 - val_loss: 13.3614\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 11.3219 - val_loss: 13.6154\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 11.1818 - val_loss: 13.8684\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 11.0458 - val_loss: 14.1209\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.9139 - val_loss: 14.3723\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 10.7861 - val_loss: 14.6226\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 10.6621 - val_loss: 14.8719\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 10.5419 - val_loss: 15.1200\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 10.4255 - val_loss: 15.3670\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 10.3127 - val_loss: 15.6126\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.2034 - val_loss: 15.8570\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 10.0974 - val_loss: 16.1000\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 9.9948 - val_loss: 16.3416\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 9.8955 - val_loss: 16.5816\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 9.7993 - val_loss: 16.8202\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 9.7063 - val_loss: 17.0571\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 9.6162 - val_loss: 17.2926\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 9.5290 - val_loss: 17.5262\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.4447 - val_loss: 17.7582\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 9.3631 - val_loss: 17.9884\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 9.2842 - val_loss: 18.2169\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 9.2079 - val_loss: 18.4434\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.1341 - val_loss: 18.6682\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 9.0628 - val_loss: 18.8911\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 8.9939 - val_loss: 19.1119\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 8.9273 - val_loss: 19.3307\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 8.8630 - val_loss: 19.5478\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 474ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73.68202614, 73.64281046, 73.60359477, 73.56437908, 73.5251634 ,\n",
       "        73.48594771, 73.44673203, 73.40751634, 73.36830065, 73.32908497,\n",
       "        73.28986928, 73.25065359, 73.21143791, 73.17222222, 73.13300654,\n",
       "        73.09379085, 73.05457516, 73.01535948, 72.97614379, 72.9369281 ,\n",
       "        72.89771242, 72.85849673, 72.81928105, 72.78006536, 72.74084967,\n",
       "        72.70163399, 72.6624183 , 72.62320261, 72.58398693, 72.54477124,\n",
       "        72.50555556, 72.46633987, 72.42712418, 72.3879085 , 72.34869281,\n",
       "        72.30947712, 72.27026144, 72.23104575, 72.19183007, 72.15261438,\n",
       "        72.11339869, 72.07418301, 72.03496732, 71.99575163, 71.95653595,\n",
       "        71.91732026, 71.87810458, 71.83888889, 71.79955649, 71.7463352 ,\n",
       "        71.69311391, 71.63989262, 71.58667134, 71.53345005, 71.48022876,\n",
       "        71.42700747, 71.37378618, 71.32056489, 71.2673436 , 71.21412232,\n",
       "        71.16090103, 71.10767974, 71.05445845, 71.00123716, 70.94801587,\n",
       "        70.89479458, 70.8415733 , 70.78835201, 70.73513072, 70.68190943,\n",
       "        70.62868814, 70.57546685, 70.52224556, 70.46902428, 70.41580299,\n",
       "        70.3625817 , 70.30936041, 70.25613912, 70.20291783, 70.14969655,\n",
       "        75.82211304,  0.        ,  1.14452577,  0.80223095,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.22516504,  0.59006268,\n",
       "         0.        ,  0.        ,  0.        ,  0.39719933,  0.6924718 ,\n",
       "         0.        ,  0.1018787 ,  0.        ,  0.72114086,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.39813259, 69.39439776, 69.39066293, 69.3869281 , 69.38319328,\n",
       "       69.37945845, 69.37572362, 69.3719888 , 69.36825397, 69.36451914,\n",
       "       69.36078431, 69.35704949, 69.35331466, 69.34957983, 69.345845  ,\n",
       "       69.34211018, 69.33837535, 69.33464052, 69.3309057 , 69.32717087,\n",
       "       69.32343604, 69.31970121, 69.31596639, 69.31223156, 69.30849673,\n",
       "       69.3047619 , 69.30102708, 69.29255369, 69.28228291, 69.27201214,\n",
       "       69.26174136, 69.25147059, 69.24119981, 69.23092904, 69.22065826,\n",
       "       69.21038749, 69.20011671, 69.18984594, 69.17957516, 69.16930439,\n",
       "       69.15903361, 69.14876284, 69.13849206, 69.12822129, 69.11795051,\n",
       "       69.10767974, 69.09740896, 69.08713819, 69.07686741, 69.06659664,\n",
       "       69.05632586, 69.04605509, 69.03578431, 69.02551354, 69.01524276,\n",
       "       69.00497199, 68.99470121, 68.98443044, 68.97415966, 68.96388889,\n",
       "       68.95361811, 68.94334734, 68.93307656, 68.92280579, 68.91253501,\n",
       "       68.90226424, 68.89199346, 68.88172269, 68.87145191, 68.86118114,\n",
       "       68.85091036, 68.84063959, 68.83036881, 68.82009804, 68.80982726,\n",
       "       68.79955649, 68.78928571, 68.77901494, 68.76874416, 68.75847339,\n",
       "       68.74820261, 68.73793184, 68.72766106, 68.71739029, 68.70711951,\n",
       "       68.69684874, 68.68657796, 68.67630719, 68.66603641, 68.65576564,\n",
       "       68.64549486, 68.63522409, 68.62495331, 68.61468254, 68.60441176,\n",
       "       68.59414099, 68.58387021, 68.57359944, 68.56332866, 68.55305789])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.945866716611047\n",
      "15.395627740677552\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
