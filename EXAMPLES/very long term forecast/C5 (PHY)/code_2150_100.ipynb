{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2245    61.612981\n",
       "2246    61.605056\n",
       "2247    61.597131\n",
       "2248    61.589205\n",
       "2249    61.581280\n",
       "Name: C5, Length: 2250, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_2150_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2145     0.000000\n",
       "2146     0.587591\n",
       "2147     0.000000\n",
       "2148     0.115061\n",
       "2149     0.000000\n",
       "Name: C5, Length: 2150, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2150)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 1, 251) (1700, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/22 [==============================] - 3s 28ms/step - loss: 5042.0752 - val_loss: 2818.8203\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4719.2114 - val_loss: 2652.3767\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4542.3906 - val_loss: 2576.2058\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4422.0127 - val_loss: 2509.3015\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4307.6641 - val_loss: 2446.5867\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4187.5132 - val_loss: 2380.2195\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4075.5518 - val_loss: 2321.3840\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3968.9753 - val_loss: 2265.0554\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3865.6895 - val_loss: 2210.9680\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3765.2559 - val_loss: 2158.9260\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3667.4055 - val_loss: 2108.8015\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3571.9602 - val_loss: 2060.4995\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3478.7957 - val_loss: 2013.9476\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3387.8110 - val_loss: 1969.0853\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3298.9287 - val_loss: 1925.8611\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3212.0830 - val_loss: 1884.2289\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 3127.2173 - val_loss: 1844.1475\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3044.2798 - val_loss: 1805.5791\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2963.2256 - val_loss: 1768.4872\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 2884.0129 - val_loss: 1732.8398\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2806.6030 - val_loss: 1698.6036\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2730.9600 - val_loss: 1665.7490\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2657.0491 - val_loss: 1634.2460\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2584.8372 - val_loss: 1604.0654\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2514.2930 - val_loss: 1575.1809\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2445.3672 - val_loss: 1546.1776\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2378.3606 - val_loss: 1521.1887\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2312.3694 - val_loss: 1496.0291\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2248.2041 - val_loss: 1472.0604\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2185.5649 - val_loss: 1449.2568\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2124.4250 - val_loss: 1427.5935\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2064.7581 - val_loss: 1407.0471\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2006.5397 - val_loss: 1387.5950\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1949.7443 - val_loss: 1369.1857\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1894.3480 - val_loss: 1351.8422\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1840.3263 - val_loss: 1335.5206\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1787.6559 - val_loss: 1320.1985\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1736.3132 - val_loss: 1305.8529\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1686.2755 - val_loss: 1292.4612\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1637.5197 - val_loss: 1280.0018\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1590.0233 - val_loss: 1268.4524\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1543.7646 - val_loss: 1257.7917\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1498.7207 - val_loss: 1247.9976\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1454.8707 - val_loss: 1239.0491\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1412.1931 - val_loss: 1230.9250\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1370.6664 - val_loss: 1223.6045\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1330.2697 - val_loss: 1217.0668\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1290.9823 - val_loss: 1211.2911\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1252.7830 - val_loss: 1206.2572\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1215.6523 - val_loss: 1201.9449\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1179.5702 - val_loss: 1198.3342\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1144.5151 - val_loss: 1195.4049\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1110.4686 - val_loss: 1193.1378\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1077.4109 - val_loss: 1191.5132\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1045.3223 - val_loss: 1190.5112\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1014.1835 - val_loss: 1190.1134\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 983.9755 - val_loss: 1190.3005\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 954.6797 - val_loss: 1191.0536\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 926.2771 - val_loss: 1192.3540\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 898.7493 - val_loss: 1194.1835\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 872.0778 - val_loss: 1196.5234\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 846.2445 - val_loss: 1199.3558\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 821.2311 - val_loss: 1202.6627\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 797.0203 - val_loss: 1206.4264\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 773.5941 - val_loss: 1210.6293\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 750.9350 - val_loss: 1215.2537\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 729.0259 - val_loss: 1220.2830\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 707.8496 - val_loss: 1225.6993\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 687.3891 - val_loss: 1231.4868\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 667.6276 - val_loss: 1237.6282\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 648.5482 - val_loss: 1244.1072\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 630.1351 - val_loss: 1250.9077\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 612.3716 - val_loss: 1258.0135\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 595.2417 - val_loss: 1265.4091\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 578.7296 - val_loss: 1273.0784\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 562.8198 - val_loss: 1281.0065\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 547.4963 - val_loss: 1289.1776\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 532.7443 - val_loss: 1297.5779\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 518.5480 - val_loss: 1306.1915\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 504.8931 - val_loss: 1315.0048\n",
      "Epoch 81/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 491.7646 - val_loss: 1324.0032\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 479.1478 - val_loss: 1333.1724\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 467.0285 - val_loss: 1342.4989\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 455.3927 - val_loss: 1351.9692\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 444.2261 - val_loss: 1361.5712\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 433.5150 - val_loss: 1371.2897\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 423.2460 - val_loss: 1381.1136\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 413.4057 - val_loss: 1391.0298\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 403.9808 - val_loss: 1401.0264\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 394.9586 - val_loss: 1411.0913\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 386.3262 - val_loss: 1421.2129\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 378.0713 - val_loss: 1431.3800\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 370.1815 - val_loss: 1441.5814\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 362.6447 - val_loss: 1451.8060\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 355.4490 - val_loss: 1462.0443\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 348.5829 - val_loss: 1472.2850\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 342.0352 - val_loss: 1482.5192\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 335.7941 - val_loss: 1492.7361\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 329.8492 - val_loss: 1502.9275\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 324.1897 - val_loss: 1513.0834\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 318.8050 - val_loss: 1523.1958\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 313.6848 - val_loss: 1533.2572\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 308.8192 - val_loss: 1543.2573\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 304.1982 - val_loss: 1553.1907\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 299.8125 - val_loss: 1563.0482\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 295.6526 - val_loss: 1572.8237\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 291.7094 - val_loss: 1582.5106\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 287.9742 - val_loss: 1592.1014\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 284.4379 - val_loss: 1601.5901\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 281.0927 - val_loss: 1610.9720\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 277.9299 - val_loss: 1620.2401\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 274.9419 - val_loss: 1629.3903\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 272.1208 - val_loss: 1638.4175\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 269.4592 - val_loss: 1647.3162\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 266.9499 - val_loss: 1656.0828\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 264.5857 - val_loss: 1664.7133\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 262.3599 - val_loss: 1673.2042\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 260.2658 - val_loss: 1681.5513\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 258.2972 - val_loss: 1689.7524\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 256.4479 - val_loss: 1697.8044\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 254.7120 - val_loss: 1705.7045\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 253.0835 - val_loss: 1713.4506\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 251.5572 - val_loss: 1721.0411\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 250.1275 - val_loss: 1728.4741\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 248.7897 - val_loss: 1735.7471\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 247.5386 - val_loss: 1742.8611\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 246.3694 - val_loss: 1749.8129\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.2778 - val_loss: 1756.6033\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 244.2594 - val_loss: 1763.2314\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 243.3101 - val_loss: 1769.6963\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 242.4258 - val_loss: 1776.0010\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 241.6027 - val_loss: 1782.1409\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 240.8373 - val_loss: 1788.1206\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 240.1261 - val_loss: 1793.9377\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 239.4659 - val_loss: 1799.5955\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 238.8534 - val_loss: 1805.0930\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 238.2857 - val_loss: 1810.4325\n",
      "Epoch 138/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 237.7599 - val_loss: 1815.6158\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 237.2734 - val_loss: 1820.6432\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 236.8236 - val_loss: 1825.5181\n",
      "Epoch 141/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 236.4081 - val_loss: 1830.2405\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 236.0246 - val_loss: 1834.8125\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 235.6711 - val_loss: 1839.2368\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 235.3452 - val_loss: 1843.5154\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 235.0453 - val_loss: 1847.6508\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 234.7694 - val_loss: 1851.6450\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 234.5159 - val_loss: 1855.5010\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 234.2831 - val_loss: 1859.2209\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 234.0696 - val_loss: 1862.8075\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 233.8740 - val_loss: 1866.2631\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 233.6947 - val_loss: 1869.5909\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 233.5308 - val_loss: 1872.7939\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 233.3810 - val_loss: 1875.8744\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 233.2441 - val_loss: 1878.8358\n",
      "Epoch 155/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 233.1193 - val_loss: 1881.6805\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 233.0054 - val_loss: 1884.4110\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.9017 - val_loss: 1887.0333\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.8074 - val_loss: 1889.5466\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.7217 - val_loss: 1891.9553\n",
      "Epoch 160/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.6438 - val_loss: 1894.2631\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.5731 - val_loss: 1896.4720\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.5091 - val_loss: 1898.5854\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.4511 - val_loss: 1900.6057\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.3986 - val_loss: 1902.5366\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.3512 - val_loss: 1904.3811\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.3083 - val_loss: 1906.1400\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.2698 - val_loss: 1907.8186\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.2350 - val_loss: 1909.4194\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.2036 - val_loss: 1910.9441\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.1756 - val_loss: 1912.3964\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.1503 - val_loss: 1913.7784\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.1276 - val_loss: 1915.0928\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.1073 - val_loss: 1916.3423\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0891 - val_loss: 1917.5295\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0730 - val_loss: 1918.6556\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 232.0585 - val_loss: 1919.7257\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0457 - val_loss: 1920.7401\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0342 - val_loss: 1921.6996\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0241 - val_loss: 1922.6111\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0151 - val_loss: 1923.4735\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0072 - val_loss: 1924.2885\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 232.0003 - val_loss: 1925.0596\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 231.9942 - val_loss: 1925.7888\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9889 - val_loss: 1926.4764\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9843 - val_loss: 1927.1267\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 231.9802 - val_loss: 1927.7394\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9767 - val_loss: 1928.3179\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 231.9738 - val_loss: 1928.8627\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 231.9713 - val_loss: 1929.3757\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9692 - val_loss: 1929.8583\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9674 - val_loss: 1930.3129\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9660 - val_loss: 1930.7391\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9649 - val_loss: 1931.1400\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9642 - val_loss: 1931.5166\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 231.9634 - val_loss: 1931.8710\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9631 - val_loss: 1932.2025\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 231.9628 - val_loss: 1932.5128\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9628 - val_loss: 1932.8042\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9629 - val_loss: 1933.0770\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9631 - val_loss: 1933.3320\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9634 - val_loss: 1933.5706\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 231.9639 - val_loss: 1933.7939\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 231.9644 - val_loss: 1934.0015\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 231.9651 - val_loss: 1934.1962\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 231.9657 - val_loss: 1934.3765\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9666 - val_loss: 1934.5455\n",
      "Epoch 207/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 231.9674 - val_loss: 1934.7037\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9683 - val_loss: 1934.8506\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9692 - val_loss: 1934.9872\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9703 - val_loss: 1935.1140\n",
      "Epoch 211/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9713 - val_loss: 1935.2314\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 231.9724 - val_loss: 1935.3412\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 231.9734 - val_loss: 1935.4426\n",
      "Epoch 214/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9746 - val_loss: 1935.5360\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9757 - val_loss: 1935.6237\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9769 - val_loss: 1935.7050\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 231.9780 - val_loss: 1935.7792\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 231.9792 - val_loss: 1935.8488\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9804 - val_loss: 1935.9124\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9816 - val_loss: 1935.9709\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 231.9829 - val_loss: 1936.0250\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 231.9841 - val_loss: 1936.0750\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 231.9853 - val_loss: 1936.1213\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 231.9866 - val_loss: 1936.1642\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 231.9878 - val_loss: 1936.2025\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 231.9891 - val_loss: 1936.2391\n",
      "Epoch 227/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 231.9903 - val_loss: 1936.2717\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 231.9916 - val_loss: 1936.3016\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 231.9928 - val_loss: 1936.3295\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 231.9940 - val_loss: 1936.3544\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 231.9953 - val_loss: 1936.3774\n",
      "Epoch 232/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 231.9965 - val_loss: 1936.3979\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 231.9977 - val_loss: 1936.4169\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 231.9989 - val_loss: 1936.4347\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0001 - val_loss: 1936.4492\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0013 - val_loss: 1936.4637\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0025 - val_loss: 1936.4764\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0037 - val_loss: 1936.4884\n",
      "Epoch 239/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0048 - val_loss: 1936.4979\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0060 - val_loss: 1936.5076\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0072 - val_loss: 1936.5162\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0083 - val_loss: 1936.5228\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0094 - val_loss: 1936.5292\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0106 - val_loss: 1936.5353\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0117 - val_loss: 1936.5403\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 232.0128 - val_loss: 1936.5439\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0139 - val_loss: 1936.5494\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0149 - val_loss: 1936.5515\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0160 - val_loss: 1936.5546\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0170 - val_loss: 1936.5559\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0181 - val_loss: 1936.5575\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0191 - val_loss: 1936.5592\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0202 - val_loss: 1936.5599\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 232.0212 - val_loss: 1936.5608\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0221 - val_loss: 1936.5614\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0231 - val_loss: 1936.5615\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0241 - val_loss: 1936.5614\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 232.0250 - val_loss: 1936.5614\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0260 - val_loss: 1936.5608\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 232.0269 - val_loss: 1936.5603\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 232.0278 - val_loss: 1936.5599\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 232.0287 - val_loss: 1936.5588\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 232.0296 - val_loss: 1936.5579\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0305 - val_loss: 1936.5563\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0314 - val_loss: 1936.5549\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0322 - val_loss: 1936.5537\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 232.0331 - val_loss: 1936.5522\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0339 - val_loss: 1936.5515\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0347 - val_loss: 1936.5504\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0355 - val_loss: 1936.5480\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0363 - val_loss: 1936.5463\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0370 - val_loss: 1936.5443\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0379 - val_loss: 1936.5422\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0387 - val_loss: 1936.5403\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0393 - val_loss: 1936.5393\n",
      "Epoch 276/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0401 - val_loss: 1936.5378\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0407 - val_loss: 1936.5364\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0415 - val_loss: 1936.5348\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0422 - val_loss: 1936.5326\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0429 - val_loss: 1936.5302\n",
      "Epoch 281/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0435 - val_loss: 1936.5291\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 232.0441 - val_loss: 1936.5277\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 232.0449 - val_loss: 1936.5262\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0455 - val_loss: 1936.5239\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0461 - val_loss: 1936.5217\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0468 - val_loss: 1936.5197\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0474 - val_loss: 1936.5181\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0480 - val_loss: 1936.5171\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0486 - val_loss: 1936.5159\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0491 - val_loss: 1936.5135\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0497 - val_loss: 1936.5125\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0503 - val_loss: 1936.5109\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0509 - val_loss: 1936.5095\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0514 - val_loss: 1936.5081\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0519 - val_loss: 1936.5070\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0524 - val_loss: 1936.5061\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0529 - val_loss: 1936.5040\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0534 - val_loss: 1936.5015\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0540 - val_loss: 1936.5007\n",
      "Epoch 300/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0544 - val_loss: 1936.4990\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0549 - val_loss: 1936.4972\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0554 - val_loss: 1936.4965\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0558 - val_loss: 1936.4954\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0563 - val_loss: 1936.4938\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0568 - val_loss: 1936.4927\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0572 - val_loss: 1936.4917\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0576 - val_loss: 1936.4901\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 232.0580 - val_loss: 1936.4890\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0584 - val_loss: 1936.4875\n",
      "Epoch 310/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0588 - val_loss: 1936.4865\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0592 - val_loss: 1936.4854\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0596 - val_loss: 1936.4846\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0600 - val_loss: 1936.4836\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0604 - val_loss: 1936.4822\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0607 - val_loss: 1936.4808\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0610 - val_loss: 1936.4797\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0614 - val_loss: 1936.4783\n",
      "Epoch 318/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0617 - val_loss: 1936.4774\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0621 - val_loss: 1936.4764\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0624 - val_loss: 1936.4756\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0627 - val_loss: 1936.4746\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0630 - val_loss: 1936.4734\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0633 - val_loss: 1936.4734\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0636 - val_loss: 1936.4727\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0640 - val_loss: 1936.4723\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0642 - val_loss: 1936.4708\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0646 - val_loss: 1936.4695\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0649 - val_loss: 1936.4680\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0651 - val_loss: 1936.4677\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0654 - val_loss: 1936.4666\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0656 - val_loss: 1936.4656\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 232.0659 - val_loss: 1936.4656\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0661 - val_loss: 1936.4648\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0664 - val_loss: 1936.4640\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0667 - val_loss: 1936.4633\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0670 - val_loss: 1936.4629\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0671 - val_loss: 1936.4615\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0674 - val_loss: 1936.4612\n",
      "Epoch 339/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0675 - val_loss: 1936.4596\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0678 - val_loss: 1936.4589\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0680 - val_loss: 1936.4581\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0683 - val_loss: 1936.4575\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0684 - val_loss: 1936.4567\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0687 - val_loss: 1936.4563\n",
      "Epoch 345/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0688 - val_loss: 1936.4552\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0690 - val_loss: 1936.4548\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0692 - val_loss: 1936.4542\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0694 - val_loss: 1936.4541\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0696 - val_loss: 1936.4539\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0698 - val_loss: 1936.4537\n",
      "Epoch 351/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0700 - val_loss: 1936.4525\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0702 - val_loss: 1936.4517\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0704 - val_loss: 1936.4517\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0705 - val_loss: 1936.4514\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 232.0707 - val_loss: 1936.4514\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0709 - val_loss: 1936.4513\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0710 - val_loss: 1936.4507\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0711 - val_loss: 1936.4506\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0713 - val_loss: 1936.4502\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0714 - val_loss: 1936.4492\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0715 - val_loss: 1936.4492\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0716 - val_loss: 1936.4485\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0718 - val_loss: 1936.4481\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0720 - val_loss: 1936.4481\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0721 - val_loss: 1936.4478\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0721 - val_loss: 1936.4469\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0724 - val_loss: 1936.4469\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0724 - val_loss: 1936.4462\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0726 - val_loss: 1936.4462\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0727 - val_loss: 1936.4462\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0728 - val_loss: 1936.4459\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0729 - val_loss: 1936.4458\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0730 - val_loss: 1936.4456\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0731 - val_loss: 1936.4452\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0732 - val_loss: 1936.4447\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0733 - val_loss: 1936.4441\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0734 - val_loss: 1936.4437\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0735 - val_loss: 1936.4436\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 232.0735 - val_loss: 1936.4430\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0737 - val_loss: 1936.4430\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0738 - val_loss: 1936.4423\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0739 - val_loss: 1936.4423\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0740 - val_loss: 1936.4421\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0742 - val_loss: 1936.4421\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0742 - val_loss: 1936.4415\n",
      "Epoch 386/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0743 - val_loss: 1936.4415\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0744 - val_loss: 1936.4412\n",
      "Epoch 388/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0744 - val_loss: 1936.4396\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0746 - val_loss: 1936.4396\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0746 - val_loss: 1936.4392\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0747 - val_loss: 1936.4392\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0748 - val_loss: 1936.4388\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0749 - val_loss: 1936.4385\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0750 - val_loss: 1936.4385\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0750 - val_loss: 1936.4381\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0750 - val_loss: 1936.4375\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0751 - val_loss: 1936.4373\n",
      "Epoch 398/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0752 - val_loss: 1936.4373\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0753 - val_loss: 1936.4373\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0754 - val_loss: 1936.4373\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0754 - val_loss: 1936.4369\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0754 - val_loss: 1936.4368\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0755 - val_loss: 1936.4360\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 232.0755 - val_loss: 1936.4360\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0756 - val_loss: 1936.4360\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0757 - val_loss: 1936.4360\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0758 - val_loss: 1936.4360\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0758 - val_loss: 1936.4360\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0758 - val_loss: 1936.4360\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0759 - val_loss: 1936.4360\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0759 - val_loss: 1936.4353\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0760 - val_loss: 1936.4349\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0760 - val_loss: 1936.4353\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0761 - val_loss: 1936.4353\n",
      "Epoch 415/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0762 - val_loss: 1936.4353\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0762 - val_loss: 1936.4351\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0762 - val_loss: 1936.4349\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0762 - val_loss: 1936.4349\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0763 - val_loss: 1936.4353\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0764 - val_loss: 1936.4353\n",
      "Epoch 421/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0764 - val_loss: 1936.4349\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0764 - val_loss: 1936.4349\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0764 - val_loss: 1936.4349\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0765 - val_loss: 1936.4351\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0765 - val_loss: 1936.4358\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0765 - val_loss: 1936.4362\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 232.0765 - val_loss: 1936.4365\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0766 - val_loss: 1936.4364\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0766 - val_loss: 1936.4364\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0766 - val_loss: 1936.4362\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0766 - val_loss: 1936.4360\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0766 - val_loss: 1936.4354\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0767 - val_loss: 1936.4354\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0767 - val_loss: 1936.4353\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0767 - val_loss: 1936.4351\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0768 - val_loss: 1936.4360\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0769 - val_loss: 1936.4362\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0769 - val_loss: 1936.4357\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0769 - val_loss: 1936.4357\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0769 - val_loss: 1936.4353\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0770 - val_loss: 1936.4353\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0770 - val_loss: 1936.4354\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0770 - val_loss: 1936.4354\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0771 - val_loss: 1936.4354\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0770 - val_loss: 1936.4354\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0770 - val_loss: 1936.4353\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0771 - val_loss: 1936.4353\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0771 - val_loss: 1936.4349\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 232.0771 - val_loss: 1936.4349\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0772 - val_loss: 1936.4347\n",
      "Epoch 451/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0772 - val_loss: 1936.4349\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 232.0772 - val_loss: 1936.4346\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0772 - val_loss: 1936.4338\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0772 - val_loss: 1936.4342\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0773 - val_loss: 1936.4343\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0773 - val_loss: 1936.4347\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0773 - val_loss: 1936.4347\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0773 - val_loss: 1936.4338\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0773 - val_loss: 1936.4340\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0773 - val_loss: 1936.4340\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0774 - val_loss: 1936.4346\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0775 - val_loss: 1936.4354\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0775 - val_loss: 1936.4357\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0775 - val_loss: 1936.4362\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0775 - val_loss: 1936.4364\n",
      "Epoch 466/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0775 - val_loss: 1936.4364\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0775 - val_loss: 1936.4364\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0775 - val_loss: 1936.4365\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0776 - val_loss: 1936.4365\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0775 - val_loss: 1936.4358\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0775 - val_loss: 1936.4358\n",
      "Epoch 472/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0775 - val_loss: 1936.4351\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 232.0775 - val_loss: 1936.4346\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0775 - val_loss: 1936.4347\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0775 - val_loss: 1936.4343\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0776 - val_loss: 1936.4346\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0776 - val_loss: 1936.4346\n",
      "Epoch 478/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0776 - val_loss: 1936.4346\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0777 - val_loss: 1936.4349\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0777 - val_loss: 1936.4351\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0777 - val_loss: 1936.4351\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0777 - val_loss: 1936.4353\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0778 - val_loss: 1936.4365\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0777 - val_loss: 1936.4365\n",
      "Epoch 485/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0778 - val_loss: 1936.4377\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0778 - val_loss: 1936.4381\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0777 - val_loss: 1936.4386\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0777 - val_loss: 1936.4388\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0778 - val_loss: 1936.4390\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0777 - val_loss: 1936.4390\n",
      "Epoch 491/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0777 - val_loss: 1936.4390\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0777 - val_loss: 1936.4390\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0777 - val_loss: 1936.4385\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 232.0778 - val_loss: 1936.4382\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0778 - val_loss: 1936.4379\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0777 - val_loss: 1936.4375\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0778 - val_loss: 1936.4373\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 232.0778 - val_loss: 1936.4368\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0778 - val_loss: 1936.4365\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.0778 - val_loss: 1936.4365\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 417ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.20238399e+01, 7.19885201e+01, 7.19834781e+01, 7.19784360e+01,\n",
       "        7.56149979e+01, 2.89798900e-01, 1.37733400e-01, 2.77729900e-01,\n",
       "        0.00000000e+00, 3.91463600e-01, 7.28807400e-01, 7.58990900e-01,\n",
       "        0.00000000e+00, 7.11076797e+01, 7.06286881e+01, 7.01496966e+01,\n",
       "        2.25165040e-01, 0.00000000e+00, 7.21395425e+01, 7.21781816e+01,\n",
       "        7.21302824e+01, 7.20823833e+01, 7.20344841e+01, 7.19896405e+01,\n",
       "        7.19845985e+01, 7.19795565e+01, 7.19745145e+01, 2.65566498e-01,\n",
       "        0.00000000e+00, 7.05399860e+01, 7.00609944e+01, 6.98665266e+01,\n",
       "        6.98161064e+01, 6.97656863e+01, 6.97152661e+01, 6.96296919e+01,\n",
       "        6.95288515e+01, 6.94280112e+01, 2.17869090e-01, 4.19610080e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.16979480e+00,\n",
       "        4.87971902e-01, 0.00000000e+00, 5.13536215e-01, 7.19806769e+01,\n",
       "        7.19756349e+01, 1.16309310e-01, 0.00000000e+00, 7.06464286e+01,\n",
       "        7.01674370e+01, 6.98777311e+01, 6.98273109e+01, 6.97768908e+01,\n",
       "        6.97264706e+01, 6.96521008e+01, 6.95512605e+01, 6.94504202e+01,\n",
       "        1.34261040e-01, 5.09722050e-01, 6.97974323e+01, 6.97470121e+01,\n",
       "        6.96931839e+01, 6.95923436e+01, 6.94915033e+01, 7.36035948e+01,\n",
       "        7.25447712e+01, 7.13737862e+01, 8.02230950e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.79876823e+01, 0.00000000e+00, 5.29952530e-01,\n",
       "        5.05194900e-01, 0.00000000e+00, 3.37131560e-01, 6.95492030e-01,\n",
       "        6.77056122e+01, 1.37401927e+00, 4.34671760e-01, 4.09106225e-01,\n",
       "        0.00000000e+00, 6.56156003e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.22253948e-02, 0.00000000e+00, 0.00000000e+00, 1.13979042e+00,\n",
       "        0.00000000e+00, 9.15276885e-01, 5.86904168e-01, 6.88693345e-01,\n",
       "        0.00000000e+00, 6.42658234e-01, 2.96472371e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([62.36586732, 62.3579422 , 62.35001708, 62.34209196, 62.33416684,\n",
       "       62.32624172, 62.31831659, 62.31039147, 62.30246635, 62.29454123,\n",
       "       62.28661611, 62.27869099, 62.27076587, 62.26284075, 62.25491562,\n",
       "       62.2469905 , 62.23906538, 62.23114026, 62.22321514, 62.21529002,\n",
       "       62.2073649 , 62.19943978, 62.19151465, 62.18358953, 62.17566441,\n",
       "       62.16773929, 62.15981417, 62.15188905, 62.14396393, 62.13603881,\n",
       "       62.12811368, 62.12018856, 62.11226344, 62.10433832, 62.0964132 ,\n",
       "       62.08848808, 62.08056296, 62.07263784, 62.06471271, 62.05678759,\n",
       "       62.04886247, 62.04093735, 62.03301223, 62.02508711, 62.01716199,\n",
       "       62.00923687, 62.00131174, 61.99338662, 61.9854615 , 61.97753638,\n",
       "       61.96961126, 61.96168614, 61.95376102, 61.9458359 , 61.93791077,\n",
       "       61.92998565, 61.92206053, 61.91413541, 61.90621029, 61.89828517,\n",
       "       61.89036005, 61.88243493, 61.8745098 , 61.86658468, 61.85865956,\n",
       "       61.85073444, 61.84280932, 61.8348842 , 61.82695908, 61.81903396,\n",
       "       61.81110883, 61.80318371, 61.79525859, 61.78733347, 61.77940835,\n",
       "       61.77148323, 61.76355811, 61.75563298, 61.74770786, 61.73978274,\n",
       "       61.73185762, 61.7239325 , 61.71600738, 61.70808226, 61.70015714,\n",
       "       61.69223201, 61.68430689, 61.67638177, 61.66845665, 61.66053153,\n",
       "       61.65260641, 61.64468129, 61.63675617, 61.62883104, 61.62090592,\n",
       "       61.6129808 , 61.60505568, 61.59713056, 61.58920544, 61.58128032])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.2373591779954\n",
      "36.71126114601956\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
