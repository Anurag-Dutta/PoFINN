{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "1845    64.758753\n",
       "1846    64.748483\n",
       "1847    64.738212\n",
       "1848    64.727941\n",
       "1849    64.717670\n",
       "Name: C5, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_1750_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "1745     0.000000\n",
       "1746     0.000000\n",
       "1747     0.000000\n",
       "1748     0.307554\n",
       "1749     0.414306\n",
       "Name: C5, Length: 1750, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1750)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 1, 251) (1300, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 3s 31ms/step - loss: 5354.8755 - val_loss: 3771.6401\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5275.7012 - val_loss: 3733.0376\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5220.8926 - val_loss: 3697.9243\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5166.4053 - val_loss: 3663.1484\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5112.3765 - val_loss: 3628.7151\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5058.8052 - val_loss: 3594.6108\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5005.6802 - val_loss: 3560.8274\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4952.9907 - val_loss: 3527.3589\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4900.7295 - val_loss: 3494.2004\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4848.8887 - val_loss: 3461.3486\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4797.4648 - val_loss: 3428.8003\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4746.4546 - val_loss: 3396.5520\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4695.8530 - val_loss: 3364.6021\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4645.6582 - val_loss: 3332.9468\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4595.8657 - val_loss: 3301.5833\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4546.4731 - val_loss: 3270.4983\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4495.1504 - val_loss: 3232.2979\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4436.1094 - val_loss: 3197.8311\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4382.6895 - val_loss: 3164.2000\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4330.5254 - val_loss: 3131.4448\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4279.4331 - val_loss: 3099.3708\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4229.1885 - val_loss: 3067.8567\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4179.6567 - val_loss: 3036.8269\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 4130.7559 - val_loss: 3006.2358\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 4082.4302 - val_loss: 2976.0503\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4034.6423 - val_loss: 2946.2478\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3987.3635 - val_loss: 2916.8103\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 3940.5735 - val_loss: 2887.7256\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3894.2551 - val_loss: 2858.9807\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3848.3943 - val_loss: 2830.5669\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 3802.9800 - val_loss: 2802.4775\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 3758.0020 - val_loss: 2774.7051\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3713.4517 - val_loss: 2747.2434\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3669.3218 - val_loss: 2720.0879\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3625.6062 - val_loss: 2693.2336\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 3582.2986 - val_loss: 2666.6768\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3539.3931 - val_loss: 2640.4121\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3496.8840 - val_loss: 2614.4373\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3454.7686 - val_loss: 2588.7483\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3413.0408 - val_loss: 2563.3420\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3371.6965 - val_loss: 2538.2153\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3330.7324 - val_loss: 2513.3655\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3290.1450 - val_loss: 2488.7898\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3249.9302 - val_loss: 2464.4858\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3210.0857 - val_loss: 2440.4504\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 3170.6057 - val_loss: 2416.6814\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 3131.4902 - val_loss: 2393.1775\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3092.7341 - val_loss: 2369.9346\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 3054.3354 - val_loss: 2346.9517\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 3016.2905 - val_loss: 2324.2261\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2978.5967 - val_loss: 2301.7561\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 2941.2524 - val_loss: 2279.5393\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 2904.2539 - val_loss: 2257.5737\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2867.5994 - val_loss: 2235.8584\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2831.2856 - val_loss: 2214.3894\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2795.3096 - val_loss: 2193.1667\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2759.6699 - val_loss: 2172.1873\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2724.3638 - val_loss: 2151.4495\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2689.3889 - val_loss: 2130.9521\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2654.7424 - val_loss: 2110.6929\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2620.4231 - val_loss: 2090.6699\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2586.4282 - val_loss: 2070.8818\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2552.7551 - val_loss: 2051.3264\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2519.4023 - val_loss: 2032.0024\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 2486.3669 - val_loss: 2012.9084\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2453.6467 - val_loss: 1994.0417\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2421.2402 - val_loss: 1975.4019\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2389.1450 - val_loss: 1956.9860\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2357.3589 - val_loss: 1938.7935\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2325.8799 - val_loss: 1920.8224\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2294.7063 - val_loss: 1903.0714\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2263.8354 - val_loss: 1885.5388\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2233.2668 - val_loss: 1868.2227\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2202.9966 - val_loss: 1851.1217\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2173.0237 - val_loss: 1834.2349\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2143.3457 - val_loss: 1817.5598\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2113.9609 - val_loss: 1801.0953\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2084.8682 - val_loss: 1784.8406\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2056.0647 - val_loss: 1768.7931\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2027.5493 - val_loss: 1752.9520\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1999.3195 - val_loss: 1737.3156\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1971.3734 - val_loss: 1721.8826\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1943.7095 - val_loss: 1706.6515\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1916.3257 - val_loss: 1691.6206\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1889.2205 - val_loss: 1676.7887\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1862.3915 - val_loss: 1662.1544\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1835.8374 - val_loss: 1647.7158\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1809.5564 - val_loss: 1633.4724\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1783.5466 - val_loss: 1619.4225\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1757.8064 - val_loss: 1605.5641\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1732.3341 - val_loss: 1591.8967\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1707.1282 - val_loss: 1578.4186\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1682.1866 - val_loss: 1565.1284\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1657.5073 - val_loss: 1552.0245\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1633.0886 - val_loss: 1539.1057\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1608.9296 - val_loss: 1526.3710\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1585.0280 - val_loss: 1513.8185\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1561.3824 - val_loss: 1501.4469\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1537.9905 - val_loss: 1489.2554\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1514.8512 - val_loss: 1477.2423\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1491.9630 - val_loss: 1465.4064\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1469.3239 - val_loss: 1453.7461\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1446.9324 - val_loss: 1442.2606\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1424.7865 - val_loss: 1430.9481\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1402.8851 - val_loss: 1419.8076\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1381.2268 - val_loss: 1408.8376\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1359.8088 - val_loss: 1398.0370\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1338.6310 - val_loss: 1387.4047\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1317.6909 - val_loss: 1376.9391\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1296.9872 - val_loss: 1366.6388\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1276.5181 - val_loss: 1356.5029\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1256.2822 - val_loss: 1346.5298\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1236.2777 - val_loss: 1336.7188\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1216.5037 - val_loss: 1327.0679\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1196.9581 - val_loss: 1317.5764\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1177.6393 - val_loss: 1308.2428\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1158.5458 - val_loss: 1299.0658\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1139.6765 - val_loss: 1290.0438\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1121.0291 - val_loss: 1281.1768\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1102.6024 - val_loss: 1272.4623\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1084.3951 - val_loss: 1263.8995\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 1066.4060 - val_loss: 1255.4875\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1048.6326 - val_loss: 1247.2244\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1031.0741 - val_loss: 1239.1095\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1013.7291 - val_loss: 1231.1415\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 996.5956 - val_loss: 1223.3188\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 979.6721 - val_loss: 1215.6407\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 962.9579 - val_loss: 1208.1056\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 946.4507 - val_loss: 1200.7126\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 930.1494 - val_loss: 1193.4604\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 914.0524 - val_loss: 1186.3475\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 898.1582 - val_loss: 1179.3730\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 882.4653 - val_loss: 1172.5354\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 866.9722 - val_loss: 1165.8339\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 851.6777 - val_loss: 1159.2670\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 836.5802 - val_loss: 1152.8336\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 821.6783 - val_loss: 1146.5325\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 806.9705 - val_loss: 1140.3624\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 792.4551 - val_loss: 1134.3223\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 778.1310 - val_loss: 1128.4106\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 763.9969 - val_loss: 1122.6268\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 750.0510 - val_loss: 1116.9694\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 736.2918 - val_loss: 1111.4368\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 722.7182 - val_loss: 1106.0280\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 709.3286 - val_loss: 1100.7423\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 696.1218 - val_loss: 1095.5781\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 683.0962 - val_loss: 1090.5343\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 670.2504 - val_loss: 1085.6097\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 657.5829 - val_loss: 1080.8031\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 645.0921 - val_loss: 1076.1132\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 632.7770 - val_loss: 1071.5391\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 620.6360 - val_loss: 1067.0793\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 608.6680 - val_loss: 1062.7333\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 596.8711 - val_loss: 1058.4990\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 585.2440 - val_loss: 1054.3756\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 573.7853 - val_loss: 1050.3621\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 562.4937 - val_loss: 1046.4569\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 551.3678 - val_loss: 1042.6594\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 540.4063 - val_loss: 1038.9680\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 529.6075 - val_loss: 1035.3820\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 518.9705 - val_loss: 1031.8995\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 508.4939 - val_loss: 1028.5201\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 498.1757 - val_loss: 1025.2423\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 488.0148 - val_loss: 1022.0645\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 478.0099 - val_loss: 1018.9860\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 468.1593 - val_loss: 1016.0056\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 458.4624 - val_loss: 1013.1221\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 448.9172 - val_loss: 1010.3345\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 439.5225 - val_loss: 1007.6412\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 430.2767 - val_loss: 1005.0414\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 421.1784 - val_loss: 1002.5336\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 412.2268 - val_loss: 1000.1172\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 403.4199 - val_loss: 997.7905\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 394.7567 - val_loss: 995.5527\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 386.2360 - val_loss: 993.4023\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 377.8557 - val_loss: 991.3381\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 369.6150 - val_loss: 989.3595\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 361.5124 - val_loss: 987.4650\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 353.5466 - val_loss: 985.6532\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 345.7160 - val_loss: 983.9233\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 338.0195 - val_loss: 982.2739\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 330.4557 - val_loss: 980.7040\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 323.0234 - val_loss: 979.2125\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 315.7211 - val_loss: 977.7981\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 308.5473 - val_loss: 976.4596\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 301.5008 - val_loss: 975.1962\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 294.5801 - val_loss: 974.0061\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 287.7841 - val_loss: 972.8889\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 281.1113 - val_loss: 971.8431\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 274.5604 - val_loss: 970.8674\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 268.1304 - val_loss: 969.9610\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 261.8195 - val_loss: 969.1226\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 255.6264 - val_loss: 968.3508\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 249.5499 - val_loss: 967.6448\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 243.5884 - val_loss: 967.0034\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 237.7409 - val_loss: 966.4253\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 232.0062 - val_loss: 965.9096\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 226.3825 - val_loss: 965.4550\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 220.8688 - val_loss: 965.0605\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 215.4636 - val_loss: 964.7249\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 210.1658 - val_loss: 964.4470\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 204.9739 - val_loss: 964.2257\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 199.8865 - val_loss: 964.0601\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 194.9025 - val_loss: 963.9488\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 190.0207 - val_loss: 963.8908\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 185.2395 - val_loss: 963.8850\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 180.5578 - val_loss: 963.9302\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 175.9744 - val_loss: 964.0255\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 171.4876 - val_loss: 964.1697\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 167.0964 - val_loss: 964.3616\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 162.7994 - val_loss: 964.6002\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 158.5955 - val_loss: 964.8845\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 154.4833 - val_loss: 965.2131\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 150.4614 - val_loss: 965.5853\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 146.5287 - val_loss: 965.9998\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 142.6839 - val_loss: 966.4556\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 138.9256 - val_loss: 966.9517\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 135.2526 - val_loss: 967.4867\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 131.6638 - val_loss: 968.0599\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 128.1579 - val_loss: 968.6702\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 124.7336 - val_loss: 969.3167\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 121.3897 - val_loss: 969.9976\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 118.1251 - val_loss: 970.7128\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 114.9382 - val_loss: 971.4606\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 111.8282 - val_loss: 972.2405\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 108.7935 - val_loss: 973.0513\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 105.8331 - val_loss: 973.8917\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 102.9456 - val_loss: 974.7608\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 100.1301 - val_loss: 975.6579\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 97.3851 - val_loss: 976.5818\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 94.7095 - val_loss: 977.5316\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 92.1023 - val_loss: 978.5060\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 89.5623 - val_loss: 979.5046\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 87.0882 - val_loss: 980.5258\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 84.6788 - val_loss: 981.5690\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 82.3330 - val_loss: 982.6334\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 80.0496 - val_loss: 983.7178\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 77.8275 - val_loss: 984.8212\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 75.6656 - val_loss: 985.9430\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 73.5629 - val_loss: 987.0821\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 71.5182 - val_loss: 988.2373\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 69.5303 - val_loss: 989.4083\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 67.5981 - val_loss: 990.5938\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 65.7205 - val_loss: 991.7930\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 63.8963 - val_loss: 993.0053\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 62.1248 - val_loss: 994.2294\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 60.4047 - val_loss: 995.4647\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 58.7349 - val_loss: 996.7106\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 57.1145 - val_loss: 997.9658\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 55.5423 - val_loss: 999.2299\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 54.0173 - val_loss: 1000.5016\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 52.5386 - val_loss: 1001.7806\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 51.1051 - val_loss: 1003.0659\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 49.7159 - val_loss: 1004.3569\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 48.3699 - val_loss: 1005.6526\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 47.0662 - val_loss: 1006.9525\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 45.8037 - val_loss: 1008.2557\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 44.5816 - val_loss: 1009.5615\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 43.3989 - val_loss: 1010.8693\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 42.2545 - val_loss: 1012.1783\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 41.1478 - val_loss: 1013.4879\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 40.0777 - val_loss: 1014.7975\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 39.0432 - val_loss: 1016.1063\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 38.0436 - val_loss: 1017.4137\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 37.0780 - val_loss: 1018.7192\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 36.1455 - val_loss: 1020.0219\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 35.2453 - val_loss: 1021.3213\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 34.3765 - val_loss: 1022.6168\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 33.5383 - val_loss: 1023.9083\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 32.7298 - val_loss: 1025.1945\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 31.9503 - val_loss: 1026.4753\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 31.1989 - val_loss: 1027.7504\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 30.4749 - val_loss: 1029.0186\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 29.7776 - val_loss: 1030.2799\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 29.1060 - val_loss: 1031.5338\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.4596 - val_loss: 1032.7800\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.8376 - val_loss: 1034.0178\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.2392 - val_loss: 1035.2463\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.6639 - val_loss: 1036.4657\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.1108 - val_loss: 1037.6757\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.5793 - val_loss: 1038.8755\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.0689 - val_loss: 1040.0648\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.5786 - val_loss: 1041.2432\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 24.1081 - val_loss: 1042.4102\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 23.6566 - val_loss: 1043.5660\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 23.2235 - val_loss: 1044.7100\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.8082 - val_loss: 1045.8419\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.4102 - val_loss: 1046.9612\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.0288 - val_loss: 1048.0680\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.6635 - val_loss: 1049.1619\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.3137 - val_loss: 1050.2426\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.9790 - val_loss: 1051.3094\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.6588 - val_loss: 1052.3628\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.3525 - val_loss: 1053.4027\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.0597 - val_loss: 1054.4283\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.7799 - val_loss: 1055.4399\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.5126 - val_loss: 1056.4369\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.2574 - val_loss: 1057.4193\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.0137 - val_loss: 1058.3871\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.7813 - val_loss: 1059.3401\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.5596 - val_loss: 1060.2784\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 18.3482 - val_loss: 1061.2015\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.1468 - val_loss: 1062.1096\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.9549 - val_loss: 1063.0024\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.7722 - val_loss: 1063.8801\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.5983 - val_loss: 1064.7424\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.4328 - val_loss: 1065.5898\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.2754 - val_loss: 1066.4218\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.1257 - val_loss: 1067.2378\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.9835 - val_loss: 1068.0392\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.8484 - val_loss: 1068.8252\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.7200 - val_loss: 1069.5959\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 16.5982 - val_loss: 1070.3513\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 16.4827 - val_loss: 1071.0914\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3730 - val_loss: 1071.8162\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2692 - val_loss: 1072.5260\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1707 - val_loss: 1073.2206\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0774 - val_loss: 1073.9001\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.9891 - val_loss: 1074.5651\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.9055 - val_loss: 1075.2152\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.8263 - val_loss: 1075.8506\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.7515 - val_loss: 1076.4717\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.6807 - val_loss: 1077.0778\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.6139 - val_loss: 1077.6702\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.5507 - val_loss: 1078.2483\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 15.4910 - val_loss: 1078.8120\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.4347 - val_loss: 1079.3624\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.3815 - val_loss: 1079.8988\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.3313 - val_loss: 1080.4215\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.2841 - val_loss: 1080.9309\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.2395 - val_loss: 1081.4268\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.1975 - val_loss: 1081.9094\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.1579 - val_loss: 1082.3794\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.1207 - val_loss: 1082.8363\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.0857 - val_loss: 1083.2808\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.0527 - val_loss: 1083.7135\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.0217 - val_loss: 1084.1335\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.9925 - val_loss: 1084.5417\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.9651 - val_loss: 1084.9384\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.9393 - val_loss: 1085.3230\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.9151 - val_loss: 1085.6964\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 14.8923 - val_loss: 1086.0583\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.8710 - val_loss: 1086.4098\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.8510 - val_loss: 1086.7501\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.8322 - val_loss: 1087.0800\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.8146 - val_loss: 1087.3997\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.7981 - val_loss: 1087.7091\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.7826 - val_loss: 1088.0088\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.7681 - val_loss: 1088.2988\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.7545 - val_loss: 1088.5792\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.7417 - val_loss: 1088.8502\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.7298 - val_loss: 1089.1122\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.7186 - val_loss: 1089.3655\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.7081 - val_loss: 1089.6096\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6984 - val_loss: 1089.8457\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6893 - val_loss: 1090.0736\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6807 - val_loss: 1090.2932\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6727 - val_loss: 1090.5051\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.6652 - val_loss: 1090.7092\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6582 - val_loss: 1090.9062\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6517 - val_loss: 1091.0958\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6456 - val_loss: 1091.2784\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6399 - val_loss: 1091.4539\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 14.6346 - val_loss: 1091.6229\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 14.6296 - val_loss: 1091.7854\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6250 - val_loss: 1091.9421\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 14.6206 - val_loss: 1092.0919\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6166 - val_loss: 1092.2363\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6128 - val_loss: 1092.3748\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6093 - val_loss: 1092.5072\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 14.6060 - val_loss: 1092.6349\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.6030 - val_loss: 1092.7572\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6002 - val_loss: 1092.8744\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5975 - val_loss: 1092.9866\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5951 - val_loss: 1093.0940\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5928 - val_loss: 1093.1969\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5907 - val_loss: 1093.2953\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5887 - val_loss: 1093.3896\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 14.5868 - val_loss: 1093.4797\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 14.5851 - val_loss: 1093.5658\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5836 - val_loss: 1093.6479\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5821 - val_loss: 1093.7264\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5808 - val_loss: 1093.8015\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 14.5795 - val_loss: 1093.8729\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 14.5784 - val_loss: 1093.9415\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 14.5773 - val_loss: 1094.0061\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5763 - val_loss: 1094.0682\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5754 - val_loss: 1094.1274\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5746 - val_loss: 1094.1837\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5739 - val_loss: 1094.2374\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5731 - val_loss: 1094.2885\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5725 - val_loss: 1094.3370\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5719 - val_loss: 1094.3829\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5714 - val_loss: 1094.4268\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5709 - val_loss: 1094.4681\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5705 - val_loss: 1094.5074\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5701 - val_loss: 1094.5446\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5698 - val_loss: 1094.5801\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5695 - val_loss: 1094.6138\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5693 - val_loss: 1094.6456\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5690 - val_loss: 1094.6758\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5688 - val_loss: 1094.7043\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5687 - val_loss: 1094.7312\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5686 - val_loss: 1094.7568\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5685 - val_loss: 1094.7809\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5683 - val_loss: 1094.8033\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5683 - val_loss: 1094.8247\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5683 - val_loss: 1094.8448\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5683 - val_loss: 1094.8638\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5683 - val_loss: 1094.8816\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5683 - val_loss: 1094.8983\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 14.5684 - val_loss: 1094.9139\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5684 - val_loss: 1094.9288\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5685 - val_loss: 1094.9424\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5687 - val_loss: 1094.9558\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5688 - val_loss: 1094.9683\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5689 - val_loss: 1094.9800\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5690 - val_loss: 1094.9906\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5692 - val_loss: 1095.0005\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5694 - val_loss: 1095.0101\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5695 - val_loss: 1095.0190\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5697 - val_loss: 1095.0273\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5699 - val_loss: 1095.0349\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5701 - val_loss: 1095.0421\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5703 - val_loss: 1095.0488\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5705 - val_loss: 1095.0549\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5707 - val_loss: 1095.0607\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5709 - val_loss: 1095.0657\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5712 - val_loss: 1095.0706\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5714 - val_loss: 1095.0750\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5717 - val_loss: 1095.0796\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5719 - val_loss: 1095.0831\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5722 - val_loss: 1095.0865\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5725 - val_loss: 1095.0896\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5727 - val_loss: 1095.0924\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5730 - val_loss: 1095.0951\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5733 - val_loss: 1095.0977\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5735 - val_loss: 1095.0994\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5738 - val_loss: 1095.1014\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 14.5741 - val_loss: 1095.1031\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5744 - val_loss: 1095.1050\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5747 - val_loss: 1095.1064\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5750 - val_loss: 1095.1079\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5752 - val_loss: 1095.1086\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5755 - val_loss: 1095.1097\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5758 - val_loss: 1095.1100\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5761 - val_loss: 1095.1112\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5764 - val_loss: 1095.1115\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5767 - val_loss: 1095.1121\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5770 - val_loss: 1095.1123\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5773 - val_loss: 1095.1125\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5776 - val_loss: 1095.1125\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5779 - val_loss: 1095.1125\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5782 - val_loss: 1095.1125\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 14.5785 - val_loss: 1095.1123\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5788 - val_loss: 1095.1123\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5791 - val_loss: 1095.1118\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5794 - val_loss: 1095.1117\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5797 - val_loss: 1095.1117\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5800 - val_loss: 1095.1115\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5803 - val_loss: 1095.1112\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5805 - val_loss: 1095.1101\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5808 - val_loss: 1095.1099\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5811 - val_loss: 1095.1091\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5814 - val_loss: 1095.1085\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 14.5817 - val_loss: 1095.1082\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5820 - val_loss: 1095.1078\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5823 - val_loss: 1095.1071\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5825 - val_loss: 1095.1061\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5828 - val_loss: 1095.1053\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5831 - val_loss: 1095.1047\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5834 - val_loss: 1095.1042\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5837 - val_loss: 1095.1030\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5840 - val_loss: 1095.1025\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5842 - val_loss: 1095.1019\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5845 - val_loss: 1095.1012\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 14.5848 - val_loss: 1095.1007\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5850 - val_loss: 1095.0997\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5853 - val_loss: 1095.0989\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5856 - val_loss: 1095.0983\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5859 - val_loss: 1095.0978\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5861 - val_loss: 1095.0969\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5864 - val_loss: 1095.0958\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5866 - val_loss: 1095.0945\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 14.5869 - val_loss: 1095.0939\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 14.5872 - val_loss: 1095.0931\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 14.5874 - val_loss: 1095.0922\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 14.5877 - val_loss: 1095.0913\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 14.5879 - val_loss: 1095.0905\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5882 - val_loss: 1095.0898\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5884 - val_loss: 1095.0889\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5886 - val_loss: 1095.0884\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.5889 - val_loss: 1095.0873\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5892 - val_loss: 1095.0864\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 14.5894 - val_loss: 1095.0857\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 14.5896 - val_loss: 1095.0851\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 14.5898 - val_loss: 1095.0844\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5901 - val_loss: 1095.0834\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5903 - val_loss: 1095.0830\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5905 - val_loss: 1095.0819\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 515ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.11076797e+01, 7.09480159e+01, 7.07883520e+01, 7.06286881e+01,\n",
       "        7.04690243e+01, 7.03093604e+01, 7.01496966e+01, 1.14452577e+00,\n",
       "        0.00000000e+00, 2.25165040e-01, 0.00000000e+00, 6.92471800e-01,\n",
       "        0.00000000e+00, 7.23748366e+01, 7.22571895e+01, 7.21395425e+01,\n",
       "        7.20218954e+01, 7.21904248e+01, 7.21781816e+01, 7.21622152e+01,\n",
       "        7.21462488e+01, 7.21302824e+01, 7.21143161e+01, 7.20983497e+01,\n",
       "        7.20823833e+01, 7.20664169e+01, 7.20504505e+01, 7.20344841e+01,\n",
       "        7.20185177e+01, 7.20025514e+01, 7.19896405e+01, 7.19879598e+01,\n",
       "        7.19862792e+01, 7.19845985e+01, 7.19829178e+01, 7.19812372e+01,\n",
       "        7.19795565e+01, 7.19778758e+01, 7.19761951e+01, 7.19745145e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.65566498e-01, 1.03668118e+00,\n",
       "        7.14013500e-02, 0.00000000e+00, 0.00000000e+00, 7.06996499e+01,\n",
       "        7.05399860e+01, 7.03803221e+01, 7.02206583e+01, 7.00609944e+01,\n",
       "        6.99013305e+01, 6.98833333e+01, 6.98665266e+01, 6.98497199e+01,\n",
       "        6.98329132e+01, 6.98161064e+01, 6.97992997e+01, 6.97824930e+01,\n",
       "        6.97656863e+01, 6.97488795e+01, 6.97320728e+01, 6.97152661e+01,\n",
       "        6.96969188e+01, 6.96633053e+01, 6.96296919e+01, 6.95960784e+01,\n",
       "        6.95624650e+01, 6.95288515e+01, 6.94952381e+01, 6.94616247e+01,\n",
       "        6.94280112e+01, 7.56711883e+01, 0.00000000e+00, 2.17869090e-01,\n",
       "        0.00000000e+00, 3.06524250e-01, 4.19610080e-01, 0.00000000e+00,\n",
       "        5.02924500e+01, 0.00000000e+00, 7.19164535e-02, 1.83462664e-01,\n",
       "        0.00000000e+00, 8.54255438e-01, 5.88962555e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.16979480e+00, 1.97798982e-01,\n",
       "        1.80295736e-01, 4.87971902e-01, 0.00000000e+00, 7.35146046e-01,\n",
       "        0.00000000e+00, 3.59862149e-01, 2.31354252e-01, 5.13536215e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65.50375817, 65.49722222, 65.49068627, 65.48415033, 65.47761438,\n",
       "       65.47107843, 65.46454248, 65.45800654, 65.45147059, 65.44493464,\n",
       "       65.43839869, 65.43186275, 65.4253268 , 65.41879085, 65.4122549 ,\n",
       "       65.40571895, 65.39918301, 65.39264706, 65.38611111, 65.37957516,\n",
       "       65.37303922, 65.36650327, 65.35996732, 65.35343137, 65.34689542,\n",
       "       65.34035948, 65.33382353, 65.32728758, 65.32075163, 65.31421569,\n",
       "       65.30767974, 65.30114379, 65.29460784, 65.2880719 , 65.28153595,\n",
       "       65.275     , 65.26846405, 65.2619281 , 65.25539216, 65.24885621,\n",
       "       65.24232026, 65.23578431, 65.22924837, 65.22271242, 65.21617647,\n",
       "       65.20964052, 65.20310458, 65.19656863, 65.19003268, 65.18349673,\n",
       "       65.17696078, 65.17042484, 65.16388889, 65.15735294, 65.15081699,\n",
       "       65.14428105, 65.1377451 , 65.13120915, 65.1246732 , 65.11813725,\n",
       "       65.11160131, 65.10506536, 65.09768908, 65.0874183 , 65.07714753,\n",
       "       65.06687675, 65.05660598, 65.0463352 , 65.03606443, 65.02579365,\n",
       "       65.01552288, 65.0052521 , 64.99498133, 64.98471055, 64.97443978,\n",
       "       64.964169  , 64.95389823, 64.94362745, 64.93335668, 64.9230859 ,\n",
       "       64.91281513, 64.90254435, 64.89227358, 64.8820028 , 64.87173203,\n",
       "       64.86146125, 64.85119048, 64.8409197 , 64.83064893, 64.82037815,\n",
       "       64.81010738, 64.7998366 , 64.78956583, 64.77929505, 64.76902428,\n",
       "       64.7587535 , 64.74848273, 64.73821195, 64.72794118, 64.7176704 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.2026220421585\n",
      "28.264193467215897\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
