{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2495    59.631700\n",
       "2496    59.623775\n",
       "2497    59.615850\n",
       "2498    59.607925\n",
       "2499    59.600000\n",
       "Name: C5, Length: 2500, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_2450_50.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2445     0.000000\n",
       "2446     0.172987\n",
       "2447     0.000000\n",
       "2448     0.000000\n",
       "2449     0.000000\n",
       "Name: C5, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(50)\n",
    "test\n",
    "training_set = training_set.head(2450)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-175)  var1(t-174)  var1(t-173)  var1(t-172)  var1(t-171)  \\\n",
      "175    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "176    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "177    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "178    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "179    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-170)  var1(t-169)  var1(t-168)  var1(t-167)  var1(t-166)  ...  \\\n",
      "175    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "176    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "177    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "178    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "179    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+45)  var2(t+45)  var1(t+46)  var2(t+46)  var1(t+47)  var2(t+47)  \\\n",
      "175   82.338772    0.000280   82.321032    0.000280   82.303291    0.000280   \n",
      "176   82.321032    0.000280   82.303291    0.000280   82.285551    0.000280   \n",
      "177   82.303291    0.000280   82.285551    0.000280   82.267810    0.000279   \n",
      "178   82.285551    0.000280   82.267810    0.000279   82.250070    0.000279   \n",
      "179   82.267810    0.000279   82.250070    0.000279   82.232330    0.000279   \n",
      "\n",
      "     var1(t+48)  var2(t+48)  var1(t+49)  var2(t+49)  \n",
      "175   82.285551    0.000280   82.267810    0.000279  \n",
      "176   82.267810    0.000279   82.250070    0.000279  \n",
      "177   82.250070    0.000279   82.232330    0.000279  \n",
      "178   82.232330    0.000279   82.214589    0.000279  \n",
      "179   82.214589    0.000279   82.196849    0.000279  \n",
      "\n",
      "[5 rows x 276 columns]\n",
      "Index(['var1(t-175)', 'var1(t-174)', 'var1(t-173)', 'var1(t-172)',\n",
      "       'var1(t-171)', 'var1(t-170)', 'var1(t-169)', 'var1(t-168)',\n",
      "       'var1(t-167)', 'var1(t-166)',\n",
      "       ...\n",
      "       'var1(t+45)', 'var2(t+45)', 'var1(t+46)', 'var2(t+46)', 'var1(t+47)',\n",
      "       'var2(t+47)', 'var1(t+48)', 'var2(t+48)', 'var1(t+49)', 'var2(t+49)'],\n",
      "      dtype='object', length=276)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 175, n_out = 50)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 176):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-150:]\n",
    "trainX = train[:,:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-150:]\n",
    "forecastX = forecast[:,:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 1, 126) (2225, 150) (1, 1, 126)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28/28 [==============================] - 3s 35ms/step - loss: 4832.6089 - val_loss: 2285.2261\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 4479.4116 - val_loss: 2122.0168\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4233.0459 - val_loss: 2019.9558\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4024.3743 - val_loss: 1934.3790\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3842.0022 - val_loss: 1842.4773\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3633.9148 - val_loss: 1758.8378\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3451.2095 - val_loss: 1683.3995\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3283.5994 - val_loss: 1616.5380\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3118.7366 - val_loss: 1555.0348\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2971.3662 - val_loss: 1499.3577\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2831.7686 - val_loss: 1447.3805\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2702.3064 - val_loss: 1398.8472\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2574.2246 - val_loss: 1353.5554\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2446.5081 - val_loss: 1307.7311\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2325.9878 - val_loss: 1276.4739\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 2260.6926 - val_loss: 1233.6788\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2110.8621 - val_loss: 1210.0717\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2006.6151 - val_loss: 1170.8667\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1909.9742 - val_loss: 1146.0054\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1820.8033 - val_loss: 1128.1411\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1732.8534 - val_loss: 1102.5094\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1648.9047 - val_loss: 1080.0898\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1569.3287 - val_loss: 1049.4025\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1480.6576 - val_loss: 1022.3016\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1406.3588 - val_loss: 1001.6760\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1415.1271 - val_loss: 993.5593\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1297.5216 - val_loss: 984.4294\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1220.0382 - val_loss: 949.9100\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1158.8054 - val_loss: 949.2879\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1111.1002 - val_loss: 972.8536\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1047.2224 - val_loss: 948.2652\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1000.4854 - val_loss: 943.5041\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1011.1365 - val_loss: 974.9012\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 907.7784 - val_loss: 976.6678\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 916.0825 - val_loss: 942.5135\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 874.6753 - val_loss: 981.6998\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 776.0272 - val_loss: 978.8008\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 735.7685 - val_loss: 976.8255\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 697.8114 - val_loss: 978.8949\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 675.6671 - val_loss: 1029.8057\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 674.7954 - val_loss: 1023.5370\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 672.5195 - val_loss: 1017.9681\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 631.3089 - val_loss: 1096.9489\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 620.4045 - val_loss: 1152.7164\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 585.8072 - val_loss: 1138.9553\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 588.8502 - val_loss: 1140.4727\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 553.2359 - val_loss: 1207.3115\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 538.2870 - val_loss: 1228.5990\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 493.6154 - val_loss: 1241.3719\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 470.4161 - val_loss: 1217.1674\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 494.3356 - val_loss: 1204.4717\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 475.4310 - val_loss: 1272.1083\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 431.2670 - val_loss: 1281.5125\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 416.7381 - val_loss: 1255.3358\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 431.7184 - val_loss: 1296.8843\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 419.3736 - val_loss: 1304.1823\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 412.5872 - val_loss: 1322.2310\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 401.1554 - val_loss: 1317.8208\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 387.9599 - val_loss: 1309.8090\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 422.3981 - val_loss: 1346.3033\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 414.5295 - val_loss: 1361.2303\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 403.9142 - val_loss: 1352.3051\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 395.1412 - val_loss: 1370.8582\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 372.9289 - val_loss: 1304.0460\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 403.0354 - val_loss: 1312.6921\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 363.2459 - val_loss: 1314.7593\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 367.8094 - val_loss: 1376.7020\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 375.9184 - val_loss: 1384.1588\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 368.1765 - val_loss: 1370.5050\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 380.8864 - val_loss: 1365.7867\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 366.2643 - val_loss: 1349.2900\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 372.8905 - val_loss: 1342.2494\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 364.5157 - val_loss: 1351.8636\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 355.9835 - val_loss: 1385.0293\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 338.8880 - val_loss: 1373.0905\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 330.7395 - val_loss: 1367.4988\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 322.5092 - val_loss: 1356.4086\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 319.0961 - val_loss: 1351.7729\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 328.0399 - val_loss: 1354.6835\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 322.1005 - val_loss: 1366.0706\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 313.7032 - val_loss: 1404.4467\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 323.7867 - val_loss: 1459.7177\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 312.0874 - val_loss: 1464.1047\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 299.0492 - val_loss: 1458.0475\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 297.2396 - val_loss: 1449.3436\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 293.6891 - val_loss: 1432.4622\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 303.6414 - val_loss: 1423.9315\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 305.4771 - val_loss: 1409.6864\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 304.9298 - val_loss: 1394.5345\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 301.0810 - val_loss: 1394.7916\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 297.2046 - val_loss: 1387.7289\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 295.6529 - val_loss: 1391.0234\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 294.1263 - val_loss: 1391.9647\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 291.8708 - val_loss: 1391.1162\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 292.3107 - val_loss: 1380.9718\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 300.0510 - val_loss: 1377.4148\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 296.7055 - val_loss: 1376.7512\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 294.0654 - val_loss: 1375.5968\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 291.8365 - val_loss: 1376.8341\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 289.8475 - val_loss: 1377.2480\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 287.9950 - val_loss: 1380.7185\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 287.1747 - val_loss: 1382.0854\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 284.9456 - val_loss: 1381.1658\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 283.0174 - val_loss: 1376.5137\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.0061 - val_loss: 1353.2240\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 268.9892 - val_loss: 1337.2412\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 294.5975 - val_loss: 1350.4730\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 288.8063 - val_loss: 1346.6630\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 283.0490 - val_loss: 1332.6116\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 280.3401 - val_loss: 1322.9583\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.3026 - val_loss: 1373.8916\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 286.5562 - val_loss: 1370.8875\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 279.9188 - val_loss: 1321.1661\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 295.1384 - val_loss: 1375.5039\n",
      "Epoch 115/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 286.1004 - val_loss: 1373.0018\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 284.2272 - val_loss: 1371.5249\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 280.8619 - val_loss: 1352.7410\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 275.2270 - val_loss: 1334.8809\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 268.6330 - val_loss: 1324.1299\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 265.0647 - val_loss: 1310.6185\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 270.5171 - val_loss: 1288.4156\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 265.2139 - val_loss: 1273.6772\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 277.7976 - val_loss: 1273.3806\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 274.4663 - val_loss: 1282.6674\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 257.0869 - val_loss: 1284.2062\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 258.3198 - val_loss: 1290.6838\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 254.2229 - val_loss: 1284.2180\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.6371 - val_loss: 1279.8274\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 251.0058 - val_loss: 1269.2319\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.9831 - val_loss: 1240.4120\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.7740 - val_loss: 1240.1854\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 272.9419 - val_loss: 1245.3778\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 269.4447 - val_loss: 1253.2645\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 273.8879 - val_loss: 1257.5149\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 265.4043 - val_loss: 1292.7588\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 270.6487 - val_loss: 1313.6338\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 260.7310 - val_loss: 1263.6720\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 265.0401 - val_loss: 1304.1542\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 261.9210 - val_loss: 1303.7620\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 265.2806 - val_loss: 1275.6437\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 269.3048 - val_loss: 1258.4250\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 264.2676 - val_loss: 1262.5828\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 259.8151 - val_loss: 1262.6238\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 255.7263 - val_loss: 1257.8602\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 253.6348 - val_loss: 1258.3123\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 250.7229 - val_loss: 1260.7988\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 248.0634 - val_loss: 1260.7291\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 246.3474 - val_loss: 1263.7404\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 245.1358 - val_loss: 1271.6305\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 235.8406 - val_loss: 1253.0166\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.4882 - val_loss: 1264.6743\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 245.8677 - val_loss: 1251.6351\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 242.8892 - val_loss: 1252.6700\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 241.2589 - val_loss: 1252.1649\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 239.5512 - val_loss: 1250.9895\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.5833 - val_loss: 1290.8900\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 238.2666 - val_loss: 1232.8396\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.7387 - val_loss: 1223.5486\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 238.9241 - val_loss: 1225.3955\n",
      "Epoch 160/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.5440 - val_loss: 1227.3291\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 236.0256 - val_loss: 1228.3690\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 234.5022 - val_loss: 1228.1652\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 258.7141 - val_loss: 1318.3560\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 258.2589 - val_loss: 1327.7115\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 256.0640 - val_loss: 1321.0629\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 253.8914 - val_loss: 1297.4066\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 250.4672 - val_loss: 1274.8547\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 250.3559 - val_loss: 1231.6672\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.9706 - val_loss: 1208.4329\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 291.1675 - val_loss: 1205.6863\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 234.5297 - val_loss: 1215.3879\n",
      "Epoch 172/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.1088 - val_loss: 1243.8240\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 233.2642 - val_loss: 1233.0385\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 230.8740 - val_loss: 1223.1479\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 228.9532 - val_loss: 1212.8340\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 225.7529 - val_loss: 1195.9696\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 221.3493 - val_loss: 1183.9667\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 217.5598 - val_loss: 1177.1528\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 215.6116 - val_loss: 1173.7285\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 255.5293 - val_loss: 1178.5757\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 250.7901 - val_loss: 1186.7345\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.4821 - val_loss: 1197.9766\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 244.8395 - val_loss: 1205.7982\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 242.5159 - val_loss: 1213.6274\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.7419 - val_loss: 1214.1453\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 238.7534 - val_loss: 1223.7322\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 237.5681 - val_loss: 1214.8206\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 245.3149 - val_loss: 1235.6366\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 238.2488 - val_loss: 1232.7050\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 233.6326 - val_loss: 1227.1060\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.2638 - val_loss: 1224.7157\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 248.8048 - val_loss: 1223.0457\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 259.6689 - val_loss: 1272.8472\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 253.3829 - val_loss: 1276.4309\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 222.6117 - val_loss: 1254.9354\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 217.4122 - val_loss: 1215.8323\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 243.3898 - val_loss: 1199.2108\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 239.1076 - val_loss: 1185.2418\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 236.4075 - val_loss: 1184.2834\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 233.4834 - val_loss: 1183.4993\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 230.4725 - val_loss: 1173.5321\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 244.4780 - val_loss: 1239.5685\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.4241 - val_loss: 1236.9944\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.2548 - val_loss: 1239.4266\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 239.2575 - val_loss: 1234.9525\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.7021 - val_loss: 1282.0240\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 249.9689 - val_loss: 1278.3846\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 248.2055 - val_loss: 1266.0432\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 291.2200 - val_loss: 1267.0291\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 274.8856 - val_loss: 1269.5349\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 236.2656 - val_loss: 1238.9459\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 226.2907 - val_loss: 1174.5802\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 250.0183 - val_loss: 1300.9320\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 245.0526 - val_loss: 1291.8511\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 243.0969 - val_loss: 1282.0250\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 239.2297 - val_loss: 1269.9424\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.6886 - val_loss: 1264.6119\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 235.7056 - val_loss: 1256.8330\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 234.6103 - val_loss: 1254.8921\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 233.6302 - val_loss: 1251.3900\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 232.7510 - val_loss: 1246.7518\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 231.8894 - val_loss: 1244.7081\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 230.8376 - val_loss: 1241.1925\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 231.0029 - val_loss: 1238.9540\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 230.0046 - val_loss: 1232.0469\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.9910 - val_loss: 1216.4486\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 229.3234 - val_loss: 1187.5314\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 295.6028 - val_loss: 1172.5721\n",
      "Epoch 229/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 287.3138 - val_loss: 1185.3115\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 275.6095 - val_loss: 1149.9554\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 267.2711 - val_loss: 1168.5884\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 262.4018 - val_loss: 1174.8052\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 287.2490 - val_loss: 1184.9899\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 281.0579 - val_loss: 1217.5997\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 258.0437 - val_loss: 1262.1676\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 254.7357 - val_loss: 1269.0865\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.8977 - val_loss: 1264.7419\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 249.9614 - val_loss: 1262.3162\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.2748 - val_loss: 1258.6547\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 245.3042 - val_loss: 1247.6215\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 244.1510 - val_loss: 1249.3435\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 241.8206 - val_loss: 1251.1018\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 254.0067 - val_loss: 1304.2578\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 247.6069 - val_loss: 1276.6071\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 279.3102 - val_loss: 1407.7256\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 278.4120 - val_loss: 1390.7789\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 292.0117 - val_loss: 1374.0854\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 282.2212 - val_loss: 1356.0176\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 287.2960 - val_loss: 1389.8798\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 279.3847 - val_loss: 1359.0006\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 274.9817 - val_loss: 1342.5724\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 271.7610 - val_loss: 1330.2554\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 247.7233 - val_loss: 1301.9374\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.4319 - val_loss: 1312.2783\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 243.5059 - val_loss: 1295.5140\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 239.0088 - val_loss: 1282.6321\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 234.7900 - val_loss: 1266.3346\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 231.7714 - val_loss: 1250.5432\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 222.7406 - val_loss: 1196.1216\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 230.4903 - val_loss: 1194.8398\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 229.0746 - val_loss: 1195.2017\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 228.0249 - val_loss: 1196.1821\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 227.0126 - val_loss: 1196.8992\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 226.0488 - val_loss: 1197.6111\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 225.1426 - val_loss: 1197.9485\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 224.2683 - val_loss: 1197.5923\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 223.3881 - val_loss: 1197.0688\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 222.6279 - val_loss: 1195.5056\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 221.7623 - val_loss: 1194.4419\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 220.3167 - val_loss: 1189.1788\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 218.8813 - val_loss: 1186.6893\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 217.8443 - val_loss: 1185.6071\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 217.2021 - val_loss: 1184.8589\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 216.1323 - val_loss: 1184.8877\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 216.0716 - val_loss: 1182.7456\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 214.4718 - val_loss: 1181.4138\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 213.7230 - val_loss: 1179.0338\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 212.9743 - val_loss: 1176.7368\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 212.2429 - val_loss: 1174.0841\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 211.5097 - val_loss: 1172.0752\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 210.7881 - val_loss: 1169.5023\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 210.0566 - val_loss: 1166.9089\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 205.6082 - val_loss: 1118.2201\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 209.0455 - val_loss: 1119.8430\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 208.1579 - val_loss: 1122.4103\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 207.0971 - val_loss: 1123.7675\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 206.1592 - val_loss: 1123.7759\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 205.2771 - val_loss: 1125.4517\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 204.4026 - val_loss: 1125.6541\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 203.5755 - val_loss: 1124.6791\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 202.8639 - val_loss: 1126.0056\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 202.0014 - val_loss: 1124.0035\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 201.2669 - val_loss: 1121.9377\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 200.5216 - val_loss: 1122.1617\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 199.7937 - val_loss: 1120.6730\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 199.0755 - val_loss: 1118.7365\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 198.3645 - val_loss: 1118.4807\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 197.6602 - val_loss: 1116.4156\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 197.0111 - val_loss: 1113.0320\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 193.8995 - val_loss: 1092.6766\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 191.1966 - val_loss: 1090.5669\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 211.2686 - val_loss: 1091.9604\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 210.5238 - val_loss: 1102.4254\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 208.3023 - val_loss: 1107.2520\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 206.8112 - val_loss: 1109.6532\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 205.5422 - val_loss: 1119.6492\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 204.4031 - val_loss: 1113.0836\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 203.3619 - val_loss: 1114.5850\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 202.4372 - val_loss: 1110.5085\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 201.2894 - val_loss: 1105.4181\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 200.4418 - val_loss: 1103.6757\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 199.5618 - val_loss: 1109.6985\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 198.9069 - val_loss: 1096.9629\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.9206 - val_loss: 1097.9717\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 224.8709 - val_loss: 1113.7899\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 197.1722 - val_loss: 1099.5795\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 221.6365 - val_loss: 1088.0378\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 219.4854 - val_loss: 1100.2531\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 216.8949 - val_loss: 1103.5131\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 202.5832 - val_loss: 1058.1382\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 197.4899 - val_loss: 1025.5543\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 224.4884 - val_loss: 1028.0454\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 220.0729 - val_loss: 1047.4708\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 215.8250 - val_loss: 1067.3207\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 190.8180 - val_loss: 1073.2539\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 182.3773 - val_loss: 1018.8322\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 194.2235 - val_loss: 1024.9177\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 192.9581 - val_loss: 1038.1646\n",
      "Epoch 329/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 188.2141 - val_loss: 1040.1831\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 186.9712 - val_loss: 1038.3674\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 185.8093 - val_loss: 1035.7106\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 185.7067 - val_loss: 1040.6370\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 184.2514 - val_loss: 1038.6953\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 183.6610 - val_loss: 1038.6775\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 183.5761 - val_loss: 1048.8108\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 182.6450 - val_loss: 1048.1190\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 181.6211 - val_loss: 1043.5115\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 181.1379 - val_loss: 1042.7494\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 180.4131 - val_loss: 1036.7466\n",
      "Epoch 340/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 179.3841 - val_loss: 1033.9709\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 178.8997 - val_loss: 1022.0674\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 197.2446 - val_loss: 1053.5505\n",
      "Epoch 343/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 177.5715 - val_loss: 1025.6957\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 177.2717 - val_loss: 1028.1514\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 176.6461 - val_loss: 1026.9377\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 176.2297 - val_loss: 1026.8909\n",
      "Epoch 347/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 175.1184 - val_loss: 1018.4680\n",
      "Epoch 348/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 174.9669 - val_loss: 1018.7476\n",
      "Epoch 349/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 199.4788 - val_loss: 1021.4734\n",
      "Epoch 350/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 203.1399 - val_loss: 1047.6484\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 175.1552 - val_loss: 1022.6783\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 172.0833 - val_loss: 1024.6461\n",
      "Epoch 353/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 171.3194 - val_loss: 1026.4946\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 171.3250 - val_loss: 1017.1998\n",
      "Epoch 355/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 170.2753 - val_loss: 1005.6991\n",
      "Epoch 356/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 198.4790 - val_loss: 1105.9133\n",
      "Epoch 357/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 195.2666 - val_loss: 1099.5164\n",
      "Epoch 358/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 218.4863 - val_loss: 1095.7915\n",
      "Epoch 359/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 217.1269 - val_loss: 1095.2650\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 215.7365 - val_loss: 1102.7893\n",
      "Epoch 361/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 214.4418 - val_loss: 1109.0326\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 214.2112 - val_loss: 1110.0411\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 239.1830 - val_loss: 1202.6556\n",
      "Epoch 364/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 229.3261 - val_loss: 1178.8800\n",
      "Epoch 365/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 224.9075 - val_loss: 1154.8776\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 223.0125 - val_loss: 1147.2679\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 220.0775 - val_loss: 1127.1605\n",
      "Epoch 368/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 215.4789 - val_loss: 1113.7227\n",
      "Epoch 369/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 210.7643 - val_loss: 1096.6785\n",
      "Epoch 370/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 203.5095 - val_loss: 1055.2678\n",
      "Epoch 371/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 190.3879 - val_loss: 1025.9388\n",
      "Epoch 372/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 189.1323 - val_loss: 1027.9614\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 180.1541 - val_loss: 1015.7351\n",
      "Epoch 374/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 178.9987 - val_loss: 1015.8222\n",
      "Epoch 375/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 178.2773 - val_loss: 1018.3624\n",
      "Epoch 376/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 177.5883 - val_loss: 1018.6296\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 176.8174 - val_loss: 1016.3051\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 176.1203 - val_loss: 1017.3842\n",
      "Epoch 379/500\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 175.4449 - val_loss: 1016.2505\n",
      "Epoch 380/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 174.7762 - val_loss: 1009.2587\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 170.8964 - val_loss: 1004.8571\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 170.2727 - val_loss: 1001.2342\n",
      "Epoch 383/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 169.6861 - val_loss: 999.8467\n",
      "Epoch 384/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 168.0970 - val_loss: 989.5524\n",
      "Epoch 385/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 196.4043 - val_loss: 995.6918\n",
      "Epoch 386/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 194.1885 - val_loss: 1007.1998\n",
      "Epoch 387/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 192.2429 - val_loss: 1018.0028\n",
      "Epoch 388/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 190.4170 - val_loss: 1021.9476\n",
      "Epoch 389/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 175.1022 - val_loss: 1021.8923\n",
      "Epoch 390/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 166.0207 - val_loss: 1020.8829\n",
      "Epoch 391/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 164.2590 - val_loss: 1006.4239\n",
      "Epoch 392/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 188.3823 - val_loss: 991.1153\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 185.9883 - val_loss: 991.8730\n",
      "Epoch 394/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 184.8164 - val_loss: 996.8564\n",
      "Epoch 395/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 183.1218 - val_loss: 1002.5231\n",
      "Epoch 396/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 182.1489 - val_loss: 1004.0490\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 180.5140 - val_loss: 1012.6274\n",
      "Epoch 398/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 179.2600 - val_loss: 983.5043\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 219.3245 - val_loss: 978.8506\n",
      "Epoch 400/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 214.9147 - val_loss: 996.5150\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 210.6404 - val_loss: 1001.0247\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 207.5821 - val_loss: 1018.9574\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 204.5836 - val_loss: 1027.7274\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 202.1268 - val_loss: 1038.9370\n",
      "Epoch 405/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 200.4928 - val_loss: 1043.5477\n",
      "Epoch 406/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 198.6400 - val_loss: 1054.6520\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 197.5184 - val_loss: 1059.4608\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 196.3689 - val_loss: 1063.9349\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 195.0728 - val_loss: 1069.3546\n",
      "Epoch 410/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 194.6922 - val_loss: 1070.1747\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 200.8913 - val_loss: 1073.6621\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 192.6423 - val_loss: 1055.3005\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 190.6053 - val_loss: 1058.5410\n",
      "Epoch 414/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 235.7482 - val_loss: 1070.8346\n",
      "Epoch 415/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.9353 - val_loss: 1123.3701\n",
      "Epoch 416/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 199.0253 - val_loss: 1122.1982\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 199.1441 - val_loss: 1091.9359\n",
      "Epoch 418/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 242.9932 - val_loss: 1089.9652\n",
      "Epoch 419/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 215.9236 - val_loss: 1091.7023\n",
      "Epoch 420/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 216.2359 - val_loss: 1164.5981\n",
      "Epoch 421/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 207.2741 - val_loss: 1119.1653\n",
      "Epoch 422/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 194.7822 - val_loss: 1083.1904\n",
      "Epoch 423/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 186.6384 - val_loss: 1072.6758\n",
      "Epoch 424/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 184.9888 - val_loss: 1067.4850\n",
      "Epoch 425/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 184.3506 - val_loss: 1066.2605\n",
      "Epoch 426/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 183.7784 - val_loss: 1063.1149\n",
      "Epoch 427/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 183.1758 - val_loss: 1059.2983\n",
      "Epoch 428/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 182.6337 - val_loss: 1057.0161\n",
      "Epoch 429/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 182.3010 - val_loss: 1052.9971\n",
      "Epoch 430/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 181.8634 - val_loss: 1051.0938\n",
      "Epoch 431/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 181.5285 - val_loss: 1045.8035\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 180.9874 - val_loss: 1045.8781\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 180.3181 - val_loss: 1046.8577\n",
      "Epoch 434/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 179.8145 - val_loss: 1045.6633\n",
      "Epoch 435/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 179.3304 - val_loss: 1044.0682\n",
      "Epoch 436/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 178.7506 - val_loss: 1042.6136\n",
      "Epoch 437/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 178.2743 - val_loss: 1040.2170\n",
      "Epoch 438/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 177.8067 - val_loss: 1037.3408\n",
      "Epoch 439/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 177.3310 - val_loss: 1036.3193\n",
      "Epoch 440/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 176.8293 - val_loss: 1034.2739\n",
      "Epoch 441/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 176.3605 - val_loss: 1032.5753\n",
      "Epoch 442/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 175.8980 - val_loss: 1030.1942\n",
      "Epoch 443/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 175.4376 - val_loss: 1028.4844\n",
      "Epoch 444/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 174.9763 - val_loss: 1026.4901\n",
      "Epoch 445/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 174.5174 - val_loss: 1024.6337\n",
      "Epoch 446/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 174.0591 - val_loss: 1022.8478\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 173.6017 - val_loss: 1021.0736\n",
      "Epoch 448/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 173.1484 - val_loss: 1017.2472\n",
      "Epoch 449/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 172.6928 - val_loss: 1018.0615\n",
      "Epoch 450/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 177.4473 - val_loss: 986.3845\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 343.0303 - val_loss: 1106.5160\n",
      "Epoch 452/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 173.0683 - val_loss: 1023.1058\n",
      "Epoch 453/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 172.3384 - val_loss: 1020.5361\n",
      "Epoch 454/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 165.7001 - val_loss: 982.8003\n",
      "Epoch 455/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 224.1285 - val_loss: 996.9553\n",
      "Epoch 456/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 217.0942 - val_loss: 1038.1736\n",
      "Epoch 457/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 172.2033 - val_loss: 979.7858\n",
      "Epoch 458/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 351.3363 - val_loss: 1008.3736\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 267.6435 - val_loss: 1138.3584\n",
      "Epoch 460/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 198.6041 - val_loss: 1134.2970\n",
      "Epoch 461/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 197.6910 - val_loss: 1120.1222\n",
      "Epoch 462/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 194.5345 - val_loss: 1100.4740\n",
      "Epoch 463/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 188.4625 - val_loss: 1071.7263\n",
      "Epoch 464/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 166.5737 - val_loss: 987.8912\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 169.4084 - val_loss: 930.8090\n",
      "Epoch 466/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 182.6764 - val_loss: 1015.8721\n",
      "Epoch 467/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 170.0217 - val_loss: 994.4204\n",
      "Epoch 468/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 169.0101 - val_loss: 1003.4702\n",
      "Epoch 469/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 168.0583 - val_loss: 955.4116\n",
      "Epoch 470/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 170.8664 - val_loss: 920.7858\n",
      "Epoch 471/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 173.9375 - val_loss: 935.4125\n",
      "Epoch 472/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 172.5784 - val_loss: 948.6827\n",
      "Epoch 473/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 171.2344 - val_loss: 958.0773\n",
      "Epoch 474/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 174.8565 - val_loss: 946.2905\n",
      "Epoch 475/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 168.0857 - val_loss: 927.5428\n",
      "Epoch 476/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 167.9957 - val_loss: 923.2559\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 167.8025 - val_loss: 928.1468\n",
      "Epoch 478/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 165.0095 - val_loss: 939.7635\n",
      "Epoch 479/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 163.6338 - val_loss: 947.4869\n",
      "Epoch 480/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 164.0338 - val_loss: 940.4077\n",
      "Epoch 481/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 163.4792 - val_loss: 958.2231\n",
      "Epoch 482/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 163.7563 - val_loss: 989.0448\n",
      "Epoch 483/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 161.2389 - val_loss: 965.4399\n",
      "Epoch 484/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 160.1404 - val_loss: 932.9199\n",
      "Epoch 485/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 161.9091 - val_loss: 938.4045\n",
      "Epoch 486/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 160.7559 - val_loss: 944.6682\n",
      "Epoch 487/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 159.8155 - val_loss: 947.2119\n",
      "Epoch 488/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 159.0070 - val_loss: 951.0628\n",
      "Epoch 489/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 158.2917 - val_loss: 954.2412\n",
      "Epoch 490/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 157.6493 - val_loss: 956.7834\n",
      "Epoch 491/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 157.0635 - val_loss: 958.8045\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 156.5220 - val_loss: 960.3809\n",
      "Epoch 493/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 156.0154 - val_loss: 961.5694\n",
      "Epoch 494/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 155.5362 - val_loss: 962.4199\n",
      "Epoch 495/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 155.0788 - val_loss: 962.9756\n",
      "Epoch 496/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 154.6388 - val_loss: 963.2730\n",
      "Epoch 497/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 154.2125 - val_loss: 963.3452\n",
      "Epoch 498/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 153.7972 - val_loss: 963.2205\n",
      "Epoch 499/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 153.3909 - val_loss: 962.9240\n",
      "Epoch 500/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 152.9919 - val_loss: 962.4774\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 428ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 126)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 126)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 186)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:150:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.58990900e-01, 7.06286881e+01, 0.00000000e+00, 7.21302824e+01,\n",
       "        7.19896405e+01, 7.19745145e+01, 7.05399860e+01, 6.88161064e+01,\n",
       "        6.86296919e+01, 2.17869090e-01, 0.00000000e+00, 4.87971902e-01,\n",
       "        7.19806769e+01, 0.00000000e+00, 6.88777311e+01, 6.87264706e+01,\n",
       "        6.84504202e+01, 6.97974323e+01, 6.95923436e+01, 7.25447712e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.77056122e+01,\n",
       "        4.09106225e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.88693345e-01, 2.96472371e-01, 7.07135010e+01, 0.00000000e+00,\n",
       "        4.31632370e-01, 3.56152862e-01, 0.00000000e+00, 5.43183088e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.01769543e-01, 5.98370969e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.41544664e-01,\n",
       "        1.39974523e+00, 0.00000000e+00, 0.00000000e+00, 1.56289890e-01,\n",
       "        0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59.98833094, 59.98040582, 59.9724807 , 59.96455558, 59.95663046,\n",
       "       59.94870534, 59.94078021, 59.93285509, 59.92492997, 59.91700485,\n",
       "       59.90907973, 59.90115461, 59.89322949, 59.88530437, 59.87737924,\n",
       "       59.86945412, 59.861529  , 59.85360388, 59.84567876, 59.83775364,\n",
       "       59.82982852, 59.8219034 , 59.81397827, 59.80605315, 59.79812803,\n",
       "       59.79020291, 59.78227779, 59.77435267, 59.76642755, 59.75850243,\n",
       "       59.7505773 , 59.74265218, 59.73472706, 59.72680194, 59.71887682,\n",
       "       59.7109517 , 59.70302658, 59.69510146, 59.68717633, 59.67925121,\n",
       "       59.67132609, 59.66340097, 59.65547585, 59.64755073, 59.63962561,\n",
       "       59.63170049, 59.62377536, 59.61585024, 59.60792512, 59.6       ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.451001262018124\n",
      "43.78437945340908\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
