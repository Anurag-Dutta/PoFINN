{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "1645    65.855719\n",
       "1646    65.854785\n",
       "1647    65.853852\n",
       "1648    65.852918\n",
       "1649    65.851984\n",
       "Name: C5, Length: 1650, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_1550_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "1545     0.419610\n",
       "1546     0.538560\n",
       "1547     0.000000\n",
       "1548     0.000000\n",
       "1549     0.000000\n",
       "Name: C5, Length: 1550, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1550)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 1, 251) (1100, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "14/14 [==============================] - 3s 40ms/step - loss: 5460.5981 - val_loss: 4314.7905\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5378.3228 - val_loss: 4260.9146\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5327.9248 - val_loss: 4223.2397\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5283.7544 - val_loss: 4185.8359\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5239.9146 - val_loss: 4148.7563\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5196.4209 - val_loss: 4111.9893\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5153.2559 - val_loss: 4075.5171\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5110.3999 - val_loss: 4039.3264\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5067.8413 - val_loss: 4003.4094\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5025.5708 - val_loss: 3967.7583\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4983.5801 - val_loss: 3932.3682\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 4941.8657 - val_loss: 3897.2349\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4900.4233 - val_loss: 3862.3569\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4859.2500 - val_loss: 3827.7288\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4818.3413 - val_loss: 3793.3496\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4777.6958 - val_loss: 3759.2173\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4737.3130 - val_loss: 3725.3296\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4697.1870 - val_loss: 3691.6846\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4657.3184 - val_loss: 3658.2805\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4617.7051 - val_loss: 3625.1162\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4578.3452 - val_loss: 3592.1895\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4539.2373 - val_loss: 3559.4993\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4490.5342 - val_loss: 3514.6055\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4444.8511 - val_loss: 3478.5432\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4402.1685 - val_loss: 3443.2664\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4360.3721 - val_loss: 3408.7012\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4319.3145 - val_loss: 3374.7131\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4278.8584 - val_loss: 3341.2085\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4238.9111 - val_loss: 3308.1272\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4199.4111 - val_loss: 3275.4272\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4160.3174 - val_loss: 3243.0796\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4121.6011 - val_loss: 3211.0632\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4083.2380 - val_loss: 3179.3630\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4045.2134 - val_loss: 3147.9641\n",
      "Epoch 35/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4007.5115 - val_loss: 3116.8586\n",
      "Epoch 36/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3970.1233 - val_loss: 3086.0359\n",
      "Epoch 37/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3933.0378 - val_loss: 3055.4895\n",
      "Epoch 38/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3896.2483 - val_loss: 3025.2136\n",
      "Epoch 39/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3859.7476 - val_loss: 2995.2017\n",
      "Epoch 40/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3823.5305 - val_loss: 2965.4512\n",
      "Epoch 41/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3787.5908 - val_loss: 2935.9553\n",
      "Epoch 42/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3751.9253 - val_loss: 2906.7122\n",
      "Epoch 43/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3716.5288 - val_loss: 2877.7175\n",
      "Epoch 44/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3681.3979 - val_loss: 2848.9683\n",
      "Epoch 45/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3646.5298 - val_loss: 2820.4614\n",
      "Epoch 46/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3611.9204 - val_loss: 2792.1946\n",
      "Epoch 47/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3577.5671 - val_loss: 2764.1648\n",
      "Epoch 48/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 3543.4668 - val_loss: 2736.3699\n",
      "Epoch 49/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3509.6177 - val_loss: 2708.8076\n",
      "Epoch 50/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3476.0171 - val_loss: 2681.4758\n",
      "Epoch 51/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3442.6621 - val_loss: 2654.3730\n",
      "Epoch 52/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3409.5515 - val_loss: 2627.4963\n",
      "Epoch 53/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3376.6829 - val_loss: 2600.8445\n",
      "Epoch 54/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3344.0540 - val_loss: 2574.4148\n",
      "Epoch 55/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3311.6636 - val_loss: 2548.2070\n",
      "Epoch 56/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3279.5083 - val_loss: 2522.2185\n",
      "Epoch 57/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3247.5884 - val_loss: 2496.4478\n",
      "Epoch 58/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3215.9009 - val_loss: 2470.8940\n",
      "Epoch 59/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3184.4441 - val_loss: 2445.5552\n",
      "Epoch 60/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3153.2175 - val_loss: 2420.4290\n",
      "Epoch 61/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3122.2185 - val_loss: 2395.5142\n",
      "Epoch 62/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 3091.4456 - val_loss: 2370.8113\n",
      "Epoch 63/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3060.8979 - val_loss: 2346.3167\n",
      "Epoch 64/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3030.5742 - val_loss: 2322.0303\n",
      "Epoch 65/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3000.4719 - val_loss: 2297.9500\n",
      "Epoch 66/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2970.5901 - val_loss: 2274.0742\n",
      "Epoch 67/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2940.9282 - val_loss: 2250.4033\n",
      "Epoch 68/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2911.4839 - val_loss: 2226.9348\n",
      "Epoch 69/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2882.2559 - val_loss: 2203.6677\n",
      "Epoch 70/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2853.2441 - val_loss: 2180.6003\n",
      "Epoch 71/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2824.4458 - val_loss: 2157.7324\n",
      "Epoch 72/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2795.8606 - val_loss: 2135.0618\n",
      "Epoch 73/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2767.4866 - val_loss: 2112.5881\n",
      "Epoch 74/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2739.3235 - val_loss: 2090.3096\n",
      "Epoch 75/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2711.3699 - val_loss: 2068.2253\n",
      "Epoch 76/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2683.6233 - val_loss: 2046.3344\n",
      "Epoch 77/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2656.0840 - val_loss: 2024.6354\n",
      "Epoch 78/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2628.7512 - val_loss: 2003.1271\n",
      "Epoch 79/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2601.6226 - val_loss: 1981.8091\n",
      "Epoch 80/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2574.6975 - val_loss: 1960.6797\n",
      "Epoch 81/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2545.7927 - val_loss: 1934.8699\n",
      "Epoch 82/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2512.7798 - val_loss: 1909.7302\n",
      "Epoch 83/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2481.1477 - val_loss: 1885.3857\n",
      "Epoch 84/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 2450.5518 - val_loss: 1861.8586\n",
      "Epoch 85/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2420.8538 - val_loss: 1838.9797\n",
      "Epoch 86/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2391.8616 - val_loss: 1816.6235\n",
      "Epoch 87/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2363.4424 - val_loss: 1794.7100\n",
      "Epoch 88/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2335.5115 - val_loss: 1773.1832\n",
      "Epoch 89/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2308.0093 - val_loss: 1752.0050\n",
      "Epoch 90/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2280.8945 - val_loss: 1731.1470\n",
      "Epoch 91/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2254.1370 - val_loss: 1710.5905\n",
      "Epoch 92/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2227.7131 - val_loss: 1690.3179\n",
      "Epoch 93/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2201.6045 - val_loss: 1670.3154\n",
      "Epoch 94/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2175.7959 - val_loss: 1650.5730\n",
      "Epoch 95/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2150.2747 - val_loss: 1631.0807\n",
      "Epoch 96/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2125.0305 - val_loss: 1611.8309\n",
      "Epoch 97/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2100.0544 - val_loss: 1592.8168\n",
      "Epoch 98/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2075.3389 - val_loss: 1574.0323\n",
      "Epoch 99/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2050.8767 - val_loss: 1555.4729\n",
      "Epoch 100/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2026.6620 - val_loss: 1537.1329\n",
      "Epoch 101/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2002.6896 - val_loss: 1519.0082\n",
      "Epoch 102/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1978.9543 - val_loss: 1501.0952\n",
      "Epoch 103/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1955.4517 - val_loss: 1483.3899\n",
      "Epoch 104/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1932.1781 - val_loss: 1465.8896\n",
      "Epoch 105/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1909.1288 - val_loss: 1448.5911\n",
      "Epoch 106/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1886.3022 - val_loss: 1431.4910\n",
      "Epoch 107/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1863.6930 - val_loss: 1414.5869\n",
      "Epoch 108/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1841.2997 - val_loss: 1397.8761\n",
      "Epoch 109/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1819.1184 - val_loss: 1381.3569\n",
      "Epoch 110/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1797.1477 - val_loss: 1365.0266\n",
      "Epoch 111/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1775.3838 - val_loss: 1348.8834\n",
      "Epoch 112/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1753.8248 - val_loss: 1332.9243\n",
      "Epoch 113/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1732.4695 - val_loss: 1317.1487\n",
      "Epoch 114/500\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 1711.3142 - val_loss: 1301.5531\n",
      "Epoch 115/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1690.3573 - val_loss: 1286.1377\n",
      "Epoch 116/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1669.5973 - val_loss: 1270.8988\n",
      "Epoch 117/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1649.0316 - val_loss: 1255.8358\n",
      "Epoch 118/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1628.6589 - val_loss: 1240.9465\n",
      "Epoch 119/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1608.4774 - val_loss: 1226.2303\n",
      "Epoch 120/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1588.4854 - val_loss: 1211.6841\n",
      "Epoch 121/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1568.6803 - val_loss: 1197.3081\n",
      "Epoch 122/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1549.0618 - val_loss: 1183.0999\n",
      "Epoch 123/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1529.6278 - val_loss: 1169.0577\n",
      "Epoch 124/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1510.3766 - val_loss: 1155.1808\n",
      "Epoch 125/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1491.3071 - val_loss: 1141.4677\n",
      "Epoch 126/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1472.4174 - val_loss: 1127.9169\n",
      "Epoch 127/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1453.7067 - val_loss: 1114.5275\n",
      "Epoch 128/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1435.1733 - val_loss: 1101.2976\n",
      "Epoch 129/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1416.8157 - val_loss: 1088.2260\n",
      "Epoch 130/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1398.6322 - val_loss: 1075.3123\n",
      "Epoch 131/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1380.6226 - val_loss: 1062.5541\n",
      "Epoch 132/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1362.7848 - val_loss: 1049.9514\n",
      "Epoch 133/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1345.1178 - val_loss: 1037.5026\n",
      "Epoch 134/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1327.6205 - val_loss: 1025.2056\n",
      "Epoch 135/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1310.2908 - val_loss: 1013.0598\n",
      "Epoch 136/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1293.1288 - val_loss: 1001.0648\n",
      "Epoch 137/500\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1276.1327 - val_loss: 989.2187\n",
      "Epoch 138/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1259.3014 - val_loss: 977.5211\n",
      "Epoch 139/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1242.6338 - val_loss: 965.9699\n",
      "Epoch 140/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1226.1285 - val_loss: 954.5649\n",
      "Epoch 141/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1209.7847 - val_loss: 943.3041\n",
      "Epoch 142/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1193.6014 - val_loss: 932.1875\n",
      "Epoch 143/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1177.5773 - val_loss: 921.2136\n",
      "Epoch 144/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1161.7113 - val_loss: 910.3815\n",
      "Epoch 145/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1146.0026 - val_loss: 899.6897\n",
      "Epoch 146/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1130.4498 - val_loss: 889.1375\n",
      "Epoch 147/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1115.0521 - val_loss: 878.7244\n",
      "Epoch 148/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1099.8083 - val_loss: 868.4479\n",
      "Epoch 149/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1084.7175 - val_loss: 858.3085\n",
      "Epoch 150/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1069.7787 - val_loss: 848.3047\n",
      "Epoch 151/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1054.9907 - val_loss: 838.4350\n",
      "Epoch 152/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1040.3527 - val_loss: 828.6992\n",
      "Epoch 153/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1025.8639 - val_loss: 819.0966\n",
      "Epoch 154/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1011.5230 - val_loss: 809.6251\n",
      "Epoch 155/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 997.3293 - val_loss: 800.2842\n",
      "Epoch 156/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 983.2814 - val_loss: 791.0733\n",
      "Epoch 157/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 969.3787 - val_loss: 781.9913\n",
      "Epoch 158/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 955.6204 - val_loss: 773.0369\n",
      "Epoch 159/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 942.0054 - val_loss: 764.2098\n",
      "Epoch 160/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 928.5325 - val_loss: 755.5084\n",
      "Epoch 161/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 915.2009 - val_loss: 746.9320\n",
      "Epoch 162/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 902.0099 - val_loss: 738.4802\n",
      "Epoch 163/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 888.9584 - val_loss: 730.1514\n",
      "Epoch 164/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 876.0455 - val_loss: 721.9445\n",
      "Epoch 165/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 863.2703 - val_loss: 713.8595\n",
      "Epoch 166/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 850.6318 - val_loss: 705.8949\n",
      "Epoch 167/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 838.1295 - val_loss: 698.0499\n",
      "Epoch 168/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 825.7623 - val_loss: 690.3234\n",
      "Epoch 169/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 813.5291 - val_loss: 682.7154\n",
      "Epoch 170/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 801.4293 - val_loss: 675.2235\n",
      "Epoch 171/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 789.4617 - val_loss: 667.8481\n",
      "Epoch 172/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 777.6259 - val_loss: 660.5880\n",
      "Epoch 173/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 765.9208 - val_loss: 653.4418\n",
      "Epoch 174/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 754.3450 - val_loss: 646.4091\n",
      "Epoch 175/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 742.8986 - val_loss: 639.4886\n",
      "Epoch 176/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 731.5800 - val_loss: 632.6800\n",
      "Epoch 177/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 720.3883 - val_loss: 625.9819\n",
      "Epoch 178/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 709.3234 - val_loss: 619.3940\n",
      "Epoch 179/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 698.3839 - val_loss: 612.9151\n",
      "Epoch 180/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 687.5690 - val_loss: 606.5441\n",
      "Epoch 181/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 676.8780 - val_loss: 600.2804\n",
      "Epoch 182/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 666.3096 - val_loss: 594.1232\n",
      "Epoch 183/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 655.8635 - val_loss: 588.0711\n",
      "Epoch 184/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 645.5389 - val_loss: 582.1243\n",
      "Epoch 185/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 635.3344 - val_loss: 576.2812\n",
      "Epoch 186/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 625.2497 - val_loss: 570.5409\n",
      "Epoch 187/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 615.2840 - val_loss: 564.9029\n",
      "Epoch 188/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 605.4362 - val_loss: 559.3661\n",
      "Epoch 189/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 595.7053 - val_loss: 553.9296\n",
      "Epoch 190/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 586.0908 - val_loss: 548.5927\n",
      "Epoch 191/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 576.5917 - val_loss: 543.3549\n",
      "Epoch 192/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 567.2075 - val_loss: 538.2147\n",
      "Epoch 193/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 557.9370 - val_loss: 533.1711\n",
      "Epoch 194/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 548.7795 - val_loss: 528.2242\n",
      "Epoch 195/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 539.7343 - val_loss: 523.3728\n",
      "Epoch 196/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 530.8007 - val_loss: 518.6154\n",
      "Epoch 197/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 521.9775 - val_loss: 513.9521\n",
      "Epoch 198/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 513.2640 - val_loss: 509.3816\n",
      "Epoch 199/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 504.6599 - val_loss: 504.9028\n",
      "Epoch 200/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 496.1637 - val_loss: 500.5154\n",
      "Epoch 201/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 487.7749 - val_loss: 496.2185\n",
      "Epoch 202/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 479.4929 - val_loss: 492.0109\n",
      "Epoch 203/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 471.3167 - val_loss: 487.8919\n",
      "Epoch 204/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 463.2454 - val_loss: 483.8611\n",
      "Epoch 205/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 455.2784 - val_loss: 479.9170\n",
      "Epoch 206/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 447.4151 - val_loss: 476.0592\n",
      "Epoch 207/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 439.6544 - val_loss: 472.2870\n",
      "Epoch 208/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 431.9957 - val_loss: 468.5992\n",
      "Epoch 209/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 424.4379 - val_loss: 464.9950\n",
      "Epoch 210/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 416.9803 - val_loss: 461.4738\n",
      "Epoch 211/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 409.6221 - val_loss: 458.0346\n",
      "Epoch 212/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 402.3627 - val_loss: 454.6765\n",
      "Epoch 213/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 395.2012 - val_loss: 451.3989\n",
      "Epoch 214/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 388.1368 - val_loss: 448.2010\n",
      "Epoch 215/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 381.1687 - val_loss: 445.0819\n",
      "Epoch 216/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 374.2964 - val_loss: 442.0407\n",
      "Epoch 217/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 367.5189 - val_loss: 439.0767\n",
      "Epoch 218/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 360.8353 - val_loss: 436.1889\n",
      "Epoch 219/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 354.2449 - val_loss: 433.3769\n",
      "Epoch 220/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 347.7475 - val_loss: 430.6395\n",
      "Epoch 221/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 341.3416 - val_loss: 427.9759\n",
      "Epoch 222/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 335.0264 - val_loss: 425.3854\n",
      "Epoch 223/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 328.8014 - val_loss: 422.8672\n",
      "Epoch 224/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 322.6658 - val_loss: 420.4204\n",
      "Epoch 225/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 316.6189 - val_loss: 418.0443\n",
      "Epoch 226/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 310.6597 - val_loss: 415.7380\n",
      "Epoch 227/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 304.7877 - val_loss: 413.5007\n",
      "Epoch 228/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 299.0022 - val_loss: 411.3318\n",
      "Epoch 229/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 293.3023 - val_loss: 409.2303\n",
      "Epoch 230/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 287.6872 - val_loss: 407.1952\n",
      "Epoch 231/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 282.1561 - val_loss: 405.2261\n",
      "Epoch 232/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 276.7083 - val_loss: 403.3220\n",
      "Epoch 233/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 271.3429 - val_loss: 401.4820\n",
      "Epoch 234/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 266.0595 - val_loss: 399.7055\n",
      "Epoch 235/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 260.8571 - val_loss: 397.9915\n",
      "Epoch 236/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 255.7348 - val_loss: 396.3394\n",
      "Epoch 237/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 250.6922 - val_loss: 394.7484\n",
      "Epoch 238/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 245.7284 - val_loss: 393.2175\n",
      "Epoch 239/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 240.8425 - val_loss: 391.7460\n",
      "Epoch 240/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 236.0339 - val_loss: 390.3332\n",
      "Epoch 241/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 231.3018 - val_loss: 388.9783\n",
      "Epoch 242/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 226.6456 - val_loss: 387.6804\n",
      "Epoch 243/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 222.0643 - val_loss: 386.4386\n",
      "Epoch 244/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 217.5571 - val_loss: 385.2524\n",
      "Epoch 245/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 213.1236 - val_loss: 384.1208\n",
      "Epoch 246/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 208.7628 - val_loss: 383.0432\n",
      "Epoch 247/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 204.4743 - val_loss: 382.0188\n",
      "Epoch 248/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 200.2569 - val_loss: 381.0465\n",
      "Epoch 249/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 196.1101 - val_loss: 380.1259\n",
      "Epoch 250/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 192.0332 - val_loss: 379.2560\n",
      "Epoch 251/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 188.0254 - val_loss: 378.4363\n",
      "Epoch 252/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 184.0859 - val_loss: 377.6657\n",
      "Epoch 253/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 180.2142 - val_loss: 376.9436\n",
      "Epoch 254/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 176.4093 - val_loss: 376.2691\n",
      "Epoch 255/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 172.6706 - val_loss: 375.6415\n",
      "Epoch 256/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 168.9974 - val_loss: 375.0601\n",
      "Epoch 257/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 165.3887 - val_loss: 374.5241\n",
      "Epoch 258/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 161.8442 - val_loss: 374.0327\n",
      "Epoch 259/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 158.3628 - val_loss: 373.5851\n",
      "Epoch 260/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 154.9441 - val_loss: 373.1807\n",
      "Epoch 261/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 151.5871 - val_loss: 372.8186\n",
      "Epoch 262/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 148.2914 - val_loss: 372.4981\n",
      "Epoch 263/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 145.0560 - val_loss: 372.2184\n",
      "Epoch 264/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 141.8804 - val_loss: 371.9789\n",
      "Epoch 265/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 138.7638 - val_loss: 371.7788\n",
      "Epoch 266/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 135.7055 - val_loss: 371.6172\n",
      "Epoch 267/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 132.7049 - val_loss: 371.4934\n",
      "Epoch 268/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 129.7612 - val_loss: 371.4068\n",
      "Epoch 269/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 126.8735 - val_loss: 371.3566\n",
      "Epoch 270/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 124.0413 - val_loss: 371.3421\n",
      "Epoch 271/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 121.2639 - val_loss: 371.3625\n",
      "Epoch 272/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 118.5405 - val_loss: 371.4171\n",
      "Epoch 273/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 115.8707 - val_loss: 371.5052\n",
      "Epoch 274/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 113.2535 - val_loss: 371.6261\n",
      "Epoch 275/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 110.6883 - val_loss: 371.7791\n",
      "Epoch 276/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 108.1746 - val_loss: 371.9633\n",
      "Epoch 277/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 105.7116 - val_loss: 372.1782\n",
      "Epoch 278/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 103.2986 - val_loss: 372.4230\n",
      "Epoch 279/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 100.9346 - val_loss: 372.6971\n",
      "Epoch 280/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 98.6196 - val_loss: 372.9996\n",
      "Epoch 281/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 96.3523 - val_loss: 373.3301\n",
      "Epoch 282/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 94.1324 - val_loss: 373.6876\n",
      "Epoch 283/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 91.9592 - val_loss: 374.0717\n",
      "Epoch 284/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 89.8319 - val_loss: 374.4814\n",
      "Epoch 285/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 87.7500 - val_loss: 374.9163\n",
      "Epoch 286/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 85.7128 - val_loss: 375.3756\n",
      "Epoch 287/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 83.7195 - val_loss: 375.8586\n",
      "Epoch 288/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 81.7697 - val_loss: 376.3648\n",
      "Epoch 289/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 79.8626 - val_loss: 376.8934\n",
      "Epoch 290/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 77.9976 - val_loss: 377.4437\n",
      "Epoch 291/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 76.1741 - val_loss: 378.0152\n",
      "Epoch 292/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 74.3913 - val_loss: 378.6071\n",
      "Epoch 293/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 72.6488 - val_loss: 379.2189\n",
      "Epoch 294/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 70.9458 - val_loss: 379.8499\n",
      "Epoch 295/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 69.2817 - val_loss: 380.4995\n",
      "Epoch 296/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 67.6559 - val_loss: 381.1670\n",
      "Epoch 297/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 66.0679 - val_loss: 381.8518\n",
      "Epoch 298/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 64.5170 - val_loss: 382.5533\n",
      "Epoch 299/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 63.0024 - val_loss: 383.2711\n",
      "Epoch 300/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 61.5239 - val_loss: 384.0041\n",
      "Epoch 301/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 60.0806 - val_loss: 384.7523\n",
      "Epoch 302/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 58.6720 - val_loss: 385.5146\n",
      "Epoch 303/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 57.2976 - val_loss: 386.2906\n",
      "Epoch 304/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 55.9566 - val_loss: 387.0797\n",
      "Epoch 305/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 54.6486 - val_loss: 387.8815\n",
      "Epoch 306/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 53.3730 - val_loss: 388.6953\n",
      "Epoch 307/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 52.1292 - val_loss: 389.5205\n",
      "Epoch 308/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 50.9165 - val_loss: 390.3565\n",
      "Epoch 309/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 49.7345 - val_loss: 391.2030\n",
      "Epoch 310/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 48.5825 - val_loss: 392.0591\n",
      "Epoch 311/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 47.4602 - val_loss: 392.9246\n",
      "Epoch 312/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 46.3668 - val_loss: 393.7987\n",
      "Epoch 313/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 45.3019 - val_loss: 394.6809\n",
      "Epoch 314/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 44.2649 - val_loss: 395.5708\n",
      "Epoch 315/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 43.2553 - val_loss: 396.4681\n",
      "Epoch 316/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 42.2725 - val_loss: 397.3720\n",
      "Epoch 317/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 41.3160 - val_loss: 398.2819\n",
      "Epoch 318/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 40.3854 - val_loss: 399.1975\n",
      "Epoch 319/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 39.4801 - val_loss: 400.1184\n",
      "Epoch 320/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 38.5996 - val_loss: 401.0440\n",
      "Epoch 321/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 37.7433 - val_loss: 401.9737\n",
      "Epoch 322/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 36.9108 - val_loss: 402.9073\n",
      "Epoch 323/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 36.1017 - val_loss: 403.8442\n",
      "Epoch 324/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 35.3153 - val_loss: 404.7841\n",
      "Epoch 325/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 34.5513 - val_loss: 405.7263\n",
      "Epoch 326/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 33.8091 - val_loss: 406.6706\n",
      "Epoch 327/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 33.0883 - val_loss: 407.6163\n",
      "Epoch 328/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 32.3884 - val_loss: 408.5633\n",
      "Epoch 329/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 31.7090 - val_loss: 409.5113\n",
      "Epoch 330/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 31.0495 - val_loss: 410.4594\n",
      "Epoch 331/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 30.4097 - val_loss: 411.4077\n",
      "Epoch 332/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 29.7889 - val_loss: 412.3554\n",
      "Epoch 333/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 29.1868 - val_loss: 413.3026\n",
      "Epoch 334/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 28.6029 - val_loss: 414.2484\n",
      "Epoch 335/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 28.0368 - val_loss: 415.1925\n",
      "Epoch 336/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 27.4883 - val_loss: 416.1351\n",
      "Epoch 337/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 26.9567 - val_loss: 417.0753\n",
      "Epoch 338/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 26.4417 - val_loss: 418.0130\n",
      "Epoch 339/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 25.9429 - val_loss: 418.9479\n",
      "Epoch 340/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 25.4597 - val_loss: 419.8796\n",
      "Epoch 341/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 24.9921 - val_loss: 420.8078\n",
      "Epoch 342/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 24.5394 - val_loss: 421.7323\n",
      "Epoch 343/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 24.1013 - val_loss: 422.6524\n",
      "Epoch 344/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.6776 - val_loss: 423.5684\n",
      "Epoch 345/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.2678 - val_loss: 424.4794\n",
      "Epoch 346/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 22.8714 - val_loss: 425.3858\n",
      "Epoch 347/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 22.4883 - val_loss: 426.2867\n",
      "Epoch 348/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 22.1180 - val_loss: 427.1825\n",
      "Epoch 349/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 21.7602 - val_loss: 428.0724\n",
      "Epoch 350/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 21.4145 - val_loss: 428.9563\n",
      "Epoch 351/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 21.0807 - val_loss: 429.8343\n",
      "Epoch 352/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 20.7584 - val_loss: 430.7057\n",
      "Epoch 353/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 20.4472 - val_loss: 431.5706\n",
      "Epoch 354/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 20.1469 - val_loss: 432.4284\n",
      "Epoch 355/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 19.8573 - val_loss: 433.2792\n",
      "Epoch 356/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 19.5779 - val_loss: 434.1231\n",
      "Epoch 357/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 19.3084 - val_loss: 434.9594\n",
      "Epoch 358/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 19.0486 - val_loss: 435.7879\n",
      "Epoch 359/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.7983 - val_loss: 436.6089\n",
      "Epoch 360/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.5571 - val_loss: 437.4219\n",
      "Epoch 361/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.3247 - val_loss: 438.2270\n",
      "Epoch 362/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 18.1009 - val_loss: 439.0237\n",
      "Epoch 363/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.8855 - val_loss: 439.8121\n",
      "Epoch 364/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.6781 - val_loss: 440.5921\n",
      "Epoch 365/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.4785 - val_loss: 441.3633\n",
      "Epoch 366/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.2866 - val_loss: 442.1261\n",
      "Epoch 367/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.1019 - val_loss: 442.8799\n",
      "Epoch 368/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 16.9243 - val_loss: 443.6246\n",
      "Epoch 369/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 16.7537 - val_loss: 444.3604\n",
      "Epoch 370/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 16.5897 - val_loss: 445.0872\n",
      "Epoch 371/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 16.4321 - val_loss: 445.8045\n",
      "Epoch 372/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 16.2808 - val_loss: 446.5126\n",
      "Epoch 373/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 16.1355 - val_loss: 447.2116\n",
      "Epoch 374/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 15.9959 - val_loss: 447.9012\n",
      "Epoch 375/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 15.8621 - val_loss: 448.5810\n",
      "Epoch 376/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 15.7336 - val_loss: 449.2516\n",
      "Epoch 377/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 15.6104 - val_loss: 449.9127\n",
      "Epoch 378/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 15.4923 - val_loss: 450.5641\n",
      "Epoch 379/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 15.3790 - val_loss: 451.2060\n",
      "Epoch 380/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 15.2704 - val_loss: 451.8381\n",
      "Epoch 381/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 15.1664 - val_loss: 452.4605\n",
      "Epoch 382/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 15.0668 - val_loss: 453.0733\n",
      "Epoch 383/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 14.9714 - val_loss: 453.6765\n",
      "Epoch 384/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.8801 - val_loss: 454.2701\n",
      "Epoch 385/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.7926 - val_loss: 454.8539\n",
      "Epoch 386/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.7090 - val_loss: 455.4278\n",
      "Epoch 387/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.6290 - val_loss: 455.9922\n",
      "Epoch 388/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.5525 - val_loss: 456.5471\n",
      "Epoch 389/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.4793 - val_loss: 457.0923\n",
      "Epoch 390/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.4094 - val_loss: 457.6280\n",
      "Epoch 391/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.3426 - val_loss: 458.1539\n",
      "Epoch 392/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.2788 - val_loss: 458.6704\n",
      "Epoch 393/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.2178 - val_loss: 459.1773\n",
      "Epoch 394/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.1597 - val_loss: 459.6751\n",
      "Epoch 395/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.1041 - val_loss: 460.1632\n",
      "Epoch 396/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 14.0511 - val_loss: 460.6424\n",
      "Epoch 397/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.0006 - val_loss: 461.1119\n",
      "Epoch 398/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.9523 - val_loss: 461.5723\n",
      "Epoch 399/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.9063 - val_loss: 462.0238\n",
      "Epoch 400/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.8625 - val_loss: 462.4661\n",
      "Epoch 401/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.8207 - val_loss: 462.8994\n",
      "Epoch 402/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.7809 - val_loss: 463.3236\n",
      "Epoch 403/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.7429 - val_loss: 463.7394\n",
      "Epoch 404/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.7068 - val_loss: 464.1458\n",
      "Epoch 405/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.6724 - val_loss: 464.5438\n",
      "Epoch 406/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.6397 - val_loss: 464.9334\n",
      "Epoch 407/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.6085 - val_loss: 465.3143\n",
      "Epoch 408/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.5789 - val_loss: 465.6869\n",
      "Epoch 409/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.5507 - val_loss: 466.0509\n",
      "Epoch 410/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.5239 - val_loss: 466.4067\n",
      "Epoch 411/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.4985 - val_loss: 466.7544\n",
      "Epoch 412/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 13.4742 - val_loss: 467.0941\n",
      "Epoch 413/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.4512 - val_loss: 467.4260\n",
      "Epoch 414/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.4293 - val_loss: 467.7502\n",
      "Epoch 415/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.4086 - val_loss: 468.0665\n",
      "Epoch 416/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.3888 - val_loss: 468.3753\n",
      "Epoch 417/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.3701 - val_loss: 468.6764\n",
      "Epoch 418/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.3523 - val_loss: 468.9700\n",
      "Epoch 419/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.3354 - val_loss: 469.2566\n",
      "Epoch 420/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.3193 - val_loss: 469.5357\n",
      "Epoch 421/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.3042 - val_loss: 469.8080\n",
      "Epoch 422/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.2898 - val_loss: 470.0732\n",
      "Epoch 423/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.2761 - val_loss: 470.3314\n",
      "Epoch 424/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.2631 - val_loss: 470.5827\n",
      "Epoch 425/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.2508 - val_loss: 470.8279\n",
      "Epoch 426/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.2392 - val_loss: 471.0663\n",
      "Epoch 427/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.2281 - val_loss: 471.2982\n",
      "Epoch 428/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.2176 - val_loss: 471.5238\n",
      "Epoch 429/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.2077 - val_loss: 471.7435\n",
      "Epoch 430/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.1983 - val_loss: 471.9572\n",
      "Epoch 431/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.1894 - val_loss: 472.1643\n",
      "Epoch 432/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.1810 - val_loss: 472.3661\n",
      "Epoch 433/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.1730 - val_loss: 472.5622\n",
      "Epoch 434/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.1654 - val_loss: 472.7525\n",
      "Epoch 435/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.1583 - val_loss: 472.9369\n",
      "Epoch 436/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.1515 - val_loss: 473.1167\n",
      "Epoch 437/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 13.1451 - val_loss: 473.2906\n",
      "Epoch 438/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 13.1390 - val_loss: 473.4598\n",
      "Epoch 439/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.1332 - val_loss: 473.6236\n",
      "Epoch 440/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.1279 - val_loss: 473.7825\n",
      "Epoch 441/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 13.1227 - val_loss: 473.9368\n",
      "Epoch 442/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.1178 - val_loss: 474.0862\n",
      "Epoch 443/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.1132 - val_loss: 474.2309\n",
      "Epoch 444/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.1088 - val_loss: 474.3709\n",
      "Epoch 445/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.1048 - val_loss: 474.5067\n",
      "Epoch 446/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.1009 - val_loss: 474.6384\n",
      "Epoch 447/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0972 - val_loss: 474.7656\n",
      "Epoch 448/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.0937 - val_loss: 474.8887\n",
      "Epoch 449/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0904 - val_loss: 475.0078\n",
      "Epoch 450/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0873 - val_loss: 475.1232\n",
      "Epoch 451/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0844 - val_loss: 475.2346\n",
      "Epoch 452/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.0816 - val_loss: 475.3425\n",
      "Epoch 453/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.0790 - val_loss: 475.4464\n",
      "Epoch 454/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0765 - val_loss: 475.5469\n",
      "Epoch 455/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0741 - val_loss: 475.6438\n",
      "Epoch 456/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0719 - val_loss: 475.7377\n",
      "Epoch 457/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0698 - val_loss: 475.8281\n",
      "Epoch 458/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.0678 - val_loss: 475.9158\n",
      "Epoch 459/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0659 - val_loss: 475.9999\n",
      "Epoch 460/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.0642 - val_loss: 476.0812\n",
      "Epoch 461/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0625 - val_loss: 476.1594\n",
      "Epoch 462/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 13.0610 - val_loss: 476.2350\n",
      "Epoch 463/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 13.0595 - val_loss: 476.3079\n",
      "Epoch 464/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0581 - val_loss: 476.3782\n",
      "Epoch 465/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0567 - val_loss: 476.4457\n",
      "Epoch 466/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0555 - val_loss: 476.5106\n",
      "Epoch 467/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0543 - val_loss: 476.5735\n",
      "Epoch 468/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0532 - val_loss: 476.6338\n",
      "Epoch 469/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0522 - val_loss: 476.6918\n",
      "Epoch 470/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 13.0512 - val_loss: 476.7474\n",
      "Epoch 471/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0503 - val_loss: 476.8014\n",
      "Epoch 472/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0494 - val_loss: 476.8528\n",
      "Epoch 473/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0486 - val_loss: 476.9023\n",
      "Epoch 474/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0478 - val_loss: 476.9499\n",
      "Epoch 475/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0471 - val_loss: 476.9958\n",
      "Epoch 476/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0464 - val_loss: 477.0396\n",
      "Epoch 477/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0457 - val_loss: 477.0815\n",
      "Epoch 478/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0451 - val_loss: 477.1219\n",
      "Epoch 479/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.0446 - val_loss: 477.1607\n",
      "Epoch 480/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 13.0441 - val_loss: 477.1977\n",
      "Epoch 481/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0436 - val_loss: 477.2334\n",
      "Epoch 482/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0431 - val_loss: 477.2677\n",
      "Epoch 483/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0426 - val_loss: 477.3003\n",
      "Epoch 484/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0423 - val_loss: 477.3315\n",
      "Epoch 485/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0419 - val_loss: 477.3618\n",
      "Epoch 486/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0415 - val_loss: 477.3904\n",
      "Epoch 487/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0412 - val_loss: 477.4180\n",
      "Epoch 488/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.0409 - val_loss: 477.4442\n",
      "Epoch 489/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.0406 - val_loss: 477.4696\n",
      "Epoch 490/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0404 - val_loss: 477.4937\n",
      "Epoch 491/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0401 - val_loss: 477.5167\n",
      "Epoch 492/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0399 - val_loss: 477.5384\n",
      "Epoch 493/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0397 - val_loss: 477.5595\n",
      "Epoch 494/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0395 - val_loss: 477.5796\n",
      "Epoch 495/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0394 - val_loss: 477.5987\n",
      "Epoch 496/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0392 - val_loss: 477.6169\n",
      "Epoch 497/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0391 - val_loss: 477.6342\n",
      "Epoch 498/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 13.0390 - val_loss: 477.6505\n",
      "Epoch 499/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0389 - val_loss: 477.6667\n",
      "Epoch 500/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.0388 - val_loss: 477.6815\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 395ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.98086368e+01, 6.98030346e+01, 6.97974323e+01, 6.97918301e+01,\n",
       "        6.97862278e+01, 6.97806256e+01, 6.97750233e+01, 6.97694211e+01,\n",
       "        6.97638189e+01, 6.97582166e+01, 6.97526144e+01, 6.97470121e+01,\n",
       "        6.97414099e+01, 6.97358077e+01, 6.97302054e+01, 6.97246032e+01,\n",
       "        6.97190009e+01, 6.97133987e+01, 6.97077965e+01, 6.97021942e+01,\n",
       "        6.96931839e+01, 6.96819795e+01, 6.96707750e+01, 6.96595705e+01,\n",
       "        6.96483660e+01, 6.96371615e+01, 6.96259570e+01, 6.96147526e+01,\n",
       "        6.96035481e+01, 6.95923436e+01, 6.95811391e+01, 6.95699346e+01,\n",
       "        6.95587302e+01, 6.95475257e+01, 6.95363212e+01, 6.95251167e+01,\n",
       "        6.95139122e+01, 6.95027077e+01, 6.94915033e+01, 6.94802988e+01,\n",
       "        6.94690943e+01, 6.94578898e+01, 6.94466853e+01, 6.94354809e+01,\n",
       "        6.94242764e+01, 6.94130719e+01, 6.94018674e+01, 7.36035948e+01,\n",
       "        7.34859477e+01, 7.33683006e+01, 7.32506536e+01, 7.31330065e+01,\n",
       "        7.30153595e+01, 7.28977124e+01, 7.27800654e+01, 7.26624183e+01,\n",
       "        7.25447712e+01, 7.24271242e+01, 7.23094771e+01, 7.21918301e+01,\n",
       "        7.20741830e+01, 7.19565360e+01, 7.18388889e+01, 7.16931139e+01,\n",
       "        7.15334500e+01, 7.13737862e+01, 7.12141223e+01, 7.10544584e+01,\n",
       "        7.08947946e+01, 7.07351307e+01, 7.05754668e+01, 7.04158030e+01,\n",
       "        7.02561391e+01, 7.58221130e+01, 8.02230950e-01, 0.00000000e+00,\n",
       "        5.90062680e-01, 0.00000000e+00, 0.00000000e+00, 7.21140860e-01,\n",
       "        6.25980949e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.06821650e-01, 4.86090854e-02, 0.00000000e+00, 7.42734313e-01,\n",
       "        8.43163490e-01, 8.04446399e-01, 2.95681089e-01, 3.09046447e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.68616617e-01, 3.83580267e-01,\n",
       "        0.00000000e+00, 1.84291288e-01, 2.47834027e-01, 1.34163260e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66.25536881, 66.24789916, 66.24042951, 66.23295985, 66.2254902 ,\n",
       "       66.21802054, 66.21055089, 66.20308123, 66.19561158, 66.18814192,\n",
       "       66.18067227, 66.17320261, 66.16573296, 66.15826331, 66.15079365,\n",
       "       66.143324  , 66.13585434, 66.12838469, 66.12091503, 66.11344538,\n",
       "       66.10597572, 66.09850607, 66.09103641, 66.08356676, 66.07609711,\n",
       "       66.06862745, 66.0611578 , 66.05368814, 66.04621849, 66.03874883,\n",
       "       66.03127918, 66.02380952, 66.01633987, 66.00887021, 66.00140056,\n",
       "       65.99393091, 65.98646125, 65.9789916 , 65.97152194, 65.96405229,\n",
       "       65.95658263, 65.94911298, 65.94164332, 65.93417367, 65.92670401,\n",
       "       65.91923436, 65.91176471, 65.90429505, 65.89960317, 65.89866947,\n",
       "       65.89773576, 65.89680205, 65.89586835, 65.89493464, 65.89400093,\n",
       "       65.89306723, 65.89213352, 65.89119981, 65.89026611, 65.8893324 ,\n",
       "       65.88839869, 65.88746499, 65.88653128, 65.88559757, 65.88466387,\n",
       "       65.88373016, 65.88279645, 65.88186275, 65.88092904, 65.87999533,\n",
       "       65.87906162, 65.87812792, 65.87719421, 65.8762605 , 65.8753268 ,\n",
       "       65.87439309, 65.87345938, 65.87252568, 65.87159197, 65.87065826,\n",
       "       65.86972456, 65.86879085, 65.86785714, 65.86692344, 65.86598973,\n",
       "       65.86505602, 65.86412232, 65.86318861, 65.8622549 , 65.8613212 ,\n",
       "       65.86038749, 65.85945378, 65.85852007, 65.85758637, 65.85665266,\n",
       "       65.85571895, 65.85478525, 65.85385154, 65.85291783, 65.85198413])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.060754587562286\n",
      "19.80356114825523\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
