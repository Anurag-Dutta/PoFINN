{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "1945    63.817052\n",
       "1946    63.810049\n",
       "1947    63.803046\n",
       "1948    63.796043\n",
       "1949    63.789041\n",
       "Name: C5, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_1850_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "1845     0.735146\n",
       "1846     0.000000\n",
       "1847     0.359862\n",
       "1848     0.231354\n",
       "1849     0.513536\n",
       "Name: C5, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1850)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 1, 251) (1400, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "18/18 [==============================] - 3s 28ms/step - loss: 5293.2090 - val_loss: 3719.1985\n",
      "Epoch 2/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5165.7266 - val_loss: 3631.2688\n",
      "Epoch 3/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5096.4155 - val_loss: 3585.4119\n",
      "Epoch 4/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5025.9863 - val_loss: 3537.9138\n",
      "Epoch 5/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4959.7324 - val_loss: 3493.0654\n",
      "Epoch 6/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 4894.3662 - val_loss: 3448.7683\n",
      "Epoch 7/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4829.9546 - val_loss: 3405.3516\n",
      "Epoch 8/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 4766.3892 - val_loss: 3362.5706\n",
      "Epoch 9/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 4703.5962 - val_loss: 3320.3696\n",
      "Epoch 10/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 4641.5298 - val_loss: 3278.7217\n",
      "Epoch 11/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4580.1592 - val_loss: 3237.6074\n",
      "Epoch 12/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4519.4624 - val_loss: 3197.0125\n",
      "Epoch 13/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4459.4243 - val_loss: 3156.9250\n",
      "Epoch 14/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4400.0288 - val_loss: 3117.3364\n",
      "Epoch 15/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4341.2681 - val_loss: 3078.2388\n",
      "Epoch 16/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4283.1304 - val_loss: 3039.6245\n",
      "Epoch 17/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4225.6084 - val_loss: 3001.4883\n",
      "Epoch 18/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4168.6943 - val_loss: 2963.8237\n",
      "Epoch 19/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4112.3813 - val_loss: 2926.6260\n",
      "Epoch 20/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4056.6628 - val_loss: 2889.8894\n",
      "Epoch 21/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4001.5330 - val_loss: 2853.6094\n",
      "Epoch 22/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3946.9854 - val_loss: 2817.7825\n",
      "Epoch 23/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3893.0151 - val_loss: 2782.4050\n",
      "Epoch 24/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3839.6179 - val_loss: 2747.5005\n",
      "Epoch 25/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3786.7861 - val_loss: 2712.9663\n",
      "Epoch 26/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3734.5166 - val_loss: 2678.9038\n",
      "Epoch 27/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3682.8040 - val_loss: 2645.2737\n",
      "Epoch 28/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3631.6433 - val_loss: 2612.0710\n",
      "Epoch 29/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3581.0308 - val_loss: 2579.2922\n",
      "Epoch 30/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3530.9619 - val_loss: 2546.9336\n",
      "Epoch 31/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3481.4309 - val_loss: 2514.9922\n",
      "Epoch 32/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3432.4341 - val_loss: 2483.4631\n",
      "Epoch 33/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3383.9670 - val_loss: 2452.3440\n",
      "Epoch 34/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3336.0264 - val_loss: 2421.6311\n",
      "Epoch 35/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3288.6069 - val_loss: 2391.3203\n",
      "Epoch 36/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 3241.7043 - val_loss: 2361.4089\n",
      "Epoch 37/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 3195.3159 - val_loss: 2331.8936\n",
      "Epoch 38/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3149.4363 - val_loss: 2302.7705\n",
      "Epoch 39/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 3104.0615 - val_loss: 2274.0371\n",
      "Epoch 40/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3059.1887 - val_loss: 2245.6897\n",
      "Epoch 41/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3014.8132 - val_loss: 2217.7249\n",
      "Epoch 42/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2970.9309 - val_loss: 2190.1396\n",
      "Epoch 43/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2927.5381 - val_loss: 2162.9312\n",
      "Epoch 44/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2884.6318 - val_loss: 2136.0957\n",
      "Epoch 45/500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 2842.2070 - val_loss: 2109.6306\n",
      "Epoch 46/500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 2800.2610 - val_loss: 2083.5325\n",
      "Epoch 47/500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 2758.7898 - val_loss: 2057.7986\n",
      "Epoch 48/500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 2717.7888 - val_loss: 2032.4254\n",
      "Epoch 49/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 2677.2549 - val_loss: 2007.4105\n",
      "Epoch 50/500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 2637.1858 - val_loss: 1982.7505\n",
      "Epoch 51/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2597.5767 - val_loss: 1958.4429\n",
      "Epoch 52/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2558.4238 - val_loss: 1934.4839\n",
      "Epoch 53/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2519.7239 - val_loss: 1910.8712\n",
      "Epoch 54/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2481.4736 - val_loss: 1887.6016\n",
      "Epoch 55/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2443.6697 - val_loss: 1864.6725\n",
      "Epoch 56/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2406.3081 - val_loss: 1842.0804\n",
      "Epoch 57/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2369.3855 - val_loss: 1819.8235\n",
      "Epoch 58/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2332.8984 - val_loss: 1797.8978\n",
      "Epoch 59/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2296.8442 - val_loss: 1776.3014\n",
      "Epoch 60/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2261.2190 - val_loss: 1755.0309\n",
      "Epoch 61/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2226.0186 - val_loss: 1734.0836\n",
      "Epoch 62/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2191.2412 - val_loss: 1713.4572\n",
      "Epoch 63/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2156.8831 - val_loss: 1693.1482\n",
      "Epoch 64/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2122.9404 - val_loss: 1673.1543\n",
      "Epoch 65/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2089.4102 - val_loss: 1653.4729\n",
      "Epoch 66/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2056.2888 - val_loss: 1634.1010\n",
      "Epoch 67/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2023.5739 - val_loss: 1615.0359\n",
      "Epoch 68/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1991.2621 - val_loss: 1596.2753\n",
      "Epoch 69/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1959.3494 - val_loss: 1577.8157\n",
      "Epoch 70/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1927.8333 - val_loss: 1559.6553\n",
      "Epoch 71/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1896.7107 - val_loss: 1541.7913\n",
      "Epoch 72/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1865.9785 - val_loss: 1524.2206\n",
      "Epoch 73/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 1835.6333 - val_loss: 1506.9408\n",
      "Epoch 74/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1805.6721 - val_loss: 1489.9495\n",
      "Epoch 75/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1776.0914 - val_loss: 1473.2438\n",
      "Epoch 76/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1746.8887 - val_loss: 1456.8214\n",
      "Epoch 77/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1718.0609 - val_loss: 1440.6794\n",
      "Epoch 78/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1689.6049 - val_loss: 1424.8157\n",
      "Epoch 79/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1661.5179 - val_loss: 1409.2274\n",
      "Epoch 80/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1633.7964 - val_loss: 1393.9121\n",
      "Epoch 81/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1606.4377 - val_loss: 1378.8674\n",
      "Epoch 82/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1579.4392 - val_loss: 1364.0905\n",
      "Epoch 83/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1552.7972 - val_loss: 1349.5789\n",
      "Epoch 84/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1526.5093 - val_loss: 1335.3301\n",
      "Epoch 85/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1500.5723 - val_loss: 1321.3419\n",
      "Epoch 86/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1474.9835 - val_loss: 1307.6116\n",
      "Epoch 87/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1449.7400 - val_loss: 1294.1366\n",
      "Epoch 88/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1424.8385 - val_loss: 1280.9147\n",
      "Epoch 89/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1400.2765 - val_loss: 1267.9434\n",
      "Epoch 90/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1376.0514 - val_loss: 1255.2201\n",
      "Epoch 91/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1352.1593 - val_loss: 1242.7426\n",
      "Epoch 92/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1328.5986 - val_loss: 1230.5082\n",
      "Epoch 93/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1305.3660 - val_loss: 1218.5148\n",
      "Epoch 94/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1282.4585 - val_loss: 1206.7598\n",
      "Epoch 95/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1259.8738 - val_loss: 1195.2410\n",
      "Epoch 96/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1237.6088 - val_loss: 1183.9557\n",
      "Epoch 97/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1215.6604 - val_loss: 1172.9017\n",
      "Epoch 98/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1194.0265 - val_loss: 1162.0767\n",
      "Epoch 99/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1172.7037 - val_loss: 1151.4779\n",
      "Epoch 100/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1151.6896 - val_loss: 1141.1038\n",
      "Epoch 101/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1130.9813 - val_loss: 1130.9508\n",
      "Epoch 102/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1110.5762 - val_loss: 1121.0176\n",
      "Epoch 103/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1090.4717 - val_loss: 1111.3015\n",
      "Epoch 104/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1070.6650 - val_loss: 1101.8004\n",
      "Epoch 105/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1051.1534 - val_loss: 1092.5114\n",
      "Epoch 106/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1031.9338 - val_loss: 1083.4326\n",
      "Epoch 107/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1013.0042 - val_loss: 1074.5618\n",
      "Epoch 108/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 994.3619 - val_loss: 1065.8964\n",
      "Epoch 109/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 976.0036 - val_loss: 1057.4342\n",
      "Epoch 110/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 957.9274 - val_loss: 1049.1730\n",
      "Epoch 111/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 940.1300 - val_loss: 1041.1102\n",
      "Epoch 112/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 922.6093 - val_loss: 1033.2441\n",
      "Epoch 113/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 905.3624 - val_loss: 1025.5719\n",
      "Epoch 114/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 888.3867 - val_loss: 1018.0915\n",
      "Epoch 115/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 871.6798 - val_loss: 1010.8008\n",
      "Epoch 116/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 855.2387 - val_loss: 1003.6971\n",
      "Epoch 117/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 839.0613 - val_loss: 996.7786\n",
      "Epoch 118/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 823.1448 - val_loss: 990.0427\n",
      "Epoch 119/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 807.4865 - val_loss: 983.4873\n",
      "Epoch 120/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 792.0837 - val_loss: 977.1100\n",
      "Epoch 121/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 776.9346 - val_loss: 970.9092\n",
      "Epoch 122/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 762.0359 - val_loss: 964.8817\n",
      "Epoch 123/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 747.3853 - val_loss: 959.0257\n",
      "Epoch 124/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 732.9804 - val_loss: 953.3384\n",
      "Epoch 125/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 718.8185 - val_loss: 947.8373\n",
      "Epoch 126/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 704.8970 - val_loss: 942.5745\n",
      "Epoch 127/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 691.2135 - val_loss: 937.3846\n",
      "Epoch 128/500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 677.7657 - val_loss: 932.3548\n",
      "Epoch 129/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 664.5510 - val_loss: 927.4839\n",
      "Epoch 130/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 651.5667 - val_loss: 922.7687\n",
      "Epoch 131/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 638.8105 - val_loss: 918.2076\n",
      "Epoch 132/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 626.2802 - val_loss: 913.7988\n",
      "Epoch 133/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 613.9727 - val_loss: 909.5395\n",
      "Epoch 134/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 601.8859 - val_loss: 905.4276\n",
      "Epoch 135/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 590.0173 - val_loss: 901.4611\n",
      "Epoch 136/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 578.3644 - val_loss: 897.6379\n",
      "Epoch 137/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 566.9249 - val_loss: 893.9556\n",
      "Epoch 138/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 555.6963 - val_loss: 890.4123\n",
      "Epoch 139/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 544.6761 - val_loss: 887.0057\n",
      "Epoch 140/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 533.8621 - val_loss: 883.7338\n",
      "Epoch 141/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 523.2515 - val_loss: 880.5946\n",
      "Epoch 142/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 512.8422 - val_loss: 877.5855\n",
      "Epoch 143/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 502.6319 - val_loss: 874.7049\n",
      "Epoch 144/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 492.6178 - val_loss: 871.9504\n",
      "Epoch 145/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 482.7978 - val_loss: 869.3200\n",
      "Epoch 146/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 473.1696 - val_loss: 866.8117\n",
      "Epoch 147/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 463.7308 - val_loss: 864.4232\n",
      "Epoch 148/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 454.4789 - val_loss: 862.1525\n",
      "Epoch 149/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 445.4114 - val_loss: 859.9976\n",
      "Epoch 150/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 436.5262 - val_loss: 857.9562\n",
      "Epoch 151/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 427.8211 - val_loss: 856.0265\n",
      "Epoch 152/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 419.2935 - val_loss: 854.2065\n",
      "Epoch 153/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 410.9410 - val_loss: 852.4938\n",
      "Epoch 154/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 402.7617 - val_loss: 850.8867\n",
      "Epoch 155/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 394.7530 - val_loss: 849.3829\n",
      "Epoch 156/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 386.9128 - val_loss: 847.9806\n",
      "Epoch 157/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 379.2383 - val_loss: 846.6776\n",
      "Epoch 158/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 371.7278 - val_loss: 845.4721\n",
      "Epoch 159/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 364.3788 - val_loss: 844.3618\n",
      "Epoch 160/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 357.1890 - val_loss: 843.3450\n",
      "Epoch 161/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 350.1561 - val_loss: 842.4196\n",
      "Epoch 162/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 343.2781 - val_loss: 841.5836\n",
      "Epoch 163/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 336.5524 - val_loss: 840.8350\n",
      "Epoch 164/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 329.9770 - val_loss: 840.1719\n",
      "Epoch 165/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 323.5498 - val_loss: 839.5924\n",
      "Epoch 166/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 317.2686 - val_loss: 839.0944\n",
      "Epoch 167/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 311.1310 - val_loss: 838.6762\n",
      "Epoch 168/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 305.1347 - val_loss: 838.3358\n",
      "Epoch 169/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 299.2778 - val_loss: 838.0713\n",
      "Epoch 170/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 293.5582 - val_loss: 837.8807\n",
      "Epoch 171/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 287.9735 - val_loss: 837.7620\n",
      "Epoch 172/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 282.5217 - val_loss: 837.7138\n",
      "Epoch 173/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 277.2005 - val_loss: 837.7337\n",
      "Epoch 174/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 272.0080 - val_loss: 837.8203\n",
      "Epoch 175/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 266.9418 - val_loss: 837.9714\n",
      "Epoch 176/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 261.9999 - val_loss: 838.1855\n",
      "Epoch 177/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 257.1803 - val_loss: 838.4605\n",
      "Epoch 178/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 252.4808 - val_loss: 838.7949\n",
      "Epoch 179/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 247.8996 - val_loss: 839.1866\n",
      "Epoch 180/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 243.4344 - val_loss: 839.6341\n",
      "Epoch 181/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 239.0834 - val_loss: 840.1354\n",
      "Epoch 182/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 234.8446 - val_loss: 840.6890\n",
      "Epoch 183/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 230.7154 - val_loss: 841.2930\n",
      "Epoch 184/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 226.6946 - val_loss: 841.9456\n",
      "Epoch 185/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 222.7797 - val_loss: 842.6455\n",
      "Epoch 186/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 218.9689 - val_loss: 843.3907\n",
      "Epoch 187/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 215.2601 - val_loss: 844.1796\n",
      "Epoch 188/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 211.6516 - val_loss: 845.0106\n",
      "Epoch 189/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 208.1414 - val_loss: 845.8820\n",
      "Epoch 190/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 204.7276 - val_loss: 846.7922\n",
      "Epoch 191/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 201.4081 - val_loss: 847.7397\n",
      "Epoch 192/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 198.1814 - val_loss: 848.7228\n",
      "Epoch 193/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 195.0453 - val_loss: 849.7400\n",
      "Epoch 194/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 191.9980 - val_loss: 850.7899\n",
      "Epoch 195/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 189.0378 - val_loss: 851.8708\n",
      "Epoch 196/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 186.1630 - val_loss: 852.9810\n",
      "Epoch 197/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 183.3715 - val_loss: 854.1196\n",
      "Epoch 198/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 180.6616 - val_loss: 855.2846\n",
      "Epoch 199/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 178.0318 - val_loss: 856.4748\n",
      "Epoch 200/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 175.4802 - val_loss: 857.6888\n",
      "Epoch 201/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 173.0051 - val_loss: 858.9251\n",
      "Epoch 202/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 170.6046 - val_loss: 860.1825\n",
      "Epoch 203/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 168.2771 - val_loss: 861.4594\n",
      "Epoch 204/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 166.0211 - val_loss: 862.7545\n",
      "Epoch 205/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 163.8350 - val_loss: 864.0667\n",
      "Epoch 206/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 161.7169 - val_loss: 865.3947\n",
      "Epoch 207/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 159.6655 - val_loss: 866.7369\n",
      "Epoch 208/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 157.6788 - val_loss: 868.0922\n",
      "Epoch 209/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 155.7557 - val_loss: 869.4597\n",
      "Epoch 210/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 153.8944 - val_loss: 870.8380\n",
      "Epoch 211/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 152.0933 - val_loss: 872.2256\n",
      "Epoch 212/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 150.3513 - val_loss: 873.6216\n",
      "Epoch 213/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 148.6664 - val_loss: 875.0251\n",
      "Epoch 214/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 147.0373 - val_loss: 876.4348\n",
      "Epoch 215/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 145.4629 - val_loss: 877.8495\n",
      "Epoch 216/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 143.9413 - val_loss: 879.2683\n",
      "Epoch 217/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 142.4715 - val_loss: 880.6903\n",
      "Epoch 218/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 141.0517 - val_loss: 882.1144\n",
      "Epoch 219/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 139.6807 - val_loss: 883.5395\n",
      "Epoch 220/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 138.3574 - val_loss: 884.9647\n",
      "Epoch 221/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 137.0803 - val_loss: 886.3890\n",
      "Epoch 222/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 135.8482 - val_loss: 887.8116\n",
      "Epoch 223/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 134.6598 - val_loss: 889.2316\n",
      "Epoch 224/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 133.5138 - val_loss: 890.6485\n",
      "Epoch 225/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 132.4091 - val_loss: 892.0610\n",
      "Epoch 226/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 131.3444 - val_loss: 893.4685\n",
      "Epoch 227/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 130.3185 - val_loss: 894.8700\n",
      "Epoch 228/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 129.3303 - val_loss: 896.2650\n",
      "Epoch 229/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 128.3786 - val_loss: 897.6525\n",
      "Epoch 230/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 127.4624 - val_loss: 899.0322\n",
      "Epoch 231/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 126.5807 - val_loss: 900.4033\n",
      "Epoch 232/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 125.7321 - val_loss: 901.7651\n",
      "Epoch 233/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 124.9157 - val_loss: 903.1169\n",
      "Epoch 234/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 124.1307 - val_loss: 904.4584\n",
      "Epoch 235/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 123.3759 - val_loss: 905.7885\n",
      "Epoch 236/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 122.6503 - val_loss: 907.1073\n",
      "Epoch 237/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 121.9530 - val_loss: 908.4137\n",
      "Epoch 238/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 121.2832 - val_loss: 909.7075\n",
      "Epoch 239/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 120.6398 - val_loss: 910.9882\n",
      "Epoch 240/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 120.0219 - val_loss: 912.2554\n",
      "Epoch 241/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 119.4288 - val_loss: 913.5085\n",
      "Epoch 242/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 118.8596 - val_loss: 914.7473\n",
      "Epoch 243/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 118.3134 - val_loss: 915.9714\n",
      "Epoch 244/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 117.7893 - val_loss: 917.1805\n",
      "Epoch 245/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 117.2868 - val_loss: 918.3740\n",
      "Epoch 246/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 116.8049 - val_loss: 919.5517\n",
      "Epoch 247/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 116.3430 - val_loss: 920.7136\n",
      "Epoch 248/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 115.9004 - val_loss: 921.8591\n",
      "Epoch 249/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 115.4761 - val_loss: 922.9881\n",
      "Epoch 250/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 115.0697 - val_loss: 924.1003\n",
      "Epoch 251/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 114.6806 - val_loss: 925.1956\n",
      "Epoch 252/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 114.3081 - val_loss: 926.2737\n",
      "Epoch 253/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 113.9514 - val_loss: 927.3345\n",
      "Epoch 254/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 113.6100 - val_loss: 928.3782\n",
      "Epoch 255/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 113.2832 - val_loss: 929.4040\n",
      "Epoch 256/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 112.9707 - val_loss: 930.4125\n",
      "Epoch 257/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 112.6717 - val_loss: 931.4029\n",
      "Epoch 258/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 112.3859 - val_loss: 932.3758\n",
      "Epoch 259/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 112.1125 - val_loss: 933.3306\n",
      "Epoch 260/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 111.8512 - val_loss: 934.2675\n",
      "Epoch 261/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 111.6015 - val_loss: 935.1868\n",
      "Epoch 262/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 111.3628 - val_loss: 936.0882\n",
      "Epoch 263/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 111.1348 - val_loss: 936.9717\n",
      "Epoch 264/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 110.9169 - val_loss: 937.8374\n",
      "Epoch 265/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 110.7088 - val_loss: 938.6855\n",
      "Epoch 266/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 110.5101 - val_loss: 939.5156\n",
      "Epoch 267/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.3204 - val_loss: 940.3281\n",
      "Epoch 268/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 110.1392 - val_loss: 941.1229\n",
      "Epoch 269/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 109.9662 - val_loss: 941.9005\n",
      "Epoch 270/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 109.8012 - val_loss: 942.6607\n",
      "Epoch 271/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 109.6438 - val_loss: 943.4034\n",
      "Epoch 272/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.4935 - val_loss: 944.1293\n",
      "Epoch 273/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.3501 - val_loss: 944.8383\n",
      "Epoch 274/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 109.2132 - val_loss: 945.5303\n",
      "Epoch 275/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.0828 - val_loss: 946.2056\n",
      "Epoch 276/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.9583 - val_loss: 946.8644\n",
      "Epoch 277/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 108.8397 - val_loss: 947.5068\n",
      "Epoch 278/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.7265 - val_loss: 948.1332\n",
      "Epoch 279/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 108.6185 - val_loss: 948.7440\n",
      "Epoch 280/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.5156 - val_loss: 949.3387\n",
      "Epoch 281/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.4175 - val_loss: 949.9178\n",
      "Epoch 282/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 108.3240 - val_loss: 950.4816\n",
      "Epoch 283/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.2349 - val_loss: 951.0309\n",
      "Epoch 284/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.1499 - val_loss: 951.5649\n",
      "Epoch 285/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.0688 - val_loss: 952.0844\n",
      "Epoch 286/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.9916 - val_loss: 952.5893\n",
      "Epoch 287/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.9180 - val_loss: 953.0801\n",
      "Epoch 288/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.8478 - val_loss: 953.5569\n",
      "Epoch 289/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.7809 - val_loss: 954.0200\n",
      "Epoch 290/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 107.7173 - val_loss: 954.4698\n",
      "Epoch 291/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.6566 - val_loss: 954.9065\n",
      "Epoch 292/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.5987 - val_loss: 955.3301\n",
      "Epoch 293/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.5435 - val_loss: 955.7412\n",
      "Epoch 294/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.4909 - val_loss: 956.1397\n",
      "Epoch 295/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.4408 - val_loss: 956.5257\n",
      "Epoch 296/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.3931 - val_loss: 956.9003\n",
      "Epoch 297/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.3476 - val_loss: 957.2627\n",
      "Epoch 298/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.3043 - val_loss: 957.6143\n",
      "Epoch 299/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.2629 - val_loss: 957.9545\n",
      "Epoch 300/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 107.2235 - val_loss: 958.2834\n",
      "Epoch 301/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.1861 - val_loss: 958.6019\n",
      "Epoch 302/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.1503 - val_loss: 958.9102\n",
      "Epoch 303/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.1162 - val_loss: 959.2080\n",
      "Epoch 304/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.0838 - val_loss: 959.4963\n",
      "Epoch 305/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.0527 - val_loss: 959.7745\n",
      "Epoch 306/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 107.0233 - val_loss: 960.0434\n",
      "Epoch 307/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.9951 - val_loss: 960.3031\n",
      "Epoch 308/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.9683 - val_loss: 960.5538\n",
      "Epoch 309/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.9428 - val_loss: 960.7959\n",
      "Epoch 310/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.9184 - val_loss: 961.0296\n",
      "Epoch 311/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.8952 - val_loss: 961.2548\n",
      "Epoch 312/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.8731 - val_loss: 961.4720\n",
      "Epoch 313/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.8521 - val_loss: 961.6815\n",
      "Epoch 314/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.8319 - val_loss: 961.8834\n",
      "Epoch 315/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.8128 - val_loss: 962.0784\n",
      "Epoch 316/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.7945 - val_loss: 962.2656\n",
      "Epoch 317/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.7771 - val_loss: 962.4462\n",
      "Epoch 318/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.7605 - val_loss: 962.6200\n",
      "Epoch 319/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.7447 - val_loss: 962.7877\n",
      "Epoch 320/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.7296 - val_loss: 962.9487\n",
      "Epoch 321/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.7152 - val_loss: 963.1031\n",
      "Epoch 322/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.7016 - val_loss: 963.2520\n",
      "Epoch 323/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.6886 - val_loss: 963.3948\n",
      "Epoch 324/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.6761 - val_loss: 963.5323\n",
      "Epoch 325/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.6643 - val_loss: 963.6645\n",
      "Epoch 326/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.6531 - val_loss: 963.7916\n",
      "Epoch 327/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.6423 - val_loss: 963.9134\n",
      "Epoch 328/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 106.6321 - val_loss: 964.0302\n",
      "Epoch 329/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.6223 - val_loss: 964.1426\n",
      "Epoch 330/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.6131 - val_loss: 964.2504\n",
      "Epoch 331/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.6042 - val_loss: 964.3538\n",
      "Epoch 332/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.5957 - val_loss: 964.4528\n",
      "Epoch 333/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.5877 - val_loss: 964.5478\n",
      "Epoch 334/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.5801 - val_loss: 964.6390\n",
      "Epoch 335/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.5728 - val_loss: 964.7263\n",
      "Epoch 336/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.5659 - val_loss: 964.8101\n",
      "Epoch 337/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.5593 - val_loss: 964.8902\n",
      "Epoch 338/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.5530 - val_loss: 964.9671\n",
      "Epoch 339/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.5471 - val_loss: 965.0406\n",
      "Epoch 340/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.5414 - val_loss: 965.1110\n",
      "Epoch 341/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.5360 - val_loss: 965.1785\n",
      "Epoch 342/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 106.5308 - val_loss: 965.2430\n",
      "Epoch 343/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.5260 - val_loss: 965.3044\n",
      "Epoch 344/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.5213 - val_loss: 965.3633\n",
      "Epoch 345/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.5169 - val_loss: 965.4196\n",
      "Epoch 346/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.5127 - val_loss: 965.4736\n",
      "Epoch 347/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.5087 - val_loss: 965.5250\n",
      "Epoch 348/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 106.5049 - val_loss: 965.5742\n",
      "Epoch 349/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.5013 - val_loss: 965.6208\n",
      "Epoch 350/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4979 - val_loss: 965.6660\n",
      "Epoch 351/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4946 - val_loss: 965.7087\n",
      "Epoch 352/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 106.4916 - val_loss: 965.7493\n",
      "Epoch 353/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4886 - val_loss: 965.7881\n",
      "Epoch 354/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4859 - val_loss: 965.8252\n",
      "Epoch 355/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4833 - val_loss: 965.8607\n",
      "Epoch 356/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4808 - val_loss: 965.8944\n",
      "Epoch 357/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4784 - val_loss: 965.9267\n",
      "Epoch 358/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4762 - val_loss: 965.9575\n",
      "Epoch 359/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4740 - val_loss: 965.9866\n",
      "Epoch 360/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4721 - val_loss: 966.0145\n",
      "Epoch 361/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4702 - val_loss: 966.0408\n",
      "Epoch 362/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4684 - val_loss: 966.0661\n",
      "Epoch 363/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4667 - val_loss: 966.0901\n",
      "Epoch 364/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4651 - val_loss: 966.1133\n",
      "Epoch 365/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4635 - val_loss: 966.1351\n",
      "Epoch 366/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 106.4621 - val_loss: 966.1560\n",
      "Epoch 367/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4608 - val_loss: 966.1757\n",
      "Epoch 368/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4595 - val_loss: 966.1945\n",
      "Epoch 369/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4583 - val_loss: 966.2119\n",
      "Epoch 370/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4572 - val_loss: 966.2290\n",
      "Epoch 371/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 106.4561 - val_loss: 966.2449\n",
      "Epoch 372/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4551 - val_loss: 966.2601\n",
      "Epoch 373/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4542 - val_loss: 966.2745\n",
      "Epoch 374/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4534 - val_loss: 966.2886\n",
      "Epoch 375/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 106.4525 - val_loss: 966.3018\n",
      "Epoch 376/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4517 - val_loss: 966.3143\n",
      "Epoch 377/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4510 - val_loss: 966.3264\n",
      "Epoch 378/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4503 - val_loss: 966.3377\n",
      "Epoch 379/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4496 - val_loss: 966.3481\n",
      "Epoch 380/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4490 - val_loss: 966.3580\n",
      "Epoch 381/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4485 - val_loss: 966.3677\n",
      "Epoch 382/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4480 - val_loss: 966.3769\n",
      "Epoch 383/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4475 - val_loss: 966.3854\n",
      "Epoch 384/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4470 - val_loss: 966.3936\n",
      "Epoch 385/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4466 - val_loss: 966.4016\n",
      "Epoch 386/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 106.4462 - val_loss: 966.4089\n",
      "Epoch 387/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4458 - val_loss: 966.4158\n",
      "Epoch 388/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4455 - val_loss: 966.4227\n",
      "Epoch 389/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4451 - val_loss: 966.4287\n",
      "Epoch 390/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4449 - val_loss: 966.4344\n",
      "Epoch 391/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4447 - val_loss: 966.4402\n",
      "Epoch 392/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4444 - val_loss: 966.4456\n",
      "Epoch 393/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4442 - val_loss: 966.4504\n",
      "Epoch 394/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4440 - val_loss: 966.4553\n",
      "Epoch 395/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4438 - val_loss: 966.4600\n",
      "Epoch 396/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 106.4436 - val_loss: 966.4639\n",
      "Epoch 397/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4435 - val_loss: 966.4681\n",
      "Epoch 398/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4433 - val_loss: 966.4717\n",
      "Epoch 399/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4432 - val_loss: 966.4755\n",
      "Epoch 400/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4431 - val_loss: 966.4790\n",
      "Epoch 401/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4430 - val_loss: 966.4819\n",
      "Epoch 402/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4429 - val_loss: 966.4847\n",
      "Epoch 403/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4429 - val_loss: 966.4875\n",
      "Epoch 404/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4428 - val_loss: 966.4902\n",
      "Epoch 405/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4428 - val_loss: 966.4927\n",
      "Epoch 406/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4427 - val_loss: 966.4954\n",
      "Epoch 407/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4427 - val_loss: 966.4977\n",
      "Epoch 408/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4426 - val_loss: 966.5002\n",
      "Epoch 409/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4426 - val_loss: 966.5023\n",
      "Epoch 410/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4426 - val_loss: 966.5042\n",
      "Epoch 411/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4426 - val_loss: 966.5059\n",
      "Epoch 412/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4426 - val_loss: 966.5071\n",
      "Epoch 413/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4426 - val_loss: 966.5087\n",
      "Epoch 414/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4427 - val_loss: 966.5101\n",
      "Epoch 415/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4427 - val_loss: 966.5120\n",
      "Epoch 416/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4427 - val_loss: 966.5132\n",
      "Epoch 417/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 106.4427 - val_loss: 966.5150\n",
      "Epoch 418/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4428 - val_loss: 966.5161\n",
      "Epoch 419/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4428 - val_loss: 966.5174\n",
      "Epoch 420/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4428 - val_loss: 966.5184\n",
      "Epoch 421/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4428 - val_loss: 966.5194\n",
      "Epoch 422/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 106.4429 - val_loss: 966.5202\n",
      "Epoch 423/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4429 - val_loss: 966.5210\n",
      "Epoch 424/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4430 - val_loss: 966.5219\n",
      "Epoch 425/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4431 - val_loss: 966.5228\n",
      "Epoch 426/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4431 - val_loss: 966.5233\n",
      "Epoch 427/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 106.4432 - val_loss: 966.5240\n",
      "Epoch 428/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4433 - val_loss: 966.5248\n",
      "Epoch 429/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4433 - val_loss: 966.5256\n",
      "Epoch 430/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4433 - val_loss: 966.5259\n",
      "Epoch 431/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4434 - val_loss: 966.5262\n",
      "Epoch 432/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4435 - val_loss: 966.5268\n",
      "Epoch 433/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 106.4435 - val_loss: 966.5273\n",
      "Epoch 434/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4437 - val_loss: 966.5279\n",
      "Epoch 435/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4437 - val_loss: 966.5281\n",
      "Epoch 436/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4437 - val_loss: 966.5286\n",
      "Epoch 437/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4437 - val_loss: 966.5288\n",
      "Epoch 438/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4439 - val_loss: 966.5289\n",
      "Epoch 439/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4440 - val_loss: 966.5292\n",
      "Epoch 440/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4441 - val_loss: 966.5299\n",
      "Epoch 441/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4441 - val_loss: 966.5303\n",
      "Epoch 442/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4442 - val_loss: 966.5305\n",
      "Epoch 443/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 106.4443 - val_loss: 966.5308\n",
      "Epoch 444/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4443 - val_loss: 966.5311\n",
      "Epoch 445/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4444 - val_loss: 966.5314\n",
      "Epoch 446/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4445 - val_loss: 966.5314\n",
      "Epoch 447/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4445 - val_loss: 966.5318\n",
      "Epoch 448/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4446 - val_loss: 966.5322\n",
      "Epoch 449/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4447 - val_loss: 966.5325\n",
      "Epoch 450/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4446 - val_loss: 966.5322\n",
      "Epoch 451/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4448 - val_loss: 966.5325\n",
      "Epoch 452/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4448 - val_loss: 966.5325\n",
      "Epoch 453/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4449 - val_loss: 966.5328\n",
      "Epoch 454/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4450 - val_loss: 966.5328\n",
      "Epoch 455/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4450 - val_loss: 966.5328\n",
      "Epoch 456/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4451 - val_loss: 966.5330\n",
      "Epoch 457/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4452 - val_loss: 966.5334\n",
      "Epoch 458/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4453 - val_loss: 966.5335\n",
      "Epoch 459/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4453 - val_loss: 966.5337\n",
      "Epoch 460/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4453 - val_loss: 966.5338\n",
      "Epoch 461/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4454 - val_loss: 966.5342\n",
      "Epoch 462/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 106.4454 - val_loss: 966.5339\n",
      "Epoch 463/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4455 - val_loss: 966.5342\n",
      "Epoch 464/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4455 - val_loss: 966.5337\n",
      "Epoch 465/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 106.4456 - val_loss: 966.5337\n",
      "Epoch 466/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 106.4457 - val_loss: 966.5335\n",
      "Epoch 467/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 106.4458 - val_loss: 966.5335\n",
      "Epoch 468/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 106.4459 - val_loss: 966.5337\n",
      "Epoch 469/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 106.4459 - val_loss: 966.5336\n",
      "Epoch 470/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 106.4460 - val_loss: 966.5338\n",
      "Epoch 471/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4460 - val_loss: 966.5342\n",
      "Epoch 472/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4461 - val_loss: 966.5345\n",
      "Epoch 473/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4460 - val_loss: 966.5344\n",
      "Epoch 474/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4461 - val_loss: 966.5344\n",
      "Epoch 475/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4462 - val_loss: 966.5346\n",
      "Epoch 476/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4461 - val_loss: 966.5344\n",
      "Epoch 477/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4462 - val_loss: 966.5342\n",
      "Epoch 478/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4464 - val_loss: 966.5342\n",
      "Epoch 479/500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 106.4464 - val_loss: 966.5342\n",
      "Epoch 480/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 106.4464 - val_loss: 966.5342\n",
      "Epoch 481/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 106.4465 - val_loss: 966.5339\n",
      "Epoch 482/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 106.4466 - val_loss: 966.5339\n",
      "Epoch 483/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4466 - val_loss: 966.5341\n",
      "Epoch 484/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4466 - val_loss: 966.5342\n",
      "Epoch 485/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 106.4467 - val_loss: 966.5341\n",
      "Epoch 486/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 106.4468 - val_loss: 966.5342\n",
      "Epoch 487/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.4468 - val_loss: 966.5342\n",
      "Epoch 488/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4468 - val_loss: 966.5344\n",
      "Epoch 489/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4468 - val_loss: 966.5344\n",
      "Epoch 490/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4469 - val_loss: 966.5344\n",
      "Epoch 491/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4469 - val_loss: 966.5346\n",
      "Epoch 492/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4470 - val_loss: 966.5346\n",
      "Epoch 493/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4470 - val_loss: 966.5346\n",
      "Epoch 494/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4470 - val_loss: 966.5346\n",
      "Epoch 495/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4471 - val_loss: 966.5346\n",
      "Epoch 496/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4471 - val_loss: 966.5345\n",
      "Epoch 497/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.4472 - val_loss: 966.5346\n",
      "Epoch 498/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 106.4472 - val_loss: 966.5349\n",
      "Epoch 499/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4472 - val_loss: 966.5345\n",
      "Epoch 500/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4472 - val_loss: 966.5345\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 410ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71.98403828, 71.98235761, 71.98067694, 71.97899627, 71.97731559,\n",
       "        71.97563492, 71.97395425,  0.34942961,  0.11630931,  0.6117962 ,\n",
       "         0.28030139,  0.        ,  0.        , 70.80609244, 70.64642857,\n",
       "        70.48676471, 70.32710084, 70.16743697, 70.00777311, 69.89453782,\n",
       "        69.87773109, 69.86092437, 69.84411765, 69.82731092, 69.8105042 ,\n",
       "        69.79369748, 69.77689076, 69.76008403, 69.74327731, 69.72647059,\n",
       "        69.70966387, 69.68571429, 69.65210084, 69.61848739, 69.58487395,\n",
       "        69.5512605 , 69.51764706, 69.48403361, 69.45042017, 69.41680672,\n",
       "         0.        ,  0.13426104,  0.        ,  0.14823352,  0.50972205,\n",
       "         0.53856009,  0.        , 69.7974323 , 69.7806256 , 69.7638189 ,\n",
       "        69.7470121 , 69.7302054 , 69.7133987 , 69.6931839 , 69.6595705 ,\n",
       "        69.625957  , 69.5923436 , 69.5587302 , 69.5251167 , 69.4915033 ,\n",
       "        69.4578898 , 69.4242764 , 73.6035948 , 73.2506536 , 72.8977124 ,\n",
       "        72.5447712 , 72.1918301 , 71.8388889 , 71.3737862 , 70.8947946 ,\n",
       "        70.415803  ,  0.80223095,  0.        , 62.5980949 ,  0.        ,\n",
       "         0.        ,  0.8044464 ,  0.        ,  0.38358027,  0.24783403,\n",
       "        57.98768234,  0.        ,  0.41181234,  0.        ,  0.34376931,\n",
       "         0.        ,  0.52995253,  0.23915488,  0.60191435,  0.5051949 ,\n",
       "         0.        ,  0.4855347 ,  0.        ,  0.66150808,  0.23557684,\n",
       "         0.33713156,  0.        ,  0.94196904,  0.69549203,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64.70739963, 64.69712885, 64.68685808, 64.6765873 , 64.66631653,\n",
       "       64.65604575, 64.64577498, 64.6355042 , 64.62523343, 64.61496265,\n",
       "       64.60469188, 64.5944211 , 64.58415033, 64.57387955, 64.56360878,\n",
       "       64.553338  , 64.54306723, 64.53279645, 64.52252568, 64.5122549 ,\n",
       "       64.50198413, 64.49171335, 64.48144258, 64.4711718 , 64.46090103,\n",
       "       64.45063025, 64.44035948, 64.4300887 , 64.41981793, 64.40954715,\n",
       "       64.39927638, 64.3890056 , 64.37873483, 64.36846405, 64.35819328,\n",
       "       64.3479225 , 64.33765173, 64.32738095, 64.31711018, 64.3068394 ,\n",
       "       64.29656863, 64.28629785, 64.27602708, 64.2657563 , 64.25548553,\n",
       "       64.24521475, 64.23494398, 64.2246732 , 64.21440243, 64.20413165,\n",
       "       64.19386088, 64.1835901 , 64.17331933, 64.16304855, 64.15277778,\n",
       "       64.142507  , 64.13223623, 64.12196545, 64.11169468, 64.1014239 ,\n",
       "       64.09115313, 64.08088235, 64.07061158, 64.0603408 , 64.05007003,\n",
       "       64.03979925, 64.02952848, 64.0192577 , 64.00898693, 63.99912465,\n",
       "       63.99212185, 63.98511905, 63.97811625, 63.97111345, 63.96411064,\n",
       "       63.95710784, 63.95010504, 63.94310224, 63.93609944, 63.92909664,\n",
       "       63.92209384, 63.91509104, 63.90808824, 63.90108543, 63.89408263,\n",
       "       63.88707983, 63.88007703, 63.87307423, 63.86607143, 63.85906863,\n",
       "       63.85206583, 63.84506303, 63.83806022, 63.83105742, 63.82405462,\n",
       "       63.81705182, 63.81004902, 63.80304622, 63.79604342, 63.78904062])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.62072180646135\n",
      "29.110097795808393\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
