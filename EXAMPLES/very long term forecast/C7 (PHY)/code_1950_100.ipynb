{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2045    66.063480\n",
       "2046    66.053676\n",
       "2047    66.043873\n",
       "2048    66.034069\n",
       "2049    66.024265\n",
       "Name: C7, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c7_interpolated_1950_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "1945     0.000000\n",
       "1946     0.000000\n",
       "1947     0.000000\n",
       "1948     0.000000\n",
       "1949     0.000000\n",
       "Name: C7, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1950)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.387115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.174230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.961345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.748459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     92.600000  0.000298\n",
       "1     92.387115  0.000298\n",
       "2     92.174230  0.000297\n",
       "3     91.961345  0.000297\n",
       "4     91.748459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 89.3180  # Value for C0\n",
    "K0 = -0.0010  # Value for K0\n",
    "K1 = 0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = -0.0204    # Value for b\n",
    "c = 2.2194    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    92.600000    92.387115    92.174230    91.961345    91.748459   \n",
      "351    92.387115    92.174230    91.961345    91.748459    91.535574   \n",
      "352    92.174230    91.961345    91.748459    91.535574    91.322689   \n",
      "353    91.961345    91.748459    91.535574    91.322689    91.109804   \n",
      "354    91.748459    91.535574    91.322689    91.109804    90.896919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    91.535574    91.322689    91.109804    90.896919    90.691597  ...   \n",
      "351    91.322689    91.109804    90.896919    90.691597    90.579552  ...   \n",
      "352    91.109804    90.896919    90.691597    90.579552    90.467507  ...   \n",
      "353    90.896919    90.691597    90.579552    90.467507    90.355462  ...   \n",
      "354    90.691597    90.579552    90.467507    90.355462    90.243417  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   80.261671    0.000263   80.252334    0.000263   80.242997    0.000263   \n",
      "351   80.252334    0.000263   80.242997    0.000263   80.233660    0.000262   \n",
      "352   80.242997    0.000263   80.233660    0.000262   80.224323    0.000262   \n",
      "353   80.233660    0.000262   80.224323    0.000262   80.214986    0.000262   \n",
      "354   80.224323    0.000262   80.214986    0.000262   80.205649    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   80.233660    0.000262   80.224323    0.000262  \n",
      "351   80.224323    0.000262   80.214986    0.000262  \n",
      "352   80.214986    0.000262   80.205649    0.000262  \n",
      "353   80.205649    0.000262   80.196312    0.000262  \n",
      "354   80.196312    0.000262   80.186975    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1, 251) (1500, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 3s 32ms/step - loss: 5609.0186 - val_loss: 3885.6775\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5401.2598 - val_loss: 3737.7812\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5317.1094 - val_loss: 3690.2183\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5251.8042 - val_loss: 3644.7070\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5187.2944 - val_loss: 3599.8191\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5112.6064 - val_loss: 3540.1399\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5036.5771 - val_loss: 3493.4509\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4970.8364 - val_loss: 3448.2651\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4906.3770 - val_loss: 3403.9675\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4842.9722 - val_loss: 3360.1970\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4780.4600 - val_loss: 3315.4553\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4705.0112 - val_loss: 3264.3494\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4638.2588 - val_loss: 3219.5007\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4573.7173 - val_loss: 3175.8643\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4510.5957 - val_loss: 3133.2107\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4448.6211 - val_loss: 3091.3914\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4387.6294 - val_loss: 3050.3174\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4327.5190 - val_loss: 3009.9326\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4268.2266 - val_loss: 2970.1982\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4209.7065 - val_loss: 2931.0850\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4151.9219 - val_loss: 2892.5718\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4094.8491 - val_loss: 2854.6399\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4038.4641 - val_loss: 2817.2747\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3982.7500 - val_loss: 2780.4634\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3927.6912 - val_loss: 2744.1948\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3873.2754 - val_loss: 2708.4595\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3819.4900 - val_loss: 2673.2478\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3766.3250 - val_loss: 2638.5522\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3713.7700 - val_loss: 2604.3657\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3661.8159 - val_loss: 2570.6807\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3610.4558 - val_loss: 2537.4907\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3559.6816 - val_loss: 2504.7896\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3509.4866 - val_loss: 2472.5718\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3459.8630 - val_loss: 2440.8318\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3410.8054 - val_loss: 2409.5635\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3362.3071 - val_loss: 2378.7617\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3314.3613 - val_loss: 2348.4226\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3266.9644 - val_loss: 2318.5405\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3220.1089 - val_loss: 2289.1108\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3173.7908 - val_loss: 2260.1287\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3128.0046 - val_loss: 2231.5896\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3082.7446 - val_loss: 2203.4893\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3038.0068 - val_loss: 2175.8237\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2993.7856 - val_loss: 2148.5884\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2950.0769 - val_loss: 2121.7791\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2906.8757 - val_loss: 2095.3921\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2864.1777 - val_loss: 2069.4229\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2821.9785 - val_loss: 2043.8677\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2780.2742 - val_loss: 2018.7227\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2739.0591 - val_loss: 1993.9838\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2698.3301 - val_loss: 1969.6477\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2658.0830 - val_loss: 1945.7100\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2618.3137 - val_loss: 1922.1680\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2579.0178 - val_loss: 1899.0165\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2540.1912 - val_loss: 1876.2529\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2501.8303 - val_loss: 1853.8735\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2463.9312 - val_loss: 1831.8744\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2426.4900 - val_loss: 1810.2527\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2389.5027 - val_loss: 1789.0038\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2352.9663 - val_loss: 1768.1254\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2316.8757 - val_loss: 1747.6135\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2281.2280 - val_loss: 1727.4646\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2246.0193 - val_loss: 1707.6754\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2211.2463 - val_loss: 1688.2426\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2176.9053 - val_loss: 1669.1627\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2142.9927 - val_loss: 1650.4326\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2109.5046 - val_loss: 1632.0493\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2076.4385 - val_loss: 1614.0089\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2043.7896 - val_loss: 1596.3082\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2011.5557 - val_loss: 1578.9442\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1979.7321 - val_loss: 1561.9142\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1948.3167 - val_loss: 1545.2140\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1917.3051 - val_loss: 1528.8408\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1886.6943 - val_loss: 1512.7917\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1856.4812 - val_loss: 1497.0634\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1826.6625 - val_loss: 1481.6528\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1797.2344 - val_loss: 1466.5569\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1768.1940 - val_loss: 1451.7723\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1739.5381 - val_loss: 1437.2965\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1711.2635 - val_loss: 1423.1257\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1683.3667 - val_loss: 1409.2574\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1655.8448 - val_loss: 1395.6886\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1628.6949 - val_loss: 1382.4159\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1601.9132 - val_loss: 1369.4363\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1575.4971 - val_loss: 1356.7473\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1549.4432 - val_loss: 1344.3456\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1523.7487 - val_loss: 1332.2284\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1498.4100 - val_loss: 1320.3920\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1473.4244 - val_loss: 1308.8344\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1448.7892 - val_loss: 1297.5525\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1424.5006 - val_loss: 1286.5432\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1400.5564 - val_loss: 1275.8033\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1376.9525 - val_loss: 1265.3306\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1353.6871 - val_loss: 1255.1218\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1330.7568 - val_loss: 1245.1740\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1308.1586 - val_loss: 1235.4843\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1285.8894 - val_loss: 1226.0502\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1263.9463 - val_loss: 1216.8682\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1242.3267 - val_loss: 1207.9358\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1221.0272 - val_loss: 1199.2504\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1200.0455 - val_loss: 1190.8091\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1179.3784 - val_loss: 1182.6088\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1159.0229 - val_loss: 1174.6469\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1138.9762 - val_loss: 1166.9207\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1119.2361 - val_loss: 1159.4269\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1099.7988 - val_loss: 1152.1631\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1080.6620 - val_loss: 1145.1271\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1061.8226 - val_loss: 1138.3149\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1043.2781 - val_loss: 1131.7247\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1025.0256 - val_loss: 1125.3534\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1007.0623 - val_loss: 1119.1981\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 989.3853 - val_loss: 1113.2563\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 971.9921 - val_loss: 1107.5253\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 954.8795 - val_loss: 1102.0017\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 938.0454 - val_loss: 1096.6837\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 921.4867 - val_loss: 1091.5684\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 905.2003 - val_loss: 1086.6525\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 889.1841 - val_loss: 1081.9336\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 873.4352 - val_loss: 1077.4093\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 857.9508 - val_loss: 1073.0765\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 842.7283 - val_loss: 1068.9329\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 827.7652 - val_loss: 1064.9753\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 813.0583 - val_loss: 1061.2014\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 798.6050 - val_loss: 1057.6084\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 784.4033 - val_loss: 1054.1936\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 770.4496 - val_loss: 1050.9546\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 756.7424 - val_loss: 1047.8883\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 743.2780 - val_loss: 1044.9924\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 730.0543 - val_loss: 1042.2640\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 717.0684 - val_loss: 1039.7007\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 704.3180 - val_loss: 1037.2997\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 691.8002 - val_loss: 1035.0583\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 679.5125 - val_loss: 1032.9741\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 667.4522 - val_loss: 1031.0442\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 655.6171 - val_loss: 1029.2662\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 644.0042 - val_loss: 1027.6375\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 632.6110 - val_loss: 1026.1552\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 621.4349 - val_loss: 1024.8171\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 610.4736 - val_loss: 1023.6204\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 599.7246 - val_loss: 1022.5625\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 589.1851 - val_loss: 1021.6411\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 578.8523 - val_loss: 1020.8529\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 568.7242 - val_loss: 1020.1960\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 558.7978 - val_loss: 1019.6679\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 549.0710 - val_loss: 1019.2654\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 539.5408 - val_loss: 1018.9867\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 530.2053 - val_loss: 1018.8287\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 521.0616 - val_loss: 1018.7892\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 512.1073 - val_loss: 1018.8655\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 503.3399 - val_loss: 1019.0552\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 494.7570 - val_loss: 1019.3555\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 486.3563 - val_loss: 1019.7644\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 478.1348 - val_loss: 1020.2789\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 470.0905 - val_loss: 1020.8969\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 462.2209 - val_loss: 1021.6158\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 454.5235 - val_loss: 1022.4331\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 446.9959 - val_loss: 1023.3463\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 439.6357 - val_loss: 1024.3530\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 432.4403 - val_loss: 1025.4509\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 425.4076 - val_loss: 1026.6375\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 418.5352 - val_loss: 1027.9102\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 411.8205 - val_loss: 1029.2667\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 405.2614 - val_loss: 1030.7047\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 398.8553 - val_loss: 1032.2217\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 392.5999 - val_loss: 1033.8157\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 386.4932 - val_loss: 1035.4838\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 380.5324 - val_loss: 1037.2238\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 374.7154 - val_loss: 1039.0337\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 369.0398 - val_loss: 1040.9109\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 363.5035 - val_loss: 1042.8534\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 358.1040 - val_loss: 1044.8583\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 352.8390 - val_loss: 1046.9242\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 347.7064 - val_loss: 1049.0480\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 342.7039 - val_loss: 1051.2279\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 337.8294 - val_loss: 1053.4619\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 333.0804 - val_loss: 1055.7473\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 328.4550 - val_loss: 1058.0823\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 323.9507 - val_loss: 1060.4644\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 319.5655 - val_loss: 1062.8917\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 315.2975 - val_loss: 1065.3621\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 311.1438 - val_loss: 1067.8737\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 307.1028 - val_loss: 1070.4237\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 303.1723 - val_loss: 1073.0106\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 299.3503 - val_loss: 1075.6324\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 295.6345 - val_loss: 1078.2867\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 292.0228 - val_loss: 1080.9718\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 288.5135 - val_loss: 1083.6854\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 285.1042 - val_loss: 1086.4258\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 281.7930 - val_loss: 1089.1913\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 278.5778 - val_loss: 1091.9795\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 275.4567 - val_loss: 1094.7887\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 272.4278 - val_loss: 1097.6168\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 269.4889 - val_loss: 1100.4629\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 266.6383 - val_loss: 1103.3241\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 263.8740 - val_loss: 1106.1993\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 261.1941 - val_loss: 1109.0865\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 258.5967 - val_loss: 1111.9838\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 256.0800 - val_loss: 1114.8898\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 253.6420 - val_loss: 1117.8029\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 251.2811 - val_loss: 1120.7208\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 248.9953 - val_loss: 1123.6431\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 246.7828 - val_loss: 1126.5671\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 244.6420 - val_loss: 1129.4916\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 242.5711 - val_loss: 1132.4158\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 240.5684 - val_loss: 1135.3368\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 238.6323 - val_loss: 1138.2542\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 236.7608 - val_loss: 1141.1665\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 234.9527 - val_loss: 1144.0717\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 233.2060 - val_loss: 1146.9694\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 231.5194 - val_loss: 1149.8575\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 229.8911 - val_loss: 1152.7345\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 228.3197 - val_loss: 1155.5997\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 226.8036 - val_loss: 1158.4519\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 225.3412 - val_loss: 1161.2894\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 223.9311 - val_loss: 1164.1116\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 222.5718 - val_loss: 1166.9169\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 221.2620 - val_loss: 1169.7023\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 220.0000 - val_loss: 1172.3447\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 218.8461 - val_loss: 1175.8669\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 217.0353 - val_loss: 1179.0516\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 215.5433 - val_loss: 1182.0919\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 214.2112 - val_loss: 1185.0371\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 212.9891 - val_loss: 1187.9087\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 211.8533 - val_loss: 1190.7185\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 210.7902 - val_loss: 1193.4723\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 209.7905 - val_loss: 1196.1746\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 208.8478 - val_loss: 1198.8287\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 207.9570 - val_loss: 1201.4363\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 207.1139 - val_loss: 1203.9989\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 206.3152 - val_loss: 1206.5175\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 205.5580 - val_loss: 1208.9926\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 204.8397 - val_loss: 1211.4248\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 204.1579 - val_loss: 1213.8148\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 203.5106 - val_loss: 1216.1630\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 202.8959 - val_loss: 1218.4694\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 202.3121 - val_loss: 1220.7344\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 201.7576 - val_loss: 1222.9587\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 201.2306 - val_loss: 1225.1417\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 200.7302 - val_loss: 1227.2848\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 200.2546 - val_loss: 1229.3871\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 199.8029 - val_loss: 1231.4492\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 199.3737 - val_loss: 1233.4711\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 198.9661 - val_loss: 1235.4534\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 198.5789 - val_loss: 1237.3962\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 198.2112 - val_loss: 1239.3004\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 197.8619 - val_loss: 1241.1654\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 197.5303 - val_loss: 1242.9915\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 197.2154 - val_loss: 1244.7788\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 196.9166 - val_loss: 1246.5280\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 196.6329 - val_loss: 1248.2394\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 196.3636 - val_loss: 1249.9133\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 196.1082 - val_loss: 1251.5497\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 195.8657 - val_loss: 1253.1495\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 195.6358 - val_loss: 1254.7126\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 195.4177 - val_loss: 1256.2399\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 195.2108 - val_loss: 1257.7312\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 195.0146 - val_loss: 1259.1871\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.8286 - val_loss: 1260.6075\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.6522 - val_loss: 1261.9943\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.4851 - val_loss: 1263.3464\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.3267 - val_loss: 1264.6648\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.1765 - val_loss: 1265.9507\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.0342 - val_loss: 1267.2029\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.8994 - val_loss: 1268.4233\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.7718 - val_loss: 1269.6118\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.6507 - val_loss: 1270.7688\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5363 - val_loss: 1271.8954\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4277 - val_loss: 1272.9915\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.3249 - val_loss: 1274.0573\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.2276 - val_loss: 1275.0940\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 193.1355 - val_loss: 1276.1019\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.0482 - val_loss: 1277.0818\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 192.9656 - val_loss: 1278.0331\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 192.8874 - val_loss: 1278.9578\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.8135 - val_loss: 1279.8552\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.7434 - val_loss: 1280.7272\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.6770 - val_loss: 1281.5728\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.6143 - val_loss: 1282.3937\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 192.5548 - val_loss: 1283.1890\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.4987 - val_loss: 1283.9608\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.4454 - val_loss: 1284.7084\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.3951 - val_loss: 1285.4336\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.3473 - val_loss: 1286.1360\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.3022 - val_loss: 1286.8158\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.2595 - val_loss: 1287.4742\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.2191 - val_loss: 1288.1115\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.1808 - val_loss: 1288.7291\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 192.1445 - val_loss: 1289.3256\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.1103 - val_loss: 1289.9030\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.0777 - val_loss: 1290.4607\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.0471 - val_loss: 1291.0005\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 192.0179 - val_loss: 1291.5221\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.9904 - val_loss: 1292.0258\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.9642 - val_loss: 1292.5126\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.9396 - val_loss: 1292.9823\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.9162 - val_loss: 1293.4357\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.8940 - val_loss: 1293.8735\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 191.8730 - val_loss: 1294.2958\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.8531 - val_loss: 1294.7031\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.8343 - val_loss: 1295.0962\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.8165 - val_loss: 1295.4750\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.7995 - val_loss: 1295.8402\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.7835 - val_loss: 1296.1924\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.7683 - val_loss: 1296.5311\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.7539 - val_loss: 1296.8575\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.7403 - val_loss: 1297.1724\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.7274 - val_loss: 1297.4744\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.7151 - val_loss: 1297.7659\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.7035 - val_loss: 1298.0458\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.6925 - val_loss: 1298.3149\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.6821 - val_loss: 1298.5743\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.6722 - val_loss: 1298.8235\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.6628 - val_loss: 1299.0631\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.6540 - val_loss: 1299.2938\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.6454 - val_loss: 1299.5150\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.6375 - val_loss: 1299.7274\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.6299 - val_loss: 1299.9313\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.6227 - val_loss: 1300.1271\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 191.6158 - val_loss: 1300.3152\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.6094 - val_loss: 1300.4954\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.6033 - val_loss: 1300.6683\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5975 - val_loss: 1300.8346\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 191.5919 - val_loss: 1300.9933\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5868 - val_loss: 1301.1466\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5818 - val_loss: 1301.2928\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5771 - val_loss: 1301.4331\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5727 - val_loss: 1301.5674\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5685 - val_loss: 1301.6964\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5644 - val_loss: 1301.8199\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5607 - val_loss: 1301.9379\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5570 - val_loss: 1302.0507\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5537 - val_loss: 1302.1594\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5504 - val_loss: 1302.2629\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5473 - val_loss: 1302.3624\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5444 - val_loss: 1302.4575\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5417 - val_loss: 1302.5483\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5392 - val_loss: 1302.6357\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.5366 - val_loss: 1302.7175\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5343 - val_loss: 1302.7974\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5322 - val_loss: 1302.8732\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5300 - val_loss: 1302.9457\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5281 - val_loss: 1303.0149\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5262 - val_loss: 1303.0807\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5244 - val_loss: 1303.1436\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5228 - val_loss: 1303.2041\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5213 - val_loss: 1303.2612\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5198 - val_loss: 1303.3164\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 191.5184 - val_loss: 1303.3684\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5171 - val_loss: 1303.4193\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5158 - val_loss: 1303.4668\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5146 - val_loss: 1303.5123\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5135 - val_loss: 1303.5557\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5125 - val_loss: 1303.5973\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5116 - val_loss: 1303.6361\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.5106 - val_loss: 1303.6746\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5097 - val_loss: 1303.7102\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5090 - val_loss: 1303.7444\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5082 - val_loss: 1303.7778\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5074 - val_loss: 1303.8081\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5068 - val_loss: 1303.8385\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5061 - val_loss: 1303.8667\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5056 - val_loss: 1303.8934\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5051 - val_loss: 1303.9194\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5045 - val_loss: 1303.9442\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5040 - val_loss: 1303.9675\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5036 - val_loss: 1303.9894\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5031 - val_loss: 1304.0103\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5028 - val_loss: 1304.0303\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5024 - val_loss: 1304.0494\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5021 - val_loss: 1304.0679\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 191.5017 - val_loss: 1304.0852\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5015 - val_loss: 1304.1016\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5012 - val_loss: 1304.1167\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5010 - val_loss: 1304.1318\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5008 - val_loss: 1304.1460\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5007 - val_loss: 1304.1594\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5004 - val_loss: 1304.1724\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5003 - val_loss: 1304.1844\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5001 - val_loss: 1304.1963\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5000 - val_loss: 1304.2072\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4999 - val_loss: 1304.2175\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.4998 - val_loss: 1304.2277\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4997 - val_loss: 1304.2374\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4996 - val_loss: 1304.2467\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4995 - val_loss: 1304.2554\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.4994 - val_loss: 1304.2632\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4994 - val_loss: 1304.2710\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4993 - val_loss: 1304.2783\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4993 - val_loss: 1304.2845\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4993 - val_loss: 1304.2913\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4993 - val_loss: 1304.2975\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.4993 - val_loss: 1304.3040\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.4993 - val_loss: 1304.3098\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 191.4993 - val_loss: 1304.3149\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.4993 - val_loss: 1304.3203\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.4993 - val_loss: 1304.3248\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4993 - val_loss: 1304.3296\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4994 - val_loss: 1304.3341\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4994 - val_loss: 1304.3381\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.4995 - val_loss: 1304.3419\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.4995 - val_loss: 1304.3458\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4995 - val_loss: 1304.3489\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4996 - val_loss: 1304.3528\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4996 - val_loss: 1304.3560\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4996 - val_loss: 1304.3583\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4998 - val_loss: 1304.3615\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4998 - val_loss: 1304.3643\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.4999 - val_loss: 1304.3668\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5000 - val_loss: 1304.3699\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.4999 - val_loss: 1304.3721\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5000 - val_loss: 1304.3743\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5001 - val_loss: 1304.3766\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5002 - val_loss: 1304.3789\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5002 - val_loss: 1304.3802\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 191.5003 - val_loss: 1304.3823\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5004 - val_loss: 1304.3835\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5004 - val_loss: 1304.3854\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5005 - val_loss: 1304.3871\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5005 - val_loss: 1304.3879\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5007 - val_loss: 1304.3898\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5007 - val_loss: 1304.3910\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.5008 - val_loss: 1304.3925\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5009 - val_loss: 1304.3932\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5010 - val_loss: 1304.3948\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5011 - val_loss: 1304.3954\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5012 - val_loss: 1304.3964\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5012 - val_loss: 1304.3973\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5013 - val_loss: 1304.3986\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5014 - val_loss: 1304.3993\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5014 - val_loss: 1304.4001\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5015 - val_loss: 1304.4011\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5016 - val_loss: 1304.4019\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5016 - val_loss: 1304.4025\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5017 - val_loss: 1304.4033\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5017 - val_loss: 1304.4037\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5019 - val_loss: 1304.4048\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 191.5019 - val_loss: 1304.4056\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5020 - val_loss: 1304.4060\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5020 - val_loss: 1304.4066\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5021 - val_loss: 1304.4075\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5021 - val_loss: 1304.4075\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5022 - val_loss: 1304.4080\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5023 - val_loss: 1304.4081\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5023 - val_loss: 1304.4087\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5025 - val_loss: 1304.4095\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5025 - val_loss: 1304.4097\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5025 - val_loss: 1304.4097\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5026 - val_loss: 1304.4100\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5027 - val_loss: 1304.4100\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.5028 - val_loss: 1304.4104\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5028 - val_loss: 1304.4109\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5029 - val_loss: 1304.4110\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5029 - val_loss: 1304.4119\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5029 - val_loss: 1304.4119\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5031 - val_loss: 1304.4122\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5031 - val_loss: 1304.4125\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 191.5032 - val_loss: 1304.4131\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5032 - val_loss: 1304.4136\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5033 - val_loss: 1304.4141\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5033 - val_loss: 1304.4141\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5033 - val_loss: 1304.4137\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5034 - val_loss: 1304.4141\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5035 - val_loss: 1304.4143\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5034 - val_loss: 1304.4143\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.5035 - val_loss: 1304.4144\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5036 - val_loss: 1304.4146\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5037 - val_loss: 1304.4152\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5037 - val_loss: 1304.4154\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5037 - val_loss: 1304.4159\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5038 - val_loss: 1304.4158\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5038 - val_loss: 1304.4159\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5038 - val_loss: 1304.4158\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5039 - val_loss: 1304.4160\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5040 - val_loss: 1304.4163\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5040 - val_loss: 1304.4165\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5040 - val_loss: 1304.4160\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 191.5041 - val_loss: 1304.4163\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5041 - val_loss: 1304.4163\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5042 - val_loss: 1304.4163\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5042 - val_loss: 1304.4163\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5042 - val_loss: 1304.4165\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.5043 - val_loss: 1304.4165\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5043 - val_loss: 1304.4163\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5044 - val_loss: 1304.4163\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5044 - val_loss: 1304.4165\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5045 - val_loss: 1304.4166\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5045 - val_loss: 1304.4171\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5045 - val_loss: 1304.4171\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5045 - val_loss: 1304.4169\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5045 - val_loss: 1304.4166\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5045 - val_loss: 1304.4163\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5046 - val_loss: 1304.4163\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5047 - val_loss: 1304.4165\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5047 - val_loss: 1304.4165\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5047 - val_loss: 1304.4169\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5048 - val_loss: 1304.4169\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 191.5048 - val_loss: 1304.4174\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 191.5048 - val_loss: 1304.4175\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.5048 - val_loss: 1304.4177\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.5048 - val_loss: 1304.4169\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(89.3180, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0010, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(-0.0204, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.2194, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 378ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.18996008e+01, 7.18668277e+01, 7.18340546e+01, 7.18012815e+01,\n",
       "        7.17685084e+01, 7.17357353e+01, 7.17029622e+01, 6.18121803e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.28102078e+01, 7.26833170e+01, 7.25564262e+01,\n",
       "        7.24295355e+01, 7.23026447e+01, 7.21757540e+01, 7.20488632e+01,\n",
       "        7.19724300e+01, 7.19396569e+01, 7.19068838e+01, 7.18741106e+01,\n",
       "        7.18413375e+01, 7.18085644e+01, 7.17757913e+01, 7.17430182e+01,\n",
       "        7.17102451e+01, 7.70429739e+01, 7.68425770e+01, 7.65400560e+01,\n",
       "        7.62375350e+01, 7.59350140e+01, 7.55762372e+01, 7.50216153e+01,\n",
       "        7.44669935e+01, 7.39123716e+01, 4.47440207e-01, 0.00000000e+00,\n",
       "        4.89240825e-01, 0.00000000e+00, 6.01749420e-01, 0.00000000e+00,\n",
       "        3.56811106e-01, 0.00000000e+00, 0.00000000e+00, 7.18158473e+01,\n",
       "        7.17830742e+01, 7.17503011e+01, 7.17175280e+01, 7.70821895e+01,\n",
       "        7.69057189e+01, 7.66072829e+01, 7.63047619e+01, 7.60022409e+01,\n",
       "        7.56994865e+01, 7.51448646e+01, 7.45902428e+01, 7.40356209e+01,\n",
       "        0.00000000e+00, 5.77498790e-01, 7.61254902e+01, 7.58229692e+01,\n",
       "        7.53708217e+01, 7.48161998e+01, 7.42615780e+01, 7.37069561e+01,\n",
       "        7.32613749e+01, 7.28807026e+01, 7.25000304e+01, 9.90242900e-01,\n",
       "        3.66189450e-01, 5.92555542e+01, 0.00000000e+00, 5.09858130e-01,\n",
       "        0.00000000e+00, 4.64400230e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.92313538e+01, 0.00000000e+00, 5.48255205e-01, 0.00000000e+00,\n",
       "        6.83598578e-01, 4.86887634e-01, 4.30270046e-01, 4.31544363e-01,\n",
       "        3.96724343e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.66708744e-02, 5.85887060e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66.99485294, 66.98504902, 66.9752451 , 66.96544118, 66.95563725,\n",
       "       66.94583333, 66.93602941, 66.92622549, 66.91642157, 66.90661765,\n",
       "       66.89681373, 66.8870098 , 66.87720588, 66.86740196, 66.85759804,\n",
       "       66.84779412, 66.8379902 , 66.82818627, 66.81838235, 66.80857843,\n",
       "       66.79877451, 66.78897059, 66.77916667, 66.76936275, 66.75955882,\n",
       "       66.7497549 , 66.73995098, 66.73014706, 66.72034314, 66.71053922,\n",
       "       66.70073529, 66.69093137, 66.68112745, 66.67132353, 66.66151961,\n",
       "       66.65171569, 66.64191176, 66.63210784, 66.62230392, 66.6125    ,\n",
       "       66.60269608, 66.59289216, 66.58308824, 66.57328431, 66.56348039,\n",
       "       66.55367647, 66.54387255, 66.53406863, 66.52426471, 66.51446078,\n",
       "       66.50465686, 66.49485294, 66.48504902, 66.4752451 , 66.46544118,\n",
       "       66.45563725, 66.44583333, 66.43602941, 66.42622549, 66.41642157,\n",
       "       66.40661765, 66.39681373, 66.3870098 , 66.37720588, 66.36740196,\n",
       "       66.35759804, 66.34779412, 66.3379902 , 66.32818627, 66.31838235,\n",
       "       66.30857843, 66.29877451, 66.28897059, 66.27916667, 66.26936275,\n",
       "       66.25955882, 66.2497549 , 66.23995098, 66.23014706, 66.22034314,\n",
       "       66.21053922, 66.20073529, 66.19093137, 66.18112745, 66.17132353,\n",
       "       66.16151961, 66.15171569, 66.14191176, 66.13210784, 66.12230392,\n",
       "       66.1125    , 66.10269608, 66.09289216, 66.08308824, 66.07328431,\n",
       "       66.06348039, 66.05367647, 66.04387255, 66.03406863, 66.02426471])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.21838151573163\n",
      "32.98324335368726\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
