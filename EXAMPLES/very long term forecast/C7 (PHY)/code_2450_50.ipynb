{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2495    62.430607\n",
       "2496    62.422956\n",
       "2497    62.415304\n",
       "2498    62.407652\n",
       "2499    62.400000\n",
       "Name: C7, Length: 2500, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c7_interpolated_2450_50.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2445     0.000000\n",
       "2446     0.002341\n",
       "2447     0.567139\n",
       "2448     0.033081\n",
       "2449     0.157533\n",
       "Name: C7, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(50)\n",
    "test\n",
    "training_set = training_set.head(2450)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.387115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.174230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.961345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.748459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     92.600000  0.000298\n",
       "1     92.387115  0.000298\n",
       "2     92.174230  0.000297\n",
       "3     91.961345  0.000297\n",
       "4     91.748459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 89.3180  # Value for C0\n",
    "K0 = -0.0010  # Value for K0\n",
    "K1 = 0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = -0.0204    # Value for b\n",
    "c = 2.2194    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-175)  var1(t-174)  var1(t-173)  var1(t-172)  var1(t-171)  \\\n",
      "175    92.600000    92.387115    92.174230    91.961345    91.748459   \n",
      "176    92.387115    92.174230    91.961345    91.748459    91.535574   \n",
      "177    92.174230    91.961345    91.748459    91.535574    91.322689   \n",
      "178    91.961345    91.748459    91.535574    91.322689    91.109804   \n",
      "179    91.748459    91.535574    91.322689    91.109804    90.896919   \n",
      "\n",
      "     var1(t-170)  var1(t-169)  var1(t-168)  var1(t-167)  var1(t-166)  ...  \\\n",
      "175    91.535574    91.322689    91.109804    90.896919    90.691597  ...   \n",
      "176    91.322689    91.109804    90.896919    90.691597    90.579552  ...   \n",
      "177    91.109804    90.896919    90.691597    90.579552    90.467507  ...   \n",
      "178    90.896919    90.691597    90.579552    90.467507    90.355462  ...   \n",
      "179    90.691597    90.579552    90.467507    90.355462    90.243417  ...   \n",
      "\n",
      "     var1(t+45)  var2(t+45)  var1(t+46)  var2(t+46)  var1(t+47)  var2(t+47)  \\\n",
      "175   84.280019    0.000280   84.265079    0.000280   84.250140    0.000280   \n",
      "176   84.265079    0.000280   84.250140    0.000280   84.235201    0.000280   \n",
      "177   84.250140    0.000280   84.235201    0.000280   84.220261    0.000279   \n",
      "178   84.235201    0.000280   84.220261    0.000279   84.205322    0.000279   \n",
      "179   84.220261    0.000279   84.205322    0.000279   84.190383    0.000279   \n",
      "\n",
      "     var1(t+48)  var2(t+48)  var1(t+49)  var2(t+49)  \n",
      "175   84.235201    0.000280   84.220261    0.000279  \n",
      "176   84.220261    0.000279   84.205322    0.000279  \n",
      "177   84.205322    0.000279   84.190383    0.000279  \n",
      "178   84.190383    0.000279   84.175444    0.000279  \n",
      "179   84.175444    0.000279   84.160504    0.000279  \n",
      "\n",
      "[5 rows x 276 columns]\n",
      "Index(['var1(t-175)', 'var1(t-174)', 'var1(t-173)', 'var1(t-172)',\n",
      "       'var1(t-171)', 'var1(t-170)', 'var1(t-169)', 'var1(t-168)',\n",
      "       'var1(t-167)', 'var1(t-166)',\n",
      "       ...\n",
      "       'var1(t+45)', 'var2(t+45)', 'var1(t+46)', 'var2(t+46)', 'var1(t+47)',\n",
      "       'var2(t+47)', 'var1(t+48)', 'var2(t+48)', 'var1(t+49)', 'var2(t+49)'],\n",
      "      dtype='object', length=276)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 175, n_out = 50)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 176):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-150:]\n",
    "trainX = train[:,:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-150:]\n",
    "forecastX = forecast[:,:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 1, 126) (2225, 150) (1, 1, 126)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28/28 [==============================] - 2s 19ms/step - loss: 5231.7861 - val_loss: 2378.8372\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4867.2227 - val_loss: 2229.2788\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4654.9746 - val_loss: 2124.2490\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4446.4043 - val_loss: 2039.4497\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4267.0400 - val_loss: 1964.2643\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4105.3574 - val_loss: 1897.0233\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3950.1812 - val_loss: 1832.8470\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3804.4172 - val_loss: 1771.2980\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3650.7786 - val_loss: 1715.3424\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3511.3552 - val_loss: 1659.3834\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3380.2224 - val_loss: 1613.4260\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3253.6660 - val_loss: 1566.8235\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3133.0762 - val_loss: 1522.1868\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3015.6213 - val_loss: 1480.1826\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2901.5032 - val_loss: 1438.8257\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2785.1377 - val_loss: 1403.1869\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2674.3154 - val_loss: 1359.8467\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2569.5964 - val_loss: 1325.5105\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2463.6721 - val_loss: 1294.5935\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2358.5427 - val_loss: 1267.0646\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2261.7830 - val_loss: 1239.7207\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2167.9741 - val_loss: 1209.2588\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2078.6406 - val_loss: 1180.9957\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1993.7207 - val_loss: 1159.7249\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1912.2367 - val_loss: 1141.4078\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1834.4120 - val_loss: 1120.1428\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1761.6045 - val_loss: 1110.9668\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1687.6202 - val_loss: 1091.5581\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1618.5762 - val_loss: 1071.0203\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1551.9065 - val_loss: 1062.0219\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1486.8707 - val_loss: 1036.5404\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1426.3602 - val_loss: 1027.9274\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1365.2797 - val_loss: 1013.4658\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1312.6122 - val_loss: 1021.4382\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1259.0619 - val_loss: 1010.5499\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1208.1918 - val_loss: 1005.5734\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1173.1974 - val_loss: 1036.0483\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1117.7174 - val_loss: 1035.1157\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1073.7695 - val_loss: 1031.6041\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1033.8586 - val_loss: 1049.0583\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 995.4894 - val_loss: 1054.0819\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1020.3802 - val_loss: 1051.7025\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 925.0837 - val_loss: 1084.4780\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 885.8750 - val_loss: 1073.6289\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 858.0154 - val_loss: 1106.2974\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 823.4035 - val_loss: 1104.5439\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 793.5948 - val_loss: 1093.3854\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 804.2977 - val_loss: 1087.6388\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 772.9171 - val_loss: 1112.6125\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 738.8726 - val_loss: 1108.4178\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 676.6631 - val_loss: 1111.0865\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 654.1753 - val_loss: 1099.7738\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 670.0681 - val_loss: 1145.5084\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 616.7736 - val_loss: 1153.9412\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 629.0024 - val_loss: 1160.7545\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 572.9267 - val_loss: 1159.8741\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 552.3235 - val_loss: 1153.8604\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 542.6970 - val_loss: 1189.7677\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 580.4996 - val_loss: 1221.9915\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 518.9604 - val_loss: 1237.4648\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 513.3619 - val_loss: 1225.6085\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 533.1772 - val_loss: 1239.5729\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 472.7680 - val_loss: 1244.2773\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 457.2661 - val_loss: 1203.3762\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 493.2327 - val_loss: 1208.9952\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 479.5949 - val_loss: 1209.3431\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 483.9467 - val_loss: 1288.4783\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 466.4144 - val_loss: 1288.1412\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 461.3057 - val_loss: 1310.1512\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 444.6488 - val_loss: 1323.6702\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 432.8081 - val_loss: 1333.7303\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 423.1149 - val_loss: 1342.9675\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 414.4269 - val_loss: 1352.7202\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 403.8529 - val_loss: 1348.0814\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 405.5302 - val_loss: 1373.1755\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 390.6052 - val_loss: 1377.9194\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 381.4151 - val_loss: 1377.6493\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 373.9380 - val_loss: 1383.6256\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 367.7502 - val_loss: 1393.7349\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 362.2399 - val_loss: 1400.2893\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 356.5526 - val_loss: 1409.5662\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 352.9507 - val_loss: 1413.9386\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 348.7908 - val_loss: 1425.4225\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 345.4978 - val_loss: 1434.5449\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 342.4606 - val_loss: 1441.1039\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 339.1479 - val_loss: 1427.9075\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 338.1342 - val_loss: 1470.1178\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 334.3317 - val_loss: 1474.2517\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 331.8191 - val_loss: 1481.3831\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 329.8009 - val_loss: 1494.6761\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 327.8400 - val_loss: 1493.0681\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 326.0377 - val_loss: 1498.0632\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 326.7502 - val_loss: 1508.2642\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 332.6252 - val_loss: 1543.9458\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 330.2197 - val_loss: 1540.2412\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 325.3066 - val_loss: 1524.8491\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 350.2967 - val_loss: 1575.2260\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 350.2308 - val_loss: 1631.8040\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 329.4674 - val_loss: 1573.0145\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 342.6073 - val_loss: 1576.6213\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 340.8960 - val_loss: 1583.9701\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 339.6083 - val_loss: 1588.9442\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 338.1014 - val_loss: 1594.4803\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 336.7513 - val_loss: 1597.4761\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 335.5431 - val_loss: 1602.3929\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 334.3878 - val_loss: 1605.6167\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 333.1661 - val_loss: 1609.0677\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 330.5742 - val_loss: 1573.3572\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 332.7617 - val_loss: 1546.8267\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 323.5721 - val_loss: 1511.3621\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 337.0086 - val_loss: 1513.2650\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 334.7325 - val_loss: 1520.8134\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 332.6667 - val_loss: 1531.9933\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 330.4401 - val_loss: 1540.2871\n",
      "Epoch 115/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 328.2953 - val_loss: 1549.9802\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 326.5147 - val_loss: 1552.7717\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 325.0991 - val_loss: 1560.4620\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 327.3629 - val_loss: 1590.7305\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 313.6519 - val_loss: 1579.6812\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 312.2082 - val_loss: 1576.3555\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 309.3919 - val_loss: 1565.3237\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 320.3643 - val_loss: 1559.2404\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 319.4569 - val_loss: 1564.6154\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 318.2313 - val_loss: 1565.3989\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 308.1694 - val_loss: 1506.3582\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 319.0339 - val_loss: 1502.3761\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 308.7894 - val_loss: 1483.2355\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 326.6412 - val_loss: 1504.9617\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 320.6271 - val_loss: 1518.5052\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 311.8767 - val_loss: 1533.9702\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 305.2485 - val_loss: 1513.3362\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 316.4310 - val_loss: 1519.1233\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 313.2437 - val_loss: 1520.7490\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 310.4608 - val_loss: 1508.7797\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 326.8796 - val_loss: 1608.9075\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 315.8866 - val_loss: 1608.5715\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 312.1877 - val_loss: 1586.1477\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 309.0766 - val_loss: 1581.3806\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 308.6562 - val_loss: 1577.2913\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 307.1138 - val_loss: 1574.1807\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 321.2863 - val_loss: 1602.0880\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 360.5758 - val_loss: 1553.2146\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 362.0732 - val_loss: 1601.5691\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 356.2892 - val_loss: 1498.7373\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 373.0844 - val_loss: 1550.9282\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 363.2042 - val_loss: 1564.0590\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 377.4723 - val_loss: 1588.9614\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 354.4379 - val_loss: 1666.0298\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 343.2501 - val_loss: 1634.5870\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 357.9888 - val_loss: 1709.9070\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 356.1884 - val_loss: 1695.4570\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 368.1458 - val_loss: 1759.4412\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 356.8700 - val_loss: 1724.7284\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 347.4706 - val_loss: 1692.9537\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 345.1528 - val_loss: 1683.2312\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 341.1327 - val_loss: 1664.3259\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 333.8347 - val_loss: 1648.5146\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 332.3147 - val_loss: 1651.9208\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 320.3805 - val_loss: 1648.6780\n",
      "Epoch 160/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 329.7718 - val_loss: 1686.6021\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 323.5235 - val_loss: 1673.3738\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 319.3035 - val_loss: 1663.4301\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 318.5150 - val_loss: 1657.6044\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 317.1485 - val_loss: 1650.2279\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 358.9579 - val_loss: 1659.6643\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 357.1784 - val_loss: 1668.4751\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 355.6654 - val_loss: 1676.8921\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 353.7056 - val_loss: 1684.3564\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 352.5796 - val_loss: 1686.2352\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 351.9803 - val_loss: 1674.1456\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 347.0653 - val_loss: 1665.9164\n",
      "Epoch 172/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 340.4895 - val_loss: 1652.6288\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 337.5243 - val_loss: 1656.2026\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 336.3263 - val_loss: 1662.1652\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 335.4053 - val_loss: 1663.7330\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 334.2646 - val_loss: 1667.1222\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 333.2027 - val_loss: 1672.0000\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 332.3261 - val_loss: 1674.0466\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 331.4715 - val_loss: 1674.8909\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 330.6013 - val_loss: 1675.1093\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 329.7060 - val_loss: 1677.9677\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 328.9614 - val_loss: 1675.8221\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 328.3598 - val_loss: 1676.1716\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 327.4594 - val_loss: 1674.9270\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 349.6363 - val_loss: 1767.9784\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 348.4188 - val_loss: 1759.5521\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 368.5344 - val_loss: 1754.3593\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 367.2087 - val_loss: 1759.2312\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 367.7685 - val_loss: 1779.1899\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 352.7332 - val_loss: 1770.1418\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 356.6961 - val_loss: 1794.6575\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 356.6907 - val_loss: 1798.6979\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 356.0287 - val_loss: 1798.2797\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 355.3021 - val_loss: 1790.8199\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 355.0876 - val_loss: 1802.5566\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 354.1353 - val_loss: 1801.1021\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 353.5099 - val_loss: 1799.7373\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 352.8866 - val_loss: 1797.8959\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 352.2651 - val_loss: 1796.1960\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 351.6438 - val_loss: 1794.0068\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 351.0194 - val_loss: 1788.5356\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 340.7420 - val_loss: 1722.5601\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 348.0522 - val_loss: 1709.0413\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 336.5173 - val_loss: 1694.5745\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 333.2639 - val_loss: 1685.7440\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 330.4858 - val_loss: 1657.3455\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 329.3713 - val_loss: 1653.5598\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 301.2523 - val_loss: 1632.8162\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 305.2713 - val_loss: 1632.2034\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 298.8381 - val_loss: 1622.7834\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 317.1886 - val_loss: 1621.7343\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 315.8903 - val_loss: 1620.6403\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 315.0486 - val_loss: 1608.5525\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 313.9094 - val_loss: 1610.7192\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 312.6691 - val_loss: 1613.5225\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 312.1762 - val_loss: 1609.0300\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 308.2730 - val_loss: 1606.4825\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 306.9023 - val_loss: 1604.8208\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 353.7735 - val_loss: 1616.9534\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 350.6939 - val_loss: 1634.2765\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 304.1852 - val_loss: 1633.8888\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 303.1089 - val_loss: 1631.1628\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 302.2091 - val_loss: 1627.8538\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 301.2142 - val_loss: 1621.7444\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 298.7762 - val_loss: 1609.6447\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 293.5638 - val_loss: 1582.2332\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 292.7288 - val_loss: 1574.4222\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 306.2751 - val_loss: 1599.1735\n",
      "Epoch 229/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 297.4834 - val_loss: 1613.3776\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 296.6304 - val_loss: 1613.5913\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 295.7776 - val_loss: 1609.1056\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 294.8500 - val_loss: 1599.1987\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 296.4274 - val_loss: 1596.5665\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 313.4698 - val_loss: 1669.1753\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 305.1703 - val_loss: 1632.7446\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 298.2720 - val_loss: 1602.4626\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 295.2968 - val_loss: 1586.1365\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 292.1799 - val_loss: 1569.7820\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 287.0386 - val_loss: 1557.5427\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 283.1193 - val_loss: 1545.3864\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 279.9021 - val_loss: 1521.1216\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 269.8744 - val_loss: 1518.6587\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 279.9723 - val_loss: 1494.2031\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 282.9109 - val_loss: 1446.7899\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 286.0517 - val_loss: 1451.2451\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 283.5448 - val_loss: 1451.3081\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 296.7883 - val_loss: 1492.8964\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 281.9983 - val_loss: 1471.1102\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 278.6303 - val_loss: 1471.3966\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 277.2891 - val_loss: 1473.0989\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 278.2674 - val_loss: 1486.8816\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 275.5851 - val_loss: 1485.1252\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 274.9883 - val_loss: 1481.3650\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 273.2051 - val_loss: 1454.3732\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 303.9684 - val_loss: 1468.6566\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 299.7027 - val_loss: 1478.9126\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 296.9979 - val_loss: 1464.5110\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 333.6556 - val_loss: 1488.8965\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 318.3090 - val_loss: 1611.6228\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 321.9542 - val_loss: 1648.9839\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 320.5855 - val_loss: 1652.4199\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 318.4958 - val_loss: 1637.2590\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 313.1578 - val_loss: 1626.4691\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 310.5063 - val_loss: 1627.5245\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 309.4041 - val_loss: 1629.6636\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 308.3433 - val_loss: 1630.1396\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 307.5826 - val_loss: 1630.2749\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 306.5368 - val_loss: 1631.0406\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 305.5248 - val_loss: 1631.9447\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 304.6690 - val_loss: 1631.5701\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 303.8302 - val_loss: 1630.7686\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 303.0059 - val_loss: 1629.6970\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 301.2177 - val_loss: 1573.0945\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 302.9031 - val_loss: 1567.8464\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 301.7831 - val_loss: 1572.3868\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 300.5586 - val_loss: 1576.2375\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 299.4301 - val_loss: 1578.9684\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 298.3781 - val_loss: 1581.5356\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 297.3462 - val_loss: 1583.5559\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 296.3893 - val_loss: 1585.0892\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 295.4744 - val_loss: 1586.0540\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 294.5927 - val_loss: 1586.8077\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 293.7401 - val_loss: 1586.6556\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 292.9337 - val_loss: 1586.7472\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 292.0787 - val_loss: 1586.8070\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 291.2766 - val_loss: 1586.2690\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 290.4890 - val_loss: 1585.5214\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 289.7126 - val_loss: 1584.5510\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 288.9450 - val_loss: 1583.3608\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 288.1820 - val_loss: 1581.8673\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 287.3567 - val_loss: 1576.2494\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 286.7124 - val_loss: 1572.0792\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 286.0097 - val_loss: 1570.9635\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 285.2489 - val_loss: 1568.4738\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 284.4704 - val_loss: 1567.9237\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 283.9097 - val_loss: 1564.1559\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 283.1502 - val_loss: 1558.1135\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 284.2474 - val_loss: 1567.9840\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 283.2892 - val_loss: 1566.9803\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 282.0618 - val_loss: 1567.0161\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 280.2930 - val_loss: 1552.8348\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 306.5974 - val_loss: 1558.5424\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 305.0142 - val_loss: 1567.4456\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.1916 - val_loss: 1593.1656\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 279.3535 - val_loss: 1567.7395\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 283.7110 - val_loss: 1588.8043\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 281.4576 - val_loss: 1575.2261\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 277.6771 - val_loss: 1560.7556\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 274.9076 - val_loss: 1555.9786\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 274.0243 - val_loss: 1550.8547\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 273.1366 - val_loss: 1546.6571\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 272.4904 - val_loss: 1542.9447\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 271.7632 - val_loss: 1539.6967\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 271.0778 - val_loss: 1536.7445\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 270.3908 - val_loss: 1533.9163\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 269.7019 - val_loss: 1531.0306\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 269.0246 - val_loss: 1527.8142\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 268.3155 - val_loss: 1525.3286\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 267.8416 - val_loss: 1520.1932\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 267.2253 - val_loss: 1516.6938\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 266.2884 - val_loss: 1515.6097\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 265.7827 - val_loss: 1510.4327\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 265.2224 - val_loss: 1507.7256\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 264.2094 - val_loss: 1509.2903\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 263.8795 - val_loss: 1508.2876\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 263.0548 - val_loss: 1504.8878\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 262.1985 - val_loss: 1500.0419\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 261.5090 - val_loss: 1496.7817\n",
      "Epoch 329/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 260.9669 - val_loss: 1493.1388\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 260.1927 - val_loss: 1492.2507\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 259.6693 - val_loss: 1486.2260\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 255.1283 - val_loss: 1454.3629\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 258.6878 - val_loss: 1488.3959\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 258.8033 - val_loss: 1495.7927\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 257.0167 - val_loss: 1488.7885\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 256.3828 - val_loss: 1483.5594\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 255.5763 - val_loss: 1479.9010\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 255.0869 - val_loss: 1477.0983\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 254.2854 - val_loss: 1474.0596\n",
      "Epoch 340/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 253.6005 - val_loss: 1472.6663\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 252.8445 - val_loss: 1470.7950\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 252.3540 - val_loss: 1471.1111\n",
      "Epoch 343/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 251.6722 - val_loss: 1469.3201\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 251.0117 - val_loss: 1466.6580\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 250.3740 - val_loss: 1464.6807\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 249.7379 - val_loss: 1460.2544\n",
      "Epoch 347/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 249.0305 - val_loss: 1449.0253\n",
      "Epoch 348/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 242.4058 - val_loss: 1395.5183\n",
      "Epoch 349/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 248.8279 - val_loss: 1397.3901\n",
      "Epoch 350/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.8516 - val_loss: 1401.4542\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 251.1800 - val_loss: 1343.9377\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 368.5943 - val_loss: 1371.4927\n",
      "Epoch 353/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 352.4582 - val_loss: 1455.0647\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 246.5422 - val_loss: 1467.8850\n",
      "Epoch 355/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 243.2336 - val_loss: 1462.9216\n",
      "Epoch 356/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 242.9821 - val_loss: 1451.2454\n",
      "Epoch 357/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 242.3829 - val_loss: 1449.8561\n",
      "Epoch 358/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 242.3533 - val_loss: 1441.9233\n",
      "Epoch 359/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 271.4626 - val_loss: 1532.9895\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 267.8550 - val_loss: 1517.2606\n",
      "Epoch 361/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 263.4562 - val_loss: 1467.7168\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.0959 - val_loss: 1494.0090\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 272.9726 - val_loss: 1534.5568\n",
      "Epoch 364/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 270.2332 - val_loss: 1498.6942\n",
      "Epoch 365/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 256.9108 - val_loss: 1448.7223\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 245.4520 - val_loss: 1429.7406\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 244.9137 - val_loss: 1426.0259\n",
      "Epoch 368/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 244.3265 - val_loss: 1423.6943\n",
      "Epoch 369/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 243.9176 - val_loss: 1412.4596\n",
      "Epoch 370/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 241.0786 - val_loss: 1365.8224\n",
      "Epoch 371/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 353.5428 - val_loss: 1392.4279\n",
      "Epoch 372/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 344.7344 - val_loss: 1431.3164\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 337.4327 - val_loss: 1457.4323\n",
      "Epoch 374/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 287.6433 - val_loss: 1566.4988\n",
      "Epoch 375/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 257.5656 - val_loss: 1544.8920\n",
      "Epoch 376/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 256.0513 - val_loss: 1527.9376\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 255.0906 - val_loss: 1519.2278\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 251.3127 - val_loss: 1479.7351\n",
      "Epoch 379/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 236.3076 - val_loss: 1436.5161\n",
      "Epoch 380/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 234.1658 - val_loss: 1413.1548\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 231.1846 - val_loss: 1389.7203\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 232.6389 - val_loss: 1364.9707\n",
      "Epoch 383/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 232.0330 - val_loss: 1369.6564\n",
      "Epoch 384/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 230.8275 - val_loss: 1339.4246\n",
      "Epoch 385/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 253.9705 - val_loss: 1434.0304\n",
      "Epoch 386/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 246.9966 - val_loss: 1415.3051\n",
      "Epoch 387/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 241.0825 - val_loss: 1397.0027\n",
      "Epoch 388/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 240.5578 - val_loss: 1395.2581\n",
      "Epoch 389/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 240.0254 - val_loss: 1394.0151\n",
      "Epoch 390/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 239.5014 - val_loss: 1393.3396\n",
      "Epoch 391/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 238.9579 - val_loss: 1392.8657\n",
      "Epoch 392/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 244.6112 - val_loss: 1443.0964\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 314.4349 - val_loss: 1690.2737\n",
      "Epoch 394/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 313.8441 - val_loss: 1576.8096\n",
      "Epoch 395/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 248.9652 - val_loss: 1361.0438\n",
      "Epoch 396/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 260.0900 - val_loss: 1327.8879\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 234.9549 - val_loss: 1331.2174\n",
      "Epoch 398/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 231.7378 - val_loss: 1281.1865\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 391.3515 - val_loss: 1267.4937\n",
      "Epoch 400/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 375.6031 - val_loss: 1329.8132\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 361.1230 - val_loss: 1436.5096\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 246.4443 - val_loss: 1416.1256\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 245.0410 - val_loss: 1402.1216\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 226.7813 - val_loss: 1357.0537\n",
      "Epoch 405/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 223.2968 - val_loss: 1326.8258\n",
      "Epoch 406/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 265.5045 - val_loss: 1485.5674\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 258.7917 - val_loss: 1452.2838\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 254.8491 - val_loss: 1413.7496\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 252.2002 - val_loss: 1382.5026\n",
      "Epoch 410/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 249.9362 - val_loss: 1367.4121\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 245.7858 - val_loss: 1354.0219\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 243.4799 - val_loss: 1307.3630\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 236.6346 - val_loss: 1284.2484\n",
      "Epoch 414/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 235.5507 - val_loss: 1283.5916\n",
      "Epoch 415/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 234.8500 - val_loss: 1282.5391\n",
      "Epoch 416/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 234.3743 - val_loss: 1282.6710\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 245.0321 - val_loss: 1343.5626\n",
      "Epoch 418/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 243.7245 - val_loss: 1343.0588\n",
      "Epoch 419/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 242.7303 - val_loss: 1332.8705\n",
      "Epoch 420/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 242.2026 - val_loss: 1325.6021\n",
      "Epoch 421/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 241.6155 - val_loss: 1323.3142\n",
      "Epoch 422/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 241.1834 - val_loss: 1321.6362\n",
      "Epoch 423/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 240.7444 - val_loss: 1322.4812\n",
      "Epoch 424/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 240.2994 - val_loss: 1320.3909\n",
      "Epoch 425/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 239.8926 - val_loss: 1319.1588\n",
      "Epoch 426/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 239.5832 - val_loss: 1320.5980\n",
      "Epoch 427/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 238.9893 - val_loss: 1315.0913\n",
      "Epoch 428/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 238.5944 - val_loss: 1315.1923\n",
      "Epoch 429/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 238.1673 - val_loss: 1311.4871\n",
      "Epoch 430/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 237.7398 - val_loss: 1311.7261\n",
      "Epoch 431/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 237.3008 - val_loss: 1308.4248\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 236.8835 - val_loss: 1306.9746\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 236.4614 - val_loss: 1305.5400\n",
      "Epoch 434/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 236.0305 - val_loss: 1303.9094\n",
      "Epoch 435/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 235.6184 - val_loss: 1304.6045\n",
      "Epoch 436/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 235.3009 - val_loss: 1303.4059\n",
      "Epoch 437/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 234.7589 - val_loss: 1299.1312\n",
      "Epoch 438/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 234.3469 - val_loss: 1296.5132\n",
      "Epoch 439/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 233.9327 - val_loss: 1294.6727\n",
      "Epoch 440/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 233.5135 - val_loss: 1294.8062\n",
      "Epoch 441/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 233.0883 - val_loss: 1292.2810\n",
      "Epoch 442/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 232.6732 - val_loss: 1286.0251\n",
      "Epoch 443/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 232.7581 - val_loss: 1290.6479\n",
      "Epoch 444/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 231.8819 - val_loss: 1288.6117\n",
      "Epoch 445/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 231.5154 - val_loss: 1289.3197\n",
      "Epoch 446/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 231.0237 - val_loss: 1285.0245\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 230.6031 - val_loss: 1284.5532\n",
      "Epoch 448/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 230.1817 - val_loss: 1282.4507\n",
      "Epoch 449/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 229.7745 - val_loss: 1280.0997\n",
      "Epoch 450/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 229.3587 - val_loss: 1278.5671\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 228.9446 - val_loss: 1276.9337\n",
      "Epoch 452/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 228.5385 - val_loss: 1275.3080\n",
      "Epoch 453/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 228.1234 - val_loss: 1274.2489\n",
      "Epoch 454/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.7079 - val_loss: 1272.9640\n",
      "Epoch 455/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 227.2992 - val_loss: 1271.5319\n",
      "Epoch 456/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 226.8879 - val_loss: 1268.8971\n",
      "Epoch 457/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 226.4847 - val_loss: 1267.2725\n",
      "Epoch 458/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 226.0024 - val_loss: 1267.4784\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 222.8448 - val_loss: 1250.8887\n",
      "Epoch 460/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 219.4721 - val_loss: 1238.8973\n",
      "Epoch 461/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 205.6029 - val_loss: 1222.2345\n",
      "Epoch 462/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 205.4261 - val_loss: 1217.8788\n",
      "Epoch 463/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 205.7987 - val_loss: 1192.5076\n",
      "Epoch 464/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 284.5511 - val_loss: 1268.4376\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 259.2627 - val_loss: 1364.3091\n",
      "Epoch 466/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 242.2834 - val_loss: 1327.5336\n",
      "Epoch 467/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 218.8129 - val_loss: 1291.1960\n",
      "Epoch 468/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 212.2981 - val_loss: 1251.5170\n",
      "Epoch 469/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 211.2879 - val_loss: 1243.2104\n",
      "Epoch 470/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 209.9118 - val_loss: 1232.3384\n",
      "Epoch 471/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 206.1332 - val_loss: 1223.5204\n",
      "Epoch 472/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 201.5069 - val_loss: 1217.9719\n",
      "Epoch 473/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 200.9391 - val_loss: 1219.1051\n",
      "Epoch 474/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 200.4149 - val_loss: 1216.1024\n",
      "Epoch 475/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 199.9294 - val_loss: 1215.3350\n",
      "Epoch 476/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 199.4445 - val_loss: 1214.1134\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 198.9781 - val_loss: 1213.3800\n",
      "Epoch 478/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 198.4867 - val_loss: 1212.6241\n",
      "Epoch 479/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 198.0345 - val_loss: 1211.4255\n",
      "Epoch 480/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 197.5877 - val_loss: 1209.8073\n",
      "Epoch 481/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 197.1519 - val_loss: 1208.2227\n",
      "Epoch 482/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 196.7160 - val_loss: 1206.0580\n",
      "Epoch 483/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 196.2895 - val_loss: 1203.4017\n",
      "Epoch 484/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 195.8399 - val_loss: 1203.3070\n",
      "Epoch 485/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 195.4064 - val_loss: 1201.9530\n",
      "Epoch 486/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 194.9657 - val_loss: 1199.9121\n",
      "Epoch 487/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 194.5329 - val_loss: 1198.6166\n",
      "Epoch 488/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 194.1027 - val_loss: 1197.0988\n",
      "Epoch 489/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 193.6765 - val_loss: 1193.9620\n",
      "Epoch 490/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 193.2481 - val_loss: 1192.5305\n",
      "Epoch 491/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 192.8176 - val_loss: 1191.4788\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 192.3839 - val_loss: 1190.8805\n",
      "Epoch 493/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 191.9604 - val_loss: 1188.4531\n",
      "Epoch 494/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 191.5627 - val_loss: 1185.9082\n",
      "Epoch 495/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 191.1078 - val_loss: 1187.1016\n",
      "Epoch 496/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 190.6429 - val_loss: 1187.6669\n",
      "Epoch 497/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 190.1478 - val_loss: 1188.0798\n",
      "Epoch 498/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 189.7073 - val_loss: 1185.6173\n",
      "Epoch 499/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 189.2681 - val_loss: 1184.8655\n",
      "Epoch 500/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 188.8758 - val_loss: 1180.5819\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(89.3180, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0010, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(-0.0204, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.2194, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 374ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 126)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 126)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 186)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:150:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 5.79249066e+01, 1.00525665e+00, 5.81023109e+01,\n",
       "        5.77241597e+01, 5.73436084e+01, 5.79015640e+01, 5.75234127e+01,\n",
       "        6.08996966e+01, 7.93619275e-01, 0.00000000e+00, 5.16042829e-01,\n",
       "        5.79669234e+01, 6.86268800e-02, 5.81843277e+01, 5.77661765e+01,\n",
       "        5.73880252e+01, 5.79435808e+01, 5.75654295e+01, 6.15299487e+01,\n",
       "        1.97836610e-02, 8.75653630e-02, 5.97576737e-01, 5.91800957e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.08871307e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.94598186e-01, 1.92284584e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.96320772e-01, 2.83887029e-01, 0.00000000e+00,\n",
       "        2.72478580e-01, 6.41270131e-02, 7.45676816e-01, 0.00000000e+00,\n",
       "        5.26171811e-02, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([62.77494022, 62.76728838, 62.75963654, 62.7519847 , 62.74433286,\n",
       "       62.73668101, 62.72902917, 62.72137733, 62.71372549, 62.70607365,\n",
       "       62.69842181, 62.69076997, 62.68311813, 62.67546628, 62.66781444,\n",
       "       62.6601626 , 62.65251076, 62.64485892, 62.63720708, 62.62955524,\n",
       "       62.6219034 , 62.61425155, 62.60659971, 62.59894787, 62.59129603,\n",
       "       62.58364419, 62.57599235, 62.56834051, 62.56068867, 62.55303682,\n",
       "       62.54538498, 62.53773314, 62.5300813 , 62.52242946, 62.51477762,\n",
       "       62.50712578, 62.49947394, 62.49182209, 62.48417025, 62.47651841,\n",
       "       62.46886657, 62.46121473, 62.45356289, 62.44591105, 62.43825921,\n",
       "       62.43060736, 62.42295552, 62.41530368, 62.40765184, 62.4       ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.5203404364337\n",
      "43.898704766424274\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
