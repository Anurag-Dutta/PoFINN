{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2245    64.343568\n",
       "2246    64.335916\n",
       "2247    64.328264\n",
       "2248    64.320612\n",
       "2249    64.312960\n",
       "Name: C7, Length: 2250, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c7_interpolated_2150_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2145     0.000000\n",
       "2146     1.246034\n",
       "2147     0.482828\n",
       "2148     0.000000\n",
       "2149     0.000000\n",
       "Name: C7, Length: 2150, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2150)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.387115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.174230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.961345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.748459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     92.600000  0.000298\n",
       "1     92.387115  0.000298\n",
       "2     92.174230  0.000297\n",
       "3     91.961345  0.000297\n",
       "4     91.748459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 89.3180  # Value for C0\n",
    "K0 = -0.0010  # Value for K0\n",
    "K1 = 0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = -0.0204    # Value for b\n",
    "c = 2.2194    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    92.600000    92.387115    92.174230    91.961345    91.748459   \n",
      "351    92.387115    92.174230    91.961345    91.748459    91.535574   \n",
      "352    92.174230    91.961345    91.748459    91.535574    91.322689   \n",
      "353    91.961345    91.748459    91.535574    91.322689    91.109804   \n",
      "354    91.748459    91.535574    91.322689    91.109804    90.896919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    91.535574    91.322689    91.109804    90.896919    90.691597  ...   \n",
      "351    91.322689    91.109804    90.896919    90.691597    90.579552  ...   \n",
      "352    91.109804    90.896919    90.691597    90.579552    90.467507  ...   \n",
      "353    90.896919    90.691597    90.579552    90.467507    90.355462  ...   \n",
      "354    90.691597    90.579552    90.467507    90.355462    90.243417  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   80.261671    0.000263   80.252334    0.000263   80.242997    0.000263   \n",
      "351   80.252334    0.000263   80.242997    0.000263   80.233660    0.000262   \n",
      "352   80.242997    0.000263   80.233660    0.000262   80.224323    0.000262   \n",
      "353   80.233660    0.000262   80.224323    0.000262   80.214986    0.000262   \n",
      "354   80.224323    0.000262   80.214986    0.000262   80.205649    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   80.233660    0.000262   80.224323    0.000262  \n",
      "351   80.224323    0.000262   80.214986    0.000262  \n",
      "352   80.214986    0.000262   80.205649    0.000262  \n",
      "353   80.205649    0.000262   80.196312    0.000262  \n",
      "354   80.196312    0.000262   80.186975    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 1, 251) (1700, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/22 [==============================] - 2s 23ms/step - loss: 5449.5708 - val_loss: 3209.9854\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 5229.7563 - val_loss: 3095.5640\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 5095.8506 - val_loss: 3028.0933\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4993.6914 - val_loss: 2966.2593\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4894.7573 - val_loss: 2909.3701\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4800.8433 - val_loss: 2854.8879\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4709.9062 - val_loss: 2802.2876\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4621.3076 - val_loss: 2751.2793\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4534.6831 - val_loss: 2701.6921\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4449.8105 - val_loss: 2653.4150\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4366.5444 - val_loss: 2606.3718\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4284.7827 - val_loss: 2560.5037\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4204.4473 - val_loss: 2515.7661\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4125.4814 - val_loss: 2472.1223\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4047.8345 - val_loss: 2429.5408\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3971.4688 - val_loss: 2387.9956\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3896.3494 - val_loss: 2347.4619\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3822.4468 - val_loss: 2307.9202\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3749.7346 - val_loss: 2269.3494\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 3678.1902 - val_loss: 2231.7332\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3607.7908 - val_loss: 2195.0532\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3538.5166 - val_loss: 2159.2944\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3470.3503 - val_loss: 2124.4417\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3403.2732 - val_loss: 2090.4810\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3337.2705 - val_loss: 2057.3977\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3272.3254 - val_loss: 2025.1794\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3208.4231 - val_loss: 1993.8127\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3145.5500 - val_loss: 1963.2853\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3083.6919 - val_loss: 1933.5802\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3022.8347 - val_loss: 1904.6996\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2962.9670 - val_loss: 1876.6177\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2904.0747 - val_loss: 1849.3279\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2846.1462 - val_loss: 1822.8184\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2789.1697 - val_loss: 1797.0792\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2733.1326 - val_loss: 1772.0989\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2678.0251 - val_loss: 1747.8666\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2623.8340 - val_loss: 1724.3721\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2570.5503 - val_loss: 1701.6046\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2518.1611 - val_loss: 1679.5542\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2466.6567 - val_loss: 1658.2107\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2416.0269 - val_loss: 1637.5642\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2366.2610 - val_loss: 1617.6042\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2317.3484 - val_loss: 1598.3212\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2269.2786 - val_loss: 1579.7056\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2222.0435 - val_loss: 1561.7476\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2175.6311 - val_loss: 1544.4373\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2130.0332 - val_loss: 1527.7659\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2085.2393 - val_loss: 1511.7236\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2041.2402 - val_loss: 1496.3010\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1998.0262 - val_loss: 1481.4894\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1955.5883 - val_loss: 1467.2784\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1913.9167 - val_loss: 1453.6602\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1873.0033 - val_loss: 1440.6245\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1832.8380 - val_loss: 1428.1635\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1793.4128 - val_loss: 1416.2673\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1754.7174 - val_loss: 1404.9274\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1716.7443 - val_loss: 1394.1349\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1679.4840 - val_loss: 1383.8806\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1642.9281 - val_loss: 1374.1560\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1607.0679 - val_loss: 1364.9515\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1571.8945 - val_loss: 1356.2584\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1537.4000 - val_loss: 1348.0631\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1503.5757 - val_loss: 1340.4548\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1470.4127 - val_loss: 1333.2570\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1437.9036 - val_loss: 1326.5363\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1406.0399 - val_loss: 1320.2856\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1374.8131 - val_loss: 1314.4976\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1344.2152 - val_loss: 1309.1631\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1314.2382 - val_loss: 1304.2743\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1284.8740 - val_loss: 1299.8224\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1256.1145 - val_loss: 1295.7998\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1227.9525 - val_loss: 1292.1981\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1200.3789 - val_loss: 1289.0092\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1173.3864 - val_loss: 1286.2249\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1146.9674 - val_loss: 1283.8372\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1121.1144 - val_loss: 1281.8383\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1095.8190 - val_loss: 1280.2198\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1071.0739 - val_loss: 1278.9745\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1046.8716 - val_loss: 1278.0935\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1023.2043 - val_loss: 1277.5697\n",
      "Epoch 81/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1000.0647 - val_loss: 1277.3950\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 977.4451 - val_loss: 1277.5616\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 955.3385 - val_loss: 1278.0615\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 933.7371 - val_loss: 1278.8876\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 912.6335 - val_loss: 1280.0315\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 892.0206 - val_loss: 1281.4861\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 871.8910 - val_loss: 1283.2430\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 852.2377 - val_loss: 1285.2954\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 833.0531 - val_loss: 1287.6353\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 814.3303 - val_loss: 1290.2554\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 796.0621 - val_loss: 1293.1479\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 778.2415 - val_loss: 1296.3058\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 760.8615 - val_loss: 1299.7209\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 743.9150 - val_loss: 1303.3866\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 727.3950 - val_loss: 1307.2952\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 711.2947 - val_loss: 1311.4396\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 695.6071 - val_loss: 1315.8119\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 680.3253 - val_loss: 1320.4055\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 665.4426 - val_loss: 1325.2130\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 650.9525 - val_loss: 1330.2272\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 636.8477 - val_loss: 1335.4410\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 623.1218 - val_loss: 1340.8474\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 609.7682 - val_loss: 1346.4393\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 596.7801 - val_loss: 1352.2098\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 584.1511 - val_loss: 1358.1516\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 571.8747 - val_loss: 1364.2583\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 559.9442 - val_loss: 1370.5228\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 548.3532 - val_loss: 1376.9384\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 537.0955 - val_loss: 1383.4982\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 526.1644 - val_loss: 1390.1954\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 515.5540 - val_loss: 1397.0237\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 505.2576 - val_loss: 1403.9758\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 495.2692 - val_loss: 1411.0463\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 485.5827 - val_loss: 1418.2281\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 476.1915 - val_loss: 1425.5143\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 467.0900 - val_loss: 1432.8995\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 458.2718 - val_loss: 1440.3771\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 449.7313 - val_loss: 1447.9403\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 441.4621 - val_loss: 1455.5831\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 433.4586 - val_loss: 1463.3002\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 425.7148 - val_loss: 1471.0846\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 418.2249 - val_loss: 1478.9310\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 410.9831 - val_loss: 1486.8333\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 403.9838 - val_loss: 1494.7856\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 397.2213 - val_loss: 1502.7820\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 390.6901 - val_loss: 1510.8171\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 384.3846 - val_loss: 1518.8856\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 378.2993 - val_loss: 1526.9816\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 372.4287 - val_loss: 1535.0997\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 366.7676 - val_loss: 1543.2351\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 361.3106 - val_loss: 1551.3818\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 356.0525 - val_loss: 1559.5353\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 350.9880 - val_loss: 1567.6908\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 346.1122 - val_loss: 1575.8431\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 341.4199 - val_loss: 1583.9719\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 336.9061 - val_loss: 1590.9102\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 332.5659 - val_loss: 1600.3838\n",
      "Epoch 138/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 328.3945 - val_loss: 1608.4753\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 324.3870 - val_loss: 1616.5396\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 320.5387 - val_loss: 1624.5734\n",
      "Epoch 141/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 316.8451 - val_loss: 1632.5713\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 313.3014 - val_loss: 1640.5295\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 309.9031 - val_loss: 1648.4448\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 306.6460 - val_loss: 1656.3125\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 303.5254 - val_loss: 1664.1294\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 300.5373 - val_loss: 1671.8910\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 297.6772 - val_loss: 1679.5941\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 294.9412 - val_loss: 1687.2357\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 292.3250 - val_loss: 1694.8123\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 289.8249 - val_loss: 1702.3201\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 287.4368 - val_loss: 1709.7562\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 285.1568 - val_loss: 1717.1184\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 282.9813 - val_loss: 1724.4026\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 280.9065 - val_loss: 1731.6072\n",
      "Epoch 155/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 278.9287 - val_loss: 1738.7294\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 277.0446 - val_loss: 1745.7670\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 275.2505 - val_loss: 1752.7163\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 273.5432 - val_loss: 1759.5767\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 271.9194 - val_loss: 1766.3455\n",
      "Epoch 160/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 270.3759 - val_loss: 1773.0199\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 268.9095 - val_loss: 1779.5988\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 267.5172 - val_loss: 1786.0807\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 266.1959 - val_loss: 1792.4637\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 264.9429 - val_loss: 1798.7468\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 263.7552 - val_loss: 1804.9285\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 262.6301 - val_loss: 1811.0065\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 261.5652 - val_loss: 1816.9812\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 260.5574 - val_loss: 1822.8510\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 259.6046 - val_loss: 1828.6141\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 258.7043 - val_loss: 1834.2715\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 257.8541 - val_loss: 1839.8212\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 257.0516 - val_loss: 1845.2638\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 256.2948 - val_loss: 1850.5981\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 255.5815 - val_loss: 1855.8241\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 254.9094 - val_loss: 1860.9404\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 254.2770 - val_loss: 1865.9485\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 253.6819 - val_loss: 1870.8481\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 253.1224 - val_loss: 1875.6388\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 252.5968 - val_loss: 1880.3219\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 252.1034 - val_loss: 1884.8967\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 251.6404 - val_loss: 1889.3645\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 251.2063 - val_loss: 1893.7242\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 250.7996 - val_loss: 1897.9778\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 250.4188 - val_loss: 1902.1254\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 250.0625 - val_loss: 1906.1672\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.7293 - val_loss: 1910.1057\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4181 - val_loss: 1913.9404\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.1274 - val_loss: 1917.6726\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 248.8562 - val_loss: 1921.3041\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 248.6034 - val_loss: 1924.8353\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 248.3679 - val_loss: 1928.2664\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 248.1486 - val_loss: 1931.6006\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 247.9446 - val_loss: 1934.8373\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 247.7550 - val_loss: 1937.9805\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 247.5788 - val_loss: 1941.0284\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 247.4152 - val_loss: 1943.9836\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 247.2635 - val_loss: 1946.8491\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 247.1229 - val_loss: 1949.6243\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 246.9928 - val_loss: 1952.3123\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 246.8722 - val_loss: 1954.9131\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 246.7608 - val_loss: 1957.4303\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 246.6579 - val_loss: 1959.8644\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 246.5628 - val_loss: 1962.2169\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 246.4751 - val_loss: 1964.4895\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 246.3943 - val_loss: 1966.6846\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 246.3198 - val_loss: 1968.8027\n",
      "Epoch 207/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 246.2514 - val_loss: 1970.8470\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 246.1883 - val_loss: 1972.8182\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 246.1305 - val_loss: 1974.7178\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 246.0773 - val_loss: 1976.5490\n",
      "Epoch 211/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 246.0287 - val_loss: 1978.3118\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.9840 - val_loss: 1980.0088\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.9431 - val_loss: 1981.6412\n",
      "Epoch 214/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.9058 - val_loss: 1983.2115\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.8716 - val_loss: 1984.7209\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.8405 - val_loss: 1986.1716\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.8120 - val_loss: 1987.5651\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.7861 - val_loss: 1988.9027\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 245.7625 - val_loss: 1990.1875\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.7410 - val_loss: 1991.4176\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.7216 - val_loss: 1992.5980\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.7040 - val_loss: 1993.7290\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6880 - val_loss: 1994.8131\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6735 - val_loss: 1995.8507\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6604 - val_loss: 1996.8445\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6487 - val_loss: 1997.7943\n",
      "Epoch 227/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6380 - val_loss: 1998.7028\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 245.6285 - val_loss: 1999.5717\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6199 - val_loss: 2000.4022\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6122 - val_loss: 2001.1940\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6053 - val_loss: 2001.9506\n",
      "Epoch 232/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5993 - val_loss: 2002.6729\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5938 - val_loss: 2003.3607\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5889 - val_loss: 2004.0170\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5847 - val_loss: 2004.6425\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5809 - val_loss: 2005.2386\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5776 - val_loss: 2005.8059\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5748 - val_loss: 2006.3463\n",
      "Epoch 239/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5722 - val_loss: 2006.8604\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5700 - val_loss: 2007.3489\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 245.5682 - val_loss: 2007.8135\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.5667 - val_loss: 2008.2551\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.5653 - val_loss: 2008.6744\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5642 - val_loss: 2009.0735\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5633 - val_loss: 2009.4509\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 245.5626 - val_loss: 2009.8096\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.5622 - val_loss: 2010.1509\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.5618 - val_loss: 2010.4728\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5615 - val_loss: 2010.7791\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5614 - val_loss: 2011.0687\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.5613 - val_loss: 2011.3423\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5615 - val_loss: 2011.6014\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5617 - val_loss: 2011.8469\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5619 - val_loss: 2012.0787\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5622 - val_loss: 2012.2979\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5626 - val_loss: 2012.5062\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5630 - val_loss: 2012.7021\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5635 - val_loss: 2012.8871\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5640 - val_loss: 2013.0623\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5646 - val_loss: 2013.2261\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5652 - val_loss: 2013.3823\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5658 - val_loss: 2013.5294\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5665 - val_loss: 2013.6672\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5671 - val_loss: 2013.7972\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5678 - val_loss: 2013.9211\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5685 - val_loss: 2014.0364\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5693 - val_loss: 2014.1449\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5701 - val_loss: 2014.2474\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5708 - val_loss: 2014.3444\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5715 - val_loss: 2014.4346\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5723 - val_loss: 2014.5195\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 245.5730 - val_loss: 2014.5995\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.5738 - val_loss: 2014.6750\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.5745 - val_loss: 2014.7449\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.5753 - val_loss: 2014.8118\n",
      "Epoch 276/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.5760 - val_loss: 2014.8732\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5768 - val_loss: 2014.9309\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5775 - val_loss: 2014.9857\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5783 - val_loss: 2015.0367\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5790 - val_loss: 2015.0846\n",
      "Epoch 281/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5798 - val_loss: 2015.1290\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5805 - val_loss: 2015.1713\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5813 - val_loss: 2015.2104\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5821 - val_loss: 2015.2474\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5828 - val_loss: 2015.2820\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5835 - val_loss: 2015.3136\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5842 - val_loss: 2015.3440\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5849 - val_loss: 2015.3717\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5856 - val_loss: 2015.3978\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5863 - val_loss: 2015.4226\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5870 - val_loss: 2015.4452\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5877 - val_loss: 2015.4667\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5884 - val_loss: 2015.4858\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5891 - val_loss: 2015.5044\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5897 - val_loss: 2015.5217\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5903 - val_loss: 2015.5367\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5911 - val_loss: 2015.5519\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5917 - val_loss: 2015.5654\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5923 - val_loss: 2015.5781\n",
      "Epoch 300/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 245.5929 - val_loss: 2015.5906\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.5936 - val_loss: 2015.6018\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.5942 - val_loss: 2015.6130\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.5947 - val_loss: 2015.6221\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.5954 - val_loss: 2015.6316\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.5959 - val_loss: 2015.6400\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5964 - val_loss: 2015.6460\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5971 - val_loss: 2015.6534\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5976 - val_loss: 2015.6594\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5981 - val_loss: 2015.6661\n",
      "Epoch 310/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5987 - val_loss: 2015.6716\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5992 - val_loss: 2015.6761\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.5997 - val_loss: 2015.6803\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6003 - val_loss: 2015.6847\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6008 - val_loss: 2015.6896\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6012 - val_loss: 2015.6923\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6018 - val_loss: 2015.6956\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6022 - val_loss: 2015.6989\n",
      "Epoch 318/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 245.6027 - val_loss: 2015.7018\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6032 - val_loss: 2015.7041\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6037 - val_loss: 2015.7067\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6041 - val_loss: 2015.7079\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6045 - val_loss: 2015.7096\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6050 - val_loss: 2015.7115\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6054 - val_loss: 2015.7136\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6058 - val_loss: 2015.7156\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 245.6062 - val_loss: 2015.7163\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6066 - val_loss: 2015.7170\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6071 - val_loss: 2015.7184\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6075 - val_loss: 2015.7195\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6079 - val_loss: 2015.7194\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6082 - val_loss: 2015.7202\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6086 - val_loss: 2015.7206\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6090 - val_loss: 2015.7206\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6093 - val_loss: 2015.7212\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6097 - val_loss: 2015.7216\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6101 - val_loss: 2015.7219\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6104 - val_loss: 2015.7230\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6107 - val_loss: 2015.7230\n",
      "Epoch 339/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6111 - val_loss: 2015.7235\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6114 - val_loss: 2015.7239\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6116 - val_loss: 2015.7235\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6120 - val_loss: 2015.7235\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6123 - val_loss: 2015.7230\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6126 - val_loss: 2015.7230\n",
      "Epoch 345/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6129 - val_loss: 2015.7235\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6133 - val_loss: 2015.7239\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6135 - val_loss: 2015.7230\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6138 - val_loss: 2015.7228\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6140 - val_loss: 2015.7227\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6142 - val_loss: 2015.7223\n",
      "Epoch 351/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6145 - val_loss: 2015.7216\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6148 - val_loss: 2015.7217\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 245.6151 - val_loss: 2015.7219\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6154 - val_loss: 2015.7217\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6155 - val_loss: 2015.7212\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6158 - val_loss: 2015.7209\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6161 - val_loss: 2015.7219\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6162 - val_loss: 2015.7208\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6165 - val_loss: 2015.7205\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6167 - val_loss: 2015.7202\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6170 - val_loss: 2015.7202\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6172 - val_loss: 2015.7206\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6173 - val_loss: 2015.7190\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6176 - val_loss: 2015.7190\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6178 - val_loss: 2015.7185\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6180 - val_loss: 2015.7180\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6182 - val_loss: 2015.7181\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6183 - val_loss: 2015.7173\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6185 - val_loss: 2015.7159\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6187 - val_loss: 2015.7152\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6189 - val_loss: 2015.7156\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6191 - val_loss: 2015.7156\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6193 - val_loss: 2015.7156\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6194 - val_loss: 2015.7155\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6195 - val_loss: 2015.7141\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6198 - val_loss: 2015.7145\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6199 - val_loss: 2015.7137\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 245.6201 - val_loss: 2015.7133\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6201 - val_loss: 2015.7129\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 245.6203 - val_loss: 2015.7129\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6204 - val_loss: 2015.7119\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6206 - val_loss: 2015.7119\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6208 - val_loss: 2015.7119\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6209 - val_loss: 2015.7125\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6210 - val_loss: 2015.7123\n",
      "Epoch 386/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6211 - val_loss: 2015.7125\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6212 - val_loss: 2015.7125\n",
      "Epoch 388/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6214 - val_loss: 2015.7125\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6215 - val_loss: 2015.7125\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6216 - val_loss: 2015.7119\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6218 - val_loss: 2015.7119\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6219 - val_loss: 2015.7119\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6220 - val_loss: 2015.7119\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6221 - val_loss: 2015.7123\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6222 - val_loss: 2015.7119\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6222 - val_loss: 2015.7115\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6224 - val_loss: 2015.7115\n",
      "Epoch 398/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6224 - val_loss: 2015.7108\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6225 - val_loss: 2015.7103\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6227 - val_loss: 2015.7112\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6228 - val_loss: 2015.7115\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6228 - val_loss: 2015.7115\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 245.6230 - val_loss: 2015.7115\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6230 - val_loss: 2015.7115\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6231 - val_loss: 2015.7115\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6232 - val_loss: 2015.7114\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6233 - val_loss: 2015.7107\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6234 - val_loss: 2015.7103\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6235 - val_loss: 2015.7101\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6236 - val_loss: 2015.7101\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6237 - val_loss: 2015.7103\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6237 - val_loss: 2015.7103\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6238 - val_loss: 2015.7101\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6238 - val_loss: 2015.7101\n",
      "Epoch 415/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6239 - val_loss: 2015.7100\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6239 - val_loss: 2015.7090\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6240 - val_loss: 2015.7092\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6241 - val_loss: 2015.7092\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6242 - val_loss: 2015.7094\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6243 - val_loss: 2015.7085\n",
      "Epoch 421/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6243 - val_loss: 2015.7074\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6243 - val_loss: 2015.7070\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6245 - val_loss: 2015.7070\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6245 - val_loss: 2015.7067\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6245 - val_loss: 2015.7059\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6246 - val_loss: 2015.7057\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 245.6247 - val_loss: 2015.7059\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6248 - val_loss: 2015.7067\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6248 - val_loss: 2015.7057\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6249 - val_loss: 2015.7067\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6249 - val_loss: 2015.7067\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6250 - val_loss: 2015.7072\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6250 - val_loss: 2015.7070\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6250 - val_loss: 2015.7078\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6251 - val_loss: 2015.7078\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6251 - val_loss: 2015.7078\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6252 - val_loss: 2015.7078\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6252 - val_loss: 2015.7070\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6253 - val_loss: 2015.7070\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6253 - val_loss: 2015.7067\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6253 - val_loss: 2015.7064\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6254 - val_loss: 2015.7063\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6254 - val_loss: 2015.7063\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6254 - val_loss: 2015.7048\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6254 - val_loss: 2015.7041\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6255 - val_loss: 2015.7041\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6256 - val_loss: 2015.7042\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6257 - val_loss: 2015.7045\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6257 - val_loss: 2015.7048\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 245.6257 - val_loss: 2015.7048\n",
      "Epoch 451/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6257 - val_loss: 2015.7048\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6258 - val_loss: 2015.7048\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6258 - val_loss: 2015.7048\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6258 - val_loss: 2015.7053\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6258 - val_loss: 2015.7053\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6258 - val_loss: 2015.7067\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6259 - val_loss: 2015.7059\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6259 - val_loss: 2015.7053\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6259 - val_loss: 2015.7052\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6259 - val_loss: 2015.7048\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6259 - val_loss: 2015.7045\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6260 - val_loss: 2015.7042\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6260 - val_loss: 2015.7042\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6260 - val_loss: 2015.7042\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6261 - val_loss: 2015.7045\n",
      "Epoch 466/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6261 - val_loss: 2015.7045\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6261 - val_loss: 2015.7045\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6261 - val_loss: 2015.7042\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6261 - val_loss: 2015.7042\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6261 - val_loss: 2015.7035\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6261 - val_loss: 2015.7034\n",
      "Epoch 472/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 245.6261 - val_loss: 2015.7028\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6262 - val_loss: 2015.7021\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6262 - val_loss: 2015.7013\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6263 - val_loss: 2015.7007\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6263 - val_loss: 2015.7003\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6263 - val_loss: 2015.7000\n",
      "Epoch 478/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6263 - val_loss: 2015.6995\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6263 - val_loss: 2015.6987\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6264 - val_loss: 2015.6978\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6264 - val_loss: 2015.6974\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6264 - val_loss: 2015.6965\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6264 - val_loss: 2015.6958\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6264 - val_loss: 2015.6956\n",
      "Epoch 485/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6265 - val_loss: 2015.6958\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6266 - val_loss: 2015.6965\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6266 - val_loss: 2015.6981\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6266 - val_loss: 2015.6995\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6266 - val_loss: 2015.7006\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6266 - val_loss: 2015.7018\n",
      "Epoch 491/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6266 - val_loss: 2015.7028\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6266 - val_loss: 2015.7031\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6266 - val_loss: 2015.7034\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 245.6266 - val_loss: 2015.7035\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6266 - val_loss: 2015.7039\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6267 - val_loss: 2015.7042\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6266 - val_loss: 2015.7053\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 245.6266 - val_loss: 2015.7059\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6266 - val_loss: 2015.7064\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 245.6266 - val_loss: 2015.7064\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(89.3180, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0010, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(-0.0204, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.2194, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 413ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.38918301e+01, 7.33882656e+01, 7.30075934e+01, 7.26269211e+01,\n",
       "        7.86927795e+01, 0.00000000e+00, 2.29425150e-01, 0.00000000e+00,\n",
       "        8.92468990e-01, 3.40304670e-01, 7.85433350e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.18376961e+01, 7.18049230e+01, 7.17721499e+01,\n",
       "        7.17393768e+01, 7.17066036e+01, 7.70233660e+01, 7.68089636e+01,\n",
       "        7.65064426e+01, 7.62039216e+01, 7.59014006e+01, 7.55146125e+01,\n",
       "        7.49599907e+01, 7.44053688e+01, 7.38507470e+01, 2.71232130e-01,\n",
       "        0.00000000e+00, 7.60246499e+01, 7.57221289e+01, 7.51859477e+01,\n",
       "        7.46313259e+01, 7.40767040e+01, 7.35220822e+01, 7.31344841e+01,\n",
       "        7.27538119e+01, 7.23731396e+01, 0.00000000e+00, 1.61724660e-01,\n",
       "        6.12137910e-01, 3.49131940e-01, 6.50809400e-02, 0.00000000e+00,\n",
       "        4.24601470e-01, 1.91040430e-01, 4.31488500e-02, 7.27961088e+01,\n",
       "        7.24154365e+01, 8.33228588e-01, 6.77165926e-01, 7.43642857e+01,\n",
       "        7.38096639e+01, 7.33318697e+01, 7.29511975e+01, 7.25705252e+01,\n",
       "        7.21898529e+01, 7.19432983e+01, 7.18449790e+01, 7.17466597e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.27256139e+01, 7.23449416e+01,\n",
       "        7.19833543e+01, 7.18850350e+01, 7.17867157e+01, 7.71017974e+01,\n",
       "        7.63383754e+01, 7.52064893e+01, 8.65812778e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.12379684e+01, 0.00000000e+00, 4.45122272e-01,\n",
       "        2.75238454e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.35018997e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.68930459e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.83581796e-02, 1.02972221e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.80919981e-01, 8.33514750e-01,\n",
       "        5.13072550e-01, 8.80311251e-01, 0.00000000e+00, 4.90560800e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65.07049259, 65.06284075, 65.0551889 , 65.04753706, 65.03988522,\n",
       "       65.03223338, 65.02458154, 65.0169297 , 65.00927786, 65.00162602,\n",
       "       64.99397418, 64.98632233, 64.97867049, 64.97101865, 64.96336681,\n",
       "       64.95571497, 64.94806313, 64.94041129, 64.93275945, 64.9251076 ,\n",
       "       64.91745576, 64.90980392, 64.90215208, 64.89450024, 64.8868484 ,\n",
       "       64.87919656, 64.87154472, 64.86389287, 64.85624103, 64.84858919,\n",
       "       64.84093735, 64.83328551, 64.82563367, 64.81798183, 64.81032999,\n",
       "       64.80267814, 64.7950263 , 64.78737446, 64.77972262, 64.77207078,\n",
       "       64.76441894, 64.7567671 , 64.74911526, 64.74146341, 64.73381157,\n",
       "       64.72615973, 64.71850789, 64.71085605, 64.70320421, 64.69555237,\n",
       "       64.68790053, 64.68024868, 64.67259684, 64.664945  , 64.65729316,\n",
       "       64.64964132, 64.64198948, 64.63433764, 64.6266858 , 64.61903396,\n",
       "       64.61138211, 64.60373027, 64.59607843, 64.58842659, 64.58077475,\n",
       "       64.57312291, 64.56547107, 64.55781923, 64.55016738, 64.54251554,\n",
       "       64.5348637 , 64.52721186, 64.51956002, 64.51190818, 64.50425634,\n",
       "       64.4966045 , 64.48895265, 64.48130081, 64.47364897, 64.46599713,\n",
       "       64.45834529, 64.45069345, 64.44304161, 64.43538977, 64.42773792,\n",
       "       64.42008608, 64.41243424, 64.4047824 , 64.39713056, 64.38947872,\n",
       "       64.38182688, 64.37417504, 64.36652319, 64.35887135, 64.35121951,\n",
       "       64.34356767, 64.33591583, 64.32826399, 64.32061215, 64.31296031])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.402589861215624\n",
      "37.209658785070154\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
