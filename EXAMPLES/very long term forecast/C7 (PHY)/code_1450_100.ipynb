{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "1545    69.143627\n",
       "1546    69.137091\n",
       "1547    69.130556\n",
       "1548    69.124020\n",
       "1549    69.117484\n",
       "Name: C7, Length: 1550, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c7_interpolated_1450_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "1445     0.161725\n",
       "1446     0.000000\n",
       "1447     0.000000\n",
       "1448     0.229425\n",
       "1449     0.013130\n",
       "Name: C7, Length: 1450, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1450)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.387115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.174230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.961345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.748459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     92.600000  0.000298\n",
       "1     92.387115  0.000298\n",
       "2     92.174230  0.000297\n",
       "3     91.961345  0.000297\n",
       "4     91.748459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 89.3180  # Value for C0\n",
    "K0 = -0.0010  # Value for K0\n",
    "K1 = 0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = -0.0204    # Value for b\n",
    "c = 2.2194    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    92.600000    92.387115    92.174230    91.961345    91.748459   \n",
      "351    92.387115    92.174230    91.961345    91.748459    91.535574   \n",
      "352    92.174230    91.961345    91.748459    91.535574    91.322689   \n",
      "353    91.961345    91.748459    91.535574    91.322689    91.109804   \n",
      "354    91.748459    91.535574    91.322689    91.109804    90.896919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    91.535574    91.322689    91.109804    90.896919    90.691597  ...   \n",
      "351    91.322689    91.109804    90.896919    90.691597    90.579552  ...   \n",
      "352    91.109804    90.896919    90.691597    90.579552    90.467507  ...   \n",
      "353    90.896919    90.691597    90.579552    90.467507    90.355462  ...   \n",
      "354    90.691597    90.579552    90.467507    90.355462    90.243417  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   80.261671    0.000263   80.252334    0.000263   80.242997    0.000263   \n",
      "351   80.252334    0.000263   80.242997    0.000263   80.233660    0.000262   \n",
      "352   80.242997    0.000263   80.233660    0.000262   80.224323    0.000262   \n",
      "353   80.233660    0.000262   80.224323    0.000262   80.214986    0.000262   \n",
      "354   80.224323    0.000262   80.214986    0.000262   80.205649    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   80.233660    0.000262   80.224323    0.000262  \n",
      "351   80.224323    0.000262   80.214986    0.000262  \n",
      "352   80.214986    0.000262   80.205649    0.000262  \n",
      "353   80.205649    0.000262   80.196312    0.000262  \n",
      "354   80.196312    0.000262   80.186975    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 251) (1000, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "13/13 [==============================] - 3s 60ms/step - loss: 5986.2798 - val_loss: 4986.7227\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 5885.5400 - val_loss: 4938.9834\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5833.5474 - val_loss: 4891.2861\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5781.7651 - val_loss: 4843.9170\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5730.3452 - val_loss: 4796.9146\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5679.3037 - val_loss: 4750.2754\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5628.6333 - val_loss: 4703.9902\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5578.3237 - val_loss: 4658.0503\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5528.3687 - val_loss: 4612.4502\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5478.7598 - val_loss: 4567.1836\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5428.7319 - val_loss: 4503.5142\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5358.8525 - val_loss: 4456.0708\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5306.9692 - val_loss: 4408.8398\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5255.6538 - val_loss: 4362.3047\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5205.0566 - val_loss: 4316.4038\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5155.0884 - val_loss: 4271.0522\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5105.6685 - val_loss: 4226.1909\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5056.7407 - val_loss: 4181.7769\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5008.2671 - val_loss: 4137.7827\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4960.2212 - val_loss: 4094.1895\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4912.5835 - val_loss: 4050.9795\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4865.3398 - val_loss: 4008.1426\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4818.4785 - val_loss: 3965.6689\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4771.9902 - val_loss: 3923.5500\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 4725.8652 - val_loss: 3881.7800\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4680.1001 - val_loss: 3840.3538\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4634.6865 - val_loss: 3799.2649\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4589.6216 - val_loss: 3758.5103\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4541.8252 - val_loss: 3709.5266\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4489.0200 - val_loss: 3665.0991\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4440.3335 - val_loss: 3621.4163\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 4376.7441 - val_loss: 3560.7825\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4324.0117 - val_loss: 3514.6382\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4273.6377 - val_loss: 3469.7380\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4224.5469 - val_loss: 3425.9197\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4176.5264 - val_loss: 3382.9937\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4129.3955 - val_loss: 3340.8247\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4083.0254 - val_loss: 3299.3193\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4037.3284 - val_loss: 3258.4111\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3992.2429 - val_loss: 3218.0532\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3947.7190 - val_loss: 3178.2078\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3903.7241 - val_loss: 3138.8469\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3860.2273 - val_loss: 3099.9463\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3817.2068 - val_loss: 3061.4875\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3774.6426 - val_loss: 3023.4563\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3732.5193 - val_loss: 2985.8362\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3690.8225 - val_loss: 2948.6179\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3649.5400 - val_loss: 2911.7893\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3608.6621 - val_loss: 2875.3430\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3568.1790 - val_loss: 2839.2688\n",
      "Epoch 51/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3528.0828 - val_loss: 2803.5615\n",
      "Epoch 52/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3488.3657 - val_loss: 2768.2134\n",
      "Epoch 53/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3449.0203 - val_loss: 2733.2178\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3410.0410 - val_loss: 2698.5703\n",
      "Epoch 55/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3371.4216 - val_loss: 2664.2654\n",
      "Epoch 56/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3333.1565 - val_loss: 2630.2981\n",
      "Epoch 57/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3295.2419 - val_loss: 2596.6638\n",
      "Epoch 58/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3257.6729 - val_loss: 2563.3584\n",
      "Epoch 59/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3220.4441 - val_loss: 2530.3779\n",
      "Epoch 60/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3183.5518 - val_loss: 2497.7185\n",
      "Epoch 61/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3146.9934 - val_loss: 2465.3772\n",
      "Epoch 62/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3110.7634 - val_loss: 2433.3496\n",
      "Epoch 63/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3074.8591 - val_loss: 2401.6331\n",
      "Epoch 64/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3039.2776 - val_loss: 2370.2236\n",
      "Epoch 65/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3004.0144 - val_loss: 2339.1204\n",
      "Epoch 66/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2969.0681 - val_loss: 2308.3179\n",
      "Epoch 67/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2934.4341 - val_loss: 2277.8145\n",
      "Epoch 68/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2900.1106 - val_loss: 2247.6074\n",
      "Epoch 69/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2866.0947 - val_loss: 2217.6948\n",
      "Epoch 70/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2832.3826 - val_loss: 2188.0732\n",
      "Epoch 71/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2798.9734 - val_loss: 2158.7400\n",
      "Epoch 72/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2765.8640 - val_loss: 2129.6929\n",
      "Epoch 73/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2733.0510 - val_loss: 2100.9299\n",
      "Epoch 74/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2700.5334 - val_loss: 2072.4487\n",
      "Epoch 75/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2668.3081 - val_loss: 2044.2478\n",
      "Epoch 76/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2636.3728 - val_loss: 2016.3232\n",
      "Epoch 77/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2604.7256 - val_loss: 1988.6741\n",
      "Epoch 78/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2573.3640 - val_loss: 1961.2980\n",
      "Epoch 79/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2542.2861 - val_loss: 1934.1929\n",
      "Epoch 80/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2511.4897 - val_loss: 1907.3564\n",
      "Epoch 81/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2480.9724 - val_loss: 1880.7866\n",
      "Epoch 82/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2450.7327 - val_loss: 1854.4825\n",
      "Epoch 83/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2420.7686 - val_loss: 1828.4414\n",
      "Epoch 84/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2391.0779 - val_loss: 1802.6609\n",
      "Epoch 85/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2361.6589 - val_loss: 1777.1401\n",
      "Epoch 86/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2332.5090 - val_loss: 1751.8765\n",
      "Epoch 87/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2303.6272 - val_loss: 1726.8678\n",
      "Epoch 88/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2275.0115 - val_loss: 1702.1134\n",
      "Epoch 89/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2246.6594 - val_loss: 1677.6110\n",
      "Epoch 90/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2218.5698 - val_loss: 1653.3590\n",
      "Epoch 91/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2190.7412 - val_loss: 1629.3558\n",
      "Epoch 92/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2163.1704 - val_loss: 1605.5984\n",
      "Epoch 93/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2135.8574 - val_loss: 1582.0869\n",
      "Epoch 94/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2108.7993 - val_loss: 1558.8179\n",
      "Epoch 95/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 2081.9946 - val_loss: 1535.7906\n",
      "Epoch 96/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2055.4424 - val_loss: 1513.0043\n",
      "Epoch 97/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2029.1401 - val_loss: 1490.4564\n",
      "Epoch 98/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2003.0869 - val_loss: 1468.1445\n",
      "Epoch 99/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1977.2805 - val_loss: 1446.0682\n",
      "Epoch 100/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1951.7192 - val_loss: 1424.2247\n",
      "Epoch 101/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1926.4019 - val_loss: 1402.6144\n",
      "Epoch 102/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1901.3265 - val_loss: 1381.2336\n",
      "Epoch 103/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1876.4921 - val_loss: 1360.0825\n",
      "Epoch 104/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1851.8964 - val_loss: 1339.1583\n",
      "Epoch 105/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1827.5386 - val_loss: 1318.4602\n",
      "Epoch 106/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1803.4172 - val_loss: 1297.9858\n",
      "Epoch 107/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1779.5297 - val_loss: 1277.7341\n",
      "Epoch 108/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1755.8750 - val_loss: 1257.7043\n",
      "Epoch 109/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1732.4515 - val_loss: 1237.8944\n",
      "Epoch 110/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1709.2585 - val_loss: 1218.3020\n",
      "Epoch 111/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1686.2936 - val_loss: 1198.9261\n",
      "Epoch 112/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1663.5554 - val_loss: 1179.7662\n",
      "Epoch 113/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1641.0428 - val_loss: 1160.8191\n",
      "Epoch 114/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1618.7540 - val_loss: 1142.0851\n",
      "Epoch 115/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1596.6886 - val_loss: 1123.5624\n",
      "Epoch 116/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1574.8441 - val_loss: 1105.2496\n",
      "Epoch 117/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1553.2192 - val_loss: 1087.1436\n",
      "Epoch 118/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1531.8119 - val_loss: 1069.2446\n",
      "Epoch 119/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1510.6222 - val_loss: 1051.5514\n",
      "Epoch 120/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1489.6475 - val_loss: 1034.0615\n",
      "Epoch 121/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1468.8878 - val_loss: 1016.7745\n",
      "Epoch 122/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1448.3405 - val_loss: 999.6884\n",
      "Epoch 123/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1428.0043 - val_loss: 982.8016\n",
      "Epoch 124/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1407.8779 - val_loss: 966.1139\n",
      "Epoch 125/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1387.9600 - val_loss: 949.6224\n",
      "Epoch 126/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1368.2493 - val_loss: 933.3265\n",
      "Epoch 127/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1348.7445 - val_loss: 917.2250\n",
      "Epoch 128/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1329.4443 - val_loss: 901.3167\n",
      "Epoch 129/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1310.3475 - val_loss: 885.5991\n",
      "Epoch 130/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1291.4519 - val_loss: 870.0726\n",
      "Epoch 131/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1272.7571 - val_loss: 854.7344\n",
      "Epoch 132/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1254.2614 - val_loss: 839.5834\n",
      "Epoch 133/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1235.9639 - val_loss: 824.6192\n",
      "Epoch 134/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1217.8623 - val_loss: 809.8393\n",
      "Epoch 135/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1199.9564 - val_loss: 795.2431\n",
      "Epoch 136/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1182.2443 - val_loss: 780.8292\n",
      "Epoch 137/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1164.7245 - val_loss: 766.5958\n",
      "Epoch 138/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1147.3961 - val_loss: 752.5429\n",
      "Epoch 139/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1130.2578 - val_loss: 738.6672\n",
      "Epoch 140/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1113.3082 - val_loss: 724.9687\n",
      "Epoch 141/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1096.5460 - val_loss: 711.4460\n",
      "Epoch 142/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1079.9697 - val_loss: 698.0980\n",
      "Epoch 143/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1063.5789 - val_loss: 684.9230\n",
      "Epoch 144/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1047.3715 - val_loss: 671.9199\n",
      "Epoch 145/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1031.3464 - val_loss: 659.0871\n",
      "Epoch 146/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1015.5023 - val_loss: 646.4235\n",
      "Epoch 147/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 999.8381 - val_loss: 633.9283\n",
      "Epoch 148/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 984.3527 - val_loss: 621.5994\n",
      "Epoch 149/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 969.0444 - val_loss: 609.4364\n",
      "Epoch 150/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 953.9122 - val_loss: 597.4376\n",
      "Epoch 151/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 938.9549 - val_loss: 585.6019\n",
      "Epoch 152/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 924.1715 - val_loss: 573.9279\n",
      "Epoch 153/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 909.5604 - val_loss: 562.4142\n",
      "Epoch 154/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 895.1203 - val_loss: 551.0598\n",
      "Epoch 155/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 880.8502 - val_loss: 539.8630\n",
      "Epoch 156/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 866.7488 - val_loss: 528.8237\n",
      "Epoch 157/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 852.8150 - val_loss: 517.9398\n",
      "Epoch 158/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 839.0472 - val_loss: 507.2098\n",
      "Epoch 159/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 825.4446 - val_loss: 496.6333\n",
      "Epoch 160/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 812.0062 - val_loss: 486.2083\n",
      "Epoch 161/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 798.7303 - val_loss: 475.9341\n",
      "Epoch 162/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 785.6161 - val_loss: 465.8095\n",
      "Epoch 163/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 772.6620 - val_loss: 455.8329\n",
      "Epoch 164/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 759.8671 - val_loss: 446.0035\n",
      "Epoch 165/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 747.2301 - val_loss: 436.3201\n",
      "Epoch 166/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 734.7498 - val_loss: 426.7808\n",
      "Epoch 167/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 722.4250 - val_loss: 417.3851\n",
      "Epoch 168/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 710.2545 - val_loss: 408.1312\n",
      "Epoch 169/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 698.2372 - val_loss: 399.0183\n",
      "Epoch 170/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 686.3716 - val_loss: 390.0455\n",
      "Epoch 171/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 674.6573 - val_loss: 381.2113\n",
      "Epoch 172/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 663.0927 - val_loss: 372.5146\n",
      "Epoch 173/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 651.6765 - val_loss: 363.9541\n",
      "Epoch 174/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 640.4073 - val_loss: 355.5281\n",
      "Epoch 175/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 629.2847 - val_loss: 347.2365\n",
      "Epoch 176/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 618.3069 - val_loss: 339.0775\n",
      "Epoch 177/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 607.4731 - val_loss: 331.0501\n",
      "Epoch 178/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 596.7820 - val_loss: 323.1525\n",
      "Epoch 179/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 586.2324 - val_loss: 315.3842\n",
      "Epoch 180/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 575.8231 - val_loss: 307.7444\n",
      "Epoch 181/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 565.5532 - val_loss: 300.2310\n",
      "Epoch 182/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 555.4214 - val_loss: 292.8433\n",
      "Epoch 183/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 545.4267 - val_loss: 285.5800\n",
      "Epoch 184/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 535.5676 - val_loss: 278.4398\n",
      "Epoch 185/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 525.8436 - val_loss: 271.4225\n",
      "Epoch 186/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 516.2530 - val_loss: 264.5256\n",
      "Epoch 187/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 506.7950 - val_loss: 257.7487\n",
      "Epoch 188/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 497.4682 - val_loss: 251.0903\n",
      "Epoch 189/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 488.2715 - val_loss: 244.5502\n",
      "Epoch 190/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 479.2043 - val_loss: 238.1261\n",
      "Epoch 191/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 470.2649 - val_loss: 231.8174\n",
      "Epoch 192/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 461.4524 - val_loss: 225.6227\n",
      "Epoch 193/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 452.7657 - val_loss: 219.5407\n",
      "Epoch 194/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 444.2036 - val_loss: 213.5711\n",
      "Epoch 195/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 435.7648 - val_loss: 207.7119\n",
      "Epoch 196/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 427.4488 - val_loss: 201.9625\n",
      "Epoch 197/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 419.2539 - val_loss: 196.3216\n",
      "Epoch 198/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 411.1793 - val_loss: 190.7879\n",
      "Epoch 199/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 403.2238 - val_loss: 185.3605\n",
      "Epoch 200/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 395.3867 - val_loss: 180.0382\n",
      "Epoch 201/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 387.6663 - val_loss: 174.8201\n",
      "Epoch 202/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 380.0618 - val_loss: 169.7048\n",
      "Epoch 203/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 372.5721 - val_loss: 164.6911\n",
      "Epoch 204/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 365.1962 - val_loss: 159.7781\n",
      "Epoch 205/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 357.9325 - val_loss: 154.9647\n",
      "Epoch 206/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 350.7805 - val_loss: 150.2498\n",
      "Epoch 207/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 343.7391 - val_loss: 145.6321\n",
      "Epoch 208/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 336.8067 - val_loss: 141.1108\n",
      "Epoch 209/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 329.9830 - val_loss: 136.6843\n",
      "Epoch 210/500\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 323.2664 - val_loss: 132.3523\n",
      "Epoch 211/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 316.6559 - val_loss: 128.1131\n",
      "Epoch 212/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 310.1507 - val_loss: 123.9658\n",
      "Epoch 213/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 303.7494 - val_loss: 119.9093\n",
      "Epoch 214/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 297.4512 - val_loss: 115.9424\n",
      "Epoch 215/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 291.2547 - val_loss: 112.0642\n",
      "Epoch 216/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 285.1594 - val_loss: 108.2735\n",
      "Epoch 217/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 279.1638 - val_loss: 104.5694\n",
      "Epoch 218/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 273.2671 - val_loss: 100.9508\n",
      "Epoch 219/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 267.4680 - val_loss: 97.4166\n",
      "Epoch 220/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 261.7660 - val_loss: 93.9655\n",
      "Epoch 221/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 256.1593 - val_loss: 90.5967\n",
      "Epoch 222/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 250.6475 - val_loss: 87.3092\n",
      "Epoch 223/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 245.2293 - val_loss: 84.1018\n",
      "Epoch 224/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 239.9035 - val_loss: 80.9734\n",
      "Epoch 225/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 234.6695 - val_loss: 77.9229\n",
      "Epoch 226/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 229.5261 - val_loss: 74.9496\n",
      "Epoch 227/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 224.4719 - val_loss: 72.0519\n",
      "Epoch 228/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 219.5064 - val_loss: 69.2296\n",
      "Epoch 229/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 214.6283 - val_loss: 66.4809\n",
      "Epoch 230/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 209.8368 - val_loss: 63.8050\n",
      "Epoch 231/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 205.1307 - val_loss: 61.2013\n",
      "Epoch 232/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 200.5094 - val_loss: 58.6681\n",
      "Epoch 233/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 195.9715 - val_loss: 56.2048\n",
      "Epoch 234/500\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 191.5161 - val_loss: 53.8101\n",
      "Epoch 235/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 187.1421 - val_loss: 51.4834\n",
      "Epoch 236/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 182.8488 - val_loss: 49.2234\n",
      "Epoch 237/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 178.6351 - val_loss: 47.0292\n",
      "Epoch 238/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 174.4998 - val_loss: 44.8998\n",
      "Epoch 239/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 170.4424 - val_loss: 42.8342\n",
      "Epoch 240/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 166.4614 - val_loss: 40.8315\n",
      "Epoch 241/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 162.5563 - val_loss: 38.8903\n",
      "Epoch 242/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 158.7256 - val_loss: 37.0102\n",
      "Epoch 243/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 154.9689 - val_loss: 35.1897\n",
      "Epoch 244/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 151.2851 - val_loss: 33.4285\n",
      "Epoch 245/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 147.6728 - val_loss: 31.7249\n",
      "Epoch 246/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 144.1316 - val_loss: 30.0784\n",
      "Epoch 247/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 140.6605 - val_loss: 28.4881\n",
      "Epoch 248/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 137.2582 - val_loss: 26.9525\n",
      "Epoch 249/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 133.9241 - val_loss: 25.4712\n",
      "Epoch 250/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 130.6571 - val_loss: 24.0430\n",
      "Epoch 251/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 127.4565 - val_loss: 22.6673\n",
      "Epoch 252/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 124.3212 - val_loss: 21.3426\n",
      "Epoch 253/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 121.2501 - val_loss: 20.0684\n",
      "Epoch 254/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 118.2429 - val_loss: 18.8440\n",
      "Epoch 255/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 115.2982 - val_loss: 17.6679\n",
      "Epoch 256/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 112.4151 - val_loss: 16.5394\n",
      "Epoch 257/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 109.5927 - val_loss: 15.4578\n",
      "Epoch 258/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 106.8305 - val_loss: 14.4220\n",
      "Epoch 259/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 104.1271 - val_loss: 13.4313\n",
      "Epoch 260/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 101.4822 - val_loss: 12.4847\n",
      "Epoch 261/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 98.8943 - val_loss: 11.5812\n",
      "Epoch 262/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 96.3627 - val_loss: 10.7202\n",
      "Epoch 263/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 93.8869 - val_loss: 9.9005\n",
      "Epoch 264/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 91.4659 - val_loss: 9.1216\n",
      "Epoch 265/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 89.0987 - val_loss: 8.3825\n",
      "Epoch 266/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 86.7845 - val_loss: 7.6823\n",
      "Epoch 267/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 84.5225 - val_loss: 7.0202\n",
      "Epoch 268/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 82.3117 - val_loss: 6.3954\n",
      "Epoch 269/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 80.1516 - val_loss: 5.8070\n",
      "Epoch 270/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 78.0412 - val_loss: 5.2545\n",
      "Epoch 271/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 75.9799 - val_loss: 4.7366\n",
      "Epoch 272/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 73.9666 - val_loss: 4.2528\n",
      "Epoch 273/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 72.0004 - val_loss: 3.8022\n",
      "Epoch 274/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 70.0808 - val_loss: 3.3840\n",
      "Epoch 275/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 68.2070 - val_loss: 2.9975\n",
      "Epoch 276/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 66.3780 - val_loss: 2.6419\n",
      "Epoch 277/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 64.5933 - val_loss: 2.3165\n",
      "Epoch 278/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 62.8520 - val_loss: 2.0203\n",
      "Epoch 279/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 61.1531 - val_loss: 1.7528\n",
      "Epoch 280/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 59.4961 - val_loss: 1.5131\n",
      "Epoch 281/500\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 57.8804 - val_loss: 1.3006\n",
      "Epoch 282/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 56.3045 - val_loss: 1.1144\n",
      "Epoch 283/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 54.7685 - val_loss: 0.9539\n",
      "Epoch 284/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 53.2714 - val_loss: 0.8184\n",
      "Epoch 285/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 51.8124 - val_loss: 0.7071\n",
      "Epoch 286/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 50.3910 - val_loss: 0.6194\n",
      "Epoch 287/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 49.0062 - val_loss: 0.5546\n",
      "Epoch 288/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.6575 - val_loss: 0.5120\n",
      "Epoch 289/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 46.3440 - val_loss: 0.4909\n",
      "Epoch 290/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 45.0652 - val_loss: 0.4906\n",
      "Epoch 291/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.8204 - val_loss: 0.5105\n",
      "Epoch 292/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 42.6090 - val_loss: 0.5500\n",
      "Epoch 293/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.4300 - val_loss: 0.6084\n",
      "Epoch 294/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.2831 - val_loss: 0.6851\n",
      "Epoch 295/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.1674 - val_loss: 0.7795\n",
      "Epoch 296/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.0824 - val_loss: 0.8909\n",
      "Epoch 297/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.0275 - val_loss: 1.0188\n",
      "Epoch 298/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.0017 - val_loss: 1.1625\n",
      "Epoch 299/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.0049 - val_loss: 1.3215\n",
      "Epoch 300/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 34.0363 - val_loss: 1.4952\n",
      "Epoch 301/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 33.0952 - val_loss: 1.6830\n",
      "Epoch 302/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 32.1810 - val_loss: 1.8844\n",
      "Epoch 303/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 31.2932 - val_loss: 2.0988\n",
      "Epoch 304/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.4311 - val_loss: 2.3256\n",
      "Epoch 305/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 29.5942 - val_loss: 2.5645\n",
      "Epoch 306/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 28.7820 - val_loss: 2.8147\n",
      "Epoch 307/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 27.9938 - val_loss: 3.0758\n",
      "Epoch 308/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 27.2290 - val_loss: 3.3473\n",
      "Epoch 309/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 26.4873 - val_loss: 3.6288\n",
      "Epoch 310/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 25.7681 - val_loss: 3.9196\n",
      "Epoch 311/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 25.0707 - val_loss: 4.2194\n",
      "Epoch 312/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 24.3947 - val_loss: 4.5277\n",
      "Epoch 313/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.7395 - val_loss: 4.8440\n",
      "Epoch 314/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 23.1046 - val_loss: 5.1677\n",
      "Epoch 315/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 22.4897 - val_loss: 5.4988\n",
      "Epoch 316/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 21.8940 - val_loss: 5.8364\n",
      "Epoch 317/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.3174 - val_loss: 6.1803\n",
      "Epoch 318/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.7591 - val_loss: 6.5299\n",
      "Epoch 319/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.2189 - val_loss: 6.8852\n",
      "Epoch 320/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 19.6959 - val_loss: 7.2454\n",
      "Epoch 321/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 19.1901 - val_loss: 7.6103\n",
      "Epoch 322/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 18.7008 - val_loss: 7.9795\n",
      "Epoch 323/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 18.2278 - val_loss: 8.3525\n",
      "Epoch 324/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 17.7704 - val_loss: 8.7291\n",
      "Epoch 325/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 17.3284 - val_loss: 9.1089\n",
      "Epoch 326/500\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 16.9011 - val_loss: 9.4916\n",
      "Epoch 327/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 16.4884 - val_loss: 9.8769\n",
      "Epoch 328/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 16.0898 - val_loss: 10.2642\n",
      "Epoch 329/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 15.7049 - val_loss: 10.6534\n",
      "Epoch 330/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 15.3333 - val_loss: 11.0443\n",
      "Epoch 331/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 14.9746 - val_loss: 11.4365\n",
      "Epoch 332/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 14.6284 - val_loss: 11.8297\n",
      "Epoch 333/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 14.2945 - val_loss: 12.2235\n",
      "Epoch 334/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 13.9724 - val_loss: 12.6178\n",
      "Epoch 335/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 13.6618 - val_loss: 13.0122\n",
      "Epoch 336/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 13.3623 - val_loss: 13.4067\n",
      "Epoch 337/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 13.0737 - val_loss: 13.8007\n",
      "Epoch 338/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 12.7955 - val_loss: 14.1941\n",
      "Epoch 339/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 12.5276 - val_loss: 14.5868\n",
      "Epoch 340/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 12.2696 - val_loss: 14.9783\n",
      "Epoch 341/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 12.0212 - val_loss: 15.3686\n",
      "Epoch 342/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 11.7820 - val_loss: 15.7575\n",
      "Epoch 343/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 11.5518 - val_loss: 16.1447\n",
      "Epoch 344/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.3303 - val_loss: 16.5300\n",
      "Epoch 345/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 11.1172 - val_loss: 16.9134\n",
      "Epoch 346/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.9122 - val_loss: 17.2945\n",
      "Epoch 347/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.7152 - val_loss: 17.6734\n",
      "Epoch 348/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.5258 - val_loss: 18.0495\n",
      "Epoch 349/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.3438 - val_loss: 18.4231\n",
      "Epoch 350/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 10.1689 - val_loss: 18.7936\n",
      "Epoch 351/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 10.0009 - val_loss: 19.1614\n",
      "Epoch 352/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.8395 - val_loss: 19.5257\n",
      "Epoch 353/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.6847 - val_loss: 19.8869\n",
      "Epoch 354/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.5360 - val_loss: 20.2447\n",
      "Epoch 355/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.3933 - val_loss: 20.5990\n",
      "Epoch 356/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.2564 - val_loss: 20.9498\n",
      "Epoch 357/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.1252 - val_loss: 21.2967\n",
      "Epoch 358/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.9993 - val_loss: 21.6400\n",
      "Epoch 359/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.8786 - val_loss: 21.9794\n",
      "Epoch 360/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.7629 - val_loss: 22.3147\n",
      "Epoch 361/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.6520 - val_loss: 22.6460\n",
      "Epoch 362/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.5458 - val_loss: 22.9731\n",
      "Epoch 363/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.4441 - val_loss: 23.2959\n",
      "Epoch 364/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.3467 - val_loss: 23.6145\n",
      "Epoch 365/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.2535 - val_loss: 23.9289\n",
      "Epoch 366/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.1642 - val_loss: 24.2389\n",
      "Epoch 367/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.0788 - val_loss: 24.5441\n",
      "Epoch 368/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.9971 - val_loss: 24.8451\n",
      "Epoch 369/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.9190 - val_loss: 25.1417\n",
      "Epoch 370/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.8443 - val_loss: 25.4337\n",
      "Epoch 371/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.7728 - val_loss: 25.7212\n",
      "Epoch 372/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.7046 - val_loss: 26.0037\n",
      "Epoch 373/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.6394 - val_loss: 26.2819\n",
      "Epoch 374/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.5770 - val_loss: 26.5554\n",
      "Epoch 375/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.5175 - val_loss: 26.8242\n",
      "Epoch 376/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.4607 - val_loss: 27.0886\n",
      "Epoch 377/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.4064 - val_loss: 27.3483\n",
      "Epoch 378/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.3546 - val_loss: 27.6032\n",
      "Epoch 379/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.3052 - val_loss: 27.8534\n",
      "Epoch 380/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.2580 - val_loss: 28.0992\n",
      "Epoch 381/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.2130 - val_loss: 28.3403\n",
      "Epoch 382/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.1700 - val_loss: 28.5767\n",
      "Epoch 383/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.1291 - val_loss: 28.8085\n",
      "Epoch 384/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.0901 - val_loss: 29.0356\n",
      "Epoch 385/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.0529 - val_loss: 29.2582\n",
      "Epoch 386/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.0175 - val_loss: 29.4766\n",
      "Epoch 387/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.9837 - val_loss: 29.6902\n",
      "Epoch 388/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.9515 - val_loss: 29.8992\n",
      "Epoch 389/500\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.9208 - val_loss: 30.1038\n",
      "Epoch 390/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.8917 - val_loss: 30.3039\n",
      "Epoch 391/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.8639 - val_loss: 30.4999\n",
      "Epoch 392/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.8374 - val_loss: 30.6915\n",
      "Epoch 393/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.8122 - val_loss: 30.8784\n",
      "Epoch 394/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.7882 - val_loss: 31.0615\n",
      "Epoch 395/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.7654 - val_loss: 31.2404\n",
      "Epoch 396/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.7437 - val_loss: 31.4150\n",
      "Epoch 397/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.7230 - val_loss: 31.5854\n",
      "Epoch 398/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.7034 - val_loss: 31.7518\n",
      "Epoch 399/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.6847 - val_loss: 31.9141\n",
      "Epoch 400/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.6669 - val_loss: 32.0728\n",
      "Epoch 401/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.6500 - val_loss: 32.2271\n",
      "Epoch 402/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.6339 - val_loss: 32.3775\n",
      "Epoch 403/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.6187 - val_loss: 32.5244\n",
      "Epoch 404/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.6041 - val_loss: 32.6672\n",
      "Epoch 405/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.5904 - val_loss: 32.8065\n",
      "Epoch 406/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.5772 - val_loss: 32.9420\n",
      "Epoch 407/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.5648 - val_loss: 33.0739\n",
      "Epoch 408/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 6.5530 - val_loss: 33.2025\n",
      "Epoch 409/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.5417 - val_loss: 33.3276\n",
      "Epoch 410/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.5310 - val_loss: 33.4490\n",
      "Epoch 411/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.5208 - val_loss: 33.5673\n",
      "Epoch 412/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.5112 - val_loss: 33.6822\n",
      "Epoch 413/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.5021 - val_loss: 33.7938\n",
      "Epoch 414/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.4933 - val_loss: 33.9023\n",
      "Epoch 415/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.4851 - val_loss: 34.0077\n",
      "Epoch 416/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4772 - val_loss: 34.1101\n",
      "Epoch 417/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4697 - val_loss: 34.2093\n",
      "Epoch 418/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4627 - val_loss: 34.3056\n",
      "Epoch 419/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4559 - val_loss: 34.3991\n",
      "Epoch 420/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4495 - val_loss: 34.4897\n",
      "Epoch 421/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4435 - val_loss: 34.5778\n",
      "Epoch 422/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.4377 - val_loss: 34.6630\n",
      "Epoch 423/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4322 - val_loss: 34.7454\n",
      "Epoch 424/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.4270 - val_loss: 34.8255\n",
      "Epoch 425/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.4221 - val_loss: 34.9030\n",
      "Epoch 426/500\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 6.4174 - val_loss: 34.9780\n",
      "Epoch 427/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4129 - val_loss: 35.0506\n",
      "Epoch 428/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.4087 - val_loss: 35.1208\n",
      "Epoch 429/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4047 - val_loss: 35.1886\n",
      "Epoch 430/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.4009 - val_loss: 35.2543\n",
      "Epoch 431/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3972 - val_loss: 35.3177\n",
      "Epoch 432/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3938 - val_loss: 35.3793\n",
      "Epoch 433/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3905 - val_loss: 35.4384\n",
      "Epoch 434/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3874 - val_loss: 35.4956\n",
      "Epoch 435/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3845 - val_loss: 35.5508\n",
      "Epoch 436/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3817 - val_loss: 35.6043\n",
      "Epoch 437/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3790 - val_loss: 35.6558\n",
      "Epoch 438/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3765 - val_loss: 35.7054\n",
      "Epoch 439/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3741 - val_loss: 35.7533\n",
      "Epoch 440/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3718 - val_loss: 35.7995\n",
      "Epoch 441/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3696 - val_loss: 35.8440\n",
      "Epoch 442/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3676 - val_loss: 35.8868\n",
      "Epoch 443/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3656 - val_loss: 35.9282\n",
      "Epoch 444/500\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 6.3638 - val_loss: 35.9680\n",
      "Epoch 445/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3620 - val_loss: 36.0065\n",
      "Epoch 446/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 6.3603 - val_loss: 36.0432\n",
      "Epoch 447/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 6.3588 - val_loss: 36.0788\n",
      "Epoch 448/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3572 - val_loss: 36.1127\n",
      "Epoch 449/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3558 - val_loss: 36.1452\n",
      "Epoch 450/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3545 - val_loss: 36.1770\n",
      "Epoch 451/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3532 - val_loss: 36.2069\n",
      "Epoch 452/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3520 - val_loss: 36.2361\n",
      "Epoch 453/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3508 - val_loss: 36.2642\n",
      "Epoch 454/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3497 - val_loss: 36.2909\n",
      "Epoch 455/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3486 - val_loss: 36.3166\n",
      "Epoch 456/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3477 - val_loss: 36.3414\n",
      "Epoch 457/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3467 - val_loss: 36.3651\n",
      "Epoch 458/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3458 - val_loss: 36.3878\n",
      "Epoch 459/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3450 - val_loss: 36.4096\n",
      "Epoch 460/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3442 - val_loss: 36.4304\n",
      "Epoch 461/500\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 6.3434 - val_loss: 36.4503\n",
      "Epoch 462/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3427 - val_loss: 36.4692\n",
      "Epoch 463/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3421 - val_loss: 36.4876\n",
      "Epoch 464/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3414 - val_loss: 36.5051\n",
      "Epoch 465/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3408 - val_loss: 36.5218\n",
      "Epoch 466/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3402 - val_loss: 36.5375\n",
      "Epoch 467/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3397 - val_loss: 36.5528\n",
      "Epoch 468/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3392 - val_loss: 36.5674\n",
      "Epoch 469/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3387 - val_loss: 36.5814\n",
      "Epoch 470/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3382 - val_loss: 36.5947\n",
      "Epoch 471/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3378 - val_loss: 36.6075\n",
      "Epoch 472/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3374 - val_loss: 36.6193\n",
      "Epoch 473/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.3370 - val_loss: 36.6310\n",
      "Epoch 474/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3367 - val_loss: 36.6420\n",
      "Epoch 475/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3364 - val_loss: 36.6524\n",
      "Epoch 476/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3360 - val_loss: 36.6623\n",
      "Epoch 477/500\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 6.3358 - val_loss: 36.6716\n",
      "Epoch 478/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3355 - val_loss: 36.6809\n",
      "Epoch 479/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3352 - val_loss: 36.6894\n",
      "Epoch 480/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3350 - val_loss: 36.6976\n",
      "Epoch 481/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3348 - val_loss: 36.7054\n",
      "Epoch 482/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3346 - val_loss: 36.7127\n",
      "Epoch 483/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3344 - val_loss: 36.7198\n",
      "Epoch 484/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3342 - val_loss: 36.7263\n",
      "Epoch 485/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3340 - val_loss: 36.7329\n",
      "Epoch 486/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3339 - val_loss: 36.7389\n",
      "Epoch 487/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3337 - val_loss: 36.7444\n",
      "Epoch 488/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3336 - val_loss: 36.7499\n",
      "Epoch 489/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3335 - val_loss: 36.7548\n",
      "Epoch 490/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3334 - val_loss: 36.7598\n",
      "Epoch 491/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.3333 - val_loss: 36.7643\n",
      "Epoch 492/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3332 - val_loss: 36.7686\n",
      "Epoch 493/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.3331 - val_loss: 36.7728\n",
      "Epoch 494/500\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 6.3331 - val_loss: 36.7767\n",
      "Epoch 495/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3330 - val_loss: 36.7803\n",
      "Epoch 496/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3329 - val_loss: 36.7838\n",
      "Epoch 497/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.3329 - val_loss: 36.7869\n",
      "Epoch 498/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3329 - val_loss: 36.7898\n",
      "Epoch 499/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3328 - val_loss: 36.7929\n",
      "Epoch 500/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.3328 - val_loss: 36.7954\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(89.3180, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0010, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(-0.0204, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.2194, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 401ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.45491597e+01, 7.44875350e+01, 7.44259104e+01, 7.43642857e+01,\n",
       "        7.43026611e+01, 7.42410364e+01, 7.41794118e+01, 7.41177871e+01,\n",
       "        7.40561625e+01, 7.39945378e+01, 7.39329132e+01, 7.38712885e+01,\n",
       "        7.38096639e+01, 7.37480392e+01, 7.36864146e+01, 7.36247899e+01,\n",
       "        7.35631653e+01, 7.35015406e+01, 7.34587605e+01, 7.34164636e+01,\n",
       "        7.33741667e+01, 7.33318697e+01, 7.32895728e+01, 7.32472759e+01,\n",
       "        7.32049790e+01, 7.31626821e+01, 7.31203852e+01, 7.30780882e+01,\n",
       "        7.30357913e+01, 7.29934944e+01, 7.29511975e+01, 7.29089006e+01,\n",
       "        7.28666036e+01, 7.28243067e+01, 7.27820098e+01, 7.27397129e+01,\n",
       "        7.26974160e+01, 7.26551190e+01, 7.26128221e+01, 7.25705252e+01,\n",
       "        7.25282283e+01, 7.24859314e+01, 7.24436345e+01, 7.24013375e+01,\n",
       "        7.23590406e+01, 7.23167437e+01, 7.22744468e+01, 7.22321499e+01,\n",
       "        7.21898529e+01, 7.21475560e+01, 7.21052591e+01, 7.20629622e+01,\n",
       "        7.20206653e+01, 7.19869958e+01, 7.19760714e+01, 7.19651471e+01,\n",
       "        7.19542227e+01, 7.19432983e+01, 7.19323739e+01, 7.19214496e+01,\n",
       "        7.19105252e+01, 7.18996008e+01, 7.18886765e+01, 7.18777521e+01,\n",
       "        7.18668277e+01, 7.18559034e+01, 7.18449790e+01, 7.18340546e+01,\n",
       "        7.18231303e+01, 7.18122059e+01, 7.18012815e+01, 7.17903571e+01,\n",
       "        7.17794328e+01, 7.17685084e+01, 7.17575840e+01, 7.17466597e+01,\n",
       "        7.17357353e+01, 7.17248109e+01, 7.17138865e+01, 7.17029622e+01,\n",
       "        7.84811325e+01, 0.00000000e+00, 6.18121803e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.48647083e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.48702437e-01, 0.00000000e+00,\n",
       "        3.93034741e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.30836868e-01, 0.00000000e+00, 0.00000000e+00, 1.36577690e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70.02908497, 70.01601307, 70.00294118, 69.98986928, 69.97679739,\n",
       "       69.96372549, 69.95065359, 69.9375817 , 69.9245098 , 69.91143791,\n",
       "       69.89836601, 69.88529412, 69.87222222, 69.85915033, 69.84607843,\n",
       "       69.83300654, 69.81993464, 69.80686275, 69.79379085, 69.78071895,\n",
       "       69.76764706, 69.75457516, 69.74150327, 69.72843137, 69.71535948,\n",
       "       69.70228758, 69.68921569, 69.67614379, 69.6630719 , 69.65      ,\n",
       "       69.6369281 , 69.62385621, 69.61078431, 69.59771242, 69.58464052,\n",
       "       69.57156863, 69.55849673, 69.54542484, 69.53235294, 69.51928105,\n",
       "       69.50620915, 69.49656863, 69.49003268, 69.48349673, 69.47696078,\n",
       "       69.47042484, 69.46388889, 69.45735294, 69.45081699, 69.44428105,\n",
       "       69.4377451 , 69.43120915, 69.4246732 , 69.41813725, 69.41160131,\n",
       "       69.40506536, 69.39852941, 69.39199346, 69.38545752, 69.37892157,\n",
       "       69.37238562, 69.36584967, 69.35931373, 69.35277778, 69.34624183,\n",
       "       69.33970588, 69.33316993, 69.32663399, 69.32009804, 69.31356209,\n",
       "       69.30702614, 69.3004902 , 69.29395425, 69.2874183 , 69.28088235,\n",
       "       69.27434641, 69.26781046, 69.26127451, 69.25473856, 69.24820261,\n",
       "       69.24166667, 69.23513072, 69.22859477, 69.22205882, 69.21552288,\n",
       "       69.20898693, 69.20245098, 69.19591503, 69.18937908, 69.18284314,\n",
       "       69.17630719, 69.16977124, 69.16323529, 69.15669935, 69.1501634 ,\n",
       "       69.14362745, 69.1370915 , 69.13055556, 69.12401961, 69.11748366])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.234777269924606\n",
      "15.726958138606065\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
