{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "1645    68.755719\n",
       "1646    68.754785\n",
       "1647    68.753852\n",
       "1648    68.752918\n",
       "1649    68.751984\n",
       "Name: C7, Length: 1650, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c7_interpolated_1550_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "1545     0.000000\n",
       "1546     0.730837\n",
       "1547     0.000000\n",
       "1548     0.000000\n",
       "1549     1.365777\n",
       "Name: C7, Length: 1550, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1550)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.387115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.174230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.961345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.748459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     92.600000  0.000298\n",
       "1     92.387115  0.000298\n",
       "2     92.174230  0.000297\n",
       "3     91.961345  0.000297\n",
       "4     91.748459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 89.3180  # Value for C0\n",
    "K0 = -0.0010  # Value for K0\n",
    "K1 = 0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = -0.0204    # Value for b\n",
    "c = 2.2194    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    92.600000    92.387115    92.174230    91.961345    91.748459   \n",
      "351    92.387115    92.174230    91.961345    91.748459    91.535574   \n",
      "352    92.174230    91.961345    91.748459    91.535574    91.322689   \n",
      "353    91.961345    91.748459    91.535574    91.322689    91.109804   \n",
      "354    91.748459    91.535574    91.322689    91.109804    90.896919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    91.535574    91.322689    91.109804    90.896919    90.691597  ...   \n",
      "351    91.322689    91.109804    90.896919    90.691597    90.579552  ...   \n",
      "352    91.109804    90.896919    90.691597    90.579552    90.467507  ...   \n",
      "353    90.896919    90.691597    90.579552    90.467507    90.355462  ...   \n",
      "354    90.691597    90.579552    90.467507    90.355462    90.243417  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   80.261671    0.000263   80.252334    0.000263   80.242997    0.000263   \n",
      "351   80.252334    0.000263   80.242997    0.000263   80.233660    0.000262   \n",
      "352   80.242997    0.000263   80.233660    0.000262   80.224323    0.000262   \n",
      "353   80.233660    0.000262   80.224323    0.000262   80.214986    0.000262   \n",
      "354   80.224323    0.000262   80.214986    0.000262   80.205649    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   80.233660    0.000262   80.224323    0.000262  \n",
      "351   80.224323    0.000262   80.214986    0.000262  \n",
      "352   80.214986    0.000262   80.205649    0.000262  \n",
      "353   80.205649    0.000262   80.196312    0.000262  \n",
      "354   80.196312    0.000262   80.186975    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 1, 251) (1100, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "14/14 [==============================] - 3s 42ms/step - loss: 5960.3667 - val_loss: 4768.3853\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 5885.7407 - val_loss: 4722.0488\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 5830.8115 - val_loss: 4660.3828\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5758.9175 - val_loss: 4612.6470\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5703.1084 - val_loss: 4565.0898\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5647.7314 - val_loss: 4518.0547\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5592.9189 - val_loss: 4471.5234\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5538.6294 - val_loss: 4425.4556\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5484.8232 - val_loss: 4371.5371\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5420.4902 - val_loss: 4323.6602\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5364.1460 - val_loss: 4275.9653\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5308.4458 - val_loss: 4229.0322\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5253.5620 - val_loss: 4182.7876\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5199.3882 - val_loss: 4137.1411\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 5145.8369 - val_loss: 4092.0308\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5092.8452 - val_loss: 4047.4148\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5040.3735 - val_loss: 4003.2656\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4988.3916 - val_loss: 3959.5613\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4936.8799 - val_loss: 3916.2869\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4885.8208 - val_loss: 3873.4299\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 4835.2036 - val_loss: 3830.9802\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4785.0166 - val_loss: 3788.9292\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4735.2515 - val_loss: 3747.2712\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4685.9004 - val_loss: 3705.9983\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4636.9575 - val_loss: 3665.1064\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4588.4160 - val_loss: 3624.5896\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4540.2715 - val_loss: 3584.4446\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 4492.5205 - val_loss: 3544.6655\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4445.1572 - val_loss: 3505.2505\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4398.1772 - val_loss: 3466.1946\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4351.5776 - val_loss: 3427.4954\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4305.3555 - val_loss: 3389.1499\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4259.5059 - val_loss: 3351.1541\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4214.0269 - val_loss: 3313.5054\n",
      "Epoch 35/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4168.9146 - val_loss: 3276.2017\n",
      "Epoch 36/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4124.1675 - val_loss: 3239.2390\n",
      "Epoch 37/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4079.7820 - val_loss: 3202.6152\n",
      "Epoch 38/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4035.7551 - val_loss: 3166.3286\n",
      "Epoch 39/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 3992.0850 - val_loss: 3130.3765\n",
      "Epoch 40/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 3948.7676 - val_loss: 3094.7559\n",
      "Epoch 41/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3905.8018 - val_loss: 3059.4648\n",
      "Epoch 42/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3863.1853 - val_loss: 3024.5002\n",
      "Epoch 43/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 3820.9148 - val_loss: 2989.8616\n",
      "Epoch 44/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3778.9885 - val_loss: 2955.5457\n",
      "Epoch 45/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3737.4043 - val_loss: 2921.5498\n",
      "Epoch 46/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3696.1597 - val_loss: 2887.8721\n",
      "Epoch 47/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3655.2529 - val_loss: 2854.5117\n",
      "Epoch 48/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3614.6812 - val_loss: 2821.4651\n",
      "Epoch 49/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3574.4426 - val_loss: 2788.7305\n",
      "Epoch 50/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3534.5349 - val_loss: 2756.3057\n",
      "Epoch 51/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3494.9565 - val_loss: 2724.1890\n",
      "Epoch 52/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3455.7051 - val_loss: 2692.3796\n",
      "Epoch 53/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3416.7793 - val_loss: 2660.8733\n",
      "Epoch 54/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3378.1755 - val_loss: 2629.6699\n",
      "Epoch 55/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3339.8928 - val_loss: 2598.7668\n",
      "Epoch 56/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3301.9294 - val_loss: 2568.1628\n",
      "Epoch 57/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3264.2832 - val_loss: 2537.8542\n",
      "Epoch 58/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3226.9524 - val_loss: 2507.8408\n",
      "Epoch 59/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3189.9346 - val_loss: 2478.1208\n",
      "Epoch 60/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3153.2285 - val_loss: 2448.6912\n",
      "Epoch 61/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3116.8320 - val_loss: 2419.5510\n",
      "Epoch 62/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3080.7434 - val_loss: 2390.6992\n",
      "Epoch 63/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3044.9602 - val_loss: 2362.1321\n",
      "Epoch 64/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3009.4819 - val_loss: 2333.8489\n",
      "Epoch 65/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2974.3057 - val_loss: 2305.8484\n",
      "Epoch 66/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2939.4302 - val_loss: 2278.1282\n",
      "Epoch 67/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2904.8528 - val_loss: 2250.6858\n",
      "Epoch 68/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2870.5730 - val_loss: 2223.5222\n",
      "Epoch 69/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2836.5886 - val_loss: 2196.6326\n",
      "Epoch 70/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2802.8979 - val_loss: 2170.0166\n",
      "Epoch 71/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2769.4988 - val_loss: 2143.6726\n",
      "Epoch 72/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2736.3904 - val_loss: 2117.5991\n",
      "Epoch 73/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2703.5696 - val_loss: 2091.7939\n",
      "Epoch 74/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2671.0359 - val_loss: 2066.2556\n",
      "Epoch 75/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2638.7878 - val_loss: 2040.9821\n",
      "Epoch 76/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2606.8230 - val_loss: 2015.9720\n",
      "Epoch 77/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2575.1394 - val_loss: 1991.2250\n",
      "Epoch 78/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2543.7366 - val_loss: 1966.7369\n",
      "Epoch 79/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2512.6125 - val_loss: 1942.5088\n",
      "Epoch 80/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2481.7649 - val_loss: 1918.5372\n",
      "Epoch 81/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2451.1931 - val_loss: 1894.8215\n",
      "Epoch 82/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2420.8953 - val_loss: 1871.3594\n",
      "Epoch 83/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2390.8687 - val_loss: 1848.1497\n",
      "Epoch 84/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2361.1130 - val_loss: 1825.1903\n",
      "Epoch 85/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2331.6257 - val_loss: 1802.4806\n",
      "Epoch 86/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2302.4070 - val_loss: 1780.0186\n",
      "Epoch 87/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2273.4529 - val_loss: 1757.8022\n",
      "Epoch 88/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2244.7637 - val_loss: 1735.8309\n",
      "Epoch 89/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2216.3372 - val_loss: 1714.1024\n",
      "Epoch 90/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2188.1714 - val_loss: 1692.6149\n",
      "Epoch 91/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2160.2664 - val_loss: 1671.3678\n",
      "Epoch 92/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2132.6189 - val_loss: 1650.3593\n",
      "Epoch 93/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2105.2280 - val_loss: 1629.5875\n",
      "Epoch 94/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2078.0925 - val_loss: 1609.0515\n",
      "Epoch 95/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2051.2104 - val_loss: 1588.7491\n",
      "Epoch 96/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2024.5807 - val_loss: 1568.6790\n",
      "Epoch 97/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1998.2019 - val_loss: 1548.8403\n",
      "Epoch 98/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1972.0714 - val_loss: 1529.2310\n",
      "Epoch 99/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1946.1891 - val_loss: 1509.8490\n",
      "Epoch 100/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1920.5529 - val_loss: 1490.6942\n",
      "Epoch 101/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1895.1620 - val_loss: 1471.7642\n",
      "Epoch 102/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1870.0137 - val_loss: 1453.0579\n",
      "Epoch 103/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1845.1079 - val_loss: 1434.5743\n",
      "Epoch 104/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1820.4421 - val_loss: 1416.3104\n",
      "Epoch 105/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1796.0150 - val_loss: 1398.2662\n",
      "Epoch 106/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1771.8263 - val_loss: 1380.4404\n",
      "Epoch 107/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1747.8733 - val_loss: 1362.8298\n",
      "Epoch 108/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1724.1547 - val_loss: 1345.4347\n",
      "Epoch 109/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1700.6696 - val_loss: 1328.2537\n",
      "Epoch 110/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1677.4167 - val_loss: 1311.2842\n",
      "Epoch 111/500\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1654.3942 - val_loss: 1294.5260\n",
      "Epoch 112/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1631.6008 - val_loss: 1277.9769\n",
      "Epoch 113/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1609.0353 - val_loss: 1261.6357\n",
      "Epoch 114/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1586.6956 - val_loss: 1245.5006\n",
      "Epoch 115/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1564.5811 - val_loss: 1229.5709\n",
      "Epoch 116/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1542.6903 - val_loss: 1213.8456\n",
      "Epoch 117/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1521.0216 - val_loss: 1198.3221\n",
      "Epoch 118/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1499.5739 - val_loss: 1182.9999\n",
      "Epoch 119/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1478.3455 - val_loss: 1167.8765\n",
      "Epoch 120/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1457.3352 - val_loss: 1152.9517\n",
      "Epoch 121/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1436.5419 - val_loss: 1138.2239\n",
      "Epoch 122/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1415.9641 - val_loss: 1123.6918\n",
      "Epoch 123/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1395.6000 - val_loss: 1109.3535\n",
      "Epoch 124/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1375.4490 - val_loss: 1095.2084\n",
      "Epoch 125/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1355.5089 - val_loss: 1081.2543\n",
      "Epoch 126/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1335.7792 - val_loss: 1067.4901\n",
      "Epoch 127/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1316.2581 - val_loss: 1053.9148\n",
      "Epoch 128/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1296.9449 - val_loss: 1040.5276\n",
      "Epoch 129/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1277.8376 - val_loss: 1027.3256\n",
      "Epoch 130/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1258.9352 - val_loss: 1014.3087\n",
      "Epoch 131/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1240.2362 - val_loss: 1001.4753\n",
      "Epoch 132/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1221.7393 - val_loss: 988.8236\n",
      "Epoch 133/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1203.4434 - val_loss: 976.3530\n",
      "Epoch 134/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1185.3472 - val_loss: 964.0615\n",
      "Epoch 135/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1167.4493 - val_loss: 951.9483\n",
      "Epoch 136/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1149.7484 - val_loss: 940.0113\n",
      "Epoch 137/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1132.2429 - val_loss: 928.2500\n",
      "Epoch 138/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1114.9318 - val_loss: 916.6629\n",
      "Epoch 139/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1097.8140 - val_loss: 905.2485\n",
      "Epoch 140/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1080.8881 - val_loss: 894.0063\n",
      "Epoch 141/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1064.1533 - val_loss: 882.9340\n",
      "Epoch 142/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1047.6074 - val_loss: 872.0303\n",
      "Epoch 143/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1031.2494 - val_loss: 861.2946\n",
      "Epoch 144/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1015.0786 - val_loss: 850.7245\n",
      "Epoch 145/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 999.0932 - val_loss: 840.3203\n",
      "Epoch 146/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 983.2921 - val_loss: 830.0790\n",
      "Epoch 147/500\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 967.6740 - val_loss: 820.0004\n",
      "Epoch 148/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 952.2374 - val_loss: 810.0833\n",
      "Epoch 149/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 936.9815 - val_loss: 800.3258\n",
      "Epoch 150/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 921.9048 - val_loss: 790.7266\n",
      "Epoch 151/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 907.0060 - val_loss: 781.2847\n",
      "Epoch 152/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 892.2839 - val_loss: 771.9993\n",
      "Epoch 153/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 877.7379 - val_loss: 762.8688\n",
      "Epoch 154/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 863.3661 - val_loss: 753.8911\n",
      "Epoch 155/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 849.1672 - val_loss: 745.0661\n",
      "Epoch 156/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 835.1403 - val_loss: 736.3918\n",
      "Epoch 157/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 821.2839 - val_loss: 727.8672\n",
      "Epoch 158/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 807.5969 - val_loss: 719.4913\n",
      "Epoch 159/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 794.0783 - val_loss: 711.2623\n",
      "Epoch 160/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 780.7267 - val_loss: 703.1796\n",
      "Epoch 161/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 767.5411 - val_loss: 695.2408\n",
      "Epoch 162/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 754.5194 - val_loss: 687.4459\n",
      "Epoch 163/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 741.6614 - val_loss: 679.7928\n",
      "Epoch 164/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 728.9656 - val_loss: 672.2805\n",
      "Epoch 165/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 716.4306 - val_loss: 664.9081\n",
      "Epoch 166/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 704.0552 - val_loss: 657.6740\n",
      "Epoch 167/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 691.8383 - val_loss: 650.5770\n",
      "Epoch 168/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 679.7790 - val_loss: 643.6157\n",
      "Epoch 169/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 667.8754 - val_loss: 636.7892\n",
      "Epoch 170/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 656.1270 - val_loss: 630.0962\n",
      "Epoch 171/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 644.5323 - val_loss: 623.5355\n",
      "Epoch 172/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 633.0902 - val_loss: 617.1049\n",
      "Epoch 173/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 621.7993 - val_loss: 610.8045\n",
      "Epoch 174/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 610.6584 - val_loss: 604.6328\n",
      "Epoch 175/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 599.6667 - val_loss: 598.5877\n",
      "Epoch 176/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 588.8228 - val_loss: 592.6689\n",
      "Epoch 177/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 578.1253 - val_loss: 586.8747\n",
      "Epoch 178/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 567.5732 - val_loss: 581.2039\n",
      "Epoch 179/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 557.1654 - val_loss: 575.6553\n",
      "Epoch 180/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 546.9005 - val_loss: 570.2280\n",
      "Epoch 181/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 536.7780 - val_loss: 564.9207\n",
      "Epoch 182/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 526.7959 - val_loss: 559.7314\n",
      "Epoch 183/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 516.9535 - val_loss: 554.6599\n",
      "Epoch 184/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 507.2493 - val_loss: 549.7045\n",
      "Epoch 185/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 497.6825 - val_loss: 544.8642\n",
      "Epoch 186/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 488.2513 - val_loss: 540.1373\n",
      "Epoch 187/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 478.9551 - val_loss: 535.5229\n",
      "Epoch 188/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 469.7928 - val_loss: 531.0197\n",
      "Epoch 189/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 460.7631 - val_loss: 526.6268\n",
      "Epoch 190/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 451.8651 - val_loss: 522.3431\n",
      "Epoch 191/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 443.0970 - val_loss: 518.1665\n",
      "Epoch 192/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 434.4577 - val_loss: 514.0966\n",
      "Epoch 193/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 425.9465 - val_loss: 510.1317\n",
      "Epoch 194/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 417.5620 - val_loss: 506.2708\n",
      "Epoch 195/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 409.3036 - val_loss: 502.5132\n",
      "Epoch 196/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 401.1696 - val_loss: 498.8572\n",
      "Epoch 197/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 393.1589 - val_loss: 495.3017\n",
      "Epoch 198/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 385.2708 - val_loss: 491.8453\n",
      "Epoch 199/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 377.5038 - val_loss: 488.4873\n",
      "Epoch 200/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 369.8569 - val_loss: 485.2260\n",
      "Epoch 201/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 362.3284 - val_loss: 482.0603\n",
      "Epoch 202/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 354.9179 - val_loss: 478.9891\n",
      "Epoch 203/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 347.6238 - val_loss: 476.0116\n",
      "Epoch 204/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 340.4455 - val_loss: 473.1258\n",
      "Epoch 205/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 333.3813 - val_loss: 470.3311\n",
      "Epoch 206/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 326.4305 - val_loss: 467.6266\n",
      "Epoch 207/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 319.5915 - val_loss: 465.0104\n",
      "Epoch 208/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 312.8637 - val_loss: 462.4816\n",
      "Epoch 209/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 306.2458 - val_loss: 460.0392\n",
      "Epoch 210/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 299.7365 - val_loss: 457.6816\n",
      "Epoch 211/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 293.3347 - val_loss: 455.4085\n",
      "Epoch 212/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 287.0399 - val_loss: 453.2177\n",
      "Epoch 213/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 280.8504 - val_loss: 451.1089\n",
      "Epoch 214/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 274.7653 - val_loss: 449.0804\n",
      "Epoch 215/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 268.7834 - val_loss: 447.1315\n",
      "Epoch 216/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 262.9038 - val_loss: 445.2604\n",
      "Epoch 217/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 257.1251 - val_loss: 443.4664\n",
      "Epoch 218/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 251.4462 - val_loss: 441.7482\n",
      "Epoch 219/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 245.8660 - val_loss: 440.1049\n",
      "Epoch 220/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 240.3838 - val_loss: 438.5351\n",
      "Epoch 221/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 234.9982 - val_loss: 437.0377\n",
      "Epoch 222/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 229.7081 - val_loss: 435.6116\n",
      "Epoch 223/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 224.5126 - val_loss: 434.2558\n",
      "Epoch 224/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 219.4107 - val_loss: 432.9691\n",
      "Epoch 225/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 214.4011 - val_loss: 431.7504\n",
      "Epoch 226/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 209.4830 - val_loss: 430.5985\n",
      "Epoch 227/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 204.6550 - val_loss: 429.5121\n",
      "Epoch 228/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 199.9161 - val_loss: 428.4905\n",
      "Epoch 229/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 195.2657 - val_loss: 427.5324\n",
      "Epoch 230/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 190.7020 - val_loss: 426.6365\n",
      "Epoch 231/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 186.2243 - val_loss: 425.8019\n",
      "Epoch 232/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 181.8315 - val_loss: 425.0276\n",
      "Epoch 233/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 177.5226 - val_loss: 424.3124\n",
      "Epoch 234/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 173.2970 - val_loss: 423.6553\n",
      "Epoch 235/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 169.1529 - val_loss: 423.0549\n",
      "Epoch 236/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 165.0897 - val_loss: 422.5106\n",
      "Epoch 237/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 161.1063 - val_loss: 422.0209\n",
      "Epoch 238/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 157.2014 - val_loss: 421.5849\n",
      "Epoch 239/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 153.3743 - val_loss: 421.2017\n",
      "Epoch 240/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 149.6237 - val_loss: 420.8699\n",
      "Epoch 241/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 145.9490 - val_loss: 420.5887\n",
      "Epoch 242/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 142.3491 - val_loss: 420.3570\n",
      "Epoch 243/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 138.8227 - val_loss: 420.1738\n",
      "Epoch 244/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 135.3690 - val_loss: 420.0379\n",
      "Epoch 245/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 131.9869 - val_loss: 419.9484\n",
      "Epoch 246/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 128.6755 - val_loss: 419.9043\n",
      "Epoch 247/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 125.4339 - val_loss: 419.9044\n",
      "Epoch 248/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 122.2608 - val_loss: 419.9479\n",
      "Epoch 249/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 119.1555 - val_loss: 420.0337\n",
      "Epoch 250/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 116.1168 - val_loss: 420.1608\n",
      "Epoch 251/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 113.1440 - val_loss: 420.3281\n",
      "Epoch 252/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 110.2359 - val_loss: 420.5348\n",
      "Epoch 253/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 107.3917 - val_loss: 420.7797\n",
      "Epoch 254/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 104.6105 - val_loss: 421.0620\n",
      "Epoch 255/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 101.8912 - val_loss: 421.3807\n",
      "Epoch 256/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 99.2329 - val_loss: 421.7348\n",
      "Epoch 257/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 96.6345 - val_loss: 422.1233\n",
      "Epoch 258/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 94.0954 - val_loss: 422.5453\n",
      "Epoch 259/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 91.6144 - val_loss: 422.9999\n",
      "Epoch 260/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 89.1906 - val_loss: 423.4861\n",
      "Epoch 261/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 86.8230 - val_loss: 424.0031\n",
      "Epoch 262/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 84.5111 - val_loss: 424.5497\n",
      "Epoch 263/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 82.2538 - val_loss: 425.1253\n",
      "Epoch 264/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 80.0500 - val_loss: 425.7287\n",
      "Epoch 265/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 77.8991 - val_loss: 426.3593\n",
      "Epoch 266/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 75.7999 - val_loss: 427.0160\n",
      "Epoch 267/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 73.7516 - val_loss: 427.6979\n",
      "Epoch 268/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 71.7537 - val_loss: 428.4043\n",
      "Epoch 269/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 69.8047 - val_loss: 429.1343\n",
      "Epoch 270/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 67.9042 - val_loss: 429.8869\n",
      "Epoch 271/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 66.0512 - val_loss: 430.6615\n",
      "Epoch 272/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 64.2450 - val_loss: 431.4571\n",
      "Epoch 273/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 62.4845 - val_loss: 432.2726\n",
      "Epoch 274/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 60.7691 - val_loss: 433.1077\n",
      "Epoch 275/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 59.0979 - val_loss: 433.9614\n",
      "Epoch 276/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 57.4698 - val_loss: 434.8327\n",
      "Epoch 277/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 55.8843 - val_loss: 435.7211\n",
      "Epoch 278/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 54.3406 - val_loss: 436.6257\n",
      "Epoch 279/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 52.8379 - val_loss: 437.5455\n",
      "Epoch 280/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 51.3754 - val_loss: 438.4801\n",
      "Epoch 281/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 49.9522 - val_loss: 439.4286\n",
      "Epoch 282/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 48.5675 - val_loss: 440.3902\n",
      "Epoch 283/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 47.2207 - val_loss: 441.3642\n",
      "Epoch 284/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 45.9111 - val_loss: 442.3498\n",
      "Epoch 285/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 44.6377 - val_loss: 443.3466\n",
      "Epoch 286/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 43.3998 - val_loss: 444.3535\n",
      "Epoch 287/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 42.1966 - val_loss: 445.3703\n",
      "Epoch 288/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 41.0278 - val_loss: 446.3958\n",
      "Epoch 289/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 39.8921 - val_loss: 447.4295\n",
      "Epoch 290/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 38.7893 - val_loss: 448.4708\n",
      "Epoch 291/500\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 37.7185 - val_loss: 449.5190\n",
      "Epoch 292/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 36.6790 - val_loss: 450.5735\n",
      "Epoch 293/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 35.6699 - val_loss: 451.6337\n",
      "Epoch 294/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 34.6909 - val_loss: 452.6989\n",
      "Epoch 295/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 33.7410 - val_loss: 453.7688\n",
      "Epoch 296/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 32.8198 - val_loss: 454.8422\n",
      "Epoch 297/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 31.9265 - val_loss: 455.9191\n",
      "Epoch 298/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 31.0604 - val_loss: 456.9987\n",
      "Epoch 299/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 30.2210 - val_loss: 458.0801\n",
      "Epoch 300/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 29.4077 - val_loss: 459.1635\n",
      "Epoch 301/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 28.6198 - val_loss: 460.2476\n",
      "Epoch 302/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 27.8567 - val_loss: 461.3325\n",
      "Epoch 303/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 27.1177 - val_loss: 462.4171\n",
      "Epoch 304/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 26.4024 - val_loss: 463.5015\n",
      "Epoch 305/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 25.7100 - val_loss: 464.5850\n",
      "Epoch 306/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 25.0402 - val_loss: 465.6667\n",
      "Epoch 307/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 24.3923 - val_loss: 466.7465\n",
      "Epoch 308/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 23.7656 - val_loss: 467.8243\n",
      "Epoch 309/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 23.1597 - val_loss: 468.8987\n",
      "Epoch 310/500\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 22.5741 - val_loss: 469.9701\n",
      "Epoch 311/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 22.0082 - val_loss: 471.0380\n",
      "Epoch 312/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 21.4613 - val_loss: 472.1018\n",
      "Epoch 313/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 20.9332 - val_loss: 473.1610\n",
      "Epoch 314/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 20.4233 - val_loss: 474.2154\n",
      "Epoch 315/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 19.9311 - val_loss: 475.2644\n",
      "Epoch 316/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 19.4560 - val_loss: 476.3077\n",
      "Epoch 317/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.9977 - val_loss: 477.3450\n",
      "Epoch 318/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.5556 - val_loss: 478.3759\n",
      "Epoch 319/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.1294 - val_loss: 479.4002\n",
      "Epoch 320/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7184 - val_loss: 480.4176\n",
      "Epoch 321/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.3223 - val_loss: 481.4279\n",
      "Epoch 322/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 16.9407 - val_loss: 482.4305\n",
      "Epoch 323/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 16.5730 - val_loss: 483.4253\n",
      "Epoch 324/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 16.2190 - val_loss: 484.4119\n",
      "Epoch 325/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 15.8782 - val_loss: 485.3904\n",
      "Epoch 326/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 15.5501 - val_loss: 486.3599\n",
      "Epoch 327/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 15.2345 - val_loss: 487.3206\n",
      "Epoch 328/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.9309 - val_loss: 488.2723\n",
      "Epoch 329/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.6390 - val_loss: 489.2148\n",
      "Epoch 330/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.3583 - val_loss: 490.1476\n",
      "Epoch 331/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.0886 - val_loss: 491.0706\n",
      "Epoch 332/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.8295 - val_loss: 491.9839\n",
      "Epoch 333/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.5805 - val_loss: 492.8871\n",
      "Epoch 334/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.3414 - val_loss: 493.7798\n",
      "Epoch 335/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.1120 - val_loss: 494.6623\n",
      "Epoch 336/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.8917 - val_loss: 495.5343\n",
      "Epoch 337/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.6805 - val_loss: 496.3954\n",
      "Epoch 338/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.4778 - val_loss: 497.2456\n",
      "Epoch 339/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.2835 - val_loss: 498.0852\n",
      "Epoch 340/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.0973 - val_loss: 498.9134\n",
      "Epoch 341/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.9189 - val_loss: 499.7307\n",
      "Epoch 342/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 11.7479 - val_loss: 500.5369\n",
      "Epoch 343/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.5841 - val_loss: 501.3314\n",
      "Epoch 344/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.4274 - val_loss: 502.1144\n",
      "Epoch 345/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.2774 - val_loss: 502.8863\n",
      "Epoch 346/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.1338 - val_loss: 503.6469\n",
      "Epoch 347/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.9965 - val_loss: 504.3956\n",
      "Epoch 348/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.8652 - val_loss: 505.1323\n",
      "Epoch 349/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.7397 - val_loss: 505.8581\n",
      "Epoch 350/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.6197 - val_loss: 506.5718\n",
      "Epoch 351/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.5052 - val_loss: 507.2740\n",
      "Epoch 352/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.3957 - val_loss: 507.9645\n",
      "Epoch 353/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.2912 - val_loss: 508.6432\n",
      "Epoch 354/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.1915 - val_loss: 509.3102\n",
      "Epoch 355/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.0963 - val_loss: 509.9656\n",
      "Epoch 356/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.0056 - val_loss: 510.6096\n",
      "Epoch 357/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 9.9190 - val_loss: 511.2418\n",
      "Epoch 358/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.8365 - val_loss: 511.8625\n",
      "Epoch 359/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.7578 - val_loss: 512.4713\n",
      "Epoch 360/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 9.6829 - val_loss: 513.0690\n",
      "Epoch 361/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.6115 - val_loss: 513.6550\n",
      "Epoch 362/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.5436 - val_loss: 514.2299\n",
      "Epoch 363/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 9.4789 - val_loss: 514.7933\n",
      "Epoch 364/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 9.4173 - val_loss: 515.3455\n",
      "Epoch 365/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 9.3587 - val_loss: 515.8864\n",
      "Epoch 366/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.3030 - val_loss: 516.4160\n",
      "Epoch 367/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 9.2501 - val_loss: 516.9348\n",
      "Epoch 368/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.1998 - val_loss: 517.4425\n",
      "Epoch 369/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 9.1520 - val_loss: 517.9396\n",
      "Epoch 370/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.1065 - val_loss: 518.4260\n",
      "Epoch 371/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 9.0634 - val_loss: 518.9014\n",
      "Epoch 372/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 9.0224 - val_loss: 519.3666\n",
      "Epoch 373/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.9835 - val_loss: 519.8214\n",
      "Epoch 374/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.9466 - val_loss: 520.2656\n",
      "Epoch 375/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.9116 - val_loss: 520.6998\n",
      "Epoch 376/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.8784 - val_loss: 521.1237\n",
      "Epoch 377/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 8.8470 - val_loss: 521.5377\n",
      "Epoch 378/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.8172 - val_loss: 521.9418\n",
      "Epoch 379/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 8.7889 - val_loss: 522.3362\n",
      "Epoch 380/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.7621 - val_loss: 522.7209\n",
      "Epoch 381/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.7367 - val_loss: 523.0962\n",
      "Epoch 382/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 8.7127 - val_loss: 523.4617\n",
      "Epoch 383/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 8.6900 - val_loss: 523.8185\n",
      "Epoch 384/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 8.6685 - val_loss: 524.1659\n",
      "Epoch 385/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 8.6482 - val_loss: 524.5045\n",
      "Epoch 386/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.6289 - val_loss: 524.8340\n",
      "Epoch 387/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 8.6107 - val_loss: 525.1553\n",
      "Epoch 388/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 8.5935 - val_loss: 525.4678\n",
      "Epoch 389/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.5772 - val_loss: 525.7717\n",
      "Epoch 390/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 8.5618 - val_loss: 526.0673\n",
      "Epoch 391/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 8.5473 - val_loss: 526.3550\n",
      "Epoch 392/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 8.5336 - val_loss: 526.6346\n",
      "Epoch 393/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 8.5207 - val_loss: 526.9069\n",
      "Epoch 394/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 8.5084 - val_loss: 527.1713\n",
      "Epoch 395/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 8.4968 - val_loss: 527.4278\n",
      "Epoch 396/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.4859 - val_loss: 527.6770\n",
      "Epoch 397/500\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 8.4756 - val_loss: 527.9193\n",
      "Epoch 398/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 8.4659 - val_loss: 528.1538\n",
      "Epoch 399/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 8.4567 - val_loss: 528.3815\n",
      "Epoch 400/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 8.4480 - val_loss: 528.6025\n",
      "Epoch 401/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.4399 - val_loss: 528.8170\n",
      "Epoch 402/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.4322 - val_loss: 529.0247\n",
      "Epoch 403/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.4249 - val_loss: 529.2260\n",
      "Epoch 404/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.4181 - val_loss: 529.4213\n",
      "Epoch 405/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.4116 - val_loss: 529.6100\n",
      "Epoch 406/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.4056 - val_loss: 529.7931\n",
      "Epoch 407/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.3998 - val_loss: 529.9700\n",
      "Epoch 408/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3944 - val_loss: 530.1414\n",
      "Epoch 409/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3893 - val_loss: 530.3069\n",
      "Epoch 410/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3845 - val_loss: 530.4673\n",
      "Epoch 411/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.3800 - val_loss: 530.6223\n",
      "Epoch 412/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3757 - val_loss: 530.7718\n",
      "Epoch 413/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3717 - val_loss: 530.9164\n",
      "Epoch 414/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3680 - val_loss: 531.0563\n",
      "Epoch 415/500\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 8.3644 - val_loss: 531.1913\n",
      "Epoch 416/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3610 - val_loss: 531.3219\n",
      "Epoch 417/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3579 - val_loss: 531.4478\n",
      "Epoch 418/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3548 - val_loss: 531.5685\n",
      "Epoch 419/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3521 - val_loss: 531.6857\n",
      "Epoch 420/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3495 - val_loss: 531.7986\n",
      "Epoch 421/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3470 - val_loss: 531.9074\n",
      "Epoch 422/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3446 - val_loss: 532.0123\n",
      "Epoch 423/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3424 - val_loss: 532.1130\n",
      "Epoch 424/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3403 - val_loss: 532.2103\n",
      "Epoch 425/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3384 - val_loss: 532.3035\n",
      "Epoch 426/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3365 - val_loss: 532.3931\n",
      "Epoch 427/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3348 - val_loss: 532.4800\n",
      "Epoch 428/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3332 - val_loss: 532.5636\n",
      "Epoch 429/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3316 - val_loss: 532.6436\n",
      "Epoch 430/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3302 - val_loss: 532.7204\n",
      "Epoch 431/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3289 - val_loss: 532.7943\n",
      "Epoch 432/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 8.3276 - val_loss: 532.8654\n",
      "Epoch 433/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3264 - val_loss: 532.9332\n",
      "Epoch 434/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 8.3253 - val_loss: 532.9990\n",
      "Epoch 435/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3242 - val_loss: 533.0615\n",
      "Epoch 436/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3232 - val_loss: 533.1218\n",
      "Epoch 437/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3222 - val_loss: 533.1791\n",
      "Epoch 438/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3214 - val_loss: 533.2344\n",
      "Epoch 439/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3206 - val_loss: 533.2875\n",
      "Epoch 440/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3198 - val_loss: 533.3382\n",
      "Epoch 441/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3190 - val_loss: 533.3868\n",
      "Epoch 442/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3184 - val_loss: 533.4336\n",
      "Epoch 443/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3177 - val_loss: 533.4775\n",
      "Epoch 444/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3171 - val_loss: 533.5203\n",
      "Epoch 445/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3166 - val_loss: 533.5609\n",
      "Epoch 446/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3160 - val_loss: 533.5999\n",
      "Epoch 447/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3155 - val_loss: 533.6372\n",
      "Epoch 448/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3151 - val_loss: 533.6724\n",
      "Epoch 449/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3146 - val_loss: 533.7062\n",
      "Epoch 450/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3142 - val_loss: 533.7383\n",
      "Epoch 451/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3139 - val_loss: 533.7692\n",
      "Epoch 452/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3135 - val_loss: 533.7982\n",
      "Epoch 453/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3132 - val_loss: 533.8260\n",
      "Epoch 454/500\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 8.3129 - val_loss: 533.8527\n",
      "Epoch 455/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 8.3126 - val_loss: 533.8781\n",
      "Epoch 456/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.3124 - val_loss: 533.9026\n",
      "Epoch 457/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.3121 - val_loss: 533.9257\n",
      "Epoch 458/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3119 - val_loss: 533.9474\n",
      "Epoch 459/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3117 - val_loss: 533.9688\n",
      "Epoch 460/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3115 - val_loss: 533.9886\n",
      "Epoch 461/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3114 - val_loss: 534.0076\n",
      "Epoch 462/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3112 - val_loss: 534.0255\n",
      "Epoch 463/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3111 - val_loss: 534.0426\n",
      "Epoch 464/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3109 - val_loss: 534.0583\n",
      "Epoch 465/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3108 - val_loss: 534.0739\n",
      "Epoch 466/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3107 - val_loss: 534.0884\n",
      "Epoch 467/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3106 - val_loss: 534.1015\n",
      "Epoch 468/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3106 - val_loss: 534.1144\n",
      "Epoch 469/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3105 - val_loss: 534.1270\n",
      "Epoch 470/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3104 - val_loss: 534.1384\n",
      "Epoch 471/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3104 - val_loss: 534.1495\n",
      "Epoch 472/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3104 - val_loss: 534.1595\n",
      "Epoch 473/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3103 - val_loss: 534.1697\n",
      "Epoch 474/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3103 - val_loss: 534.1787\n",
      "Epoch 475/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3103 - val_loss: 534.1874\n",
      "Epoch 476/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3103 - val_loss: 534.1956\n",
      "Epoch 477/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3103 - val_loss: 534.2034\n",
      "Epoch 478/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3103 - val_loss: 534.2108\n",
      "Epoch 479/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 8.3103 - val_loss: 534.2177\n",
      "Epoch 480/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3104 - val_loss: 534.2240\n",
      "Epoch 481/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3104 - val_loss: 534.2301\n",
      "Epoch 482/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3104 - val_loss: 534.2360\n",
      "Epoch 483/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3105 - val_loss: 534.2415\n",
      "Epoch 484/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3105 - val_loss: 534.2463\n",
      "Epoch 485/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3105 - val_loss: 534.2510\n",
      "Epoch 486/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3106 - val_loss: 534.2557\n",
      "Epoch 487/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3107 - val_loss: 534.2597\n",
      "Epoch 488/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3107 - val_loss: 534.2635\n",
      "Epoch 489/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3108 - val_loss: 534.2674\n",
      "Epoch 490/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3108 - val_loss: 534.2704\n",
      "Epoch 491/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.3109 - val_loss: 534.2733\n",
      "Epoch 492/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3110 - val_loss: 534.2764\n",
      "Epoch 493/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3111 - val_loss: 534.2790\n",
      "Epoch 494/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3112 - val_loss: 534.2816\n",
      "Epoch 495/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3112 - val_loss: 534.2841\n",
      "Epoch 496/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3113 - val_loss: 534.2861\n",
      "Epoch 497/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3114 - val_loss: 534.2880\n",
      "Epoch 498/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.3115 - val_loss: 534.2902\n",
      "Epoch 499/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3116 - val_loss: 534.2922\n",
      "Epoch 500/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3117 - val_loss: 534.2933\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(89.3180, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0010, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(-0.0204, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.2194, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 428ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.28102078e+01, 7.27679108e+01, 7.27256139e+01, 7.26833170e+01,\n",
       "        7.26410201e+01, 7.25987232e+01, 7.25564262e+01, 7.25141293e+01,\n",
       "        7.24718324e+01, 7.24295355e+01, 7.23872386e+01, 7.23449416e+01,\n",
       "        7.23026447e+01, 7.22603478e+01, 7.22180509e+01, 7.21757540e+01,\n",
       "        7.21334571e+01, 7.20911601e+01, 7.20488632e+01, 7.20065663e+01,\n",
       "        7.19833543e+01, 7.19724300e+01, 7.19615056e+01, 7.19505812e+01,\n",
       "        7.19396569e+01, 7.19287325e+01, 7.19178081e+01, 7.19068838e+01,\n",
       "        7.18959594e+01, 7.18850350e+01, 7.18741106e+01, 7.18631863e+01,\n",
       "        7.18522619e+01, 7.18413375e+01, 7.18304132e+01, 7.18194888e+01,\n",
       "        7.18085644e+01, 7.17976401e+01, 7.17867157e+01, 7.17757913e+01,\n",
       "        7.17648669e+01, 7.17539426e+01, 7.17430182e+01, 7.17320938e+01,\n",
       "        7.17211695e+01, 7.17102451e+01, 7.16993207e+01, 7.71017974e+01,\n",
       "        7.70429739e+01, 7.69841503e+01, 7.69253268e+01, 7.68425770e+01,\n",
       "        7.67417367e+01, 7.66408964e+01, 7.65400560e+01, 7.64392157e+01,\n",
       "        7.63383754e+01, 7.62375350e+01, 7.61366947e+01, 7.60358543e+01,\n",
       "        7.59350140e+01, 7.58341737e+01, 7.57333333e+01, 7.55762372e+01,\n",
       "        7.53913632e+01, 7.52064893e+01, 7.50216153e+01, 7.48367414e+01,\n",
       "        7.46518674e+01, 7.44669935e+01, 7.42821195e+01, 7.40972456e+01,\n",
       "        7.39123716e+01, 7.85414047e+01, 8.65812778e-01, 4.47440207e-01,\n",
       "        3.89988650e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.35769043e+01, 4.89240825e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.01749420e-01,\n",
       "        0.00000000e+00, 9.62374210e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.56811106e-01, 3.91098469e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.44057649e-01, 7.65121341e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.11094771, 69.10441176, 69.09787582, 69.09133987, 69.08480392,\n",
       "       69.07826797, 69.07173203, 69.06519608, 69.05866013, 69.05212418,\n",
       "       69.04558824, 69.03905229, 69.03251634, 69.02598039, 69.01944444,\n",
       "       69.0129085 , 69.00637255, 68.9998366 , 68.99330065, 68.98676471,\n",
       "       68.98022876, 68.97369281, 68.96715686, 68.96062092, 68.95408497,\n",
       "       68.94754902, 68.94101307, 68.93447712, 68.92794118, 68.92140523,\n",
       "       68.91486928, 68.90833333, 68.90179739, 68.89526144, 68.88872549,\n",
       "       68.88218954, 68.87565359, 68.86911765, 68.8625817 , 68.85604575,\n",
       "       68.8495098 , 68.84297386, 68.83643791, 68.82990196, 68.82336601,\n",
       "       68.81683007, 68.81029412, 68.80375817, 68.79960317, 68.79866947,\n",
       "       68.79773576, 68.79680205, 68.79586835, 68.79493464, 68.79400093,\n",
       "       68.79306723, 68.79213352, 68.79119981, 68.79026611, 68.7893324 ,\n",
       "       68.78839869, 68.78746499, 68.78653128, 68.78559757, 68.78466387,\n",
       "       68.78373016, 68.78279645, 68.78186275, 68.78092904, 68.77999533,\n",
       "       68.77906162, 68.77812792, 68.77719421, 68.7762605 , 68.7753268 ,\n",
       "       68.77439309, 68.77345938, 68.77252568, 68.77159197, 68.77065826,\n",
       "       68.76972456, 68.76879085, 68.76785714, 68.76692344, 68.76598973,\n",
       "       68.76505602, 68.76412232, 68.76318861, 68.7622549 , 68.7613212 ,\n",
       "       68.76038749, 68.75945378, 68.75852007, 68.75758637, 68.75665266,\n",
       "       68.75571895, 68.75478525, 68.75385154, 68.75291783, 68.75198413])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.55043833982619\n",
      "20.575686364953484\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
