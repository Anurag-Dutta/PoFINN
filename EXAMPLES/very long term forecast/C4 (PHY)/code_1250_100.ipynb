{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1345    69.907493\n",
       "1346    69.904692\n",
       "1347    69.901891\n",
       "1348    69.899090\n",
       "1349    69.896289\n",
       "Name: C4, Length: 1350, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_1250_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1245    70.187605\n",
       "1246    70.184804\n",
       "1247    70.182003\n",
       "1248    70.179202\n",
       "1249    70.176401\n",
       "Name: C4, Length: 1250, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1250)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.409524</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.219048</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.028571</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.838095</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.600000  0.000298\n",
       "1     88.409524  0.000298\n",
       "2     88.219048  0.000297\n",
       "3     88.028571  0.000297\n",
       "4     87.838095  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAm80lEQVR4nO3deXxU9b3/8dcne0ggCRAghEDYFAMWgQBSBVoXQG81WkFBquCG1loX2tvi9XGvrba/a+tSq6BCUYsrUFsrrriAIotIAAXCGhbZZQ9rIIHv7485cIeYyJIhZybzfj4eeeSc7/kO8zkzMG/O+Z4zX3POISIi0SvG7wJERMRfCgIRkSinIBARiXIKAhGRKKcgEBGJcnF+F3A6GjZs6HJzc/0uQ0QkosydO3ebcy6zYntEBkFubi6FhYV+lyEiElHM7JvK2nVqSEQkyikIRESinIJARCTKKQhERKKcgkBEJMopCEREopyCQEQkykVVEIybuYZJX2/0uwwRkbASVUEwfs463pq/we8yRETCSlQFQVZaEptKSv0uQ0QkrERVEDRJS2LzbgWBiEiwqAqCpmlJ7Nh3iNKyw36XIiISNqIqCJqkJQPwrY4KRESOiaogyEpLAtA4gYhIkKgKgiZeEGxWEIiIHBOSIDCzfma2zMyKzWxEJdt7mdk8Mys3s/5B7eeZ2SwzKzKzBWZ2XSjqqUqTejoiEBGpqNpBYGaxwCjgMiAPGGRmeRW6rQWGAq9VaN8P3Oicaw/0A540s/Tq1lSVlMQ46iXFsbnkwJl6ChGRiBOKGcq6AcXOuVUAZjYeKAAWH+3gnFvjbTsS/EDn3PKg5Y1mtgXIBHaFoK5KZaUl64hARCRIKE4NZQPrgtbXe22nxMy6AQnAyiq2DzOzQjMr3Lp162kVCrqXQESkorAYLDazLOBl4Cbn3JHK+jjnxjjn8p1z+ZmZ35l7+aTp7mIRkeOFIgg2ADlB6828tpNiZvWAd4EHnHNfhKCe79UkLYltew9yqLzSvBERiTqhCII5QFsza2lmCcBAYNLJPNDr/ybwknPujRDUckJZaUk4B1v26KhARARCEATOuXLgLmAysASY6JwrMrOHzOxKADPrambrgQHAaDMr8h5+LdALGGpmX3k/51W3pu9z9O5i3UsgIhIQiquGcM69B7xXoe1/gpbnEDhlVPFxrwCvhKKGk6W7i0VEjhcWg8U1SXcXi4gcL+qCoG5iHCkJsToiEBHxRF0QmBlZ6cls3q27i0VEIAqDAHQvgYhIsKgMglYNU1iyaTclB8r8LkVExHdRGQQD8nMoLTvCG3PX+12KiIjvojIIOmSn0bl5Oi/PWsORI87vckREfBWVQQAw5Ie5rNm+n8+Lt/ldioiIr6I2CPp1aELD1ARemrnG71JERHwVtUGQGBfLoG7NmbJsC+t27Pe7HBER30RtEABc3705MWa88sU3fpciIuKbqA6CrLRk+uQ1ZkLhOkrLDvtdjoiIL6I6CABu6NGCXfvLmPT1Rr9LERHxRdQHQY9WDWjbKJWXZq3BOV1KKiLRJ+qDwMy4sUcLFm3YzT8KdYOZiESfkASBmfUzs2VmVmxmIyrZ3svM5plZuZn1r7BtiJmt8H6GhKKeUzUgP4cL2zTkN/9cwDhdTioiUabaQWBmscAo4DIgDxhkZnkVuq0FhgKvVXhsfeBBoDvQDXjQzDKqW9OpSoqPZeyQfPrkNebBSUWMmlqs00QiEjVCcUTQDSh2zq1yzh0CxgMFwR2cc2uccwuAijPG9wU+cs7tcM7tBD4C+oWgplOWFB/LM4M7c3WnbB6dvIxHPliqMBCRqBCKqSqzgXVB6+sJ/A//dB+bHYKaTktcbAyPD+hISmIsoz9bxd7Sch4u6EBMjPlVkojIGReSOYtrgpkNA4YBNG/e/Iw9T0yM8XBBB+omxfPspyvZd7CcRwd0JD426sfVRaSWCsWn2wYgJ2i9mdcW0sc658Y45/Kdc/mZmZmnVejJMjN+268dv+l3Nv/+aiN3vjpPN5yJSK0ViiCYA7Q1s5ZmlgAMBCad5GMnA33MLMMbJO7jtYWFO3/UhocL2vPR4m+5Zdwc9h0s97skEZGQq3YQOOfKgbsIfIAvASY654rM7CEzuxLAzLqa2XpgADDazIq8x+4AHiYQJnOAh7y2sHFDj1yeuLYjX6zawQ3Pz2ZPqWY1E5HaxSLxypj8/HxXWFhYo8/5waLN/OK1efTJa8wzgztjpgFkEYksZjbXOZdfsV0joCepX4cm/Lbf2by/aDPPT1/tdzkiIiGjIDgFt/VsRd/2jXnk/aUUrgmrM1giIqdNQXAKzIxHB3QkOyOZX7w2j217D/pdkohItSkITlG9pHieHdyFXfvLuPv1+Rw+EnljLCIiwRQEpyGvaT0evqoDM1du5y8fLfe7HBGRalEQnKZr83O4Lj+HkVOLmbL0W7/LERE5bQqCavh9QXvysupx34SvWbdjv9/liIicFgVBNSTFx/LszzpzxDnufHUeB8v1NRQiEnkUBNXUokEKjw/oyMINJTz09mK/yxEROWUKghDo074Jt/duxauz1/LmfE13KSKRRUEQIv/Z52y6tazP/f9aSNHGEr/LERE5aQqCEImLjWHkoE6kJydwy98L2VRywO+SREROioIghBrVS+LFm7qy92A5N704R99UKiIRQUEQYudk1WPU4M6s2LKXu16bT/nhitM0i4iEFwXBGdD7rEz+cFUHPlu+lf9+q4hI/KpvEYkeETNncaQZ1K0563bs55lPV9KiQR3u6N3a75JERCoVkiMCM+tnZsvMrNjMRlSyPdHMJnjbZ5tZrtceb2bjzGyhmS0xs/tDUU+4+HWfs7miY1MeeX8p7yzY6Hc5IiKVqnYQmFksMAq4DMgDBplZXoVutwA7nXNtgL8Af/LaBwCJzrlzgS7A7UdDojaIiTEe7f8DuuZmMHzi15rDQETCUiiOCLoBxc65Vc65Q8B4oKBCnwJgnLf8BnCxBeZ6dECKmcUBycAhYHcIagobSfGxjLkhn+z0ZG57qZDV2/b5XZKIyHFCEQTZwLqg9fVeW6V9vMnuS4AGBEJhH7AJWAs8VtXk9WY2zMwKzaxw69atISi75mSkJPDi0K6YGTe9+CU79h3yuyQRkWP8vmqoG3AYaAq0BH5lZq0q6+icG+Ocy3fO5WdmZtZkjSGR2zCFv92Yz8aSUgpGTddpIhEJG6EIgg1ATtB6M6+t0j7eaaA0YDtwPfCBc67MObcFmAHkh6CmsNSlRQav33Y+ANeOnsUTHy6jTPcZiIjPQhEEc4C2ZtbSzBKAgcCkCn0mAUO85f7AFBe4uH4tcBGAmaUA5wNLQ1BT2OrSIoP37u7J1Z2a8dSUYvo/N4s1GjcQER9VOwi8c/53AZOBJcBE51yRmT1kZld63Z4HGphZMTAcOHqJ6Sgg1cyKCATKi865BdWtKdzVTYrn8Ws7MvL6TqzeupfLn/qcCXPW6sYzEfGFReKHT35+vissLPS7jJDYuOsAwyd+xRerdtCvfRP+96fnkpGS4HdZIlILmdlc59x3Tr/7PVgc9ZqmJ/Paredz/2Xt+GTpt/T76zSmr9jmd1kiEkUUBGEgJsa4vXdr3rzzAuomxfOz52fzh3cWa+pLEakRCoIw0iE7jbfvupAbzm/B2OmrKRg5g+Xf7vG7LBGp5RQEYSY5IZaHr+rAC0Pz2bb3ID95ejovzlitgWQROWMUBGHqonaNef+eXlzQugG/f3sxQ1+cw5Y9pX6XJSK1kIIgjGXWTeSFoV15uKA9X6zaTr8nP+ejxd/6XZaI1DIKgjBnZtzQI5d3776QJvWSuO2lQv7rzYXsP1Tud2kiUksoCCJEm0Z1efMXP+T2Xq14/cu1/OSp6SxcX+J3WSJSCygIIkhiXCz3X34Or97anf2HDnP1MzMYNbWYw0c0kCwip09BEIF+2LohH9zbk77tm/Do5GUM+tsXbNh1wO+yRCRCKQgiVHqdBEZe34nHBnSkaEMJ/Z6cxltfVfzSVxGRE1MQRDAzo3+XZrx3T0/aNkrlnvFfce/4+ewuLfO7NBGJIAqCWqBFgxQm3t6Dey9py9sLNnHZk5/z5WpNfCMiJ0dBUEvExcZw7yVnMfH2HsTGGAPHzOKxyZr4RkROTEFQy3RpkcF79/Tkms7NGDm1mP7PzmS1Jr4Rke+hIKiFUhPjeHRAR54Z3Jk12/dz+V8/Z/yXmvhGRCoXkiAws35mtszMis1sRCXbE81sgrd9tpnlBm37gZnNMrMiM1toZkmhqEng8nOz+ODennRqns6Ify3k9pfnsmPfIb/LEpEwU+0gMLNYAlNOXgbkAYPMLK9Ct1uAnc65NsBfgD95j40DXgHucM61B34E6JKXEMpKS+aVW7rzwOXnMHXZFvo9OY1py7f6XZaIhJFQHBF0A4qdc6ucc4eA8UBBhT4FwDhv+Q3gYjMzoA+wwDn3NYBzbrtzTrOxhFhMjHFbr1b8+xcXUC85nhtf+JKH3l5MaZleahEJTRBkA+uC1td7bZX28Sa7LwEaAGcBzswmm9k8M/tNVU9iZsPMrNDMCrdu1f9oT0f7pmm888sLGdKjBS/MWM1Vo2awdPNuv8sSEZ/5PVgcB1wIDPZ+X21mF1fW0Tk3xjmX75zLz8zMrMkaa5Wk+Fh+X9CBF4d2Zdveg1w5cgYvTF/NEX1fkUjUCkUQbABygtabeW2V9vHGBdKA7QSOHqY557Y55/YD7wGdQ1CTnMCP2zXig3t70bNNQx56ZzFDXvySLbs18Y1INApFEMwB2ppZSzNLAAYCkyr0mQQM8Zb7A1Nc4FrGycC5ZlbHC4jewOIQ1CQnoWFqImOH5PPwVR2Ys2YHfZ+cxuSizX6XJSI1rNpB4J3zv4vAh/oSYKJzrsjMHjKzK71uzwMNzKwYGA6M8B67E3iCQJh8Bcxzzr1b3Zrk5JkZN5zfgnd+2ZOm6cnc/vJc7v/XAk18IxJFLBJvMsrPz3eFhYV+l1HrHCo/whMfLWf0tJXkNkjhyevOo2NOut9liUiImNlc51x+xXa/B4sljCTExTDisna8duv5lJYd5ppnZzJyygpNfCNSyykI5Dt6tG7AB/f0ol+HJjz24XL+46nPeXP+en2BnUgtpSCQSqXViefpQZ0YeX0njjjHfRO+pvefpzL281XsPajxA5HaRGMEckJHjjg+Xb6F0Z+tYvbqHdRLiuOGHi0Y8sNcGtXVV0OJRIqqxggUBHJK5q/dyZhpq/igaDPxsTFc0zmbW3u2onVmqt+licgJKAgkpFZv28fYz1fxj7mBsYM+eY0Z1qs1XVpk+F2aiFRBQSBnxNY9B3lp1hpemvUNJQfK6Jqbwe29WnNRu0bExJjf5YlIEAWBnFH7DpYzsXAdYz9fzYZdB2jTKJVhPVtR0KkpiXGxfpcnIigIpIaUHz7Cuws3MfqzVSzetJtGdRO5+cKWXN+9OfWS4v0uTySqKQikRjnnmF68jdGfrWJ68TZSE+O4vntzbr6gJU3SdKWRiB8UBOKbRRtKGDNtFe8u3ESMQcF52Qzr1YqzGtf1uzSRqKIgEN+t27Gf56evZsKcdRwoO8xF7Rpxe69WdGtZn8CEdSJyJikIJGzs3HeIl7/4hr/PXMOOfYfomJPO3Re14eJzGvtdmkitpi+dk7CRkZLA3Re3ZeaIi/jDVR3Ytf8Qt4wr5LXZa/0uTSQqKQjEN0nxsfzs/BZ8dF9vLmrXiAf+vZC3vqo4uZ2InGkKAvFdQlwMzwzuTLfc+vxq4td8suRbv0sSiSohCQIz62dmy8ys2MxGVLI90cwmeNtnm1luhe3NzWyvmf06FPVI5EmKj2XskHzaN63Hz1+dx8yV2/wuSSRqVDsIzCwWGAVcBuQBg8wsr0K3W4Cdzrk2wF+AP1XY/gTwfnVrkchWNymev9/UjdwGdbhtXCHz1+70uySRqBCKI4JuQLFzbpVz7hAwHiio0KcAGOctvwFcbN71gmZ2FbAaKApBLRLhMlISeOWW7jRITWToi3NYunm33yWJ1HqhCIJsYF3Q+nqvrdI+3mT3JQQms08Ffgv8/kRPYmbDzKzQzAq3bt0agrIlXDWql8Srt3YnOT6Wn439kjXb9vldkkit5vdg8e+Avzjn9p6oo3NujHMu3zmXn5mZeeYrE1/l1K/DK7d244hzDB47m427DvhdkkitFYog2ADkBK0389oq7WNmcUAasB3oDvzZzNYA9wL/ZWZ3haAmqQXaNKrLSzd3Y/eBMn72/Gy27T3od0kitVIogmAO0NbMWppZAjAQmFShzyRgiLfcH5jiAno653Kdc7nAk8D/c86NDEFNUkt0yE7jhZu6snHXAW58/ktKDpT5XZJIrVPtIPDO+d8FTAaWABOdc0Vm9pCZXel1e57AmEAxMBz4ziWmIlXpmluf0Tfks2LLHm7++xz2Hyr3uySRWkXfNSQR4/2Fm/jFa/O4oE1Dxg7J14Q3IqdI3zUkEe+yc7P4c/+OfL5iG3e/Pp/yw0f8LkmkVlAQSETp36UZv7sij8lF3/KbNxZw5EjkHdGKhJs4vwsQOVVDL2jJntJyHv9oOalJcfz+yvaaz0CkGhQEEpHuuqgNew6WM2baKuomxfGffdv5XZJIxFIQSEQyM+6/rB17SssZNXUldZPiuaN3a7/LEolICgKJWGbGH67qwL6D5Tzy/lLqJMRyY49cv8sSiTgKAolosTHG49d25EDZYf7nrSIS42K4rmtzv8sSiSi6akgiXnxsDCOv70TvszIZ8a+F/Hu+ZjkTORUKAqkVEuNiGX1DF3q0asDwiV/x3sJNfpckEjEUBFJrHJ3lrHPzDO5+fT4fL9aUlyInQ0EgtUqdhDhevKkr7ZvW485X5zFtueauEDkRBYHUOnWT4hl3czdaN0pl2MuFfLFqu98liYQ1BYHUSul1Enjllm7kZNTh5r/PYe43mv9YpCoKAqm1GqQm8uqt3WlUN5GhL3zJwvUlfpckEpYUBFKrNaqXxGu3nU9anXhueGE2Szbt9rskkbCj+QgkKqzbsZ9rR89i1/4y2jZOJTs9OfCTkUyzjDrHltOS4/0uVeSMqWo+gpDcWWxm/YC/ArHAWOfcIxW2JwIvAV0IzFV8nXNujZldCjwCJACHgP90zk0JRU0iwXLq12H8sPMZM20Va3fsZ9m3e5iydAsHy4+f06BuYhzZGf8XEhXDomFqgr7pVGqdageBmcUCo4BLgfXAHDOb5JxbHNTtFmCnc66NmQ0E/gRcB2wDrnDObTSzDgSmu8yubk0ilWnRIIU/Xn3usXXnHNv3HWLDzgNs2HWA9Tv3By0f4Ms1O9hTevy0mIlxMceHRHBQZCTTuG4icbE64yqRJRRHBN2AYufcKgAzGw8UAMFBUAD8zlt+AxhpZuacmx/UpwhINrNE59zBENQl8r3MjIapiTRMTaRjTnqlfXaXlgXCITgsdgXWl2zazba9h47rHxtjNKmXROtGqdx7SVs6N8+ogT0RqZ5QBEE2sC5ofT3Qvao+zrlyMysBGhA4IjjqGmBeVSFgZsOAYQDNm+tLxaRm1EuKp15WPOdk1at0e2nZ4WPBcPT3+p37mbVqO9c8O5Mbzm/Bf/Y9m7pJGnuQ8BUW3z5qZu0JnC7qU1Uf59wYYAwEBotrqDSR75UUH0vrzFRaZ6Ye1773YDmPTV7GuFlrmFy0md9f2YF+HZr4VKXI9wvFycwNQE7QejOvrdI+ZhYHpBEYNMbMmgFvAjc651aGoB4R36UmxvG7K9vz5p0XUD8lkTtemcuwlwrZVHLA79JEviMUQTAHaGtmLc0sARgITKrQZxIwxFvuD0xxzjkzSwfeBUY452aEoBaRsHJeTjqT7rqAEZe1Y9qKrVz6xDTGzVzD4SM6qJXwUe0gcM6VA3cRuOJnCTDROVdkZg+Z2ZVet+eBBmZWDAwHRnjtdwFtgP8xs6+8n0bVrUkknMTHxnBH79Z8eG9vOjVP58FJRVzz7Ezd3CZhQzeUidQg5xxvfbWRh99ZTMmBMm7r1Yp7Lm5LUnys36VJFKjqhjJd8CxSg8yMqzpl8/Hw3lzdKZtnP11J3yenMX3FthM/WOQMURCI+CAjJYFHB3Tktdu6E2PGz56fzfAJX7F9r26hkZqnIBDx0Q9bN+T9e3py90VteHvBRi554jPemLueSDxlK5FLQSDis6T4WIb3OZt37+5Jq8xUfv2Prxk8djZrtu3zuzSJEgoCkTBxVuO6/OP2Hvzx6g4sXF9C3yenMWpqMYcqfDGeSKgpCETCSEyMMbh7Cz7+VW8uPqcRj05exhVPT9cMa3JGKQhEwlDjekk8M7gLY2/MZ09pGf2fm8l//3sRu0vL/C5NaiEFgUgYuySvMR8O783QH+by6uxvuPSJz/hg0SYNJktIKQhEwlxqYhwPXhH8vUXzGPLiHFZu3et3aVJLKAhEIkTHnHTevusCHrwij/lrd9LvyWn873tL2KPTRVJN+ooJkQi0be9B/vzBUiYWric1MY4rz2vKwK45nJudpqk0pUpVfcWEgkAkgi1cX8K4WWt4Z8FGSsuOkJdVj4Hdcig4L5u0ZE2GI8dTEIjUYrtLy5j01UbGz1nLog27SYqP4fJzsxjYtTldczN0lCCAgkAkaizaUML4OWt5a/5G9hwsp1VmCgO75nBN52Y0SE30uzzxkYJAJMrsP1TOuws2MWHOOgq/2Ul8rNEnrwnXdc3hwjYNiYnRUUK0OaNBYGb9gL8CscBY59wjFbYnAi8BXQhMUXmdc26Nt+1+4BbgMHC3c27yiZ5PQSByalZ8u4cJc9bxz3nr2bm/jOz0ZK7rmsOA/GZkpSX7XZ7UkDMWBGYWCywHLgXWE5i6cpBzbnFQnzuBHzjn7jCzgcDVzrnrzCwPeB3oBjQFPgbOcs4d/r7nVBCInJ6D5Yf5sOhbJsxZx/TibcQY/PjsRlzXNYeL2jUiLlZXlNdmVQVBXAj+7G5AsXNulfdE44ECYHFQnwLgd97yG8BIC4xeFQDjnXMHgdXeVJbdgFkhqEtEKkiMi+WKjk25omNT1m7fz8TCdUwsXMcnS7fQqG4i/bs047quObRokOJ3qVKDQhEE2cC6oPX1QPeq+jjnys2sBGjgtX9R4bHZlT2JmQ0DhgE0b948BGWLRLfmDerw675nc+8lbZm6bCsT5qzluc9W8synK7mgTQOu69qcvu0bkxinaTRru1AEQY1wzo0BxkDg1JDP5YjUGnGxMVya15hL8xqzuaSUfxSuY0LhOu5+fT7pdeL5aadmDOyWw1mN6/pdqpwhoQiCDUBO0Hozr62yPuvNLA5IIzBofDKPFZEa0iQtiV9e3JZf/LgNM1ZuY/yX63j5izW8MGM13XLr89vLzqZLi/p+lykhFoqRoTlAWzNraWYJwEBgUoU+k4Ah3nJ/YIoLjFJPAgaaWaKZtQTaAl+GoCYRqYaYGKNn20xGDe7MF/dfzAOXn8M3O/ZxzbOzuPv1+WzYdcDvEiWEqn1E4J3zvwuYTODy0Recc0Vm9hBQ6JybBDwPvOwNBu8gEBZ4/SYSGFguB35xoiuGRKRmNUhN5LZerbi+e3NGf7aS0dNWMbloM7f3asUdP2pNnYSIOcMsVdANZSJySjbsOsAj7y/l7a830rheIr/t146rzsvWDWoRoKrLR3XRsIickuz0ZJ4e1Il//rwHTeolMXzi11z9zAzmfrPD79LkNCkIROS0dGlRnzfvvIAnru3I5t2lGj+IYAoCETltMTHGTzs3Y8qvfsTdF7VhctFmLnrsU574cBn7D5X7XZ6cJAWBiFRbSmIcw/uczSe/6k2f9k14akoxP37sU/41bz1HjkTeOGS0URCISMg0y6jD04M68cYdPWis8YOIoSAQkZDLz63Pv++8gMcHdGRTicYPwp2CQETOiJgY45ouzZj66x/xS40fhDUFgYicUSmJcfxK4wdhTUEgIjVC4wfhS0EgIjVK4wfhR0EgIjWusvGDix//lGc+LeZQ+RG/y4s6CgIR8U3w+EHvszL58wfLuPypz3W6qIYpCETEd80y6jD6hnxeGJrPgUOH6f/cLP747mJKy/RlxDVBQSAiYeOido2ZfF8vru/WnL99vprLn/qceWt3+l1WracgEJGwkpoYxx+vPpeXb+lG6aHD9H92Jv/7/hIdHZxBCgIRCUs922Yy+b5eXJufw+jPVvGTp6fz9bpdfpdVK1UrCMysvpl9ZGYrvN8ZVfQb4vVZYWZDvLY6ZvaumS01syIze6Q6tYhI7VM3KZ5HrvkB427uxt7Scn767EwenbyUg+U6Ogil6h4RjAA+cc61BT7x1o9jZvWBB4HuQDfgwaDAeMw51w7oBFxgZpdVsx4RqYV6nxU4Ovhpp2xGTV3JlU/PYNGGEr/LqjWqGwQFwDhveRxwVSV9+gIfOed2OOd2Ah8B/Zxz+51zUwGcc4eAeUCzatYjIrVUWnI8jw7oyItDu7LrwCEKRs3giQ+X6b6DEKhuEDR2zm3yljcDjSvpkw2sC1pf77UdY2bpwBUEjioqZWbDzKzQzAq3bt1araJFJHL9uF0jPry3NwXnNeWpKcUUjJpB0UYdHVTHCYPAzD42s0WV/BQE93POOeCUv0HKzOKA14GnnHOrqurnnBvjnMt3zuVnZmae6tOISC2SVieeJ649j7/dmM+2vQcpGDmDv368grLDOjo4HXEn6uCcu6SqbWb2rZllOec2mVkWsKWSbhuAHwWtNwM+DVofA6xwzj15MgWLiBx1aV5j8ltk8Lu3i/jLx8v5cPFmHr+2I+2a1PO7tIhS3VNDk4Ah3vIQ4K1K+kwG+phZhjdI3Mdrw8z+AKQB91azDhGJUhkpCfx1YCee+1kXvt1dyhVPT2fklBWU6+jgpFU3CB4BLjWzFcAl3jpmlm9mYwGcczuAh4E53s9DzrkdZtYMeADIA+aZ2Vdmdms16xGRKNWvQxM+vK83fds34bEPl/PTZ2ey/Ns9fpcVESxwaj+y5Ofnu8LCQr/LEJEw9e6CTfz3W4vYW1rOvZe2ZVjPVsTF6v5ZM5vrnMuv2K5XRkRqnf/4QRYf3teLi89pxJ8/WMZVz+i+g++jIBCRWqlhaiLPDO7MqOs7s7nkIAWjZvDI+0v1nUWVUBCISK1lZvzHD7L4ZHhv+nduxnOfraTvk9OYWbzN79LCisYIRCRqzCzexv1vLuSb7fs5LyedZhnJZKUl0STt6O8kmqYlk1k3kdgY87vckKtqjEBBICJRpbTsMM9+upIvV+9g8+5SNu46wMEKX1MRG2M0qptIk7QkstKSyAoKiqPB0ahuIvERNgBdVRCc8IYyEZHaJCk+lvsuPevYunOOXfvL2FRSyubdBwK/S0rZVFLKppIDLN28h6lLt3KgwtiCGWSmJpKVnkxWveCQSKJpejJN6iXRuF4SCXHhHxYKAhGJamZGRkoCGSkJ5DWt/I5k5xy7S8u9gDjghUQpm73llVv3MqN4G3sOln/nsQ1TE4NOOx1/GiorLRAWSfGxZ3o3v5eCQETkBMyMtOR40pLjObtJ3Sr77SktO3Y0cey3d5Sxbsd+Zq/azu7S74ZFg5SE444ostICRxRZ6f+3nJxw5sJCQSAiEiJ1k+KpmxRP28ZVh8W+g+Vs3h0UFCUH2OgFx4Zdpcz9Zic795d953HpdeJpUi+JN37+Q1ITQ/vRrSAQEalBKYlxtM5MpXVmapV9SssOHzdOcfQIY8ueUlLOwJGBgkBEJMwkxceS2zCF3IYpNfJ84T+cLSIiZ5SCQEQkyikIRESinIJARCTKKQhERKKcgkBEJMopCEREopyCQEQkykXk11Cb2Vbgm9N8eEMg0meliPR9iPT6QfsQLiJ9H2q6/hbOucyKjREZBNVhZoWVfR93JIn0fYj0+kH7EC4ifR/CpX6dGhIRiXIKAhGRKBeNQTDG7wJCINL3IdLrB+1DuIj0fQiL+qNujEBERI4XjUcEIiISREEgIhLloiYIzKyfmS0zs2IzG+F3PVUxsxwzm2pmi82syMzu8drrm9lHZrbC+53htZuZPeXt1wIz6+zvHgSYWayZzTezd7z1lmY226tzgpkleO2J3nqxtz3X18I9ZpZuZm+Y2VIzW2JmPSLwPbjP+zu0yMxeN7OkcH8fzOwFM9tiZouC2k75dTezIV7/FWY2JAz24VHv79ICM3vTzNKDtt3v7cMyM+sb1F5zn1nOuVr/A8QCK4FWQALwNZDnd11V1JoFdPaW6wLLgTzgz8AIr30E8Cdv+XLgfcCA84HZfu+DV9dw4DXgHW99IjDQW34O+Lm3fCfwnLc8EJjgd+1eLeOAW73lBCA9kt4DIBtYDSQHvf5Dw/19AHoBnYFFQW2n9LoD9YFV3u8MbznD533oA8R5y38K2oc87/MoEWjpfU7F1vRnlq9/WWvwjekBTA5avx+43++6TrL2t4BLgWVAlteWBSzzlkcDg4L6H+vnY83NgE+Ai4B3vH+o24L+IRx7P4DJQA9vOc7rZz7Xn+Z9iFqF9kh6D7KBdd6HYZz3PvSNhPcByK3wIXpKrzswCBgd1H5cPz/2ocK2q4FXveXjPouOvg81/ZkVLaeGjv6jOGq91xbWvMPzTsBsoLFzbpO3aTPQ2FsOx317EvgNcMRbbwDscs6Ve+vBNR6r39te4vX3U0tgK/Cid3prrJmlEEHvgXNuA/AYsBbYROB1nUtkvQ9HnerrHnbvRwU3EziSgTDZh2gJgohjZqnAP4F7nXO7g7e5wH8RwvK6XzP7CbDFOTfX71qqIY7Aof2zzrlOwD4CpySOCef3AMA7j15AINSaAilAP1+LCoFwf91PxMweAMqBV/2uJVi0BMEGICdovZnXFpbMLJ5ACLzqnPuX1/ytmWV527OALV57uO3bBcCVZrYGGE/g9NBfgXQzi/P6BNd4rH5vexqwvSYLrsR6YL1zbra3/gaBYIiU9wDgEmC1c26rc64M+BeB9yaS3oejTvV1D8f3AzMbCvwEGOwFGoTJPkRLEMwB2npXTCQQGAyb5HNNlTIzA54HljjnngjaNAk4evXDEAJjB0fbb/SuoDgfKAk6jK5xzrn7nXPNnHO5BF7nKc65wcBUoL/XrWL9R/erv9ff1//xOec2A+vM7Gyv6WJgMRHyHnjWAuebWR3v79TRfYiY9yHIqb7uk4E+ZpbhHRn18dp8Y2b9CJwuvdI5tz9o0yRgoHfVVkugLfAlNf2ZVZMDKH7+ELjCYDmBkfgH/K7ne+q8kMCh7wLgK+/ncgLnaz8BVgAfA/W9/gaM8vZrIZDv9z4E7cuP+L+rhlp5f8GLgX8AiV57krde7G1v5XfdXl3nAYXe+/BvAlefRNR7APweWAosAl4mcGVKWL8PwOsExjTKCByZ3XI6rzuB8/DF3s9NYbAPxQTO+R/9N/1cUP8HvH1YBlwW1F5jn1n6igkRkSgXLaeGRESkCgoCEZEopyAQEYlyCgIRkSinIBARiXIKAhGRKKcgEBGJcv8fEv8vMdwknysAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.600000    88.409524    88.219048    88.028571    87.838095   \n",
      "351    88.409524    88.219048    88.028571    87.838095    87.647619   \n",
      "352    88.219048    88.028571    87.838095    87.647619    87.457143   \n",
      "353    88.028571    87.838095    87.647619    87.457143    87.266667   \n",
      "354    87.838095    87.647619    87.457143    87.266667    87.076190   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.647619    87.457143    87.266667    87.076190    86.896218  ...   \n",
      "351    87.457143    87.266667    87.076190    86.896218    86.845798  ...   \n",
      "352    87.266667    87.076190    86.896218    86.845798    86.795378  ...   \n",
      "353    87.076190    86.896218    86.845798    86.795378    86.744958  ...   \n",
      "354    86.896218    86.845798    86.795378    86.744958    86.694538  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   78.880345    0.000263   78.856069    0.000263   78.831793    0.000263   \n",
      "351   78.856069    0.000263   78.831793    0.000263   78.807516    0.000262   \n",
      "352   78.831793    0.000263   78.807516    0.000262   78.783240    0.000262   \n",
      "353   78.807516    0.000262   78.783240    0.000262   78.758964    0.000262   \n",
      "354   78.783240    0.000262   78.758964    0.000262   78.734687    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   78.807516    0.000262   78.783240    0.000262  \n",
      "351   78.783240    0.000262   78.758964    0.000262  \n",
      "352   78.758964    0.000262   78.734687    0.000262  \n",
      "353   78.734687    0.000262   78.710411    0.000262  \n",
      "354   78.710411    0.000262   78.686134    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1, 251) (800, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 4s 62ms/step - loss: 5770.0835 - val_loss: 4974.7651\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5696.2314 - val_loss: 4938.0947\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5656.8955 - val_loss: 4901.2983\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5617.5088 - val_loss: 4864.6338\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5578.3037 - val_loss: 4828.1860\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5539.3301 - val_loss: 4791.9678\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5500.5947 - val_loss: 4755.9795\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5462.0903 - val_loss: 4720.2134\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5423.8135 - val_loss: 4684.6616\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5385.7549 - val_loss: 4649.3218\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5347.9126 - val_loss: 4614.1895\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5310.2798 - val_loss: 4579.2617\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5272.8560 - val_loss: 4544.5342\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 5235.6367 - val_loss: 4510.0059\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 5198.6201 - val_loss: 4475.6758\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 5161.8062 - val_loss: 4441.5396\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 5125.1914 - val_loss: 4407.5977\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 5088.7744 - val_loss: 4373.8486\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5052.5542 - val_loss: 4340.2905\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5016.5293 - val_loss: 4306.9233\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4980.6992 - val_loss: 4273.7446\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 4945.0620 - val_loss: 4240.7534\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4909.6162 - val_loss: 4207.9497\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4874.3623 - val_loss: 4175.3325\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4839.2988 - val_loss: 4142.8994\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4804.4243 - val_loss: 4110.6509\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4769.7373 - val_loss: 4078.5847\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4735.2378 - val_loss: 4046.7017\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4700.9248 - val_loss: 4015.0000\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4666.7974 - val_loss: 3983.4790\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4632.8545 - val_loss: 3952.1379\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 4599.0957 - val_loss: 3920.9758\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4565.5210 - val_loss: 3889.9915\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4532.1274 - val_loss: 3859.1851\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4498.9160 - val_loss: 3828.5559\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4465.8853 - val_loss: 3798.1016\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4433.0342 - val_loss: 3767.8235\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4400.3618 - val_loss: 3737.7192\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4367.8687 - val_loss: 3707.7883\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4335.5532 - val_loss: 3678.0305\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 4303.4136 - val_loss: 3648.4453\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4271.4521 - val_loss: 3619.0312\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4239.6646 - val_loss: 3589.7883\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4208.0522 - val_loss: 3560.7148\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 4176.6143 - val_loss: 3531.8110\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4145.3496 - val_loss: 3503.0757\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4114.2578 - val_loss: 3474.5085\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4083.3374 - val_loss: 3446.1086\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4052.5874 - val_loss: 3417.8755\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 4022.0098 - val_loss: 3389.8074\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 3991.6008 - val_loss: 3361.9050\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 3961.3608 - val_loss: 3334.1665\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3931.2898 - val_loss: 3306.5923\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 3901.3862 - val_loss: 3279.1821\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3871.6499 - val_loss: 3251.9331\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3842.0806 - val_loss: 3224.8464\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3812.6770 - val_loss: 3197.9209\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 3783.4375 - val_loss: 3171.1558\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 3754.3638 - val_loss: 3144.5510\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3725.4531 - val_loss: 3118.1042\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 3696.7051 - val_loss: 3091.8174\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3668.1204 - val_loss: 3065.6877\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 3639.6968 - val_loss: 3039.7153\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 3611.4355 - val_loss: 3013.8999\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 3583.3340 - val_loss: 2988.2400\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 3555.3921 - val_loss: 2962.7361\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3527.6106 - val_loss: 2937.3862\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3499.9871 - val_loss: 2912.1909\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3472.5215 - val_loss: 2887.1489\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3445.2134 - val_loss: 2862.2598\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3418.0620 - val_loss: 2837.5222\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3391.0669 - val_loss: 2812.9375\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3364.2271 - val_loss: 2788.5032\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3337.5422 - val_loss: 2764.2192\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3311.0122 - val_loss: 2740.0850\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3284.6355 - val_loss: 2716.1006\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3258.4116 - val_loss: 2692.2642\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3232.3403 - val_loss: 2668.5757\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3206.4214 - val_loss: 2645.0347\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3180.6533 - val_loss: 2621.6404\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3155.0356 - val_loss: 2598.3921\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3129.5688 - val_loss: 2575.2896\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3104.2510 - val_loss: 2552.3325\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3079.0820 - val_loss: 2529.5190\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3054.0610 - val_loss: 2506.8499\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3029.1882 - val_loss: 2484.3237\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3004.4629 - val_loss: 2461.9409\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2979.8835 - val_loss: 2439.6997\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2955.4504 - val_loss: 2417.5994\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2931.1626 - val_loss: 2395.6411\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2907.0198 - val_loss: 2373.8225\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2883.0208 - val_loss: 2352.1440\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2859.1658 - val_loss: 2330.6047\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2835.4539 - val_loss: 2309.2039\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2811.8843 - val_loss: 2287.9414\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2788.4570 - val_loss: 2266.8159\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2765.1707 - val_loss: 2245.8276\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2742.0256 - val_loss: 2224.9763\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2719.0205 - val_loss: 2204.2605\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2696.1555 - val_loss: 2183.6802\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2673.4292 - val_loss: 2163.2339\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2650.8418 - val_loss: 2142.9224\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2628.3928 - val_loss: 2122.7437\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2606.0806 - val_loss: 2102.6990\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2583.9058 - val_loss: 2082.7866\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2561.8677 - val_loss: 2063.0056\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2539.9646 - val_loss: 2043.3571\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2518.1975 - val_loss: 2023.8391\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2496.5649 - val_loss: 2004.4521\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2475.0669 - val_loss: 1985.1936\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2453.7024 - val_loss: 1966.0648\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2432.4712 - val_loss: 1947.0662\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2411.3730 - val_loss: 1928.1949\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2390.4067 - val_loss: 1909.4508\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2369.5720 - val_loss: 1890.8350\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2348.8687 - val_loss: 1872.3447\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2328.2954 - val_loss: 1853.9812\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2307.8521 - val_loss: 1835.7434\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2287.5386 - val_loss: 1817.6301\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2267.3540 - val_loss: 1799.6420\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2247.2976 - val_loss: 1781.7776\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2227.3694 - val_loss: 1764.0367\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2207.5684 - val_loss: 1746.4196\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2187.8948 - val_loss: 1728.9242\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2168.3477 - val_loss: 1711.5510\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2148.9258 - val_loss: 1694.3000\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2129.6296 - val_loss: 1677.1693\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2110.4585 - val_loss: 1660.1595\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2091.4124 - val_loss: 1643.2688\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2072.4890 - val_loss: 1626.4985\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2053.6895 - val_loss: 1609.8474\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2035.0129 - val_loss: 1593.3137\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2016.4586 - val_loss: 1576.8988\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1998.0261 - val_loss: 1560.6008\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1979.7152 - val_loss: 1544.4202\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1961.5250 - val_loss: 1528.3561\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1943.4553 - val_loss: 1512.4080\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1925.5051 - val_loss: 1496.5745\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1907.6738 - val_loss: 1480.8558\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1889.9623 - val_loss: 1465.2533\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1872.3691 - val_loss: 1449.7639\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1854.8942 - val_loss: 1434.3883\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1837.5364 - val_loss: 1419.1254\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1820.2952 - val_loss: 1403.9749\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1803.1707 - val_loss: 1388.9373\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1786.1627 - val_loss: 1374.0109\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1769.2699 - val_loss: 1359.1958\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1752.4924 - val_loss: 1344.4910\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1735.8289 - val_loss: 1329.8961\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1719.2799 - val_loss: 1315.4117\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1702.8447 - val_loss: 1301.0354\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1686.5221 - val_loss: 1286.7686\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1670.3121 - val_loss: 1272.6091\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1654.2142 - val_loss: 1258.5588\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1638.2292 - val_loss: 1244.6147\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1622.3542 - val_loss: 1230.7781\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1606.5906 - val_loss: 1217.0479\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1590.9373 - val_loss: 1203.4231\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1575.3939 - val_loss: 1189.9041\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1559.9596 - val_loss: 1176.4895\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1544.6343 - val_loss: 1163.1798\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1529.4177 - val_loss: 1149.9745\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1514.3090 - val_loss: 1136.8723\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1499.3079 - val_loss: 1123.8733\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1484.4133 - val_loss: 1110.9766\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1469.6262 - val_loss: 1098.1824\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1454.9451 - val_loss: 1085.4897\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1440.3694 - val_loss: 1072.8989\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1425.8992 - val_loss: 1060.4080\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1411.5334 - val_loss: 1048.0183\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1397.2723 - val_loss: 1035.7279\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1383.1152 - val_loss: 1023.5371\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1369.0610 - val_loss: 1011.4452\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1355.1101 - val_loss: 999.4520\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1341.2620 - val_loss: 987.5563\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1327.5160 - val_loss: 975.7590\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1313.8715 - val_loss: 964.0585\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1300.3281 - val_loss: 952.4546\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1286.8854 - val_loss: 940.9471\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1273.5432 - val_loss: 929.5355\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1260.3005 - val_loss: 918.2189\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1247.1580 - val_loss: 906.9979\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 1234.1140 - val_loss: 895.8709\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1221.1685 - val_loss: 884.8377\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1208.3212 - val_loss: 873.8987\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1195.5718 - val_loss: 863.0524\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1182.9196 - val_loss: 852.2992\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1170.3640 - val_loss: 841.6382\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1157.9050 - val_loss: 831.0690\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1145.5417 - val_loss: 820.5911\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1133.2742 - val_loss: 810.2040\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1121.1013 - val_loss: 799.9077\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1109.0236 - val_loss: 789.7010\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1097.0398 - val_loss: 779.5843\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1085.1497 - val_loss: 769.5571\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1073.3531 - val_loss: 759.6188\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1061.6495 - val_loss: 749.7679\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1050.0383 - val_loss: 740.0056\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1038.5188 - val_loss: 730.3302\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1027.0912 - val_loss: 720.7423\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1015.7548 - val_loss: 711.2404\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1004.5089 - val_loss: 701.8252\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 993.3535 - val_loss: 692.4959\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 982.2884 - val_loss: 683.2512\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 971.3123 - val_loss: 674.0922\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 960.4254 - val_loss: 665.0170\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 949.6268 - val_loss: 656.0256\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 938.9171 - val_loss: 647.1182\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 928.2946 - val_loss: 638.2941\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 917.7598 - val_loss: 629.5524\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 907.3120 - val_loss: 620.8929\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 896.9505 - val_loss: 612.3154\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 886.6754 - val_loss: 603.8195\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 876.4858 - val_loss: 595.4046\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 866.3815 - val_loss: 587.0701\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 856.3622 - val_loss: 578.8163\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 846.4276 - val_loss: 570.6420\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 836.5770 - val_loss: 562.5468\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 826.8097 - val_loss: 554.5310\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 817.1259 - val_loss: 546.5930\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 807.5244 - val_loss: 538.7331\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 798.0054 - val_loss: 530.9510\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 788.5685 - val_loss: 523.2466\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 779.2135 - val_loss: 515.6193\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 769.9392 - val_loss: 508.0673\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 760.7456 - val_loss: 500.5917\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 751.6327 - val_loss: 493.1917\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 742.5995 - val_loss: 485.8668\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 733.6461 - val_loss: 478.6170\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 724.7716 - val_loss: 471.4413\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 715.9757 - val_loss: 464.3392\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 707.2580 - val_loss: 457.3106\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 698.6181 - val_loss: 450.3550\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 690.0558 - val_loss: 443.4726\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 681.5707 - val_loss: 436.6616\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 673.1620 - val_loss: 429.9229\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 664.8297 - val_loss: 423.2552\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 656.5731 - val_loss: 416.6591\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 648.3922 - val_loss: 410.1336\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 640.2863 - val_loss: 403.6777\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 632.2549 - val_loss: 397.2918\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 624.2978 - val_loss: 390.9754\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 616.4146 - val_loss: 384.7277\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 608.6046 - val_loss: 378.5488\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 600.8676 - val_loss: 372.4377\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 593.2036 - val_loss: 366.3945\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 585.6114 - val_loss: 360.4183\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 578.0912 - val_loss: 354.5095\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 570.6425 - val_loss: 348.6671\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 563.2647 - val_loss: 342.8900\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 555.9574 - val_loss: 337.1790\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 548.7204 - val_loss: 331.5334\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 541.5532 - val_loss: 325.9527\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 534.4554 - val_loss: 320.4365\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 527.4271 - val_loss: 314.9839\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 520.4670 - val_loss: 309.5953\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 513.5753 - val_loss: 304.2701\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 506.7518 - val_loss: 299.0074\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 499.9953 - val_loss: 293.8072\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 493.3059 - val_loss: 288.6693\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 486.6834 - val_loss: 283.5922\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 480.1269 - val_loss: 278.5774\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 473.6364 - val_loss: 273.6227\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 467.2114 - val_loss: 268.7283\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 460.8514 - val_loss: 263.8947\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 454.5562 - val_loss: 259.1199\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 448.3250 - val_loss: 254.4043\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 442.1580 - val_loss: 249.7481\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 436.0548 - val_loss: 245.1498\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 430.0143 - val_loss: 240.6095\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 424.0366 - val_loss: 236.1270\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 418.1212 - val_loss: 231.7014\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 412.2676 - val_loss: 227.3327\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 406.4757 - val_loss: 223.0207\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 400.7451 - val_loss: 218.7645\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 395.0754 - val_loss: 214.5638\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 389.4658 - val_loss: 210.4184\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 383.9162 - val_loss: 206.3275\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 378.4262 - val_loss: 202.2913\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 372.9957 - val_loss: 198.3092\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 367.6241 - val_loss: 194.3807\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 362.3110 - val_loss: 190.5055\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 357.0559 - val_loss: 186.6831\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 351.8587 - val_loss: 182.9129\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 346.7184 - val_loss: 179.1948\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 341.6354 - val_loss: 175.5286\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 336.6089 - val_loss: 171.9141\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 331.6389 - val_loss: 168.3495\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 326.7243 - val_loss: 164.8363\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 321.8654 - val_loss: 161.3727\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 317.0614 - val_loss: 157.9587\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 312.3118 - val_loss: 154.5942\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 307.6165 - val_loss: 151.2784\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 302.9754 - val_loss: 148.0113\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 298.3875 - val_loss: 144.7924\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 293.8530 - val_loss: 141.6212\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 289.3710 - val_loss: 138.4974\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 284.9417 - val_loss: 135.4207\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 280.5645 - val_loss: 132.3904\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 276.2387 - val_loss: 129.4063\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 271.9641 - val_loss: 126.4681\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 267.7405 - val_loss: 123.5756\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 263.5674 - val_loss: 120.7277\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 259.4444 - val_loss: 117.9245\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 255.3712 - val_loss: 115.1661\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 251.3475 - val_loss: 112.4514\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 247.3726 - val_loss: 109.7800\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 243.4463 - val_loss: 107.1516\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 239.5683 - val_loss: 104.5665\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 235.7384 - val_loss: 102.0235\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 231.9559 - val_loss: 99.5225\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 228.2206 - val_loss: 97.0632\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 224.5320 - val_loss: 94.6452\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 220.8901 - val_loss: 92.2678\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 217.2938 - val_loss: 89.9310\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 213.7434 - val_loss: 87.6343\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 210.2384 - val_loss: 85.3775\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 206.7784 - val_loss: 83.1599\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 203.3629 - val_loss: 80.9815\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 199.9916 - val_loss: 78.8417\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 196.6643 - val_loss: 76.7399\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 193.3803 - val_loss: 74.6763\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 190.1398 - val_loss: 72.6503\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 186.9420 - val_loss: 70.6613\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 183.7866 - val_loss: 68.7089\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 180.6731 - val_loss: 66.7931\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 177.6013 - val_loss: 64.9132\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 174.5710 - val_loss: 63.0691\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 171.5817 - val_loss: 61.2604\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 168.6330 - val_loss: 59.4866\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 165.7247 - val_loss: 57.7474\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 162.8564 - val_loss: 56.0422\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 160.0273 - val_loss: 54.3710\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 157.2374 - val_loss: 52.7332\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 154.4865 - val_loss: 51.1285\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 151.7740 - val_loss: 49.5567\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 149.0999 - val_loss: 48.0171\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 146.4632 - val_loss: 46.5099\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 143.8643 - val_loss: 45.0341\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 141.3026 - val_loss: 43.5898\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 138.7775 - val_loss: 42.1766\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 136.2890 - val_loss: 40.7941\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 133.8366 - val_loss: 39.4416\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 131.4197 - val_loss: 38.1192\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 129.0382 - val_loss: 36.8263\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 126.6917 - val_loss: 35.5628\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 124.3801 - val_loss: 34.3282\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 122.1027 - val_loss: 33.1219\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 119.8594 - val_loss: 31.9439\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 117.6497 - val_loss: 30.7938\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 115.4735 - val_loss: 29.6713\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 113.3302 - val_loss: 28.5759\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 111.2197 - val_loss: 27.5074\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 109.1416 - val_loss: 26.4654\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 107.0956 - val_loss: 25.4496\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 105.0812 - val_loss: 24.4596\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 103.0981 - val_loss: 23.4951\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 101.1458 - val_loss: 22.5555\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 99.2244 - val_loss: 21.6409\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 97.3334 - val_loss: 20.7509\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 95.4724 - val_loss: 19.8851\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 93.6412 - val_loss: 19.0429\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 91.8392 - val_loss: 18.2244\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 90.0664 - val_loss: 17.4291\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 88.3224 - val_loss: 16.6565\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 86.6068 - val_loss: 15.9065\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 84.9194 - val_loss: 15.1788\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 83.2598 - val_loss: 14.4731\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 81.6278 - val_loss: 13.7890\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 80.0231 - val_loss: 13.1260\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 78.4450 - val_loss: 12.4840\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 76.8935 - val_loss: 11.8626\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 75.3683 - val_loss: 11.2616\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 73.8690 - val_loss: 10.6806\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 72.3954 - val_loss: 10.1194\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 70.9470 - val_loss: 9.5775\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 69.5238 - val_loss: 9.0548\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 68.1253 - val_loss: 8.5509\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 66.7512 - val_loss: 8.0655\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 65.4013 - val_loss: 7.5983\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 64.0751 - val_loss: 7.1490\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 62.7724 - val_loss: 6.7172\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 61.4928 - val_loss: 6.3028\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 60.2364 - val_loss: 5.9054\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 59.0026 - val_loss: 5.5249\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 57.7914 - val_loss: 5.1607\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 56.6020 - val_loss: 4.8127\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 55.4345 - val_loss: 4.4806\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 54.2886 - val_loss: 4.1641\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 53.1639 - val_loss: 3.8630\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 52.0601 - val_loss: 3.5768\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 50.9769 - val_loss: 3.3054\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 49.9142 - val_loss: 3.0485\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 48.8716 - val_loss: 2.8059\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 47.8490 - val_loss: 2.5772\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 46.8459 - val_loss: 2.3621\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 45.8620 - val_loss: 2.1605\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 44.8971 - val_loss: 1.9720\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 43.9510 - val_loss: 1.7964\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 43.0235 - val_loss: 1.6334\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 42.1142 - val_loss: 1.4828\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 41.2229 - val_loss: 1.3443\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 40.3492 - val_loss: 1.2177\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 39.4931 - val_loss: 1.1027\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 38.6542 - val_loss: 0.9990\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 37.8322 - val_loss: 0.9065\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 37.0270 - val_loss: 0.8248\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 36.2384 - val_loss: 0.7538\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 35.4659 - val_loss: 0.6931\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 34.7092 - val_loss: 0.6426\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 33.9683 - val_loss: 0.6020\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 33.2429 - val_loss: 0.5711\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 32.5327 - val_loss: 0.5496\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 31.8375 - val_loss: 0.5374\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 31.1571 - val_loss: 0.5341\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 30.4911 - val_loss: 0.5397\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 29.8395 - val_loss: 0.5537\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 29.2021 - val_loss: 0.5761\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 28.5783 - val_loss: 0.6066\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 27.9683 - val_loss: 0.6450\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 27.3716 - val_loss: 0.6911\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 26.7880 - val_loss: 0.7447\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 26.2174 - val_loss: 0.8055\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 25.6597 - val_loss: 0.8734\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 25.1144 - val_loss: 0.9482\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 24.5814 - val_loss: 1.0296\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 24.0605 - val_loss: 1.1175\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 23.5515 - val_loss: 1.2116\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 23.0542 - val_loss: 1.3118\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 22.5683 - val_loss: 1.4179\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22.0937 - val_loss: 1.5297\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21.6303 - val_loss: 1.6470\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21.1777 - val_loss: 1.7696\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 20.7358 - val_loss: 1.8974\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 20.3043 - val_loss: 2.0302\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 19.8832 - val_loss: 2.1677\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 19.4721 - val_loss: 2.3099\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 19.0710 - val_loss: 2.4565\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 18.6796 - val_loss: 2.6074\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 18.2977 - val_loss: 2.7624\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 17.9253 - val_loss: 2.9214\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 17.5620 - val_loss: 3.0841\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 17.2077 - val_loss: 3.2506\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 16.8622 - val_loss: 3.4205\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 16.5254 - val_loss: 3.5937\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 16.1971 - val_loss: 3.7700\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 15.8772 - val_loss: 3.9494\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.5654 - val_loss: 4.1317\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 15.2616 - val_loss: 4.3168\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 14.9656 - val_loss: 4.5043\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 14.6774 - val_loss: 4.6944\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 14.3966 - val_loss: 4.8867\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 14.1232 - val_loss: 5.0813\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 13.8570 - val_loss: 5.2780\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 13.5979 - val_loss: 5.4765\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 13.3457 - val_loss: 5.6769\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 13.1002 - val_loss: 5.8789\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 12.8614 - val_loss: 6.0826\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.6290 - val_loss: 6.2876\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 12.4030 - val_loss: 6.4940\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 12.1831 - val_loss: 6.7016\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 11.9694 - val_loss: 6.9103\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 11.7615 - val_loss: 7.1200\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 11.5594 - val_loss: 7.3305\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 11.3631 - val_loss: 7.5418\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 11.1723 - val_loss: 7.7538\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 10.9868 - val_loss: 7.9663\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 10.8066 - val_loss: 8.1795\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 10.6316 - val_loss: 8.3928\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 10.4617 - val_loss: 8.6065\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 10.2966 - val_loss: 8.8205\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 10.1364 - val_loss: 9.0345\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.9809 - val_loss: 9.2484\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.8300 - val_loss: 9.4623\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.6835 - val_loss: 9.6761\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 9.5415 - val_loss: 9.8898\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 9.4036 - val_loss: 10.1030\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 9.2699 - val_loss: 10.3158\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 9.1403 - val_loss: 10.5282\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 9.0146 - val_loss: 10.7401\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 8.8928 - val_loss: 10.9515\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 8.7747 - val_loss: 11.1621\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 8.6602 - val_loss: 11.3719\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 8.5494 - val_loss: 11.5811\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 8.4420 - val_loss: 11.7893\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 8.3380 - val_loss: 11.9965\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 8.2373 - val_loss: 12.2027\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 8.1398 - val_loss: 12.4081\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 8.0454 - val_loss: 12.6122\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.9541 - val_loss: 12.8154\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.8657 - val_loss: 13.0172\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 7.7802 - val_loss: 13.2178\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 7.6974 - val_loss: 13.4173\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 7.6174 - val_loss: 13.6153\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.5401 - val_loss: 13.8119\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 7.4653 - val_loss: 14.0071\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 7.3930 - val_loss: 14.2010\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 7.3231 - val_loss: 14.3933\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.2556 - val_loss: 14.5842\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.1904 - val_loss: 14.7734\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 431ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.43443044e+01, 7.43162932e+01, 7.42882820e+01, 7.42602708e+01,\n",
       "        7.42322596e+01, 7.42042484e+01, 7.41762372e+01, 7.41482260e+01,\n",
       "        7.41202148e+01, 7.40922035e+01, 7.40641923e+01, 7.40361811e+01,\n",
       "        7.40081699e+01, 7.39702381e+01, 7.39282213e+01, 7.38862045e+01,\n",
       "        7.38441877e+01, 7.38021709e+01, 7.37601541e+01, 7.37181372e+01,\n",
       "        7.36761204e+01, 7.36341036e+01, 7.35920868e+01, 7.35500700e+01,\n",
       "        7.35080532e+01, 7.34660364e+01, 7.34240196e+01, 7.33820028e+01,\n",
       "        7.33399860e+01, 7.32979692e+01, 7.32559524e+01, 7.32139356e+01,\n",
       "        7.31719188e+01, 7.31299020e+01, 7.30878852e+01, 7.30458684e+01,\n",
       "        7.30038515e+01, 7.29618347e+01, 7.29198179e+01, 7.28778011e+01,\n",
       "        7.28357843e+01, 7.27937675e+01, 7.27517507e+01, 7.27097339e+01,\n",
       "        7.26677171e+01, 7.26257003e+01, 7.25836835e+01, 7.25416667e+01,\n",
       "        7.24995798e+01, 7.24491597e+01, 7.23987395e+01, 7.23483193e+01,\n",
       "        7.22978992e+01, 7.22474790e+01, 7.21970588e+01, 7.21466387e+01,\n",
       "        7.20962185e+01, 7.20457983e+01, 7.19953781e+01, 7.19449580e+01,\n",
       "        7.18945378e+01, 7.18441177e+01, 7.17936975e+01, 7.17432773e+01,\n",
       "        7.16928571e+01, 7.16424370e+01, 7.15920168e+01, 7.15415966e+01,\n",
       "        7.14911765e+01, 7.14407563e+01, 7.13903361e+01, 7.13399160e+01,\n",
       "        7.12894958e+01, 7.12390756e+01, 7.11886555e+01, 7.11382353e+01,\n",
       "        7.10878151e+01, 7.10373950e+01, 7.09869748e+01, 7.09365546e+01,\n",
       "        7.59762115e+01, 4.20791447e-01, 2.50196904e-02, 0.00000000e+00,\n",
       "        1.00360058e-01, 2.04454392e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        8.59306455e-02, 4.63057578e-01, 6.41931444e-02, 4.23435479e-01,\n",
       "        2.80094087e-01, 0.00000000e+00, 4.60363358e-01, 0.00000000e+00,\n",
       "        6.39821112e-01, 8.07693124e-01, 3.26410592e-01, 2.46869147e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70.17359944, 70.17079832, 70.1679972 , 70.16519608, 70.16239496,\n",
       "       70.15959384, 70.15679272, 70.1539916 , 70.15119048, 70.14838936,\n",
       "       70.14558824, 70.14278711, 70.13998599, 70.13718487, 70.13438375,\n",
       "       70.13158263, 70.12878151, 70.12598039, 70.12317927, 70.12037815,\n",
       "       70.11757703, 70.11477591, 70.11197479, 70.10917367, 70.10637255,\n",
       "       70.10357143, 70.10077031, 70.09796919, 70.09516807, 70.09236695,\n",
       "       70.08956583, 70.08676471, 70.08396359, 70.08116246, 70.07836134,\n",
       "       70.07556022, 70.0727591 , 70.06995798, 70.06715686, 70.06435574,\n",
       "       70.06155462, 70.0587535 , 70.05595238, 70.05315126, 70.05035014,\n",
       "       70.04754902, 70.0447479 , 70.04194678, 70.03914566, 70.03634454,\n",
       "       70.03354342, 70.0307423 , 70.02794118, 70.02514006, 70.02233894,\n",
       "       70.01953782, 70.01673669, 70.01393557, 70.01113445, 70.00833333,\n",
       "       70.00553221, 70.00273109, 69.99992997, 69.99712885, 69.99432773,\n",
       "       69.99152661, 69.98872549, 69.98592437, 69.98312325, 69.98032213,\n",
       "       69.97752101, 69.97471989, 69.97191877, 69.96911765, 69.96631653,\n",
       "       69.96351541, 69.96071429, 69.95791317, 69.95511204, 69.95231092,\n",
       "       69.9495098 , 69.94670868, 69.94390756, 69.94110644, 69.93830532,\n",
       "       69.9355042 , 69.93270308, 69.92990196, 69.92710084, 69.92429972,\n",
       "       69.9214986 , 69.91869748, 69.91589636, 69.91309524, 69.91029412,\n",
       "       69.907493  , 69.90469188, 69.90189076, 69.89908964, 69.89628852])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.489576082930753\n",
      "15.481778343831502\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
