{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "2445    55.664071\n",
       "2446    55.651773\n",
       "2447    55.639475\n",
       "2448    55.627178\n",
       "2449    55.614880\n",
       "Name: C4, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_2350_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "2345     0.449005\n",
       "2346     0.000000\n",
       "2347     0.195732\n",
       "2348     0.811637\n",
       "2349     0.995561\n",
       "Name: C4, Length: 2350, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2350)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.409524</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.219048</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.028571</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.838095</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.600000  0.000298\n",
       "1     88.409524  0.000298\n",
       "2     88.219048  0.000297\n",
       "3     88.028571  0.000297\n",
       "4     87.838095  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAr+ElEQVR4nO3deZwcdZ3/8dd3zmSOJHOG3DO5CWBISCAhEC7liCvoKqgoRtQf68oqLj91cfktgv5U1F11+elPRAG55BDBcAtEEMjJJOS+r8k1mcyRzJnM+d0/+pjumT6qqqu6q7o/z8cjj5nuqer6VmfmXd/+1vdQWmuEEEJ4T1aqCyCEEMIaCXAhhPAoCXAhhPAoCXAhhPAoCXAhhPConGQerLy8XFdVVSXzkEII4Xnr1q1r1FpXDH4+qQFeVVVFTU1NMg8phBCep5SqjfS8NKEIIYRHSYALIYRHSYALIYRHSYALIYRHSYALIYRHSYALIYRHSYALIYRHeSLAX9h4lMdXR+wGKYQQGcsTAf7aljp++eZu+vpl7nIhhAjwRIAvOWcMje1drN3fnOqiCCGEa3giwC+bUcmw3Cxe2VyX6qIIIYRreCLAC/NzuHR6Ja9uOUZHV2+qiyOEEK7giQAHuPGCiTR3dHH9/as4evJUqosjhBAp55kAXzy9gge/OJ9DzZ1c+6sVPLGmlpOd3akulhBCpIxK5qr08+bN04lOJ7vneBtff3ID2+tayc1WXDqjkk/MGcflMysZlpttU0mFEMI9lFLrtNbzBj+f1PnA7TC1sphXvnERW4+2smzDEZZtOMob2+opzs/hE3PH8ZWLJjOxrCDVxRRCCMd5rgY+WF+/ZvW+Jv68/jAvbjxKX7/mox8ay1cvmcxZY0faeiwhhEiFaDVwzwd4qPrW0zz03n6eWHOQ9q5eLp5Wzj9fMoWFU8pQSjl2XCGEcFJGBHhAy6kenlhTy0PvHaCxvYuzxo7gxgsmcu3ssRQPy3X8+EIIYaeMCvCA0z19PLf+CI+uOsCOY20U5GXzkVmjWTS1nEVTyxk3anjSyiKEEFZlZIAHaK3ZcOgkT609xPId9TS2+7ofVpUVsHBKOYumlrFwchllRflJL5sQQsSTNr1QrFBKMWdiCXMmlqC1Zld9Oyv2NLJybyMvbTzKk2sPAnDmmBFcOKWMRVPLOL+6jKL8jHh7hBAelRE18Fh6+/rZfKSFlXubWLGnkZraE3T39pOTpZg9YRQXTinjwinlzJ00ivwc6WcuhEi+jG5CMeN0Tx/ra0+wYm8jK/Y0senwSfo1DMvNYn5VKQunlLFoSjlnjxtJdpb0bBFCOC+hAFdK/SvwFUADm4GbgTHAU0AZsA64SWsdc2y7FwJ8sNbTPazd18yKvY2s3NPEzvo2AIqH5bBgchmLppSxaGo5UyuLpKuiEMIRlgNcKTUOeA+YpbU+pZR6BngFWAI8p7V+Sil1P7BRa/2bWK/lxQAfrKGti1X7mli5p5EVexs51OybWKuiON/Xfj6lnPnVpUwqLSBLauhCCBskehMzBxiulOoBCoA64HLgRv/PHwHuBmIGeDqoKM7n2tljuXb2WAAONXey0t/csmJPE8s2HAWgMC+bmWNGMGvMCM4cM4JZY0cwY3Qxw/OkHV0IYQ+jTSi3AT8ETgGvA7cBq7XWU/0/nwC8qrU+O8K+twC3AEycOPG82tr0Xdsy0MNl46GTbKtrZdvRVrbXtdLmn8M8S0F1eSGzxo70B3sxs8aOoLJ4WIpLLoRwM8s1cKVUCXAdUA2cBP4EXG30wFrrB4AHwNeEYnQ/L1JKMeOMYmacURx8TmvN4ROn2Hq0lW11vkBfX3uCFzceDW4za8wIPrdgIh8/dxyF0nVRCGGQkbT4MLBfa90AoJR6DlgEjFJK5Wite4HxwBHniuldSikmlBYwobSAq88+I/h8S2cP24+1svlwC899cIQ7n9/Cj1/ZwSfmjOPzCyaFXQSEECISIwF+EFiglCrA14RyBVADvAV8Cl9PlKXAMqcKmY5GFuSyYHIZCyaX8ZWLq1l/8CRPrK7l6ZpDPLa6lvlVJXx+wSSuPvsM6X8uhIjIaBv4PcCngV7gA3xdCsfhC+9S/3Of11p3xXqddOiF4rQTHd08u+4wT6yp5UBTJ6WFeVw/bzyfO3+SzHMuRIaSgTwe09+vWbG3kcdX1/Lm9uP0a83iaRV8fsEkLp9ZKYOIhMggEuAedqzlNE+uPchT7x+kvrWLsSOHccP8CUypKKJoWA7F+TkUDcuhKD+H4vxcCvOzycn2zHKnQog4JMDTQE9fP8u3H+eJNbW8u7sx5rbDc7OHhHtRfg4jhufyofEjWTC5jGkyelQIT5AATzNN7V2c6Oym7XQv7V29tJ/upc3/tb3L92/gZz3Bx00d3TS0+W5VlBXmccHk0uDNVAl0e/T09bOjro1zxhtf0u+xVQf4j2Vb2XT3lYwwuOhIy6keth5p4cKp5Ya27+rtY3d9O2ePM16u+/++l3tf3cGOH1xteNHw5o5udtW3sWBymeHj2KGls4eG9i6mVhYZ3ufWP67n5U11HLj3o4b3OdTcScupHlPvY6IyejrZdFRWlG9p/vJAv/RV+5pYva+J1XubeGXzMd9rSqDb4t5Xd/Dge/t58/bFTK001h304RUHADje2mU4wP/XozWs3d/M5ruvNLTS1H/8ZQvP1Bxm1XcvZ8xIY4uZPPDOPgDau3oNB/iNv1vNjmNt7P/xkqT+/lz76/eobeo0FcYvb6ozfZyLf/oWgKnjOEUCPMOE9ku/Yd6EuIHuC3NfqMuEXcZsPHQSgOaOHsP79Ps/CZu5Ob29rtW3b7+x7dfVngCgwz8y2Ii+fn+5TPy/7zjWZnhbO9U2dabkuKkkAZ7hjAT6y5t9tZTiYTlMH13M9NFFTKssDn5fUZwvwR6iLxjGFvYx8T4GWj+zDB6nP7C9iWMELiwyMZs7SYCLMJEC/VDzKVbva2LTkZPsqm/ntS3HeLLzUHCfkcNzfaE+upgZo4uZNrqI6aOLKU+zJepe3lTHzmOtfOmiakYV5EXdrt+flKaC0l+LNnMdDNaOY4Tr2zuPk52luHhaBb3+g4Ru397Vy49e2c5tV0xj9Iihc/IMnIvxcpn1/AeHmT1+FJMrIrdd9/drVu5tYtHUMpo7ulmxtyk4mVwkx1pOA3DGyMTnGDrWcpq3dh7ns+dPNLT9tqOtVI7IT9rvvgS4iEkpxcSyAiaWFXDD/AmArx29sb2b3fVt7KpvY2d9O7vr23hp41H+eHrg43lpYR7TKos4c8wILqgu5fzqUk+vO/roqgOs2d/MH1Ye4Jsfns4XL6yKWDPts9AcYqWmG9hHEX2fLz78PgBr//2K4EUi9MKy6fBJ/rjmIG9sq+f9Oz8c4Ri+r05+wvrXpzcC0duUn11/mO88u4lffHo2b247zsub65gxujjqdBMLfrw85uuZ8dXH17Hh0Ekum1EZ9YJw/f0rycnK4slbFrDkvncpHpbDxruuTMqnFglwYZpSiorifN8c6CE9ILTWHG/rYld9G7v8ob6rvo2n3z/EH1YeAGDG6OLgjdLzq0s9VUvv69dMrSxi3KjhfP+lbby3p5H/un42JYXhtfFIQRlPMMBN/M0HmlA00XuSFeZl09Hdx4Pv7Y/Zzt7Q1sW2o63MGjsiYrms0NrcJ4pounp9b+iqvU3Bc91e1xp3viCtdcIXntZTvvsY7THuG7x/4ETY47bTvXzhobU8/pULEjq2ERLgwjZKKUaPGMboEcO4eFpF8PnuXt+6o6v97erPrjvMo6t80wpPqywK9nq5YLK7A71Pa8aMHMYfbp7P46tr+cFL21ly37v86sY5nDepNLjdQBgrvvvcZo61nOJn18+OeW6Bmq6ZNvA+A+E6obSAHcfaeHLtwWDMh15YQm+A/mHlfn76qdk88M5eSgryuH7ehIgBXtvUwSd/s5I/3Hx+wl3pQrsxRwvciiLfBXJfQwfnVZUA8M2nNzChtIDzJpVEfe3fvrOPf1o8mT3H23l1yzG+fvnUqIG+53g7+TlZTCgNn64i0PPmdE+fqfN6b0+jLReQeCTAhePycrI4b1IJ500q4dbLptLTFxrozfx5/WEeW+0L9KmVRSyYXMoF1b5Ad9Nc6X39muwshVKKmxZWMWdiCbf+cT03/HY1375qBrdcPJmsLBXWNr3taAsbD7fw0fve5dc3zmVeVWnE1w60NZv5gzdSO+7r11QW53O8bWCaotCbnoF28bPGjuAvG47yb1fP5Eev7ADgY7PHBi8soTYdbqGxvZtvP7uJV2+72HB5o5Uv4GRnz5BPM75tfF8PnzjFJdMHKgaf/M3KYDNJpIC999UdjB01nPvf3su2ulY+MWfckIAO+PDP/w4MbXYJLMByymSAg++Tg9Gul1ZJgIuky83OYu7EEuZOLOFrl/oGvmw50sLqfc2s3tfE8+uP8Pjqg4Av0C+ZXsGlMyqYX1Xq+B9ELH39mpyQ5oezx43kxa9fxHf/vJl7X93B+/ub+e/PzhnSC2VqZRG9ff18+oHV3P2xWdy0sGrIawfbsy00ocQss9bMry7lYFMnm4+0+I4R0mYeCNAvX1TN7c9s5I9rDgZ/9sLGo2EBC77BQEXDfLGxva6VllM9jBxurN96tPIFHGjqiBjggYvMsdbTQz51dHT10tun6ewZaOIoyMums9sXuB8cPEGp/zV3H2+LGuDRDPf/vpnpehlwrOU0VeWFpvczQybMECmXm53FnIkl/POlU3jkS+ez8XtX8pdbF3HHNTMZM3IYj62q5aYH13Lu91/n5ofX8ocV+9nf2JH0cvb16yHt2iOG5fKrG+fw/evO4u1dDdxw/yrqTvp6QQS2HV8ynBe+fhGXTq/gP5Zt5Z4Xtw4JxtDHK/c08sHB8HbVRMqck6W4eVFV1J8DTB9dzOLpFTy+ppbJFb7QecR/3wIGmjpm/J/XuPWJ9cHnn1t/GIDjradjthOf7unjufWHY553tH7codsE2sMDFv3kb8z+/uvkhHysOCOkN83OY200tvs+ffxtx3F6+mJ3mg+cQ3+/5lR3X/B+weDjGnHpf75teh+zJMCF6+RkZ3HuhFF89ZIpPPblC9jwvY/w8Bfn8+l5E9jf2MHdL27jsv98m0t+9hZ3LdvC8u31lmpIZvX1a3Kyh1aRlVJ8YWEVDy6dR21TR/DjdujNwhHDcnngC/P40qJqHl5xgFserQkrc/CGpIbvv7SN6+9fxRNrjC0/GKsm3tvna/b56IfGBJ/7+66GsHMKlPXG8ydS39rFvgbfxXHr0daIrxmo3QI8tfYQWmvO/9Fyzr3n9fByhXy/bMMRbn9mI799Z294+ULCObT2Hyo0wA81h4f8yc4Ig6VC/ot21bcFBxY9vvog33l2U8RjBJz9vb9yoqObe17cypl3vRas/Ufy/5bv5un3B8rcH6m9yWHShCJcryAvh8tmVnLZzEoADjR28M7uBv6+s4E/1fhuiOZlZzG/uoSzx42kKC+HgvwcivKzKcjLoTA/m8K8HArzcyjIy6Yo3/fzgtxsU129fG3g0es8l86o5E9fvZAl970L+JoqQv+ks7MUd31sFtUVhdz9wlY++ZuVXD9vAtXlBcF1UwPH6deaO5/fwvv7m7lwSjlV5YVUlRdQURR50FRdyymaO7qpKisMW5avX/tq4KGLgnzrTxv51Hnjfcfyp39OluKKMysZOTyXllM9LJ5ewfraEzFr1defN54/rTvMi/7h6L39mvciTLK2+XBLMGjvW76b68+bQEVxPs0d3WEXsbUHmsP26+vX7Gtop6dv4F08fOJU1PKE7hfQ2N4d9rPnPzjCLz59LjDQX3ywN7bV84j/Jvvqfc0RtwH4rzd2hT0+3Wu+nTxREuDCc3xhVsgXFlbR1dtHzYETvL3zOH/f1cDDKw7QbeLjbkGeL+TDwj4/h8I8X9gX5vueK8jL4URnNxEq4GFmjR3BHdfM5N5Xd0Td5qYFk5hQMpxv/WkTP3hpW8RtPjJrNFVlhTy0Yj9/2TCwfmphXnbw/EPd/PD7wZpmZXE+1eWFVJcX0nKqJ/hJ4J5rz+J7L2wN7vPYqgO8vq0e8PU/z83OYlSBL8CL8rP50kXV3Ld8d9TzuPbcsazZ38w3nvwg+NznH1wTto3Wmo/96r3g49M9/Sy692/8w+wxvLbl2JAmlcA+97y4ja1HW3j/wAmG5Q5cNDf4pykYsg/xm2IC9jW0M7miiK4ogfvLNweCeXD5Gtqir1kz666/xjyuEyTAhafl52SzaGo5i6aWc6e/A0FPXz+dXX10dPfS2d1Le1cfnf4ZGju7fc93dPXS0dU38PNu3+OOrl5OdHRzqLnTt21XLx3dfcE/5DGj4k8CVWGgK+SlMyp5/84raOro5kBjBz94eXtwDhXw1da/u+RMvn3VDI6cPMX+xg4ONHZwoKmT/Y0dbPHfkAxoO93LeZNKuHxmZXDbN7fX09ndx1j/xFWD+3//8s3dNHV0Myw3i9III0tv/8h09jd2hC3AHaowP4c3bl/Mgh8t50RnD1efdQYXTi3jrmVbI24P8P8/N5c1+5p4dHUtWvsuNm2ne8N6eXR29wXHDQCMGzWcvQ323fN4dcsxbr1satQBUEcj1MwDzVSB9nS3kAAXaSc3O4uRBVmMLLDeOyKU1pqu3n46u/sosfCa0SrtSinKi3zDrj913viwAA/Iyc5iUlkhk8oKYUb4z3791h5+9tedwcdVZYXcetnUsG06u3uDPSkG08DnLpjIXR+bFXXd1dnjR0YNcPBdQAOLhxTkZ/OFhVWc7Ozh54OaFwKqywtZcs4Y/rz+CO1dvVx51mj+78fPoeqOl6Me46EvzufIyVPc+Dtf7X54bralbn0BibRVu23KH7mJKUQcSimG5WZTWphnqp92rBGSsfYxuleuvz0n1vYFeTkxy5yllKFFs61EnpW1BjYdPhnx+VjTBSTDtqMt8TdKAQlwIWwWmpdGM8xKPJkNNadrj4HyxDpMvDJc+6sV9hUoDjMX2Pv+tsfSMcyO4DRLAlwIF0pGjTNSDVkFv8Y/vpESWplKJdIucS8+Jo6TSGc/s+ez6N6/JXC0+CTAhRAJSXbjRqraoaP1U4+lqaM7/kYJkAAXwmFmJzSyuk6tlWBLVRiaq+nbW8i20z20RBoAFMe/P7/Z1nLYQQJcCIdYymErTQ4WDmR2H9uaQlJ8MxLgd+/uZ/b3X4+/oQdIgAths7CbmAYTORm1ZyvhaebTQ2DT8PO3hxOxn8BU564hAS6EG5lMLEu18EiHDaZw/P2dmuvarnNxgttCXwJcCIclq9HAyePEajNOdjt66hth3EMCXAiXSWYlz2gYLv7ZW44c2Ej4u230o5tIgAvhkCTdw7Q4StLCTnEMztlIx3BTGLusNcQSCXAhbBZ6s9D4SMzEks3IYQzVduM8NiK0bdxql8hYr5lKVqZHcJIEuBAulIy4ipWtRo7vVBnd8onCCyTAhXBYsiqPqRuUY6F74qCvpvZ1SW3cDSTAhXCbJNYmJQy9TQJcCBdJVlOAE4ex0saeSna1z6eSBLgQDtFaG7+JqQY/NjHvuDYW/IZecUg5DBdjCDNzm4ft5+LeK27LfAlwIWyWvDbvBHuuxEgjI6/tllAF9/UOSRZDAa6UGqWUelYptUMptV0ptVApVaqUekMptdv/tcTpwgrhTclJulRNFGVtHhcV9tXM67voupFyRmvg/w28prWeCcwGtgN3AMu11tOA5f7HQogEZWZdUlgRN8CVUiOBxcCDAFrrbq31SeA64BH/Zo8AH3emiEJkjmQ1BThxA8/Q3N4Wq8+OzEbowGsmm5EaeDXQADyslPpAKfV7pVQhMFprXeff5hgwOtLOSqlblFI1SqmahoYGe0othAdojIdEQiMgtbHgHxyekefrTqAcgxi9uTp0xzg/lzaUICMBngPMBX6jtZ4DdDCouUT7LucR33at9QNa63la63kVFRWJllcI4edkjhkbiRl5EeNU3Nx0W++QZDES4IeBw1rrNf7Hz+IL9Hql1BgA/9fjzhRRCG8zG2gZsaSaiePKYKPo4ga41voYcEgpNcP/1BXANuAFYKn/uaXAMkdKKIRIIxLGdsoxuN3XgSeUUnnAPuBmfOH/jFLqy0AtcIMzRRQic6TbSEy7bso6UQlPh2YXQwGutd4AzIvwoytsLY0QacR3E8/amphmAktjbMTnkF4iEUc8qpiPkyFe6KeyDu+20JeRmELYLFmhl0jom33tWNsMCf0URKzLcjVpJMCFcJjZOEvukmopGr0Z+OqxCbDcRgJciAzkyJJqsr5l0kmAC5EG3NqEYN+FYiD57Wuicuu7ZpwEuBCOMR8QgT3MRJThkLQyEjOR6WQt5qPbbhSGctushxLgQtjM0jJhCSxLltiRjb62iX0NNaUERnHaM39KOizOYIUEuBAOMz8S05lyRCJt0t4mAS5EBnKmKcBAbdrqK8tAnogkwIVwIbM36uwKIzfUyONORpjCMrot9CXAhXCIlelUrbTlWp2y1sixYmVlvCB12w2/dCQBLoTNLNUQE1iWLJHjRtvFzCcAK0uemRvIE38jt9WMk0UCXAiHme1hIjVXYZQEuBAZKHUjMa01YMuSapFJgAvhQuYDy562c7vnRrFyoYjXNp/S2QhTeOxIJMCFcIhvnUFzf/JOBF6ApdpvjH2CS6pF2SRT26WTSQJcCJvZM6rSwD4Wbh7Ge41EXivea0baxtANTxd0bXQrCXAhHObmkZjC2yTAhRC2GHydWvrQ2iFNSNZHYtpfDU+HC6UEuBAOshwSSai1R9rHzpysqT1hab/4IzFT16bitkmzJMCFcEiyFyiOl2t2x95AO7azI5eMbOmyXE0aCXAhbGZlrcrQWqXRMLIjkKPWZk3cZBy6q/VRnMIcCXAhhCF2NB9YDWzJ+cgkwIVwIfPD781J1khMNzdtpMOUBRLgQjjIzRHh1gCLF/oyEnOABLgQDrESkIn0JolXa49UQ7ZjwE4iAzwN9SgxsqSa66I1OSTAhbDZkIWBnVqpxsE7gJGGyRu+uSoN1kkjAS5EBnKixmrsQmVxNkK5KEQkAS6EC5kffm9PINs9SMZKqeJdXOwqol2Dn1JJAlwIB7lt5F4oFxdNGCQBLoRDLNXwLM3r7dsn7kjMSD+PNo7HxFJniYzDNLb8miypFo0EuBA2GxJ+JqZXBRPzexsvkmWh4ZmhGelqEuBCZKDULalm8bUduFylQ61dAlwIFzIbV9ZuFiZ+3LjHsNaOFIcM5QmQABfCQe76c3dGsqd3lS6FAyTAhUgT8XItUjNEtKYJp5c6UybuYg4+TqRKfSZcKCORABfCIQND3M3tYzqMHEwvKzdXnS6HGGA4wJVS2UqpD5RSL/kfVyul1iil9iilnlZK5TlXTCG8xMKixvYuGB+XE1EcrFR7JG3TYf4UMzXw24DtIY9/AvxCaz0VOAF82c6CCZHJkrIQssNLqkU5RML7pPL64LaeK4YCXCk1Hvgo8Hv/YwVcDjzr3+QR4OMOlE8Ib0viH3yqar6JrNpjZaIvb9Tvk8NoDfyXwHeAfv/jMuCk1rrX//gwMC7SjkqpW5RSNUqpmoaGhkTKKkRGcKqWF3E6WRMjMQcXK1VBGuntcfOUBU6KG+BKqX8Ajmut11k5gNb6Aa31PK31vIqKCisvIYQnDQxxNx51TjQ5JCK05HZkpEeaxz0jx8A2i4BrlVJLgGHACOC/gVFKqRx/LXw8cMS5YgrhHZZuSA6qzzo5NSs4U2MNXKjsDn2nuLlsRsWtgWutv6u1Hq+1rgI+A/xNa/054C3gU/7NlgLLHCulECImK4EcqReGG2rIsqSacYn0A/834Hal1B58beIP2lMkIdKH2/7gBzPVRz3a2SS0pJqRbV1wVXEpI00oQVrrt4G3/d/vA863v0hCZDY39E821ITjolxN/TuWGjISUwiHWBuJmaSFkA1uZ2VNzNivJ0uq2UkCXAibWeoXrWI/jrePXTVQO6ZtDSt7kha1SBa33fiUABciQ7ktjIyS2vgACXAhHJTMASbJnk8FhnYbNLen0SXVRDQS4EK4jHMjMY1HodtqufGadrz6aSJREuBCOMxMGFobiencjc+wNTHj9c82tBCysJMEuBA2s6PfsukwtKknih017/B7mPZfXOxaH9NS7x2XVfUlwIUQhkQLYysXrEQucm5r3kklCXAhHJTM+pqVmmkitVlbaus2LamWqSTAhXAZp/LJTN66rZYbvzyZmeoS4EI4xOqamFaPY24ng9uZGInpveH33g99CXAhbGZtJKb5dWcSHYkZ6YZcrKMaH35vvOeKleOkdEm11B06IglwIdJEqoItkcNamffcRZX4lJMAF8JBbr/hlkjou2lJtUwlAS6EyyRzTcwYWw95xo4+0FZ7vcQru9svlE6RABfCIVbWxCS4j9k9zDF6Ay/RnituztV0CH0JcCFsZm1NTCv7hN4stLKkWqQXjV4SK3OIWxHvXFK6pJrLQl8CXIg0kcisgAkd1+El1QYXUpZYGyABLoSDrPU1dlk1L4pkBmminzbSlQS4EA5zS33RzA3EiO3ZtiyplvhrRJKpkS4BLoRDEgk8s+tomj2UE6M3I5U5WWt8WpGsqXudJAEuhM0SqWWaCq+EbxbGf0mnmkkS6n8ubeBBEuBCuECyZvZz4sCJjJQ0dA9T8joqCXAhHJS0yalSIJm5KgN5IpMAF8JpLqlBmpn8KmJ7dpy9ZEm15JMAF8IhiVQKTY3E1PbVQGMd14mZBVPJUndEl52QBLgQNktklZtE7mE6cXPPqTbqVK8ElC4kwIVwAbsW6jV/XCde1MSrGthWIU0v0UiAC+GgNPiUHlWqasKR3lO39c9OFglwIRyWqtr1YKGliDthlIWZBQ014bjjrUgbEuBCOCSROTvMhr7ZGmi0rWMuqZakUZVx19606SKQDrPUSIALYbdkjcS04bDxwtCpZpLgbISGth00UEhq8UES4EK4gLUpWd2ZZE6UyqWnmnIS4EK4jFunSx1cqlS17Ue8ienOt8xxEuBCOCyRBQ+cKkfcduaIa2LG22eowW3zRkI/WT1K0iH04wa4UmqCUuotpdQ2pdRWpdRt/udLlVJvKKV2+7+WOF9cIbwjmflgNoyihaRbm2VCpbKIbgt9IzXwXuB/a61nAQuAW5VSs4A7gOVa62nAcv9jIUQCrNQ+g6HiwIhIQz0DE0hUKz0P3dIt0w3iBrjWuk5rvd7/fRuwHRgHXAc84t/sEeDjDpVRCE9J1tqUbo0xZ2rIbj3b1DLVBq6UqgLmAGuA0VrrOv+PjgGjo+xzi1KqRilV09DQkEhZhfAc21aLd4Eh7dkpatuP9CnFbU0byWI4wJVSRcCfgW9qrVtDf6Z9v6UR30Kt9QNa63la63kVFRUJFVYIL0pG7dpYfhmfTzZi0Fqbg9a05IWx91PfUIArpXLxhfcTWuvn/E/XK6XG+H8+BjjuTBGFEHazMhLTLVLZBu62OVeM9EJRwIPAdq31z0N+9AKw1P/9UmCZ/cUTwruStRpPIFSsBFvckZgGXjORODX0+iq8nB7oKJM0OQa2WQTcBGxWSm3wP/fvwL3AM0qpLwO1wA2OlFAIjwntlWE0j8300Y60TzIYPhdP1OPTQ9wA11q/R/SL7BX2FkcI4QbW2u2dra0HyHSyA2QkphAOS8o8Jwbyy0gt3w1LqsWfttbCi0Y6jqtvsBojAS5EmjC1jqaNNdZkN+VIA80ACXAhHOOO+bNjiReG4SvZ21/9NDYSU1rVo5EAF8Jm4SvfmN/L6OCfVPfGiHb8VJcrk0iAC5GB4q96Y2E2QofnTQmWI9JzLmubThYJcCEclowGACPNG2GfDKJuY29ZrTUJxVmv02JZhhwnSfs4SQJciDThxJJqTr+GsSXVBj+WNpoACXAhHJLIqEpz+yRHKmufEtqRSYALYTMrPTfC9zF4nBT3zYgWquFNNW5rdEgvEuBCuJDTFU5L09xaaJsevIuR05LIN04CXAiHJePTv5E8DpujxcvTEdrEiRusySYBLkSacHrIftTh9zFS365h8SrK95lOAlwIhyTt5qKDtUK5eehuEuBC2ExhoKkiiuhrW0U4TqpHYkZ7Pka5Ul3mdCMBLoTD3LLyuplXtGu9S2s3S80fOx3as62QABciDZiNoujt2eb3sXIcr3Lb6UiAC5EmUtUvPKGRmAZ2HrykmtzFHCABLoRDrNY+TdemrR1GpAEJcCFsZmVUpVvFquxaaieX6rOtJMCFcJyRZgI16LG5Ixi5IWdkiH9gm0hBG29YfGCfRHrhBI5kfo8kzSHjsiuyBLgQacLUkmo23pB0uk49+GIidfgBEuBCZDDH51yxqcoqTS+RSYAL4RCr/YzN7pduXfWEcRLgQtjM2pqY4dsbW+jA+VppzFGVg5s2DBU6sfKIcBLgQjjMykhMs4xcJ4z0jgneiIw0qtJoYUKPk7RRlUnax2V3MSXAhUgTZi4CgWYaM23LUZt2Ylyh7JiNcPBAHplga4AEuBBCeJQEuBAOsfph272rYgq3kQAXwm5hn/BN9ijxb+90u7kd624OWS0+0nEGNbsYOS+5HBknAS6Ew4z1KEnsGIaWVDMwQnJgJGaEYxgsS/iixslh5TiWRm+67OoiAS5EurBwFbBj9GYi1x4jN1GHzpUuAiTAhRCOcVuNNd1IgAvhEMvTyUroCYMkwIWwWcJrYmLPavFx9jK0lYpxQ3ZICSOWOc4+kfaQC5hhEuBCOMzoYBUnXjd8h4Fv497EjLi+pcHDKOsXMKsszTuTBkvESYALkSas3Nwzs89HfvFO5NdIaEk1I9uoQSMxrR8v1I2/X2PPC8XxTM0hdh5rc+S1EwpwpdTVSqmdSqk9Sqk77CqUEOmgt7+fpo5uTnT2GN7nhy9v51RPH9vrWg3v8/bOBtNlu+2pDTF/3tdv/LVaT/nPL0L19FvPboq4T21TZ9TX6zFzcL/V+5pN72OFlbJ959lNXPXLd9h21Pj/qVGWA1wplQ38GrgGmAV8Vik1y66CCeF1Nz24FoCXN9XF3fZUty8Y1h7wBdG7uxvj7tPvz8sfvrLdUHlCmxm2+S8Q7V29Yds0tXcD8NCK/QBkZ0Wv7hbm5wCwt6EDgLqW0wB0hLzmxkMnw/YZnps9qExDX/cbT34Q9ZgAbad7hzz3k9d2xNzHLv/8xHrL+04sK7CxJD6J1MDPB/ZorfdprbuBp4Dr7CmWEN41qiA37PH8qpK4+3QMCtJbL5sSd58Y2RpR66mhwffm9uNhj3OyfS9aWpgHDA3cUIEAD7jmnDOA2LXUnOzwyNkW4ZPGvsaOqPsDNLZ3xfy5VQV52dwwb7wjrw1QNOj9skMiAT4OOBTy+LD/uTBKqVuUUjVKqZqGBvMf9YTwmhmji5k7cRTgC8Cnb1kYd5+PzBod/P78qlK+deWMuPtcMXN08DgAV511RsztL51RERb6xfk5/PrGOWHb/OKGc5k1ZgTLb78EgIunlTNrzIiwbc4aO4IHbjov+PiXnz6Xr106hctn+s5h6YVVQy5aNy2YxB3XzAw+XnbrIrKzFLddMQ2AH37i7CHlnT66iM/Mn0B2lmLMyOFUFucD8PzXFvFPiydz32fDy372OF85v375VJ772oX84LqzqPDv88w/LeSWxZP5hv94oSqL81k4uYxVd1zBvf/4Ic70n++dS85k6z1XDdk+Sw1cPH/8j+fw7atm8Mm545lYWsDShZPIzVZcGfL/CXDvP54z5HXsoKyuGqKU+hRwtdb6K/7HNwEXaK3/Jdo+8+bN0zU1NZaOJ4QQmUoptU5rPW/w84nUwI8AE0Iej/c/J4QQIgkSCfD3gWlKqWqlVB7wGeAFe4olhBAiHsut6lrrXqXUvwB/BbKBh7TWW20rmRBCiJgSui2qtX4FeMWmsgghhDBBRmIKIYRHSYALIYRHSYALIYRHSYALIYRHWR7IY+lgSjUAtRZ3LwfiTxCR3uQ9kPcg088fMvM9mKS1rhj8ZFIDPBFKqZpII5EyibwH8h5k+vmDvAehpAlFCCE8SgJcCCE8yksB/kCqC+AC8h7Ie5Dp5w/yHgR5pg1cCCFEOC/VwIUQQoSQABdCCI/yRIBnyuLJSqkDSqnNSqkNSqka/3OlSqk3lFK7/V9L/M8rpdR9/vdkk1JqbmpLb41S6iGl1HGl1JaQ50yfs1JqqX/73Uqppak4F6uivAd3K6WO+H8XNiilloT87Lv+92CnUuqqkOc9+XeilJqglHpLKbVNKbVVKXWb//mM+j2wRGvt6n/4pqrdC0wG8oCNwKxUl8uhcz0AlA967qfAHf7v7wB+4v9+CfAqoIAFwJpUl9/iOS8G5gJbrJ4zUArs838t8X9fkupzS/A9uBv4VoRtZ/n/BvKBav/fRraX/06AMcBc//fFwC7/eWbU74GVf16ogWf64snXAY/4v38E+HjI849qn9XAKKXUmBSULyFa63eA5kFPmz3nq4A3tNbNWusTwBvA1Y4X3iZR3oNorgOe0lp3aa33A3vw/Y149u9Ea12ntV7v/74N2I5vfd2M+j2wwgsBbmjx5DShgdeVUuuUUrf4nxutta7zf38MCKyWms7vi9lzTtf34l/8TQQPBZoPSPP3QClVBcwB1iC/B3F5IcAzyUVa67nANcCtSqnFoT/Uvs+JGdXvMxPP2e83wBTgXKAO+K+UliYJlFJFwJ+Bb2qtW0N/lsG/BzF5IcAzZvFkrfUR/9fjwPP4PhbXB5pG/F+P+zdP5/fF7Dmn3Xuhta7XWvdprfuB3+H7XYA0fQ+UUrn4wvsJrfVz/qcz/vcgHi8EeEYsnqyUKlRKFQe+B64EtuA718Dd9KXAMv/3LwBf8N+RXwC0hHzc9Dqz5/xX4EqlVIm/qeFK/3OeNeh+xifw/S6A7z34jFIqXylVDUwD1uLhvxOllAIeBLZrrX8e8qOM/z2IK9V3UY38w3fXeRe+u+x3pro8Dp3jZHw9BzYCWwPnCZQBy4HdwJtAqf95Bfza/55sBual+hwsnveT+JoIevC1WX7ZyjkDX8J3Q28PcHOqz8uG9+Ax/zluwhdYY0K2v9P/HuwErgl53pN/J8BF+JpHNgEb/P+WZNrvgZV/MpReCCE8ygtNKEIIISKQABdCCI+SABdCCI+SABdCCI+SABdCCI+SABdCCI+SABdCCI/6H1LuKaN5DiVuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.600000    88.409524    88.219048    88.028571    87.838095   \n",
      "351    88.409524    88.219048    88.028571    87.838095    87.647619   \n",
      "352    88.219048    88.028571    87.838095    87.647619    87.457143   \n",
      "353    88.028571    87.838095    87.647619    87.457143    87.266667   \n",
      "354    87.838095    87.647619    87.457143    87.266667    87.076190   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.647619    87.457143    87.266667    87.076190    86.896218  ...   \n",
      "351    87.457143    87.266667    87.076190    86.896218    86.845798  ...   \n",
      "352    87.266667    87.076190    86.896218    86.845798    86.795378  ...   \n",
      "353    87.076190    86.896218    86.845798    86.795378    86.744958  ...   \n",
      "354    86.896218    86.845798    86.795378    86.744958    86.694538  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   78.880345    0.000263   78.856069    0.000263   78.831793    0.000263   \n",
      "351   78.856069    0.000263   78.831793    0.000263   78.807516    0.000262   \n",
      "352   78.831793    0.000263   78.807516    0.000262   78.783240    0.000262   \n",
      "353   78.807516    0.000262   78.783240    0.000262   78.758964    0.000262   \n",
      "354   78.783240    0.000262   78.758964    0.000262   78.734687    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   78.807516    0.000262   78.783240    0.000262  \n",
      "351   78.783240    0.000262   78.758964    0.000262  \n",
      "352   78.758964    0.000262   78.734687    0.000262  \n",
      "353   78.734687    0.000262   78.710411    0.000262  \n",
      "354   78.710411    0.000262   78.686134    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 1, 251) (1900, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 3s 25ms/step - loss: 4931.6377 - val_loss: 2669.9727\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4562.1616 - val_loss: 2476.5542\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4366.5547 - val_loss: 2393.3330\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4225.3350 - val_loss: 2323.4187\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4103.9761 - val_loss: 2263.1277\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3989.4917 - val_loss: 2202.9158\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3879.7424 - val_loss: 2146.3220\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3773.9070 - val_loss: 2093.1914\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3671.3582 - val_loss: 2042.3857\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3571.7954 - val_loss: 1993.7253\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3474.9917 - val_loss: 1947.1117\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3380.7888 - val_loss: 1902.7513\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3289.0642 - val_loss: 1859.9764\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3199.7168 - val_loss: 1818.9796\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3112.6641 - val_loss: 1779.7263\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3027.8335 - val_loss: 1742.1667\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2945.1626 - val_loss: 1706.2538\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2864.5925 - val_loss: 1671.9437\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2786.0737 - val_loss: 1639.1947\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2709.5562 - val_loss: 1607.9608\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2635.0227 - val_loss: 1578.2428\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2562.3511 - val_loss: 1549.9280\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2491.5696 - val_loss: 1523.0417\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2422.6289 - val_loss: 1497.5326\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2355.4839 - val_loss: 1473.3655\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2290.0986 - val_loss: 1450.5071\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2226.4387 - val_loss: 1428.9227\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2164.4695 - val_loss: 1408.5743\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2104.1575 - val_loss: 1389.4062\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2045.4681 - val_loss: 1371.0205\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1988.4990 - val_loss: 1354.6833\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1932.9094 - val_loss: 1339.1064\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1878.9133 - val_loss: 1324.7615\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1826.5107 - val_loss: 1314.1942\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1775.3955 - val_loss: 1301.9902\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1725.8140 - val_loss: 1290.8044\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1677.6455 - val_loss: 1280.6099\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1630.8616 - val_loss: 1271.3788\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1585.4351 - val_loss: 1263.0841\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1541.3380 - val_loss: 1255.6990\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1498.5427 - val_loss: 1249.1965\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1457.0231 - val_loss: 1243.5509\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1416.7524 - val_loss: 1238.7365\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1377.7043 - val_loss: 1234.1339\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1335.6732 - val_loss: 1232.2300\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1311.7004 - val_loss: 1229.4333\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1272.7542 - val_loss: 1227.4336\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1235.2184 - val_loss: 1226.2859\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1199.3356 - val_loss: 1225.9337\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1164.9490 - val_loss: 1226.3300\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1131.9390 - val_loss: 1227.4346\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1100.2175 - val_loss: 1229.2114\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1069.7169 - val_loss: 1231.6282\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1040.3796 - val_loss: 1234.6536\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1012.1581 - val_loss: 1238.2585\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 985.0092 - val_loss: 1242.4147\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 958.8928 - val_loss: 1247.0955\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 933.7731 - val_loss: 1252.2743\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 909.6169 - val_loss: 1257.9258\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 886.3914 - val_loss: 1264.0253\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 864.0672 - val_loss: 1270.5487\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 842.6150 - val_loss: 1277.4724\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 822.0068 - val_loss: 1284.7736\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 802.2164 - val_loss: 1292.4299\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 783.2173 - val_loss: 1300.4191\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 764.9847 - val_loss: 1308.7201\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 747.4943 - val_loss: 1317.3118\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 730.7223 - val_loss: 1326.1742\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 714.6456 - val_loss: 1335.2869\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 699.2419 - val_loss: 1344.6305\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 684.4893 - val_loss: 1354.1860\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 670.3661 - val_loss: 1363.9351\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 656.8519 - val_loss: 1373.8590\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 643.9261 - val_loss: 1383.9403\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 631.5689 - val_loss: 1394.1622\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 619.7606 - val_loss: 1404.5076\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 608.4824 - val_loss: 1414.9602\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 597.7157 - val_loss: 1425.5048\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 587.4426 - val_loss: 1436.1249\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 577.6449 - val_loss: 1446.8059\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 568.3059 - val_loss: 1457.5341\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 559.4084 - val_loss: 1468.2947\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 550.9359 - val_loss: 1479.0745\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 542.8724 - val_loss: 1489.8600\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 535.2025 - val_loss: 1500.6400\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 527.9103 - val_loss: 1511.4001\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 520.9817 - val_loss: 1522.1310\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 514.4017 - val_loss: 1532.8195\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 508.1564 - val_loss: 1543.4559\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 502.2319 - val_loss: 1554.0304\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 496.6148 - val_loss: 1564.5323\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 491.2926 - val_loss: 1574.9523\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 486.2522 - val_loss: 1585.2821\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 481.4817 - val_loss: 1595.5132\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 476.9691 - val_loss: 1605.6365\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 472.7030 - val_loss: 1615.6464\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 468.6722 - val_loss: 1625.5342\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 464.8659 - val_loss: 1635.2937\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 461.2737 - val_loss: 1644.9192\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 457.8856 - val_loss: 1654.4052\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 454.6918 - val_loss: 1663.7451\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 451.6828 - val_loss: 1672.9353\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 448.8497 - val_loss: 1681.9703\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 446.1837 - val_loss: 1690.8469\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 443.6764 - val_loss: 1699.5610\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 441.3197 - val_loss: 1708.1089\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 439.1059 - val_loss: 1716.4888\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 437.0273 - val_loss: 1724.6970\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 435.0771 - val_loss: 1732.7325\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 433.2480 - val_loss: 1740.5922\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 431.5337 - val_loss: 1748.2753\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 429.9278 - val_loss: 1755.7811\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 428.4243 - val_loss: 1763.1067\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 427.0174 - val_loss: 1770.2552\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 425.7015 - val_loss: 1777.2230\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 424.4717 - val_loss: 1784.0118\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 423.3225 - val_loss: 1790.6216\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 422.2495 - val_loss: 1797.0529\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 421.2480 - val_loss: 1803.3069\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 420.3137 - val_loss: 1809.3850\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 419.4425 - val_loss: 1815.2872\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 418.6306 - val_loss: 1821.0153\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 417.8742 - val_loss: 1826.5724\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 417.1699 - val_loss: 1831.9596\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 416.5142 - val_loss: 1837.1780\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 415.9043 - val_loss: 1842.2307\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 415.3370 - val_loss: 1847.1207\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 414.8097 - val_loss: 1851.8494\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 414.3196 - val_loss: 1856.4203\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.8643 - val_loss: 1860.8353\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.4414 - val_loss: 1865.0980\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 413.0489 - val_loss: 1869.2107\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 412.6844 - val_loss: 1873.1772\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 412.3464 - val_loss: 1877.0004\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 412.0327 - val_loss: 1880.6836\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 411.7419 - val_loss: 1884.2292\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 411.4722 - val_loss: 1887.6411\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 411.2223 - val_loss: 1890.9233\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 410.9905 - val_loss: 1894.0780\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 410.7758 - val_loss: 1897.1083\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 410.5768 - val_loss: 1900.0184\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 410.3925 - val_loss: 1902.8115\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 410.2217 - val_loss: 1905.4911\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 410.0637 - val_loss: 1908.0605\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 409.9170 - val_loss: 1910.5228\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 409.7813 - val_loss: 1912.8810\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 409.6558 - val_loss: 1915.1384\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 409.5393 - val_loss: 1917.2998\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 409.4315 - val_loss: 1919.3668\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 409.3317 - val_loss: 1921.3427\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 409.2391 - val_loss: 1923.2312\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 409.1534 - val_loss: 1925.0342\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 409.0741 - val_loss: 1926.7566\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 409.0006 - val_loss: 1928.4000\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.9325 - val_loss: 1929.9668\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.8693 - val_loss: 1931.4620\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.8109 - val_loss: 1932.8872\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.7566 - val_loss: 1934.2438\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.7063 - val_loss: 1935.5361\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.6598 - val_loss: 1936.7657\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.6166 - val_loss: 1937.9369\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 408.5766 - val_loss: 1939.0496\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 408.5395 - val_loss: 1940.1084\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 408.5050 - val_loss: 1941.1135\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.4731 - val_loss: 1942.0690\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.4435 - val_loss: 1942.9762\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.4160 - val_loss: 1943.8363\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.3905 - val_loss: 1944.6539\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.3669 - val_loss: 1945.4293\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.3449 - val_loss: 1946.1642\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.3245 - val_loss: 1946.8599\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.3056 - val_loss: 1947.5198\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.2881 - val_loss: 1948.1450\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.2718 - val_loss: 1948.7363\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.2567 - val_loss: 1949.2969\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.2428 - val_loss: 1949.8273\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.2297 - val_loss: 1950.3280\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 408.2178 - val_loss: 1950.8022\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.2066 - val_loss: 1951.2506\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.1962 - val_loss: 1951.6732\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 408.1867 - val_loss: 1952.0737\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 408.1778 - val_loss: 1952.4513\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1696 - val_loss: 1952.8076\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1620 - val_loss: 1953.1444\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1550 - val_loss: 1953.4617\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1486 - val_loss: 1953.7607\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1425 - val_loss: 1954.0431\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 408.1370 - val_loss: 1954.3096\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 408.1318 - val_loss: 1954.5602\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1271 - val_loss: 1954.7960\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1229 - val_loss: 1955.0194\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1188 - val_loss: 1955.2290\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1152 - val_loss: 1955.4263\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1118 - val_loss: 1955.6117\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1087 - val_loss: 1955.7869\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1059 - val_loss: 1955.9513\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.1034 - val_loss: 1956.1056\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.1010 - val_loss: 1956.2513\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0988 - val_loss: 1956.3877\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0969 - val_loss: 1956.5165\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0951 - val_loss: 1956.6370\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.0936 - val_loss: 1956.7500\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0922 - val_loss: 1956.8571\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0909 - val_loss: 1956.9564\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0898 - val_loss: 1957.0503\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0887 - val_loss: 1957.1388\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0879 - val_loss: 1957.2214\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0871 - val_loss: 1957.2991\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0864 - val_loss: 1957.3718\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0858 - val_loss: 1957.4402\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0854 - val_loss: 1957.5034\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0850 - val_loss: 1957.5641\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0846 - val_loss: 1957.6199\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.0844 - val_loss: 1957.6724\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0841 - val_loss: 1957.7220\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 408.0840 - val_loss: 1957.7681\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 408.0840 - val_loss: 1957.8115\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0840 - val_loss: 1957.8518\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0840 - val_loss: 1957.8898\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0840 - val_loss: 1957.9252\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0840 - val_loss: 1957.9589\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0842 - val_loss: 1957.9897\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0844 - val_loss: 1958.0190\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0845 - val_loss: 1958.0460\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.0848 - val_loss: 1958.0714\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0851 - val_loss: 1958.0948\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0853 - val_loss: 1958.1174\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.0856 - val_loss: 1958.1384\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.0859 - val_loss: 1958.1572\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0863 - val_loss: 1958.1761\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.0865 - val_loss: 1958.1932\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0869 - val_loss: 1958.2091\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0872 - val_loss: 1958.2240\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.0876 - val_loss: 1958.2371\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 408.0881 - val_loss: 1958.2509\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 408.0885 - val_loss: 1958.2625\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.0888 - val_loss: 1958.2740\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0891 - val_loss: 1958.2844\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0896 - val_loss: 1958.2944\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0900 - val_loss: 1958.3035\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 408.0904 - val_loss: 1958.3124\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 408.0908 - val_loss: 1958.3207\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0911 - val_loss: 1958.3281\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0916 - val_loss: 1958.3346\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0920 - val_loss: 1958.3411\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.0925 - val_loss: 1958.3472\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0929 - val_loss: 1958.3533\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.0933 - val_loss: 1958.3589\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0936 - val_loss: 1958.3635\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0940 - val_loss: 1958.3679\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.0945 - val_loss: 1958.3721\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0948 - val_loss: 1958.3768\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0952 - val_loss: 1958.3801\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0956 - val_loss: 1958.3840\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.0960 - val_loss: 1958.3868\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0963 - val_loss: 1958.3901\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.0967 - val_loss: 1958.3931\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.0970 - val_loss: 1958.3959\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0974 - val_loss: 1958.3977\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.0977 - val_loss: 1958.3997\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0982 - val_loss: 1958.4016\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.0984 - val_loss: 1958.4041\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0988 - val_loss: 1958.4062\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.0992 - val_loss: 1958.4078\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.0995 - val_loss: 1958.4092\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.0998 - val_loss: 1958.4106\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1001 - val_loss: 1958.4120\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1004 - val_loss: 1958.4142\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1006 - val_loss: 1958.4152\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 408.1011 - val_loss: 1958.4165\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1013 - val_loss: 1958.4172\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1017 - val_loss: 1958.4175\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1018 - val_loss: 1958.4186\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1022 - val_loss: 1958.4194\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1025 - val_loss: 1958.4197\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1028 - val_loss: 1958.4197\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1031 - val_loss: 1958.4209\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1033 - val_loss: 1958.4220\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1035 - val_loss: 1958.4224\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1038 - val_loss: 1958.4229\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1041 - val_loss: 1958.4243\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1042 - val_loss: 1958.4250\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1044 - val_loss: 1958.4250\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1047 - val_loss: 1958.4257\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1049 - val_loss: 1958.4260\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1052 - val_loss: 1958.4260\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1055 - val_loss: 1958.4261\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1056 - val_loss: 1958.4266\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1058 - val_loss: 1958.4268\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1060 - val_loss: 1958.4268\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1063 - val_loss: 1958.4268\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1064 - val_loss: 1958.4272\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1066 - val_loss: 1958.4276\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1068 - val_loss: 1958.4276\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1070 - val_loss: 1958.4280\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1071 - val_loss: 1958.4279\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 408.1074 - val_loss: 1958.4280\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.1075 - val_loss: 1958.4280\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1076 - val_loss: 1958.4280\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1078 - val_loss: 1958.4280\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1080 - val_loss: 1958.4281\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1082 - val_loss: 1958.4281\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1083 - val_loss: 1958.4281\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1084 - val_loss: 1958.4276\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1086 - val_loss: 1958.4280\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1087 - val_loss: 1958.4280\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1089 - val_loss: 1958.4280\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1090 - val_loss: 1958.4276\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1092 - val_loss: 1958.4276\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1093 - val_loss: 1958.4279\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1095 - val_loss: 1958.4279\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1095 - val_loss: 1958.4279\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1097 - val_loss: 1958.4279\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1098 - val_loss: 1958.4279\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1099 - val_loss: 1958.4279\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1100 - val_loss: 1958.4279\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1101 - val_loss: 1958.4279\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1102 - val_loss: 1958.4280\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1103 - val_loss: 1958.4276\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1104 - val_loss: 1958.4276\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1105 - val_loss: 1958.4276\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1106 - val_loss: 1958.4283\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1107 - val_loss: 1958.4283\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1109 - val_loss: 1958.4285\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1109 - val_loss: 1958.4288\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 408.1109 - val_loss: 1958.4290\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 408.1110 - val_loss: 1958.4290\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 408.1112 - val_loss: 1958.4290\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1112 - val_loss: 1958.4294\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1113 - val_loss: 1958.4290\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1113 - val_loss: 1958.4288\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1114 - val_loss: 1958.4286\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1115 - val_loss: 1958.4283\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1116 - val_loss: 1958.4283\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1116 - val_loss: 1958.4280\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1118 - val_loss: 1958.4275\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1118 - val_loss: 1958.4272\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1119 - val_loss: 1958.4271\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1120 - val_loss: 1958.4272\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1121 - val_loss: 1958.4276\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1121 - val_loss: 1958.4276\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1122 - val_loss: 1958.4280\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1122 - val_loss: 1957.5103\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.2249 - val_loss: 1958.4445\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1121 - val_loss: 1958.4446\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1121 - val_loss: 1958.4435\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1121 - val_loss: 1958.4421\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1121 - val_loss: 1958.4403\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1122 - val_loss: 1958.4397\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1123 - val_loss: 1958.4375\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 408.1125 - val_loss: 1958.4366\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1126 - val_loss: 1958.4366\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1126 - val_loss: 1958.4362\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1126 - val_loss: 1958.4355\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1127 - val_loss: 1958.4348\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1127 - val_loss: 1958.4338\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1127 - val_loss: 1958.4333\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1128 - val_loss: 1958.4327\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1129 - val_loss: 1958.4326\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1129 - val_loss: 1958.4319\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1130 - val_loss: 1958.4313\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1130 - val_loss: 1958.4299\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1131 - val_loss: 1958.4290\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1132 - val_loss: 1958.4286\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1133 - val_loss: 1958.4286\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1133 - val_loss: 1958.4283\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.1133 - val_loss: 1958.4283\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1134 - val_loss: 1958.4283\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1134 - val_loss: 1958.4293\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1134 - val_loss: 1958.4290\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1133 - val_loss: 1958.4283\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.1134 - val_loss: 1958.4279\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1135 - val_loss: 1958.4276\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1135 - val_loss: 1958.4275\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 408.1136 - val_loss: 1958.4270\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 408.1136 - val_loss: 1958.4265\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1137 - val_loss: 1958.4270\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.1137 - val_loss: 1958.4268\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.1137 - val_loss: 1958.4266\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.1137 - val_loss: 1958.4261\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1137 - val_loss: 1958.4257\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1138 - val_loss: 1958.4252\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1138 - val_loss: 1958.4252\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1139 - val_loss: 1958.4257\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1139 - val_loss: 1958.4261\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1139 - val_loss: 1958.4270\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.1139 - val_loss: 1958.4272\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1139 - val_loss: 1958.4279\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1139 - val_loss: 1958.4279\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1139 - val_loss: 1958.4279\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1139 - val_loss: 1958.4276\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1139 - val_loss: 1958.4268\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1139 - val_loss: 1958.4268\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1140 - val_loss: 1958.4265\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.1140 - val_loss: 1958.4258\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1141 - val_loss: 1958.4258\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 408.1141 - val_loss: 1958.4252\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1141 - val_loss: 1958.4250\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1141 - val_loss: 1958.4252\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1141 - val_loss: 1958.4250\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1141 - val_loss: 1958.4248\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1141 - val_loss: 1958.4248\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1142 - val_loss: 1958.4248\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1142 - val_loss: 1958.4257\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1142 - val_loss: 1958.4260\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1141 - val_loss: 1958.4260\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1141 - val_loss: 1958.4258\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1141 - val_loss: 1958.4258\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1142 - val_loss: 1958.4253\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1142 - val_loss: 1958.4253\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1142 - val_loss: 1958.4250\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1142 - val_loss: 1958.4248\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1142 - val_loss: 1958.4243\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1142 - val_loss: 1958.4238\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1142 - val_loss: 1958.4235\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1142 - val_loss: 1958.4235\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1142 - val_loss: 1958.4233\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1143 - val_loss: 1958.4232\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 408.1143 - val_loss: 1958.4227\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.1144 - val_loss: 1958.4225\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1144 - val_loss: 1958.4224\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4222\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4222\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4222\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1145 - val_loss: 1958.4218\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1145 - val_loss: 1958.4218\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4215\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1146 - val_loss: 1958.4218\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 408.1146 - val_loss: 1958.4219\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1146 - val_loss: 1958.4224\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4225\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4237\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4246\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4247\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1145 - val_loss: 1958.4253\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4257\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1144 - val_loss: 1958.4260\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1145 - val_loss: 1958.4261\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1144 - val_loss: 1958.4266\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4271\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1144 - val_loss: 1958.4271\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 408.1144 - val_loss: 1958.4275\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1144 - val_loss: 1958.4272\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1144 - val_loss: 1958.4272\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1144 - val_loss: 1958.4271\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1144 - val_loss: 1958.4270\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1144 - val_loss: 1958.4270\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1145 - val_loss: 1958.4268\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.1144 - val_loss: 1958.4266\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1144 - val_loss: 1958.4263\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1144 - val_loss: 1958.4258\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1144 - val_loss: 1958.4250\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4243\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 408.1145 - val_loss: 1958.4243\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1145 - val_loss: 1958.4237\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1144 - val_loss: 1958.4235\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1145 - val_loss: 1958.4235\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1145 - val_loss: 1958.4230\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4227\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4222\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4219\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4218\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1145 - val_loss: 1958.4213\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 408.1145 - val_loss: 1958.4208\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1146 - val_loss: 1958.4203\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1146 - val_loss: 1958.4203\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1146 - val_loss: 1958.4196\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 408.1147 - val_loss: 1958.4191\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 408.1147 - val_loss: 1958.4189\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1146 - val_loss: 1958.4186\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1147 - val_loss: 1958.4185\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1147 - val_loss: 1958.4185\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1147 - val_loss: 1958.4182\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1147 - val_loss: 1958.4182\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1148 - val_loss: 1958.4182\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1148 - val_loss: 1958.4185\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1148 - val_loss: 1958.4185\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1148 - val_loss: 1958.4185\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1148 - val_loss: 1958.4185\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1148 - val_loss: 1958.4182\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1148 - val_loss: 1958.4182\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1148 - val_loss: 1958.4182\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1148 - val_loss: 1958.4185\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 408.1148 - val_loss: 1958.4185\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1148 - val_loss: 1958.4181\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1148 - val_loss: 1958.4181\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1148 - val_loss: 1958.4181\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1148 - val_loss: 1958.4181\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1148 - val_loss: 1958.4182\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 408.1148 - val_loss: 1958.4182\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1148 - val_loss: 1958.4181\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1148 - val_loss: 1958.4181\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1148 - val_loss: 1958.4181\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1148 - val_loss: 1958.4181\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1148 - val_loss: 1958.4181\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1148 - val_loss: 1958.4181\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1148 - val_loss: 1958.4181\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 408.1148 - val_loss: 1958.4180\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 408.1148 - val_loss: 1958.4180\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 408.1148 - val_loss: 1958.4180\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 672ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.01932073e+01, 7.36761204e+01, 7.25416667e+01, 7.11886555e+01,\n",
       "        7.11075211e+01, 4.39326410e-01, 3.17974810e-01, 3.42982888e-01,\n",
       "        2.95476110e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.43500507e-01, 7.03304622e+01, 7.02548319e+01, 7.01792017e+01,\n",
       "        5.86903811e-01, 0.00000000e+00, 7.05125350e+01, 7.04369048e+01,\n",
       "        7.03612745e+01, 7.02856443e+01, 7.02100140e+01, 7.39282213e+01,\n",
       "        7.27937675e+01, 7.14911765e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        9.65869900e-02, 7.02408263e+01, 7.42602708e+01, 7.32559524e+01,\n",
       "        7.20457983e+01, 1.00360058e-01, 7.26537115e+01, 7.13231092e+01,\n",
       "        7.05769608e+01, 1.33408070e-01, 3.12022328e-01, 4.34099140e-02,\n",
       "        8.12284648e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.17936975e+01,\n",
       "        4.63057580e-01, 2.55010930e-01, 0.00000000e+00, 7.02576330e+01,\n",
       "        7.01820028e+01, 7.35080532e+01, 7.23483193e+01, 7.09869748e+01,\n",
       "        7.29058123e+01, 7.16256303e+01, 7.06273810e+01, 8.41440100e-02,\n",
       "        5.84851560e-01, 0.00000000e+00, 7.15415966e+01, 4.60363360e-01,\n",
       "        7.21802521e+01, 7.08189076e+01, 7.04929272e+01, 7.14575630e+01,\n",
       "        7.05993697e+01, 7.03724790e+01, 1.62238000e-01, 1.15270970e-01,\n",
       "        0.00000000e+00, 6.69685440e+01, 5.63798010e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 8.49525000e-02, 0.00000000e+00,\n",
       "        6.65316391e+01, 7.21141845e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.63008595e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.99926808e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.16610482e-01, 0.00000000e+00, 1.08397090e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.27636027e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56.83234269, 56.82004509, 56.80774749, 56.79544989, 56.78315229,\n",
       "       56.77085468, 56.75855708, 56.74625948, 56.73396188, 56.72166428,\n",
       "       56.70936667, 56.69706907, 56.68477147, 56.67247387, 56.66017627,\n",
       "       56.64787866, 56.63558106, 56.62328346, 56.61098586, 56.59868826,\n",
       "       56.58639065, 56.57409305, 56.56179545, 56.54949785, 56.53720025,\n",
       "       56.52490264, 56.51260504, 56.50030744, 56.48800984, 56.47571224,\n",
       "       56.46341463, 56.45111703, 56.43881943, 56.42652183, 56.41422423,\n",
       "       56.40192662, 56.38962902, 56.37733142, 56.36503382, 56.35273622,\n",
       "       56.34043861, 56.32814101, 56.31584341, 56.30354581, 56.29124821,\n",
       "       56.2789506 , 56.266653  , 56.2543554 , 56.2420578 , 56.2297602 ,\n",
       "       56.21746259, 56.20516499, 56.19286739, 56.18056979, 56.16827219,\n",
       "       56.15597458, 56.14367698, 56.13137938, 56.11908178, 56.10678418,\n",
       "       56.09448658, 56.08218897, 56.06989137, 56.05759377, 56.04529617,\n",
       "       56.03299857, 56.02070096, 56.00840336, 55.99610576, 55.98380816,\n",
       "       55.97151056, 55.95921295, 55.94691535, 55.93461775, 55.92232015,\n",
       "       55.91002255, 55.89772494, 55.88542734, 55.87312974, 55.86083214,\n",
       "       55.84853454, 55.83623693, 55.82393933, 55.81164173, 55.79934413,\n",
       "       55.78704653, 55.77474892, 55.76245132, 55.75015372, 55.73785612,\n",
       "       55.72555852, 55.71326091, 55.70096331, 55.68866571, 55.67636811,\n",
       "       55.66407051, 55.6517729 , 55.6394753 , 55.6271777 , 55.6148801 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.01875443647359\n",
      "39.085666916119955\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
