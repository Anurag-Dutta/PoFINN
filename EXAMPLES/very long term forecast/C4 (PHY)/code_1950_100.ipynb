{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "2045    61.268079\n",
       "2046    61.248004\n",
       "2047    61.227930\n",
       "2048    61.207855\n",
       "2049    61.187780\n",
       "Name: C4, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_1950_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1945     0.000000\n",
       "1946     0.189781\n",
       "1947     0.643501\n",
       "1948     0.000000\n",
       "1949     0.200734\n",
       "Name: C4, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1950)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.409524</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.219048</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.028571</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.838095</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.600000  0.000298\n",
       "1     88.409524  0.000298\n",
       "2     88.219048  0.000297\n",
       "3     88.028571  0.000297\n",
       "4     87.838095  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.600000    88.409524    88.219048    88.028571    87.838095   \n",
      "351    88.409524    88.219048    88.028571    87.838095    87.647619   \n",
      "352    88.219048    88.028571    87.838095    87.647619    87.457143   \n",
      "353    88.028571    87.838095    87.647619    87.457143    87.266667   \n",
      "354    87.838095    87.647619    87.457143    87.266667    87.076190   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.647619    87.457143    87.266667    87.076190    86.896218  ...   \n",
      "351    87.457143    87.266667    87.076190    86.896218    86.845798  ...   \n",
      "352    87.266667    87.076190    86.896218    86.845798    86.795378  ...   \n",
      "353    87.076190    86.896218    86.845798    86.795378    86.744958  ...   \n",
      "354    86.896218    86.845798    86.795378    86.744958    86.694538  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   78.880345    0.000263   78.856069    0.000263   78.831793    0.000263   \n",
      "351   78.856069    0.000263   78.831793    0.000263   78.807516    0.000262   \n",
      "352   78.831793    0.000263   78.807516    0.000262   78.783240    0.000262   \n",
      "353   78.807516    0.000262   78.783240    0.000262   78.758964    0.000262   \n",
      "354   78.783240    0.000262   78.758964    0.000262   78.734687    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   78.807516    0.000262   78.783240    0.000262  \n",
      "351   78.783240    0.000262   78.758964    0.000262  \n",
      "352   78.758964    0.000262   78.734687    0.000262  \n",
      "353   78.734687    0.000262   78.710411    0.000262  \n",
      "354   78.710411    0.000262   78.686134    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1, 251) (1500, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 3s 30ms/step - loss: 5260.3599 - val_loss: 3657.8809\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5050.6514 - val_loss: 3475.4885\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4918.0864 - val_loss: 3403.8684\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4834.5264 - val_loss: 3345.3816\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4744.4448 - val_loss: 3278.7373\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4658.6177 - val_loss: 3220.2480\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4574.0298 - val_loss: 3159.7351\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4490.7524 - val_loss: 3102.5339\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4409.7358 - val_loss: 3046.9995\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4330.6499 - val_loss: 2992.8821\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4253.2012 - val_loss: 2939.9924\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4177.2070 - val_loss: 2888.7593\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4102.5474 - val_loss: 2838.2827\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4029.1445 - val_loss: 2788.7239\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3956.9375 - val_loss: 2740.1626\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3885.8816 - val_loss: 2692.5662\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3815.9387 - val_loss: 2645.9084\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3747.0789 - val_loss: 2600.1675\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3679.2754 - val_loss: 2555.3237\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3612.5076 - val_loss: 2511.3586\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3546.7529 - val_loss: 2468.2563\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3481.9937 - val_loss: 2426.0022\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3418.2134 - val_loss: 2384.5818\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3355.3955 - val_loss: 2343.9827\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3293.5264 - val_loss: 2304.1924\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3232.5928 - val_loss: 2265.1992\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 3172.5801 - val_loss: 2226.9912\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3113.4773 - val_loss: 2189.5581\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3055.2722 - val_loss: 2152.8884\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2997.9521 - val_loss: 2116.9731\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2941.5078 - val_loss: 2081.8018\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2885.9275 - val_loss: 2047.3638\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2831.2009 - val_loss: 2013.6504\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2777.3174 - val_loss: 1980.6516\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2724.2671 - val_loss: 1948.3596\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2672.0413 - val_loss: 1916.7635\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2620.6299 - val_loss: 1885.8562\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2570.0234 - val_loss: 1855.6274\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2520.2129 - val_loss: 1826.0699\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2471.1880 - val_loss: 1797.1740\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2422.9417 - val_loss: 1768.9319\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2375.4648 - val_loss: 1741.3351\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 2328.7473 - val_loss: 1714.3752\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 2282.7815 - val_loss: 1688.0444\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2237.5596 - val_loss: 1662.3348\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2193.0730 - val_loss: 1637.2383\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2149.3127 - val_loss: 1612.7467\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2106.2712 - val_loss: 1588.8524\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2063.9404 - val_loss: 1565.5480\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2022.3123 - val_loss: 1542.8250\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1981.3783 - val_loss: 1520.6761\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1941.1318 - val_loss: 1499.0941\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1901.5643 - val_loss: 1478.0709\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1862.6681 - val_loss: 1457.5997\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1824.4358 - val_loss: 1437.6732\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1786.8596 - val_loss: 1418.2832\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1749.9323 - val_loss: 1399.4229\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1713.6464 - val_loss: 1381.0848\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1677.9941 - val_loss: 1363.2621\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1642.9686 - val_loss: 1345.9476\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1608.5627 - val_loss: 1329.1337\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1574.7688 - val_loss: 1312.8142\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1541.5803 - val_loss: 1296.9811\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1508.9891 - val_loss: 1281.6283\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1476.9891 - val_loss: 1266.7480\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1445.5728 - val_loss: 1252.3340\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1414.7334 - val_loss: 1238.3790\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1384.4640 - val_loss: 1224.8763\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1354.7577 - val_loss: 1211.8192\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1325.6071 - val_loss: 1199.2010\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1297.0067 - val_loss: 1187.0150\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1268.9489 - val_loss: 1175.2545\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1241.4269 - val_loss: 1163.9125\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1214.4343 - val_loss: 1152.9832\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1187.9645 - val_loss: 1142.4590\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1162.0111 - val_loss: 1132.3340\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1136.5671 - val_loss: 1122.6016\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1111.6262 - val_loss: 1113.2556\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1087.1821 - val_loss: 1104.2887\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 1063.2283 - val_loss: 1095.6954\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1039.7582 - val_loss: 1087.4688\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1016.7653 - val_loss: 1079.6027\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 994.2438 - val_loss: 1072.0909\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 972.1872 - val_loss: 1064.9271\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 950.5892 - val_loss: 1058.1050\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 929.4434 - val_loss: 1051.6184\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 908.7443 - val_loss: 1045.4612\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 888.4850 - val_loss: 1039.6268\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 868.6597 - val_loss: 1034.1096\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 849.2625 - val_loss: 1028.9033\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 830.2870 - val_loss: 1024.0021\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 811.7276 - val_loss: 1019.3996\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 793.5778 - val_loss: 1015.0899\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 775.8320 - val_loss: 1011.0673\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 758.4843 - val_loss: 1007.3253\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 741.5287 - val_loss: 1003.8585\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 724.9597 - val_loss: 1000.6608\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 708.7708 - val_loss: 997.7267\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 692.9568 - val_loss: 995.0500\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 677.5119 - val_loss: 992.6252\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 662.4302 - val_loss: 990.4464\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 647.7063 - val_loss: 988.5079\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 633.3340 - val_loss: 986.8041\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 619.3086 - val_loss: 985.3295\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 605.6238 - val_loss: 984.0782\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 592.2744 - val_loss: 983.0449\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 579.2545 - val_loss: 982.2239\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 566.5589 - val_loss: 981.6099\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 554.1824 - val_loss: 981.1974\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 542.1191 - val_loss: 980.9808\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 530.3641 - val_loss: 980.9549\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 518.9118 - val_loss: 981.1144\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 507.7569 - val_loss: 981.4539\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 496.8943 - val_loss: 981.9681\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 486.3185 - val_loss: 982.6521\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 476.0247 - val_loss: 983.5002\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 466.0076 - val_loss: 984.5079\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 456.2619 - val_loss: 985.6696\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 446.7827 - val_loss: 986.9807\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 437.5651 - val_loss: 988.4356\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 428.6038 - val_loss: 990.0298\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 419.8939 - val_loss: 991.7584\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 411.4308 - val_loss: 993.6166\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 403.2092 - val_loss: 995.5994\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 395.2247 - val_loss: 997.7018\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 387.4724 - val_loss: 999.9195\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 379.9474 - val_loss: 1002.2478\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 372.6449 - val_loss: 1004.6821\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 365.5604 - val_loss: 1007.2177\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 358.6892 - val_loss: 1009.8501\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 352.0269 - val_loss: 1012.5750\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 345.5688 - val_loss: 1015.3879\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 339.3103 - val_loss: 1018.2847\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 333.2474 - val_loss: 1021.2606\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 327.3752 - val_loss: 1024.3118\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 321.6896 - val_loss: 1027.4343\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 316.1862 - val_loss: 1030.6235\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 310.8610 - val_loss: 1033.8759\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 305.7095 - val_loss: 1037.1869\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 300.7277 - val_loss: 1040.5531\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 295.9113 - val_loss: 1043.9706\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 291.2566 - val_loss: 1047.4353\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 286.7593 - val_loss: 1050.9437\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 282.4155 - val_loss: 1054.4923\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 278.2214 - val_loss: 1058.0771\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 274.1730 - val_loss: 1061.6952\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 270.2666 - val_loss: 1065.3424\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 266.4985 - val_loss: 1069.0157\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 262.8650 - val_loss: 1072.7120\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 259.3622 - val_loss: 1076.4281\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 255.9870 - val_loss: 1080.1602\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 252.7354 - val_loss: 1083.9056\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 249.6041 - val_loss: 1087.6616\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 246.5899 - val_loss: 1091.4247\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 243.6892 - val_loss: 1095.1918\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 240.8988 - val_loss: 1098.9613\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 238.2152 - val_loss: 1102.7294\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 235.6356 - val_loss: 1106.4940\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 233.1565 - val_loss: 1110.2520\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 230.7752 - val_loss: 1114.0012\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 228.4883 - val_loss: 1117.7391\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 226.2932 - val_loss: 1121.4634\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 224.1868 - val_loss: 1125.1724\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 222.1662 - val_loss: 1128.8627\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 220.2287 - val_loss: 1132.5333\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 218.3716 - val_loss: 1136.1815\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 216.5921 - val_loss: 1139.8054\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 214.8877 - val_loss: 1143.4028\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 213.2560 - val_loss: 1146.9733\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 211.6941 - val_loss: 1150.5133\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 210.1999 - val_loss: 1154.0226\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 208.7708 - val_loss: 1157.4989\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 207.4046 - val_loss: 1160.9408\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 206.0990 - val_loss: 1164.3472\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 204.8517 - val_loss: 1167.7161\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 203.6606 - val_loss: 1171.0471\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 202.5237 - val_loss: 1174.3380\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 201.4388 - val_loss: 1177.5883\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 200.4040 - val_loss: 1180.7961\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 199.4175 - val_loss: 1183.9614\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 198.4771 - val_loss: 1187.0828\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 197.5811 - val_loss: 1190.1595\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 196.7279 - val_loss: 1193.1913\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 195.9155 - val_loss: 1196.1758\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 195.1426 - val_loss: 1199.1135\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 194.4072 - val_loss: 1202.0045\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 193.7078 - val_loss: 1204.8469\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 193.0430 - val_loss: 1207.6409\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 192.4114 - val_loss: 1210.3860\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 191.8112 - val_loss: 1213.0820\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 191.2413 - val_loss: 1215.7284\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 190.7004 - val_loss: 1218.3254\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 190.1870 - val_loss: 1220.8721\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 189.7003 - val_loss: 1223.3684\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 189.2386 - val_loss: 1225.8148\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 188.8010 - val_loss: 1228.2104\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 188.3864 - val_loss: 1230.5569\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 187.9937 - val_loss: 1232.8525\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 187.6217 - val_loss: 1235.0977\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 187.2696 - val_loss: 1237.2937\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 186.9365 - val_loss: 1239.4399\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 186.6213 - val_loss: 1241.5367\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 186.3232 - val_loss: 1243.5846\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 186.0414 - val_loss: 1245.5829\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 185.7750 - val_loss: 1247.5333\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 185.5234 - val_loss: 1249.4352\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 185.2857 - val_loss: 1251.2898\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 185.0611 - val_loss: 1253.0970\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 184.8492 - val_loss: 1254.8572\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 184.6492 - val_loss: 1256.5710\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 184.4605 - val_loss: 1258.2400\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 184.2825 - val_loss: 1259.8633\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 184.1145 - val_loss: 1261.4425\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 183.9562 - val_loss: 1262.9773\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 183.8069 - val_loss: 1264.4686\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 183.6662 - val_loss: 1265.9180\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 183.5336 - val_loss: 1267.3252\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 183.4087 - val_loss: 1268.6912\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 183.2910 - val_loss: 1270.0161\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 183.1801 - val_loss: 1271.3015\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 183.0758 - val_loss: 1272.5480\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 182.9775 - val_loss: 1273.7551\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 182.8849 - val_loss: 1274.9250\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 182.7978 - val_loss: 1276.0579\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 182.7158 - val_loss: 1277.1547\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 182.6387 - val_loss: 1278.2163\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 182.5661 - val_loss: 1279.2429\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 182.4977 - val_loss: 1280.2358\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 182.4335 - val_loss: 1281.1951\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 182.3731 - val_loss: 1282.1218\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 182.3161 - val_loss: 1283.0167\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 182.2626 - val_loss: 1283.8813\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 182.2122 - val_loss: 1284.7151\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 182.1648 - val_loss: 1285.5200\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 182.1203 - val_loss: 1286.2960\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 182.0784 - val_loss: 1287.0444\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 182.0389 - val_loss: 1287.7653\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 182.0019 - val_loss: 1288.4596\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 181.9670 - val_loss: 1289.1285\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 181.9342 - val_loss: 1289.7727\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 181.9033 - val_loss: 1290.3920\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.8743 - val_loss: 1290.9883\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.8470 - val_loss: 1291.5610\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.8212 - val_loss: 1292.1123\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 181.7970 - val_loss: 1292.6415\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 181.7743 - val_loss: 1293.1505\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 181.7529 - val_loss: 1293.6385\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 181.7327 - val_loss: 1294.1075\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 181.7137 - val_loss: 1294.5573\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 181.6959 - val_loss: 1294.9895\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.6791 - val_loss: 1295.4027\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.6633 - val_loss: 1295.7997\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.6485 - val_loss: 1296.1801\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.6344 - val_loss: 1296.5447\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.6212 - val_loss: 1296.8938\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 181.6088 - val_loss: 1297.2275\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.5972 - val_loss: 1297.5475\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.5861 - val_loss: 1297.8534\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.5758 - val_loss: 1298.1458\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.5661 - val_loss: 1298.4261\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.5568 - val_loss: 1298.6935\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.5482 - val_loss: 1298.9496\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.5401 - val_loss: 1299.1931\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.5324 - val_loss: 1299.4265\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.5252 - val_loss: 1299.6486\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.5184 - val_loss: 1299.8608\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.5121 - val_loss: 1300.0636\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.5060 - val_loss: 1300.2565\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.5004 - val_loss: 1300.4406\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4951 - val_loss: 1300.6155\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4902 - val_loss: 1300.7831\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4855 - val_loss: 1300.9429\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4811 - val_loss: 1301.0941\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4770 - val_loss: 1301.2390\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4731 - val_loss: 1301.3763\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4694 - val_loss: 1301.5067\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4660 - val_loss: 1301.6317\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4628 - val_loss: 1301.7504\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4598 - val_loss: 1301.8630\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4570 - val_loss: 1301.9698\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4543 - val_loss: 1302.0717\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4518 - val_loss: 1302.1678\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4495 - val_loss: 1302.2590\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4473 - val_loss: 1302.3457\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4454 - val_loss: 1302.4283\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4435 - val_loss: 1302.5068\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4417 - val_loss: 1302.5814\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4401 - val_loss: 1302.6522\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4386 - val_loss: 1302.7191\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4370 - val_loss: 1302.7820\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4358 - val_loss: 1302.8422\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4345 - val_loss: 1302.8994\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4334 - val_loss: 1302.9524\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4323 - val_loss: 1303.0029\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4314 - val_loss: 1303.0514\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4305 - val_loss: 1303.0969\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4297 - val_loss: 1303.1394\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4289 - val_loss: 1303.1805\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4282 - val_loss: 1303.2191\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4276 - val_loss: 1303.2554\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 181.4271 - val_loss: 1303.2904\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4265 - val_loss: 1303.3225\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4260 - val_loss: 1303.3540\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4256 - val_loss: 1303.3835\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4253 - val_loss: 1303.4104\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4248 - val_loss: 1303.4363\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4245 - val_loss: 1303.4603\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4243 - val_loss: 1303.4838\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4240 - val_loss: 1303.5051\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4239 - val_loss: 1303.5258\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4237 - val_loss: 1303.5454\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4236 - val_loss: 1303.5640\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4234 - val_loss: 1303.5813\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4234 - val_loss: 1303.5973\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4233 - val_loss: 1303.6132\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4233 - val_loss: 1303.6277\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4232 - val_loss: 1303.6412\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4232 - val_loss: 1303.6543\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4233 - val_loss: 1303.6663\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4233 - val_loss: 1303.6777\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4233 - val_loss: 1303.6882\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4234 - val_loss: 1303.6982\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4234 - val_loss: 1303.7079\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4235 - val_loss: 1303.7170\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 181.4236 - val_loss: 1303.7255\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 181.4237 - val_loss: 1303.7327\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4239 - val_loss: 1303.7408\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4239 - val_loss: 1303.7476\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4241 - val_loss: 1303.7538\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 181.4242 - val_loss: 1303.7605\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4244 - val_loss: 1303.7660\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4245 - val_loss: 1303.7719\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4247 - val_loss: 1303.7766\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4249 - val_loss: 1303.7825\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4250 - val_loss: 1303.7866\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4252 - val_loss: 1303.7904\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4254 - val_loss: 1303.7948\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4256 - val_loss: 1303.7986\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4257 - val_loss: 1303.8011\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 181.4260 - val_loss: 1303.8048\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 181.4261 - val_loss: 1303.8081\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 181.4263 - val_loss: 1303.8109\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4265 - val_loss: 1303.8137\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 181.4266 - val_loss: 1303.8169\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4268 - val_loss: 1303.8188\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4271 - val_loss: 1303.8214\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4273 - val_loss: 1303.8235\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4274 - val_loss: 1303.8254\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4276 - val_loss: 1303.8278\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4279 - val_loss: 1303.8302\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4280 - val_loss: 1303.8313\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4283 - val_loss: 1303.8333\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4284 - val_loss: 1303.8345\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4286 - val_loss: 1303.8358\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4288 - val_loss: 1303.8381\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4289 - val_loss: 1303.8396\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4290 - val_loss: 1303.8403\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4293 - val_loss: 1303.8413\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4295 - val_loss: 1303.8419\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4296 - val_loss: 1303.8423\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4299 - val_loss: 1303.8429\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4301 - val_loss: 1303.8438\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4303 - val_loss: 1303.8455\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4304 - val_loss: 1303.8458\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4306 - val_loss: 1303.8467\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 181.4308 - val_loss: 1303.8475\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4309 - val_loss: 1303.8481\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4311 - val_loss: 1303.8485\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4313 - val_loss: 1303.8491\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4315 - val_loss: 1303.8502\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4316 - val_loss: 1303.8511\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4317 - val_loss: 1303.8514\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4319 - val_loss: 1303.8522\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4320 - val_loss: 1303.8523\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4322 - val_loss: 1303.8527\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4323 - val_loss: 1303.8525\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4326 - val_loss: 1303.8528\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4327 - val_loss: 1303.8530\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4328 - val_loss: 1303.8529\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4330 - val_loss: 1303.8535\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4332 - val_loss: 1303.8536\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4333 - val_loss: 1303.8541\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4335 - val_loss: 1303.8545\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4335 - val_loss: 1303.8545\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4337 - val_loss: 1303.8549\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4338 - val_loss: 1303.8547\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4340 - val_loss: 1303.8547\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4341 - val_loss: 1303.8552\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4342 - val_loss: 1303.8547\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4344 - val_loss: 1303.8558\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4344 - val_loss: 1303.8558\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4346 - val_loss: 1303.8558\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4347 - val_loss: 1303.8558\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4349 - val_loss: 1303.8564\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4349 - val_loss: 1303.8566\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 181.4351 - val_loss: 1303.8571\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 181.4351 - val_loss: 1303.8567\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4353 - val_loss: 1303.8571\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4354 - val_loss: 1303.8572\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4355 - val_loss: 1303.8572\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4357 - val_loss: 1303.8578\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4357 - val_loss: 1303.8575\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4359 - val_loss: 1303.8575\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4359 - val_loss: 1303.8572\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4361 - val_loss: 1303.8578\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4361 - val_loss: 1303.8583\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4362 - val_loss: 1303.8577\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4363 - val_loss: 1303.8578\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4364 - val_loss: 1303.8583\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4365 - val_loss: 1303.8583\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4366 - val_loss: 1303.8583\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4366 - val_loss: 1303.8583\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4368 - val_loss: 1303.8584\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 181.4368 - val_loss: 1303.8593\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4369 - val_loss: 1303.8593\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4369 - val_loss: 1303.8590\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4370 - val_loss: 1303.8594\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4371 - val_loss: 1303.8590\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4372 - val_loss: 1303.8594\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4372 - val_loss: 1303.8594\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4373 - val_loss: 1303.8595\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4375 - val_loss: 1303.8604\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4375 - val_loss: 1303.8600\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4375 - val_loss: 1303.8590\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4378 - val_loss: 1303.8600\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4377 - val_loss: 1303.8600\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4378 - val_loss: 1303.8591\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4379 - val_loss: 1303.8591\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4379 - val_loss: 1303.8589\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 181.4380 - val_loss: 1303.8591\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 181.4381 - val_loss: 1303.8588\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 181.4382 - val_loss: 1303.8594\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 181.4383 - val_loss: 1303.8606\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 181.4382 - val_loss: 1303.8610\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 181.4383 - val_loss: 1303.8606\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4384 - val_loss: 1303.8606\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4384 - val_loss: 1303.8606\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4385 - val_loss: 1303.8606\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4385 - val_loss: 1303.8606\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4386 - val_loss: 1303.8612\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4386 - val_loss: 1303.8617\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4386 - val_loss: 1303.8613\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4386 - val_loss: 1303.8611\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4387 - val_loss: 1303.8605\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4389 - val_loss: 1303.8605\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4389 - val_loss: 1303.8600\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4390 - val_loss: 1303.8605\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 181.4390 - val_loss: 1303.8605\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 181.4391 - val_loss: 1303.8605\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 181.4390 - val_loss: 1303.8605\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 181.4391 - val_loss: 1303.8600\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 181.4391 - val_loss: 1303.8600\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 181.4391 - val_loss: 1303.8590\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4393 - val_loss: 1303.8590\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4393 - val_loss: 1303.8590\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4393 - val_loss: 1303.8589\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4394 - val_loss: 1303.8584\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4394 - val_loss: 1303.8585\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4395 - val_loss: 1303.8588\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4395 - val_loss: 1303.8588\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4396 - val_loss: 1303.8590\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4396 - val_loss: 1303.8594\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4397 - val_loss: 1303.8604\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4396 - val_loss: 1303.8606\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4396 - val_loss: 1303.8606\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4397 - val_loss: 1303.8606\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 181.4397 - val_loss: 1303.8611\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4397 - val_loss: 1303.8611\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4398 - val_loss: 1303.8611\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4398 - val_loss: 1303.8613\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4399 - val_loss: 1303.8613\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4399 - val_loss: 1303.8615\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4399 - val_loss: 1303.8618\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4399 - val_loss: 1303.8615\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4399 - val_loss: 1303.8612\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4399 - val_loss: 1303.8612\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4399 - val_loss: 1303.8601\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4400 - val_loss: 1303.8590\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4401 - val_loss: 1303.8590\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4402 - val_loss: 1303.8597\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4402 - val_loss: 1303.8601\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4402 - val_loss: 1303.8605\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4402 - val_loss: 1303.8608\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4402 - val_loss: 1303.8612\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4402 - val_loss: 1303.8612\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4402 - val_loss: 1303.8608\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4402 - val_loss: 1303.8607\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 181.4403 - val_loss: 1303.8606\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4404 - val_loss: 1303.8612\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4404 - val_loss: 1303.8613\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4404 - val_loss: 1303.8612\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4404 - val_loss: 1303.8617\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4404 - val_loss: 1303.8617\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 181.4404 - val_loss: 1303.8617\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181.4405 - val_loss: 1303.8618\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4404 - val_loss: 1303.8621\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4404 - val_loss: 1303.8618\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4405 - val_loss: 1303.8618\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4405 - val_loss: 1303.8618\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181.4405 - val_loss: 1303.8618\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 466ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.03304622e+01, 7.03052521e+01, 7.02800420e+01, 7.02548319e+01,\n",
       "        7.02296219e+01, 7.02044118e+01, 7.01792017e+01, 0.00000000e+00,\n",
       "        4.45066273e-01, 5.86903811e-01, 5.00404894e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.05629552e+01, 7.05377451e+01, 7.05125350e+01,\n",
       "        7.04873249e+01, 7.04621149e+01, 7.04369048e+01, 7.04116947e+01,\n",
       "        7.03864846e+01, 7.03612745e+01, 7.03360644e+01, 7.03108543e+01,\n",
       "        7.02856443e+01, 7.02604342e+01, 7.02352241e+01, 7.02100140e+01,\n",
       "        7.01848039e+01, 7.42042484e+01, 7.39282213e+01, 7.35500700e+01,\n",
       "        7.31719188e+01, 7.27937675e+01, 7.23987395e+01, 7.19449580e+01,\n",
       "        7.14911765e+01, 7.10373950e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.94080590e-01, 8.16541190e-01, 0.00000000e+00, 7.86594450e-01,\n",
       "        0.00000000e+00, 9.65869900e-02, 0.00000000e+00, 7.02660364e+01,\n",
       "        7.02408263e+01, 7.02156162e+01, 7.01904062e+01, 7.42602708e+01,\n",
       "        7.40081699e+01, 7.36341036e+01, 7.32559524e+01, 7.28778011e+01,\n",
       "        7.24995798e+01, 7.20457983e+01, 7.15920168e+01, 7.11382353e+01,\n",
       "        1.00360058e-01, 0.00000000e+00, 7.30318628e+01, 7.26537115e+01,\n",
       "        7.22306723e+01, 7.17768908e+01, 7.13231092e+01, 7.08693277e+01,\n",
       "        7.06525910e+01, 7.05769608e+01, 7.05013305e+01, 6.53601830e-01,\n",
       "        1.33408070e-01, 6.51591797e+01, 7.42013680e-02, 3.12022328e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.34099140e-02, 0.00000000e+00,\n",
       "        7.18918381e+01, 8.12284648e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.46806204e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.83917192e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63.17517507, 63.15510037, 63.13502568, 63.11495098, 63.09487628,\n",
       "       63.07480159, 63.05472689, 63.03465219, 63.0145775 , 62.9945028 ,\n",
       "       62.9744281 , 62.95435341, 62.93427871, 62.91420401, 62.89412932,\n",
       "       62.87405462, 62.85397993, 62.83390523, 62.81383053, 62.79375584,\n",
       "       62.77368114, 62.75360644, 62.73353175, 62.71345705, 62.69338235,\n",
       "       62.67330766, 62.65323296, 62.63315826, 62.61308357, 62.59300887,\n",
       "       62.57293417, 62.55285948, 62.53278478, 62.51271008, 62.49263539,\n",
       "       62.47256069, 62.45248599, 62.4324113 , 62.4123366 , 62.3922619 ,\n",
       "       62.37218721, 62.35211251, 62.33203782, 62.31196312, 62.29188842,\n",
       "       62.27181373, 62.25173903, 62.23166433, 62.21158964, 62.19151494,\n",
       "       62.17144024, 62.15136555, 62.13129085, 62.11121615, 62.09114146,\n",
       "       62.07106676, 62.05099206, 62.03091737, 62.01084267, 61.99076797,\n",
       "       61.97069328, 61.95061858, 61.93054388, 61.91046919, 61.89039449,\n",
       "       61.87031979, 61.8502451 , 61.8301704 , 61.8100957 , 61.79002101,\n",
       "       61.76994631, 61.74987162, 61.72979692, 61.70972222, 61.68964753,\n",
       "       61.66957283, 61.64949813, 61.62942344, 61.60934874, 61.58927404,\n",
       "       61.56919935, 61.54912465, 61.52904995, 61.50897526, 61.48890056,\n",
       "       61.46882586, 61.44875117, 61.42867647, 61.40860177, 61.38852708,\n",
       "       61.36845238, 61.34837768, 61.32830299, 61.30822829, 61.28815359,\n",
       "       61.2680789 , 61.2480042 , 61.22792951, 61.20785481, 61.18778011])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.48891431213245\n",
      "32.08897202255831\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
