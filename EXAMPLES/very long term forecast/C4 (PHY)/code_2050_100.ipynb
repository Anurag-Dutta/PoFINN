{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "2145    59.353351\n",
       "2146    59.341053\n",
       "2147    59.328756\n",
       "2148    59.316458\n",
       "2149    59.304161\n",
       "Name: C4, Length: 2150, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_2050_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "2045     0.000000\n",
       "2046     0.000000\n",
       "2047     0.000000\n",
       "2048     0.000000\n",
       "2049     0.000000\n",
       "Name: C4, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2050)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.409524</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.219048</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.028571</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.838095</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.600000  0.000298\n",
       "1     88.409524  0.000298\n",
       "2     88.219048  0.000297\n",
       "3     88.028571  0.000297\n",
       "4     87.838095  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.600000    88.409524    88.219048    88.028571    87.838095   \n",
      "351    88.409524    88.219048    88.028571    87.838095    87.647619   \n",
      "352    88.219048    88.028571    87.838095    87.647619    87.457143   \n",
      "353    88.028571    87.838095    87.647619    87.457143    87.266667   \n",
      "354    87.838095    87.647619    87.457143    87.266667    87.076190   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.647619    87.457143    87.266667    87.076190    86.896218  ...   \n",
      "351    87.457143    87.266667    87.076190    86.896218    86.845798  ...   \n",
      "352    87.266667    87.076190    86.896218    86.845798    86.795378  ...   \n",
      "353    87.076190    86.896218    86.845798    86.795378    86.744958  ...   \n",
      "354    86.896218    86.845798    86.795378    86.744958    86.694538  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   78.880345    0.000263   78.856069    0.000263   78.831793    0.000263   \n",
      "351   78.856069    0.000263   78.831793    0.000263   78.807516    0.000262   \n",
      "352   78.831793    0.000263   78.807516    0.000262   78.783240    0.000262   \n",
      "353   78.807516    0.000262   78.783240    0.000262   78.758964    0.000262   \n",
      "354   78.783240    0.000262   78.758964    0.000262   78.734687    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   78.807516    0.000262   78.783240    0.000262  \n",
      "351   78.783240    0.000262   78.758964    0.000262  \n",
      "352   78.758964    0.000262   78.734687    0.000262  \n",
      "353   78.734687    0.000262   78.710411    0.000262  \n",
      "354   78.710411    0.000262   78.686134    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 1, 251) (1600, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 34ms/step - loss: 5192.0991 - val_loss: 3120.5635\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 5006.2114 - val_loss: 2997.5447\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4881.4639 - val_loss: 2932.0696\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4793.5024 - val_loss: 2879.4663\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4708.5698 - val_loss: 2828.3999\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4616.4478 - val_loss: 2771.7876\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4530.4258 - val_loss: 2721.9231\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4448.1597 - val_loss: 2672.5054\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4349.8955 - val_loss: 2613.2729\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4264.6382 - val_loss: 2565.1692\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4183.7563 - val_loss: 2518.6704\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4104.9102 - val_loss: 2473.5366\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4027.7773 - val_loss: 2429.6140\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3952.1602 - val_loss: 2386.8071\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3877.9363 - val_loss: 2345.0527\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3805.0215 - val_loss: 2304.3032\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3733.3530 - val_loss: 2264.5222\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3662.8828 - val_loss: 2225.6799\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3593.5710 - val_loss: 2187.7510\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3525.3872 - val_loss: 2150.7136\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3458.3008 - val_loss: 2114.5483\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3392.2891 - val_loss: 2079.2378\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3327.3293 - val_loss: 2044.7656\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3263.4021 - val_loss: 2011.1168\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3200.4893 - val_loss: 1978.2776\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3138.5737 - val_loss: 1946.2341\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3077.6396 - val_loss: 1914.9740\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3017.6724 - val_loss: 1884.4856\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2958.6575 - val_loss: 1854.7565\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2900.5815 - val_loss: 1825.7758\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2843.4324 - val_loss: 1797.5325\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2787.1968 - val_loss: 1770.0156\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2731.8630 - val_loss: 1743.2151\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2677.4199 - val_loss: 1717.1211\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2623.8557 - val_loss: 1691.7227\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2571.1587 - val_loss: 1667.0110\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2519.3198 - val_loss: 1642.9763\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 2468.3276 - val_loss: 1619.6089\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2418.1711 - val_loss: 1596.8998\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2368.8416 - val_loss: 1574.8397\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2320.3286 - val_loss: 1553.4196\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2272.6223 - val_loss: 1532.6304\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2225.7134 - val_loss: 1512.4631\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2179.5923 - val_loss: 1492.9095\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2134.2495 - val_loss: 1473.9611\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2089.6758 - val_loss: 1455.6090\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2045.8630 - val_loss: 1437.8444\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2002.8015 - val_loss: 1420.6594\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1960.4822 - val_loss: 1404.0459\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1918.8972 - val_loss: 1387.9952\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1878.0369 - val_loss: 1372.4994\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1837.8936 - val_loss: 1357.5500\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1798.4586 - val_loss: 1343.1400\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1759.7234 - val_loss: 1329.2604\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1721.6797 - val_loss: 1315.9036\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1684.3193 - val_loss: 1303.0620\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1647.6344 - val_loss: 1290.7273\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1611.6165 - val_loss: 1278.8922\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1576.2581 - val_loss: 1267.5490\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1541.5505 - val_loss: 1256.6897\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1507.4867 - val_loss: 1246.3065\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1474.0581 - val_loss: 1236.3928\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1441.2576 - val_loss: 1226.9403\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1409.0773 - val_loss: 1217.9417\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1377.5094 - val_loss: 1209.3894\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1346.5465 - val_loss: 1201.2766\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1316.1809 - val_loss: 1193.5952\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1286.4052 - val_loss: 1186.3384\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1257.2124 - val_loss: 1179.4989\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1228.5941 - val_loss: 1173.0691\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1200.5443 - val_loss: 1167.0422\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1173.0548 - val_loss: 1161.4111\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1146.1188 - val_loss: 1156.1681\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1119.7286 - val_loss: 1151.3066\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1093.8777 - val_loss: 1146.8196\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1068.5586 - val_loss: 1142.6998\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1043.7644 - val_loss: 1138.9402\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1019.4883 - val_loss: 1135.5339\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 995.7228 - val_loss: 1132.4745\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 972.4615 - val_loss: 1129.7544\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 949.6974 - val_loss: 1127.3669\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 927.4236 - val_loss: 1125.3057\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 905.6330 - val_loss: 1123.5634\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 884.3192 - val_loss: 1122.1334\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 863.4752 - val_loss: 1121.0092\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 843.0946 - val_loss: 1120.1838\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 823.1709 - val_loss: 1119.6508\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 803.6969 - val_loss: 1119.4036\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 784.6665 - val_loss: 1119.4353\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 766.0731 - val_loss: 1119.7396\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 747.9099 - val_loss: 1120.3101\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 730.1704 - val_loss: 1121.1399\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 712.8488 - val_loss: 1122.2229\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 695.9383 - val_loss: 1123.5525\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 679.4325 - val_loss: 1125.1224\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 663.3251 - val_loss: 1126.9263\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 647.6100 - val_loss: 1128.9576\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 632.2806 - val_loss: 1131.2102\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 617.3312 - val_loss: 1133.6781\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 602.7552 - val_loss: 1136.3547\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 588.5468 - val_loss: 1139.2339\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 574.6998 - val_loss: 1142.3098\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 561.2078 - val_loss: 1145.5759\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 548.0652 - val_loss: 1149.0266\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 535.2657 - val_loss: 1152.6559\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 522.8036 - val_loss: 1156.4573\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 510.6728 - val_loss: 1160.4250\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 498.8675 - val_loss: 1164.5535\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 487.3821 - val_loss: 1168.8365\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 476.2105 - val_loss: 1173.2686\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 465.3470 - val_loss: 1177.8438\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 454.7859 - val_loss: 1182.5563\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 444.5216 - val_loss: 1187.4005\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 434.5484 - val_loss: 1192.3708\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 424.8607 - val_loss: 1197.4618\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 415.4530 - val_loss: 1202.6677\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 406.3197 - val_loss: 1207.9833\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 397.4556 - val_loss: 1213.4030\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 388.8549 - val_loss: 1218.9211\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 380.5124 - val_loss: 1224.5330\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 372.4228 - val_loss: 1230.2330\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 364.5807 - val_loss: 1236.0156\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 356.9810 - val_loss: 1241.8766\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 349.6183 - val_loss: 1247.8099\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 342.4877 - val_loss: 1253.8113\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 335.5840 - val_loss: 1259.8752\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 328.9020 - val_loss: 1265.9973\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 322.4366 - val_loss: 1272.1720\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 316.1834 - val_loss: 1278.3950\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 310.1370 - val_loss: 1284.6614\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 304.2927 - val_loss: 1290.9670\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 298.6456 - val_loss: 1297.3070\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 293.1911 - val_loss: 1303.6768\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 287.9244 - val_loss: 1310.0720\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 282.8409 - val_loss: 1316.4882\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 277.9359 - val_loss: 1322.9213\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 273.2050 - val_loss: 1329.3666\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 268.6437 - val_loss: 1335.8207\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 264.2477 - val_loss: 1342.2793\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 260.0123 - val_loss: 1348.7386\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 255.9334 - val_loss: 1355.1941\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 252.0068 - val_loss: 1361.6426\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 248.2284 - val_loss: 1368.0800\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 244.5938 - val_loss: 1374.5032\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 241.0990 - val_loss: 1380.9083\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 237.7401 - val_loss: 1387.2917\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 234.5131 - val_loss: 1393.6501\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 231.4142 - val_loss: 1399.9806\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 228.4395 - val_loss: 1406.2799\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 225.5852 - val_loss: 1412.5446\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 222.8476 - val_loss: 1418.7717\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 220.2232 - val_loss: 1424.9583\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 217.7084 - val_loss: 1431.1021\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 215.2997 - val_loss: 1437.1997\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 212.9937 - val_loss: 1443.2487\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 210.7868 - val_loss: 1449.2466\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 208.6761 - val_loss: 1455.1912\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 206.6580 - val_loss: 1461.0796\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 204.7295 - val_loss: 1466.9099\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 202.8876 - val_loss: 1472.6799\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 201.1289 - val_loss: 1478.3879\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 199.4509 - val_loss: 1484.0311\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 197.8505 - val_loss: 1489.6082\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 196.3248 - val_loss: 1495.1173\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 194.8711 - val_loss: 1500.5566\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 193.4867 - val_loss: 1505.9249\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 192.1690 - val_loss: 1511.2203\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 190.9153 - val_loss: 1516.4421\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 189.7232 - val_loss: 1521.5890\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 188.5902 - val_loss: 1526.6581\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 187.5141 - val_loss: 1531.6503\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 186.4924 - val_loss: 1536.5632\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 185.5230 - val_loss: 1541.3975\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 184.6036 - val_loss: 1546.1501\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 183.7322 - val_loss: 1550.8224\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 182.9066 - val_loss: 1555.4119\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 182.1250 - val_loss: 1559.9203\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3853 - val_loss: 1564.3447\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 180.6858 - val_loss: 1568.6865\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 180.0246 - val_loss: 1572.9443\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 179.4000 - val_loss: 1577.1180\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 178.8103 - val_loss: 1581.2076\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 178.2538 - val_loss: 1585.2139\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 177.7290 - val_loss: 1589.1357\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 177.2343 - val_loss: 1592.9733\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 176.7683 - val_loss: 1596.7279\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 176.3296 - val_loss: 1600.3988\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 175.9168 - val_loss: 1603.9851\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 175.5288 - val_loss: 1607.4890\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 175.1641 - val_loss: 1610.9102\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 174.8215 - val_loss: 1614.2499\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 174.4999 - val_loss: 1617.5072\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 174.1983 - val_loss: 1620.6846\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 173.9155 - val_loss: 1623.7816\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 173.6504 - val_loss: 1626.7982\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 173.4023 - val_loss: 1629.7361\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 173.1701 - val_loss: 1632.5967\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 172.9529 - val_loss: 1635.3793\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 172.7498 - val_loss: 1638.0863\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.5602 - val_loss: 1640.7175\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.3832 - val_loss: 1643.2742\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.2180 - val_loss: 1645.7574\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 172.0640 - val_loss: 1648.1683\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 171.9204 - val_loss: 1650.5082\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 171.7868 - val_loss: 1652.7781\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 171.6624 - val_loss: 1654.9797\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 171.5466 - val_loss: 1657.1119\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 171.4390 - val_loss: 1659.1783\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 171.3391 - val_loss: 1661.1794\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 171.2463 - val_loss: 1663.1162\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 171.1602 - val_loss: 1664.9895\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 171.0803 - val_loss: 1666.8011\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 171.0063 - val_loss: 1668.5527\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 170.9378 - val_loss: 1670.2458\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 170.8743 - val_loss: 1671.8796\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 170.8156 - val_loss: 1673.4573\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.7613 - val_loss: 1674.9792\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.7112 - val_loss: 1676.4480\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 170.6648 - val_loss: 1677.8636\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 170.6220 - val_loss: 1679.2279\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 170.5826 - val_loss: 1680.5416\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.5462 - val_loss: 1681.8064\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.5128 - val_loss: 1683.0244\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 170.4819 - val_loss: 1684.1965\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 170.4535 - val_loss: 1685.3217\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.4274 - val_loss: 1686.4043\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 170.4034 - val_loss: 1687.4443\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 170.3814 - val_loss: 1688.4437\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.3611 - val_loss: 1689.4021\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.3425 - val_loss: 1690.3220\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.3255 - val_loss: 1691.2048\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.3099 - val_loss: 1692.0504\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.2956 - val_loss: 1692.8611\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 170.2825 - val_loss: 1693.6365\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.2706 - val_loss: 1694.3799\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.2596 - val_loss: 1695.0911\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2496 - val_loss: 1695.7712\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2405 - val_loss: 1696.4219\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2322 - val_loss: 1697.0430\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2246 - val_loss: 1697.6367\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.2177 - val_loss: 1698.2034\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.2114 - val_loss: 1698.7448\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2057 - val_loss: 1699.2604\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.2005 - val_loss: 1699.7532\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1958 - val_loss: 1700.2214\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1917 - val_loss: 1700.6683\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 170.1878 - val_loss: 1701.0944\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1843 - val_loss: 1701.5000\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1812 - val_loss: 1701.8860\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1783 - val_loss: 1702.2532\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 170.1758 - val_loss: 1702.6019\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 170.1736 - val_loss: 1702.9346\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.1715 - val_loss: 1703.2490\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.1697 - val_loss: 1703.5482\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.1681 - val_loss: 1703.8324\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.1667 - val_loss: 1704.1013\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1654 - val_loss: 1704.3567\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.1644 - val_loss: 1704.6002\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 170.1634 - val_loss: 1704.8298\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.1626 - val_loss: 1705.0472\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1618 - val_loss: 1705.2522\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1613 - val_loss: 1705.4469\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.1608 - val_loss: 1705.6311\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.1604 - val_loss: 1705.8054\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.1601 - val_loss: 1705.9703\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.1599 - val_loss: 1706.1262\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.1597 - val_loss: 1706.2731\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.1596 - val_loss: 1706.4114\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.1595 - val_loss: 1706.5414\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.1596 - val_loss: 1706.6654\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 170.1597 - val_loss: 1706.7820\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.1598 - val_loss: 1706.8920\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.1598 - val_loss: 1706.9949\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.1601 - val_loss: 1707.0918\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.1604 - val_loss: 1707.1838\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.1606 - val_loss: 1707.2698\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.1609 - val_loss: 1707.3516\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1612 - val_loss: 1707.4270\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1615 - val_loss: 1707.4990\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1619 - val_loss: 1707.5662\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1623 - val_loss: 1707.6287\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1627 - val_loss: 1707.6887\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1631 - val_loss: 1707.7429\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1635 - val_loss: 1707.7949\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1640 - val_loss: 1707.8445\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1645 - val_loss: 1707.8899\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1650 - val_loss: 1707.9332\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 170.1654 - val_loss: 1707.9723\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1660 - val_loss: 1708.0104\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1664 - val_loss: 1708.0453\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1669 - val_loss: 1708.0779\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1674 - val_loss: 1708.1080\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1680 - val_loss: 1708.1367\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1685 - val_loss: 1708.1628\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1690 - val_loss: 1708.1882\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1695 - val_loss: 1708.2109\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1701 - val_loss: 1708.2327\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1705 - val_loss: 1708.2523\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1711 - val_loss: 1708.2711\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1717 - val_loss: 1708.2874\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1722 - val_loss: 1708.3040\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1727 - val_loss: 1708.3184\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1733 - val_loss: 1708.3320\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1739 - val_loss: 1708.3441\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1743 - val_loss: 1708.3568\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1749 - val_loss: 1708.3672\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1755 - val_loss: 1708.3779\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1760 - val_loss: 1708.3881\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1765 - val_loss: 1708.3965\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1770 - val_loss: 1708.4043\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1776 - val_loss: 1708.4121\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1781 - val_loss: 1708.4189\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1786 - val_loss: 1708.4252\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1791 - val_loss: 1708.4309\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1797 - val_loss: 1708.4363\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1801 - val_loss: 1708.4414\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1806 - val_loss: 1708.4457\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1811 - val_loss: 1708.4495\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1817 - val_loss: 1708.4537\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1821 - val_loss: 1708.4576\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1826 - val_loss: 1708.4606\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1830 - val_loss: 1708.4639\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1835 - val_loss: 1708.4661\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1841 - val_loss: 1708.4684\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1845 - val_loss: 1708.4709\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1850 - val_loss: 1708.4727\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1855 - val_loss: 1708.4749\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1859 - val_loss: 1708.4763\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1863 - val_loss: 1708.4778\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1867 - val_loss: 1708.4789\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1872 - val_loss: 1708.4799\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1876 - val_loss: 1708.4808\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1881 - val_loss: 1708.4822\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1885 - val_loss: 1708.4828\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1889 - val_loss: 1708.4832\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1892 - val_loss: 1708.4834\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1897 - val_loss: 1708.4841\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1901 - val_loss: 1708.4847\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1905 - val_loss: 1708.4847\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1909 - val_loss: 1708.4847\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1913 - val_loss: 1708.4851\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1916 - val_loss: 1708.4847\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1920 - val_loss: 1708.4847\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1924 - val_loss: 1708.4847\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1928 - val_loss: 1708.4847\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.1931 - val_loss: 1708.4847\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 170.1935 - val_loss: 1708.4847\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1939 - val_loss: 1708.4846\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1941 - val_loss: 1708.4844\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1945 - val_loss: 1708.4844\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1949 - val_loss: 1708.4841\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1952 - val_loss: 1708.4840\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.1955 - val_loss: 1708.4836\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1958 - val_loss: 1708.4828\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1961 - val_loss: 1708.4828\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1964 - val_loss: 1708.4824\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1967 - val_loss: 1708.4822\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1971 - val_loss: 1708.4822\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1973 - val_loss: 1708.4814\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1977 - val_loss: 1708.4812\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1979 - val_loss: 1708.4807\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1982 - val_loss: 1708.4799\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1985 - val_loss: 1708.4795\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1987 - val_loss: 1708.4791\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1990 - val_loss: 1708.4789\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1993 - val_loss: 1708.4779\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1996 - val_loss: 1708.4778\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.1999 - val_loss: 1708.4772\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2001 - val_loss: 1708.4773\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2003 - val_loss: 1708.4769\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2006 - val_loss: 1708.4769\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2008 - val_loss: 1708.4766\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2010 - val_loss: 1708.4762\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 170.2013 - val_loss: 1708.4762\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2015 - val_loss: 1708.4746\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2017 - val_loss: 1708.4739\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2020 - val_loss: 1708.4734\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2022 - val_loss: 1708.4734\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2024 - val_loss: 1708.4724\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2026 - val_loss: 1708.4717\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2028 - val_loss: 1708.4714\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2030 - val_loss: 1708.4717\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2032 - val_loss: 1708.4711\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2034 - val_loss: 1708.4711\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2036 - val_loss: 1708.4709\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2038 - val_loss: 1708.4705\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2040 - val_loss: 1708.4700\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2042 - val_loss: 1708.4700\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2044 - val_loss: 1708.4700\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2045 - val_loss: 1708.4700\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2047 - val_loss: 1708.4690\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2048 - val_loss: 1708.4690\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2051 - val_loss: 1708.4685\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2052 - val_loss: 1708.4681\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2054 - val_loss: 1708.4680\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2055 - val_loss: 1708.4674\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 170.2057 - val_loss: 1708.4672\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2058 - val_loss: 1708.4672\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2060 - val_loss: 1708.4670\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2061 - val_loss: 1708.4664\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2063 - val_loss: 1708.4664\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2064 - val_loss: 1708.4658\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2065 - val_loss: 1708.4656\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2066 - val_loss: 1708.4645\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2068 - val_loss: 1708.4645\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2069 - val_loss: 1708.4635\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2071 - val_loss: 1708.4635\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2072 - val_loss: 1708.4631\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2074 - val_loss: 1708.4631\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2075 - val_loss: 1708.4631\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2076 - val_loss: 1708.4631\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2076 - val_loss: 1708.4626\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2079 - val_loss: 1708.4626\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2079 - val_loss: 1708.4625\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2081 - val_loss: 1708.4626\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2082 - val_loss: 1708.4625\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2083 - val_loss: 1708.4623\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 170.2083 - val_loss: 1708.4613\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 170.2085 - val_loss: 1708.4606\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2086 - val_loss: 1708.4606\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2087 - val_loss: 1708.4603\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2088 - val_loss: 1708.4603\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2089 - val_loss: 1708.4602\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2090 - val_loss: 1708.4600\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2091 - val_loss: 1708.4597\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2092 - val_loss: 1708.4594\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2093 - val_loss: 1708.4597\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2094 - val_loss: 1708.4602\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2094 - val_loss: 1708.4600\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2095 - val_loss: 1708.4594\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2096 - val_loss: 1708.4596\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2096 - val_loss: 1708.4590\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2098 - val_loss: 1708.4590\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2099 - val_loss: 1708.4590\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2099 - val_loss: 1708.4590\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2100 - val_loss: 1708.4584\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2100 - val_loss: 1708.4583\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2101 - val_loss: 1708.4574\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2103 - val_loss: 1708.4583\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.2103 - val_loss: 1708.4590\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 170.2103 - val_loss: 1708.4583\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2104 - val_loss: 1708.4573\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2105 - val_loss: 1708.4573\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2105 - val_loss: 1708.4567\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2105 - val_loss: 1708.4558\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2107 - val_loss: 1708.4561\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2108 - val_loss: 1708.4567\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2108 - val_loss: 1708.4567\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2109 - val_loss: 1708.4567\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2109 - val_loss: 1708.4568\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2110 - val_loss: 1708.4570\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2110 - val_loss: 1708.4573\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2111 - val_loss: 1708.4576\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2111 - val_loss: 1708.4568\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2113 - val_loss: 1708.4568\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2113 - val_loss: 1708.4568\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2113 - val_loss: 1708.4567\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2114 - val_loss: 1708.4567\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2114 - val_loss: 1708.4567\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2115 - val_loss: 1708.4568\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2115 - val_loss: 1708.4567\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2115 - val_loss: 1708.4564\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 170.2116 - val_loss: 1708.4563\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2117 - val_loss: 1708.4563\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2118 - val_loss: 1708.4568\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2117 - val_loss: 1708.4568\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2117 - val_loss: 1708.4567\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2118 - val_loss: 1708.4563\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2118 - val_loss: 1708.4553\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2119 - val_loss: 1708.4548\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2120 - val_loss: 1708.4554\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2120 - val_loss: 1708.4553\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2120 - val_loss: 1708.4547\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2120 - val_loss: 1708.4543\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2120 - val_loss: 1708.4541\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2121 - val_loss: 1708.4535\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2122 - val_loss: 1708.4531\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2122 - val_loss: 1708.4541\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2122 - val_loss: 1708.4543\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2123 - val_loss: 1708.4545\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2123 - val_loss: 1708.4547\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2123 - val_loss: 1708.4548\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2123 - val_loss: 1708.4545\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2123 - val_loss: 1708.4543\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 170.2124 - val_loss: 1708.4543\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 170.2124 - val_loss: 1708.4541\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2125 - val_loss: 1708.4541\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2125 - val_loss: 1708.4541\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2125 - val_loss: 1708.4545\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2125 - val_loss: 1708.4545\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 170.2125 - val_loss: 1708.4545\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2126 - val_loss: 1708.4545\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2125 - val_loss: 1708.4539\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2126 - val_loss: 1708.4537\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2126 - val_loss: 1708.4534\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2127 - val_loss: 1708.4537\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2127 - val_loss: 1708.4539\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2127 - val_loss: 1708.4539\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2128 - val_loss: 1708.4539\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.2128 - val_loss: 1708.4539\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 471ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72.6677171 , 72.247479  , 71.7936975 , 71.339916  , 75.9762115 ,\n",
       "         0.46305758,  0.32641059,  0.        ,  0.25501093,  0.33133194,\n",
       "         0.        ,  0.        ,  0.15703595, 70.2828431 , 70.257633  ,\n",
       "        70.232423  , 70.2072129 , 70.1820028 , 74.1762372 , 73.8862045 ,\n",
       "        73.5080532 , 73.129902  , 72.7517507 , 72.3483193 , 71.8945378 ,\n",
       "        71.4407563 , 70.9869748 ,  0.        ,  0.63982111, 72.9058123 ,\n",
       "        72.5276611 , 72.0794118 , 71.6256303 , 71.1718487 , 70.7180672 ,\n",
       "        70.627381  , 70.5517507 , 70.4761204 ,  0.08414401,  0.        ,\n",
       "         0.45067608,  0.58485156,  0.        ,  0.78594762,  0.        ,\n",
       "         0.        ,  0.        , 71.5415966 , 71.0878151 ,  0.20445439,\n",
       "         0.46036336, 72.9898459 , 72.6116947 , 72.1802521 , 71.7264706 ,\n",
       "        71.2726891 , 70.8189076 , 70.6441877 , 70.5685574 , 70.4929272 ,\n",
       "         0.        ,  0.20198622, 71.457563  , 71.0037815 , 70.675     ,\n",
       "        70.5993697 , 70.5237395 , 70.4481092 , 70.372479  , 70.2968487 ,\n",
       "        70.2212185 ,  0.162238  ,  0.        , 49.3277016 ,  0.11527097,\n",
       "         0.        ,  0.6063081 ,  0.        ,  0.15735251,  0.31272775,\n",
       "        66.96854401,  0.        ,  0.24773748,  0.56379801,  0.        ,\n",
       "         0.        ,  0.        ,  0.22701006,  0.08626924,  0.        ,\n",
       "         0.        ,  1.32656157,  0.        ,  0.        ,  1.25560772,\n",
       "         0.0849525 ,  0.        ,  0.17908391,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61.16770542, 61.14763072, 61.12755602, 61.10748133, 61.08740663,\n",
       "       61.06733193, 61.04725724, 61.02718254, 61.00710784, 60.98703315,\n",
       "       60.96695845, 60.94688375, 60.92680906, 60.90673436, 60.88665966,\n",
       "       60.86658497, 60.84651027, 60.82643557, 60.80636088, 60.78628618,\n",
       "       60.76621148, 60.74613679, 60.72606209, 60.70598739, 60.6859127 ,\n",
       "       60.665838  , 60.64576331, 60.62568861, 60.60561391, 60.58553922,\n",
       "       60.56546452, 60.54538982, 60.52531513, 60.50524043, 60.48516573,\n",
       "       60.46509104, 60.44501634, 60.42494164, 60.40486695, 60.38479225,\n",
       "       60.36471755, 60.34464286, 60.32456816, 60.30449346, 60.28441877,\n",
       "       60.26434407, 60.24426937, 60.22419468, 60.20411998, 60.18404528,\n",
       "       60.16397059, 60.14389589, 60.1238212 , 60.1037465 , 60.0836718 ,\n",
       "       60.06359711, 60.04352241, 60.02344771, 60.00337302, 59.98329832,\n",
       "       59.96322362, 59.94314893, 59.92307423, 59.90299953, 59.88292484,\n",
       "       59.86285014, 59.84277544, 59.82270075, 59.80262605, 59.78255135,\n",
       "       59.76247666, 59.74240196, 59.72232726, 59.70225257, 59.68217787,\n",
       "       59.66210317, 59.64202848, 59.62195378, 59.60187908, 59.58180439,\n",
       "       59.56172969, 59.541655  , 59.5215803 , 59.5015056 , 59.48862472,\n",
       "       59.47632712, 59.46402951, 59.45173191, 59.43943431, 59.42713671,\n",
       "       59.41483911, 59.4025415 , 59.3902439 , 59.3779463 , 59.3656487 ,\n",
       "       59.3533511 , 59.34105349, 59.32875589, 59.31645829, 59.30416069])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.98341449823185\n",
      "35.38946937628516\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
