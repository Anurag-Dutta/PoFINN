{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1945    63.275549\n",
       "1946    63.255474\n",
       "1947    63.235399\n",
       "1948    63.215324\n",
       "1949    63.195250\n",
       "Name: C4, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_1850_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1845     0.157353\n",
       "1846     0.000000\n",
       "1847     0.000000\n",
       "1848     0.312728\n",
       "1849     0.207403\n",
       "Name: C4, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1850)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.409524</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.219048</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.028571</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.838095</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.600000  0.000298\n",
       "1     88.409524  0.000298\n",
       "2     88.219048  0.000297\n",
       "3     88.028571  0.000297\n",
       "4     87.838095  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsoElEQVR4nO3deXhU5dnH8e+dHUiAhISdsKNCoAgRUEBARHEFW1vRFtFq1dbWVlutra+v1tpWa1vftlKVWvcdLRar4sLmBkjYd9l3CAlL2BJI8rx/zEmYhIQsk8lMmN/nuubKnDPPmXPnBM59zrMdc84hIiKRKyrUAYiISGgpEYiIRDglAhGRCKdEICIS4ZQIREQiXEyoA6iN1NRU16lTp1CHISLSoCxYsCDHOZdWfn2DTASdOnUiKysr1GGIiDQoZra5ovWqGhIRiXBKBCIiEU6JQEQkwikRiIhEOCUCEZEIp0QgIhLhlAhERCJcRCWCdxZt5+W5FXajFRGJWBGVCN5ftpPnv9wU6jBERMJKRCWCji0as3XvEYqL9TAeEZESEZUI0lMaU1BYTPbBglCHIiISNiIrEbRoAsCWvUdCHImISPiIqETQMaUxAJtzD4c4EhGR8BFRiaBt80ZEGWzVHYGISKmISgRxMVG0bd6IzUoEIiKlIioRgK/BeHOuEoGISImISwQlXUhFRMQn4hJBekoTcg8f41BBYahDEREJCxGYCNRzSETEX8Qlgl5tmwK+6SZERCQCE0Gn1CZc3qcNz32xiZxDGmEsIhJxiQDgzlE9yD9exJOz1oc6FBGRkIvIRNA1LZFv9mvPS3M3s+tAfqjDEREJqYhMBAA/Hdkd5xx/n7E21KGIiIRUnSQCMxttZmvMbJ2Z3VvB5+eb2UIzKzSzq8t9NsHM1nqvCXURT3V0SGnMNed04I35W/lyfU597VZEJOwEnAjMLBqYCFwC9ASuNbOe5YptAW4AXi23bQrwADAQGAA8YGbJgcZUXT8d2YP0Fo353jPzeHLWepzTcwpEJPLUxR3BAGCdc26Dc+4Y8Dowxr+Ac26Tc24pUFxu24uBj51ze51z+4CPgdF1EFO1pCXFM/XHQ7gkow2PTlvNLS8t4MDR4/W1exGRsFAXiaAdsNVveZu3rk63NbNbzCzLzLL27NlTq0ArkhgfwxPXnc39l/dk5upsrnzic1buyKuz7xcRCXcNprHYOTfJOZfpnMtMS0ur0+82M24a0pnXbxlE/vEirvrHF0zO2lr1hiIip4G6SATbgQ5+y+29dcHets5ldkrhvTuG0i89mbvfWsqj01ar3UBETnt1kQjmA93NrLOZxQHjgKnV3PZD4CIzS/YaiS/y1oVMamI8L900gGsHpPPkrPX8fca6UIYjIhJ0MYF+gXOu0Mx+jO8EHg0865xbYWYPAVnOualmdg4wBUgGrjCz3zjnejnn9prZb/ElE4CHnHN7A40pUDHRUfxubAYFhUX85eOvaRwXzc1Du4Q6LBGRoLCGWPWRmZnpsrKygr6fwqJifvr6Yt5btpOHx2bwvUEdg75PEZFgMbMFzrnM8usDviM4ncVER/H4NX3JP17E/7yznEax0Xyrf/tQhyUiUqcaTK+hUImLiWLid/sxpFsqd7+1hPeWavpqETm9KBFUQ0JsNJOu70//jsn89PVFfLJyd6hDEhGpM0oE1dQ4LoZnbziHnm2b8qNXFjJt+a5QhyQiUieUCGogKSGWF78/gF7tmvKjVxbw5nwNOhORhk+JoIaaN47jlZsHMqR7Gve8vZSnZuvhNiLSsCkR1ELjuBieuT6Ty/u04ZEPVvOH91dpBLKINFjqPlpLcTFR/HXc2SQ3juPpTzew9/Axfjs2g4TY6FCHJiJSI0oEAYiOMh4a04vkJnH8bfpavlyfy72XnMnlfdpgZqEOT0SkWlQ1FCAz465RPXj9lkE0axTLT15bxLefmsPSbftDHZqISLUoEdSRQV1a8O5PhvDot3qzKfcwVz7xBb+YvITdefmhDk1E5JSUCOpQdJRxzTnpzPzFcG4d1oWpi3cw4k+zmDhzHfnHi0IdnohIhZQIgiApIZZfXXIWH991PkO7p/LYh2sY+efZvLd0p3oXiUjYUSIIoo4tmvD0+Exe/cFAkhJiuP3VhVzz9FyWbz8Q6tBEREopEdSD87qm8t4dQ/n9Vb1Zv+cQVzzxOfe8tYTsg2o/EJHQUyKoJ9FRxnUD05l593B+MLQLUxZtZ8Rjs/jHLLUfiEhoKRHUs6YJsfz60rP46M5hnNctlT9OW8Oox2fzwTK1H4hIaCgRhEjn1Cb88/pMXrl5II1jY/jhKwsZN2kuK3ao/UBE6pcSQYgN7pbKe3cM4eGxGazNPsTlf/+ce99eyp6DBaEOTUQihBJBGIiJjuJ7gzoy8xfDuWlwZ95asI0Rf5rFU7PXU1Co9gMRCS4lgjDSrFEs/3N5Tz6683wGdUnhkQ9Wc9Hjn/Lhil1qPxCRoFEiCENd0hJ5ZsI5vPj9AcRFR3HrSwu47p/zWLUzL9ShichpSIkgjJ3fI40PfjqUh8b0YtWuPC7722f86t/LyDmk9gMRqTtKBGEuJjqK68/txKxfDGfCeZ2YnLWVEY/N4p+fbuBYYXGowxOR04ASQQPRvHEcD1zRi2k/O5/MTsn87v1VXPT4bN5ftpPCIiUEEam9OkkEZjbazNaY2Tozu7eCz+PN7A3v83lm1slb38nMjprZYu/1VF3Eczrr1jKR524cwPM3nkN0lPGjVxYy6A8z+P37q1i7+2CowxORBijgJ5SZWTQwERgFbAPmm9lU59xKv2I3Afucc93MbBzwKHCN99l651zfQOOINMPPaMngbqnMXJ3N5AXbePbzjUz6dAPfaN+MqzM7cGWftjRrHBvqMEWkAbBAuyWa2bnAg865i73lXwE45/7gV+ZDr8wcM4sBdgFpQEfgv865jJrsMzMz02VlZQUU9+km51AB7yzazlsLtrF610HiYqK4qGcrvp3ZgSHdUomO0qMzRSKdmS1wzmWWX18XzyxuB2z1W94GDKysjHOu0MwOAC28zzqb2SIgD/gf59xnFe3EzG4BbgFIT0+vg7BPL6mJ8dw8tAs3DenMih15TM7ayn+W7OC/S3fSumkC3+zXjqv7t6dLWmKoQxWRMBPqh9fvBNKdc7lm1h94x8x6OedO6jDvnJsETALfHUE9x9lgmBkZ7ZqR0a4Zv77sLKavymZy1laemr2ef8xaT2bHZK7u357L+rQhKUFVRyJSN4lgO9DBb7m9t66iMtu8qqFmQK7z1UsVADjnFpjZeqAHoHqfOhAfE82lvdtwae82ZOfl8+9F25mctZV7/72MB99dwaUZbbi6f3sGdWlBlKqORCJWXSSC+UB3M+uM74Q/DriuXJmpwARgDnA1MMM558wsDdjrnCsysy5Ad2BDHcQk5bRsmsBtw7py6/ldWLx1P5MXbOPdJTv496LtdE5twsTr+tGzbdNQhykiIRBw91HnXCHwY+BDYBXwpnNuhZk9ZGZXesX+BbQws3XAXUBJF9PzgaVmthh4C7jNObc30JikcmbG2enJ/P6q3sy/70L+Oq4v+ceL+PZTXzJzdXaowxOREAi411AoqNdQ3dqdl8/3n5/Pqp15/ObKXow/t1OoQxKRIKis15BGFgutmibw5q3ncsGZLbn/Pyv47X9XUlTc8C4QRKR2lAgEgCbxMTw9PpMbB3fiX59v5NaXFnDkWGGowxKReqBEIKWio4wHrujFg1f0ZMbq3Xzn6TnszssPdVgiEmRKBHKSGwZ35pkJmWzYc5irJn6h5yCInOaUCKRCF5zZism3nUuRc3z7qTnMWqMeRSKnKyUCqVSvts145/bBpKc05qYXsnhp7uZQhyQiQaBEIKfUplkj3rztXIb1SOP+d5bzsHoUiZx2lAikSonxMUwa358J53bkmc838sOX1aNI5HSiRCDVEhMdxW/GZPDAFT35eNVuxk2aS7Z6FImcFpQIpEZuHNyZSeMzWbv7EGMnfsGKHQdCHZKIBEiJQGpsVE9fj6JiB1c/OYdpy3eFOiQRCYASgdRKRrtmTP3xYHq0TuK2lxcwceY6GuK8VSKiSeckQPnHi7j37aW8s3gHifExtGoaT6umCbRumkDLpgmlyyU/05LiiY+JDnXYIhEpmI+qlAiWEBvN49f05fweaSzddoDsg/nsOpDPvI17yT6Yz/Giky80UprE0TIpntbNEmiV5EsSvqSRQNvmCfRs0xQzPShHpL4oEUjAzIxv9mvPN/u1L7PeOce+I8fZnZfPrrx8svPy2Z1XwG6/nyt35JFzqAD/oQm92jblrlE9uODMlkoIIvVAiUCCxsxIaRJHSpM4zmpT+dPPCouKyT18jN15+azYkceTs9Zz0wtZ9O3QnLtG9WBo91QlhAizamceb8zfym3DutK6WUKow6mVN7O2cuFZrUhpEhfqUKqkxmIJuZjoKFo1TaBP++ZcOyCd6T8fxiPf7M2egwVc/+xXfOfpOXy5PifUYUo92px7mOe/3MS+I8dCHUqtbNhziHveWspPXlsY6lCqRYlAwk5sdBTjBqQz8xfD+e3YDLbuPcp1/5zHtZPmkrVJTzJtCCZnbeXdJTtqvX1JVWEgN4Kj/+9T7puyrFbbvjpvCzc9P7/W+z5WVAxAzsHaJ7KH/7uSix//tNbb14QSgYStuJgoxg/qyKy7h/PAFT1Zm32Iq5+aw/h/zWPx1v2hDk9O4e63lvKT1xbVevuSzoxG7TPB6l0HeWXellptu2HPIeZsyK31vks4at8r85nPN7Jm98GAY6gOJQIJewmx0dw4uDOf3TOCX196Jit25DF24hfc9Px8lm/XyObTUckJNCpETUMOiIqgdiklAmkwGsVFc8v5Xfn0nhHcffEZZG3ex+V//5xbX8pi9S49POd04uqgaigQxc4FcC/S8CgRSIOTGB/D7SO68dkvR/CzC7vz5bpcRv/fZ9z+6kLWZdfPrbQEV3HpQNfQnI6dCywJBVKlFQrqPioNVtOEWH52YQ9uOK8Tz3y2kee+2MgHy3Yypm87bhvWlTNaJ4U6RAlQqO4InHNE1UG9VEOZuEGJQBq85o3j+MXFZ/D9IZ15evZ6XpiziSmLttM1rQmXZLRhdEZrerXVaOWGpOQEGqp6+mIXqnuR0FAikNNGSpM4fnXpWfzg/C58sHwX05bv5MnZ63li5jraJzdidK/WXNK7NWd3SK6Tqz0JnpKqoVD9lRwuohqL6yQRmNlo4K9ANPCMc+6Rcp/HAy8C/YFc4Brn3Cbvs18BNwFFwB3OuQ/rIiaJXKmJ8Ywf1JHxgzqy9/AxPlm1m2nLd/HinM088/lGWibFc3Gv1ozOaM3AzinERKupLNyEvrE4wDaCBpZDAk4EZhYNTARGAduA+WY21Tm30q/YTcA+51w3MxsHPApcY2Y9gXFAL6At8ImZ9XDOFQUalwj47hK+k9mB72R24GD+cWaszmba8l28tWAbL83dTPPGsYw6qxWjM1ozpHuqZkatwHNfbOTM1k05t2uLettnSdV6fV2Vb99/lISYKFokxvv276i0KvGVeZvpl558ymlTGpq6uCMYAKxzzm0AMLPXgTGAfyIYAzzovX8LeMJ8R3kM8LpzrgDYaGbrvO+bUwdxiZSRlBDLmL7tGNO3HUePFTH76z18uGIX01bsYvKCbSTGxzDizJZcktGaYT3SaBKvmlOAP324huNFjqev78+IM1rWyz6L67mVdfAjMwDY9MhlgNdYXEkOum/K8jJlq+t4UTGxYXr3WRf/0tsBW/2WtwEDKyvjnCs0swNAC2/93HLbtqtoJ2Z2C3ALQHp6eh2ELZGsUVw0ozN81UPHCov5cn0O05bv4qOVu3l3yQ7iY6IY1iONS3q35pKMNiTERu6dQrHzTZlw64sLeHp8f0acWf1kcDD/OEkJsTXfaR1WDc3dkMuATinVahfKPVRAi8R4bxzBqctX53crSWf3TVnGoi37+eHwrjz+ydd8cuewsGqnCs/0VAHn3CTnXKZzLjMtLS3U4chpJC4miuFntOSRb/Xhq1+P5LUfDGLcOR1Ysm0/d76xhCGPzmDizHXk5R8PdaghUewc487pQI/Widz+6kI25x6u9rb/Xridg7U4bidGFgd+shw3aS7Pf7mpWmVnrtnj27+relTz7K/3VPl9+w4fY8WOA6QmxrNqVx4/eW0RG/YcLp2LqDrq4+FhdZEItgMd/Jbbe+sqLGNmMUAzfI3G1dlWpN7EREdxbtcW/GZMBnPu9SWFXm2b8diHaxj8hxn8cdpqcg4VhDrMeuWcr4vupPGZxEQZd76xmMJqnsgemLqCe95aWqt9Agz940zW7zlU4+3L25hz6uTVqUVjABZs9k1qWFyujWDKom28s6jsqWn+Rl/ZrXuP8M6i7RVeKOQePsZlf/uci3q14vUfDCpdvy67+r9TcT3UktVFIpgPdDezzmYWh6/xd2q5MlOBCd77q4EZzpfmpgLjzCzezDoD3YGv6iAmkYBFRRnndm3BC98fwH9/MoTze6Tx5Oz1DH5kBv/7n+Vs3Xsk1CHWi2Kvvrxt80Y8fFVvFm7Zzz9mra/29jv2H63FPn0/i4odL8/dzKGCwhp/R21kbdoH+O5I/G9G3pi/lVfmbS5bdrOv7ILN+/jZG4vJPVT5TKPtmjdiYJcTje0P/XdlpWXLG/SH6fxj1rpql6+NgBOBc64Q+DHwIbAKeNM5t8LMHjKzK71i/wJaeI3BdwH3etuuAN7E17A8DbhdPYYkHGW0a8bE7/Zj+l3DGNu3Ha99tYXhf5rFXW8sZm09zRAZKr5E4DsrXvmNtozt25a/Tl9b7RlgK3pcaVX8Z+187otNbN9X82RSEyWJZ232IfYfOXbSFBNpSQnsOVhQpppm1c48DhUUllbzxEaf2KB8bU5hAJf1ew4WkHc0uImwTtoInHPvO+d6OOe6Oud+5637X+fcVO99vnPu2865bs65ASU9jLzPfudtd4Zz7oO6iEckWLqkJfLo1X349J4R3HBeJz5YvotRj3/KD17MYtGWfaEOLyh8M3GeWP7NmAxaJcVz5xuLOXKs6hPUyp15XPP0nBq1sZQ/keYGWB1XVVNDsXO09Z6EtmjLfpxzbN17lJ+8tohVO/No3iiWA0ePl8bVv2MyxQ6WbN3PcS8RfPp1TpnvK/P95RLBVxv3lll39FgRn56izaHYOXbn5TNrTTaHg3B31GAai0XCSZtmjbj/8p58ce8F3DGyO19t3MtV//iS6/45l8/X5tRLA199cM6d1Ke+WaNY/vydvmzKPczv3ltVre+Zt3EvD05dUaP9+quLZwOcen9wdnoy0VFG1ua9pXcI7y7ZwfZ9R2kUF03+8eLSE3z/jsmY+aqSjhf6EsGvpyzjK6/doPyfv8hb4X/XsCHnRDvBfVOWcf2zX1XaHlJY5Ji7IZcbnpvPrrz8Ovmd/SkRiAQgpUkcd43qwRf3XsB9l57FuuxDfO9f8xgz8QumLd950pVgQ1PZnD/ndm3BLUO78Mq8LcxYvbta3/Xvhdt5f9nO6u3X7/032jfj7zPWsXJH7acar6rvUbFzNImPplfbpmRt2lfmiv7mF7NIiI3m6PGi0hN6s0axnNEqiazNe8tUfa3YccCLv+zfvdArc0WftqXrFm7eX/q+JAHkHa34rqnYOfLyfXcCSQl1P75FiUCkDiTGx/CD87vw2S9H8Idv9ubA0ePc9vJCRj0+m8lZW0urDxqakhNiRV0p77qoB2e1aco9by2tsidV73bN6NO+Gb+esozsalzR+l9RL9nmO7nuPBC8doKSdpD+HZNZsm3/SX+vkl5S+cd8P82gX8dkFm/ZT/7xE82aJe0m5e8ISudO8kuoCzafqEosGVNQ2UC6wuLi0m64TWszLqMKSgQidSg+JpprB6Qz4+fD+fu1ZxMXE83dby1l+GOzeP6LjWVOGg1ByQ1NRYOf4mOi+b9r+pKXX8i9by87ZXVYy6R4Hr+mL/nHi7jn7aVVVp3Vd9VaSXfRzI4p5B8vZvn2sncfH67YBcBhr00kyozMjskcLChkhd+dykKvneikqiHvQPoPLF7g16YU7SWIyq4X1mcfxjnfHWgwBjcqEYgEQXSUccU32vL+HUN47oZzaNs8gQffXcnIP8/m7QXbSk8M4e7ElWzFn5/ROolfjj6TT1btZvKCbZV+T1xMFF3TEvnVJWcxa80epiw69XChig5PMHNDyZQSmZ2SAd/cQ/4u7d2GlQ9dTNNGvqvxKPO1E0DZ9oute4+SnZd/UtXQiTurEwdyXfYhDhzxXeWXJFr/fxeN406c8PPyj3P7iG4svH9UYL9oJZQIRILIzBhxZksm33Yer948kBaJcfx88hIu+9tnzFyTHfaNytV5LsCN53ViQKcUfv/+KvYerrgvfbR3ohs/qCNnpzfnd++tYv+RyvvdV3RUAjlSVT2LoqS7aKumCbRPbnTS5/nHi2gcF1P694oyIz2lMamJ8RwoV6+/cMv+kxJZYbHDOcf+I+XKbvXdFZTcEfhXDTXyu/IP9oWDEoFIPTmvWyrv/Ggwf7/2bI4cK+LG5+Zz3T/nsaSa/fFDoeTK9lSn0ago4+GrMjiUX8gjH1Tci6hksrWoKOPhsRnsO3KMP364pvL91nvV0ImxEv3Sk0/6/FBBkVfOt2xmmBn9OzYvLZOaGEdMlLFs+/6T4i8qdvz4tUVM86qYfN9B6d8+uoI2Av8qoGBPwqdEIFKPorwqo0/uGsZvruzF17sPMmbiF9z+6kI2VTENQigUV+OOAKBHqyRuHtqFN7O2MX/TXpIbx3LdwHQmje9P22YJpSc6gF5tm3Hj4M68Om9LaZ16eRWd97btq/1I7kZxp65XL3Ynfsc+7Zud9HnplBolicBb/40OzUvLNImPoUerJJZuO3DS3UtxMXRvmVhmXfeWiaWJYIfXEO5/5d+yaXzpe90RiJyG4mKimHBeJ2bdPZw7LujGjFXZXPiX2Tzwn+VhNZdRVW0E/u4Y2Y12zRtx35RlFBY5YqOMi3q1psg5Yso1Nt85qgetmyZw35TlFc5bVL6OHeA3766sdXfc72R2OOXnxe7ElBJ92jc/6fOSXkTle1H1aXeibHSU0ad9M5ZuO3BSnIXFxXyj3Pd+o31zX9Jwjg17fBcBD717YuqJ2KgTp+dgNykpEYiEUFJCLHdddAaz7x7Od87pwMvztjDsjzP56ydrgzKCtKacd46uziygjeNiePDKXny9+xAHCwoxM44eK2J3XsFJbQeJ8TE8cEVPVu3M44U5m0/6rspqQl6bv6XGvwNA59Qmp/zc+d0R9Gp78gNnSsYKlCYCLxP09rt7iI2Kok/75hw4epwt5eahKnauTFnw3U3kHj7GNr/pMzb43RX6J8ONOYeZODN48w0pEYiEgZZNE/j9Vb356M7zGdo9jcc/+Zphj83ipbmbQzoG4VTjCCoyqmcrRvVsBfjuIkpGwc6tYGTw6IzWDD8jjb98tOakMQIlV8ADO6eUWf/oB6vZc7Bmd0wVVfWUVzKxHlDhA4mOld4R+JZLGp+bNTrRpz8m2kr3Vb7dJ6NdM1IT48usK7lDWOqNkyhRcodUWRfUYFAiEAkjXdMSeWp8f97+4Xl0Tm3M/e8s56LHP+X9ZTtD0sOo/BVwdTx4ZS8ax0WTlBBLk3hf3XxB4cnJzMx46MoMCotdmSoROHE1HBdz4hTVObUJ+ceL+f371ZvWokTXtMQqy/g3FgP8dVxffjs2o3T5xMn55MR4eZ82pCbG8fDYDM5onURcTBSLy53cSx6B2sSvraKk7JJt+8uUXetNUV2+gTghNninaz2LTyQM9e+YzJu3nsv0Vdk8Om01P3plIXHRUaQmxpGWFE9qou/VIjHO9z4p3veZt75Zo9g6eQJW+Svg6mjXvBEzfj6c5o1jS69iK0oEAOktGvOTC7rxp4++ZswTnzO0expDuqdyzCvv37ZwZuskrujThr/NWMfm3MMM6Z7G0O6p9O3Q/KRHQPonzSgzvt59kIP5hXyjfTNiKnhcZPnnD4zp63tQ4v3v+B5LeaJq6MR3lnjiun5lvqtX26Ys2rK/zLqPV+5mQKcU5vx6JH0e/AjwJblebZvykV9PIoAX52zit2MyTmolCeZT8pQIRMKUmXFhz1YMPyON95btZOXOPPYcLCDn0DF2HMhn2fYD5B4+VmGVQUyUkdKkbJLwJY+40iRSspzSJK7CkyP4PymsZrG39mbyLGk0TTrF859vHdaV6KgoPl65iydnr+cJv7rwvh2SS58alpQQw+0XdCMmOooZq7N5YsZa/jZ9LU3iohnUpQWDu6UypHsq3VsmlmlcjY7yTWX92ldbSIqPYWCXFgztnsrgbql0TWuCmZ3yGcXgXzVU9fH49aVn8e2nyj52/QcvZjHlR+dxdrmuqXde2IMfvrygzLrXvtrKtn1HOZhfto0oPkZ3BCIRKyY6ijF925VepforLnbsP3qcnEMF5BwsIOfwMd/PQyWvY+QeKmB99iH2HCoovdL2ZwbJjePKJImSO424kv7/tXxkZFSU8ei3epPZKaXSMrHRUfxweFd+OLwrefnHmbM+ly/W5eCcryfS4598DcB9l/YkPiaaO0Z2546R3Tlw5DhzNuTw+bocPl+bw/TV2QCkJcVzXtcTD4Hp0745l/Vuw5BuqXy+Locv1uXwySrfRHmtmyYwuFsqhcWuwt/xt2MzWL0zj2sHpDPiT7M4o1WSd8wqPx7ndEph+s+HMXHmOv698MQI6pKEPfm2c8nx2jnO75HGlNsHc/fkJXRvlcRPR3bny/U53P/OipMeZ6k7AhGpUJR35Z/SJI4e3kmqMs45DhYUknOwgFy/hLHn0DFyDhWQ6yWOJdv2k3OwgMPHTsyLFMhEZ9eck17tsk0TYrm4V2su7tX6pM+aNY49aXl0RhtGZ7QBfI+M/HJ9Dp+t9b0AbjivE98dmI6ZcVmfNlzWx1d2S+6R0qQwffVunCvb8Fti/KCOgG/CuzNbJ/Hlel+jd3LjuFP+Hl3TEvnd2N5lEkHJw2nOKZcUe7RK4p3bB5cml2tS0uneKokfvryAA0ePk3+8mO8P7kxfvzELdU2JQCRCmBlNE2JpmhBLl7Sqyx89VkTOoQIOFRRWmWSCqUerRL7eXfUzfjukNOaalHSuOSed4mLHlr1HaJfcqMKr9/QWjbmuRTrXDfSV3Zh7uMKpJUq0adaIJ7/Xn6Jix/Z9R09ZtkT53Z6q10/5GPulJzP77hFMW76Ln72xmGvO6UDHFqfuAhsIJQIRqVCjuGg6pDQOdRi8fsu5bMyp2QPso6KMTlWMHfAvW52eReAbNJbeonbHpKaPq0yIjT6pETxYlAhEJKz5qr4qb2MIVyffEdR+PEgtm2iqTeMIRESCwMpN1VdYVPNxIBVNtREMSgQiIkFQkzaCKr8rwFiqokQgIhIE5U/eNW0jqE9KBCIiQVC+J1Bt7gjqa1YRJQIRkSCoyzsCNRaLiDRA/ifvId1SSUuKr7xwJeqrMimgRGBmKWb2sZmt9X6e/Iw3X7kJXpm1ZjbBb/0sM1tjZou9V8tA4hERCRf+VUMv3zyQYT2qMYqv8m8LPKBTCPSO4F5gunOuOzDdWy7DzFKAB4CBwADggXIJ47vOub7eKzvAeEREpIYCTQRjgBe89y8AYysoczHwsXNur3NuH/AxMDrA/YqInPbq6xkUgSaCVs65nd77XUCrCsq0A7b6LW/z1pV4zqsWut9OMaWfmd1iZllmlrVnz54AwxYRaTiC3Vhc5RQTZvYJcPJUgHCf/4JzzplZTdPXd51z280sCXgbGA+8WFFB59wkYBJAZmZm+HbIFRFpYKpMBM65Cyv7zMx2m1kb59xOM2sDVFTHvx0Y7rfcHpjlffd27+dBM3sVXxtChYlARCRShfvI4qlASS+gCcB/KijzIXCRmSV7jcQXAR+aWYyZpQKYWSxwObA8wHhERE4bDWVA2SPAKDNbC1zoLWNmmWb2DIBzbi/wW2C+93rIWxePLyEsBRbju3P4Z4DxiIicdmryzOjaCGgaaudcLjCygvVZwM1+y88Cz5YrcxjoH8j+RUQkcBpZLCISpjQNtYiIAOHfWCwiIkHSUBqLRUQkyDT7qIhIhNIdgYiIACc//7iuKRGIiARR59QmoQ6hSgGNIxARkcpN//kwUhNr/kCaEvU1qZoSgYhIkHRNS6yT71FjsYhIhGoozyMQEZEGTolARCTCKRGIiISp+mosViIQEQlzaiwWEYlUGlksIiIQ/AfTKBGIiIQpPY9AREQAPY9ARESCTIlARCRMaRpqEREB1H1URCRiaUCZiIgAejCNiIgEmRKBiEiYahCNxWaWYmYfm9la72dyJeWmmdl+M/tvufWdzWyema0zszfMLC6QeERETkfh3lh8LzDdOdcdmO4tV+QxYHwF6x8FHnfOdQP2ATcFGI+IyGmjoYwsHgO84L1/ARhbUSHn3HTgoP86802ecQHwVlXbi4hEsnAfWdzKObfTe78LaFWDbVsA+51zhd7yNqBdZYXN7BYzyzKzrD179tQuWhGRBqS+2giqfHi9mX0CtK7go/v8F5xzzsyCFrZzbhIwCSAzM7O+uteKiIRekG8JqkwEzrkLK/vMzHabWRvn3E4zawNk12DfuUBzM4vx7graA9trsL2IiNSBQKuGpgITvPcTgP9Ud0PnnANmAlfXZnsRkdNdQxlZ/AgwyszWAhd6y5hZppk9U1LIzD4DJgMjzWybmV3sffRL4C4zW4evzeBfAcYjInLaCfbI4iqrhk7FOZcLjKxgfRZws9/y0Eq23wAMCCQGEZHTVj21FmtksYhImAv3AWUiIhIkDaWNQEREgizcB5SJiEgDp0QgIhKmGsTsoyIiEnwW5NZiJQIRkTDl1H1URERAjcUiIhJkSgQiImFK4whERATQyGIRkYil7qMiIgIEf/ZRJQIRkTClNgIREfFRG4GIiASTEoGISJjSyGIREQHUfVRERIJMiUBEJMxpriERkQilAWUiIgLoeQQiIhJkSgQiImHK1dPY4oASgZmlmNnHZrbW+5lcSblpZrbfzP5bbv3zZrbRzBZ7r76BxCMicjoK98bie4HpzrnuwHRvuSKPAeMr+exu51xf77U4wHhERE4bDaWxeAzwgvf+BWBsRYWcc9OBgwHuS0QkIoX7gLJWzrmd3vtdQKtafMfvzGypmT1uZvEBxiMiIjUUU1UBM/sEaF3BR/f5LzjnnJnV9EbmV/gSSBwwCfgl8FAlcdwC3AKQnp5ew92IiDQ89TUNdZWJwDl3YWWfmdluM2vjnNtpZm2A7Jrs3O9uosDMngN+cYqyk/AlCzIzM+vr+IiIhFy4P5hmKjDBez8B+E9NNvaSB+YbLTEWWB5gPCIip42G0lj8CDDKzNYCF3rLmFmmmT1TUsjMPgMmAyPNbJuZXex99IqZLQOWAanAwwHGIyJy2gl2Y3GVVUOn4pzLBUZWsD4LuNlveWgl218QyP5FRE5nDWJAmYiINHxKBCIiEU6JQEQkTDWUxmIREQmycB9ZLCIiQdI1LZHLerchKsiZIKBeQyIiEjyjM1ozOqOiiR3qlu4IREQinBKBiEiEUyIQEYlwSgQiIhFOiUBEJMIpEYiIRDglAhGRCKdEICIS4czV12QWdcjM9gCba7l5KpBTh+EEg2KsOw0hTsVYNxRj1To659LKr2yQiSAQZpblnMsMdRynohjrTkOIUzHWDcVYe6oaEhGJcEoEIiIRLhITwaRQB1ANirHuNIQ4FWPdUIy1FHFtBCIiUlYk3hGIiIgfJQIRkQgXUYnAzEab2RozW2dm94Yohg5mNtPMVprZCjP7qbf+QTPbbmaLvdelftv8yot5jZldXI+xbjKzZV48Wd66FDP72MzWej+TvfVmZn/z4lxqZv3qIb4z/I7XYjPLM7OfhfpYmtmzZpZtZsv91tX4uJnZBK/8WjObUA8xPmZmq704pphZc299JzM76nc8n/Lbpr/3b2Sd93vU2aO0Komxxn/bYP+/ryTON/xi3GRmi731ITmWVXLORcQLiAbWA12AOGAJ0DMEcbQB+nnvk4CvgZ7Ag8AvKijf04s1Hujs/Q7R9RTrJiC13Lo/Avd67+8FHvXeXwp8ABgwCJgXgr/vLqBjqI8lcD7QD1he2+MGpAAbvJ/J3vvkIMd4ERDjvX/UL8ZO/uXKfc9XXtzm/R6XBDnGGv1t6+P/fUVxlvv8z8D/hvJYVvWKpDuCAcA659wG59wx4HVgTH0H4Zzb6Zxb6L0/CKwC2p1ikzHA6865AufcRmAdvt8lVMYAL3jvXwDG+q1/0fnMBZqbWZt6jGsksN45d6oR5/VyLJ1znwJ7K9h3TY7bxcDHzrm9zrl9wMfA6GDG6Jz7yDlX6C3OBdqf6ju8OJs65+Y635nsRb/fKygxnkJlf9ug/78/VZzeVf13gNdO9R3BPpZViaRE0A7Y6re8jVOfgIPOzDoBZwPzvFU/9m7Lny2pOiC0cTvgIzNbYGa3eOtaOed2eu93Aa2896E+vuMo+58t3I5lTY9bqI/n9/FdlZbobGaLzGy2mQ311rXz4ipRXzHW5G8b6uM4FNjtnFvrty6cjiUQWYkgrJhZIvA28DPnXB7wJNAV6AvsxHc7GWpDnHP9gEuA283sfP8PvSuXkPc/NrM44EpgsrcqHI9lqXA5bpUxs/uAQuAVb9VOIN05dzZwF/CqmTUNUXhh/betwLWUvUAJp2NZKpISwXagg99ye29dvTOzWHxJ4BXn3L8BnHO7nXNFzrli4J+cqLIIWdzOue3ez2xgihfT7pIqH+9ndqjjxJeoFjrndnvxht2xpObHLSSxmtkNwOXAd72EhVfdkuu9X4Cvzr2HF49/9VHQY6zF3zZkf3MziwG+CbxRsi6cjqW/SEoE84HuZtbZu4IcB0yt7yC8OsN/Aaucc3/xW+9fn34VUNIDYSowzszizawz0B1fo1Kw42xiZkkl7/E1JC734inpwTIB+I9fnNd7vWAGAQf8qkKCrcxVV7gdS7991+S4fQhcZGbJXvXHRd66oDGz0cA9wJXOuSN+69PMLNp73wXfcdvgxZlnZoO8f9fX+/1ewYqxpn/bUP6/vxBY7ZwrrfIJp2NZRn21SofDC18Pja/xZeH7QhTDEHzVAkuBxd7rUuAlYJm3firQxm+b+7yY11BPPQnw9bJY4r1WlBwvoAUwHVgLfAKkeOsNmOjFuQzIrKc4mwC5QDO/dSE9lviS0k7gOL663ptqc9zw1dOv81431kOM6/DVp5f8u3zKK/st79/AYmAhcIXf92TiOxmvB57Am60giDHW+G8b7P/3FcXprX8euK1c2ZAcy6pemmJCRCTCRVLVkIiIVECJQEQkwikRiIhEOCUCEZEIp0QgIhLhlAhERCKcEoGISIT7f2CKk49F7u1lAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.600000    88.409524    88.219048    88.028571    87.838095   \n",
      "351    88.409524    88.219048    88.028571    87.838095    87.647619   \n",
      "352    88.219048    88.028571    87.838095    87.647619    87.457143   \n",
      "353    88.028571    87.838095    87.647619    87.457143    87.266667   \n",
      "354    87.838095    87.647619    87.457143    87.266667    87.076190   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.647619    87.457143    87.266667    87.076190    86.896218  ...   \n",
      "351    87.457143    87.266667    87.076190    86.896218    86.845798  ...   \n",
      "352    87.266667    87.076190    86.896218    86.845798    86.795378  ...   \n",
      "353    87.076190    86.896218    86.845798    86.795378    86.744958  ...   \n",
      "354    86.896218    86.845798    86.795378    86.744958    86.694538  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   78.880345    0.000263   78.856069    0.000263   78.831793    0.000263   \n",
      "351   78.856069    0.000263   78.831793    0.000263   78.807516    0.000262   \n",
      "352   78.831793    0.000263   78.807516    0.000262   78.783240    0.000262   \n",
      "353   78.807516    0.000262   78.783240    0.000262   78.758964    0.000262   \n",
      "354   78.783240    0.000262   78.758964    0.000262   78.734687    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   78.807516    0.000262   78.783240    0.000262  \n",
      "351   78.783240    0.000262   78.758964    0.000262  \n",
      "352   78.758964    0.000262   78.734687    0.000262  \n",
      "353   78.734687    0.000262   78.710411    0.000262  \n",
      "354   78.710411    0.000262   78.686134    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 1, 251) (1400, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "18/18 [==============================] - 3s 43ms/step - loss: 5340.8184 - val_loss: 3735.6934\n",
      "Epoch 2/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5184.2095 - val_loss: 3617.6416\n",
      "Epoch 3/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5086.3149 - val_loss: 3563.3904\n",
      "Epoch 4/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5022.5625 - val_loss: 3518.8633\n",
      "Epoch 5/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4961.1411 - val_loss: 3474.8293\n",
      "Epoch 6/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 4890.4019 - val_loss: 3422.5063\n",
      "Epoch 7/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4826.3438 - val_loss: 3377.8213\n",
      "Epoch 8/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4764.5234 - val_loss: 3333.8274\n",
      "Epoch 9/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 4695.1953 - val_loss: 3280.7302\n",
      "Epoch 10/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 4624.1016 - val_loss: 3235.6704\n",
      "Epoch 11/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 4561.2163 - val_loss: 3191.7881\n",
      "Epoch 12/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 4499.7607 - val_loss: 3148.9177\n",
      "Epoch 13/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4439.4741 - val_loss: 3106.8918\n",
      "Epoch 14/500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4380.1689 - val_loss: 3065.6123\n",
      "Epoch 15/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4321.7290 - val_loss: 3024.8760\n",
      "Epoch 16/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 4254.8203 - val_loss: 2982.9243\n",
      "Epoch 17/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 4191.6455 - val_loss: 2942.8464\n",
      "Epoch 18/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4130.9146 - val_loss: 2903.5134\n",
      "Epoch 19/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4071.6531 - val_loss: 2864.8555\n",
      "Epoch 20/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 4013.5769 - val_loss: 2826.8215\n",
      "Epoch 21/500\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 3956.5054 - val_loss: 2789.3770\n",
      "Epoch 22/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3900.3276 - val_loss: 2752.4980\n",
      "Epoch 23/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3844.9700 - val_loss: 2716.1663\n",
      "Epoch 24/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3790.3809 - val_loss: 2680.3662\n",
      "Epoch 25/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 3736.5220 - val_loss: 2645.0864\n",
      "Epoch 26/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3683.3618 - val_loss: 2610.3159\n",
      "Epoch 27/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3630.8765 - val_loss: 2576.0447\n",
      "Epoch 28/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3579.0464 - val_loss: 2542.2654\n",
      "Epoch 29/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3527.8538 - val_loss: 2508.9695\n",
      "Epoch 30/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3477.2844 - val_loss: 2476.1499\n",
      "Epoch 31/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3427.3232 - val_loss: 2443.8008\n",
      "Epoch 32/500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 3377.9614 - val_loss: 2411.9153\n",
      "Epoch 33/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 3329.1858 - val_loss: 2380.4880\n",
      "Epoch 34/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3280.9883 - val_loss: 2349.5132\n",
      "Epoch 35/500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 3233.3596 - val_loss: 2318.9856\n",
      "Epoch 36/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3186.2910 - val_loss: 2288.9004\n",
      "Epoch 37/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 3139.7761 - val_loss: 2259.2529\n",
      "Epoch 38/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 3093.8059 - val_loss: 2230.0376\n",
      "Epoch 39/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3048.3748 - val_loss: 2201.2505\n",
      "Epoch 40/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 3003.4758 - val_loss: 2172.8872\n",
      "Epoch 41/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2959.1028 - val_loss: 2144.9429\n",
      "Epoch 42/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2915.2502 - val_loss: 2117.4143\n",
      "Epoch 43/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2871.9119 - val_loss: 2090.2961\n",
      "Epoch 44/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2829.0820 - val_loss: 2063.5852\n",
      "Epoch 45/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2786.7561 - val_loss: 2037.2770\n",
      "Epoch 46/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2744.9285 - val_loss: 2011.3680\n",
      "Epoch 47/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2703.5935 - val_loss: 1985.8547\n",
      "Epoch 48/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2662.7483 - val_loss: 1960.7324\n",
      "Epoch 49/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2622.3865 - val_loss: 1935.9980\n",
      "Epoch 50/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2582.5034 - val_loss: 1911.6482\n",
      "Epoch 51/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2543.0950 - val_loss: 1887.6779\n",
      "Epoch 52/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2504.1570 - val_loss: 1864.0854\n",
      "Epoch 53/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2465.6841 - val_loss: 1840.8662\n",
      "Epoch 54/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2427.6733 - val_loss: 1818.0167\n",
      "Epoch 55/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2390.1199 - val_loss: 1795.5343\n",
      "Epoch 56/500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 2353.0198 - val_loss: 1773.4148\n",
      "Epoch 57/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2316.3689 - val_loss: 1751.6550\n",
      "Epoch 58/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2280.1633 - val_loss: 1730.2517\n",
      "Epoch 59/500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 2244.3987 - val_loss: 1709.2015\n",
      "Epoch 60/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2209.0713 - val_loss: 1688.5011\n",
      "Epoch 61/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2174.1777 - val_loss: 1668.1471\n",
      "Epoch 62/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2139.7136 - val_loss: 1648.1368\n",
      "Epoch 63/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2105.6758 - val_loss: 1628.4663\n",
      "Epoch 64/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2072.0603 - val_loss: 1609.1334\n",
      "Epoch 65/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2038.8629 - val_loss: 1590.1343\n",
      "Epoch 66/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2006.0817 - val_loss: 1571.4655\n",
      "Epoch 67/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1973.7114 - val_loss: 1553.1249\n",
      "Epoch 68/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1941.7498 - val_loss: 1535.1086\n",
      "Epoch 69/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1910.1921 - val_loss: 1517.4142\n",
      "Epoch 70/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1879.0361 - val_loss: 1500.0380\n",
      "Epoch 71/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1848.2776 - val_loss: 1482.9774\n",
      "Epoch 72/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1817.9131 - val_loss: 1466.2291\n",
      "Epoch 73/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1787.9396 - val_loss: 1449.7905\n",
      "Epoch 74/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1758.3535 - val_loss: 1433.6580\n",
      "Epoch 75/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1729.1517 - val_loss: 1417.8291\n",
      "Epoch 76/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1700.3309 - val_loss: 1402.3009\n",
      "Epoch 77/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1671.8876 - val_loss: 1387.0703\n",
      "Epoch 78/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1643.8193 - val_loss: 1372.1342\n",
      "Epoch 79/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1616.1219 - val_loss: 1357.4895\n",
      "Epoch 80/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1588.7930 - val_loss: 1343.1328\n",
      "Epoch 81/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1561.8287 - val_loss: 1329.0651\n",
      "Epoch 82/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1535.2262 - val_loss: 1315.4753\n",
      "Epoch 83/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1500.1238 - val_loss: 1295.1628\n",
      "Epoch 84/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1466.4381 - val_loss: 1279.8120\n",
      "Epoch 85/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1436.4491 - val_loss: 1265.2581\n",
      "Epoch 86/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1407.7666 - val_loss: 1251.3428\n",
      "Epoch 87/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1380.0807 - val_loss: 1237.9478\n",
      "Epoch 88/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1353.1909 - val_loss: 1225.0043\n",
      "Epoch 89/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1326.9795 - val_loss: 1212.4681\n",
      "Epoch 90/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1301.3702 - val_loss: 1200.3098\n",
      "Epoch 91/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1276.3114 - val_loss: 1188.5063\n",
      "Epoch 92/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1251.7646 - val_loss: 1177.0419\n",
      "Epoch 93/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1227.7013 - val_loss: 1165.9015\n",
      "Epoch 94/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1204.0980 - val_loss: 1155.0742\n",
      "Epoch 95/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1180.9360 - val_loss: 1144.5509\n",
      "Epoch 96/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1158.1997 - val_loss: 1134.3224\n",
      "Epoch 97/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1135.8749 - val_loss: 1124.3815\n",
      "Epoch 98/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1113.9502 - val_loss: 1114.7205\n",
      "Epoch 99/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1092.4148 - val_loss: 1105.3342\n",
      "Epoch 100/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1071.2598 - val_loss: 1096.2162\n",
      "Epoch 101/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1050.4758 - val_loss: 1087.3610\n",
      "Epoch 102/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1030.0553 - val_loss: 1078.7637\n",
      "Epoch 103/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1009.9913 - val_loss: 1070.4193\n",
      "Epoch 104/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 990.2769 - val_loss: 1062.3235\n",
      "Epoch 105/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 970.9056 - val_loss: 1054.4713\n",
      "Epoch 106/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 951.8718 - val_loss: 1046.8588\n",
      "Epoch 107/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 933.1696 - val_loss: 1039.4821\n",
      "Epoch 108/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 914.7935 - val_loss: 1032.3364\n",
      "Epoch 109/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 896.7386 - val_loss: 1025.4183\n",
      "Epoch 110/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 878.9998 - val_loss: 1018.7239\n",
      "Epoch 111/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 861.5722 - val_loss: 1012.2495\n",
      "Epoch 112/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 844.4517 - val_loss: 1005.9907\n",
      "Epoch 113/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 827.6334 - val_loss: 999.9437\n",
      "Epoch 114/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 811.1133 - val_loss: 994.1030\n",
      "Epoch 115/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 794.8870 - val_loss: 988.4569\n",
      "Epoch 116/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 778.9628 - val_loss: 982.6293\n",
      "Epoch 117/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 759.2340 - val_loss: 976.1199\n",
      "Epoch 118/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 740.2208 - val_loss: 969.9777\n",
      "Epoch 119/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 722.1650 - val_loss: 964.3312\n",
      "Epoch 120/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 705.0154 - val_loss: 959.0845\n",
      "Epoch 121/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 688.5688 - val_loss: 954.1735\n",
      "Epoch 122/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 672.7001 - val_loss: 949.5591\n",
      "Epoch 123/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 657.3318 - val_loss: 945.2153\n",
      "Epoch 124/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 642.4127 - val_loss: 941.1230\n",
      "Epoch 125/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 627.9064 - val_loss: 937.2681\n",
      "Epoch 126/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 613.7850 - val_loss: 933.6381\n",
      "Epoch 127/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 600.0270 - val_loss: 930.2236\n",
      "Epoch 128/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 586.6148 - val_loss: 927.0157\n",
      "Epoch 129/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 573.5333 - val_loss: 924.0070\n",
      "Epoch 130/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 560.7700 - val_loss: 921.1908\n",
      "Epoch 131/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 548.3137 - val_loss: 918.5607\n",
      "Epoch 132/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 536.1543 - val_loss: 916.1108\n",
      "Epoch 133/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 524.2831 - val_loss: 913.8359\n",
      "Epoch 134/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 512.6920 - val_loss: 911.7308\n",
      "Epoch 135/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 501.3734 - val_loss: 909.7910\n",
      "Epoch 136/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 490.3204 - val_loss: 908.0117\n",
      "Epoch 137/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 479.5266 - val_loss: 906.3884\n",
      "Epoch 138/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 468.9856 - val_loss: 904.9170\n",
      "Epoch 139/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 458.6919 - val_loss: 903.5934\n",
      "Epoch 140/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 448.6400 - val_loss: 902.4138\n",
      "Epoch 141/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 438.8246 - val_loss: 901.3742\n",
      "Epoch 142/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 429.2408 - val_loss: 900.4710\n",
      "Epoch 143/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 419.8836 - val_loss: 899.7004\n",
      "Epoch 144/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 410.7485 - val_loss: 899.0591\n",
      "Epoch 145/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 401.8309 - val_loss: 898.5433\n",
      "Epoch 146/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 393.1268 - val_loss: 898.1499\n",
      "Epoch 147/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 384.6315 - val_loss: 897.8753\n",
      "Epoch 148/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 376.3413 - val_loss: 897.7164\n",
      "Epoch 149/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 368.2518 - val_loss: 897.6700\n",
      "Epoch 150/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 360.3594 - val_loss: 897.7329\n",
      "Epoch 151/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 352.6603 - val_loss: 897.9019\n",
      "Epoch 152/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 345.1512 - val_loss: 898.1741\n",
      "Epoch 153/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 337.8280 - val_loss: 898.5463\n",
      "Epoch 154/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 330.6868 - val_loss: 899.0157\n",
      "Epoch 155/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 323.7246 - val_loss: 899.5791\n",
      "Epoch 156/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 316.9378 - val_loss: 900.2340\n",
      "Epoch 157/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 310.3230 - val_loss: 900.9774\n",
      "Epoch 158/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 303.8770 - val_loss: 901.8062\n",
      "Epoch 159/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 297.5965 - val_loss: 902.7180\n",
      "Epoch 160/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 291.4782 - val_loss: 903.7100\n",
      "Epoch 161/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 285.5190 - val_loss: 904.7791\n",
      "Epoch 162/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 279.7159 - val_loss: 905.9232\n",
      "Epoch 163/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 274.0656 - val_loss: 907.1394\n",
      "Epoch 164/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 268.5654 - val_loss: 908.4251\n",
      "Epoch 165/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 263.2122 - val_loss: 909.7778\n",
      "Epoch 166/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 258.0028 - val_loss: 911.1949\n",
      "Epoch 167/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 252.9348 - val_loss: 912.6739\n",
      "Epoch 168/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 248.0050 - val_loss: 914.2124\n",
      "Epoch 169/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 243.2105 - val_loss: 915.8078\n",
      "Epoch 170/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 238.5488 - val_loss: 917.4579\n",
      "Epoch 171/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 234.0172 - val_loss: 919.1602\n",
      "Epoch 172/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 229.6129 - val_loss: 920.9122\n",
      "Epoch 173/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 225.3332 - val_loss: 922.7121\n",
      "Epoch 174/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 221.1753 - val_loss: 924.5569\n",
      "Epoch 175/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 217.1370 - val_loss: 926.4451\n",
      "Epoch 176/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 213.2154 - val_loss: 928.3741\n",
      "Epoch 177/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 209.4081 - val_loss: 930.3416\n",
      "Epoch 178/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 205.7125 - val_loss: 932.3458\n",
      "Epoch 179/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 202.1263 - val_loss: 934.3842\n",
      "Epoch 180/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 198.6470 - val_loss: 936.4551\n",
      "Epoch 181/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 195.2722 - val_loss: 938.5562\n",
      "Epoch 182/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 191.9993 - val_loss: 940.6855\n",
      "Epoch 183/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 188.8264 - val_loss: 942.8411\n",
      "Epoch 184/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 185.7509 - val_loss: 945.0212\n",
      "Epoch 185/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 182.7706 - val_loss: 947.2233\n",
      "Epoch 186/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 179.8834 - val_loss: 949.4462\n",
      "Epoch 187/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 177.0867 - val_loss: 951.6876\n",
      "Epoch 188/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 174.3788 - val_loss: 953.9460\n",
      "Epoch 189/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 171.7571 - val_loss: 956.2194\n",
      "Epoch 190/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 169.2196 - val_loss: 958.5062\n",
      "Epoch 191/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 166.7645 - val_loss: 960.8041\n",
      "Epoch 192/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 164.3896 - val_loss: 963.1125\n",
      "Epoch 193/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 162.0928 - val_loss: 965.4287\n",
      "Epoch 194/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 159.8722 - val_loss: 967.7520\n",
      "Epoch 195/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 157.7256 - val_loss: 970.0801\n",
      "Epoch 196/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 155.6512 - val_loss: 972.4120\n",
      "Epoch 197/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 153.6472 - val_loss: 974.7460\n",
      "Epoch 198/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 151.7116 - val_loss: 977.0806\n",
      "Epoch 199/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 149.8427 - val_loss: 979.4141\n",
      "Epoch 200/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 148.0387 - val_loss: 981.7455\n",
      "Epoch 201/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 146.2975 - val_loss: 984.0735\n",
      "Epoch 202/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 144.6177 - val_loss: 986.3967\n",
      "Epoch 203/500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 142.9974 - val_loss: 988.7135\n",
      "Epoch 204/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 141.4350 - val_loss: 991.0231\n",
      "Epoch 205/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 139.9288 - val_loss: 993.3238\n",
      "Epoch 206/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 138.4772 - val_loss: 995.6149\n",
      "Epoch 207/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 137.0787 - val_loss: 997.8951\n",
      "Epoch 208/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 135.7315 - val_loss: 1000.1631\n",
      "Epoch 209/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 134.4343 - val_loss: 1002.4184\n",
      "Epoch 210/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 133.1854 - val_loss: 1004.6596\n",
      "Epoch 211/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 131.9834 - val_loss: 1006.8853\n",
      "Epoch 212/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 130.8270 - val_loss: 1009.0950\n",
      "Epoch 213/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 129.7145 - val_loss: 1011.2880\n",
      "Epoch 214/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 128.6448 - val_loss: 1013.4632\n",
      "Epoch 215/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 127.6163 - val_loss: 1015.6195\n",
      "Epoch 216/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 126.6280 - val_loss: 1017.7562\n",
      "Epoch 217/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 125.6783 - val_loss: 1019.8727\n",
      "Epoch 218/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 124.7661 - val_loss: 1021.9684\n",
      "Epoch 219/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 123.8900 - val_loss: 1024.0425\n",
      "Epoch 220/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 123.0490 - val_loss: 1026.0942\n",
      "Epoch 221/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 122.2417 - val_loss: 1028.1229\n",
      "Epoch 222/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 121.4671 - val_loss: 1030.1283\n",
      "Epoch 223/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 120.7240 - val_loss: 1032.1095\n",
      "Epoch 224/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 120.0113 - val_loss: 1034.0662\n",
      "Epoch 225/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 119.3280 - val_loss: 1035.9977\n",
      "Epoch 226/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 118.6731 - val_loss: 1037.9034\n",
      "Epoch 227/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 118.0456 - val_loss: 1039.7833\n",
      "Epoch 228/500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 117.4444 - val_loss: 1041.6367\n",
      "Epoch 229/500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 116.8685 - val_loss: 1043.4634\n",
      "Epoch 230/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 116.3170 - val_loss: 1045.2629\n",
      "Epoch 231/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 115.7892 - val_loss: 1047.0354\n",
      "Epoch 232/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 115.2841 - val_loss: 1048.7798\n",
      "Epoch 233/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 114.8007 - val_loss: 1050.4967\n",
      "Epoch 234/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 114.3383 - val_loss: 1052.1858\n",
      "Epoch 235/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 113.8960 - val_loss: 1053.8462\n",
      "Epoch 236/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 113.4732 - val_loss: 1055.4783\n",
      "Epoch 237/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 113.0690 - val_loss: 1057.0813\n",
      "Epoch 238/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 112.6827 - val_loss: 1058.6562\n",
      "Epoch 239/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 112.3137 - val_loss: 1060.2026\n",
      "Epoch 240/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 111.9611 - val_loss: 1061.7200\n",
      "Epoch 241/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 111.6243 - val_loss: 1063.2087\n",
      "Epoch 242/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 111.3028 - val_loss: 1064.6686\n",
      "Epoch 243/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.9958 - val_loss: 1066.0996\n",
      "Epoch 244/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.7028 - val_loss: 1067.5021\n",
      "Epoch 245/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.4232 - val_loss: 1068.8761\n",
      "Epoch 246/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.1563 - val_loss: 1070.2212\n",
      "Epoch 247/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 109.9019 - val_loss: 1071.5380\n",
      "Epoch 248/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 109.6591 - val_loss: 1072.8268\n",
      "Epoch 249/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 109.4277 - val_loss: 1074.0870\n",
      "Epoch 250/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 109.2070 - val_loss: 1075.3192\n",
      "Epoch 251/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 108.9966 - val_loss: 1076.5240\n",
      "Epoch 252/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 108.7961 - val_loss: 1077.7009\n",
      "Epoch 253/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 108.6050 - val_loss: 1078.8506\n",
      "Epoch 254/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 108.4230 - val_loss: 1079.9733\n",
      "Epoch 255/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 108.2494 - val_loss: 1081.0690\n",
      "Epoch 256/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 108.0842 - val_loss: 1082.1378\n",
      "Epoch 257/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.9268 - val_loss: 1083.1807\n",
      "Epoch 258/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.7769 - val_loss: 1084.1971\n",
      "Epoch 259/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.6342 - val_loss: 1085.1881\n",
      "Epoch 260/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.4983 - val_loss: 1086.1539\n",
      "Epoch 261/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.3689 - val_loss: 1087.0940\n",
      "Epoch 262/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 107.2457 - val_loss: 1088.0104\n",
      "Epoch 263/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 107.1284 - val_loss: 1088.9011\n",
      "Epoch 264/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.0169 - val_loss: 1089.7683\n",
      "Epoch 265/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.9106 - val_loss: 1090.6118\n",
      "Epoch 266/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.8096 - val_loss: 1091.4320\n",
      "Epoch 267/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.7133 - val_loss: 1092.2294\n",
      "Epoch 268/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.6218 - val_loss: 1093.0040\n",
      "Epoch 269/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.5347 - val_loss: 1093.7567\n",
      "Epoch 270/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.4518 - val_loss: 1094.4877\n",
      "Epoch 271/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.3729 - val_loss: 1095.1973\n",
      "Epoch 272/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.2979 - val_loss: 1095.8859\n",
      "Epoch 273/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.2264 - val_loss: 1096.5540\n",
      "Epoch 274/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.1585 - val_loss: 1097.2014\n",
      "Epoch 275/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.0939 - val_loss: 1097.8293\n",
      "Epoch 276/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.0324 - val_loss: 1098.4384\n",
      "Epoch 277/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.9739 - val_loss: 1099.0276\n",
      "Epoch 278/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.9183 - val_loss: 1099.5985\n",
      "Epoch 279/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 105.8653 - val_loss: 1100.1514\n",
      "Epoch 280/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 105.8149 - val_loss: 1100.6860\n",
      "Epoch 281/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 105.7670 - val_loss: 1101.2035\n",
      "Epoch 282/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 105.7214 - val_loss: 1101.7037\n",
      "Epoch 283/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 105.6781 - val_loss: 1102.1874\n",
      "Epoch 284/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.6369 - val_loss: 1102.6558\n",
      "Epoch 285/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.5976 - val_loss: 1103.1078\n",
      "Epoch 286/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.5603 - val_loss: 1103.5442\n",
      "Epoch 287/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.5247 - val_loss: 1103.9661\n",
      "Epoch 288/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.4910 - val_loss: 1104.3730\n",
      "Epoch 289/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.4588 - val_loss: 1104.7659\n",
      "Epoch 290/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.4282 - val_loss: 1105.1449\n",
      "Epoch 291/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.3991 - val_loss: 1105.5101\n",
      "Epoch 292/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.3714 - val_loss: 1105.8625\n",
      "Epoch 293/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.3451 - val_loss: 1106.2020\n",
      "Epoch 294/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.3199 - val_loss: 1106.5295\n",
      "Epoch 295/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.2961 - val_loss: 1106.8446\n",
      "Epoch 296/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.2734 - val_loss: 1107.1481\n",
      "Epoch 297/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.2518 - val_loss: 1107.4404\n",
      "Epoch 298/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.2312 - val_loss: 1107.7212\n",
      "Epoch 299/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.2117 - val_loss: 1107.9916\n",
      "Epoch 300/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.1931 - val_loss: 1108.2516\n",
      "Epoch 301/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.1754 - val_loss: 1108.5016\n",
      "Epoch 302/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.1585 - val_loss: 1108.7417\n",
      "Epoch 303/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.1426 - val_loss: 1108.9728\n",
      "Epoch 304/500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 105.1273 - val_loss: 1109.1948\n",
      "Epoch 305/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 105.1128 - val_loss: 1109.4080\n",
      "Epoch 306/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.0990 - val_loss: 1109.6123\n",
      "Epoch 307/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.0859 - val_loss: 1109.8088\n",
      "Epoch 308/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.0734 - val_loss: 1109.9967\n",
      "Epoch 309/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.0616 - val_loss: 1110.1777\n",
      "Epoch 310/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.0502 - val_loss: 1110.3511\n",
      "Epoch 311/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.0394 - val_loss: 1110.5172\n",
      "Epoch 312/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 105.0292 - val_loss: 1110.6760\n",
      "Epoch 313/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 105.0196 - val_loss: 1110.8287\n",
      "Epoch 314/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 105.0103 - val_loss: 1110.9749\n",
      "Epoch 315/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.0015 - val_loss: 1111.1147\n",
      "Epoch 316/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.9932 - val_loss: 1111.2489\n",
      "Epoch 317/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.9853 - val_loss: 1111.3771\n",
      "Epoch 318/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.9777 - val_loss: 1111.5000\n",
      "Epoch 319/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.9705 - val_loss: 1111.6168\n",
      "Epoch 320/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.9637 - val_loss: 1111.7290\n",
      "Epoch 321/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 104.9573 - val_loss: 1111.8363\n",
      "Epoch 322/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.9512 - val_loss: 1111.9387\n",
      "Epoch 323/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.9453 - val_loss: 1112.0363\n",
      "Epoch 324/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.9398 - val_loss: 1112.1299\n",
      "Epoch 325/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.9346 - val_loss: 1112.2194\n",
      "Epoch 326/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.9296 - val_loss: 1112.3044\n",
      "Epoch 327/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.9249 - val_loss: 1112.3860\n",
      "Epoch 328/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.9204 - val_loss: 1112.4640\n",
      "Epoch 329/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 104.9162 - val_loss: 1112.5378\n",
      "Epoch 330/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.9121 - val_loss: 1112.6088\n",
      "Epoch 331/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.9083 - val_loss: 1112.6759\n",
      "Epoch 332/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.9046 - val_loss: 1112.7402\n",
      "Epoch 333/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.9012 - val_loss: 1112.8013\n",
      "Epoch 334/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8979 - val_loss: 1112.8595\n",
      "Epoch 335/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8949 - val_loss: 1112.9152\n",
      "Epoch 336/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8920 - val_loss: 1112.9679\n",
      "Epoch 337/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8892 - val_loss: 1113.0183\n",
      "Epoch 338/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8866 - val_loss: 1113.0660\n",
      "Epoch 339/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8841 - val_loss: 1113.1113\n",
      "Epoch 340/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8819 - val_loss: 1113.1549\n",
      "Epoch 341/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8796 - val_loss: 1113.1959\n",
      "Epoch 342/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8776 - val_loss: 1113.2352\n",
      "Epoch 343/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8756 - val_loss: 1113.2726\n",
      "Epoch 344/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8738 - val_loss: 1113.3081\n",
      "Epoch 345/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8720 - val_loss: 1113.3419\n",
      "Epoch 346/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8704 - val_loss: 1113.3741\n",
      "Epoch 347/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8688 - val_loss: 1113.4043\n",
      "Epoch 348/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8674 - val_loss: 1113.4332\n",
      "Epoch 349/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8660 - val_loss: 1113.4606\n",
      "Epoch 350/500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 104.8647 - val_loss: 1113.4863\n",
      "Epoch 351/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8635 - val_loss: 1113.5112\n",
      "Epoch 352/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8624 - val_loss: 1113.5344\n",
      "Epoch 353/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8613 - val_loss: 1113.5566\n",
      "Epoch 354/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8603 - val_loss: 1113.5774\n",
      "Epoch 355/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8594 - val_loss: 1113.5975\n",
      "Epoch 356/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8585 - val_loss: 1113.6163\n",
      "Epoch 357/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8577 - val_loss: 1113.6342\n",
      "Epoch 358/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8569 - val_loss: 1113.6511\n",
      "Epoch 359/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8562 - val_loss: 1113.6669\n",
      "Epoch 360/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8555 - val_loss: 1113.6821\n",
      "Epoch 361/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8549 - val_loss: 1113.6963\n",
      "Epoch 362/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8544 - val_loss: 1113.7101\n",
      "Epoch 363/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8538 - val_loss: 1113.7230\n",
      "Epoch 364/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8533 - val_loss: 1113.7350\n",
      "Epoch 365/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8529 - val_loss: 1113.7463\n",
      "Epoch 366/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8524 - val_loss: 1113.7572\n",
      "Epoch 367/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8520 - val_loss: 1113.7672\n",
      "Epoch 368/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8517 - val_loss: 1113.7773\n",
      "Epoch 369/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8514 - val_loss: 1113.7864\n",
      "Epoch 370/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8510 - val_loss: 1113.7950\n",
      "Epoch 371/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8508 - val_loss: 1113.8029\n",
      "Epoch 372/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 104.8505 - val_loss: 1113.8107\n",
      "Epoch 373/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 104.8503 - val_loss: 1113.8184\n",
      "Epoch 374/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 104.8501 - val_loss: 1113.8256\n",
      "Epoch 375/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8499 - val_loss: 1113.8322\n",
      "Epoch 376/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8497 - val_loss: 1113.8379\n",
      "Epoch 377/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8495 - val_loss: 1113.8438\n",
      "Epoch 378/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8494 - val_loss: 1113.8489\n",
      "Epoch 379/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8494 - val_loss: 1113.8540\n",
      "Epoch 380/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8493 - val_loss: 1113.8593\n",
      "Epoch 381/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8492 - val_loss: 1113.8640\n",
      "Epoch 382/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8491 - val_loss: 1113.8682\n",
      "Epoch 383/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8491 - val_loss: 1113.8727\n",
      "Epoch 384/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8490 - val_loss: 1113.8765\n",
      "Epoch 385/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8490 - val_loss: 1113.8799\n",
      "Epoch 386/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8489 - val_loss: 1113.8835\n",
      "Epoch 387/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8489 - val_loss: 1113.8871\n",
      "Epoch 388/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8489 - val_loss: 1113.8905\n",
      "Epoch 389/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8488 - val_loss: 1113.8931\n",
      "Epoch 390/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8489 - val_loss: 1113.8956\n",
      "Epoch 391/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8489 - val_loss: 1113.8983\n",
      "Epoch 392/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8489 - val_loss: 1113.9009\n",
      "Epoch 393/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8489 - val_loss: 1113.9031\n",
      "Epoch 394/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8490 - val_loss: 1113.9054\n",
      "Epoch 395/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8490 - val_loss: 1113.9073\n",
      "Epoch 396/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8490 - val_loss: 1113.9093\n",
      "Epoch 397/500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 104.8491 - val_loss: 1113.9113\n",
      "Epoch 398/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 104.8491 - val_loss: 1113.9127\n",
      "Epoch 399/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8492 - val_loss: 1113.9146\n",
      "Epoch 400/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8492 - val_loss: 1113.9158\n",
      "Epoch 401/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8493 - val_loss: 1113.9174\n",
      "Epoch 402/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8494 - val_loss: 1113.9187\n",
      "Epoch 403/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8494 - val_loss: 1113.9199\n",
      "Epoch 404/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8495 - val_loss: 1113.9210\n",
      "Epoch 405/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8496 - val_loss: 1113.9221\n",
      "Epoch 406/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8496 - val_loss: 1113.9235\n",
      "Epoch 407/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8497 - val_loss: 1113.9241\n",
      "Epoch 408/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8498 - val_loss: 1113.9248\n",
      "Epoch 409/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8499 - val_loss: 1113.9260\n",
      "Epoch 410/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8500 - val_loss: 1113.9265\n",
      "Epoch 411/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8500 - val_loss: 1113.9274\n",
      "Epoch 412/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8501 - val_loss: 1113.9279\n",
      "Epoch 413/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8502 - val_loss: 1113.9283\n",
      "Epoch 414/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8503 - val_loss: 1113.9291\n",
      "Epoch 415/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8504 - val_loss: 1113.9297\n",
      "Epoch 416/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8505 - val_loss: 1113.9299\n",
      "Epoch 417/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 104.8506 - val_loss: 1113.9303\n",
      "Epoch 418/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8507 - val_loss: 1113.9310\n",
      "Epoch 419/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8508 - val_loss: 1113.9315\n",
      "Epoch 420/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8509 - val_loss: 1113.9321\n",
      "Epoch 421/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8510 - val_loss: 1113.9326\n",
      "Epoch 422/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8510 - val_loss: 1113.9330\n",
      "Epoch 423/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8511 - val_loss: 1113.9340\n",
      "Epoch 424/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8512 - val_loss: 1113.9342\n",
      "Epoch 425/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8512 - val_loss: 1113.9343\n",
      "Epoch 426/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8513 - val_loss: 1113.9347\n",
      "Epoch 427/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8514 - val_loss: 1113.9351\n",
      "Epoch 428/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8515 - val_loss: 1113.9351\n",
      "Epoch 429/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8516 - val_loss: 1113.9355\n",
      "Epoch 430/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8517 - val_loss: 1113.9359\n",
      "Epoch 431/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8517 - val_loss: 1113.9357\n",
      "Epoch 432/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8518 - val_loss: 1113.9364\n",
      "Epoch 433/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8519 - val_loss: 1113.9364\n",
      "Epoch 434/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8520 - val_loss: 1113.9364\n",
      "Epoch 435/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8520 - val_loss: 1113.9366\n",
      "Epoch 436/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8521 - val_loss: 1113.9370\n",
      "Epoch 437/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8522 - val_loss: 1113.9371\n",
      "Epoch 438/500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 104.8523 - val_loss: 1113.9370\n",
      "Epoch 439/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8524 - val_loss: 1113.9371\n",
      "Epoch 440/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8524 - val_loss: 1113.9369\n",
      "Epoch 441/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8525 - val_loss: 1113.9370\n",
      "Epoch 442/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8526 - val_loss: 1113.9370\n",
      "Epoch 443/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8527 - val_loss: 1113.9375\n",
      "Epoch 444/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8527 - val_loss: 1113.9374\n",
      "Epoch 445/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8529 - val_loss: 1113.9375\n",
      "Epoch 446/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8529 - val_loss: 1113.9374\n",
      "Epoch 447/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8530 - val_loss: 1113.9375\n",
      "Epoch 448/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8530 - val_loss: 1113.9375\n",
      "Epoch 449/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8531 - val_loss: 1113.9375\n",
      "Epoch 450/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8532 - val_loss: 1113.9375\n",
      "Epoch 451/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 104.8533 - val_loss: 1113.9375\n",
      "Epoch 452/500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 104.8533 - val_loss: 1113.9377\n",
      "Epoch 453/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 104.8534 - val_loss: 1113.9380\n",
      "Epoch 454/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8535 - val_loss: 1113.9376\n",
      "Epoch 455/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8536 - val_loss: 1113.9376\n",
      "Epoch 456/500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 104.8536 - val_loss: 1113.9377\n",
      "Epoch 457/500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 104.8537 - val_loss: 1113.9377\n",
      "Epoch 458/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8538 - val_loss: 1113.9377\n",
      "Epoch 459/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8538 - val_loss: 1113.9377\n",
      "Epoch 460/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8539 - val_loss: 1113.9377\n",
      "Epoch 461/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8539 - val_loss: 1113.9381\n",
      "Epoch 462/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8539 - val_loss: 1113.9381\n",
      "Epoch 463/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8540 - val_loss: 1113.9382\n",
      "Epoch 464/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8541 - val_loss: 1113.9385\n",
      "Epoch 465/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8541 - val_loss: 1113.9380\n",
      "Epoch 466/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8542 - val_loss: 1113.9382\n",
      "Epoch 467/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8542 - val_loss: 1113.9385\n",
      "Epoch 468/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8542 - val_loss: 1113.9385\n",
      "Epoch 469/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8543 - val_loss: 1113.9386\n",
      "Epoch 470/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8544 - val_loss: 1113.9390\n",
      "Epoch 471/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8543 - val_loss: 1113.9386\n",
      "Epoch 472/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8545 - val_loss: 1113.9386\n",
      "Epoch 473/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8545 - val_loss: 1113.9388\n",
      "Epoch 474/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8545 - val_loss: 1113.9388\n",
      "Epoch 475/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8546 - val_loss: 1113.9393\n",
      "Epoch 476/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8546 - val_loss: 1113.9392\n",
      "Epoch 477/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8547 - val_loss: 1113.9388\n",
      "Epoch 478/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8547 - val_loss: 1113.9390\n",
      "Epoch 479/500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 104.8548 - val_loss: 1113.9393\n",
      "Epoch 480/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 104.8548 - val_loss: 1113.9393\n",
      "Epoch 481/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8548 - val_loss: 1113.9393\n",
      "Epoch 482/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8549 - val_loss: 1113.9393\n",
      "Epoch 483/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8549 - val_loss: 1113.9392\n",
      "Epoch 484/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8550 - val_loss: 1113.9395\n",
      "Epoch 485/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8550 - val_loss: 1113.9395\n",
      "Epoch 486/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8550 - val_loss: 1113.9395\n",
      "Epoch 487/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8551 - val_loss: 1113.9397\n",
      "Epoch 488/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8551 - val_loss: 1113.9397\n",
      "Epoch 489/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8551 - val_loss: 1113.9395\n",
      "Epoch 490/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8552 - val_loss: 1113.9392\n",
      "Epoch 491/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8553 - val_loss: 1113.9393\n",
      "Epoch 492/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8553 - val_loss: 1113.9395\n",
      "Epoch 493/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8553 - val_loss: 1113.9395\n",
      "Epoch 494/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8554 - val_loss: 1113.9395\n",
      "Epoch 495/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8554 - val_loss: 1113.9399\n",
      "Epoch 496/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8554 - val_loss: 1113.9402\n",
      "Epoch 497/500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 104.8554 - val_loss: 1113.9402\n",
      "Epoch 498/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 104.8554 - val_loss: 1113.9402\n",
      "Epoch 499/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8555 - val_loss: 1113.9404\n",
      "Epoch 500/500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 104.8555 - val_loss: 1113.9404\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 481ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.06105742e+01, 7.05853642e+01, 7.05601541e+01, 7.05349440e+01,\n",
       "        7.05097339e+01, 7.04845238e+01, 7.04593137e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        9.55886240e-01, 7.15584034e+01, 7.14071429e+01, 7.12558823e+01,\n",
       "        7.11046219e+01, 7.09533613e+01, 7.08021008e+01, 7.06918067e+01,\n",
       "        7.06665966e+01, 7.06413866e+01, 7.06161765e+01, 7.05909664e+01,\n",
       "        7.05657563e+01, 7.05405462e+01, 7.05153361e+01, 7.04901261e+01,\n",
       "        7.04649160e+01, 7.04397059e+01, 7.04144958e+01, 7.03892857e+01,\n",
       "        7.03640756e+01, 7.03388655e+01, 7.03136555e+01, 7.02884454e+01,\n",
       "        7.02632353e+01, 7.02380252e+01, 7.02128151e+01, 7.01876050e+01,\n",
       "        3.27307880e-01, 8.42299700e-01, 0.00000000e+00, 3.95751450e-02,\n",
       "        2.30693817e-01, 7.03150560e-02, 0.00000000e+00, 7.05461485e+01,\n",
       "        7.05209384e+01, 7.04957283e+01, 7.04705182e+01, 7.04453081e+01,\n",
       "        7.04200980e+01, 7.03948880e+01, 7.03696779e+01, 7.03444678e+01,\n",
       "        7.03192577e+01, 7.02940476e+01, 7.02688375e+01, 7.02436275e+01,\n",
       "        7.02184174e+01, 7.01932073e+01, 7.42882820e+01, 7.40361811e+01,\n",
       "        7.36761204e+01, 7.32979692e+01, 7.29198179e+01, 7.25416667e+01,\n",
       "        7.20962185e+01, 7.16424370e+01, 7.11886555e+01, 0.00000000e+00,\n",
       "        2.80094090e-01, 7.11075211e+01, 4.29049370e-01, 0.00000000e+00,\n",
       "        4.39326410e-01, 0.00000000e+00, 0.00000000e+00, 3.17974810e-01,\n",
       "        6.88514404e+01, 4.78183292e-02, 3.42982888e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.95476113e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.57392964e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.89780742e-01, 6.43500507e-01, 0.00000000e+00, 2.00733528e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64.37878151, 64.37037815, 64.36197479, 64.35357143, 64.34516807,\n",
       "       64.33676471, 64.32836134, 64.31995798, 64.31155462, 64.30315126,\n",
       "       64.2947479 , 64.28634454, 64.27794118, 64.26953782, 64.26113445,\n",
       "       64.25273109, 64.24432773, 64.23592437, 64.22752101, 64.21911765,\n",
       "       64.21071429, 64.20231092, 64.19390756, 64.1855042 , 64.17710084,\n",
       "       64.16869748, 64.16029412, 64.15189076, 64.14348739, 64.13508403,\n",
       "       64.12668067, 64.11827731, 64.10987395, 64.10147059, 64.09306723,\n",
       "       64.08466387, 64.0762605 , 64.06785714, 64.05945378, 64.05105042,\n",
       "       64.04264706, 64.0342437 , 64.02584034, 64.01743697, 64.00903361,\n",
       "       64.00063025, 63.99222689, 63.98382353, 63.97542017, 63.96701681,\n",
       "       63.95861345, 63.95021008, 63.94180672, 63.93340336, 63.925     ,\n",
       "       63.91659664, 63.90819328, 63.89978992, 63.89138655, 63.88298319,\n",
       "       63.87457983, 63.86617647, 63.85777311, 63.84936975, 63.84096639,\n",
       "       63.83256303, 63.82415966, 63.8157563 , 63.80735294, 63.79749066,\n",
       "       63.77741597, 63.75734127, 63.73726657, 63.71719188, 63.69711718,\n",
       "       63.67704248, 63.65696779, 63.63689309, 63.61681839, 63.5967437 ,\n",
       "       63.576669  , 63.5565943 , 63.53651961, 63.51644491, 63.49637021,\n",
       "       63.47629552, 63.45622082, 63.43614613, 63.41607143, 63.39599673,\n",
       "       63.37592204, 63.35584734, 63.33577264, 63.31569795, 63.29562325,\n",
       "       63.27554855, 63.25547386, 63.23539916, 63.21532446, 63.19524977])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.54331423914485\n",
      "29.49766958322913\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
