{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2495    67.025142\n",
       "2496    67.018856\n",
       "2497    67.012571\n",
       "2498    67.006285\n",
       "2499    67.000000\n",
       "Name: C3, Length: 2500, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_2450_50.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2445     0.000000\n",
       "2446     0.000000\n",
       "2447     0.795728\n",
       "2448     0.000000\n",
       "2449     0.000000\n",
       "Name: C3, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(50)\n",
    "test\n",
    "training_set = training_set.head(2450)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-175)  var1(t-174)  var1(t-173)  var1(t-172)  var1(t-171)  \\\n",
      "175    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "176    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "177    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "178    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "179    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-170)  var1(t-169)  var1(t-168)  var1(t-167)  var1(t-166)  ...  \\\n",
      "175    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "176    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "177    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "178    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "179    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+45)  var2(t+45)  var1(t+46)  var2(t+46)  var1(t+47)  var2(t+47)  \\\n",
      "175   83.735014    0.000280   83.723810    0.000280   83.712605    0.000280   \n",
      "176   83.723810    0.000280   83.712605    0.000280   83.701401    0.000280   \n",
      "177   83.712605    0.000280   83.701401    0.000280   83.690196    0.000279   \n",
      "178   83.701401    0.000280   83.690196    0.000279   83.678992    0.000279   \n",
      "179   83.690196    0.000279   83.678992    0.000279   83.667787    0.000279   \n",
      "\n",
      "     var1(t+48)  var2(t+48)  var1(t+49)  var2(t+49)  \n",
      "175   83.701401    0.000280   83.690196    0.000279  \n",
      "176   83.690196    0.000279   83.678992    0.000279  \n",
      "177   83.678992    0.000279   83.667787    0.000279  \n",
      "178   83.667787    0.000279   83.656583    0.000279  \n",
      "179   83.656583    0.000279   83.645378    0.000279  \n",
      "\n",
      "[5 rows x 276 columns]\n",
      "Index(['var1(t-175)', 'var1(t-174)', 'var1(t-173)', 'var1(t-172)',\n",
      "       'var1(t-171)', 'var1(t-170)', 'var1(t-169)', 'var1(t-168)',\n",
      "       'var1(t-167)', 'var1(t-166)',\n",
      "       ...\n",
      "       'var1(t+45)', 'var2(t+45)', 'var1(t+46)', 'var2(t+46)', 'var1(t+47)',\n",
      "       'var2(t+47)', 'var1(t+48)', 'var2(t+48)', 'var1(t+49)', 'var2(t+49)'],\n",
      "      dtype='object', length=276)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 175, n_out = 50)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 176):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-150:]\n",
    "trainX = train[:,:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-150:]\n",
    "forecastX = forecast[:,:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 1, 126) (2225, 150) (1, 1, 126)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28/28 [==============================] - 4s 37ms/step - loss: 5361.7383 - val_loss: 2617.2651\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 5051.7866 - val_loss: 2470.4834\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 4813.8647 - val_loss: 2357.5527\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4621.6318 - val_loss: 2272.6821\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4439.1255 - val_loss: 2194.6655\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 4280.3501 - val_loss: 2122.7439\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 4124.0425 - val_loss: 2058.6050\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 3981.7561 - val_loss: 1997.1621\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 3845.4358 - val_loss: 1938.1764\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 3714.3987 - val_loss: 1881.7301\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 3646.5339 - val_loss: 1846.2003\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 3486.8079 - val_loss: 1785.1630\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 3353.9231 - val_loss: 1738.7257\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 3241.6382 - val_loss: 1695.2056\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 3130.7673 - val_loss: 1652.4274\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 3025.0552 - val_loss: 1615.7649\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2923.0872 - val_loss: 1576.7743\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 2821.3206 - val_loss: 1540.6857\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 2727.6047 - val_loss: 1511.0039\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 2629.3240 - val_loss: 1470.7587\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 2538.1321 - val_loss: 1434.6699\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 2437.6038 - val_loss: 1404.7329\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 2345.9072 - val_loss: 1373.2004\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2257.8347 - val_loss: 1349.5146\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2174.0984 - val_loss: 1316.4857\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2090.5432 - val_loss: 1284.3451\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2012.9518 - val_loss: 1262.3408\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1936.7814 - val_loss: 1236.2307\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1865.5134 - val_loss: 1218.0226\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1796.0640 - val_loss: 1198.3678\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1727.3800 - val_loss: 1178.9103\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1664.9374 - val_loss: 1170.3717\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1630.7345 - val_loss: 1169.7140\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1535.2202 - val_loss: 1165.3379\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1473.0776 - val_loss: 1152.5865\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1411.4543 - val_loss: 1124.2708\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1400.1854 - val_loss: 1109.1074\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1353.4227 - val_loss: 1131.2986\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1300.2755 - val_loss: 1117.2787\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1256.1345 - val_loss: 1128.7800\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1246.0278 - val_loss: 1115.7972\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1182.4899 - val_loss: 1179.1913\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1131.1617 - val_loss: 1166.3568\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1088.4359 - val_loss: 1170.7930\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1048.4991 - val_loss: 1162.6975\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1009.1869 - val_loss: 1162.7109\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 973.3950 - val_loss: 1160.3099\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 942.2634 - val_loss: 1173.6481\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 930.1666 - val_loss: 1182.5793\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 881.7753 - val_loss: 1178.9677\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 919.0895 - val_loss: 1187.9727\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 823.2524 - val_loss: 1202.8636\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 794.0994 - val_loss: 1198.3501\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 808.6402 - val_loss: 1183.4565\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 792.5722 - val_loss: 1213.5663\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 782.1061 - val_loss: 1218.7378\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 697.3806 - val_loss: 1213.9061\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 707.5316 - val_loss: 1243.4047\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 662.9590 - val_loss: 1273.6527\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 638.0526 - val_loss: 1241.7229\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 622.5655 - val_loss: 1277.3966\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 631.5612 - val_loss: 1247.0155\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 661.2929 - val_loss: 1285.6823\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 607.9227 - val_loss: 1308.1084\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 611.3332 - val_loss: 1306.3707\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 555.6535 - val_loss: 1336.6808\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 621.5094 - val_loss: 1305.0875\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 581.1205 - val_loss: 1315.6646\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 547.1385 - val_loss: 1382.2361\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 507.1657 - val_loss: 1413.5597\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 499.6325 - val_loss: 1425.8126\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 486.2361 - val_loss: 1384.4047\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 497.7015 - val_loss: 1366.7632\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 481.3134 - val_loss: 1361.2410\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 522.3405 - val_loss: 1328.2366\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 532.3289 - val_loss: 1322.3372\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 461.3899 - val_loss: 1321.6835\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 483.6035 - val_loss: 1347.8665\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 464.3617 - val_loss: 1319.2787\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 530.5369 - val_loss: 1359.9590\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 529.7563 - val_loss: 1419.7136\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 479.6440 - val_loss: 1454.3160\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 487.5198 - val_loss: 1465.1670\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 446.5134 - val_loss: 1394.9315\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 509.1952 - val_loss: 1355.5530\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 484.3748 - val_loss: 1351.7443\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 490.6880 - val_loss: 1398.3424\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 472.4231 - val_loss: 1414.8464\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 424.7623 - val_loss: 1518.3127\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 411.3016 - val_loss: 1534.8344\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 405.5255 - val_loss: 1536.2842\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 398.2961 - val_loss: 1531.6639\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 400.2192 - val_loss: 1566.6896\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 392.0024 - val_loss: 1554.2510\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 408.7045 - val_loss: 1550.6448\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 401.0048 - val_loss: 1554.7944\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 396.3249 - val_loss: 1562.8221\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 392.2642 - val_loss: 1559.8505\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 405.9577 - val_loss: 1558.4586\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 383.4279 - val_loss: 1600.1373\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 365.8596 - val_loss: 1591.8673\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 379.1891 - val_loss: 1598.1285\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 359.4234 - val_loss: 1595.3503\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 367.1125 - val_loss: 1648.3245\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 365.3364 - val_loss: 1656.0315\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 364.4266 - val_loss: 1661.3860\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 362.6973 - val_loss: 1664.0872\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 361.4786 - val_loss: 1671.4652\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 360.3463 - val_loss: 1673.4486\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 359.3174 - val_loss: 1678.8397\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 358.1889 - val_loss: 1677.2094\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 348.7798 - val_loss: 1612.8553\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 383.6279 - val_loss: 1614.7572\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 380.7718 - val_loss: 1636.4009\n",
      "Epoch 115/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 361.8676 - val_loss: 1655.4321\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 356.0703 - val_loss: 1640.8629\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 360.0391 - val_loss: 1662.1173\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 353.7237 - val_loss: 1649.9937\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 356.5540 - val_loss: 1670.1893\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 351.5507 - val_loss: 1659.3879\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 350.3240 - val_loss: 1662.0685\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 349.3294 - val_loss: 1662.0685\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 347.4186 - val_loss: 1659.0475\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 347.6848 - val_loss: 1661.3235\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 346.6832 - val_loss: 1662.3937\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 345.6238 - val_loss: 1662.7843\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 363.9163 - val_loss: 1660.9359\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 361.7013 - val_loss: 1673.7699\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 359.7852 - val_loss: 1676.9894\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 358.4797 - val_loss: 1675.7843\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 339.6552 - val_loss: 1572.8861\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 347.0108 - val_loss: 1574.5596\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 363.8008 - val_loss: 1652.7642\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 358.9872 - val_loss: 1660.0211\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 357.2062 - val_loss: 1667.5286\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 355.8536 - val_loss: 1671.9680\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 354.6168 - val_loss: 1675.7632\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 353.3761 - val_loss: 1676.1691\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 360.6015 - val_loss: 1718.2725\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 349.7127 - val_loss: 1653.5404\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 358.8059 - val_loss: 1634.7571\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 345.6572 - val_loss: 1538.5271\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 367.8126 - val_loss: 1493.8982\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 379.2736 - val_loss: 1465.4653\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 376.0740 - val_loss: 1482.8910\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 367.9035 - val_loss: 1520.6157\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 361.6443 - val_loss: 1525.4639\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 316.2208 - val_loss: 1511.1396\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 312.5516 - val_loss: 1506.6239\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 310.3265 - val_loss: 1513.1069\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 306.6077 - val_loss: 1498.7867\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 304.3778 - val_loss: 1497.5576\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 306.3030 - val_loss: 1420.7202\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 338.3300 - val_loss: 1504.1686\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 332.3163 - val_loss: 1509.0691\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 328.4410 - val_loss: 1511.4553\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 325.9778 - val_loss: 1511.6080\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 321.6012 - val_loss: 1516.2086\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 318.4999 - val_loss: 1521.6910\n",
      "Epoch 160/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 316.3515 - val_loss: 1527.0741\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 313.5403 - val_loss: 1528.6298\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 310.6996 - val_loss: 1521.4242\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 303.4230 - val_loss: 1499.2908\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 301.9362 - val_loss: 1501.2770\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 300.5324 - val_loss: 1504.0001\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 298.8824 - val_loss: 1505.9146\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 297.6131 - val_loss: 1508.1011\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 296.4526 - val_loss: 1508.6869\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 295.3365 - val_loss: 1509.9484\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 294.1632 - val_loss: 1508.4661\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 297.2130 - val_loss: 1508.5557\n",
      "Epoch 172/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 296.1999 - val_loss: 1510.8304\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 295.1677 - val_loss: 1513.0736\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 294.2621 - val_loss: 1513.6910\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 293.3394 - val_loss: 1515.1202\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 292.4203 - val_loss: 1516.6941\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 291.4678 - val_loss: 1518.2327\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 290.6637 - val_loss: 1517.2332\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 290.0386 - val_loss: 1514.5000\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 289.2496 - val_loss: 1513.9801\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 288.4465 - val_loss: 1513.2988\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 287.6305 - val_loss: 1513.0920\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 285.9879 - val_loss: 1504.7712\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 273.8296 - val_loss: 1442.2295\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 309.4275 - val_loss: 1455.2714\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 306.2433 - val_loss: 1471.1000\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 295.3810 - val_loss: 1506.6753\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 287.9145 - val_loss: 1575.2788\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 287.7134 - val_loss: 1566.4207\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 283.8833 - val_loss: 1542.2914\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 279.3481 - val_loss: 1515.5992\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 276.2563 - val_loss: 1503.2139\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 274.8846 - val_loss: 1495.9379\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 277.3221 - val_loss: 1481.5790\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 271.8917 - val_loss: 1478.5305\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 276.6736 - val_loss: 1454.3043\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 285.2605 - val_loss: 1424.3810\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 280.3760 - val_loss: 1400.7603\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 328.0034 - val_loss: 1413.7518\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 316.6584 - val_loss: 1423.4274\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 311.7657 - val_loss: 1421.0948\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 306.9915 - val_loss: 1428.5740\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 303.3289 - val_loss: 1422.7888\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 327.2689 - val_loss: 1426.6632\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 322.0498 - val_loss: 1428.6975\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 318.8684 - val_loss: 1453.5166\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 318.3943 - val_loss: 1470.7792\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 314.6105 - val_loss: 1472.1617\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 311.7681 - val_loss: 1475.4216\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 309.5036 - val_loss: 1482.2394\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 307.1818 - val_loss: 1487.7716\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 305.4304 - val_loss: 1494.8304\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 304.0876 - val_loss: 1500.4801\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 302.5915 - val_loss: 1501.7296\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 301.2351 - val_loss: 1504.8328\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 300.0022 - val_loss: 1506.5605\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 298.8455 - val_loss: 1507.5323\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 297.7217 - val_loss: 1507.3549\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 296.6578 - val_loss: 1508.5801\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 295.4880 - val_loss: 1508.9082\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 301.8492 - val_loss: 1512.9037\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 298.5615 - val_loss: 1516.3972\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 293.4590 - val_loss: 1516.1466\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 292.2464 - val_loss: 1515.1128\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 291.0233 - val_loss: 1513.5100\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 290.1194 - val_loss: 1511.7000\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 291.9245 - val_loss: 1515.5693\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.6985 - val_loss: 1513.2186\n",
      "Epoch 229/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 288.0536 - val_loss: 1508.5699\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 286.9362 - val_loss: 1506.1672\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 286.1138 - val_loss: 1503.8510\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 284.9091 - val_loss: 1469.1445\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 283.2383 - val_loss: 1431.9008\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 284.5967 - val_loss: 1436.1449\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 283.3398 - val_loss: 1439.4551\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 282.1335 - val_loss: 1439.9755\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 296.5437 - val_loss: 1482.6810\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 280.5503 - val_loss: 1447.0569\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 279.5539 - val_loss: 1446.1797\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 278.5533 - val_loss: 1445.8324\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 282.9844 - val_loss: 1467.1624\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 278.3931 - val_loss: 1447.3312\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 275.7010 - val_loss: 1443.9382\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 280.4140 - val_loss: 1469.9507\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 279.0204 - val_loss: 1467.5494\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 277.3942 - val_loss: 1461.0190\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 275.6131 - val_loss: 1451.7719\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.7293 - val_loss: 1523.6654\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 285.6365 - val_loss: 1506.0654\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 280.1142 - val_loss: 1493.8252\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 278.2808 - val_loss: 1484.2227\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.7451 - val_loss: 1473.4381\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 278.7623 - val_loss: 1470.2098\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 272.6901 - val_loss: 1449.1567\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 270.2087 - val_loss: 1440.3761\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 269.3058 - val_loss: 1436.7554\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 268.0558 - val_loss: 1429.1454\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 265.3311 - val_loss: 1421.7012\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 263.6431 - val_loss: 1417.6125\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 262.8661 - val_loss: 1415.4998\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 262.1190 - val_loss: 1413.7797\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 261.3735 - val_loss: 1411.0654\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 260.6339 - val_loss: 1408.5048\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 259.9001 - val_loss: 1406.0857\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 259.1698 - val_loss: 1404.1970\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 258.4375 - val_loss: 1401.3169\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 257.7079 - val_loss: 1398.5493\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 256.9832 - val_loss: 1395.8856\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 256.2625 - val_loss: 1393.4474\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 255.5382 - val_loss: 1390.5540\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 254.8185 - val_loss: 1387.5422\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 254.0677 - val_loss: 1382.1366\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 248.4072 - val_loss: 1361.7034\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 243.3561 - val_loss: 1330.2656\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 245.8359 - val_loss: 1345.0295\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 242.0206 - val_loss: 1308.7048\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 251.1483 - val_loss: 1310.1757\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 250.0680 - val_loss: 1314.5746\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 248.9867 - val_loss: 1316.0641\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 247.9801 - val_loss: 1317.4954\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 247.0308 - val_loss: 1318.6155\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 246.1289 - val_loss: 1319.3635\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 245.2672 - val_loss: 1319.7562\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 244.4368 - val_loss: 1320.8445\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 243.6304 - val_loss: 1320.9877\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 242.8513 - val_loss: 1319.4619\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 242.0857 - val_loss: 1318.0267\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 241.3359 - val_loss: 1310.4821\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 240.6550 - val_loss: 1320.1094\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 239.8868 - val_loss: 1318.4017\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 231.4200 - val_loss: 1247.8352\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 253.8497 - val_loss: 1324.4591\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 260.9080 - val_loss: 1323.1583\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 243.5325 - val_loss: 1272.4730\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 239.3801 - val_loss: 1274.4257\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 237.1638 - val_loss: 1271.2268\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 236.3277 - val_loss: 1273.0365\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 234.8177 - val_loss: 1274.5459\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 233.8742 - val_loss: 1272.0734\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 232.4382 - val_loss: 1263.6821\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 272.7050 - val_loss: 1261.9497\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 269.8734 - val_loss: 1279.5548\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 267.0282 - val_loss: 1275.6418\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 265.2468 - val_loss: 1291.7379\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 252.6208 - val_loss: 1339.8245\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 246.5032 - val_loss: 1367.9469\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 245.3931 - val_loss: 1363.6322\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 241.1570 - val_loss: 1339.9606\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 237.4760 - val_loss: 1324.3352\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 229.0673 - val_loss: 1296.0778\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 223.1573 - val_loss: 1278.9508\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 229.1823 - val_loss: 1308.0455\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 230.0481 - val_loss: 1288.5875\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 217.1490 - val_loss: 1228.5345\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 223.4155 - val_loss: 1257.0927\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 213.6953 - val_loss: 1198.0931\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 276.6568 - val_loss: 1200.7649\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 232.9579 - val_loss: 1271.0840\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 286.1965 - val_loss: 1433.4132\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 307.6703 - val_loss: 1384.1995\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 323.4274 - val_loss: 1361.2377\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 319.2878 - val_loss: 1493.3365\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 300.2137 - val_loss: 1492.1362\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 295.6211 - val_loss: 1474.6617\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 283.7319 - val_loss: 1416.2507\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 238.4221 - val_loss: 1178.0686\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 330.2000 - val_loss: 1234.3003\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 281.1381 - val_loss: 1251.1005\n",
      "Epoch 329/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 259.5742 - val_loss: 1180.4753\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 240.0283 - val_loss: 1253.7787\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 230.1806 - val_loss: 1233.6857\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 223.1051 - val_loss: 1216.0455\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 220.5116 - val_loss: 1196.8376\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 238.6107 - val_loss: 1198.3621\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 226.1751 - val_loss: 1187.3982\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 234.9788 - val_loss: 1182.1342\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 232.4635 - val_loss: 1181.3118\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 223.8799 - val_loss: 1160.1278\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 218.4549 - val_loss: 1162.1559\n",
      "Epoch 340/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 217.8586 - val_loss: 1174.5826\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 206.6162 - val_loss: 1156.9397\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 196.1234 - val_loss: 1171.8821\n",
      "Epoch 343/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 192.4252 - val_loss: 1120.3356\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 217.0374 - val_loss: 1104.4674\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 230.0584 - val_loss: 1151.2563\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 224.6533 - val_loss: 1157.7877\n",
      "Epoch 347/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 223.0658 - val_loss: 1162.1702\n",
      "Epoch 348/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 221.6632 - val_loss: 1167.2921\n",
      "Epoch 349/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 220.4920 - val_loss: 1168.9723\n",
      "Epoch 350/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 219.3939 - val_loss: 1168.8457\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 217.9687 - val_loss: 1161.5895\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 211.6588 - val_loss: 1138.5011\n",
      "Epoch 353/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 212.0480 - val_loss: 1150.8372\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 208.4963 - val_loss: 1149.5901\n",
      "Epoch 355/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 207.0309 - val_loss: 1147.5492\n",
      "Epoch 356/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 204.0749 - val_loss: 1147.0594\n",
      "Epoch 357/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 203.4418 - val_loss: 1146.7170\n",
      "Epoch 358/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 202.7910 - val_loss: 1148.2435\n",
      "Epoch 359/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 202.1022 - val_loss: 1148.5424\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 201.4336 - val_loss: 1148.4281\n",
      "Epoch 361/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 201.0700 - val_loss: 1147.3903\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 200.4749 - val_loss: 1147.6410\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 199.7237 - val_loss: 1146.9974\n",
      "Epoch 364/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 199.2053 - val_loss: 1146.1942\n",
      "Epoch 365/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 198.6747 - val_loss: 1145.2332\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 198.1849 - val_loss: 1144.1814\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 197.6587 - val_loss: 1143.0233\n",
      "Epoch 368/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 197.1779 - val_loss: 1141.7720\n",
      "Epoch 369/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 196.6604 - val_loss: 1140.4482\n",
      "Epoch 370/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 196.1835 - val_loss: 1139.0352\n",
      "Epoch 371/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 195.6761 - val_loss: 1137.5743\n",
      "Epoch 372/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 195.2009 - val_loss: 1135.9722\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 194.6999 - val_loss: 1131.9237\n",
      "Epoch 374/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 192.2251 - val_loss: 1139.0258\n",
      "Epoch 375/500\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 187.1533 - val_loss: 1106.4576\n",
      "Epoch 376/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 180.7564 - val_loss: 1074.5679\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 220.4780 - val_loss: 1063.9653\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 227.1427 - val_loss: 1177.2786\n",
      "Epoch 379/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 197.2284 - val_loss: 1176.0581\n",
      "Epoch 380/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 195.8202 - val_loss: 1164.7559\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 193.3348 - val_loss: 1150.6000\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 192.1379 - val_loss: 1139.3124\n",
      "Epoch 383/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 186.7932 - val_loss: 1088.7175\n",
      "Epoch 384/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 174.8669 - val_loss: 1031.2323\n",
      "Epoch 385/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 196.7022 - val_loss: 1011.7083\n",
      "Epoch 386/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 192.9742 - val_loss: 1003.4901\n",
      "Epoch 387/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 187.6008 - val_loss: 993.9970\n",
      "Epoch 388/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 238.3503 - val_loss: 983.0722\n",
      "Epoch 389/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 230.3228 - val_loss: 996.5341\n",
      "Epoch 390/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 222.3358 - val_loss: 1016.8534\n",
      "Epoch 391/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 215.9837 - val_loss: 1037.4640\n",
      "Epoch 392/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 219.1647 - val_loss: 1155.8965\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 188.0345 - val_loss: 1135.6709\n",
      "Epoch 394/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 184.3835 - val_loss: 1106.8698\n",
      "Epoch 395/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 182.9247 - val_loss: 1099.9718\n",
      "Epoch 396/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 181.8236 - val_loss: 1087.3510\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 179.4161 - val_loss: 1074.1429\n",
      "Epoch 398/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 170.7352 - val_loss: 1046.3511\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 166.7134 - val_loss: 1030.4900\n",
      "Epoch 400/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 166.2263 - val_loss: 1027.3977\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 165.5437 - val_loss: 1026.9691\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 165.1687 - val_loss: 1025.8971\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 164.7743 - val_loss: 1025.9126\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 164.1149 - val_loss: 1024.3208\n",
      "Epoch 405/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 163.5265 - val_loss: 1022.7067\n",
      "Epoch 406/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 163.0569 - val_loss: 1020.9062\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 162.5970 - val_loss: 1019.1985\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 162.1528 - val_loss: 1016.5075\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 161.9713 - val_loss: 1013.0891\n",
      "Epoch 410/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 161.1234 - val_loss: 1011.0797\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 160.8037 - val_loss: 1009.3789\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 160.1070 - val_loss: 1007.3818\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 159.5403 - val_loss: 1006.0003\n",
      "Epoch 414/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 159.0876 - val_loss: 1004.7734\n",
      "Epoch 415/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 158.6217 - val_loss: 1003.5021\n",
      "Epoch 416/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 158.1223 - val_loss: 1002.0891\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 155.8567 - val_loss: 995.5748\n",
      "Epoch 418/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 154.3041 - val_loss: 990.0055\n",
      "Epoch 419/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 154.0549 - val_loss: 988.4866\n",
      "Epoch 420/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 153.3355 - val_loss: 986.8153\n",
      "Epoch 421/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 152.8798 - val_loss: 985.1088\n",
      "Epoch 422/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 152.6638 - val_loss: 982.2653\n",
      "Epoch 423/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 154.6589 - val_loss: 996.1776\n",
      "Epoch 424/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 152.1161 - val_loss: 980.3083\n",
      "Epoch 425/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 151.3761 - val_loss: 978.3810\n",
      "Epoch 426/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 150.5791 - val_loss: 978.1903\n",
      "Epoch 427/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 150.1174 - val_loss: 976.1572\n",
      "Epoch 428/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 149.6935 - val_loss: 974.7254\n",
      "Epoch 429/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 149.2521 - val_loss: 973.6861\n",
      "Epoch 430/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 148.8199 - val_loss: 971.5261\n",
      "Epoch 431/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 148.3964 - val_loss: 969.8541\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 147.9726 - val_loss: 968.0632\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 147.5525 - val_loss: 965.9518\n",
      "Epoch 434/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 147.1342 - val_loss: 964.2896\n",
      "Epoch 435/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 146.7185 - val_loss: 962.6693\n",
      "Epoch 436/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 146.3042 - val_loss: 961.0634\n",
      "Epoch 437/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 145.8917 - val_loss: 959.5047\n",
      "Epoch 438/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 145.4810 - val_loss: 957.6606\n",
      "Epoch 439/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 145.0726 - val_loss: 953.0948\n",
      "Epoch 440/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 148.2725 - val_loss: 943.7521\n",
      "Epoch 441/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 157.2267 - val_loss: 990.3882\n",
      "Epoch 442/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 154.3496 - val_loss: 977.2141\n",
      "Epoch 443/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 144.0213 - val_loss: 943.7850\n",
      "Epoch 444/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 142.9684 - val_loss: 944.1093\n",
      "Epoch 445/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 142.7187 - val_loss: 937.2452\n",
      "Epoch 446/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 142.2495 - val_loss: 938.4658\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 141.3059 - val_loss: 931.4024\n",
      "Epoch 448/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 140.5919 - val_loss: 918.5659\n",
      "Epoch 449/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 133.6848 - val_loss: 866.7663\n",
      "Epoch 450/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.0842 - val_loss: 863.0279\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 219.0850 - val_loss: 892.0084\n",
      "Epoch 452/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 206.3475 - val_loss: 902.3195\n",
      "Epoch 453/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 206.5546 - val_loss: 974.5251\n",
      "Epoch 454/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 222.1981 - val_loss: 1068.8186\n",
      "Epoch 455/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 203.3031 - val_loss: 997.0120\n",
      "Epoch 456/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 212.5618 - val_loss: 984.2734\n",
      "Epoch 457/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 204.0992 - val_loss: 964.8051\n",
      "Epoch 458/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 187.8055 - val_loss: 933.4272\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 179.4376 - val_loss: 936.0122\n",
      "Epoch 460/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 176.0242 - val_loss: 943.9973\n",
      "Epoch 461/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 172.0686 - val_loss: 942.4470\n",
      "Epoch 462/500\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 168.9064 - val_loss: 933.9865\n",
      "Epoch 463/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 166.3459 - val_loss: 930.3178\n",
      "Epoch 464/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 162.9847 - val_loss: 932.1431\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 160.5290 - val_loss: 932.6013\n",
      "Epoch 466/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 157.0839 - val_loss: 932.3582\n",
      "Epoch 467/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 155.6854 - val_loss: 934.8319\n",
      "Epoch 468/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 152.8959 - val_loss: 932.2938\n",
      "Epoch 469/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 151.4697 - val_loss: 929.3292\n",
      "Epoch 470/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 150.1865 - val_loss: 932.5732\n",
      "Epoch 471/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 149.1679 - val_loss: 937.4884\n",
      "Epoch 472/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 148.3654 - val_loss: 940.9077\n",
      "Epoch 473/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 147.6961 - val_loss: 942.5931\n",
      "Epoch 474/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 146.9403 - val_loss: 945.5593\n",
      "Epoch 475/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 145.8662 - val_loss: 945.5468\n",
      "Epoch 476/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 145.0789 - val_loss: 943.0991\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 141.7184 - val_loss: 928.6238\n",
      "Epoch 478/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 140.4759 - val_loss: 925.0587\n",
      "Epoch 479/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 140.4170 - val_loss: 927.9521\n",
      "Epoch 480/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 139.3853 - val_loss: 924.4421\n",
      "Epoch 481/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 138.7323 - val_loss: 926.2734\n",
      "Epoch 482/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 138.4381 - val_loss: 924.0187\n",
      "Epoch 483/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 137.9714 - val_loss: 923.5804\n",
      "Epoch 484/500\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 137.3440 - val_loss: 923.9929\n",
      "Epoch 485/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 136.8872 - val_loss: 919.4682\n",
      "Epoch 486/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 135.9259 - val_loss: 906.9016\n",
      "Epoch 487/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 218.7983 - val_loss: 932.3751\n",
      "Epoch 488/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 167.8100 - val_loss: 960.9306\n",
      "Epoch 489/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 138.6607 - val_loss: 957.2697\n",
      "Epoch 490/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 138.4334 - val_loss: 950.8531\n",
      "Epoch 491/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 138.7875 - val_loss: 939.0948\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 136.7358 - val_loss: 924.5486\n",
      "Epoch 493/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 163.1055 - val_loss: 1058.2281\n",
      "Epoch 494/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 208.4042 - val_loss: 1067.2808\n",
      "Epoch 495/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 201.8085 - val_loss: 1076.4991\n",
      "Epoch 496/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 190.9385 - val_loss: 1188.2959\n",
      "Epoch 497/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 176.4578 - val_loss: 1162.7589\n",
      "Epoch 498/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 174.8919 - val_loss: 1147.6687\n",
      "Epoch 499/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 171.9565 - val_loss: 1130.0720\n",
      "Epoch 500/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 171.1609 - val_loss: 1118.2572\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 480ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 126)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 126)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 186)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:150:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 7.49828245e+01, 0.00000000e+00, 7.53163445e+01,\n",
       "        7.46054202e+01, 7.43759244e+01, 7.49389402e+01, 7.44681746e+01,\n",
       "        7.67478058e+01, 4.78058785e-01, 5.77322320e-02, 7.82079101e-01,\n",
       "        7.44556364e+01, 5.08463920e-01, 7.45482866e+01, 7.80838235e+01,\n",
       "        9.95775300e-03, 7.44438982e+01, 7.62998133e+01, 7.59786181e+01,\n",
       "        5.18556535e+01, 3.11801523e-01, 0.00000000e+00, 7.14011917e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.83667201e-01, 9.58728909e-01, 7.16532059e+01, 0.00000000e+00,\n",
       "        4.29334521e-01, 2.64387727e-01, 0.00000000e+00, 1.47637188e-01,\n",
       "        0.00000000e+00, 4.10679311e-01, 0.00000000e+00, 6.47156954e-01,\n",
       "        7.19510436e-01, 7.76764229e-02, 9.81494784e-04, 7.82730803e-02,\n",
       "        6.29821181e-01, 0.00000000e+00, 0.00000000e+00, 9.27949667e-01,\n",
       "        0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([67.30798661, 67.30170117, 67.29541573, 67.28913029, 67.28284485,\n",
       "       67.2765594 , 67.27027396, 67.26398852, 67.25770308, 67.25141764,\n",
       "       67.2451322 , 67.23884676, 67.23256132, 67.22627588, 67.21999044,\n",
       "       67.21370499, 67.20741955, 67.20113411, 67.19484867, 67.18856323,\n",
       "       67.18227779, 67.17599235, 67.16970691, 67.16342147, 67.15713603,\n",
       "       67.15085058, 67.14456514, 67.1382797 , 67.13199426, 67.12570882,\n",
       "       67.11942338, 67.11313794, 67.1068525 , 67.10056706, 67.09428162,\n",
       "       67.08799617, 67.08171073, 67.07542529, 67.06913985, 67.06285441,\n",
       "       67.05656897, 67.05028353, 67.04399809, 67.03771265, 67.03142721,\n",
       "       67.02514176, 67.01885632, 67.01257088, 67.00628544, 67.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.36448439437551\n",
      "48.06736648908796\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
