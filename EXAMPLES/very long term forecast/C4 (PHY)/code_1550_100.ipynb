{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1645    66.229624\n",
       "1646    66.219073\n",
       "1647    66.208522\n",
       "1648    66.197972\n",
       "1649    66.187421\n",
       "Name: C4, Length: 1650, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_1550_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1545     0.000000\n",
       "1546     0.070315\n",
       "1547     0.000000\n",
       "1548     0.000000\n",
       "1549     0.000000\n",
       "Name: C4, Length: 1550, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1550)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.409524</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.219048</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.028571</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.838095</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.600000  0.000298\n",
       "1     88.409524  0.000298\n",
       "2     88.219048  0.000297\n",
       "3     88.028571  0.000297\n",
       "4     87.838095  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.600000    88.409524    88.219048    88.028571    87.838095   \n",
      "351    88.409524    88.219048    88.028571    87.838095    87.647619   \n",
      "352    88.219048    88.028571    87.838095    87.647619    87.457143   \n",
      "353    88.028571    87.838095    87.647619    87.457143    87.266667   \n",
      "354    87.838095    87.647619    87.457143    87.266667    87.076190   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.647619    87.457143    87.266667    87.076190    86.896218  ...   \n",
      "351    87.457143    87.266667    87.076190    86.896218    86.845798  ...   \n",
      "352    87.266667    87.076190    86.896218    86.845798    86.795378  ...   \n",
      "353    87.076190    86.896218    86.845798    86.795378    86.744958  ...   \n",
      "354    86.896218    86.845798    86.795378    86.744958    86.694538  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   78.880345    0.000263   78.856069    0.000263   78.831793    0.000263   \n",
      "351   78.856069    0.000263   78.831793    0.000263   78.807516    0.000262   \n",
      "352   78.831793    0.000263   78.807516    0.000262   78.783240    0.000262   \n",
      "353   78.807516    0.000262   78.783240    0.000262   78.758964    0.000262   \n",
      "354   78.783240    0.000262   78.758964    0.000262   78.734687    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   78.807516    0.000262   78.783240    0.000262  \n",
      "351   78.783240    0.000262   78.758964    0.000262  \n",
      "352   78.758964    0.000262   78.734687    0.000262  \n",
      "353   78.734687    0.000262   78.710411    0.000262  \n",
      "354   78.710411    0.000262   78.686134    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 1, 251) (1100, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "14/14 [==============================] - 3s 41ms/step - loss: 5576.3120 - val_loss: 4467.6558\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5493.2114 - val_loss: 4415.7412\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5444.5894 - val_loss: 4374.8184\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5396.9453 - val_loss: 4334.1406\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5349.6201 - val_loss: 4293.7998\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5302.6558 - val_loss: 4253.7944\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5256.0449 - val_loss: 4214.1123\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5209.7744 - val_loss: 4174.7437\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5163.8325 - val_loss: 4135.6802\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5118.2104 - val_loss: 4096.9170\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5072.9053 - val_loss: 4058.4492\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5027.9102 - val_loss: 4020.2722\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4983.2227 - val_loss: 3982.3840\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4938.8394 - val_loss: 3944.7800\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4894.7563 - val_loss: 3907.4604\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4850.9722 - val_loss: 3870.4214\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4807.4829 - val_loss: 3833.6614\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4764.2891 - val_loss: 3797.1775\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4721.3862 - val_loss: 3760.9692\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4678.7739 - val_loss: 3725.0337\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4636.4497 - val_loss: 3689.3699\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4593.6826 - val_loss: 3641.6179\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4536.2036 - val_loss: 3602.7991\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4490.1680 - val_loss: 3564.2546\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4444.8911 - val_loss: 3526.5388\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 4400.5005 - val_loss: 3489.5283\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4356.8364 - val_loss: 3453.0989\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4313.7769 - val_loss: 3417.1677\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4271.2402 - val_loss: 3381.6790\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4229.1714 - val_loss: 3346.5969\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4187.5332 - val_loss: 3311.8938\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4146.2983 - val_loss: 3277.5500\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4105.4463 - val_loss: 3243.5500\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4064.9604 - val_loss: 3209.8823\n",
      "Epoch 35/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4024.8279 - val_loss: 3176.5366\n",
      "Epoch 36/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3985.0378 - val_loss: 3143.5037\n",
      "Epoch 37/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3945.5828 - val_loss: 3110.7766\n",
      "Epoch 38/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3906.4529 - val_loss: 3078.3503\n",
      "Epoch 39/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3867.6428 - val_loss: 3046.2185\n",
      "Epoch 40/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3829.1465 - val_loss: 3014.3765\n",
      "Epoch 41/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3790.9587 - val_loss: 2982.8196\n",
      "Epoch 42/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3753.0757 - val_loss: 2951.5444\n",
      "Epoch 43/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3715.4917 - val_loss: 2920.5471\n",
      "Epoch 44/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3678.2031 - val_loss: 2889.8247\n",
      "Epoch 45/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3641.2078 - val_loss: 2859.3735\n",
      "Epoch 46/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3604.5005 - val_loss: 2829.1914\n",
      "Epoch 47/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3568.0801 - val_loss: 2799.2754\n",
      "Epoch 48/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3531.9421 - val_loss: 2769.6228\n",
      "Epoch 49/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3496.0850 - val_loss: 2740.2307\n",
      "Epoch 50/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3460.5056 - val_loss: 2711.0979\n",
      "Epoch 51/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3425.2012 - val_loss: 2682.2207\n",
      "Epoch 52/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 3390.1697 - val_loss: 2653.5984\n",
      "Epoch 53/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3355.4097 - val_loss: 2625.2285\n",
      "Epoch 54/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 3320.9177 - val_loss: 2597.1094\n",
      "Epoch 55/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3286.6921 - val_loss: 2569.2385\n",
      "Epoch 56/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 3252.7314 - val_loss: 2541.6140\n",
      "Epoch 57/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3219.0334 - val_loss: 2514.2339\n",
      "Epoch 58/500\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 3185.5955 - val_loss: 2487.0969\n",
      "Epoch 59/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 3152.4167 - val_loss: 2460.2017\n",
      "Epoch 60/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 3119.4946 - val_loss: 2433.5457\n",
      "Epoch 61/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 3086.8284 - val_loss: 2407.1282\n",
      "Epoch 62/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3054.4155 - val_loss: 2380.9470\n",
      "Epoch 63/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 3022.2546 - val_loss: 2355.0005\n",
      "Epoch 64/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2990.3438 - val_loss: 2329.2878\n",
      "Epoch 65/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 2958.6824 - val_loss: 2303.8064\n",
      "Epoch 66/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2927.2673 - val_loss: 2278.5549\n",
      "Epoch 67/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2896.0984 - val_loss: 2253.5325\n",
      "Epoch 68/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2865.1726 - val_loss: 2228.7380\n",
      "Epoch 69/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2834.4902 - val_loss: 2204.1682\n",
      "Epoch 70/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2804.0486 - val_loss: 2179.8242\n",
      "Epoch 71/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2773.8462 - val_loss: 2155.7029\n",
      "Epoch 72/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2743.8831 - val_loss: 2131.8035\n",
      "Epoch 73/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2714.1560 - val_loss: 2108.1243\n",
      "Epoch 74/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2684.6646 - val_loss: 2084.6646\n",
      "Epoch 75/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2655.4070 - val_loss: 2061.4219\n",
      "Epoch 76/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2626.3821 - val_loss: 2038.3960\n",
      "Epoch 77/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2597.5889 - val_loss: 2015.5851\n",
      "Epoch 78/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2569.0256 - val_loss: 1992.9884\n",
      "Epoch 79/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2540.6909 - val_loss: 1970.6042\n",
      "Epoch 80/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2512.5835 - val_loss: 1948.4315\n",
      "Epoch 81/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 2484.7024 - val_loss: 1926.4690\n",
      "Epoch 82/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2457.0461 - val_loss: 1904.7151\n",
      "Epoch 83/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2429.6135 - val_loss: 1883.1687\n",
      "Epoch 84/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2402.4031 - val_loss: 1861.8289\n",
      "Epoch 85/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2375.4133 - val_loss: 1840.6938\n",
      "Epoch 86/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2348.6438 - val_loss: 1819.7633\n",
      "Epoch 87/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2322.0930 - val_loss: 1799.0354\n",
      "Epoch 88/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2295.7590 - val_loss: 1778.5090\n",
      "Epoch 89/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2269.6418 - val_loss: 1758.1831\n",
      "Epoch 90/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 2243.7397 - val_loss: 1738.0559\n",
      "Epoch 91/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2218.0508 - val_loss: 1718.1274\n",
      "Epoch 92/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2192.5750 - val_loss: 1698.3955\n",
      "Epoch 93/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2167.3101 - val_loss: 1678.8595\n",
      "Epoch 94/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2142.2561 - val_loss: 1659.5183\n",
      "Epoch 95/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2117.4109 - val_loss: 1640.3701\n",
      "Epoch 96/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2092.7737 - val_loss: 1621.4152\n",
      "Epoch 97/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2068.3435 - val_loss: 1602.6509\n",
      "Epoch 98/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2044.1188 - val_loss: 1584.0769\n",
      "Epoch 99/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2020.0989 - val_loss: 1565.6915\n",
      "Epoch 100/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1996.2822 - val_loss: 1547.4946\n",
      "Epoch 101/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1972.6686 - val_loss: 1529.4843\n",
      "Epoch 102/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1949.2559 - val_loss: 1511.6599\n",
      "Epoch 103/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1926.0432 - val_loss: 1494.0200\n",
      "Epoch 104/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1903.0302 - val_loss: 1476.5641\n",
      "Epoch 105/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1880.2147 - val_loss: 1459.2898\n",
      "Epoch 106/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1857.5962 - val_loss: 1442.1982\n",
      "Epoch 107/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1835.1736 - val_loss: 1425.2865\n",
      "Epoch 108/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1812.9464 - val_loss: 1408.5544\n",
      "Epoch 109/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1790.9128 - val_loss: 1392.0004\n",
      "Epoch 110/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1769.0714 - val_loss: 1375.6238\n",
      "Epoch 111/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1747.4221 - val_loss: 1359.4227\n",
      "Epoch 112/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1725.9628 - val_loss: 1343.3972\n",
      "Epoch 113/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1704.6934 - val_loss: 1327.5454\n",
      "Epoch 114/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1683.6123 - val_loss: 1311.8672\n",
      "Epoch 115/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1662.7185 - val_loss: 1296.3610\n",
      "Epoch 116/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1642.0118 - val_loss: 1281.0254\n",
      "Epoch 117/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1621.4902 - val_loss: 1265.8605\n",
      "Epoch 118/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1601.1528 - val_loss: 1250.8640\n",
      "Epoch 119/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1580.9994 - val_loss: 1236.0355\n",
      "Epoch 120/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1561.0283 - val_loss: 1221.3744\n",
      "Epoch 121/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1541.2380 - val_loss: 1206.8792\n",
      "Epoch 122/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1521.6285 - val_loss: 1192.5486\n",
      "Epoch 123/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1502.1987 - val_loss: 1178.3822\n",
      "Epoch 124/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1482.9470 - val_loss: 1164.3788\n",
      "Epoch 125/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1463.8726 - val_loss: 1150.5372\n",
      "Epoch 126/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1444.9753 - val_loss: 1136.8577\n",
      "Epoch 127/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1426.2532 - val_loss: 1123.3365\n",
      "Epoch 128/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1407.7054 - val_loss: 1109.9755\n",
      "Epoch 129/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1389.3313 - val_loss: 1096.7723\n",
      "Epoch 130/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1371.1295 - val_loss: 1083.7266\n",
      "Epoch 131/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1353.0995 - val_loss: 1070.8361\n",
      "Epoch 132/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1335.2396 - val_loss: 1058.1007\n",
      "Epoch 133/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1317.5494 - val_loss: 1045.5199\n",
      "Epoch 134/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1300.0284 - val_loss: 1033.0923\n",
      "Epoch 135/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1282.6753 - val_loss: 1020.8174\n",
      "Epoch 136/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1265.4888 - val_loss: 1008.6929\n",
      "Epoch 137/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1248.4680 - val_loss: 996.7192\n",
      "Epoch 138/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1231.6122 - val_loss: 984.8948\n",
      "Epoch 139/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1214.9199 - val_loss: 973.2186\n",
      "Epoch 140/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1198.3910 - val_loss: 961.6898\n",
      "Epoch 141/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1182.0243 - val_loss: 950.3077\n",
      "Epoch 142/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1165.8187 - val_loss: 939.0714\n",
      "Epoch 143/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1149.7732 - val_loss: 927.9794\n",
      "Epoch 144/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1133.8872 - val_loss: 917.0313\n",
      "Epoch 145/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1118.1598 - val_loss: 906.2264\n",
      "Epoch 146/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1102.5897 - val_loss: 895.5625\n",
      "Epoch 147/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1087.1765 - val_loss: 885.0407\n",
      "Epoch 148/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1071.9187 - val_loss: 874.6576\n",
      "Epoch 149/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1056.8154 - val_loss: 864.4137\n",
      "Epoch 150/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1041.8658 - val_loss: 854.3082\n",
      "Epoch 151/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1027.0697 - val_loss: 844.3402\n",
      "Epoch 152/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1012.4254 - val_loss: 834.5078\n",
      "Epoch 153/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 997.9319 - val_loss: 824.8108\n",
      "Epoch 154/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 983.5888 - val_loss: 815.2484\n",
      "Epoch 155/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 969.3950 - val_loss: 805.8197\n",
      "Epoch 156/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 955.3494 - val_loss: 796.5226\n",
      "Epoch 157/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 941.4514 - val_loss: 787.3581\n",
      "Epoch 158/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 927.7001 - val_loss: 778.3239\n",
      "Epoch 159/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 914.0947 - val_loss: 769.4197\n",
      "Epoch 160/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 900.6342 - val_loss: 760.6447\n",
      "Epoch 161/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 887.3174 - val_loss: 751.9969\n",
      "Epoch 162/500\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 874.1435 - val_loss: 743.4764\n",
      "Epoch 163/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 861.1117 - val_loss: 735.0822\n",
      "Epoch 164/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 848.2214 - val_loss: 726.8137\n",
      "Epoch 165/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 835.4717 - val_loss: 718.6693\n",
      "Epoch 166/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 822.8617 - val_loss: 710.6479\n",
      "Epoch 167/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 810.3897 - val_loss: 702.7493\n",
      "Epoch 168/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 798.0560 - val_loss: 694.9722\n",
      "Epoch 169/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 785.8591 - val_loss: 687.3165\n",
      "Epoch 170/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 773.7983 - val_loss: 679.7799\n",
      "Epoch 171/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 761.8725 - val_loss: 672.3623\n",
      "Epoch 172/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 750.0810 - val_loss: 665.0630\n",
      "Epoch 173/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 738.4229 - val_loss: 657.8807\n",
      "Epoch 174/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 726.8977 - val_loss: 650.8146\n",
      "Epoch 175/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 715.5043 - val_loss: 643.8643\n",
      "Epoch 176/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 704.2415 - val_loss: 637.0281\n",
      "Epoch 177/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 693.1085 - val_loss: 630.3055\n",
      "Epoch 178/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 682.1047 - val_loss: 623.6956\n",
      "Epoch 179/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 671.2294 - val_loss: 617.1974\n",
      "Epoch 180/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 660.4811 - val_loss: 610.8101\n",
      "Epoch 181/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 649.8598 - val_loss: 604.5330\n",
      "Epoch 182/500\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 639.3638 - val_loss: 598.3646\n",
      "Epoch 183/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 628.9930 - val_loss: 592.3051\n",
      "Epoch 184/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 618.7461 - val_loss: 586.3523\n",
      "Epoch 185/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 608.6221 - val_loss: 580.5061\n",
      "Epoch 186/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 598.6207 - val_loss: 574.7653\n",
      "Epoch 187/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 588.7402 - val_loss: 569.1293\n",
      "Epoch 188/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 578.9805 - val_loss: 563.5971\n",
      "Epoch 189/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 569.3406 - val_loss: 558.1680\n",
      "Epoch 190/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 559.8199 - val_loss: 552.8410\n",
      "Epoch 191/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 550.4173 - val_loss: 547.6151\n",
      "Epoch 192/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 541.1316 - val_loss: 542.4891\n",
      "Epoch 193/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 531.9621 - val_loss: 537.4628\n",
      "Epoch 194/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 522.9083 - val_loss: 532.5348\n",
      "Epoch 195/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 513.9689 - val_loss: 527.7044\n",
      "Epoch 196/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 505.1436 - val_loss: 522.9708\n",
      "Epoch 197/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 496.4313 - val_loss: 518.3329\n",
      "Epoch 198/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 487.8310 - val_loss: 513.7900\n",
      "Epoch 199/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 479.3420 - val_loss: 509.3416\n",
      "Epoch 200/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 470.9637 - val_loss: 504.9862\n",
      "Epoch 201/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 462.6948 - val_loss: 500.7227\n",
      "Epoch 202/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 454.5347 - val_loss: 496.5511\n",
      "Epoch 203/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 446.4828 - val_loss: 492.4705\n",
      "Epoch 204/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 438.5382 - val_loss: 488.4790\n",
      "Epoch 205/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 430.6995 - val_loss: 484.5764\n",
      "Epoch 206/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 422.9664 - val_loss: 480.7621\n",
      "Epoch 207/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 415.3382 - val_loss: 477.0349\n",
      "Epoch 208/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 407.8139 - val_loss: 473.3935\n",
      "Epoch 209/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 400.3925 - val_loss: 469.8381\n",
      "Epoch 210/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 393.0734 - val_loss: 466.3668\n",
      "Epoch 211/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 385.8555 - val_loss: 462.9793\n",
      "Epoch 212/500\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 378.7381 - val_loss: 459.6744\n",
      "Epoch 213/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 371.7204 - val_loss: 456.4514\n",
      "Epoch 214/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 364.8018 - val_loss: 453.3096\n",
      "Epoch 215/500\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 357.9810 - val_loss: 450.2476\n",
      "Epoch 216/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 351.2573 - val_loss: 447.2650\n",
      "Epoch 217/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 344.6301 - val_loss: 444.3609\n",
      "Epoch 218/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 338.0986 - val_loss: 441.5345\n",
      "Epoch 219/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 331.6619 - val_loss: 438.7846\n",
      "Epoch 220/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 325.3191 - val_loss: 436.1106\n",
      "Epoch 221/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 319.0695 - val_loss: 433.5114\n",
      "Epoch 222/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 312.9121 - val_loss: 430.9866\n",
      "Epoch 223/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 306.8466 - val_loss: 428.5349\n",
      "Epoch 224/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 300.8714 - val_loss: 426.1556\n",
      "Epoch 225/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 294.9860 - val_loss: 423.8477\n",
      "Epoch 226/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 289.1897 - val_loss: 421.6104\n",
      "Epoch 227/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 283.4816 - val_loss: 419.4430\n",
      "Epoch 228/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 277.8611 - val_loss: 417.3446\n",
      "Epoch 229/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 272.3271 - val_loss: 415.3144\n",
      "Epoch 230/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 266.8792 - val_loss: 413.3513\n",
      "Epoch 231/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 261.5164 - val_loss: 411.4548\n",
      "Epoch 232/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 256.2376 - val_loss: 409.6234\n",
      "Epoch 233/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 251.0421 - val_loss: 407.8571\n",
      "Epoch 234/500\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 245.9295 - val_loss: 406.1546\n",
      "Epoch 235/500\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 240.8987 - val_loss: 404.5150\n",
      "Epoch 236/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 235.9487 - val_loss: 402.9374\n",
      "Epoch 237/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 231.0788 - val_loss: 401.4214\n",
      "Epoch 238/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 226.2885 - val_loss: 399.9657\n",
      "Epoch 239/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 221.5767 - val_loss: 398.5697\n",
      "Epoch 240/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 216.9428 - val_loss: 397.2324\n",
      "Epoch 241/500\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 212.3861 - val_loss: 395.9532\n",
      "Epoch 242/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 207.9056 - val_loss: 394.7310\n",
      "Epoch 243/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 203.5004 - val_loss: 393.5650\n",
      "Epoch 244/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 199.1701 - val_loss: 392.4545\n",
      "Epoch 245/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 194.9136 - val_loss: 391.3987\n",
      "Epoch 246/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 190.7301 - val_loss: 390.3967\n",
      "Epoch 247/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 186.6188 - val_loss: 389.4474\n",
      "Epoch 248/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 182.5790 - val_loss: 388.5504\n",
      "Epoch 249/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 178.6098 - val_loss: 387.7046\n",
      "Epoch 250/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 174.7108 - val_loss: 386.9093\n",
      "Epoch 251/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 170.8811 - val_loss: 386.1638\n",
      "Epoch 252/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 167.1196 - val_loss: 385.4669\n",
      "Epoch 253/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 163.4256 - val_loss: 384.8181\n",
      "Epoch 254/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 159.7985 - val_loss: 384.2166\n",
      "Epoch 255/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 156.2378 - val_loss: 383.6615\n",
      "Epoch 256/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 152.7422 - val_loss: 383.1519\n",
      "Epoch 257/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 149.3112 - val_loss: 382.6871\n",
      "Epoch 258/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 145.9440 - val_loss: 382.2663\n",
      "Epoch 259/500\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 142.6396 - val_loss: 381.8888\n",
      "Epoch 260/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 139.3975 - val_loss: 381.5536\n",
      "Epoch 261/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 136.2170 - val_loss: 381.2600\n",
      "Epoch 262/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 133.0970 - val_loss: 381.0072\n",
      "Epoch 263/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 130.0372 - val_loss: 380.7944\n",
      "Epoch 264/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 127.0367 - val_loss: 380.6208\n",
      "Epoch 265/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 124.0947 - val_loss: 380.4857\n",
      "Epoch 266/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 121.2105 - val_loss: 380.3882\n",
      "Epoch 267/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 118.3832 - val_loss: 380.3277\n",
      "Epoch 268/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 115.6122 - val_loss: 380.3032\n",
      "Epoch 269/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 112.8968 - val_loss: 380.3142\n",
      "Epoch 270/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 110.2361 - val_loss: 380.3596\n",
      "Epoch 271/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 107.6292 - val_loss: 380.4390\n",
      "Epoch 272/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 105.0758 - val_loss: 380.5514\n",
      "Epoch 273/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 102.5751 - val_loss: 380.6962\n",
      "Epoch 274/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 100.1264 - val_loss: 380.8725\n",
      "Epoch 275/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 97.7288 - val_loss: 381.0796\n",
      "Epoch 276/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 95.3815 - val_loss: 381.3168\n",
      "Epoch 277/500\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 93.0841 - val_loss: 381.5833\n",
      "Epoch 278/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 90.8357 - val_loss: 381.8785\n",
      "Epoch 279/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 88.6357 - val_loss: 382.2016\n",
      "Epoch 280/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 86.4832 - val_loss: 382.5518\n",
      "Epoch 281/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 84.3776 - val_loss: 382.9286\n",
      "Epoch 282/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 82.3182 - val_loss: 383.3310\n",
      "Epoch 283/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 80.3045 - val_loss: 383.7585\n",
      "Epoch 284/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 78.3354 - val_loss: 384.2102\n",
      "Epoch 285/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 76.4107 - val_loss: 384.6856\n",
      "Epoch 286/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 74.5294 - val_loss: 385.1839\n",
      "Epoch 287/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 72.6909 - val_loss: 385.7044\n",
      "Epoch 288/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 70.8946 - val_loss: 386.2466\n",
      "Epoch 289/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 69.1397 - val_loss: 386.8095\n",
      "Epoch 290/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 67.4255 - val_loss: 387.3928\n",
      "Epoch 291/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 65.7515 - val_loss: 387.9956\n",
      "Epoch 292/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 64.1171 - val_loss: 388.6172\n",
      "Epoch 293/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 62.5214 - val_loss: 389.2571\n",
      "Epoch 294/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 60.9639 - val_loss: 389.9146\n",
      "Epoch 295/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 59.4439 - val_loss: 390.5889\n",
      "Epoch 296/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 57.9607 - val_loss: 391.2796\n",
      "Epoch 297/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 56.5139 - val_loss: 391.9859\n",
      "Epoch 298/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 55.1027 - val_loss: 392.7074\n",
      "Epoch 299/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 53.7265 - val_loss: 393.4434\n",
      "Epoch 300/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 52.3845 - val_loss: 394.1931\n",
      "Epoch 301/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 51.0764 - val_loss: 394.9561\n",
      "Epoch 302/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 49.8015 - val_loss: 395.7316\n",
      "Epoch 303/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 48.5591 - val_loss: 396.5192\n",
      "Epoch 304/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 47.3487 - val_loss: 397.3182\n",
      "Epoch 305/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 46.1698 - val_loss: 398.1282\n",
      "Epoch 306/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 45.0215 - val_loss: 398.9483\n",
      "Epoch 307/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 43.9036 - val_loss: 399.7783\n",
      "Epoch 308/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 42.8152 - val_loss: 400.6174\n",
      "Epoch 309/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 41.7558 - val_loss: 401.4651\n",
      "Epoch 310/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 40.7250 - val_loss: 402.3210\n",
      "Epoch 311/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 39.7221 - val_loss: 403.1844\n",
      "Epoch 312/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 38.7464 - val_loss: 404.0550\n",
      "Epoch 313/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 37.7976 - val_loss: 404.9318\n",
      "Epoch 314/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 36.8751 - val_loss: 405.8149\n",
      "Epoch 315/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 35.9783 - val_loss: 406.7033\n",
      "Epoch 316/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 35.1067 - val_loss: 407.5970\n",
      "Epoch 317/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 34.2598 - val_loss: 408.4950\n",
      "Epoch 318/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 33.4370 - val_loss: 409.3971\n",
      "Epoch 319/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 32.6379 - val_loss: 410.3025\n",
      "Epoch 320/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 31.8619 - val_loss: 411.2113\n",
      "Epoch 321/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 31.1084 - val_loss: 412.1228\n",
      "Epoch 322/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 30.3771 - val_loss: 413.0365\n",
      "Epoch 323/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 29.6674 - val_loss: 413.9520\n",
      "Epoch 324/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 28.9789 - val_loss: 414.8687\n",
      "Epoch 325/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 28.3111 - val_loss: 415.7864\n",
      "Epoch 326/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 27.6635 - val_loss: 416.7044\n",
      "Epoch 327/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 27.0356 - val_loss: 417.6227\n",
      "Epoch 328/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 26.4269 - val_loss: 418.5408\n",
      "Epoch 329/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 25.8371 - val_loss: 419.4581\n",
      "Epoch 330/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 25.2656 - val_loss: 420.3743\n",
      "Epoch 331/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 24.7120 - val_loss: 421.2891\n",
      "Epoch 332/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 24.1759 - val_loss: 422.2022\n",
      "Epoch 333/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 23.6570 - val_loss: 423.1130\n",
      "Epoch 334/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 23.1546 - val_loss: 424.0215\n",
      "Epoch 335/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 22.6685 - val_loss: 424.9271\n",
      "Epoch 336/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 22.1982 - val_loss: 425.8295\n",
      "Epoch 337/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 21.7433 - val_loss: 426.7284\n",
      "Epoch 338/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 21.3034 - val_loss: 427.6234\n",
      "Epoch 339/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 20.8782 - val_loss: 428.5144\n",
      "Epoch 340/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 20.4672 - val_loss: 429.4012\n",
      "Epoch 341/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 20.0700 - val_loss: 430.2834\n",
      "Epoch 342/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 19.6863 - val_loss: 431.1605\n",
      "Epoch 343/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 19.3158 - val_loss: 432.0321\n",
      "Epoch 344/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.9581 - val_loss: 432.8982\n",
      "Epoch 345/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 18.6128 - val_loss: 433.7590\n",
      "Epoch 346/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 18.2796 - val_loss: 434.6137\n",
      "Epoch 347/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.9580 - val_loss: 435.4623\n",
      "Epoch 348/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.6479 - val_loss: 436.3043\n",
      "Epoch 349/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.3489 - val_loss: 437.1396\n",
      "Epoch 350/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.0607 - val_loss: 437.9680\n",
      "Epoch 351/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 16.7829 - val_loss: 438.7895\n",
      "Epoch 352/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 16.5153 - val_loss: 439.6037\n",
      "Epoch 353/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 16.2575 - val_loss: 440.4106\n",
      "Epoch 354/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 16.0092 - val_loss: 441.2099\n",
      "Epoch 355/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 15.7701 - val_loss: 442.0014\n",
      "Epoch 356/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 15.5401 - val_loss: 442.7849\n",
      "Epoch 357/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 15.3187 - val_loss: 443.5603\n",
      "Epoch 358/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 15.1058 - val_loss: 444.3275\n",
      "Epoch 359/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 14.9011 - val_loss: 445.0862\n",
      "Epoch 360/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.7042 - val_loss: 445.8366\n",
      "Epoch 361/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.5151 - val_loss: 446.5783\n",
      "Epoch 362/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.3333 - val_loss: 447.3114\n",
      "Epoch 363/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.1587 - val_loss: 448.0356\n",
      "Epoch 364/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.9910 - val_loss: 448.7508\n",
      "Epoch 365/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 13.8300 - val_loss: 449.4572\n",
      "Epoch 366/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 13.6754 - val_loss: 450.1543\n",
      "Epoch 367/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 13.5271 - val_loss: 450.8424\n",
      "Epoch 368/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 13.3849 - val_loss: 451.5211\n",
      "Epoch 369/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 13.2485 - val_loss: 452.1906\n",
      "Epoch 370/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 13.1177 - val_loss: 452.8507\n",
      "Epoch 371/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 12.9924 - val_loss: 453.5015\n",
      "Epoch 372/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 12.8723 - val_loss: 454.1425\n",
      "Epoch 373/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.7573 - val_loss: 454.7740\n",
      "Epoch 374/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 12.6471 - val_loss: 455.3966\n",
      "Epoch 375/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 12.5417 - val_loss: 456.0093\n",
      "Epoch 376/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.4407 - val_loss: 456.6122\n",
      "Epoch 377/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.3442 - val_loss: 457.2060\n",
      "Epoch 378/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.2518 - val_loss: 457.7900\n",
      "Epoch 379/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 12.1635 - val_loss: 458.3640\n",
      "Epoch 380/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.0791 - val_loss: 458.9289\n",
      "Epoch 381/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.9984 - val_loss: 459.4838\n",
      "Epoch 382/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.9213 - val_loss: 460.0296\n",
      "Epoch 383/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.8477 - val_loss: 460.5658\n",
      "Epoch 384/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.7773 - val_loss: 461.0921\n",
      "Epoch 385/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.7102 - val_loss: 461.6094\n",
      "Epoch 386/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.6462 - val_loss: 462.1167\n",
      "Epoch 387/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.5851 - val_loss: 462.6148\n",
      "Epoch 388/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.5268 - val_loss: 463.1034\n",
      "Epoch 389/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 11.4713 - val_loss: 463.5830\n",
      "Epoch 390/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.4183 - val_loss: 464.0533\n",
      "Epoch 391/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.3678 - val_loss: 464.5143\n",
      "Epoch 392/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.3197 - val_loss: 464.9659\n",
      "Epoch 393/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 11.2739 - val_loss: 465.4089\n",
      "Epoch 394/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.2302 - val_loss: 465.8426\n",
      "Epoch 395/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.1887 - val_loss: 466.2673\n",
      "Epoch 396/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.1492 - val_loss: 466.6831\n",
      "Epoch 397/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.1116 - val_loss: 467.0898\n",
      "Epoch 398/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.0758 - val_loss: 467.4883\n",
      "Epoch 399/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.0418 - val_loss: 467.8782\n",
      "Epoch 400/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 11.0095 - val_loss: 468.2595\n",
      "Epoch 401/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.9787 - val_loss: 468.6322\n",
      "Epoch 402/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.9495 - val_loss: 468.9965\n",
      "Epoch 403/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.9218 - val_loss: 469.3526\n",
      "Epoch 404/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.8954 - val_loss: 469.7005\n",
      "Epoch 405/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.8704 - val_loss: 470.0401\n",
      "Epoch 406/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.8467 - val_loss: 470.3715\n",
      "Epoch 407/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.8242 - val_loss: 470.6956\n",
      "Epoch 408/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.8028 - val_loss: 471.0117\n",
      "Epoch 409/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.7825 - val_loss: 471.3200\n",
      "Epoch 410/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.7633 - val_loss: 471.6209\n",
      "Epoch 411/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 10.7450 - val_loss: 471.9138\n",
      "Epoch 412/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.7278 - val_loss: 472.2001\n",
      "Epoch 413/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.7113 - val_loss: 472.4789\n",
      "Epoch 414/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6958 - val_loss: 472.7505\n",
      "Epoch 415/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6811 - val_loss: 473.0150\n",
      "Epoch 416/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6672 - val_loss: 473.2726\n",
      "Epoch 417/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.6540 - val_loss: 473.5238\n",
      "Epoch 418/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6415 - val_loss: 473.7680\n",
      "Epoch 419/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6296 - val_loss: 474.0052\n",
      "Epoch 420/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 10.6185 - val_loss: 474.2363\n",
      "Epoch 421/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.6079 - val_loss: 474.4609\n",
      "Epoch 422/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.5979 - val_loss: 474.6796\n",
      "Epoch 423/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.5884 - val_loss: 474.8921\n",
      "Epoch 424/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.5794 - val_loss: 475.0983\n",
      "Epoch 425/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.5709 - val_loss: 475.2988\n",
      "Epoch 426/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.5629 - val_loss: 475.4933\n",
      "Epoch 427/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.5554 - val_loss: 475.6827\n",
      "Epoch 428/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.5482 - val_loss: 475.8658\n",
      "Epoch 429/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.5414 - val_loss: 476.0439\n",
      "Epoch 430/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.5350 - val_loss: 476.2166\n",
      "Epoch 431/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.5290 - val_loss: 476.3843\n",
      "Epoch 432/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 10.5232 - val_loss: 476.5466\n",
      "Epoch 433/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.5179 - val_loss: 476.7047\n",
      "Epoch 434/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.5127 - val_loss: 476.8568\n",
      "Epoch 435/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.5079 - val_loss: 477.0048\n",
      "Epoch 436/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.5034 - val_loss: 477.1479\n",
      "Epoch 437/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4991 - val_loss: 477.2865\n",
      "Epoch 438/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4951 - val_loss: 477.4205\n",
      "Epoch 439/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4912 - val_loss: 477.5504\n",
      "Epoch 440/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4876 - val_loss: 477.6764\n",
      "Epoch 441/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4842 - val_loss: 477.7972\n",
      "Epoch 442/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4810 - val_loss: 477.9148\n",
      "Epoch 443/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4779 - val_loss: 478.0281\n",
      "Epoch 444/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4751 - val_loss: 478.1379\n",
      "Epoch 445/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4724 - val_loss: 478.2438\n",
      "Epoch 446/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4698 - val_loss: 478.3460\n",
      "Epoch 447/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4674 - val_loss: 478.4449\n",
      "Epoch 448/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4652 - val_loss: 478.5402\n",
      "Epoch 449/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4630 - val_loss: 478.6321\n",
      "Epoch 450/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4610 - val_loss: 478.7211\n",
      "Epoch 451/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 10.4591 - val_loss: 478.8066\n",
      "Epoch 452/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4573 - val_loss: 478.8893\n",
      "Epoch 453/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 10.4556 - val_loss: 478.9685\n",
      "Epoch 454/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4540 - val_loss: 479.0450\n",
      "Epoch 455/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4525 - val_loss: 479.1187\n",
      "Epoch 456/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4511 - val_loss: 479.1901\n",
      "Epoch 457/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4497 - val_loss: 479.2581\n",
      "Epoch 458/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4484 - val_loss: 479.3238\n",
      "Epoch 459/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4473 - val_loss: 479.3872\n",
      "Epoch 460/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4462 - val_loss: 479.4480\n",
      "Epoch 461/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4451 - val_loss: 479.5065\n",
      "Epoch 462/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4441 - val_loss: 479.5629\n",
      "Epoch 463/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4432 - val_loss: 479.6169\n",
      "Epoch 464/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4423 - val_loss: 479.6688\n",
      "Epoch 465/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4415 - val_loss: 479.7185\n",
      "Epoch 466/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4407 - val_loss: 479.7661\n",
      "Epoch 467/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4400 - val_loss: 479.8123\n",
      "Epoch 468/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4393 - val_loss: 479.8563\n",
      "Epoch 469/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4386 - val_loss: 479.8985\n",
      "Epoch 470/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4381 - val_loss: 479.9394\n",
      "Epoch 471/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4375 - val_loss: 479.9779\n",
      "Epoch 472/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4370 - val_loss: 480.0152\n",
      "Epoch 473/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4365 - val_loss: 480.0508\n",
      "Epoch 474/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4360 - val_loss: 480.0850\n",
      "Epoch 475/500\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 10.4356 - val_loss: 480.1175\n",
      "Epoch 476/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4352 - val_loss: 480.1490\n",
      "Epoch 477/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4348 - val_loss: 480.1788\n",
      "Epoch 478/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4345 - val_loss: 480.2074\n",
      "Epoch 479/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4341 - val_loss: 480.2345\n",
      "Epoch 480/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4338 - val_loss: 480.2608\n",
      "Epoch 481/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4336 - val_loss: 480.2860\n",
      "Epoch 482/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4333 - val_loss: 480.3099\n",
      "Epoch 483/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4331 - val_loss: 480.3325\n",
      "Epoch 484/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4329 - val_loss: 480.3544\n",
      "Epoch 485/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4326 - val_loss: 480.3747\n",
      "Epoch 486/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4325 - val_loss: 480.3945\n",
      "Epoch 487/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4323 - val_loss: 480.4135\n",
      "Epoch 488/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4321 - val_loss: 480.4313\n",
      "Epoch 489/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4320 - val_loss: 480.4483\n",
      "Epoch 490/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4319 - val_loss: 480.4644\n",
      "Epoch 491/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4318 - val_loss: 480.4796\n",
      "Epoch 492/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4317 - val_loss: 480.4942\n",
      "Epoch 493/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 10.4316 - val_loss: 480.5082\n",
      "Epoch 494/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 10.4315 - val_loss: 480.5211\n",
      "Epoch 495/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4314 - val_loss: 480.5334\n",
      "Epoch 496/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4314 - val_loss: 480.5455\n",
      "Epoch 497/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 10.4314 - val_loss: 480.5570\n",
      "Epoch 498/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4314 - val_loss: 480.5681\n",
      "Epoch 499/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4313 - val_loss: 480.5785\n",
      "Epoch 500/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4313 - val_loss: 480.5881\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 448ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70.56295518, 70.55455182, 70.54614846, 70.5377451 , 70.52934174,\n",
       "        70.52093838, 70.51253501, 70.50413165, 70.49572829, 70.48732493,\n",
       "        70.47892157, 70.47051821, 70.46211485, 70.45371148, 70.44530812,\n",
       "        70.43690476, 70.4285014 , 70.42009804, 70.41169468, 70.40329132,\n",
       "        70.39488796, 70.38648459, 70.37808123, 70.36967787, 70.36127451,\n",
       "        70.35287115, 70.34446779, 70.33606443, 70.32766106, 70.3192577 ,\n",
       "        70.31085434, 70.30245098, 70.29404762, 70.28564426, 70.2772409 ,\n",
       "        70.26883754, 70.26043417, 70.25203081, 70.24362745, 70.23522409,\n",
       "        70.22682073, 70.21841737, 70.21001401, 70.20161064, 70.19320728,\n",
       "        70.18480392, 70.17640056, 74.288282  , 74.2042484 , 74.1202148 ,\n",
       "        74.0361811 , 73.9282213 , 73.8021709 , 73.6761204 , 73.55007   ,\n",
       "        73.4240196 , 73.2979692 , 73.1719188 , 73.0458684 , 72.9198179 ,\n",
       "        72.7937675 , 72.6677171 , 72.5416667 , 72.3987395 , 72.247479  ,\n",
       "        72.0962185 , 71.944958  , 71.7936975 , 71.642437  , 71.4911765 ,\n",
       "        71.339916  , 71.1886555 , 71.037395  , 75.9762115 ,  0.        ,\n",
       "         0.        ,  0.46305758,  0.28009409,  0.        ,  0.32641059,\n",
       "        71.10752106,  0.19408059,  0.        ,  0.42904937,  0.81654119,\n",
       "         0.25501093,  0.        ,  0.        ,  0.33133194,  0.43932641,\n",
       "         0.78659445,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.09658699,  0.15703595,  0.31797481,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([67.20530579, 67.19531513, 67.18532446, 67.1753338 , 67.16534314,\n",
       "       67.15535247, 67.14536181, 67.13537115, 67.12538049, 67.11538982,\n",
       "       67.10539916, 67.0954085 , 67.08541783, 67.07542717, 67.06543651,\n",
       "       67.05544585, 67.04545518, 67.03546452, 67.02547386, 67.01548319,\n",
       "       67.00549253, 66.99550187, 66.9855112 , 66.97552054, 66.96552988,\n",
       "       66.95553922, 66.94554855, 66.93555789, 66.92556723, 66.91557656,\n",
       "       66.9055859 , 66.89559524, 66.88560458, 66.87561391, 66.86562325,\n",
       "       66.85563259, 66.84564192, 66.83565126, 66.8256606 , 66.81566993,\n",
       "       66.80567927, 66.79568861, 66.78569795, 66.77570728, 66.76571662,\n",
       "       66.75572596, 66.74573529, 66.73574463, 66.72551587, 66.71496499,\n",
       "       66.7044141 , 66.69386321, 66.68331232, 66.67276144, 66.66221055,\n",
       "       66.65165966, 66.64110878, 66.63055789, 66.620007  , 66.60945612,\n",
       "       66.59890523, 66.58835434, 66.57780345, 66.56725257, 66.55670168,\n",
       "       66.54615079, 66.53559991, 66.52504902, 66.51449813, 66.50394725,\n",
       "       66.49339636, 66.48284547, 66.47229458, 66.4617437 , 66.45119281,\n",
       "       66.44064192, 66.43009104, 66.41954015, 66.40898926, 66.39843838,\n",
       "       66.38788749, 66.3773366 , 66.36678571, 66.35623483, 66.34568394,\n",
       "       66.33513305, 66.32458217, 66.31403128, 66.30348039, 66.29292951,\n",
       "       66.28237862, 66.27182773, 66.26127684, 66.25072596, 66.24017507,\n",
       "       66.22962418, 66.2190733 , 66.20852241, 66.19797152, 66.18742063])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.31258170489832\n",
      "19.877210395266452\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
