{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1845    64.420798\n",
       "1846    64.412395\n",
       "1847    64.403992\n",
       "1848    64.395588\n",
       "1849    64.387185\n",
       "Name: C4, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_1750_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1745     0.043410\n",
       "1746     0.000000\n",
       "1747     0.499962\n",
       "1748     0.000000\n",
       "1749     0.000000\n",
       "Name: C4, Length: 1750, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1750)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.409524</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.219048</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.028571</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.838095</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.600000  0.000298\n",
       "1     88.409524  0.000298\n",
       "2     88.219048  0.000297\n",
       "3     88.028571  0.000297\n",
       "4     87.838095  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.600000    88.409524    88.219048    88.028571    87.838095   \n",
      "351    88.409524    88.219048    88.028571    87.838095    87.647619   \n",
      "352    88.219048    88.028571    87.838095    87.647619    87.457143   \n",
      "353    88.028571    87.838095    87.647619    87.457143    87.266667   \n",
      "354    87.838095    87.647619    87.457143    87.266667    87.076190   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.647619    87.457143    87.266667    87.076190    86.896218  ...   \n",
      "351    87.457143    87.266667    87.076190    86.896218    86.845798  ...   \n",
      "352    87.266667    87.076190    86.896218    86.845798    86.795378  ...   \n",
      "353    87.076190    86.896218    86.845798    86.795378    86.744958  ...   \n",
      "354    86.896218    86.845798    86.795378    86.744958    86.694538  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   78.880345    0.000263   78.856069    0.000263   78.831793    0.000263   \n",
      "351   78.856069    0.000263   78.831793    0.000263   78.807516    0.000262   \n",
      "352   78.831793    0.000263   78.807516    0.000262   78.783240    0.000262   \n",
      "353   78.807516    0.000262   78.783240    0.000262   78.758964    0.000262   \n",
      "354   78.783240    0.000262   78.758964    0.000262   78.734687    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   78.807516    0.000262   78.783240    0.000262  \n",
      "351   78.783240    0.000262   78.758964    0.000262  \n",
      "352   78.758964    0.000262   78.734687    0.000262  \n",
      "353   78.734687    0.000262   78.710411    0.000262  \n",
      "354   78.710411    0.000262   78.686134    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 1, 251) (1300, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 3s 44ms/step - loss: 5592.6753 - val_loss: 3887.2156\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 5520.8706 - val_loss: 3855.8809\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 5474.0103 - val_loss: 3825.0515\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 5415.0571 - val_loss: 3778.9692\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5358.3779 - val_loss: 3746.4937\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5309.6284 - val_loss: 3714.5183\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5261.5298 - val_loss: 3683.0007\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5213.9868 - val_loss: 3651.8669\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 5166.9185 - val_loss: 3621.0691\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 5120.2700 - val_loss: 3590.5789\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5074.0107 - val_loss: 3560.3765\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5028.1196 - val_loss: 3530.4502\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4982.5815 - val_loss: 3500.7898\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4937.3857 - val_loss: 3471.3884\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4892.5225 - val_loss: 3442.2400\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4847.9863 - val_loss: 3413.3398\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4803.7705 - val_loss: 3384.6843\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4759.8701 - val_loss: 3356.2698\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4716.2822 - val_loss: 3328.0930\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4673.0010 - val_loss: 3300.1511\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4630.0249 - val_loss: 3272.4421\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4587.3506 - val_loss: 3244.9634\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4544.9746 - val_loss: 3217.7129\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 4502.8936 - val_loss: 3190.6890\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 4461.1069 - val_loss: 3163.8889\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 4419.6108 - val_loss: 3137.3123\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 4378.4048 - val_loss: 3110.9563\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4337.4844 - val_loss: 3084.8193\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4296.8501 - val_loss: 3058.9001\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4256.4980 - val_loss: 3033.1970\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4216.4263 - val_loss: 3007.7095\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4176.6348 - val_loss: 2982.4341\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 4137.1201 - val_loss: 2957.3713\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4097.8804 - val_loss: 2932.5190\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4058.9153 - val_loss: 2907.8752\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4020.2219 - val_loss: 2883.4402\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3981.7996 - val_loss: 2859.2112\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3943.6458 - val_loss: 2835.1882\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3905.7593 - val_loss: 2811.3687\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3868.1392 - val_loss: 2787.7522\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3830.7827 - val_loss: 2764.3372\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3793.6885 - val_loss: 2741.1226\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3756.8564 - val_loss: 2718.1074\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3720.2837 - val_loss: 2695.2903\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3683.9695 - val_loss: 2672.6704\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3647.9119 - val_loss: 2650.2461\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3612.1108 - val_loss: 2628.0168\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3576.5623 - val_loss: 2605.9805\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3541.2676 - val_loss: 2584.1370\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3506.2236 - val_loss: 2562.4851\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3471.4299 - val_loss: 2541.0234\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3436.8850 - val_loss: 2519.7512\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3402.5874 - val_loss: 2498.6670\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3368.5352 - val_loss: 2477.7700\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3334.7278 - val_loss: 2457.0588\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3301.1643 - val_loss: 2436.5334\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3267.8425 - val_loss: 2416.1919\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3234.7615 - val_loss: 2396.0327\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 3201.9204 - val_loss: 2376.0562\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3169.3169 - val_loss: 2356.2605\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 3136.9517 - val_loss: 2336.6453\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 3104.8208 - val_loss: 2317.2090\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3072.9255 - val_loss: 2297.9502\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 3041.2632 - val_loss: 2278.8691\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3009.8335 - val_loss: 2259.9641\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2978.6343 - val_loss: 2241.2344\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2947.6653 - val_loss: 2222.6792\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2916.9255 - val_loss: 2204.2969\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2886.4126 - val_loss: 2186.0874\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2856.1265 - val_loss: 2168.0496\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2826.0654 - val_loss: 2150.1816\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2796.2280 - val_loss: 2132.4839\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2766.6143 - val_loss: 2114.9546\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2737.2219 - val_loss: 2097.5930\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2708.0505 - val_loss: 2080.3984\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2679.0981 - val_loss: 2063.3701\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2650.3647 - val_loss: 2046.5072\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2621.8486 - val_loss: 2029.8080\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2593.5488 - val_loss: 2013.2723\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2565.4641 - val_loss: 1996.8994\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2537.5935 - val_loss: 1980.6880\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2509.9363 - val_loss: 1964.6373\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2482.4910 - val_loss: 1948.7466\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2455.2571 - val_loss: 1933.0150\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2428.2327 - val_loss: 1917.4420\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2401.4172 - val_loss: 1902.0261\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2374.8101 - val_loss: 1886.7667\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 2348.4099 - val_loss: 1871.6631\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2322.2144 - val_loss: 1856.7141\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2296.2246 - val_loss: 1841.9194\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2270.4380 - val_loss: 1827.2778\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2244.8540 - val_loss: 1812.7891\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2219.4731 - val_loss: 1798.4519\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2194.2920 - val_loss: 1784.2649\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2169.3108 - val_loss: 1770.2284\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2144.5291 - val_loss: 1756.3411\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2119.9451 - val_loss: 1742.6024\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2095.5576 - val_loss: 1729.0110\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2071.3660 - val_loss: 1715.5660\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2047.3698 - val_loss: 1702.2679\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2023.5677 - val_loss: 1689.1145\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1999.9584 - val_loss: 1676.1060\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1976.5419 - val_loss: 1663.2407\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1953.3159 - val_loss: 1650.5187\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1930.2803 - val_loss: 1637.9387\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1907.4343 - val_loss: 1625.4999\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1884.7765 - val_loss: 1613.2017\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1862.3062 - val_loss: 1601.0437\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1840.0228 - val_loss: 1589.0250\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1817.9254 - val_loss: 1577.1444\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1796.0122 - val_loss: 1565.4014\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1774.2832 - val_loss: 1553.7948\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1752.7368 - val_loss: 1542.3247\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 1731.3724 - val_loss: 1530.9896\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1710.1898 - val_loss: 1519.7897\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1689.1871 - val_loss: 1508.7233\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1668.3640 - val_loss: 1497.7899\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1647.7192 - val_loss: 1486.9889\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1627.2522 - val_loss: 1476.3198\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1606.9619 - val_loss: 1465.7817\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1586.8477 - val_loss: 1455.3734\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1566.9086 - val_loss: 1445.0947\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1547.1432 - val_loss: 1434.9447\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1527.5515 - val_loss: 1424.9226\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1508.1320 - val_loss: 1415.0278\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1488.8848 - val_loss: 1405.2599\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1469.8077 - val_loss: 1395.6178\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1450.9011 - val_loss: 1386.1003\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1432.1631 - val_loss: 1376.7079\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1413.5934 - val_loss: 1367.4390\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1395.1914 - val_loss: 1358.2931\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1376.9563 - val_loss: 1349.2692\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1358.8864 - val_loss: 1340.3671\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1340.9814 - val_loss: 1331.5858\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1323.2410 - val_loss: 1322.9248\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1305.6633 - val_loss: 1314.3832\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1288.2485 - val_loss: 1305.9604\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1270.9955 - val_loss: 1297.6553\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1253.9030 - val_loss: 1289.4678\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 1236.9707 - val_loss: 1281.3967\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 1220.1975 - val_loss: 1273.4415\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1203.5828 - val_loss: 1265.6017\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1187.1256 - val_loss: 1257.8759\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1170.8252 - val_loss: 1250.2633\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1154.6812 - val_loss: 1242.7625\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1138.6918 - val_loss: 1235.3711\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1122.8574 - val_loss: 1228.0764\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1106.8190 - val_loss: 1219.1135\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1086.1412 - val_loss: 1209.4042\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1065.9153 - val_loss: 1200.1898\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1046.7227 - val_loss: 1191.5586\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1028.4205 - val_loss: 1183.3638\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1010.7769 - val_loss: 1175.5081\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 993.6487 - val_loss: 1167.9337\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 976.9478 - val_loss: 1160.6030\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 960.6168 - val_loss: 1153.4906\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 944.6167 - val_loss: 1146.5782\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 928.9180 - val_loss: 1139.8516\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 913.4983 - val_loss: 1133.3003\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 898.3403 - val_loss: 1126.9148\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 883.4297 - val_loss: 1120.6879\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 868.7553 - val_loss: 1114.6138\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 854.3071 - val_loss: 1108.6869\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 840.0765 - val_loss: 1102.9026\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 826.0565 - val_loss: 1097.2568\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 812.2408 - val_loss: 1091.7461\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 798.6237 - val_loss: 1086.3668\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 785.2000 - val_loss: 1081.1161\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 771.9653 - val_loss: 1075.9915\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 758.9158 - val_loss: 1070.9901\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 746.0469 - val_loss: 1066.1097\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 733.3555 - val_loss: 1061.3479\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 720.8390 - val_loss: 1056.7029\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 708.4934 - val_loss: 1052.1727\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 696.3168 - val_loss: 1047.7554\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 684.3058 - val_loss: 1043.4492\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 672.4580 - val_loss: 1039.2523\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 660.7715 - val_loss: 1035.1633\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 649.2438 - val_loss: 1031.1804\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 637.8725 - val_loss: 1027.3024\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 626.6561 - val_loss: 1023.5275\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 615.5923 - val_loss: 1019.8547\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 604.6794 - val_loss: 1016.2825\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 593.9154 - val_loss: 1012.8093\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 583.2987 - val_loss: 1009.4341\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 572.8271 - val_loss: 1006.1555\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 562.4995 - val_loss: 1002.9722\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 552.3141 - val_loss: 999.8831\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 542.2693 - val_loss: 996.8871\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 532.3640 - val_loss: 993.9828\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 522.5961 - val_loss: 991.1693\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 512.9646 - val_loss: 988.4453\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 503.4681 - val_loss: 985.8098\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 494.1050 - val_loss: 983.2618\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 484.8742 - val_loss: 980.7999\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 475.7742 - val_loss: 978.4231\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 466.8034 - val_loss: 976.1307\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 457.9612 - val_loss: 973.9211\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 449.2458 - val_loss: 971.7937\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 440.6559 - val_loss: 969.7474\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 432.1906 - val_loss: 967.7811\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 423.8484 - val_loss: 965.8938\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 415.6284 - val_loss: 964.0844\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 407.5291 - val_loss: 962.3522\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 399.5498 - val_loss: 960.6961\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 391.6890 - val_loss: 959.1151\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 383.9456 - val_loss: 957.6080\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 376.3184 - val_loss: 956.1741\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 368.8066 - val_loss: 954.8126\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 361.4090 - val_loss: 953.5222\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 354.1244 - val_loss: 952.3022\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 346.9518 - val_loss: 951.1515\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 339.8901 - val_loss: 950.0692\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 332.9379 - val_loss: 949.0544\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 326.0945 - val_loss: 948.1061\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 319.3588 - val_loss: 947.2235\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 312.7298 - val_loss: 946.4055\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 306.2063 - val_loss: 945.6513\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 299.7874 - val_loss: 944.9600\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 293.4720 - val_loss: 944.3306\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 287.2589 - val_loss: 943.7622\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 281.1472 - val_loss: 943.2541\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 275.1363 - val_loss: 942.8051\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 269.2245 - val_loss: 942.4142\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 263.4112 - val_loss: 942.0809\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 257.6953 - val_loss: 941.8041\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 252.0760 - val_loss: 941.5828\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 246.5520 - val_loss: 941.4163\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 241.1225 - val_loss: 941.3036\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 235.7864 - val_loss: 941.2440\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 230.5428 - val_loss: 941.2363\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 225.3908 - val_loss: 941.2796\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 220.3293 - val_loss: 941.3733\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 215.3575 - val_loss: 941.5164\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 210.4743 - val_loss: 941.7078\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 205.6785 - val_loss: 941.9471\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 200.9693 - val_loss: 942.2328\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 196.3462 - val_loss: 942.5645\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 191.8077 - val_loss: 942.9412\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 187.3528 - val_loss: 943.3620\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 182.9809 - val_loss: 943.8262\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 178.6910 - val_loss: 944.3325\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 174.4821 - val_loss: 944.8804\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 170.3530 - val_loss: 945.4689\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 166.3033 - val_loss: 946.0971\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 162.3317 - val_loss: 946.7643\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 158.4373 - val_loss: 947.4696\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 154.6192 - val_loss: 948.2120\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 150.8765 - val_loss: 948.9906\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 147.2083 - val_loss: 949.8048\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 143.6135 - val_loss: 950.6537\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 140.0913 - val_loss: 951.5363\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 136.6407 - val_loss: 952.4518\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 133.2610 - val_loss: 953.3993\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 129.9512 - val_loss: 954.3781\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 126.7104 - val_loss: 955.3873\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 123.5377 - val_loss: 956.4261\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 120.4320 - val_loss: 957.4936\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 117.3924 - val_loss: 958.5889\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 114.4184 - val_loss: 959.7117\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 111.5087 - val_loss: 960.8602\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 108.6626 - val_loss: 962.0343\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 105.8792 - val_loss: 963.2331\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 103.1576 - val_loss: 964.4557\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 100.4968 - val_loss: 965.7012\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 97.8960 - val_loss: 966.9690\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 95.3544 - val_loss: 968.2582\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 92.8710 - val_loss: 969.5679\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 90.4452 - val_loss: 970.8973\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 88.0758 - val_loss: 972.2457\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 85.7621 - val_loss: 973.6124\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 83.5032 - val_loss: 974.9965\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 81.2983 - val_loss: 976.3973\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 79.1464 - val_loss: 977.8140\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 77.0468 - val_loss: 979.2458\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 74.9986 - val_loss: 980.6918\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 73.0011 - val_loss: 982.1515\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 71.0531 - val_loss: 983.6243\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 69.1541 - val_loss: 985.1090\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 67.3033 - val_loss: 986.6050\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 65.4997 - val_loss: 988.1118\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 63.7425 - val_loss: 989.6284\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 62.0309 - val_loss: 991.1544\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 60.3642 - val_loss: 992.6888\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 58.7415 - val_loss: 994.2310\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 57.1620 - val_loss: 995.7802\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 55.6250 - val_loss: 997.3359\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 54.1296 - val_loss: 998.8972\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 52.6752 - val_loss: 1000.4635\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 51.2607 - val_loss: 1002.0342\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 49.8856 - val_loss: 1003.6089\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 48.5492 - val_loss: 1005.1862\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 47.2505 - val_loss: 1006.7659\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 45.9889 - val_loss: 1008.3480\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 44.7635 - val_loss: 1009.9305\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 43.5737 - val_loss: 1011.5138\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 42.4188 - val_loss: 1013.0970\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 41.2980 - val_loss: 1014.6794\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 40.2106 - val_loss: 1016.2608\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 39.1559 - val_loss: 1017.8401\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 38.1332 - val_loss: 1019.4168\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 37.1417 - val_loss: 1020.9907\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 36.1809 - val_loss: 1022.5609\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 35.2499 - val_loss: 1024.1271\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 34.3482 - val_loss: 1025.6886\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 33.4751 - val_loss: 1027.2449\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 32.6298 - val_loss: 1028.7955\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 31.8118 - val_loss: 1030.3398\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 31.0204 - val_loss: 1031.8774\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 30.2549 - val_loss: 1033.4078\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 29.5147 - val_loss: 1034.9305\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 28.7993 - val_loss: 1036.4451\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 28.1080 - val_loss: 1037.9513\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 27.4401 - val_loss: 1039.4484\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 26.7951 - val_loss: 1040.9359\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 26.1725 - val_loss: 1042.4135\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 25.5715 - val_loss: 1043.8810\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 24.9916 - val_loss: 1045.3381\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 24.4323 - val_loss: 1046.7842\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 23.8931 - val_loss: 1048.2184\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 23.3733 - val_loss: 1049.6410\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 22.8724 - val_loss: 1051.0513\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 22.3899 - val_loss: 1052.4493\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.9253 - val_loss: 1053.8346\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.4781 - val_loss: 1055.2069\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.0477 - val_loss: 1056.5658\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 20.6337 - val_loss: 1057.9110\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.2356 - val_loss: 1059.2419\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.8529 - val_loss: 1060.5590\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.4851 - val_loss: 1061.8616\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 19.1317 - val_loss: 1063.1494\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.7925 - val_loss: 1064.4224\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.4667 - val_loss: 1065.6801\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.1542 - val_loss: 1066.9224\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.8544 - val_loss: 1068.1493\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.5669 - val_loss: 1069.3602\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 17.2913 - val_loss: 1070.5553\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.0272 - val_loss: 1071.7346\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.7742 - val_loss: 1072.8979\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.5320 - val_loss: 1074.0446\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.3002 - val_loss: 1075.1747\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.0784 - val_loss: 1076.2881\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.8662 - val_loss: 1077.3853\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.6634 - val_loss: 1078.4657\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.4695 - val_loss: 1079.5292\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.2843 - val_loss: 1080.5760\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 15.1074 - val_loss: 1081.6057\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.9385 - val_loss: 1082.6188\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.7774 - val_loss: 1083.6146\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.6237 - val_loss: 1084.5934\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.4771 - val_loss: 1085.5554\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.3374 - val_loss: 1086.5004\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 14.2043 - val_loss: 1087.4281\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.0776 - val_loss: 1088.3390\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.9569 - val_loss: 1089.2328\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.8420 - val_loss: 1090.1101\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.7328 - val_loss: 1090.9697\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.6289 - val_loss: 1091.8130\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.5302 - val_loss: 1092.6393\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.4364 - val_loss: 1093.4492\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.3473 - val_loss: 1094.2426\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.2627 - val_loss: 1095.0194\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.1824 - val_loss: 1095.7799\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.1062 - val_loss: 1096.5239\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0340 - val_loss: 1097.2518\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.9655 - val_loss: 1097.9637\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.9007 - val_loss: 1098.6598\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.8392 - val_loss: 1099.3397\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.7810 - val_loss: 1100.0043\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.7260 - val_loss: 1100.6532\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.6739 - val_loss: 1101.2871\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.6246 - val_loss: 1101.9065\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.5780 - val_loss: 1102.5098\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.5339 - val_loss: 1103.0984\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.4924 - val_loss: 1103.6731\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.4531 - val_loss: 1104.2322\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.4160 - val_loss: 1104.7776\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.3811 - val_loss: 1105.3087\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 12.3481 - val_loss: 1105.8263\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 12.3170 - val_loss: 1106.3298\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.2876 - val_loss: 1106.8197\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.2600 - val_loss: 1107.2964\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.2340 - val_loss: 1107.7598\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.2095 - val_loss: 1108.2102\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.1865 - val_loss: 1108.6482\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.1648 - val_loss: 1109.0736\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.1444 - val_loss: 1109.4868\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.1252 - val_loss: 1109.8882\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.1071 - val_loss: 1110.2775\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0902 - val_loss: 1110.6552\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0743 - val_loss: 1111.0215\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0593 - val_loss: 1111.3765\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0452 - val_loss: 1111.7206\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0321 - val_loss: 1112.0536\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0197 - val_loss: 1112.3768\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.0081 - val_loss: 1112.6892\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9973 - val_loss: 1112.9916\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9870 - val_loss: 1113.2848\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 11.9775 - val_loss: 1113.5673\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9685 - val_loss: 1113.8414\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9601 - val_loss: 1114.1056\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9523 - val_loss: 1114.3613\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9449 - val_loss: 1114.6074\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9380 - val_loss: 1114.8458\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9316 - val_loss: 1115.0756\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9256 - val_loss: 1115.2971\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9199 - val_loss: 1115.5114\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9146 - val_loss: 1115.7172\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9097 - val_loss: 1115.9156\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.9051 - val_loss: 1116.1071\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9008 - val_loss: 1116.2915\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8967 - val_loss: 1116.4684\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8930 - val_loss: 1116.6390\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8895 - val_loss: 1116.8030\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8862 - val_loss: 1116.9607\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8832 - val_loss: 1117.1125\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8803 - val_loss: 1117.2578\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8776 - val_loss: 1117.3975\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8752 - val_loss: 1117.5319\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 11.8728 - val_loss: 1117.6608\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8707 - val_loss: 1117.7844\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8687 - val_loss: 1117.9031\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8668 - val_loss: 1118.0166\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8650 - val_loss: 1118.1254\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8634 - val_loss: 1118.2296\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8619 - val_loss: 1118.3293\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8605 - val_loss: 1118.4248\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8592 - val_loss: 1118.5161\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8580 - val_loss: 1118.6033\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8569 - val_loss: 1118.6863\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8559 - val_loss: 1118.7666\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8549 - val_loss: 1118.8425\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8540 - val_loss: 1118.9154\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8532 - val_loss: 1118.9849\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8525 - val_loss: 1119.0509\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8518 - val_loss: 1119.1140\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8511 - val_loss: 1119.1738\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8506 - val_loss: 1119.2310\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 11.8501 - val_loss: 1119.2855\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8495 - val_loss: 1119.3373\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8491 - val_loss: 1119.3865\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8487 - val_loss: 1119.4335\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8483 - val_loss: 1119.4778\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8480 - val_loss: 1119.5200\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8477 - val_loss: 1119.5604\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8474 - val_loss: 1119.5981\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8472 - val_loss: 1119.6346\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8470 - val_loss: 1119.6686\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8469 - val_loss: 1119.7017\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8467 - val_loss: 1119.7318\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8466 - val_loss: 1119.7615\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8465 - val_loss: 1119.7889\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8464 - val_loss: 1119.8153\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8463 - val_loss: 1119.8397\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8463 - val_loss: 1119.8629\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8463 - val_loss: 1119.8845\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8463 - val_loss: 1119.9052\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 11.8463 - val_loss: 1119.9248\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 11.8463 - val_loss: 1119.9430\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8464 - val_loss: 1119.9606\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8464 - val_loss: 1119.9766\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8464 - val_loss: 1119.9918\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8465 - val_loss: 1120.0063\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8466 - val_loss: 1120.0200\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8467 - val_loss: 1120.0325\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8468 - val_loss: 1120.0448\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8469 - val_loss: 1120.0557\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8470 - val_loss: 1120.0660\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8472 - val_loss: 1120.0757\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8473 - val_loss: 1120.0848\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8474 - val_loss: 1120.0935\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8476 - val_loss: 1120.1014\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8478 - val_loss: 1120.1091\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8479 - val_loss: 1120.1155\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8481 - val_loss: 1120.1217\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8483 - val_loss: 1120.1283\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8484 - val_loss: 1120.1339\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 11.8486 - val_loss: 1120.1389\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8488 - val_loss: 1120.1439\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8490 - val_loss: 1120.1483\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8492 - val_loss: 1120.1523\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8494 - val_loss: 1120.1561\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8496 - val_loss: 1120.1595\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8498 - val_loss: 1120.1626\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 11.8500 - val_loss: 1120.1656\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8502 - val_loss: 1120.1685\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8504 - val_loss: 1120.1707\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8506 - val_loss: 1120.1726\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8508 - val_loss: 1120.1744\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8511 - val_loss: 1120.1760\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8513 - val_loss: 1120.1776\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8515 - val_loss: 1120.1788\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.8517 - val_loss: 1120.1801\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8519 - val_loss: 1120.1810\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8522 - val_loss: 1120.1818\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 11.8524 - val_loss: 1120.1829\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 11.8526 - val_loss: 1120.1833\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8528 - val_loss: 1120.1836\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8530 - val_loss: 1120.1840\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.8533 - val_loss: 1120.1842\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 452ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.18441177e+01, 7.16928571e+01, 7.15415966e+01, 7.13903361e+01,\n",
       "        7.12390756e+01, 7.10878151e+01, 7.09365546e+01, 2.50196900e-02,\n",
       "        2.04454392e-01, 8.59306460e-02, 4.23435479e-01, 4.60363358e-01,\n",
       "        8.07693124e-01, 7.31158964e+01, 7.29898459e+01, 7.28637955e+01,\n",
       "        7.27377451e+01, 7.26116947e+01, 7.24827731e+01, 7.23315126e+01,\n",
       "        7.21802521e+01, 7.20289916e+01, 7.18777311e+01, 7.17264706e+01,\n",
       "        7.15752101e+01, 7.14239496e+01, 7.12726891e+01, 7.11214286e+01,\n",
       "        7.09701681e+01, 7.08189076e+01, 7.06946078e+01, 7.06693978e+01,\n",
       "        7.06441877e+01, 7.06189776e+01, 7.05937675e+01, 7.05685574e+01,\n",
       "        7.05433473e+01, 7.05181372e+01, 7.04929272e+01, 7.04677171e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.48075680e-01, 7.61106490e-01,\n",
       "        2.01986220e-01, 4.64026210e-01, 8.09544860e-01, 7.14575630e+01,\n",
       "        7.13063025e+01, 7.11550420e+01, 7.10037815e+01, 7.08525210e+01,\n",
       "        7.07012605e+01, 7.06750000e+01, 7.06497899e+01, 7.06245798e+01,\n",
       "        7.05993697e+01, 7.05741597e+01, 7.05489496e+01, 7.05237395e+01,\n",
       "        7.04985294e+01, 7.04733193e+01, 7.04481092e+01, 7.04228992e+01,\n",
       "        7.03976891e+01, 7.03724790e+01, 7.03472689e+01, 7.03220588e+01,\n",
       "        7.02968487e+01, 7.02716387e+01, 7.02464286e+01, 7.02212185e+01,\n",
       "        7.01960084e+01, 7.60199509e+01, 1.62238002e-01, 3.44524920e-01,\n",
       "        4.52334553e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.93277016e+01, 3.46844375e-01, 0.00000000e+00, 1.15270972e-01,\n",
       "        6.16381407e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        8.47232521e-01, 6.06308103e-01, 0.00000000e+00, 6.27414048e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.57352507e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.12727749e-01, 2.07402796e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65.21911765, 65.21071429, 65.20231092, 65.19390756, 65.1855042 ,\n",
       "       65.17710084, 65.16869748, 65.16029412, 65.15189076, 65.14348739,\n",
       "       65.13508403, 65.12668067, 65.11827731, 65.10987395, 65.10147059,\n",
       "       65.09306723, 65.08466387, 65.0762605 , 65.06785714, 65.05945378,\n",
       "       65.05105042, 65.04264706, 65.0342437 , 65.02584034, 65.01743697,\n",
       "       65.00903361, 65.00063025, 64.99222689, 64.98382353, 64.97542017,\n",
       "       64.96701681, 64.95861345, 64.95021008, 64.94180672, 64.93340336,\n",
       "       64.925     , 64.91659664, 64.90819328, 64.89978992, 64.89138655,\n",
       "       64.88298319, 64.87457983, 64.86617647, 64.85777311, 64.84936975,\n",
       "       64.84096639, 64.83256303, 64.82415966, 64.8157563 , 64.80735294,\n",
       "       64.79894958, 64.79054622, 64.78214286, 64.7737395 , 64.76533613,\n",
       "       64.75693277, 64.74852941, 64.74012605, 64.73172269, 64.72331933,\n",
       "       64.71491597, 64.70651261, 64.69810924, 64.68970588, 64.68130252,\n",
       "       64.67289916, 64.6644958 , 64.65609244, 64.64768908, 64.63928571,\n",
       "       64.63088235, 64.62247899, 64.61407563, 64.60567227, 64.59726891,\n",
       "       64.58886555, 64.58046218, 64.57205882, 64.56365546, 64.5552521 ,\n",
       "       64.54684874, 64.53844538, 64.53004202, 64.52163866, 64.51323529,\n",
       "       64.50483193, 64.49642857, 64.48802521, 64.47962185, 64.47121849,\n",
       "       64.46281513, 64.45441176, 64.4460084 , 64.43760504, 64.42920168,\n",
       "       64.42079832, 64.41239496, 64.4039916 , 64.39558824, 64.38718487])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.04024834863052\n",
      "28.44925099190306\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
