{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "1345    73.979155\n",
       "1346    73.974486\n",
       "1347    73.969818\n",
       "1348    73.965149\n",
       "1349    73.960481\n",
       "Name: C3, Length: 1350, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_1250_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "1245    74.375924\n",
       "1246    74.373497\n",
       "1247    74.371069\n",
       "1248    74.368641\n",
       "1249    74.366214\n",
       "Name: C3, Length: 1250, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1250)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1, 251) (800, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 3s 83ms/step - loss: 6313.9883 - val_loss: 5659.2007\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 6249.8198 - val_loss: 5628.0762\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6217.0117 - val_loss: 5596.8745\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6184.2183 - val_loss: 5565.7627\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 6151.5391 - val_loss: 5534.7817\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 6118.1362 - val_loss: 5497.3037\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 6078.8799 - val_loss: 5464.9077\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 6044.6733 - val_loss: 5432.4287\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 6010.5771 - val_loss: 5400.1836\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5976.7427 - val_loss: 5368.1963\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5943.1675 - val_loss: 5336.4502\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5909.8291 - val_loss: 5304.9214\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5876.7056 - val_loss: 5273.5884\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5843.7764 - val_loss: 5242.4404\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5811.0312 - val_loss: 5211.4644\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5778.4600 - val_loss: 5180.6538\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5746.0537 - val_loss: 5150.0024\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5713.8091 - val_loss: 5119.5049\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5681.7192 - val_loss: 5089.1577\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5649.7817 - val_loss: 5058.9575\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5617.9932 - val_loss: 5028.9014\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5586.3506 - val_loss: 4998.9873\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5554.8521 - val_loss: 4969.2139\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5523.4956 - val_loss: 4939.5786\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5492.2803 - val_loss: 4910.0811\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5461.2041 - val_loss: 4880.7188\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 5430.2656 - val_loss: 4851.4907\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5399.4634 - val_loss: 4822.3955\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 5368.7964 - val_loss: 4793.4336\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5338.2642 - val_loss: 4764.6025\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5307.8647 - val_loss: 4735.9019\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5277.5981 - val_loss: 4707.3306\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5247.4624 - val_loss: 4678.8877\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 5217.4580 - val_loss: 4650.5732\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 5187.5835 - val_loss: 4622.3857\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5157.8384 - val_loss: 4594.3257\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5128.2222 - val_loss: 4566.3896\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5098.7339 - val_loss: 4538.5806\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5069.3721 - val_loss: 4510.8960\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5040.1382 - val_loss: 4483.3354\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5011.0298 - val_loss: 4455.8975\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4982.0464 - val_loss: 4428.5840\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4953.1899 - val_loss: 4401.3916\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4924.4561 - val_loss: 4374.3218\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4895.8462 - val_loss: 4347.3735\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4867.3604 - val_loss: 4320.5459\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4838.9971 - val_loss: 4293.8379\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4810.7563 - val_loss: 4267.2505\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 4782.6372 - val_loss: 4240.7822\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4754.6396 - val_loss: 4214.4331\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4726.7627 - val_loss: 4188.2017\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4699.0059 - val_loss: 4162.0894\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4671.3701 - val_loss: 4136.0938\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4643.8530 - val_loss: 4110.2158\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4616.4561 - val_loss: 4084.4546\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4589.1758 - val_loss: 4058.8086\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4562.0146 - val_loss: 4033.2788\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4534.9717 - val_loss: 4007.8647\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4508.0449 - val_loss: 3982.5652\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4481.2358 - val_loss: 3957.3801\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4454.5430 - val_loss: 3932.3098\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 4427.9668 - val_loss: 3907.3528\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4401.5054 - val_loss: 3882.5090\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 4375.1592 - val_loss: 3857.7781\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 4348.9282 - val_loss: 3833.1597\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 4322.8115 - val_loss: 3808.6531\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4296.8091 - val_loss: 3784.2583\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4270.9204 - val_loss: 3759.9753\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4245.1445 - val_loss: 3735.8022\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4219.4814 - val_loss: 3711.7410\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4193.9307 - val_loss: 3687.7891\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4168.4932 - val_loss: 3663.9468\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4143.1660 - val_loss: 3640.2141\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 4117.9502 - val_loss: 3616.5906\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 4092.8452 - val_loss: 3593.0757\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4067.8523 - val_loss: 3569.6694\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 4042.9683 - val_loss: 3546.3711\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4018.1946 - val_loss: 3523.1802\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 3993.5300 - val_loss: 3500.0962\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 3968.9746 - val_loss: 3477.1187\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3944.5281 - val_loss: 3454.2485\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3920.1899 - val_loss: 3431.4844\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3895.9602 - val_loss: 3408.8257\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3871.8374 - val_loss: 3386.2722\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3847.8218 - val_loss: 3363.8242\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3823.9141 - val_loss: 3341.4817\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3800.1125 - val_loss: 3319.2422\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3776.4172 - val_loss: 3297.1069\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3752.8276 - val_loss: 3275.0757\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3729.3433 - val_loss: 3253.1482\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3705.9648 - val_loss: 3231.3237\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3682.6914 - val_loss: 3209.6021\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3659.5222 - val_loss: 3187.9819\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3636.4575 - val_loss: 3166.4648\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 3613.4966 - val_loss: 3145.0486\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3590.6392 - val_loss: 3123.7339\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3567.8848 - val_loss: 3102.5212\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3545.2336 - val_loss: 3081.4077\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3522.6843 - val_loss: 3060.3950\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3500.2378 - val_loss: 3039.4829\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3477.8933 - val_loss: 3018.6702\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3455.6509 - val_loss: 2997.9568\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3433.5085 - val_loss: 2977.3433\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3411.4683 - val_loss: 2956.8284\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3389.5281 - val_loss: 2936.4116\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3367.6882 - val_loss: 2916.0930\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3345.9485 - val_loss: 2895.8716\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3324.3081 - val_loss: 2875.7488\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3302.7676 - val_loss: 2855.7229\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3281.3257 - val_loss: 2835.7935\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3259.9829 - val_loss: 2815.9617\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3238.7383 - val_loss: 2796.2253\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3217.5923 - val_loss: 2776.5852\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3196.5435 - val_loss: 2757.0403\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3175.5923 - val_loss: 2737.5908\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3154.7383 - val_loss: 2718.2368\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3133.9812 - val_loss: 2698.9773\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3113.3208 - val_loss: 2679.8130\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3092.7566 - val_loss: 2660.7417\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3072.2883 - val_loss: 2641.7651\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3051.9163 - val_loss: 2622.8821\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3031.6392 - val_loss: 2604.0913\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3011.4573 - val_loss: 2585.3953\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2991.3701 - val_loss: 2566.7903\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 2971.3774 - val_loss: 2548.2786\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2951.4790 - val_loss: 2529.8589\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2931.6746 - val_loss: 2511.5310\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2911.9636 - val_loss: 2493.2947\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2892.3462 - val_loss: 2475.1492\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2872.8218 - val_loss: 2457.0950\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2853.3901 - val_loss: 2439.1316\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2834.0513 - val_loss: 2421.2585\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2814.8044 - val_loss: 2403.4756\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2795.6492 - val_loss: 2385.7820\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2776.5857 - val_loss: 2368.1780\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2757.6133 - val_loss: 2350.6633\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2738.7324 - val_loss: 2333.2388\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2719.9426 - val_loss: 2315.9016\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2701.2427 - val_loss: 2298.6528\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2682.6331 - val_loss: 2281.4934\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2664.1140 - val_loss: 2264.4204\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2645.6841 - val_loss: 2247.4360\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2627.3438 - val_loss: 2230.5391\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2609.0923 - val_loss: 2213.7278\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2590.9302 - val_loss: 2197.0046\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2572.8560 - val_loss: 2180.3674\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2554.8706 - val_loss: 2163.8167\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2536.9731 - val_loss: 2147.3521\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2519.1633 - val_loss: 2130.9727\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2501.4414 - val_loss: 2114.6785\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2483.8062 - val_loss: 2098.4702\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 2466.2583 - val_loss: 2082.3467\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2448.7969 - val_loss: 2066.3071\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2431.4221 - val_loss: 2050.3530\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2414.1333 - val_loss: 2034.4818\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 2396.9302 - val_loss: 2018.6951\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2379.8130 - val_loss: 2002.9912\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2362.7812 - val_loss: 1987.3717\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2345.8340 - val_loss: 1971.8344\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2328.9722 - val_loss: 1956.3806\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2312.1948 - val_loss: 1941.0085\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2295.5020 - val_loss: 1925.7197\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2278.8931 - val_loss: 1910.5120\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2262.3677 - val_loss: 1895.3864\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2245.9263 - val_loss: 1880.3424\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2229.5681 - val_loss: 1865.3793\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2213.2927 - val_loss: 1850.4983\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2197.1011 - val_loss: 1835.6969\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2180.9915 - val_loss: 1820.9762\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2164.9641 - val_loss: 1806.3356\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2149.0181 - val_loss: 1791.7758\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2133.1548 - val_loss: 1777.2952\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2117.3728 - val_loss: 1762.8939\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2101.6724 - val_loss: 1748.5719\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2086.0525 - val_loss: 1734.3289\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 2070.5134 - val_loss: 1720.1648\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2055.0552 - val_loss: 1706.0791\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2039.6774 - val_loss: 1692.0719\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2024.3793 - val_loss: 1678.1426\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2009.1614 - val_loss: 1664.2906\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1994.0227 - val_loss: 1650.5162\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1978.9629 - val_loss: 1636.8197\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1963.9832 - val_loss: 1623.1995\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1949.0817 - val_loss: 1609.6570\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1934.2592 - val_loss: 1596.1898\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1919.5146 - val_loss: 1582.7993\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1904.8480 - val_loss: 1569.4857\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1890.2600 - val_loss: 1556.2465\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1875.7493 - val_loss: 1543.0840\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1861.3158 - val_loss: 1529.9968\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1846.9597 - val_loss: 1516.9839\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1832.6804 - val_loss: 1504.0465\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1818.4779 - val_loss: 1491.1833\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1804.3518 - val_loss: 1478.3948\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1790.3018 - val_loss: 1465.6798\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1776.3279 - val_loss: 1453.0396\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1762.4294 - val_loss: 1440.4729\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1748.6071 - val_loss: 1427.9791\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1734.8596 - val_loss: 1415.5592\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1721.1871 - val_loss: 1403.2114\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1707.5896 - val_loss: 1390.9371\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1694.0667 - val_loss: 1378.7352\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1680.6179 - val_loss: 1366.6051\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1667.2434 - val_loss: 1354.5476\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1653.9430 - val_loss: 1342.5612\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1640.7155 - val_loss: 1330.6462\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1627.5618 - val_loss: 1318.8033\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1614.4812 - val_loss: 1307.0320\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1601.4739 - val_loss: 1295.3301\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1588.5392 - val_loss: 1283.6995\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1575.6770 - val_loss: 1272.1399\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1562.8870 - val_loss: 1260.6501\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1550.1692 - val_loss: 1249.2302\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1537.5232 - val_loss: 1237.8799\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1524.9486 - val_loss: 1226.5985\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 1512.4453 - val_loss: 1215.3871\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1500.0137 - val_loss: 1204.2455\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1487.6526 - val_loss: 1193.1716\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1475.3621 - val_loss: 1182.1672\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1463.1426 - val_loss: 1171.2300\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1450.9926 - val_loss: 1160.3619\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1438.9133 - val_loss: 1149.5614\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1426.9036 - val_loss: 1138.8286\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1414.9635 - val_loss: 1128.1630\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1403.0925 - val_loss: 1117.5648\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1391.2908 - val_loss: 1107.0336\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1379.5579 - val_loss: 1096.5693\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1367.8938 - val_loss: 1086.1719\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1356.2982 - val_loss: 1075.8400\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1344.7706 - val_loss: 1065.5748\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1333.3114 - val_loss: 1055.3762\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1319.9525 - val_loss: 1041.8799\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1305.3557 - val_loss: 1028.8433\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1290.8933 - val_loss: 1016.1655\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1276.8674 - val_loss: 1003.8925\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1263.2614 - val_loss: 991.9684\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1250.0077 - val_loss: 980.3338\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1237.0482 - val_loss: 968.9445\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1224.3386 - val_loss: 957.7660\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1211.8455 - val_loss: 946.7742\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1199.5460 - val_loss: 935.9518\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1187.4205 - val_loss: 925.2828\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1175.4546 - val_loss: 914.7562\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1163.6375 - val_loss: 904.3629\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1151.9602 - val_loss: 894.0961\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1140.4143 - val_loss: 883.9493\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1128.9939 - val_loss: 873.9178\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1117.6934 - val_loss: 863.9961\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1106.5083 - val_loss: 854.1804\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1095.4343 - val_loss: 844.4674\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1084.4677 - val_loss: 834.8544\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1073.6055 - val_loss: 825.3383\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1062.8445 - val_loss: 815.9167\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1052.1829 - val_loss: 806.5873\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1041.6174 - val_loss: 797.3478\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1031.1462 - val_loss: 788.1970\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1020.7681 - val_loss: 779.1335\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1010.4808 - val_loss: 770.1552\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1000.2821 - val_loss: 761.2599\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 990.1713 - val_loss: 752.4479\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 980.1471 - val_loss: 743.7172\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 970.2076 - val_loss: 735.0659\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 960.3517 - val_loss: 726.4940\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 950.5782 - val_loss: 717.9996\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 940.8860 - val_loss: 709.5815\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 931.2738 - val_loss: 701.2399\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 921.7413 - val_loss: 692.9734\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 912.2875 - val_loss: 684.7810\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 902.9109 - val_loss: 676.6617\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 893.6111 - val_loss: 668.6149\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 884.3871 - val_loss: 660.6404\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 875.2384 - val_loss: 652.7373\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 866.1639 - val_loss: 644.9034\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 857.1632 - val_loss: 637.1406\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 848.2349 - val_loss: 629.4465\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 839.3793 - val_loss: 621.8205\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 830.5952 - val_loss: 614.2625\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 821.8822 - val_loss: 606.7722\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 813.2396 - val_loss: 599.3483\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 804.6670 - val_loss: 591.9911\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 796.1636 - val_loss: 584.6989\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 787.7288 - val_loss: 577.4727\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 779.3623 - val_loss: 570.3105\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 771.0634 - val_loss: 563.2125\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 762.8314 - val_loss: 556.1786\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 754.6663 - val_loss: 549.2072\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 746.5673 - val_loss: 542.2992\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 738.5338 - val_loss: 535.4534\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 730.5654 - val_loss: 528.6693\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 722.6622 - val_loss: 521.9465\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 714.8230 - val_loss: 515.2853\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 707.0480 - val_loss: 508.6843\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 699.3361 - val_loss: 502.1430\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 691.6873 - val_loss: 495.6617\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 684.1010 - val_loss: 489.2396\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 676.5768 - val_loss: 482.8770\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 669.1145 - val_loss: 476.5721\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 661.7139 - val_loss: 470.3260\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 654.3746 - val_loss: 464.1379\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 647.0956 - val_loss: 458.0071\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 639.8772 - val_loss: 451.9331\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 632.7182 - val_loss: 445.9164\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 625.6189 - val_loss: 439.9552\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 618.5785 - val_loss: 434.0507\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 611.5973 - val_loss: 428.2016\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 604.6744 - val_loss: 422.4078\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 597.8097 - val_loss: 416.6689\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 591.0026 - val_loss: 410.9843\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 584.2527 - val_loss: 405.3540\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 577.5598 - val_loss: 399.7779\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 570.9241 - val_loss: 394.2553\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 564.3448 - val_loss: 388.7864\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 557.8213 - val_loss: 383.3700\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 551.3535 - val_loss: 378.0066\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 544.9413 - val_loss: 372.6953\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 538.5841 - val_loss: 367.4360\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 532.2820 - val_loss: 362.2281\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 526.0340 - val_loss: 357.0718\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 519.8400 - val_loss: 351.9664\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 513.7000 - val_loss: 346.9118\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 507.6137 - val_loss: 341.9076\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 501.5806 - val_loss: 336.9536\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 495.6001 - val_loss: 332.0497\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 489.6725 - val_loss: 327.1950\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 483.7972 - val_loss: 322.3894\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 477.9738 - val_loss: 317.6335\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 472.2025 - val_loss: 312.9254\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 466.4822 - val_loss: 308.2663\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 460.8136 - val_loss: 303.6548\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 455.1956 - val_loss: 299.0914\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 449.6280 - val_loss: 294.5751\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 444.1108 - val_loss: 290.1064\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 438.6435 - val_loss: 285.6845\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 433.2261 - val_loss: 281.3090\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 427.8577 - val_loss: 276.9797\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 422.5387 - val_loss: 272.6965\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 417.2686 - val_loss: 268.4594\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 412.0468 - val_loss: 264.2673\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 406.8734 - val_loss: 260.1205\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 401.7482 - val_loss: 256.0187\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 396.6705 - val_loss: 251.9618\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 391.6405 - val_loss: 247.9488\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 386.6576 - val_loss: 243.9799\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 381.7215 - val_loss: 240.0556\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 376.8323 - val_loss: 236.1741\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 371.9894 - val_loss: 232.3360\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 367.1926 - val_loss: 228.5410\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 362.4417 - val_loss: 224.7884\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 357.7363 - val_loss: 221.0787\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 353.0763 - val_loss: 217.4111\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 348.4613 - val_loss: 213.7851\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 343.8911 - val_loss: 210.2008\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 339.3652 - val_loss: 206.6585\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 334.8837 - val_loss: 203.1563\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 330.4463 - val_loss: 199.6956\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 326.0522 - val_loss: 196.2749\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 321.7017 - val_loss: 192.8949\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 317.3943 - val_loss: 189.5544\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 313.1299 - val_loss: 186.2544\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 308.9084 - val_loss: 182.9937\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 304.7293 - val_loss: 179.7724\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 300.5922 - val_loss: 176.5896\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 296.4971 - val_loss: 173.4462\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 292.4436 - val_loss: 170.3403\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 288.4314 - val_loss: 167.2733\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 284.4606 - val_loss: 164.2444\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 280.5308 - val_loss: 161.2529\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 276.6414 - val_loss: 158.2988\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 272.7922 - val_loss: 155.3818\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 268.9834 - val_loss: 152.5019\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 265.2143 - val_loss: 149.6584\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 261.4846 - val_loss: 146.8510\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 257.7944 - val_loss: 144.0802\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 254.1434 - val_loss: 141.3450\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 250.5312 - val_loss: 138.6458\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 246.9576 - val_loss: 135.9817\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 243.4225 - val_loss: 133.3524\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 239.9253 - val_loss: 130.7583\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 236.4661 - val_loss: 128.1992\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 233.0446 - val_loss: 125.6740\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 229.6603 - val_loss: 123.1829\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 226.3132 - val_loss: 120.7257\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 223.0030 - val_loss: 118.3017\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 219.7290 - val_loss: 115.9112\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 216.4917 - val_loss: 113.5538\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 213.2904 - val_loss: 111.2290\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 210.1248 - val_loss: 108.9374\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 206.9953 - val_loss: 106.6775\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 203.9007 - val_loss: 104.4497\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 200.8412 - val_loss: 102.2540\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 197.8169 - val_loss: 100.0896\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 194.8271 - val_loss: 97.9567\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 191.8718 - val_loss: 95.8550\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 188.9507 - val_loss: 93.7841\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 186.0636 - val_loss: 91.7434\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 183.2101 - val_loss: 89.7331\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 180.3900 - val_loss: 87.7532\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 177.6031 - val_loss: 85.8028\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 174.8490 - val_loss: 83.8823\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 172.1278 - val_loss: 81.9912\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 169.4391 - val_loss: 80.1287\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 166.7825 - val_loss: 78.2954\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 164.1581 - val_loss: 76.4906\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 161.5653 - val_loss: 74.7140\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 159.0040 - val_loss: 72.9655\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 156.4738 - val_loss: 71.2449\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 153.9749 - val_loss: 69.5519\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 151.5068 - val_loss: 67.8864\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 149.0691 - val_loss: 66.2481\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 146.6617 - val_loss: 64.6365\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 144.2844 - val_loss: 63.0515\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 141.9371 - val_loss: 61.4929\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 139.6194 - val_loss: 59.9609\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 137.3311 - val_loss: 58.4544\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 135.0718 - val_loss: 56.9735\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 132.8415 - val_loss: 55.5182\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 130.6398 - val_loss: 54.0883\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 128.4667 - val_loss: 52.6831\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 126.3218 - val_loss: 51.3027\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 124.2048 - val_loss: 49.9468\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 122.1156 - val_loss: 48.6152\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 120.0541 - val_loss: 47.3076\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 118.0196 - val_loss: 46.0239\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 116.0124 - val_loss: 44.7635\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 114.0317 - val_loss: 43.5264\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 112.0777 - val_loss: 42.3124\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 110.1501 - val_loss: 41.1211\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 108.2485 - val_loss: 39.9529\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 106.3731 - val_loss: 38.8068\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 104.5233 - val_loss: 37.6829\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 102.6991 - val_loss: 36.5808\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 100.9001 - val_loss: 35.5004\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 99.1259 - val_loss: 34.4413\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 97.3765 - val_loss: 33.4037\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 95.6517 - val_loss: 32.3870\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 93.9514 - val_loss: 31.3911\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 92.2751 - val_loss: 30.4157\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 90.6227 - val_loss: 29.4605\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 88.9940 - val_loss: 28.5256\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 87.3887 - val_loss: 27.6103\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 85.8066 - val_loss: 26.7148\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 84.2476 - val_loss: 25.8385\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 82.7112 - val_loss: 24.9816\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 81.1975 - val_loss: 24.1435\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 79.7062 - val_loss: 23.3243\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 78.2370 - val_loss: 22.5236\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 76.7898 - val_loss: 21.7411\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 75.3642 - val_loss: 20.9767\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 73.9601 - val_loss: 20.2301\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 72.5773 - val_loss: 19.5014\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 71.2157 - val_loss: 18.7899\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 69.8749 - val_loss: 18.0956\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 68.5546 - val_loss: 17.4184\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 67.2547 - val_loss: 16.7579\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 65.9751 - val_loss: 16.1139\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 64.7154 - val_loss: 15.4863\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 63.4755 - val_loss: 14.8747\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 62.2552 - val_loss: 14.2790\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 61.0542 - val_loss: 13.6992\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 59.8725 - val_loss: 13.1348\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 58.7096 - val_loss: 12.5856\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 57.5656 - val_loss: 12.0516\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 56.4400 - val_loss: 11.5323\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 55.3327 - val_loss: 11.0277\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 54.2435 - val_loss: 10.5376\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 53.1724 - val_loss: 10.0618\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 52.1189 - val_loss: 9.6000\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 51.0830 - val_loss: 9.1520\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 50.0643 - val_loss: 8.7176\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 49.0628 - val_loss: 8.2967\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 48.0782 - val_loss: 7.8891\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 47.1104 - val_loss: 7.4944\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 46.1590 - val_loss: 7.1127\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 45.2240 - val_loss: 6.7435\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 44.3051 - val_loss: 6.3867\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 43.4023 - val_loss: 6.0423\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 42.5150 - val_loss: 5.7099\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 41.6435 - val_loss: 5.3894\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 40.7873 - val_loss: 5.0805\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 39.9462 - val_loss: 4.7832\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 39.1202 - val_loss: 4.4971\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 38.3089 - val_loss: 4.2221\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 37.5122 - val_loss: 3.9581\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 36.7300 - val_loss: 3.7048\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 35.9620 - val_loss: 3.4621\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 35.2082 - val_loss: 3.2297\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 34.4680 - val_loss: 3.0075\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 33.7417 - val_loss: 2.7953\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 33.0289 - val_loss: 2.5930\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 32.3295 - val_loss: 2.4003\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 31.6431 - val_loss: 2.2171\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 30.9698 - val_loss: 2.0432\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 30.3092 - val_loss: 1.8784\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 29.6613 - val_loss: 1.7225\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 29.0258 - val_loss: 1.5754\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 28.4026 - val_loss: 1.4370\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 27.7915 - val_loss: 1.3070\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 27.1924 - val_loss: 1.1853\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 26.6051 - val_loss: 1.0716\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 26.0293 - val_loss: 0.9659\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.82098740e+01, 7.81846639e+01, 7.81594538e+01, 7.81342437e+01,\n",
       "        7.81090336e+01, 7.80838235e+01, 7.80586134e+01, 7.80334034e+01,\n",
       "        7.80081933e+01, 7.79829832e+01, 7.79577731e+01, 7.79325630e+01,\n",
       "        7.79073529e+01, 7.78682540e+01, 7.78234360e+01, 7.77786181e+01,\n",
       "        7.77338002e+01, 7.76889823e+01, 7.76441643e+01, 7.75993464e+01,\n",
       "        7.75545285e+01, 7.75097105e+01, 7.74648926e+01, 7.74200747e+01,\n",
       "        7.73752568e+01, 7.73304388e+01, 7.72856209e+01, 7.72408030e+01,\n",
       "        7.71959851e+01, 7.71511671e+01, 7.71063492e+01, 7.70615313e+01,\n",
       "        7.70167134e+01, 7.69718954e+01, 7.69270775e+01, 7.68822596e+01,\n",
       "        7.68374416e+01, 7.67926237e+01, 7.67478058e+01, 7.67029879e+01,\n",
       "        7.66581699e+01, 7.66133520e+01, 7.65685341e+01, 7.65237161e+01,\n",
       "        7.64788982e+01, 7.64340803e+01, 7.63892624e+01, 7.63444444e+01,\n",
       "        7.62998133e+01, 7.62774043e+01, 7.62549953e+01, 7.62325864e+01,\n",
       "        7.62101774e+01, 7.61877684e+01, 7.61653595e+01, 7.61429505e+01,\n",
       "        7.61205415e+01, 7.60981326e+01, 7.60757236e+01, 7.60533147e+01,\n",
       "        7.60309057e+01, 7.60084967e+01, 7.59860878e+01, 7.59636788e+01,\n",
       "        7.59412698e+01, 7.59188609e+01, 7.58964519e+01, 7.58740430e+01,\n",
       "        7.58516340e+01, 7.58292250e+01, 7.58068161e+01, 7.57844071e+01,\n",
       "        7.57619981e+01, 7.57395892e+01, 7.57171802e+01, 7.56947712e+01,\n",
       "        7.56723623e+01, 7.56499533e+01, 7.56275443e+01, 7.56051354e+01,\n",
       "        7.54206314e+01, 1.33370146e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 9.74150002e-01, 9.95775312e-03, 3.10590327e-01,\n",
       "        3.55119079e-01, 0.00000000e+00, 0.00000000e+00, 7.64558315e-01,\n",
       "        0.00000000e+00, 3.39932404e-02, 1.19662857e+00, 0.00000000e+00,\n",
       "        1.07672811e-01, 0.00000000e+00, 0.00000000e+00, 3.69773686e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([74.36378618, 74.36135854, 74.35893091, 74.35650327, 74.35407563,\n",
       "       74.35164799, 74.34922035, 74.34679272, 74.34436508, 74.34193744,\n",
       "       74.3395098 , 74.33708217, 74.33465453, 74.33222689, 74.32979925,\n",
       "       74.32737162, 74.32494398, 74.32251634, 74.3200887 , 74.31766106,\n",
       "       74.31523343, 74.31280579, 74.31037815, 74.30795051, 74.30552288,\n",
       "       74.30309524, 74.3006676 , 74.29661531, 74.29194678, 74.28727824,\n",
       "       74.28260971, 74.27794118, 74.27327264, 74.26860411, 74.26393557,\n",
       "       74.25926704, 74.25459851, 74.24992997, 74.24526144, 74.2405929 ,\n",
       "       74.23592437, 74.23125584, 74.2265873 , 74.22191877, 74.21725023,\n",
       "       74.2125817 , 74.20791317, 74.20324463, 74.1985761 , 74.19390756,\n",
       "       74.18923903, 74.18457049, 74.17990196, 74.17523343, 74.17056489,\n",
       "       74.16589636, 74.16122782, 74.15655929, 74.15189076, 74.14722222,\n",
       "       74.14255369, 74.13788515, 74.13321662, 74.12854809, 74.12387955,\n",
       "       74.11921102, 74.11454248, 74.10987395, 74.10520542, 74.10053688,\n",
       "       74.09586835, 74.09119981, 74.08653128, 74.08186275, 74.07719421,\n",
       "       74.07252568, 74.06785714, 74.06318861, 74.05852007, 74.05385154,\n",
       "       74.04918301, 74.04451447, 74.03984594, 74.0351774 , 74.03050887,\n",
       "       74.02584034, 74.0211718 , 74.01650327, 74.01183473, 74.0071662 ,\n",
       "       74.00249767, 73.99782913, 73.9931606 , 73.98849206, 73.98382353,\n",
       "       73.979155  , 73.97448646, 73.96981793, 73.96514939, 73.96048086])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.248909341277816\n",
      "16.088689678185077\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
