{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "1645    71.755719\n",
       "1646    71.754785\n",
       "1647    71.753852\n",
       "1648    71.752918\n",
       "1649    71.751984\n",
       "Name: C3, Length: 1650, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_1550_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "1545     0.000000\n",
       "1546     0.242449\n",
       "1547     0.000000\n",
       "1548     0.000000\n",
       "1549     0.000000\n",
       "Name: C3, Length: 1550, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1550)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 1, 251) (1100, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "14/14 [==============================] - 2s 36ms/step - loss: 6012.9521 - val_loss: 4952.4990\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5935.2852 - val_loss: 4900.7148\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5871.9414 - val_loss: 4840.4629\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5805.6362 - val_loss: 4787.4570\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5744.7471 - val_loss: 4734.9331\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5684.4604 - val_loss: 4683.0039\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5624.7949 - val_loss: 4631.6333\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5565.7104 - val_loss: 4580.7856\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 5507.1680 - val_loss: 4530.4336\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5449.1436 - val_loss: 4480.5596\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5391.6191 - val_loss: 4431.1504\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5334.5801 - val_loss: 4382.1953\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 5278.0195 - val_loss: 4333.6870\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5221.9268 - val_loss: 4285.6201\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5166.2949 - val_loss: 4237.9868\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5111.1216 - val_loss: 4190.7832\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5056.3984 - val_loss: 4144.0049\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5002.1235 - val_loss: 4097.6479\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4948.2891 - val_loss: 4051.7090\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4894.8950 - val_loss: 4006.1843\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4841.9360 - val_loss: 3961.0701\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4789.4102 - val_loss: 3916.3635\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4737.3115 - val_loss: 3872.0623\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4685.6387 - val_loss: 3828.1619\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4634.3882 - val_loss: 3784.6604\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4583.5566 - val_loss: 3741.5552\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4533.1436 - val_loss: 3698.8433\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4483.1426 - val_loss: 3656.5212\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4433.5542 - val_loss: 3614.5881\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4384.3735 - val_loss: 3573.0398\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4335.5986 - val_loss: 3531.8748\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4287.2280 - val_loss: 3491.0898\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4239.2568 - val_loss: 3450.6833\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4191.6846 - val_loss: 3410.6514\n",
      "Epoch 35/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4144.5078 - val_loss: 3370.9932\n",
      "Epoch 36/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4097.7246 - val_loss: 3331.7056\n",
      "Epoch 37/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4051.3323 - val_loss: 3292.7864\n",
      "Epoch 38/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4005.3279 - val_loss: 3254.2327\n",
      "Epoch 39/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3959.7102 - val_loss: 3216.0435\n",
      "Epoch 40/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3914.4756 - val_loss: 3178.2156\n",
      "Epoch 41/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3869.6233 - val_loss: 3140.7461\n",
      "Epoch 42/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3825.1492 - val_loss: 3103.6340\n",
      "Epoch 43/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3781.0520 - val_loss: 3066.8765\n",
      "Epoch 44/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3737.3293 - val_loss: 3030.4709\n",
      "Epoch 45/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 3693.9795 - val_loss: 2994.4165\n",
      "Epoch 46/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3650.9995 - val_loss: 2958.7095\n",
      "Epoch 47/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3608.3867 - val_loss: 2923.3484\n",
      "Epoch 48/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3566.1401 - val_loss: 2888.3318\n",
      "Epoch 49/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3524.2573 - val_loss: 2853.6558\n",
      "Epoch 50/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3482.7356 - val_loss: 2819.3196\n",
      "Epoch 51/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3441.5728 - val_loss: 2785.3213\n",
      "Epoch 52/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3400.7671 - val_loss: 2751.6577\n",
      "Epoch 53/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3360.3162 - val_loss: 2718.3279\n",
      "Epoch 54/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3320.2185 - val_loss: 2685.3284\n",
      "Epoch 55/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3280.4707 - val_loss: 2652.6582\n",
      "Epoch 56/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3241.0718 - val_loss: 2620.3149\n",
      "Epoch 57/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3202.0195 - val_loss: 2588.2964\n",
      "Epoch 58/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3163.3120 - val_loss: 2556.6008\n",
      "Epoch 59/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3124.9465 - val_loss: 2525.2268\n",
      "Epoch 60/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3086.9216 - val_loss: 2494.1716\n",
      "Epoch 61/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3049.2349 - val_loss: 2463.4326\n",
      "Epoch 62/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3011.8843 - val_loss: 2433.0088\n",
      "Epoch 63/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2974.8682 - val_loss: 2402.8982\n",
      "Epoch 64/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2938.1846 - val_loss: 2373.0984\n",
      "Epoch 65/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2901.8313 - val_loss: 2343.6079\n",
      "Epoch 66/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2865.8066 - val_loss: 2314.4243\n",
      "Epoch 67/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2830.1079 - val_loss: 2285.5449\n",
      "Epoch 68/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2794.7336 - val_loss: 2256.9700\n",
      "Epoch 69/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2759.6821 - val_loss: 2228.6960\n",
      "Epoch 70/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2724.9507 - val_loss: 2200.7212\n",
      "Epoch 71/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2690.5378 - val_loss: 2173.0444\n",
      "Epoch 72/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2656.4426 - val_loss: 2145.6626\n",
      "Epoch 73/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2622.6621 - val_loss: 2118.5750\n",
      "Epoch 74/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 2589.1943 - val_loss: 2091.7793\n",
      "Epoch 75/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2556.0378 - val_loss: 2065.2732\n",
      "Epoch 76/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2523.1904 - val_loss: 2039.0554\n",
      "Epoch 77/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2490.6504 - val_loss: 2013.1239\n",
      "Epoch 78/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2458.4160 - val_loss: 1987.4773\n",
      "Epoch 79/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2426.4858 - val_loss: 1962.1132\n",
      "Epoch 80/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2394.8569 - val_loss: 1937.0295\n",
      "Epoch 81/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2363.5281 - val_loss: 1912.2255\n",
      "Epoch 82/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2332.4976 - val_loss: 1887.6982\n",
      "Epoch 83/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2301.7634 - val_loss: 1863.4473\n",
      "Epoch 84/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2271.3242 - val_loss: 1839.4688\n",
      "Epoch 85/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2241.1770 - val_loss: 1815.7622\n",
      "Epoch 86/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2211.3215 - val_loss: 1792.3264\n",
      "Epoch 87/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2181.7549 - val_loss: 1769.1587\n",
      "Epoch 88/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2152.4763 - val_loss: 1746.2574\n",
      "Epoch 89/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2123.4827 - val_loss: 1723.6205\n",
      "Epoch 90/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2094.7737 - val_loss: 1701.2473\n",
      "Epoch 91/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2066.3467 - val_loss: 1679.1353\n",
      "Epoch 92/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2038.2002 - val_loss: 1657.2827\n",
      "Epoch 93/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2010.3324 - val_loss: 1635.6884\n",
      "Epoch 94/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1982.7416 - val_loss: 1614.3495\n",
      "Epoch 95/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1955.4263 - val_loss: 1593.2657\n",
      "Epoch 96/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1928.3844 - val_loss: 1572.4340\n",
      "Epoch 97/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1901.6146 - val_loss: 1551.8540\n",
      "Epoch 98/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1875.1149 - val_loss: 1531.5232\n",
      "Epoch 99/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1848.8838 - val_loss: 1511.4393\n",
      "Epoch 100/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1822.9192 - val_loss: 1491.6017\n",
      "Epoch 101/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1797.2196 - val_loss: 1472.0079\n",
      "Epoch 102/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1771.7836 - val_loss: 1452.6580\n",
      "Epoch 103/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1746.6097 - val_loss: 1433.5479\n",
      "Epoch 104/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1721.6963 - val_loss: 1414.6772\n",
      "Epoch 105/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1697.0408 - val_loss: 1396.0450\n",
      "Epoch 106/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1672.6427 - val_loss: 1377.6475\n",
      "Epoch 107/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1648.4993 - val_loss: 1359.4850\n",
      "Epoch 108/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1624.6100 - val_loss: 1341.5549\n",
      "Epoch 109/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1600.9719 - val_loss: 1323.8566\n",
      "Epoch 110/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1577.5848 - val_loss: 1306.3866\n",
      "Epoch 111/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1554.4462 - val_loss: 1289.1451\n",
      "Epoch 112/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1531.5553 - val_loss: 1272.1299\n",
      "Epoch 113/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1508.9094 - val_loss: 1255.3386\n",
      "Epoch 114/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1486.5077 - val_loss: 1238.7714\n",
      "Epoch 115/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1464.3483 - val_loss: 1222.4243\n",
      "Epoch 116/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1442.4294 - val_loss: 1206.2977\n",
      "Epoch 117/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1420.7493 - val_loss: 1190.3885\n",
      "Epoch 118/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1399.3070 - val_loss: 1174.6963\n",
      "Epoch 119/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1378.1008 - val_loss: 1159.2191\n",
      "Epoch 120/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1357.1290 - val_loss: 1143.9545\n",
      "Epoch 121/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1336.3900 - val_loss: 1128.9027\n",
      "Epoch 122/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1315.8822 - val_loss: 1114.0602\n",
      "Epoch 123/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1295.6040 - val_loss: 1099.4272\n",
      "Epoch 124/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1275.5543 - val_loss: 1085.0009\n",
      "Epoch 125/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1255.7314 - val_loss: 1070.7800\n",
      "Epoch 126/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1236.1329 - val_loss: 1056.7633\n",
      "Epoch 127/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1216.7587 - val_loss: 1042.9487\n",
      "Epoch 128/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1197.6062 - val_loss: 1029.3352\n",
      "Epoch 129/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1178.6742 - val_loss: 1015.9211\n",
      "Epoch 130/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1159.9611 - val_loss: 1002.7043\n",
      "Epoch 131/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1141.4656 - val_loss: 989.6842\n",
      "Epoch 132/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1123.1860 - val_loss: 976.8586\n",
      "Epoch 133/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1105.1207 - val_loss: 964.2258\n",
      "Epoch 134/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1087.2688 - val_loss: 951.7852\n",
      "Epoch 135/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1069.6278 - val_loss: 939.5346\n",
      "Epoch 136/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1052.1973 - val_loss: 927.4724\n",
      "Epoch 137/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1034.9746 - val_loss: 915.5970\n",
      "Epoch 138/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1017.9592 - val_loss: 903.9072\n",
      "Epoch 139/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1001.1494 - val_loss: 892.4020\n",
      "Epoch 140/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 984.5433 - val_loss: 881.0789\n",
      "Epoch 141/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 968.1398 - val_loss: 869.9371\n",
      "Epoch 142/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 951.9376 - val_loss: 858.9745\n",
      "Epoch 143/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 935.9346 - val_loss: 848.1899\n",
      "Epoch 144/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 920.1297 - val_loss: 837.5818\n",
      "Epoch 145/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 904.5213 - val_loss: 827.1489\n",
      "Epoch 146/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 889.1083 - val_loss: 816.8893\n",
      "Epoch 147/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 873.8888 - val_loss: 806.8014\n",
      "Epoch 148/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 858.8616 - val_loss: 796.8849\n",
      "Epoch 149/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 844.0253 - val_loss: 787.1368\n",
      "Epoch 150/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 829.3784 - val_loss: 777.5563\n",
      "Epoch 151/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 814.9190 - val_loss: 768.1422\n",
      "Epoch 152/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 800.6463 - val_loss: 758.8926\n",
      "Epoch 153/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 786.5585 - val_loss: 749.8061\n",
      "Epoch 154/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 772.6545 - val_loss: 740.8812\n",
      "Epoch 155/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 758.9324 - val_loss: 732.1163\n",
      "Epoch 156/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 745.3911 - val_loss: 723.5109\n",
      "Epoch 157/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 732.0291 - val_loss: 715.0620\n",
      "Epoch 158/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 718.8450 - val_loss: 706.7692\n",
      "Epoch 159/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 705.8372 - val_loss: 698.6310\n",
      "Epoch 160/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 693.0045 - val_loss: 690.6458\n",
      "Epoch 161/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 680.3456 - val_loss: 682.8115\n",
      "Epoch 162/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 667.8588 - val_loss: 675.1276\n",
      "Epoch 163/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 655.5426 - val_loss: 667.5924\n",
      "Epoch 164/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 643.3960 - val_loss: 660.2040\n",
      "Epoch 165/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 631.4175 - val_loss: 652.9613\n",
      "Epoch 166/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 619.6053 - val_loss: 645.8629\n",
      "Epoch 167/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 607.9580 - val_loss: 638.9075\n",
      "Epoch 168/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 596.4753 - val_loss: 632.0934\n",
      "Epoch 169/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 585.1546 - val_loss: 625.4192\n",
      "Epoch 170/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 573.9950 - val_loss: 618.8834\n",
      "Epoch 171/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 562.9951 - val_loss: 612.4853\n",
      "Epoch 172/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 552.1535 - val_loss: 606.2225\n",
      "Epoch 173/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 541.4687 - val_loss: 600.0937\n",
      "Epoch 174/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 530.9395 - val_loss: 594.0981\n",
      "Epoch 175/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 520.5646 - val_loss: 588.2338\n",
      "Epoch 176/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 510.3420 - val_loss: 582.4995\n",
      "Epoch 177/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 500.2709 - val_loss: 576.8938\n",
      "Epoch 178/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 490.3498 - val_loss: 571.4152\n",
      "Epoch 179/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 480.5775 - val_loss: 566.0624\n",
      "Epoch 180/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 470.9527 - val_loss: 560.8341\n",
      "Epoch 181/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 461.4737 - val_loss: 555.7287\n",
      "Epoch 182/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 452.1393 - val_loss: 550.7449\n",
      "Epoch 183/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 442.9480 - val_loss: 545.8813\n",
      "Epoch 184/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 433.8988 - val_loss: 541.1365\n",
      "Epoch 185/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 424.9901 - val_loss: 536.5090\n",
      "Epoch 186/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 416.2205 - val_loss: 531.9979\n",
      "Epoch 187/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 407.5891 - val_loss: 527.6010\n",
      "Epoch 188/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 399.0940 - val_loss: 523.3175\n",
      "Epoch 189/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 390.7339 - val_loss: 519.1459\n",
      "Epoch 190/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 382.5081 - val_loss: 515.0848\n",
      "Epoch 191/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 374.4145 - val_loss: 511.1330\n",
      "Epoch 192/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 366.4523 - val_loss: 507.2887\n",
      "Epoch 193/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 358.6199 - val_loss: 503.5510\n",
      "Epoch 194/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 350.9160 - val_loss: 499.9181\n",
      "Epoch 195/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 343.3394 - val_loss: 496.3889\n",
      "Epoch 196/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 335.8888 - val_loss: 492.9621\n",
      "Epoch 197/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 328.5629 - val_loss: 489.6364\n",
      "Epoch 198/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 321.3603 - val_loss: 486.4101\n",
      "Epoch 199/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 314.2796 - val_loss: 483.2822\n",
      "Epoch 200/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 307.3194 - val_loss: 480.2510\n",
      "Epoch 201/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 300.4790 - val_loss: 477.3157\n",
      "Epoch 202/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 293.7569 - val_loss: 474.4745\n",
      "Epoch 203/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 287.1514 - val_loss: 471.7263\n",
      "Epoch 204/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 280.6617 - val_loss: 469.0697\n",
      "Epoch 205/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 274.2863 - val_loss: 466.5033\n",
      "Epoch 206/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 268.0237 - val_loss: 464.0259\n",
      "Epoch 207/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 261.8730 - val_loss: 461.6361\n",
      "Epoch 208/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 255.8325 - val_loss: 459.3326\n",
      "Epoch 209/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 249.9015 - val_loss: 457.1141\n",
      "Epoch 210/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 244.0783 - val_loss: 454.9794\n",
      "Epoch 211/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 238.3620 - val_loss: 452.9271\n",
      "Epoch 212/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 232.7510 - val_loss: 450.9559\n",
      "Epoch 213/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 227.2441 - val_loss: 449.0645\n",
      "Epoch 214/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 221.8401 - val_loss: 447.2516\n",
      "Epoch 215/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 216.5379 - val_loss: 445.5161\n",
      "Epoch 216/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 211.3362 - val_loss: 443.8566\n",
      "Epoch 217/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 206.2336 - val_loss: 442.2717\n",
      "Epoch 218/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 201.2291 - val_loss: 440.7602\n",
      "Epoch 219/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 196.3210 - val_loss: 439.3209\n",
      "Epoch 220/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 191.5088 - val_loss: 437.9525\n",
      "Epoch 221/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 186.7907 - val_loss: 436.6539\n",
      "Epoch 222/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 182.1658 - val_loss: 435.4236\n",
      "Epoch 223/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 177.6328 - val_loss: 434.2607\n",
      "Epoch 224/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 173.1906 - val_loss: 433.1636\n",
      "Epoch 225/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 168.8379 - val_loss: 432.1312\n",
      "Epoch 226/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 164.5733 - val_loss: 431.1624\n",
      "Epoch 227/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 160.3960 - val_loss: 430.2559\n",
      "Epoch 228/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 156.3046 - val_loss: 429.4104\n",
      "Epoch 229/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 152.2979 - val_loss: 428.6246\n",
      "Epoch 230/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 148.3748 - val_loss: 427.8976\n",
      "Epoch 231/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 144.5341 - val_loss: 427.2283\n",
      "Epoch 232/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 140.7745 - val_loss: 426.6151\n",
      "Epoch 233/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 137.0952 - val_loss: 426.0569\n",
      "Epoch 234/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 133.4948 - val_loss: 425.5530\n",
      "Epoch 235/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 129.9723 - val_loss: 425.1016\n",
      "Epoch 236/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 126.5266 - val_loss: 424.7020\n",
      "Epoch 237/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 123.1562 - val_loss: 424.3526\n",
      "Epoch 238/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 119.8602 - val_loss: 424.0526\n",
      "Epoch 239/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 116.6375 - val_loss: 423.8010\n",
      "Epoch 240/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 113.4870 - val_loss: 423.5963\n",
      "Epoch 241/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 110.4074 - val_loss: 423.4377\n",
      "Epoch 242/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 107.3980 - val_loss: 423.3238\n",
      "Epoch 243/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 104.4575 - val_loss: 423.2537\n",
      "Epoch 244/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 101.5845 - val_loss: 423.2263\n",
      "Epoch 245/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 98.7785 - val_loss: 423.2403\n",
      "Epoch 246/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 96.0381 - val_loss: 423.2948\n",
      "Epoch 247/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 93.3623 - val_loss: 423.3888\n",
      "Epoch 248/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 90.7501 - val_loss: 423.5210\n",
      "Epoch 249/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 88.2002 - val_loss: 423.6906\n",
      "Epoch 250/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 85.7116 - val_loss: 423.8964\n",
      "Epoch 251/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 83.2835 - val_loss: 424.1374\n",
      "Epoch 252/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 80.9148 - val_loss: 424.4126\n",
      "Epoch 253/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 78.6043 - val_loss: 424.7209\n",
      "Epoch 254/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 76.3512 - val_loss: 425.0614\n",
      "Epoch 255/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 74.1542 - val_loss: 425.4331\n",
      "Epoch 256/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 72.0126 - val_loss: 425.8350\n",
      "Epoch 257/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 69.9253 - val_loss: 426.2661\n",
      "Epoch 258/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 67.8912 - val_loss: 426.7254\n",
      "Epoch 259/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 65.9096 - val_loss: 427.2119\n",
      "Epoch 260/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 63.9794 - val_loss: 427.7248\n",
      "Epoch 261/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 62.0996 - val_loss: 428.2631\n",
      "Epoch 262/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 60.2693 - val_loss: 428.8259\n",
      "Epoch 263/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 58.4875 - val_loss: 429.4123\n",
      "Epoch 264/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 56.7533 - val_loss: 430.0213\n",
      "Epoch 265/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 55.0657 - val_loss: 430.6520\n",
      "Epoch 266/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 53.4239 - val_loss: 431.3036\n",
      "Epoch 267/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 51.8269 - val_loss: 431.9753\n",
      "Epoch 268/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 50.2739 - val_loss: 432.6662\n",
      "Epoch 269/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 48.7639 - val_loss: 433.3752\n",
      "Epoch 270/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 47.2963 - val_loss: 434.1018\n",
      "Epoch 271/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 45.8698 - val_loss: 434.8451\n",
      "Epoch 272/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 44.4839 - val_loss: 435.6041\n",
      "Epoch 273/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 43.1376 - val_loss: 436.3782\n",
      "Epoch 274/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 41.8300 - val_loss: 437.1665\n",
      "Epoch 275/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 40.5603 - val_loss: 437.9684\n",
      "Epoch 276/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 39.3279 - val_loss: 438.7828\n",
      "Epoch 277/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 38.1317 - val_loss: 439.6092\n",
      "Epoch 278/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 36.9710 - val_loss: 440.4469\n",
      "Epoch 279/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 35.8451 - val_loss: 441.2950\n",
      "Epoch 280/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 34.7531 - val_loss: 442.1530\n",
      "Epoch 281/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 33.6942 - val_loss: 443.0198\n",
      "Epoch 282/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 32.6678 - val_loss: 443.8951\n",
      "Epoch 283/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 31.6730 - val_loss: 444.7781\n",
      "Epoch 284/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 30.7091 - val_loss: 445.6682\n",
      "Epoch 285/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 29.7754 - val_loss: 446.5645\n",
      "Epoch 286/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 28.8711 - val_loss: 447.4667\n",
      "Epoch 287/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 27.9955 - val_loss: 448.3741\n",
      "Epoch 288/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 27.1480 - val_loss: 449.2857\n",
      "Epoch 289/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 26.3279 - val_loss: 450.2016\n",
      "Epoch 290/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 25.5343 - val_loss: 451.1206\n",
      "Epoch 291/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 24.7667 - val_loss: 452.0425\n",
      "Epoch 292/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 24.0244 - val_loss: 452.9663\n",
      "Epoch 293/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.3069 - val_loss: 453.8919\n",
      "Epoch 294/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 22.6135 - val_loss: 454.8184\n",
      "Epoch 295/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 21.9435 - val_loss: 455.7456\n",
      "Epoch 296/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 21.2962 - val_loss: 456.6727\n",
      "Epoch 297/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 20.6712 - val_loss: 457.5995\n",
      "Epoch 298/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 20.0678 - val_loss: 458.5254\n",
      "Epoch 299/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 19.4853 - val_loss: 459.4497\n",
      "Epoch 300/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.9233 - val_loss: 460.3725\n",
      "Epoch 301/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 18.3811 - val_loss: 461.2930\n",
      "Epoch 302/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.8581 - val_loss: 462.2104\n",
      "Epoch 303/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.3540 - val_loss: 463.1248\n",
      "Epoch 304/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 16.8681 - val_loss: 464.0356\n",
      "Epoch 305/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 16.3999 - val_loss: 464.9426\n",
      "Epoch 306/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 15.9489 - val_loss: 465.8451\n",
      "Epoch 307/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 15.5145 - val_loss: 466.7431\n",
      "Epoch 308/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 15.0963 - val_loss: 467.6359\n",
      "Epoch 309/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 14.6938 - val_loss: 468.5232\n",
      "Epoch 310/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.3066 - val_loss: 469.4051\n",
      "Epoch 311/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.9340 - val_loss: 470.2806\n",
      "Epoch 312/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 13.5758 - val_loss: 471.1499\n",
      "Epoch 313/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.2313 - val_loss: 472.0124\n",
      "Epoch 314/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.9004 - val_loss: 472.8681\n",
      "Epoch 315/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.5824 - val_loss: 473.7166\n",
      "Epoch 316/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 12.2770 - val_loss: 474.5575\n",
      "Epoch 317/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.9837 - val_loss: 475.3910\n",
      "Epoch 318/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.7022 - val_loss: 476.2162\n",
      "Epoch 319/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 11.4320 - val_loss: 477.0336\n",
      "Epoch 320/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 11.1729 - val_loss: 477.8425\n",
      "Epoch 321/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 10.9243 - val_loss: 478.6428\n",
      "Epoch 322/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 10.6860 - val_loss: 479.4341\n",
      "Epoch 323/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.4577 - val_loss: 480.2169\n",
      "Epoch 324/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 10.2389 - val_loss: 480.9902\n",
      "Epoch 325/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 10.0293 - val_loss: 481.7541\n",
      "Epoch 326/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 9.8287 - val_loss: 482.5088\n",
      "Epoch 327/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.6367 - val_loss: 483.2538\n",
      "Epoch 328/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 9.4529 - val_loss: 483.9893\n",
      "Epoch 329/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 9.2771 - val_loss: 484.7148\n",
      "Epoch 330/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 9.1090 - val_loss: 485.4305\n",
      "Epoch 331/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.9483 - val_loss: 486.1363\n",
      "Epoch 332/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.7947 - val_loss: 486.8317\n",
      "Epoch 333/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.6480 - val_loss: 487.5172\n",
      "Epoch 334/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.5079 - val_loss: 488.1920\n",
      "Epoch 335/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.3741 - val_loss: 488.8570\n",
      "Epoch 336/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.2465 - val_loss: 489.5112\n",
      "Epoch 337/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.1247 - val_loss: 490.1551\n",
      "Epoch 338/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.0085 - val_loss: 490.7887\n",
      "Epoch 339/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 7.8978 - val_loss: 491.4116\n",
      "Epoch 340/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 7.7922 - val_loss: 492.0244\n",
      "Epoch 341/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 7.6916 - val_loss: 492.6261\n",
      "Epoch 342/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 7.5958 - val_loss: 493.2177\n",
      "Epoch 343/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 7.5046 - val_loss: 493.7987\n",
      "Epoch 344/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 7.4177 - val_loss: 494.3692\n",
      "Epoch 345/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 7.3351 - val_loss: 494.9293\n",
      "Epoch 346/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 7.2565 - val_loss: 495.4787\n",
      "Epoch 347/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 7.1817 - val_loss: 496.0179\n",
      "Epoch 348/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 7.1107 - val_loss: 496.5466\n",
      "Epoch 349/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 7.0432 - val_loss: 497.0645\n",
      "Epoch 350/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.9791 - val_loss: 497.5729\n",
      "Epoch 351/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.9181 - val_loss: 498.0709\n",
      "Epoch 352/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 6.8603 - val_loss: 498.5589\n",
      "Epoch 353/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.8054 - val_loss: 499.0359\n",
      "Epoch 354/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.7533 - val_loss: 499.5032\n",
      "Epoch 355/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.7039 - val_loss: 499.9604\n",
      "Epoch 356/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 6.6572 - val_loss: 500.4080\n",
      "Epoch 357/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.6128 - val_loss: 500.8453\n",
      "Epoch 358/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.5708 - val_loss: 501.2733\n",
      "Epoch 359/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 6.5310 - val_loss: 501.6913\n",
      "Epoch 360/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.4933 - val_loss: 502.0997\n",
      "Epoch 361/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 6.4576 - val_loss: 502.4989\n",
      "Epoch 362/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 6.4238 - val_loss: 502.8887\n",
      "Epoch 363/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 6.3919 - val_loss: 503.2689\n",
      "Epoch 364/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 6.3617 - val_loss: 503.6405\n",
      "Epoch 365/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 6.3331 - val_loss: 504.0027\n",
      "Epoch 366/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.3062 - val_loss: 504.3561\n",
      "Epoch 367/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 6.2807 - val_loss: 504.7007\n",
      "Epoch 368/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.2566 - val_loss: 505.0365\n",
      "Epoch 369/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 6.2338 - val_loss: 505.3635\n",
      "Epoch 370/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 6.2124 - val_loss: 505.6827\n",
      "Epoch 371/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.1921 - val_loss: 505.9931\n",
      "Epoch 372/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.1730 - val_loss: 506.2954\n",
      "Epoch 373/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 6.1550 - val_loss: 506.5896\n",
      "Epoch 374/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 6.1380 - val_loss: 506.8756\n",
      "Epoch 375/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 6.1220 - val_loss: 507.1541\n",
      "Epoch 376/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 6.1069 - val_loss: 507.4248\n",
      "Epoch 377/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 6.0927 - val_loss: 507.6874\n",
      "Epoch 378/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.0793 - val_loss: 507.9433\n",
      "Epoch 379/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 6.0667 - val_loss: 508.1918\n",
      "Epoch 380/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 6.0548 - val_loss: 508.4333\n",
      "Epoch 381/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.0436 - val_loss: 508.6675\n",
      "Epoch 382/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.0331 - val_loss: 508.8948\n",
      "Epoch 383/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.0232 - val_loss: 509.1152\n",
      "Epoch 384/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 6.0139 - val_loss: 509.3294\n",
      "Epoch 385/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.0052 - val_loss: 509.5367\n",
      "Epoch 386/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.9969 - val_loss: 509.7379\n",
      "Epoch 387/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.9892 - val_loss: 509.9328\n",
      "Epoch 388/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 5.9819 - val_loss: 510.1218\n",
      "Epoch 389/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 5.9751 - val_loss: 510.3044\n",
      "Epoch 390/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.9687 - val_loss: 510.4816\n",
      "Epoch 391/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.9627 - val_loss: 510.6530\n",
      "Epoch 392/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.9570 - val_loss: 510.8188\n",
      "Epoch 393/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.9517 - val_loss: 510.9794\n",
      "Epoch 394/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.9467 - val_loss: 511.1344\n",
      "Epoch 395/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.9420 - val_loss: 511.2843\n",
      "Epoch 396/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.9376 - val_loss: 511.4293\n",
      "Epoch 397/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.9335 - val_loss: 511.5688\n",
      "Epoch 398/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 5.9296 - val_loss: 511.7038\n",
      "Epoch 399/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.9260 - val_loss: 511.8346\n",
      "Epoch 400/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.9226 - val_loss: 511.9599\n",
      "Epoch 401/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.9194 - val_loss: 512.0814\n",
      "Epoch 402/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.9164 - val_loss: 512.1986\n",
      "Epoch 403/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.9136 - val_loss: 512.3118\n",
      "Epoch 404/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.9109 - val_loss: 512.4204\n",
      "Epoch 405/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.9085 - val_loss: 512.5255\n",
      "Epoch 406/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.9061 - val_loss: 512.6255\n",
      "Epoch 407/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.9040 - val_loss: 512.7231\n",
      "Epoch 408/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 5.9020 - val_loss: 512.8165\n",
      "Epoch 409/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.9001 - val_loss: 512.9067\n",
      "Epoch 410/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8983 - val_loss: 512.9933\n",
      "Epoch 411/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8966 - val_loss: 513.0768\n",
      "Epoch 412/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8950 - val_loss: 513.1566\n",
      "Epoch 413/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8935 - val_loss: 513.2335\n",
      "Epoch 414/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8922 - val_loss: 513.3074\n",
      "Epoch 415/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8909 - val_loss: 513.3783\n",
      "Epoch 416/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8897 - val_loss: 513.4467\n",
      "Epoch 417/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8885 - val_loss: 513.5121\n",
      "Epoch 418/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8875 - val_loss: 513.5748\n",
      "Epoch 419/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8865 - val_loss: 513.6348\n",
      "Epoch 420/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8855 - val_loss: 513.6922\n",
      "Epoch 421/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8847 - val_loss: 513.7475\n",
      "Epoch 422/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8838 - val_loss: 513.7999\n",
      "Epoch 423/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 5.8831 - val_loss: 513.8506\n",
      "Epoch 424/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8824 - val_loss: 513.8992\n",
      "Epoch 425/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8817 - val_loss: 513.9453\n",
      "Epoch 426/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8811 - val_loss: 513.9899\n",
      "Epoch 427/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 5.8805 - val_loss: 514.0317\n",
      "Epoch 428/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 5.8800 - val_loss: 514.0726\n",
      "Epoch 429/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8795 - val_loss: 514.1108\n",
      "Epoch 430/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 5.8790 - val_loss: 514.1477\n",
      "Epoch 431/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 5.8786 - val_loss: 514.1827\n",
      "Epoch 432/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8782 - val_loss: 514.2163\n",
      "Epoch 433/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8778 - val_loss: 514.2484\n",
      "Epoch 434/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.8775 - val_loss: 514.2790\n",
      "Epoch 435/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.8771 - val_loss: 514.3083\n",
      "Epoch 436/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8768 - val_loss: 514.3362\n",
      "Epoch 437/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8765 - val_loss: 514.3624\n",
      "Epoch 438/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8763 - val_loss: 514.3877\n",
      "Epoch 439/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8760 - val_loss: 514.4114\n",
      "Epoch 440/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8758 - val_loss: 514.4343\n",
      "Epoch 441/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8756 - val_loss: 514.4559\n",
      "Epoch 442/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8754 - val_loss: 514.4762\n",
      "Epoch 443/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8753 - val_loss: 514.4954\n",
      "Epoch 444/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8751 - val_loss: 514.5139\n",
      "Epoch 445/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 5.8750 - val_loss: 514.5317\n",
      "Epoch 446/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.8749 - val_loss: 514.5484\n",
      "Epoch 447/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8748 - val_loss: 514.5644\n",
      "Epoch 448/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 5.8746 - val_loss: 514.5794\n",
      "Epoch 449/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 5.8745 - val_loss: 514.5934\n",
      "Epoch 450/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8745 - val_loss: 514.6066\n",
      "Epoch 451/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 5.8744 - val_loss: 514.6197\n",
      "Epoch 452/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 5.8743 - val_loss: 514.6313\n",
      "Epoch 453/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8743 - val_loss: 514.6428\n",
      "Epoch 454/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8743 - val_loss: 514.6533\n",
      "Epoch 455/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8742 - val_loss: 514.6633\n",
      "Epoch 456/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8742 - val_loss: 514.6729\n",
      "Epoch 457/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8742 - val_loss: 514.6818\n",
      "Epoch 458/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.8742 - val_loss: 514.6905\n",
      "Epoch 459/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8742 - val_loss: 514.6979\n",
      "Epoch 460/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8742 - val_loss: 514.7059\n",
      "Epoch 461/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8742 - val_loss: 514.7130\n",
      "Epoch 462/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.8742 - val_loss: 514.7192\n",
      "Epoch 463/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8742 - val_loss: 514.7256\n",
      "Epoch 464/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8743 - val_loss: 514.7313\n",
      "Epoch 465/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.8743 - val_loss: 514.7369\n",
      "Epoch 466/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 5.8743 - val_loss: 514.7419\n",
      "Epoch 467/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 5.8744 - val_loss: 514.7467\n",
      "Epoch 468/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8744 - val_loss: 514.7513\n",
      "Epoch 469/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8745 - val_loss: 514.7556\n",
      "Epoch 470/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8745 - val_loss: 514.7596\n",
      "Epoch 471/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8746 - val_loss: 514.7628\n",
      "Epoch 472/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8747 - val_loss: 514.7664\n",
      "Epoch 473/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8747 - val_loss: 514.7693\n",
      "Epoch 474/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.8748 - val_loss: 514.7722\n",
      "Epoch 475/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8749 - val_loss: 514.7750\n",
      "Epoch 476/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8749 - val_loss: 514.7776\n",
      "Epoch 477/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8750 - val_loss: 514.7795\n",
      "Epoch 478/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8751 - val_loss: 514.7820\n",
      "Epoch 479/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8752 - val_loss: 514.7841\n",
      "Epoch 480/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8752 - val_loss: 514.7859\n",
      "Epoch 481/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8753 - val_loss: 514.7874\n",
      "Epoch 482/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8754 - val_loss: 514.7889\n",
      "Epoch 483/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8755 - val_loss: 514.7900\n",
      "Epoch 484/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8756 - val_loss: 514.7915\n",
      "Epoch 485/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 5.8757 - val_loss: 514.7925\n",
      "Epoch 486/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 5.8758 - val_loss: 514.7938\n",
      "Epoch 487/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8759 - val_loss: 514.7947\n",
      "Epoch 488/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8760 - val_loss: 514.7953\n",
      "Epoch 489/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8761 - val_loss: 514.7962\n",
      "Epoch 490/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8762 - val_loss: 514.7968\n",
      "Epoch 491/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 5.8763 - val_loss: 514.7972\n",
      "Epoch 492/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8764 - val_loss: 514.7980\n",
      "Epoch 493/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8765 - val_loss: 514.7984\n",
      "Epoch 494/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8766 - val_loss: 514.7988\n",
      "Epoch 495/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8767 - val_loss: 514.7993\n",
      "Epoch 496/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8768 - val_loss: 514.7996\n",
      "Epoch 497/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8769 - val_loss: 514.7997\n",
      "Epoch 498/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8770 - val_loss: 514.8000\n",
      "Epoch 499/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8771 - val_loss: 514.8002\n",
      "Epoch 500/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.8773 - val_loss: 514.8002\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 410ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.50705929e+01, 7.50442624e+01, 7.50179318e+01, 7.49916013e+01,\n",
       "        7.49652708e+01, 7.49389402e+01, 7.49126097e+01, 7.48862792e+01,\n",
       "        7.48599487e+01, 7.48336181e+01, 7.48072876e+01, 7.47809570e+01,\n",
       "        7.47546265e+01, 7.47282960e+01, 7.47019655e+01, 7.46756349e+01,\n",
       "        7.46493044e+01, 7.46229739e+01, 7.45966433e+01, 7.45703128e+01,\n",
       "        7.45555696e+01, 7.45482866e+01, 7.45410037e+01, 7.45337208e+01,\n",
       "        7.45264379e+01, 7.45191550e+01, 7.45118721e+01, 7.45045892e+01,\n",
       "        7.44973063e+01, 7.44900233e+01, 7.44827404e+01, 7.44754575e+01,\n",
       "        7.44681746e+01, 7.44608917e+01, 7.44536088e+01, 7.44463259e+01,\n",
       "        7.44390430e+01, 7.44317600e+01, 7.44244771e+01, 7.44171942e+01,\n",
       "        7.44099113e+01, 7.44026284e+01, 7.43953455e+01, 7.43880626e+01,\n",
       "        7.43807796e+01, 7.43734967e+01, 7.43662138e+01, 7.81594538e+01,\n",
       "        7.80838235e+01, 7.80081933e+01, 7.79325630e+01, 7.78234360e+01,\n",
       "        7.76889823e+01, 7.75545285e+01, 7.74200747e+01, 7.72856209e+01,\n",
       "        7.71511671e+01, 7.70167134e+01, 7.68822596e+01, 7.67478058e+01,\n",
       "        7.66133520e+01, 7.64788982e+01, 7.63444444e+01, 7.62549953e+01,\n",
       "        7.61877684e+01, 7.61205415e+01, 7.60533147e+01, 7.59860878e+01,\n",
       "        7.59188609e+01, 7.58516340e+01, 7.57844071e+01, 7.57171802e+01,\n",
       "        7.56499533e+01, 7.54206314e+01, 0.00000000e+00, 9.95775300e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.10170059e+01, 2.75105417e-01, 1.08811498e+00, 6.24775290e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.78058785e-01, 1.47021383e-01,\n",
       "        2.75084823e-01, 5.81867754e-01, 2.32320845e-01, 0.00000000e+00,\n",
       "        5.50841987e-01, 3.95178497e-01, 9.49467063e-01, 0.00000000e+00,\n",
       "        1.04638457e+00, 0.00000000e+00, 9.38433111e-01, 3.85843426e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72.11094771, 72.10441176, 72.09787582, 72.09133987, 72.08480392,\n",
       "       72.07826797, 72.07173203, 72.06519608, 72.05866013, 72.05212418,\n",
       "       72.04558824, 72.03905229, 72.03251634, 72.02598039, 72.01944444,\n",
       "       72.0129085 , 72.00637255, 71.9998366 , 71.99330065, 71.98676471,\n",
       "       71.98022876, 71.97369281, 71.96715686, 71.96062092, 71.95408497,\n",
       "       71.94754902, 71.94101307, 71.93447712, 71.92794118, 71.92140523,\n",
       "       71.91486928, 71.90833333, 71.90179739, 71.89526144, 71.88872549,\n",
       "       71.88218954, 71.87565359, 71.86911765, 71.8625817 , 71.85604575,\n",
       "       71.8495098 , 71.84297386, 71.83643791, 71.82990196, 71.82336601,\n",
       "       71.81683007, 71.81029412, 71.80375817, 71.79960317, 71.79866947,\n",
       "       71.79773576, 71.79680205, 71.79586835, 71.79493464, 71.79400093,\n",
       "       71.79306723, 71.79213352, 71.79119981, 71.79026611, 71.7893324 ,\n",
       "       71.78839869, 71.78746499, 71.78653128, 71.78559757, 71.78466387,\n",
       "       71.78373016, 71.78279645, 71.78186275, 71.78092904, 71.77999533,\n",
       "       71.77906162, 71.77812792, 71.77719421, 71.7762605 , 71.7753268 ,\n",
       "       71.77439309, 71.77345938, 71.77252568, 71.77159197, 71.77065826,\n",
       "       71.76972456, 71.76879085, 71.76785714, 71.76692344, 71.76598973,\n",
       "       71.76505602, 71.76412232, 71.76318861, 71.7622549 , 71.7613212 ,\n",
       "       71.76038749, 71.75945378, 71.75852007, 71.75758637, 71.75665266,\n",
       "       71.75571895, 71.75478525, 71.75385154, 71.75291783, 71.75198413])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.86432965232382\n",
      "20.45410235094633\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
