{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2245    68.596502\n",
       "2246    68.590217\n",
       "2247    68.583931\n",
       "2248    68.577646\n",
       "2249    68.571360\n",
       "Name: C3, Length: 2250, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_2150_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2145     0.000000\n",
       "2146     0.000000\n",
       "2147     0.000000\n",
       "2148     0.574664\n",
       "2149     0.000000\n",
       "Name: C3, Length: 2150, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2150)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 1, 251) (1700, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/22 [==============================] - 3s 27ms/step - loss: 5555.4829 - val_loss: 3200.3154\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 5297.0464 - val_loss: 3075.8025\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 5167.3535 - val_loss: 3002.8484\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 5039.3867 - val_loss: 2931.3997\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4929.3447 - val_loss: 2869.3389\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4826.7695 - val_loss: 2812.2217\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4727.3750 - val_loss: 2757.1443\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4630.5483 - val_loss: 2703.8091\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4535.9224 - val_loss: 2652.0552\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4443.2700 - val_loss: 2601.9043\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4352.4087 - val_loss: 2553.3035\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4263.5254 - val_loss: 2505.2544\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4175.9219 - val_loss: 2459.0454\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4090.0676 - val_loss: 2414.0347\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 4005.7507 - val_loss: 2370.2434\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3922.9302 - val_loss: 2327.6418\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3841.5684 - val_loss: 2286.2046\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3761.6350 - val_loss: 2245.9082\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3683.0996 - val_loss: 2206.7305\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 3605.9375 - val_loss: 2168.6506\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3530.1216 - val_loss: 2131.6499\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3455.6316 - val_loss: 2095.7095\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3382.4468 - val_loss: 2060.8118\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3310.5442 - val_loss: 2026.9404\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3239.9067 - val_loss: 1993.3943\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3156.7927 - val_loss: 1953.4069\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3080.6714 - val_loss: 1919.9615\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3008.5132 - val_loss: 1888.1937\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2938.7153 - val_loss: 1857.8248\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2870.8359 - val_loss: 1828.6969\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2804.6333 - val_loss: 1800.7162\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2739.9626 - val_loss: 1773.8198\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2676.7288 - val_loss: 1747.9619\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2614.8621 - val_loss: 1723.1047\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2554.3083 - val_loss: 1699.2184\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2495.0242 - val_loss: 1676.2748\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2436.9724 - val_loss: 1654.2513\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2380.1213 - val_loss: 1633.1252\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2324.4431 - val_loss: 1612.8763\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 2269.9111 - val_loss: 1593.4858\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2216.5027 - val_loss: 1574.9358\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2164.1953 - val_loss: 1557.2085\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2112.9692 - val_loss: 1540.2874\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2062.8047 - val_loss: 1524.1565\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2013.6824 - val_loss: 1508.8004\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1965.5858 - val_loss: 1494.2037\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1918.4978 - val_loss: 1480.3516\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1872.4012 - val_loss: 1467.2294\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1827.2809 - val_loss: 1454.8231\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1783.1206 - val_loss: 1443.1185\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1739.9059 - val_loss: 1432.1022\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1697.6218 - val_loss: 1421.7600\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1656.2537 - val_loss: 1412.0791\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1615.7877 - val_loss: 1403.0455\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1576.2096 - val_loss: 1394.6467\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 1537.5057 - val_loss: 1386.8700\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1499.6631 - val_loss: 1379.7018\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1462.6678 - val_loss: 1373.1301\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1426.5076 - val_loss: 1367.1420\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1391.1689 - val_loss: 1361.7252\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1356.6392 - val_loss: 1356.8672\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1322.9064 - val_loss: 1352.5562\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1289.9572 - val_loss: 1348.7797\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1257.7800 - val_loss: 1345.5255\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1226.3625 - val_loss: 1342.7822\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1195.6929 - val_loss: 1340.5377\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1165.7590 - val_loss: 1338.7803\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1136.5491 - val_loss: 1337.4982\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1108.0515 - val_loss: 1336.6799\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1080.2548 - val_loss: 1336.3138\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1053.1476 - val_loss: 1336.3888\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1026.7183 - val_loss: 1336.8931\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1000.9562 - val_loss: 1337.8157\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 975.8492 - val_loss: 1339.1453\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 951.3868 - val_loss: 1340.8707\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 927.5582 - val_loss: 1342.9814\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 904.3522 - val_loss: 1345.4658\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 881.7582 - val_loss: 1348.3131\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 859.7656 - val_loss: 1351.5128\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 838.3633 - val_loss: 1355.0541\n",
      "Epoch 81/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 817.5416 - val_loss: 1358.9261\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 797.2892 - val_loss: 1363.1185\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 777.5961 - val_loss: 1367.6202\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 758.4518 - val_loss: 1372.4216\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 739.8465 - val_loss: 1377.5117\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 721.7697 - val_loss: 1382.8806\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 704.2115 - val_loss: 1388.5181\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 687.1617 - val_loss: 1394.4137\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 670.6110 - val_loss: 1400.5577\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 654.5490 - val_loss: 1406.9401\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 638.9662 - val_loss: 1413.5511\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 623.8530 - val_loss: 1420.3806\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 609.1995 - val_loss: 1427.4194\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 594.9966 - val_loss: 1434.6577\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 581.2347 - val_loss: 1442.0856\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 567.9047 - val_loss: 1449.6940\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 554.9972 - val_loss: 1457.4738\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 542.5028 - val_loss: 1465.4153\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 530.4125 - val_loss: 1473.5103\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 518.7176 - val_loss: 1481.7483\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 507.4091 - val_loss: 1490.1217\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 496.4779 - val_loss: 1498.6207\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 485.9157 - val_loss: 1507.2375\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 475.7133 - val_loss: 1515.9633\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 465.8625 - val_loss: 1524.7887\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 456.3547 - val_loss: 1533.7067\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 447.1816 - val_loss: 1542.7081\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 438.3349 - val_loss: 1551.7848\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 429.8062 - val_loss: 1560.9294\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 421.5878 - val_loss: 1570.1333\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 413.6712 - val_loss: 1579.3896\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 406.0488 - val_loss: 1588.6897\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 398.7128 - val_loss: 1598.0266\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 391.6553 - val_loss: 1607.3931\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 384.8688 - val_loss: 1616.7816\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 378.3457 - val_loss: 1626.1853\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 372.0788 - val_loss: 1635.5973\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 366.0607 - val_loss: 1645.0103\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 360.2837 - val_loss: 1654.4186\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 354.7414 - val_loss: 1663.8151\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 349.4265 - val_loss: 1673.1934\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 344.3320 - val_loss: 1682.5479\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 339.4512 - val_loss: 1691.8718\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 334.7776 - val_loss: 1701.1592\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 330.3046 - val_loss: 1710.4052\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 326.0257 - val_loss: 1719.6040\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 321.9346 - val_loss: 1728.7496\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 318.0251 - val_loss: 1737.8379\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 314.2910 - val_loss: 1746.8619\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 310.7264 - val_loss: 1755.8198\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 307.3255 - val_loss: 1764.7041\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 304.0825 - val_loss: 1773.5117\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 300.9918 - val_loss: 1782.2377\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 298.0479 - val_loss: 1790.8783\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 295.2454 - val_loss: 1799.4292\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 292.5790 - val_loss: 1807.8871\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 290.0436 - val_loss: 1816.2479\n",
      "Epoch 138/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 287.6342 - val_loss: 1824.5081\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 285.3458 - val_loss: 1832.6650\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 283.1739 - val_loss: 1840.7145\n",
      "Epoch 141/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 281.1134 - val_loss: 1848.6542\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 279.1602 - val_loss: 1856.4819\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 277.3095 - val_loss: 1864.1951\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 275.5573 - val_loss: 1871.7900\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 273.8992 - val_loss: 1879.2662\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 272.3312 - val_loss: 1886.6199\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 270.8495 - val_loss: 1893.8500\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 269.4502 - val_loss: 1900.9557\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 268.1295 - val_loss: 1907.9346\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 266.8838 - val_loss: 1914.7845\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 265.7099 - val_loss: 1921.5066\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 264.6040 - val_loss: 1928.0970\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 263.5632 - val_loss: 1934.5579\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 262.5841 - val_loss: 1940.8849\n",
      "Epoch 155/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 261.6640 - val_loss: 1947.0791\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 260.7998 - val_loss: 1953.1420\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 259.9887 - val_loss: 1959.0717\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 259.2278 - val_loss: 1964.8680\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 258.5147 - val_loss: 1970.5322\n",
      "Epoch 160/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 257.8468 - val_loss: 1976.0629\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 257.2218 - val_loss: 1981.4596\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 256.6372 - val_loss: 1986.7260\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 256.0911 - val_loss: 1991.8600\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 255.5810 - val_loss: 1996.8634\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 255.1050 - val_loss: 2001.7361\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 254.6613 - val_loss: 2006.4794\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 254.2480 - val_loss: 2011.0956\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 253.8632 - val_loss: 2015.5844\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 253.5052 - val_loss: 2019.9467\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 253.1726 - val_loss: 2024.1854\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 252.8635 - val_loss: 2028.3004\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 252.5769 - val_loss: 2032.2939\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 252.3110 - val_loss: 2036.1676\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 252.0647 - val_loss: 2039.9229\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 251.8367 - val_loss: 2043.5619\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 251.6259 - val_loss: 2047.0862\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 251.4310 - val_loss: 2050.4980\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 251.2510 - val_loss: 2053.7981\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 251.0850 - val_loss: 2056.9888\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 250.9320 - val_loss: 2060.0728\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 250.7910 - val_loss: 2063.0522\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 250.6613 - val_loss: 2065.9275\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 250.5421 - val_loss: 2068.7026\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 250.4326 - val_loss: 2071.3792\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 250.3320 - val_loss: 2073.9600\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 250.2399 - val_loss: 2076.4458\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 250.1554 - val_loss: 2078.8391\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 250.0781 - val_loss: 2081.1428\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 250.0075 - val_loss: 2083.3594\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 249.9429 - val_loss: 2085.4897\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.8840 - val_loss: 2087.5376\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.8304 - val_loss: 2089.5054\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.7814 - val_loss: 2091.3938\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.7369 - val_loss: 2093.2056\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.6965 - val_loss: 2094.9426\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.6598 - val_loss: 2096.6104\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.6264 - val_loss: 2098.2058\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 249.5963 - val_loss: 2099.7339\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.5689 - val_loss: 2101.1958\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.5443 - val_loss: 2102.5959\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.5221 - val_loss: 2103.9338\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.5020 - val_loss: 2105.2109\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4839 - val_loss: 2106.4333\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4677 - val_loss: 2107.5996\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4531 - val_loss: 2108.7112\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4401 - val_loss: 2109.7725\n",
      "Epoch 207/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4285 - val_loss: 2110.7827\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4180 - val_loss: 2111.7468\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4087 - val_loss: 2112.6648\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4005 - val_loss: 2113.5383\n",
      "Epoch 211/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3932 - val_loss: 2114.3687\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3867 - val_loss: 2115.1584\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 249.3811 - val_loss: 2115.9082\n",
      "Epoch 214/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3760 - val_loss: 2116.6211\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3717 - val_loss: 2117.2988\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3680 - val_loss: 2117.9409\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3646 - val_loss: 2118.5508\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 249.3618 - val_loss: 2119.1287\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3593 - val_loss: 2119.6760\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3573 - val_loss: 2120.1938\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3557 - val_loss: 2120.6851\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3542 - val_loss: 2121.1492\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3531 - val_loss: 2121.5894\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3521 - val_loss: 2122.0039\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3515 - val_loss: 2122.3955\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3510 - val_loss: 2122.7666\n",
      "Epoch 227/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3506 - val_loss: 2123.1160\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3505 - val_loss: 2123.4451\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 249.3505 - val_loss: 2123.7556\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 249.3506 - val_loss: 2124.0493\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 249.3508 - val_loss: 2124.3245\n",
      "Epoch 232/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 249.3511 - val_loss: 2124.5845\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 249.3515 - val_loss: 2124.8291\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 249.3519 - val_loss: 2125.0598\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3524 - val_loss: 2125.2751\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 249.3530 - val_loss: 2125.4785\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 249.3537 - val_loss: 2125.6694\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3543 - val_loss: 2125.8481\n",
      "Epoch 239/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3551 - val_loss: 2126.0151\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3559 - val_loss: 2126.1731\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3566 - val_loss: 2126.3198\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3575 - val_loss: 2126.4580\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3584 - val_loss: 2126.5874\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3592 - val_loss: 2126.7092\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3600 - val_loss: 2126.8223\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3609 - val_loss: 2126.9277\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3619 - val_loss: 2127.0266\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3628 - val_loss: 2127.1199\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3637 - val_loss: 2127.2053\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3647 - val_loss: 2127.2869\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3656 - val_loss: 2127.3613\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3666 - val_loss: 2127.4309\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3675 - val_loss: 2127.4963\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 249.3685 - val_loss: 2127.5569\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3694 - val_loss: 2127.6130\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3704 - val_loss: 2127.6658\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3712 - val_loss: 2127.7151\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3722 - val_loss: 2127.7605\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3731 - val_loss: 2127.8027\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3741 - val_loss: 2127.8413\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3750 - val_loss: 2127.8779\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3759 - val_loss: 2127.9111\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3768 - val_loss: 2127.9424\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3778 - val_loss: 2127.9712\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3786 - val_loss: 2127.9973\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 249.3795 - val_loss: 2128.0217\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3804 - val_loss: 2128.0439\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3813 - val_loss: 2128.0645\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3821 - val_loss: 2128.0825\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3830 - val_loss: 2128.0996\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3839 - val_loss: 2128.1150\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3847 - val_loss: 2128.1304\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3856 - val_loss: 2128.1438\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3864 - val_loss: 2128.1558\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 249.3872 - val_loss: 2128.1663\n",
      "Epoch 276/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.3880 - val_loss: 2128.1770\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3889 - val_loss: 2128.1860\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3896 - val_loss: 2128.1943\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3904 - val_loss: 2128.2004\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3912 - val_loss: 2128.2078\n",
      "Epoch 281/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3919 - val_loss: 2128.2134\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3927 - val_loss: 2128.2188\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3934 - val_loss: 2128.2234\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3942 - val_loss: 2128.2266\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3949 - val_loss: 2128.2295\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3957 - val_loss: 2128.2349\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3963 - val_loss: 2128.2363\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.3970 - val_loss: 2128.2375\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3977 - val_loss: 2128.2395\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3984 - val_loss: 2128.2407\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3991 - val_loss: 2128.2415\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.3997 - val_loss: 2128.2437\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4003 - val_loss: 2128.2441\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 249.4010 - val_loss: 2128.2429\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4017 - val_loss: 2128.2437\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4023 - val_loss: 2128.2429\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4029 - val_loss: 2128.2429\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4035 - val_loss: 2128.2419\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4042 - val_loss: 2128.2415\n",
      "Epoch 300/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4047 - val_loss: 2128.2407\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4052 - val_loss: 2128.2385\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4059 - val_loss: 2128.2380\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4064 - val_loss: 2128.2371\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4069 - val_loss: 2128.2356\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4074 - val_loss: 2128.2339\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4080 - val_loss: 2128.2317\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4085 - val_loss: 2128.2302\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4090 - val_loss: 2128.2275\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4095 - val_loss: 2128.2258\n",
      "Epoch 310/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4101 - val_loss: 2128.2239\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4105 - val_loss: 2128.2212\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4110 - val_loss: 2128.2180\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4115 - val_loss: 2128.2158\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4120 - val_loss: 2128.2139\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4124 - val_loss: 2128.2109\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4129 - val_loss: 2128.2080\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4133 - val_loss: 2128.2053\n",
      "Epoch 318/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4137 - val_loss: 2128.2031\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4142 - val_loss: 2128.2000\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4146 - val_loss: 2128.1978\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4150 - val_loss: 2128.1948\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4154 - val_loss: 2128.1924\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4158 - val_loss: 2128.1877\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4162 - val_loss: 2128.1841\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4166 - val_loss: 2128.1807\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4169 - val_loss: 2128.1768\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4173 - val_loss: 2128.1738\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4177 - val_loss: 2128.1702\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4181 - val_loss: 2128.1677\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4184 - val_loss: 2128.1646\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4187 - val_loss: 2128.1599\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4191 - val_loss: 2128.1562\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4194 - val_loss: 2128.1526\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4196 - val_loss: 2128.1484\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4200 - val_loss: 2128.1440\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4203 - val_loss: 2128.1399\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4207 - val_loss: 2128.1362\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4209 - val_loss: 2128.1306\n",
      "Epoch 339/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4212 - val_loss: 2128.1267\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4216 - val_loss: 2128.1228\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4218 - val_loss: 2128.1187\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4221 - val_loss: 2128.1150\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4223 - val_loss: 2128.1104\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4226 - val_loss: 2128.1047\n",
      "Epoch 345/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4228 - val_loss: 2128.1003\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4232 - val_loss: 2128.0959\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4233 - val_loss: 2128.0903\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4236 - val_loss: 2128.0852\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4239 - val_loss: 2128.0801\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4241 - val_loss: 2128.0747\n",
      "Epoch 351/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4243 - val_loss: 2128.0686\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4246 - val_loss: 2128.0630\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 249.4248 - val_loss: 2128.0566\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 249.4251 - val_loss: 2128.0510\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4252 - val_loss: 2128.0437\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4255 - val_loss: 2128.0376\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4257 - val_loss: 2128.0312\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4259 - val_loss: 2128.0251\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4261 - val_loss: 2128.0186\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4263 - val_loss: 2128.0125\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4265 - val_loss: 2128.0056\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4267 - val_loss: 2127.9988\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4268 - val_loss: 2127.9915\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4271 - val_loss: 2127.9849\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4272 - val_loss: 2127.9763\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4274 - val_loss: 2127.9683\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4275 - val_loss: 2127.9595\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4277 - val_loss: 2127.9512\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4278 - val_loss: 2127.9421\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4279 - val_loss: 2127.9321\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4281 - val_loss: 2127.9221\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4284 - val_loss: 2127.9119\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4285 - val_loss: 2127.9011\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4286 - val_loss: 2127.8901\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4287 - val_loss: 2127.8787\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4288 - val_loss: 2127.8665\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4290 - val_loss: 2127.8528\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 249.4292 - val_loss: 2127.8386\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4293 - val_loss: 2127.8235\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4294 - val_loss: 2127.8074\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4295 - val_loss: 2127.7905\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4297 - val_loss: 2127.7727\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 249.4298 - val_loss: 2127.7542\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4300 - val_loss: 2127.7336\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4300 - val_loss: 2127.7102\n",
      "Epoch 386/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4301 - val_loss: 2127.6848\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4303 - val_loss: 2127.6575\n",
      "Epoch 388/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4303 - val_loss: 2127.6267\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4304 - val_loss: 2127.5911\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4306 - val_loss: 2127.5518\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4306 - val_loss: 2127.5061\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4306 - val_loss: 2127.4500\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4309 - val_loss: 2127.3835\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4310 - val_loss: 2127.2981\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4311 - val_loss: 2127.1787\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4311 - val_loss: 2126.9937\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4312 - val_loss: 2126.6396\n",
      "Epoch 398/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4312 - val_loss: 2124.4885\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 248.3211 - val_loss: 2068.2473\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.6003 - val_loss: 2136.8457\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4319 - val_loss: 2136.8445\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4314 - val_loss: 2136.8350\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4314 - val_loss: 2136.8252\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 249.4316 - val_loss: 2136.8159\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4317 - val_loss: 2136.8083\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4317 - val_loss: 2136.8008\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4319 - val_loss: 2136.7944\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4320 - val_loss: 2136.7891\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4320 - val_loss: 2136.7820\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4321 - val_loss: 2136.7769\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4321 - val_loss: 2136.7717\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4323 - val_loss: 2136.7664\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4324 - val_loss: 2136.7617\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4324 - val_loss: 2136.7585\n",
      "Epoch 415/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4325 - val_loss: 2136.7559\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4325 - val_loss: 2136.7532\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4326 - val_loss: 2136.7488\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4327 - val_loss: 2136.7461\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4327 - val_loss: 2136.7429\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4328 - val_loss: 2136.7405\n",
      "Epoch 421/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4329 - val_loss: 2136.7390\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4330 - val_loss: 2136.7383\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4330 - val_loss: 2136.7371\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4330 - val_loss: 2136.7349\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4330 - val_loss: 2136.7339\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4331 - val_loss: 2136.7324\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4332 - val_loss: 2136.7310\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4332 - val_loss: 2136.7302\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4333 - val_loss: 2136.7295\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 249.4333 - val_loss: 2136.7288\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4334 - val_loss: 2136.7278\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4334 - val_loss: 2136.7266\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4335 - val_loss: 2136.7256\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4335 - val_loss: 2136.7256\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4336 - val_loss: 2136.7251\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4337 - val_loss: 2136.7256\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4337 - val_loss: 2136.7268\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4338 - val_loss: 2136.7266\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4338 - val_loss: 2136.7261\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4337 - val_loss: 2136.7251\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4337 - val_loss: 2136.7249\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4338 - val_loss: 2136.7239\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4338 - val_loss: 2136.7231\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4338 - val_loss: 2136.7229\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4339 - val_loss: 2136.7207\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4339 - val_loss: 2136.7192\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4340 - val_loss: 2136.7192\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4341 - val_loss: 2136.7200\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4341 - val_loss: 2136.7202\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4341 - val_loss: 2136.7207\n",
      "Epoch 451/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4341 - val_loss: 2136.7207\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4341 - val_loss: 2136.7202\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4342 - val_loss: 2136.7200\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 249.4342 - val_loss: 2136.7195\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 249.4342 - val_loss: 2136.7192\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4342 - val_loss: 2136.7192\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4342 - val_loss: 2136.7188\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4343 - val_loss: 2136.7185\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4343 - val_loss: 2136.7183\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4343 - val_loss: 2136.7175\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4343 - val_loss: 2136.7175\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4344 - val_loss: 2136.7185\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4344 - val_loss: 2136.7192\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4345 - val_loss: 2136.7192\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4345 - val_loss: 2136.7192\n",
      "Epoch 466/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4345 - val_loss: 2136.7207\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4345 - val_loss: 2136.7214\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4345 - val_loss: 2136.7229\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4345 - val_loss: 2136.7236\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4345 - val_loss: 2136.7244\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4346 - val_loss: 2136.7246\n",
      "Epoch 472/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4346 - val_loss: 2136.7246\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4345 - val_loss: 2136.7239\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 249.4345 - val_loss: 2136.7229\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4345 - val_loss: 2136.7227\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 249.4345 - val_loss: 2136.7214\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4345 - val_loss: 2136.7190\n",
      "Epoch 478/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4346 - val_loss: 2136.7183\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4346 - val_loss: 2136.7175\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4346 - val_loss: 2136.7153\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4346 - val_loss: 2136.7144\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4346 - val_loss: 2136.7122\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4347 - val_loss: 2136.7122\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 249.4348 - val_loss: 2136.7129\n",
      "Epoch 485/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4348 - val_loss: 2136.7146\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4349 - val_loss: 2136.7151\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4349 - val_loss: 2136.7153\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4349 - val_loss: 2136.7168\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4348 - val_loss: 2136.7180\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4348 - val_loss: 2136.7183\n",
      "Epoch 491/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4349 - val_loss: 2136.7188\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4348 - val_loss: 2136.7188\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4349 - val_loss: 2136.7190\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4349 - val_loss: 2136.7200\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.4350 - val_loss: 2136.7207\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4350 - val_loss: 2136.7209\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4350 - val_loss: 2136.7214\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4350 - val_loss: 2136.7222\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 249.4349 - val_loss: 2136.7214\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 249.4350 - val_loss: 2136.7209\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 366ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.56424837e+01, 7.54304435e+01, 7.51934687e+01, 7.49564939e+01,\n",
       "        7.92870941e+01, 6.86986327e-01, 0.00000000e+00, 9.08673465e-01,\n",
       "        1.88238750e-02, 1.82585105e-01, 1.43628478e-01, 4.37101305e-01,\n",
       "        1.37467071e-01, 7.60084967e+01, 7.58068161e+01, 7.56051354e+01,\n",
       "        3.55119079e-01, 0.00000000e+00, 7.66880486e+01, 7.62923436e+01,\n",
       "        7.60906629e+01, 7.58889823e+01, 7.56873016e+01, 7.54831046e+01,\n",
       "        7.52461298e+01, 7.50091550e+01, 7.47721802e+01, 4.43340153e-01,\n",
       "        4.37472165e-01, 7.57694678e+01, 7.55677871e+01, 7.53426751e+01,\n",
       "        7.51057003e+01, 7.48687255e+01, 7.46317507e+01, 7.45142997e+01,\n",
       "        7.44487535e+01, 7.43820723e+01, 3.90890960e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.76755190e-01, 0.00000000e+00, 0.00000000e+00, 7.50618161e+01,\n",
       "        7.48248413e+01, 0.00000000e+00, 1.82285339e-01, 7.58142857e+01,\n",
       "        7.56126050e+01, 7.53953361e+01, 7.51583613e+01, 7.49213865e+01,\n",
       "        7.46844118e+01, 7.45288656e+01, 7.44633193e+01, 7.43977731e+01,\n",
       "        5.16547800e-01, 0.00000000e+00, 7.50179318e+01, 7.47809570e+01,\n",
       "        7.45555696e+01, 7.44900233e+01, 7.44244771e+01, 7.81594538e+01,\n",
       "        7.71511671e+01, 7.61205415e+01, 0.00000000e+00, 6.24775290e-01,\n",
       "        5.50841987e-01, 7.10341339e+01, 0.00000000e+00, 4.21792805e-01,\n",
       "        0.00000000e+00, 3.34997177e-01, 9.17057400e-02, 6.05774283e-01,\n",
       "        7.12472992e+01, 0.00000000e+00, 0.00000000e+00, 3.56297940e-03,\n",
       "        9.07903969e-01, 0.00000000e+00, 1.89784721e-01, 0.00000000e+00,\n",
       "        9.62052822e-01, 5.57508171e-01, 7.73981065e-02, 6.18999958e-01,\n",
       "        0.00000000e+00, 3.14758360e-01, 2.01358795e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.99594712e-02, 0.00000000e+00, 9.65788126e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.19361891, 69.18733347, 69.18104803, 69.17476259, 69.16847715,\n",
       "       69.16219171, 69.15590626, 69.14962082, 69.14333538, 69.13704994,\n",
       "       69.1307645 , 69.12447906, 69.11819362, 69.11190818, 69.10562274,\n",
       "       69.0993373 , 69.09305185, 69.08676641, 69.08048097, 69.07419553,\n",
       "       69.06791009, 69.06162465, 69.05533921, 69.04905377, 69.04276833,\n",
       "       69.03648289, 69.03019744, 69.023912  , 69.01762656, 69.01134112,\n",
       "       69.00505568, 68.99877024, 68.9924848 , 68.98619936, 68.97991392,\n",
       "       68.97362848, 68.96734303, 68.96105759, 68.95477215, 68.94848671,\n",
       "       68.94220127, 68.93591583, 68.92963039, 68.92334495, 68.91705951,\n",
       "       68.91077407, 68.90448862, 68.89820318, 68.89191774, 68.8856323 ,\n",
       "       68.87934686, 68.87306142, 68.86677598, 68.86049054, 68.8542051 ,\n",
       "       68.84791966, 68.84163421, 68.83534877, 68.82906333, 68.82277789,\n",
       "       68.81649245, 68.81020701, 68.80392157, 68.79763613, 68.79135069,\n",
       "       68.78506525, 68.7787798 , 68.77249436, 68.76620892, 68.75992348,\n",
       "       68.75363804, 68.7473526 , 68.74106716, 68.73478172, 68.72849628,\n",
       "       68.72221084, 68.71592539, 68.70963995, 68.70335451, 68.69706907,\n",
       "       68.69078363, 68.68449819, 68.67821275, 68.67192731, 68.66564187,\n",
       "       68.65935643, 68.65307098, 68.64678554, 68.6405001 , 68.63421466,\n",
       "       68.62792922, 68.62164378, 68.61535834, 68.6090729 , 68.60278746,\n",
       "       68.59650202, 68.59021657, 68.58393113, 68.57764569, 68.57136025])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.116977425781684\n",
      "39.29409850141126\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
