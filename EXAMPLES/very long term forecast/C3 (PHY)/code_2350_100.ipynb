{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2445    67.339414\n",
       "2446    67.333128\n",
       "2447    67.326843\n",
       "2448    67.320557\n",
       "2449    67.314272\n",
       "Name: C3, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_2350_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2345     0.383667\n",
       "2346     0.583870\n",
       "2347     0.599392\n",
       "2348     0.958729\n",
       "2349     0.000000\n",
       "Name: C3, Length: 2350, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2350)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 1, 251) (1900, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 3s 23ms/step - loss: 5487.4512 - val_loss: 3039.0193\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5095.9644 - val_loss: 2854.2356\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4908.3970 - val_loss: 2778.2014\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4791.5845 - val_loss: 2712.5117\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4665.8394 - val_loss: 2646.6572\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4557.3765 - val_loss: 2589.0481\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4452.9790 - val_loss: 2533.9524\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4351.8550 - val_loss: 2480.9849\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4253.4839 - val_loss: 2429.9214\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4157.5610 - val_loss: 2380.6196\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4063.8892 - val_loss: 2332.9795\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3972.3306 - val_loss: 2286.9255\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3882.7812 - val_loss: 2242.3967\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3795.1592 - val_loss: 2199.3425\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3709.3970 - val_loss: 2157.7185\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3625.4385 - val_loss: 2117.4780\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3543.2295 - val_loss: 2078.5427\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3462.7322 - val_loss: 2040.8882\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3383.9099 - val_loss: 2004.6398\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3306.7224 - val_loss: 1969.9688\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3231.1714 - val_loss: 1935.0092\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3157.1191 - val_loss: 1902.1846\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3084.5669 - val_loss: 1870.0087\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3013.4795 - val_loss: 1838.7799\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2943.9016 - val_loss: 1809.2869\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2875.8289 - val_loss: 1781.3411\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2809.2834 - val_loss: 1754.3948\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2744.1267 - val_loss: 1727.6790\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2680.5029 - val_loss: 1705.1064\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2617.6003 - val_loss: 1679.0643\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2556.1379 - val_loss: 1654.6851\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2496.3923 - val_loss: 1630.0894\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2439.4514 - val_loss: 1618.6218\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2381.8293 - val_loss: 1598.9537\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2325.9656 - val_loss: 1580.2283\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2271.3450 - val_loss: 1562.4255\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2217.9468 - val_loss: 1545.5259\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2165.7517 - val_loss: 1529.5118\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2114.7412 - val_loss: 1514.3646\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2064.8960 - val_loss: 1500.0654\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 2016.1975 - val_loss: 1486.5962\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1968.6273 - val_loss: 1473.9459\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1922.1249 - val_loss: 1459.6234\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1922.5378 - val_loss: 1464.0094\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1883.4139 - val_loss: 1452.9926\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1839.6193 - val_loss: 1442.7150\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1796.8502 - val_loss: 1433.1654\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1755.1003 - val_loss: 1424.3281\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1714.3524 - val_loss: 1416.1870\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1674.5901 - val_loss: 1408.7257\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1635.7968 - val_loss: 1401.9281\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1597.9550 - val_loss: 1395.7786\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1561.0491 - val_loss: 1390.2614\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1525.0620 - val_loss: 1385.2257\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1487.3210 - val_loss: 1380.3541\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1447.8376 - val_loss: 1376.3147\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1410.6378 - val_loss: 1373.0815\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1375.2500 - val_loss: 1370.5526\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1341.3124 - val_loss: 1368.6753\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1308.6312 - val_loss: 1367.4094\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1277.0884 - val_loss: 1366.7236\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1246.6029 - val_loss: 1366.5903\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1217.1145 - val_loss: 1366.9847\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1188.5748 - val_loss: 1367.8838\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1160.9440 - val_loss: 1369.2644\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1134.1877 - val_loss: 1371.1029\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1108.2750 - val_loss: 1373.3727\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1083.1792 - val_loss: 1376.0354\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1058.8745 - val_loss: 1379.0084\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1035.3330 - val_loss: 1381.1093\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1009.6795 - val_loss: 1369.3657\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1046.0404 - val_loss: 1385.1885\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1023.1776 - val_loss: 1389.1971\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1000.8890 - val_loss: 1393.4507\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 979.2999 - val_loss: 1398.0468\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 958.4036 - val_loss: 1402.9840\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 938.1816 - val_loss: 1408.2496\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 918.6169 - val_loss: 1413.8286\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 899.6920 - val_loss: 1419.7069\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 881.3899 - val_loss: 1425.8706\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 863.6946 - val_loss: 1432.3059\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 846.5900 - val_loss: 1438.9996\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 830.0612 - val_loss: 1445.9379\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 814.0927 - val_loss: 1453.1088\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 798.6697 - val_loss: 1460.4985\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 783.7784 - val_loss: 1468.0953\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 769.4044 - val_loss: 1475.8868\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 755.5337 - val_loss: 1483.8607\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 742.1532 - val_loss: 1492.0054\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 729.2496 - val_loss: 1500.3092\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 716.8099 - val_loss: 1508.7605\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 704.8217 - val_loss: 1517.3485\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 693.2717 - val_loss: 1526.0620\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 682.1487 - val_loss: 1534.8905\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 671.4402 - val_loss: 1543.8225\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 661.1347 - val_loss: 1552.8489\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 651.2202 - val_loss: 1561.9589\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 641.6857 - val_loss: 1571.1429\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 632.5200 - val_loss: 1580.3910\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 623.7122 - val_loss: 1589.6936\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 615.2516 - val_loss: 1599.0421\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 607.1277 - val_loss: 1608.4268\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 599.3302 - val_loss: 1617.8386\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 591.8489 - val_loss: 1627.2700\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 584.6740 - val_loss: 1636.7125\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 577.7957 - val_loss: 1646.1571\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 571.2043 - val_loss: 1655.5964\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 564.8910 - val_loss: 1665.0223\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 558.8462 - val_loss: 1674.4280\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 553.0609 - val_loss: 1683.8063\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 547.5265 - val_loss: 1693.1497\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 542.2346 - val_loss: 1702.4520\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 537.1763 - val_loss: 1711.7063\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 532.3441 - val_loss: 1720.9066\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 527.7294 - val_loss: 1730.0468\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 523.3246 - val_loss: 1739.1204\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 519.1219 - val_loss: 1748.1227\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 515.1141 - val_loss: 1757.0482\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 511.2936 - val_loss: 1765.8922\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 507.6536 - val_loss: 1774.6483\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 504.1870 - val_loss: 1783.3143\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 500.8871 - val_loss: 1791.8835\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 497.7473 - val_loss: 1800.3536\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 494.7613 - val_loss: 1808.7197\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 491.9228 - val_loss: 1816.9783\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 489.2258 - val_loss: 1825.1254\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 486.6643 - val_loss: 1833.1589\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 484.2328 - val_loss: 1841.0748\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 481.9259 - val_loss: 1848.8707\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 479.7380 - val_loss: 1856.5444\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 477.6640 - val_loss: 1864.0941\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 475.6987 - val_loss: 1871.5161\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 473.8376 - val_loss: 1878.8097\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 472.0757 - val_loss: 1885.9724\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 470.4088 - val_loss: 1893.0028\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 468.8320 - val_loss: 1899.9009\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 467.3416 - val_loss: 1906.6638\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 465.9331 - val_loss: 1913.2917\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 464.6028 - val_loss: 1919.7841\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 463.3468 - val_loss: 1926.1395\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 462.1617 - val_loss: 1932.3580\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 461.0437 - val_loss: 1938.4395\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 459.9896 - val_loss: 1944.3842\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 458.9961 - val_loss: 1950.1919\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 458.0601 - val_loss: 1955.8641\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 457.1786 - val_loss: 1961.3982\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 456.3489 - val_loss: 1966.7974\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 455.5681 - val_loss: 1972.0620\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 454.8338 - val_loss: 1977.1931\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 454.1432 - val_loss: 1982.1904\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 453.4942 - val_loss: 1987.0563\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 452.8844 - val_loss: 1991.7916\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 452.3115 - val_loss: 1996.3976\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 451.7736 - val_loss: 2000.8756\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 451.2687 - val_loss: 2005.2273\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 450.7951 - val_loss: 2009.4540\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 450.3506 - val_loss: 2013.5577\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 449.9338 - val_loss: 2017.5406\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 449.5431 - val_loss: 2021.4036\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 449.1770 - val_loss: 2025.1488\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 448.8338 - val_loss: 2028.7797\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 448.5122 - val_loss: 2032.2965\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 448.2110 - val_loss: 2035.7013\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 447.9291 - val_loss: 2038.9968\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 447.6650 - val_loss: 2042.1857\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 447.4179 - val_loss: 2045.2683\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 447.1868 - val_loss: 2048.2498\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 446.9703 - val_loss: 2051.1304\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 446.7677 - val_loss: 2053.9116\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 446.5782 - val_loss: 2056.5972\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 446.4011 - val_loss: 2059.1887\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 446.2353 - val_loss: 2061.6887\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 446.0804 - val_loss: 2064.1001\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 445.9353 - val_loss: 2066.4241\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 445.7999 - val_loss: 2068.6628\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 445.6731 - val_loss: 2070.8208\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 445.5545 - val_loss: 2072.8970\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 445.4436 - val_loss: 2074.8962\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 445.3400 - val_loss: 2076.8198\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 445.2430 - val_loss: 2078.6685\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 445.1524 - val_loss: 2080.4470\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 445.0677 - val_loss: 2082.1570\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.9884 - val_loss: 2083.7986\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 444.9143 - val_loss: 2085.3757\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.8448 - val_loss: 2086.8894\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.7800 - val_loss: 2088.3416\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.7194 - val_loss: 2089.7363\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.6626 - val_loss: 2091.0723\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.6095 - val_loss: 2092.3535\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.5599 - val_loss: 2093.5830\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 444.5133 - val_loss: 2094.7605\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.4698 - val_loss: 2095.8879\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.4290 - val_loss: 2096.9670\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.3909 - val_loss: 2098.0012\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.3551 - val_loss: 2098.9893\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.3216 - val_loss: 2099.9370\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.2903 - val_loss: 2100.8416\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.2609 - val_loss: 2101.7070\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.2334 - val_loss: 2102.5342\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.2076 - val_loss: 2103.3245\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.1834 - val_loss: 2104.0791\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 444.1608 - val_loss: 2104.7996\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 444.1396 - val_loss: 2105.4883\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 444.1198 - val_loss: 2106.1455\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.1010 - val_loss: 2106.7734\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.0836 - val_loss: 2107.3718\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.0671 - val_loss: 2107.9421\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 444.0517 - val_loss: 2108.4868\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.0373 - val_loss: 2109.0054\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 444.0238 - val_loss: 2109.4995\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 444.0110 - val_loss: 2109.9714\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.9993 - val_loss: 2110.4204\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.9881 - val_loss: 2110.8486\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.9775 - val_loss: 2111.2559\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.9677 - val_loss: 2111.6433\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.9585 - val_loss: 2112.0132\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.9499 - val_loss: 2112.3643\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.9418 - val_loss: 2112.6987\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.9341 - val_loss: 2113.0164\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.9271 - val_loss: 2113.3188\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.9202 - val_loss: 2113.6062\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.9140 - val_loss: 2113.8799\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 443.9081 - val_loss: 2114.1394\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 443.9026 - val_loss: 2114.3855\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8975 - val_loss: 2114.6213\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8927 - val_loss: 2114.8455\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8882 - val_loss: 2115.0566\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8839 - val_loss: 2115.2568\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8799 - val_loss: 2115.4478\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8762 - val_loss: 2115.6304\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8727 - val_loss: 2115.8005\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8694 - val_loss: 2115.9639\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8665 - val_loss: 2116.1194\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8636 - val_loss: 2116.2656\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8610 - val_loss: 2116.4060\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8585 - val_loss: 2116.5376\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8563 - val_loss: 2116.6636\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8540 - val_loss: 2116.7817\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8521 - val_loss: 2116.8945\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8503 - val_loss: 2117.0017\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8485 - val_loss: 2117.1028\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8469 - val_loss: 2117.1992\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8455 - val_loss: 2117.2905\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8440 - val_loss: 2117.3762\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8428 - val_loss: 2117.4578\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8416 - val_loss: 2117.5364\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 443.8404 - val_loss: 2117.6089\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8394 - val_loss: 2117.6775\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8384 - val_loss: 2117.7427\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8377 - val_loss: 2117.8047\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8369 - val_loss: 2117.8625\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 443.8362 - val_loss: 2117.9189\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8355 - val_loss: 2117.9719\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8349 - val_loss: 2118.0215\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8344 - val_loss: 2118.0693\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8340 - val_loss: 2118.1143\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8335 - val_loss: 2118.1560\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8331 - val_loss: 2118.1965\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8326 - val_loss: 2118.2341\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8324 - val_loss: 2118.2700\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8322 - val_loss: 2118.3052\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8318 - val_loss: 2118.3364\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8315 - val_loss: 2118.3665\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8313 - val_loss: 2118.3955\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8313 - val_loss: 2118.4229\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8312 - val_loss: 2118.4490\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8309 - val_loss: 2118.4731\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8308 - val_loss: 2118.4963\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8307 - val_loss: 2118.5178\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8308 - val_loss: 2118.5388\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8308 - val_loss: 2118.5588\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 443.8306 - val_loss: 2118.5767\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 443.8307 - val_loss: 2118.5938\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8307 - val_loss: 2118.6099\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8307 - val_loss: 2118.6260\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 443.8307 - val_loss: 2118.6401\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 443.8308 - val_loss: 2118.6545\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 443.8308 - val_loss: 2118.6670\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 443.8309 - val_loss: 2118.6797\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8310 - val_loss: 2118.6912\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8311 - val_loss: 2118.7019\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8311 - val_loss: 2118.7117\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8313 - val_loss: 2118.7222\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8314 - val_loss: 2118.7322\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8314 - val_loss: 2118.7407\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8315 - val_loss: 2118.7493\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8318 - val_loss: 2118.7573\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8319 - val_loss: 2118.7639\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8319 - val_loss: 2118.7710\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8322 - val_loss: 2118.7781\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8322 - val_loss: 2118.7842\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8323 - val_loss: 2118.7900\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8325 - val_loss: 2118.7961\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8327 - val_loss: 2118.8020\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8327 - val_loss: 2118.8071\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8329 - val_loss: 2118.8113\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8330 - val_loss: 2118.8159\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8331 - val_loss: 2118.8196\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8332 - val_loss: 2118.8240\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8334 - val_loss: 2118.8269\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8336 - val_loss: 2118.8298\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8338 - val_loss: 2118.8335\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8339 - val_loss: 2118.8369\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8340 - val_loss: 2118.8406\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8342 - val_loss: 2118.8425\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8343 - val_loss: 2118.8457\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8344 - val_loss: 2118.8489\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8346 - val_loss: 2118.8516\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8346 - val_loss: 2118.8545\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8348 - val_loss: 2118.8567\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 443.8350 - val_loss: 2118.8591\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8351 - val_loss: 2118.8611\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 443.8352 - val_loss: 2118.8623\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8354 - val_loss: 2118.8647\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8354 - val_loss: 2118.8662\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8355 - val_loss: 2118.8679\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8356 - val_loss: 2118.8691\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8358 - val_loss: 2118.8704\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 443.8358 - val_loss: 2118.8723\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8360 - val_loss: 2118.8733\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8362 - val_loss: 2118.8750\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8363 - val_loss: 2118.8774\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8363 - val_loss: 2118.8787\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8363 - val_loss: 2118.8799\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8365 - val_loss: 2118.8809\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8366 - val_loss: 2118.8816\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8368 - val_loss: 2118.8828\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8368 - val_loss: 2118.8833\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8370 - val_loss: 2118.8843\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8371 - val_loss: 2118.8857\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8371 - val_loss: 2118.8877\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8372 - val_loss: 2118.8899\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8373 - val_loss: 2118.8926\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8374 - val_loss: 2118.8984\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8375 - val_loss: 2118.9126\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8376 - val_loss: 2118.2109\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 441.0645 - val_loss: 2107.8069\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.1631 - val_loss: 2107.9026\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 444.1840 - val_loss: 2108.5745\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 444.1569 - val_loss: 2109.2300\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.1317 - val_loss: 2109.8394\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.1099 - val_loss: 2110.4041\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.0906 - val_loss: 2110.9321\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.0734 - val_loss: 2111.4243\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 444.0576 - val_loss: 2111.8848\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 444.0432 - val_loss: 2112.3145\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 444.0303 - val_loss: 2112.7180\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 444.0183 - val_loss: 2113.0957\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 444.0071 - val_loss: 2113.4504\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.9969 - val_loss: 2113.7827\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.9873 - val_loss: 2114.0942\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.9787 - val_loss: 2114.3884\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.9704 - val_loss: 2114.6628\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.9627 - val_loss: 2114.9194\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.9558 - val_loss: 2115.1614\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.9491 - val_loss: 2115.3887\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.9430 - val_loss: 2115.6013\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.9375 - val_loss: 2115.8010\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.9321 - val_loss: 2115.9902\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.9271 - val_loss: 2116.1665\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.9225 - val_loss: 2116.3333\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.9181 - val_loss: 2116.4893\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.9141 - val_loss: 2116.6362\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.9103 - val_loss: 2116.7737\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 443.9068 - val_loss: 2116.9036\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.9035 - val_loss: 2117.0239\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 443.9002 - val_loss: 2117.1362\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8975 - val_loss: 2117.2444\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8947 - val_loss: 2117.3455\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8922 - val_loss: 2117.4387\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8898 - val_loss: 2117.5269\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8877 - val_loss: 2117.6106\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8854 - val_loss: 2117.6882\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8835 - val_loss: 2117.7607\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8819 - val_loss: 2117.8315\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8800 - val_loss: 2117.8955\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8784 - val_loss: 2117.9558\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8770 - val_loss: 2118.0146\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8755 - val_loss: 2118.0688\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8741 - val_loss: 2118.1187\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8729 - val_loss: 2118.1667\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8717 - val_loss: 2118.2112\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8705 - val_loss: 2118.2539\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8696 - val_loss: 2118.2939\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8685 - val_loss: 2118.3301\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8676 - val_loss: 2118.3657\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8667 - val_loss: 2118.3970\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8661 - val_loss: 2118.4287\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8652 - val_loss: 2118.4580\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8645 - val_loss: 2118.4851\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8639 - val_loss: 2118.5110\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8632 - val_loss: 2118.5339\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 443.8627 - val_loss: 2118.5583\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 443.8621 - val_loss: 2118.5786\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8615 - val_loss: 2118.5986\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8611 - val_loss: 2118.6167\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 443.8607 - val_loss: 2118.6350\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8602 - val_loss: 2118.6519\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8596 - val_loss: 2118.6682\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8593 - val_loss: 2118.6826\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8590 - val_loss: 2118.6968\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8586 - val_loss: 2118.7083\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8583 - val_loss: 2118.7205\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8579 - val_loss: 2118.7314\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8577 - val_loss: 2118.7424\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8575 - val_loss: 2118.7517\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8572 - val_loss: 2118.7620\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8570 - val_loss: 2118.7708\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8568 - val_loss: 2118.7791\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8565 - val_loss: 2118.7866\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8563 - val_loss: 2118.7932\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8563 - val_loss: 2118.8003\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8561 - val_loss: 2118.8081\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8559 - val_loss: 2118.8154\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8556 - val_loss: 2118.8208\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8556 - val_loss: 2118.8267\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8554 - val_loss: 2118.8330\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8553 - val_loss: 2118.8379\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8552 - val_loss: 2118.8425\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 443.8550 - val_loss: 2118.8455\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8549 - val_loss: 2118.8494\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8547 - val_loss: 2118.8535\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8546 - val_loss: 2118.8557\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8546 - val_loss: 2118.8591\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8545 - val_loss: 2118.8621\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8545 - val_loss: 2118.8647\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8544 - val_loss: 2118.8682\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8544 - val_loss: 2118.8713\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8542 - val_loss: 2118.8738\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8542 - val_loss: 2118.8767\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8541 - val_loss: 2118.8801\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8541 - val_loss: 2118.8818\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8540 - val_loss: 2118.8843\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8539 - val_loss: 2118.8860\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8539 - val_loss: 2118.8884\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8538 - val_loss: 2118.8889\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8538 - val_loss: 2118.8909\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8537 - val_loss: 2118.8918\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8537 - val_loss: 2118.8938\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8536 - val_loss: 2118.8948\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8536 - val_loss: 2118.8955\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8536 - val_loss: 2118.8965\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8535 - val_loss: 2118.8975\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 443.8535 - val_loss: 2118.8977\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8535 - val_loss: 2118.8984\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8535 - val_loss: 2118.8994\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8535 - val_loss: 2118.8999\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8534 - val_loss: 2118.9006\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8534 - val_loss: 2118.9019\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8533 - val_loss: 2118.9021\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8533 - val_loss: 2118.9031\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8533 - val_loss: 2118.9031\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8533 - val_loss: 2118.9033\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8533 - val_loss: 2118.9033\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8532 - val_loss: 2118.9031\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8533 - val_loss: 2118.9031\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8533 - val_loss: 2118.9031\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8533 - val_loss: 2118.9031\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8533 - val_loss: 2118.9031\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8533 - val_loss: 2118.9031\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8533 - val_loss: 2118.9033\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8532 - val_loss: 2118.9033\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8532 - val_loss: 2118.9031\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8532 - val_loss: 2118.9031\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8533 - val_loss: 2118.9033\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8534 - val_loss: 2118.9033\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8533 - val_loss: 2118.9036\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8533 - val_loss: 2118.9036\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 443.8534 - val_loss: 2118.9045\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 443.8533 - val_loss: 2118.9060\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8532 - val_loss: 2118.9067\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8532 - val_loss: 2118.9070\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8532 - val_loss: 2118.9070\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8532 - val_loss: 2118.9075\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8532 - val_loss: 2118.9080\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8532 - val_loss: 2118.9080\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8532 - val_loss: 2118.9084\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8532 - val_loss: 2118.9089\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8532 - val_loss: 2118.9092\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8532 - val_loss: 2118.9094\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8532 - val_loss: 2118.9099\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8531 - val_loss: 2118.9102\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8531 - val_loss: 2118.9111\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8531 - val_loss: 2118.9111\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8532 - val_loss: 2118.9124\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8531 - val_loss: 2118.9126\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8532 - val_loss: 2118.9128\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8531 - val_loss: 2118.9136\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8531 - val_loss: 2118.9141\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8531 - val_loss: 2118.9146\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8531 - val_loss: 2118.9155\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8531 - val_loss: 2118.9155\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8531 - val_loss: 2118.9165\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 443.8531 - val_loss: 2118.9170\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 443.8531 - val_loss: 2118.9182\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8531 - val_loss: 2118.9194\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8530 - val_loss: 2118.9199\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8531 - val_loss: 2118.9211\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 443.8530 - val_loss: 2118.9221\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 443.8530 - val_loss: 2118.9221\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 413ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74.3807796 , 77.5545285 , 76.3444444 , 75.7171802 , 71.0170059 ,\n",
       "         0.58186775,  0.93843311,  0.48236462,  0.39528209,  0.33446464,\n",
       "         0.        ,  0.        ,  0.        , 74.4997339 , 74.4341877 ,\n",
       "        74.3686415 ,  0.        ,  0.        , 74.9126097 , 74.6756349 ,\n",
       "        74.5264379 , 74.4608917 , 74.3953455 , 77.823436  , 76.613352  ,\n",
       "        75.851634  ,  0.        ,  0.14702138,  1.04638457, 74.4220495 ,\n",
       "        78.1342437 , 77.1063492 , 76.0981326 ,  0.        , 76.4639589 ,\n",
       "        75.7769374 , 75.1144771 ,  0.44711974, 24.9879092 ,  0.22026402,\n",
       "         0.        ,  0.5758512 ,  1.63416767,  0.        ,  0.        ,\n",
       "         0.77963716,  1.18474197, 75.9860878 ,  0.        ,  0.        ,\n",
       "         0.94946706, 74.4366153 , 74.3710691 , 77.3752568 , 76.2325864 ,\n",
       "        75.6275443 , 76.7328665 , 75.9113912 , 75.2724603 ,  0.38277531,\n",
       "         0.        ,  0.51323855, 75.874043  ,  1.19662857, 76.1578898 ,\n",
       "        75.5528478 , 74.8511718 , 75.8366947 , 75.1846919 , 74.5361485 ,\n",
       "         0.        ,  0.2913605 ,  0.        , 73.8344498 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.57466406,\n",
       "        67.83885193,  0.        ,  0.35322338,  0.        ,  0.0803013 ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.69430047,  1.04173553,  0.10474031,  0.85554153,  0.        ,\n",
       "         0.        ,  0.79572785,  0.        ,  0.        ,  0.36300284]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([67.93653071, 67.93024527, 67.92395983, 67.91767439, 67.91138895,\n",
       "       67.9051035 , 67.89881806, 67.89253262, 67.88624718, 67.87996174,\n",
       "       67.8736763 , 67.86739086, 67.86110542, 67.85481998, 67.84853454,\n",
       "       67.84224909, 67.83596365, 67.82967821, 67.82339277, 67.81710733,\n",
       "       67.81082189, 67.80453645, 67.79825101, 67.79196557, 67.78568013,\n",
       "       67.77939468, 67.77310924, 67.7668238 , 67.76053836, 67.75425292,\n",
       "       67.74796748, 67.74168204, 67.7353966 , 67.72911116, 67.72282572,\n",
       "       67.71654027, 67.71025483, 67.70396939, 67.69768395, 67.69139851,\n",
       "       67.68511307, 67.67882763, 67.67254219, 67.66625675, 67.65997131,\n",
       "       67.65368586, 67.64740042, 67.64111498, 67.63482954, 67.6285441 ,\n",
       "       67.62225866, 67.61597322, 67.60968778, 67.60340234, 67.5971169 ,\n",
       "       67.59083145, 67.58454601, 67.57826057, 67.57197513, 67.56568969,\n",
       "       67.55940425, 67.55311881, 67.54683337, 67.54054793, 67.53426249,\n",
       "       67.52797704, 67.5216916 , 67.51540616, 67.50912072, 67.50283528,\n",
       "       67.49654984, 67.4902644 , 67.48397896, 67.47769352, 67.47140808,\n",
       "       67.46512263, 67.45883719, 67.45255175, 67.44626631, 67.43998087,\n",
       "       67.43369543, 67.42740999, 67.42112455, 67.41483911, 67.40855367,\n",
       "       67.40226822, 67.39598278, 67.38969734, 67.3834119 , 67.37712646,\n",
       "       67.37084102, 67.36455558, 67.35827014, 67.3519847 , 67.34569926,\n",
       "       67.33941381, 67.33312837, 67.32684293, 67.32055749, 67.31427205])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.65733451927069\n",
      "42.555567874607895\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
