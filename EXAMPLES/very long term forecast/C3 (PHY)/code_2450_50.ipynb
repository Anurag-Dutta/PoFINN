{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "2495    52.162308\n",
       "2496    52.146731\n",
       "2497    52.131154\n",
       "2498    52.115577\n",
       "2499    52.100000\n",
       "Name: C2, Length: 2500, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_2450_50.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "2445     0.000000\n",
       "2446     0.000000\n",
       "2447     0.000000\n",
       "2448     0.116940\n",
       "2449     0.000000\n",
       "Name: C2, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(50)\n",
    "test\n",
    "training_set = training_set.head(2450)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.500000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.275910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.051821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.827731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.603641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     90.500000  0.000298\n",
       "1     90.275910  0.000298\n",
       "2     90.051821  0.000297\n",
       "3     89.827731  0.000297\n",
       "4     89.603641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD4CAYAAAD//dEpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAA6wUlEQVR4nO3deXxU5bnA8d+TnS1hSQhh30U2RSK44I6IS4VW63KpYqulm63WbrTe1tbae7W3ra2tteJuWxVFrVhUigjuKEHCDrIpBAIEAoQtZHvuH3NmcmYyk8xkMpnJ8Hw/n/lk5pz3nHnPDJxn3l1UFWOMMaYpKfHOgDHGmLbBAoYxxpiwWMAwxhgTFgsYxhhjwmIBwxhjTFjS4p2BlpSbm6v9+/ePdzaMMaZNWbZs2V5VzWsqXVIFjP79+1NUVBTvbBhjTJsiIp+Hk86qpIwxxoTFAoYxxpiwWMAwxhgTFgsYxhhjwmIBwxhjTFgsYBhjjAmLBQxjjDFhsYABLP2snPveWI9N9W6MMaG1SMAQkckiskFENonIzCD7zxWRT0SkRkSuDtg3XUQ2Oo/pru1jRWSVc84HRERaIq/BrCw5yEOLN3PgaHWs3sIYY9q8qAOGiKQCDwKXAsOB60VkeECybcBNwDMBx3YF7gLGA+OAu0Ski7P7IeDrwBDnMTnavIaSn50JwO5DlbF6C2OMafNaooQxDtikqltUtQp4DpjiTqCqn6nqSqAu4NhLgAWqWq6q+4EFwGQRKQCyVXWJeuqJngamtkBeg+qRnQXAroMWMIwxJpSWCBi9gO2u1yXOtmiO7eU8b/KcIjJDRIpEpKisrCzsTLvlOwFjT8XxZh1vjDEngjbf6K2qs1S1UFUL8/KanGwxqO5OldSuCithGGNMKC0RMHYAfVyvezvbojl2h/O8OeeMWGZaKl07ZFjAMMaYRrREwFgKDBGRASKSAVwHzA3z2PnAJBHp4jR2TwLmq2opUCEiZzi9o24EXmmBvIbUvVMmeyxgGGNMSFEHDFWtAW7Fc/NfBzyvqmtE5G4RuRJARE4XkRLgy8DDIrLGObYc+DWeoLMUuNvZBvBt4FFgE7AZeD3avDamR06WlTCMMaYRLbKAkqq+BrwWsO0XrudL8a9icqd7HHg8yPYiYGRL5C8cPbKzWLOzorXezhhj2pw23+jdUrpnZ7H38HGqawN7/hpjjAELGD49srNQhbJD1rXWGGOCsYDh8I32tnYMY4wJygKGY2BeRwCKtx+Ib0aMMSZBWcBwDMjtwEn5nZi3sjTeWTHGmIRkAcPlitEFFH2+n9KDx+KdFWOMSTgWMFwuH10AYKUMY4wJwgKGy8C8jgwvyObfFjCMMaYBCxgBrjilgOLtB9hefjTeWTHGmIRiASPAFaN6AvDMx9vinBNjjEksFjAC9O3Wni+N6cXf3t7MW+t3xzs7xhiTMCxgBPE/XxrFiJ7Z3PZsMZvLDsc7O8YYkxAsYASRlZ7KwzcUkpGWwtefLqKisjreWTLGmLizgBFCr87teHDaaXy+7yh3zC6mrk7jnSVjjIkrCxiNOGNgN35xxXDeXLeHPy7cGO/sGGNMXLVIwBCRySKyQUQ2icjMIPszRWS2s/8jEenvbJ8mIsWuR52InOrsW+yc07uve0vkNVI3ntmPL4/tzQMLN/LGahufYYw5cUUdMEQkFXgQuBQYDlwvIsMDkt0M7FfVwcD9wH0AqvpPVT1VVU8FbgC2qmqx67hp3v2quifavDaHiPDrqSM5pU9nvj97Bat3HIxHNowxJu5aooQxDtikqltUtQp4DpgSkGYK8JTzfA5wkbNWt9v1zrEJJys9lVk3jKVL+3S+9uRSdh6wuaaMMSeelggYvYDtrtclzragaZw1wA8C3QLSXAs8G7DtCac66udBAgwAIjJDRIpEpKisrKy519Ck/OwsHrvpdI5W1fK1J5dy+HhNzN7LGGMSUUI0eovIeOCoqq52bZ6mqqOAc5zHDcGOVdVZqlqoqoV5eXkxzefJBdk8OO00Nu45zHef+YQaW87VGHMCaYmAsQPo43rd29kWNI2IpAE5wD7X/usIKF2o6g7n7yHgGTxVX3F33tA87p4ygkUbynjWpg8xxpxAWiJgLAWGiMgAEcnAc/OfG5BmLjDdeX418JaqKoCIpADX4Gq/EJE0Ecl1nqcDVwCrSRD/Na4vp/bpzKPvbaXWxmcYY04QUQcMp03iVmA+sA54XlXXiMjdInKlk+wxoJuIbALuANxdb88FtqvqFte2TGC+iKwEivGUUB6JNq8tRUT4+jkD+XzfURastfmmjDEnBnF+6CeFwsJCLSoqapX3qqmt4/zfLaZHdhZzvnVWq7ynMcbEgogsU9XCptIlRKN3W5SWmsLXzh5A0ef7Wb5tf7yzY4wxMWcBIwrXnN6HTllpPPru1nhnxRhjYs4CRhQ6ZqYxbXw/Xl9daiv0GWOSngWMKN10Vn9SRHj8fStlGGOSmwWMKPXIyeLKU3ry/NLtHDxm62YYY5KXBYwWcMs5AzlSVcuv5q7h7U/L2Hv4eLyzZIwxLS4t3hlIBsN7ZnPVab158ZMSXlruGeSen53JiJ45jOiZ7Txy6N2lHSGmxDLGmIRn4zBa0MGj1awpPcjanRWs3VnBmp0VbCo77BsN3ikrjWsK+zDz0mGkp1rhzhiTGMIdh2EljBaU0z6dswblctagXN+2yupaNuw6xJqdFXy0dR+PvbeVVTsO8tdpp5HbMTOOuTXGmMhYCaOVvVK8gx/PWUm3DhnMurGQkb1y4p0lY8wJzkZ6J6gpp/bixW+dhYhw1UMf8K/lgRP7GmNMYrKAEQcje+Xwyq1nc0qfztw+u5jfzFtra2sYYxKeBYw4ye2YyT9vGc+NZ/bjkXe38tUnl3LgaFW8s2WMMSFZwIij9NQU7p4ykvuuGsVHW8q58i/vs2HXoXhnyxhjgrKAkQCuPb0vz844g8rqWr741/d5Y3VpvLNkjDENWMBIEGP7deHV705gaH4nvvmPT/jDfzZQZ6v5GWMSSIsEDBGZLCIbRGSTiMwMsj9TRGY7+z8Skf7O9v4ickxEip3H31zHjBWRVc4xD8gJMEQ6PzuL2d84g2sKe/PAW5uY8fciDlXa/FTGmMQQdcAQkVTgQeBSYDhwvYgMD0h2M7BfVQcD9wP3ufZtVtVTncc3XdsfAr4ODHEek6PNa1uQmZbKfVeN5u4pI1i8oYypD77P5rLD8c6WMca0SAljHLBJVbeoahXwHDAlIM0U4Cnn+RzgosZKDCJSAGSr6hL1jCx8GpjaAnltE0SEG8/szz9uGc/+o9VM/cv7vFJs4zWMMfHVEgGjF7Dd9brE2RY0jarWAAeBbs6+ASKyXETeFpFzXOlLmjgnACIyQ0SKRKSorKwsuitJMGcM7MbcW89maI9O3PZcMd+fXUyFVVEZY+Ik3o3epUBfVR0D3AE8IyLZkZxAVWepaqGqFubl5cUkk/HUu0t7Zs84g+9PHMrcFTu57E/vUvRZebyzZYw5AbVEwNgB9HG97u1sC5pGRNKAHGCfqh5X1X0AqroM2AwMddL3buKcJ4y01BRumziE579xJiJwzcMf8ocFn9rocGNMq2qJgLEUGCIiA0QkA7gOmBuQZi4w3Xl+NfCWqqqI5DmN5ojIQDyN21tUtRSoEJEznLaOG4FXWiCvbdrYfl147Xvn8MUxvXlg4Ua+/PCHbNtna4kbY1pH1AHDaZO4FZgPrAOeV9U1InK3iFzpJHsM6CYim/BUPXm73p4LrBSRYjyN4d9UVW99y7eBR4FNeEoer0eb12TQKSud319zCn++fgyb9hzm0j+9w4vLSkimWYeNMYnJpjdvw3YcOMb3Zxfz8dZyrhhdwG+mjiKnfXq8s2WMaWNsevMTQK/O7Xj262fw48kn8cbqXVz6p3dYsmVfvLNljElSFjDauNQU4dvnD+alb59FZnoq1z+yhN++sZ6qGmsQN8a0LAsYSWJ07878+7sTuLawD39dvJmr//YBW2yEuDGmBVnASCIdMtO496rR/O0rp7Gt/CiXP/Aez328zRrEjTEtwgJGEpo8soA3bjuX0/p1ZuZLq/jmP5ZRfsQWZzLGRMcCRpLqkZPF3782njsvO5lF68uYdP87LFy3O97ZMsa0YRYwklhKivD1cwfyyq1nk9sxg5ufKmLmiys5fLwm3lkzxrRBFjBOACcXZPPKrWfzrfMH8XzRdi790zt8vNXmozLGRMYCxgkiMy2Vn0we5pmPCuHaWR/yv6+t43hNbbyzZoxpIyxgnGAK+3fl9dvO4fpxfXn4nS1c+ef3WbuzIt7ZMsa0ARYwTkAdMtP4ny+O4ombTqf8aBVTHnyPvy7eRK2tIW6MaYQFjBPYBcO6M//2c7l4eD6/fWMD1zz8IStLDlBngcMYE4RNPmhQVV4p3snPX1nNocoacjtmMGFwLucOzWPCkFy6d8qKdxaNMTEU7uSDaa2RGZPYRISpY3px7tA8Fq3fwzsby3h3417+VbwT8PSyOneIJ4CM7deFrPTUOOfYGBMPVsIwQdXVKWtLKzzB49O9FH1eTnWtkpWewhkDu3HOkDzOG5rLoLyOeNa4Msa0VeGWMFokYIjIZOBPQCrwqKreG7A/E3gaGAvsA65V1c9E5GLgXiADqAJ+pKpvOccsBgqAY85pJqnqnsbyYQEjdo4cr+Gjrft459O9vLOxjC1lRwDomZPFBcO6850LBtOzc7s459IY0xytViXlLLH6IHAxUAIsFZG5qrrWlexmYL+qDhaR64D7gGuBvcAXVHWniIzEs2pfL9dx01TVIkAC6JCZxoXD8rlwWD4A28uP8t6mvbzzaRlzlpXw0ic7+N5FQ7h5wgAy0qwvhTHJqCX+Z48DNqnqFlWtAp4DpgSkmQI85TyfA1wkIqKqy1V1p7N9DdDOKY2YBNena3uuH9eXh74yljfvOI8JQ3K57431TP7TO7y3cW+8s2eMiYGWCBi9gO2u1yX4lxL80jhrgB8EugWkuQr4RFWPu7Y9ISLFIvJzCVFRLiIzRKRIRIrKysqiuQ7TTH26tueRGwt54qbTqa1TvvLYR3znn5+w88Cxpg82cXP4eA23P7ecA0cTZybjZz7axryVpWGn33HgGHe+vIqa2sRdMGzTnsPc8NhHFG8/EPYxv5y7hv+bvz52mWqmhKg7EJEReKqpvuHaPE1VRwHnOI8bgh2rqrNUtVBVC/Py8mKfWROSd1zHDy4eypvrdnPR79/mocWbbfW/BPX0h5/xr+KdPPT25nhnxednL6/iO898Enb6n8xZyT8/2saSLYk7N1pFZTXvbtzL/ggC8/LtB1i9I/FmYGiJgLED6ON63dvZFjSNiKQBOXgavxGR3sDLwI2q6vuXq6o7nL+HgGfwVH2ZBJeVnsp3Lxpi1VRtiNB2e7kp6vc3EXn7FaVE0JtQVUnEzoctETCWAkNEZICIZADXAXMD0swFpjvPrwbeUlUVkc7APGCmqr7vTSwiaSKS6zxPB64AVrdAXk0rCVVNVXrQqqlMy/EGu0QeHeDtiRrJ/V81svStJeqA4bRJ3Iqnh9M64HlVXSMid4vIlU6yx4BuIrIJuAOY6Wy/FRgM/MJpqygWke5AJjBfRFYCxXhKKI9Em1fT+qyaysSS91d4AscLX94iKTEompDjm1pkpLeqvga8FrDtF67nlcCXgxx3D3BPiNOObYm8mfjzVlNNHdOLu/+9lvveWM8Ly7Zzx8VDmTyiB2mpCdGUZtog7021LoGLGN6sRVL1l7QlDGPC5a6mQuHWZ5Zzwe8X8+T7WzliqwCaZvDdVBM3XtRXSUVSwtDI0rcWCxim1V0wrDsL7jiPh28YS/dOWfzy1bWcde9b/N/89ew5VBnv7Jk2JBFvqoF8VVIRHpO0VVLGRCo1RbhkRA8uGdGDZZ+X88g7W/nr4s088s5WvjimF18/dwCDu3eKdzZPCAl4XwqbN+ttoZdUJBFDVa1Kyphgxvbryt9uGMuiH5zPNaf35l/FO5j4h3e4+cmlLNmyz1ekTwZ1dcrXny7izbW7452VsHoWvb9pL5/tPRJy/+yl23hg4cYWzFVkfG0YTfShKD9SFbceet5gFlm32vpAfuR4DSX7j8YiaxGzgGESRv/cDtwzdRQfzLyQ708cSvH2A1w3awlTHnyfV1fsTOjRvOE6Wl3LgrW7+f7sYraXJ8ZNoDE/fGEF//v6upD756/ZzcNvb47bd1Nfwmho/ppd9J85j4rKas657y3O/N+3Qp5ne/lRvvbk0pi0pdU3ejf0zb8vY8bTDafLU9TXSH7DYx8x4b5FLZ6v5rCAYRJOt46Z3DZxCO/PvJDffHEkhypr+O6zyzn/d4t5oo03kHtLS4eO13Dbc8sTPghW19ZR9Nn+kKU8VeVIVS1rS+MzKtlbwgiWv1nvbAFgfekhjlTVNnqe3/1nA2+t38N/1u5q8Tz6AkaQEsYba3bxnyClTW8J41BlNZ9sO9DieWouCxgmYWWlpzJtfD8W3nEes24YS4/sLH716lrO/N+F/PaN9eypaHsN5N7Vb8f268In2w7EtTonHKqw70gVm8uCV0t5r+fjrfGZmsN7Dw62qnDndukAHDxW7dsWKvDlOGkPHK0Ouj8a3iqpxmqkAn8EqZP+hy+s8G1LhKWTLWCYhJeSIkwa0YM53zqLF791FmcPzuWhtzcz4b5F/OiFFXy6+1C8sxg27w3ritEFXD22N39etIklW/bFOVehecc3LP0seEBoan+sNdYqUB8E6udwqqgMXjrNCRJcWkpjVVJeI+6aH3CMZ+De5/vqqy2r6+pYvGEPrxQHzrzUeixgmDZlbL8uPPQVTwP5taf34dWVO5l0/zvMeLqIVSUH4529JrlvHr+6cgT9u3XgjtnFVFSGvlGpatyqrrw/apc2UYJorNoq0L7Dx6mO4Hqqa+soP9LUxH0N3zs7SBAINTNvTAOG8zficRh4ehN6VdXUcdMTS7ntueKWzF5ELGCYNql/bgd+PXUkH8y8iO9dNIQPt+zjC395j68+8THLPt8f7+yF5P1FnpIidMhM4w/XnMKuikru+ffakMf8aeFGJt3/DocaCSrRaOw+5s3vx02UMLzVVht2HeLe19eHDB6L1u9h7D1vsnpH+MH94j+8za9eXRN0X4qvDaPhvmBB4Et//SBoZ4NOWZ4RBsXbD7CnopJt+47yf/PXN9kxwV1N9Pcln/Py8pIGadTVr7axaiX3Pu84jDRXwKiutSopY6LStUMGd1w8lPdnXsiPLjmJ4u0HuOqhD5j26JKErOqpC2gAHdO3C984bxDPF5Xw1vrgXW1L9h9jy94j/M9rcVgfQSEjLYWS/ceCdkutq4PcjhmAp1pq5ksr+dvbm9kQoprw5IJsAFZEsDbEsB7ZIdeSaKwNo0NmKuBpl/AGj31HqtjtavsqO3ScT3cf8vVIWr7tAE9+8Bllhyt5cNFmNpcdDpmv8f/zJr90BbIXirbzr+U7G6TzZu3htzcz+M7XQpYWl22r/6HjHYeR6hcw6o9bF6dOBhYwTFLIzkrnOxcM5r2fXMjPLhvGhl2HuW7WEq7524e8u7EsYcZy+BpAXdtunziEk/I7MfPFVUGrTLy/PJ/9eBvvfNq6i4TVqTKmT2cgeMO2ogzM7Uhuxww+3lruW9c9VPVgj5ws8rMzWRFB9eGpfTvz+b6j7A9SLVU/+WDo7/fgsWo6t0/3e+31xzc/5bpZS/yOP3isOqwqqsy0VCpc+3PapQdP75y6fUYqdQqHQrSj1NQGljAgLaX+Fv2H/3zqe75mpwUMY6LWITONGecO4r2fXMBdXxjOtvKj3PDYx1z78BLWxuk/mVuwtREy01L5/TWnUH6kil+92rBqqk6VHtlZDOnekZ+8uJLDrdituE5hRM8cstJTWBnkJl/ndP8c268Ly7ftZ1BuBwBWNVLldErvzhGtPndK784AFJc0PKax6c29pY6Dx6p9Paa8r71y2qVTcawa94/+isoaX/tHRSMBIzBAZDvnapgPT0Y6t89o8P5u7h81wdowZhfVL2x6rLo2Lr2mLGCYpJSVnspXzx7A2z8+n19PHcmmssNc8ed3+eXcNTFp2AyXrw0joOFgZK8cvnX+IF5evoOiz8rZf6SKK//yHm+sLqVWoV1GKvddPZrSg5U8tHhTq+VXUdLThJN6ZPPYe1t59N0t/vtVSRFheEEOn5cf5agz3qGxEsSpfTuzde+RsJeGHd07hxQJXo3V2PTm3s/64LFqOmTWz4Lk/v5TRKipU176pMRvfzgljOx2aQ2CT7D03jjQ1Dnd93/F87mmpQZvYfr5v1azcU/o6rJYsYBhklpmWio3nNGPt35wHtPG9+OpDz/jot8v5sVlJXGppqofxNVw37fOH0R+dib3zFvH0epaVpYc5MDRaurqlBSB0/p2YeqpPXnk3a2tNlVEnXp+xQ8v8Mzrdc88/1HfqpCSAsN7ZqMK63Z5SnHrdlY0WPNk4brdrCut8JUYGiuFAOypqOSFou10yExjcPeOQUs4jQ3cU1cJw8392ntDdrdVHDxWTWZaKlnpKSFv7tvLj7JkS3nQgBGYF++rhU4bVagecbWu4+rqAPEvYQSqrG58MGIsWMAwJ4TO7TP49dSRvHrrBPp0bc8PXljBl//2YatXU3l/9QYb9ds+I40fTPI03P9ruaevfXpqCnXOr3iAH08eRorAfW9saPR91uw8GHaVRWPdPT0lCBjuNFYHqlPPFBYnOwHF23ZRVVvXYHzMzU8Vcemf3mVEz2wnj41/9j97eRU/mrOSjbsPMaJnTsTflW9UfWWN33oZ7sF5GWmeW+BxV3CrOFbNsapa0lNDB4xrHv6Q2jr1O1edKjV16itlBebDu0Z3yBJGwPcl+PeSCtRmA4aITBaRDSKySURmBtmfKSKznf0fiUh/176fOts3iMgl4Z7TmOYY2SuHF795Fr+9ejRb9h5p9WqqptZ3vuq03gzr0YkHF3mqndLTUqitU98vzZ6d2zHjnIG8umJnyO7Dn+87wuUPvMdDb2+OOr916snr8J6hAoYn4PTq3I7srDS/gXGhus52bp9Br87tWLuzgro65TvPfML7mxqu+e5t8F1bWsGIntnsqqhk3+HjvLaqlP/+1yqgvmqvsTaMo1U1ftU97naGDGfxLvfNd//RKk7/zZscqqzh+aISXnC1HXjtcxrg9x2p4lhVLfNWlvLw257quv96ZIlfT6jArO06WBm0RFTn14ahDRq9A72+uuWnMWlK1AFDRFKBB4FLgeHA9SIyPCDZzcB+VR0M3A/c5xw7HM8a4COAycBfRSQ1zHMa0ywpKcI1hX1Y9IPz+coZ/Xjaqaaas6wk5g2JTY36TU0R7rz8ZN+v1IxU8SthAHzjvEF075TJPfPWBr3xeHvhPLhoE7sORjd9ivfGdVKP4AHD24YhIr4us1npKXTKTAtZ5XTwaDXDe2azZudBjlV7brbTHv2oQboh+R0BWL/rkK+Es7a0gm//8xP+sWQbhyqrfZ9jsBX3vNuOVvk3EB9wBYwxfTsDUNiva/3+o9V+HQt+NGdlg3N3cfW6OvkXb1D0eX0PshUlB/nMNUI7MGv3zFvHY+9tDZLf+ueK599IV6fLcjBPfvBZyH2x0hIljHHAJlXdoqpVwHPAlIA0U4CnnOdzgIvEUyafAjynqsdVdSuwyTlfOOc0Jio57dO5e8pI5t46gb5d2/PDF1ZwzcOxraaqH7gXOs05Q/I4/6Q8wFMl5S5hgKcn2A8vOYnl2w4wd0V9v/9t+47ypb++z3vOr/WjVbXc28hMs157D1WFDJSeEoTQMTP40jne7p9QP8YiRYQRvbJDBox1uyoYXpDNlr1HuO255UHT3PDYR2Q61UUbdh3ylXAeebf+Rruq5KCvau+O51ewaP0e/7y5LsndldU9anxsv64s+++JXDKyR9B8eF34+8XsOHCM7/zzE87834Xsrjjutz81oMQ48Q9vu6awb/jZzl66ndqAz7zWNUe7d/LBbh1CBwzwBN/W1BIBoxfgLrOVONuCplHVGuAg0K2RY8M5JwAiMkNEikSkqKysdfuom+QwslcOc5xqqq1ONdWPXljB0x9+xoK1u1mz8yDlR6papJG8vpdU4/NE/PflJ3NSficG5XV0qoX89199Wm9G9Mzmt29sYPWOg6gqVbW1fLLtAHucm9kpvXP4V/FOXl5e0qABGurr1mcXbWfgz15rcANTX149r08O0o7hLv2c3t/zK/1oVS2je3dmfemhoO+7vfwoI5xG8jfX1d/k3b/qV2w/4PvFvfPAMV81lnscyvLtB/xKat5A8JVHP2LAT+f5fV/uKsfAaUa6dcxs8rvdUnaEs+99i3mrSikNUmprn5HaYNstzrTlwWLxkeM1/P4//u1QVX7jMDyfa1NrlT/xQcOSSiy1+RX3VHUWMAugsLAwMUZnmTbHW011yfAe/H7BBp5bup0XlvlP85CRlkJBThY9srM8f3PaOX+zfH9zO2SS0khDZf28Qo0HjMHdOzH/++cCzk054JwpKcIvrxzBtEc/4oo/v8eA3A6+X+FVtZ7qrG9fMJj7Xl/P92ev4BevrOHik/O5bFQBE4bkkpXe8AY34q43uPvKkVw8PJ8uHTJc1Wee9/b+4t93+Di3zy7mK2f0o66uPqBcPrqAJVv68e+VOxk/oCuz3tnC3f9ewz1TR/l/BuoZ4Z6ZluLX2Hzny6t8zysqaxqMLD9zUDfmuL6Tx9/b6hsoCLB17xHq6tRXwirZX3+8u2fSropKKqtryUpP5Y7ZxeR2yvRNhf7ETafz1SeXNvhsmhJY4vB65qNtbAsyvcjuQ8fp27W937YH39pETrt0Tu3dmd0Vx9my9wj/Xlna6Pv+8c2NbNh1iHumjqRbx8yI8x2plggYO4A+rte9nW3B0pSISBqQA+xr4timzmlMi/NWU/3yCyPYe+Q4pQcq2XngGLsqKtl1sJLSg56/y7btZ9fB0gbz+6SnCt07ZQUEkvrAUum0TYQzD92vXl3DkeM1niqpIAHm9P5dWfLTi5i/Zhf/XrmTec7NxfurvmNmGq/ffg4fbNrHvFWl/GfNLl5avoOOmWlcdHL3Br+0K6vr+PGLK0l9WThzYDcuGZEP1AcE7w18V0Ul727cy7sb99K7Szt6Un/TrlNP9dmFw7pz01n9efKDz7h5wkAGOAP6wNN9NK9TJrNuLGT64x/7tr9S7D+txrMfeyoZvIHrl1eO8AsYaaniV+31l0Wb+Mui+jEqLy2vv2X49VxSTw+tsf26sKLkgN/U7af06UxaimdsRooELx14dcpM45BTKnptVfAb+89cQdCttk4pO+QfZDbsPsT0xz/m8ZsKgfCnjH999S7Wllbw9o8uCCt9NFoiYCwFhojIADw39euA/wpIMxeYDnwIXA28paoqInOBZ0TkD0BPYAjwMZ7/T02d05iYSUnx3Pi7d8riFGdqjEB1dUr50SpXIDnmCyilBytZs7OCBWt3+/2K9mqsu6TXE+9/BsA/bh5PTYg1SLt2yOD6cX25flxf+s+cB8DzRZ6bamqKkJmWygXDunPBsO5UfXEUH27Zx+urSpm/Zhf7A+q/bzyzH18e24fXV5fyxupd/PwVzzxJqc5Yhb/fPJ5ln+8nOyud7p0y2XPoOCX7jzGqV47vHF86rRfjBnRFxBM0nvzgM+YW7+S2iUN8abxVX+cNzfNtO7kgmy+O6Rl0vizv+ISOmWn85osjufPl1QDMnnEm5/9uccjPr0NGKjV1Sn52lu9Xfn52JgvuOI/sLE+jdU1ARGifkUrn9unsPVzFuUPzWLwhdDV3Wqrw6q0T+N1/NvB2I1O2nJTfyTe31h+uOYWaOuXHc1by+wWfBk0/YXBe0O1fHNOLl5cH/93sngY9lqIOGKpaIyK3AvOBVOBxVV0jIncDRao6F3gM+LuIbALK8QQAnHTPA2uBGuA7qloLEOyc0ebVmJaUkiLkdswkt2MmI103TTdV5eCxar9AcqiymglDcsN+n3DTnj24G+9vqp9wMXDQV0ZaCucNzeO8oXncM3Ukc5aVMPOl+l/A1bXKqN45jOqdw48uOYlPdx/mvU17uXxUAQBD8ztxrKqWj7eW8/GdE9ldUcmi9XsY7QzEA08j8th+nucn9fCMzdiw278Tgbu94OYJA3jsva1MPLk7M84dxPbyY/x9yed+6d0N8tPG9/MFjP65HXjj9nOY/Md3g34ez804k8/Lj/gWqfIGaW+wAP/5m8AzQ4C31Lh4QxnfvXAwf34r+Mj6FBFG9c7h7MHdfAHj/mtPYUvZEb9jNuw+xKUje7B4QxlfOq03qp6A4fXXaafx6oqdvm6yGWkpzL31bK78y/t+7+etevrvf60Omp/W0CLjMFT1NVUdqqqDVPU3zrZfOMECVa1U1S+r6mBVHaeqW1zH/sY57iRVfb2xcxrT1ogIndtncHJBNhcM685/je/LN84bRCfXTauljOjpH7Qaa1hPS03h7MH+gcg9dkBEOKlHJ26eMIAeOVm+7fNWlXKnMwYiPzuL68b1DTlGIz87i16d25GRmuIXJNyN6727eKqzvnb2AAB+PXUkV4wu8DuPewS09zw3T/CkH9Yjmxe/dVbQ9x9W0IkrRvf0vT61T2cCJ4oNVnKb/Y0zfM9/MOkk+nVr3yAN1LdDub/L8QO68YNJJzVIOyC3g2+2WREhK91z6/3KGX25bFQB/V1VdgAFOe0anGNtaUWjJZ7W0OYbvY0xHh0y/P87NzatBHhGY7uFs6hRTrt0KqvrfI3GTfnt1aPp1jHDry3A/aPe27bQztXLKPBXv7unUGW1J4+5rgbeUNOFe0sU3sNTUxr2OqqpVV+bhXdNjHYB1xXYe8zLG4/dn3OozzwjLYWaOvVM85IizoC8OtKdgYOBnaG8I9ADhVGTGVM2NYgxSeKMgV39XgdrKHcLDBCZaU0HgM7t0+mUlca8laV8uLnp9UbOHpzLsB7ZfjdddxXT0aoaUqS+BxZAbif/sQfuQsDRKk8js7sba3rAzXVkr2zG9O3coCdaaor4BZdH393CviNVjBvg+dx6ZHtKUoHtGoFjVLxBwXvzdrdHhSrVeQODN0h7z5HhCxj+7+HdHqipHwGxZgHDmCQxpm8Xv9eNDQ4EqK7xv0ldHlAVFMy08f1Y9ctLgs5c2xi/gOG6OQ7N78SUU3v53dwDu+G6j00R4Qun9GRQXkffttP6duGHk4b6Xl97el9e/vbZvtdXnuKpluqRneVX0vnACXhpATdnbwknPcRMsYE37XBKGJeO7MGjNxb6govvr/MegWWYzLQUHr5hLIt+eL7f9saqGVtjMk0LGMYkiYy0FD6793Lf66Z+jfbLDV43H47sdmkhFwJyq61T+s+cxw9fWFG/zXVjm3JqL+6/9tQGx33r/EFB03fpkMGfrx/ToCPAlafUj+vt08W//v/WCwez+leXMGlED64f14epD77Pd/75iS8QXeqM8vbei73tGpeO9ATQrzntJV7ej9Xby8w931OoqqT+3TowcXi+Lzh5r8hbqvOWYkb2ckbLpwiXjOjBgNwOvPWD8/jKGX3Jz86MaF3wWLCAYUyCGty9I5eNanzKisY0VSWVnZXuF2Ai0SkrPeQ03X55cO6u81zjFMKZr+snk4f5VskLJ33fbu35/kRPKePcIf7dUr1Tm0we2YM7Lx/O8Zo6qmrrPKsJ9u3MhcO6A3DmwG5AfYlmyqmekkngtCjedhTveBd3YPa2f3gbtb2qAxrXvcd6q9a8l3jWoIY94gbmdeSeqaNol54a8kdAx8y0JgeDtgRr9DYmQXnmkGr+b7pI67u9jb7huH3ikAaDFsMV7vyOtc75m5oew5feuSk3NtIe6qtuvAMi87OzWPTD8309tv65ZBsQetr3Tln+patwqqQCG87rA4bnM/ct3dtI1msDJqF0W3rnxNAHtiALGMYkqJmXDvNbWjRS4QaMq8f2Zs6ykgZtII0J7MIbruEF2b5f9E35ypn9qKtT33iOpozp28XXPbcpgucm7g0u7pHouw/5zxUVGK68N21vT61BeR0Y1qMTQ/Lr8+mOcd+9cHCDRuxvnDeQ54u2+66tqWnvAWcaFuG+q0ZRcayG37zW9MSSLc0ChjEJ6pIRza+OgqYnOPTKTEvx66ba0n49ZYRv1Ph5J+WFHOQY6CeTh0X0Pt4R7eGqU210vQkJMYFLfSD23OUH5nXkjdvPDXmeMwZ2a9Cw/oNJJ/mN1/CWoh5avJmS/cf48/VjGpzHu5jVtaf3ZUvZYb+A0S7I5IexYG0YxiSpcEsYwWbDbUnu6phtrTSFRWPqVDlWXUtVTV3Qz6ipGjBvIA7/8226Ss2dZN7KnUHbbRqrkmotFjCMSVLh3tA0xjci97iG3EYWBGotn+4+zLsb97Ki5GCT7R3QMIB4D3n9ttClCgXGOdO9h9NmU+eaL6tO8U1q6J+m6faZWLMqKWOSVLhBoM6p6oiF8iNVvrW9H7h+DBefnB+bN2qmEEMtGj/G+bBCjQD38tZ2hVPC8KbpkZNFTa1nJH1OQPuVur6n1ugRFYwFDGOSzND8jny6+3DYJYyfXnoyxybWNp2wGf6x5HPf7LmThueHNZ1IrKWmiO9mH+wzaupe7A3ETQUCb7pwBtR583PlKT353kVDGuzff6SKvYerfIMNW2OQXjAWMIxJMrNuKGRtaUXIZVUDdemQQfj9o5ov3tNaeLkDRrBSWOC9WAP6SZ01qBtnD871m/W24UmgS/sMLhvVI6wOBd4ZS0JNdNjB+S69gwpjvPR8SBYwjEky/XM7NJj9NF7ct+OmBhK2lrQUoQoY268LU8c0XPl5WI9OvP1pWcgbff/cDkGPC9S3W/uwe3qlCBTkZDHl1ODnzUhL4amvjWOg8726SxihpjCJBQsYxpiYu++qUXFvsPXylnSuHtuby0Y1nD/rh5ecxIXDujOqd/Duv706N5x6PFpK021O7gWn3CWM9BATFcZCVO8kIl1FZIGIbHT+Bi3Zish0J81GEZnubGsvIvNEZL2IrBGRe13pbxKRMhEpdh63RJNPY0x8eO+BXzqtd3wz4uKd+C9wVlqv9NQUxjvThIB/FVWvzu18U4Y0JrAaqyl1qhHNE+U+/8C81itNRhuaZgILVXUIsNB57UdEugJ3AeOBccBdrsDyO1UdBowBzhaRS12HzlbVU53Ho1Hm0xhjAHzTrYRaR6Mx90wdGXYPpUjKU6pNN7a7uaemas3272gDxhTgKef5U8DUIGkuARaoarmq7gcWAJNV9aiqLgJQ1SrgEyBxfoYYY1pMnDr1BOVde2Nw945NpPSXmiIRjSSPRGH/Lr7ZccPh7qHVmp9ttG0Y+arqnYZyFxCsk3UvYLvrdYmzzUdEOgNfAP7k2nyViJwLfAp8X1Xd53AfOwOYAdC3b99mXIIxJlbiNV6gMe0yUrl8VAHnBMxqG4r3fhxJL69Ib+LTxveLKL37/K0Zi5ssYYjImyKyOshjijudeprtI867iKQBzwIPuNb6fhXor6qj8ZRIngp1vKrOUtVCVS3MywvvH4AxpnVFWqcfS80dwxBpL69Yxkr/EkbrfbZNBgxVnaiqI4M8XgF2i0gBgPN3T5BT7AD6uF73drZ5zQI2quofXe+5T1WPOy8fBcZGdFXGGNOYZtzMF//o/BbPRnON7p3Dv787AWhbbRhzgenO8+nAK0HSzAcmiUgXp7F7krMNEbkHyAFudx/gDUKOK4HWn8fXGNNiEqkNI+KsaOhBfi32HhESEV932nDXC2kJ0QaMe4GLRWQjMNF5jYgUisijAKpaDvwaWOo87lbVchHpDdwJDAc+Ceg++z2nq+0K4HvATVHm0xgTBwnYhAE0q4AR8bWEmh69pfTr1p7eXdrx8yuGx/R93KJq9FbVfcBFQbYXAbe4Xj8OPB6QpoQQ35uq/hT4aTR5M8aYoBKotBONrPRU3vvJha36nja9uTEmZmL9K7u5Ium91Zz4Eq/JAWPNAoYxJuaS4f4ZaehL1Oq4aFjAMMbETCLeNJMgdsWNBQxjTMwl0jgMiHzajkgl1tW2HAsYxpiYScACRrPbFyIdtZ6I1x4tCxjGmJhLtDaMRKwqawssYBhjYiYRb8yRxq7mlEgSLUC2FAsYxpiYS7T7Z7MG7kV8QAJGyyhZwDDGxEwijsNI1l//rcEChjEm5hJtIFusB+4lKwsYxpiYSaZamcjnkko+FjCMMTGXSL/SE21MSFtiAcMYc8KJ5cC9RKt+a0kWMIwxMZdI99Dm5iXSBvxkqo7zsoBhjImZRFzTG0jOBoZWYAHDGBN7bbiEEflAvwgPaEOiChgi0lVEFojIRudvlxDppjtpNorIdNf2xSKywVltr1hEujvbM0VktohsEpGPRKR/NPk0xsRHov6Qb9b4kARbcS8eoi1hzAQWquoQYKHz2o+IdAXuAsYD44C7AgLLNFU91XnscbbdDOxX1cHA/cB9UebTGBNH1jMpOUQbMKYATznPnwKmBklzCbBAVctVdT+wAJgcwXnnABdJwlaGGmNCSYb/tZH2ekrm0BhtwMhX1VLn+S4gP0iaXsB21+sSZ5vXE0511M9dQcF3jKrWAAeBbsEyICIzRKRIRIrKysqiuBRjTKwkWr1+cwJZxAP3kiBYBkprKoGIvAn0CLLrTvcLVVURifSfxTRV3SEinYAXgRuApyM5garOAmYBFBYWJtg/S2NObIl4z0zmcRKx1mTAUNWJofaJyG4RKVDVUhEpAPYESbYDON/1ujew2Dn3DufvIRF5Bk8bx9POMX2AEhFJA3KAfeFckDEm8STaLTqWgSyZA1K0VVJzAW+vp+nAK0HSzAcmiUgXp7F7EjBfRNJEJBdARNKBK4DVQc57NfCWJvO3YEySSsSmx+beSCK9ksS78ug1WcJowr3A8yJyM/A5cA2AiBQC31TVW1S1XER+DSx1jrnb2dYBT+BIB1KBN4FHnDSPAX8XkU1AOXBdlPk0xsRRov3eS8A41iZEFTBUdR9wUZDtRcAtrtePA48HpDkCjA1x3krgy9HkzRgTf8lwY471QL+2xEZ6G2NiLpFuos2eSyrC6JcMwTKQBQxjTMwk6j0zGUdhtwYLGMaYmEukJoxIR51HnD6BrrWlWcAwxpxwmjVwL+L3SL5SjAUMY0zsJOBNM5lLALFmAcMYE3OJNvlgAsaxNsEChjEmZhLxvhzr9S0SLTi2JAsYxpjYS7h7aOShzEolFjCMMTFkN9nkYgHDGBNziVTAsCVam88ChjEmZhJ1gFzzutXaSG8LGMaYmEusX90JlZk2xQKGMSZmEvVXdiTZSqxgF18WMIwxMZdIXU2bP/lghOkTtDouGhYwjDExk6i3zEQt+SS6qAKGiHQVkQUistH52yVEuulOmo0iMt3Z1klEil2PvSLyR2ffTSJS5tp3S7DzGmPahrZcrWOTD9aLtoQxE1ioqkOAhc5rPyLSFbgLGI9nze67RKSLqh5S1VO9Dzwr9r3kOnS2a/+jUebTGBMHifhLvrXu54l47dGKNmBMAZ5ynj8FTA2S5hJggaqWq+p+YAEw2Z1ARIYC3YF3o8yPMSYBJdqP7mRsX2gN0QaMfFUtdZ7vAvKDpOkFbHe9LnG2uV2Hp0Th/nd1lYisFJE5ItInVAZEZIaIFIlIUVlZWTMuwRgTK4l4Y450fXGbS6pekwFDRN4UkdVBHlPc6ZybfXM/qeuAZ12vXwX6q+poPCWSp4Ie5XnfWapaqKqFeXl5zXx7Y0wsRXqTjrVmDdyLuJdU8klrKoGqTgy1T0R2i0iBqpaKSAGwJ0iyHcD5rte9gcWuc5wCpKnqMtd77nOlfxT4bVP5NMYkoAS8ayZW6Gpboq2SmgtMd55PB14JkmY+MElEuji9qCY527yux790gRN8vK4E1kWZT2NMHCVYASOmcSzRrrUlNVnCaMK9wPMicjOeXk7XAIhIIfBNVb1FVctF5NfAUueYu1W13HWOa4DLAs77PRG5EqgByoGbosynMSYOErCA0Ww2l1SUAcOpOrooyPYi4BbX68eBx0OcY2CQbT8FfhpN3owxJphkLgHEmo30NsbEjCToz+xI8hVxr6pIM9OGWMAwxsRcIv2qb26PLZtLygKGMSaGku+WeWKzgGGMiZmCzllMPDmfrIzEudWcMzSPIfkdw04f8cC9RCpOtbBoe0kZY0xIZw3K5axBufHOhp8H/+u0Zh0XaWkpQZtvopI4Yd8YY0xCs4BhjDGNiLSCKXkrpCxgGGNMWBK1i3BrsoBhjDEmLBYwjDGmEZH3kopNPhKBBQxjjAlD5L2kkq8KywKGMcaYsFjAMMaYRkS8gp5VSRljzInNVtyzgGGMMSZMFjCMMaYREfeSSuI6qagChoh0FZEFIrLR+dslRLo3ROSAiPw7YPsAEflIRDaJyGwRyXC2ZzqvNzn7+0eTT2OMiVakvZ6SsJNU1CWMmcBCVR0CLHReB/N/wA1Btt8H3K+qg4H9wM3O9puB/c72+510xhhj4ijagDEFeMp5/hQwNVgiVV0IHHJvE0+4vhCYE+R493nnABdJMnZqNsYkvKH5nbh8VEHY6dNTU7h8VAH9u3WIYa7iI9rpzfNVtdR5vgvIj+DYbsABVa1xXpcAvZznvYDtAKpaIyIHnfR7A08iIjOAGQB9+/aN+AKMMaYxl48u4PLR4QeMDplpPDiteVOoJ7omA4aIvAn0CLLrTvcLVVURafXWHlWdBcwCKCwsTN7WJmOMibMmA4aqTgy1T0R2i0iBqpaKSAGwJ4L33gd0FpE0p5TRG9jh7NsB9AFKRCQNyHHSG2OMiZNo2zDmAtOd59OBV8I9UD3rGC4Crg5yvPu8VwNvaTKve2iMMW1AtAHjXuBiEdkITHReIyKFIvKoN5GIvAu8gKfxukRELnF2/QS4Q0Q24WmjeMzZ/hjQzdl+B6F7XxljjGklkkw/3AsLC7WoqCje2TDGmDZFRJapamFT6WyktzHGmLBYwDDGGBMWCxjGGGPCklRtGCJSBnzezMNzCTIw8ARwol43nLjXbtd9Ygnnuvupal5TJ0qqgBENESkKp9En2Zyo1w0n7rXbdZ9YWvK6rUrKGGNMWCxgGGOMCYsFjHqz4p2BODlRrxtO3Gu36z6xtNh1WxuGMcaYsFgJwxhjTFgsYBhjjAmLBQxARCaLyAZnDfGkm+hQRD4TkVUiUiwiRc62oOuxi8cDzmexUkTazEowIvK4iOwRkdWubRFfp4hMd9JvFJHpwd4rkYS47l+KyA7nOy8Wkctc+37qXPcG10Sgbe7/gYj0EZFFIrJWRNaIyG3O9qT+zhu57th/56p6Qj+AVGAzMBDIAFYAw+Odrxa+xs+A3IBtvwVmOs9nAvc5zy8DXgcEOAP4KN75j+A6zwVOA1Y39zqBrsAW528X53mXeF9bM677l8APg6Qd7vwbzwQGOP/2U9vi/wOgADjNed4J+NS5vqT+zhu57ph/51bCgHHAJlXdoqpVwHN41hRPdqHWY58CPK0eS/AschX++pRxpKrvAOUBmyO9zkuABaparqr7gQXA5JhnPgohrjuUKcBzqnpcVbcCm/D8H2hz/w9UtVRVP3GeHwLW4VneOam/80auO5QW+84tYLjWD3e41xZPFgr8R0SWOWugQ+j12JPt84j0OpPp+m91ql4e91bLkKTXLSL9gTHAR5xA33nAdUOMv3MLGCeGCap6GnAp8B0ROde9Uz3l1qTvX32iXKfjIWAQcCpQCvw+rrmJIRHpCLwI3K6qFe59yfydB7numH/nFjDq1w/3cq8tnhRUdYfzdw/wMp6i6G5vVZP4r8eebJ9HpNeZFNevqrtVtVZV64BH8HznkGTXLSLpeG6a/1TVl5zNSf+dB7vu1vjOLWDAUmCIiAwQkQzgOjxriicFEekgIp28z4FJwGpCr8c+F7jR6VFyBnDQVbxviyK9zvnAJBHp4hTpJznb2pSAdqcv4vnOwXPd14lIpogMAIYAH9MG/x+IiOBZznmdqv7BtSupv/NQ190q33m8W/wT4YGn98SneHoM3Bnv/LTwtQ3E0/thBbDGe3141lBfCGwE3gS6OtsFeND5LFYBhfG+hgiu9Vk8RfFqPPWxNzfnOoGv4WkY3AR8Nd7X1czr/rtzXSudm0CBK/2dznVvAC51bW9T/w+ACXiqm1YCxc7jsmT/zhu57ph/5zY1iDHGmLBYlZQxxpiwWMAwxhgTFgsYxhhjwmIBwxhjTFgsYBhjjAmLBQxjjDFhsYBhjDEmLP8PoCrfH1DP7AkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-175)  var1(t-174)  var1(t-173)  var1(t-172)  var1(t-171)  \\\n",
      "175    90.500000    90.275910    90.051821    89.827731    89.603641   \n",
      "176    90.275910    90.051821    89.827731    89.603641    89.379552   \n",
      "177    90.051821    89.827731    89.603641    89.379552    89.155462   \n",
      "178    89.827731    89.603641    89.379552    89.155462    88.931373   \n",
      "179    89.603641    89.379552    89.155462    88.931373    88.707283   \n",
      "\n",
      "     var1(t-170)  var1(t-169)  var1(t-168)  var1(t-167)  var1(t-166)  ...  \\\n",
      "175    89.379552    89.155462    88.931373    88.707283    88.494958  ...   \n",
      "176    89.155462    88.931373    88.707283    88.494958    88.427731  ...   \n",
      "177    88.931373    88.707283    88.494958    88.427731    88.360504  ...   \n",
      "178    88.707283    88.494958    88.427731    88.360504    88.293277  ...   \n",
      "179    88.494958    88.427731    88.360504    88.293277    88.226050  ...   \n",
      "\n",
      "     var1(t+45)  var2(t+45)  var1(t+46)  var2(t+46)  var1(t+47)  var2(t+47)  \\\n",
      "175   83.025023    0.000280   83.006349    0.000280   82.987675    0.000280   \n",
      "176   83.006349    0.000280   82.987675    0.000280   82.969001    0.000280   \n",
      "177   82.987675    0.000280   82.969001    0.000280   82.950327    0.000279   \n",
      "178   82.969001    0.000280   82.950327    0.000279   82.931653    0.000279   \n",
      "179   82.950327    0.000279   82.931653    0.000279   82.912979    0.000279   \n",
      "\n",
      "     var1(t+48)  var2(t+48)  var1(t+49)  var2(t+49)  \n",
      "175   82.969001    0.000280   82.950327    0.000279  \n",
      "176   82.950327    0.000279   82.931653    0.000279  \n",
      "177   82.931653    0.000279   82.912979    0.000279  \n",
      "178   82.912979    0.000279   82.894304    0.000279  \n",
      "179   82.894304    0.000279   82.875630    0.000279  \n",
      "\n",
      "[5 rows x 276 columns]\n",
      "Index(['var1(t-175)', 'var1(t-174)', 'var1(t-173)', 'var1(t-172)',\n",
      "       'var1(t-171)', 'var1(t-170)', 'var1(t-169)', 'var1(t-168)',\n",
      "       'var1(t-167)', 'var1(t-166)',\n",
      "       ...\n",
      "       'var1(t+45)', 'var2(t+45)', 'var1(t+46)', 'var2(t+46)', 'var1(t+47)',\n",
      "       'var2(t+47)', 'var1(t+48)', 'var2(t+48)', 'var1(t+49)', 'var2(t+49)'],\n",
      "      dtype='object', length=276)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 175, n_out = 50)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 176):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-150:]\n",
    "trainX = train[:,:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-150:]\n",
    "forecastX = forecast[:,:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 1, 126) (2225, 150) (1, 1, 126)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28/28 [==============================] - 2s 20ms/step - loss: 4939.2900 - val_loss: 2357.5525\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4580.8779 - val_loss: 2201.0276\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4375.4619 - val_loss: 2106.4685\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4205.2847 - val_loss: 2029.8268\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4058.7615 - val_loss: 1965.5414\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3919.8757 - val_loss: 1904.2506\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3771.5107 - val_loss: 1842.4009\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3637.9890 - val_loss: 1782.5798\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3504.4800 - val_loss: 1726.4110\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3374.8672 - val_loss: 1674.9026\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3243.4460 - val_loss: 1623.1232\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3122.5469 - val_loss: 1574.5101\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3005.3650 - val_loss: 1528.5703\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2893.5015 - val_loss: 1482.3209\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2785.2209 - val_loss: 1437.3724\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2667.8848 - val_loss: 1391.8118\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2562.0115 - val_loss: 1355.6309\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2460.6865 - val_loss: 1313.4500\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2362.6392 - val_loss: 1276.3849\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2270.2314 - val_loss: 1241.0067\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2182.6709 - val_loss: 1213.6947\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2113.5349 - val_loss: 1188.0642\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2016.6251 - val_loss: 1162.4430\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1935.4797 - val_loss: 1137.4556\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1888.0635 - val_loss: 1116.3525\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1783.8126 - val_loss: 1088.6205\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1711.3563 - val_loss: 1064.2939\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1716.7296 - val_loss: 1035.3564\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1576.8434 - val_loss: 1025.2000\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1510.5463 - val_loss: 1003.6995\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1468.3503 - val_loss: 1014.6492\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1397.7429 - val_loss: 1000.2772\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1343.6951 - val_loss: 1002.5186\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1336.0308 - val_loss: 1009.3556\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1241.9642 - val_loss: 1008.8235\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1190.8250 - val_loss: 995.0699\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1152.0549 - val_loss: 992.0521\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1142.6389 - val_loss: 1017.5923\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1060.2709 - val_loss: 996.6874\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1028.7819 - val_loss: 1023.4532\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1072.8398 - val_loss: 1049.6019\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 980.6453 - val_loss: 1115.6552\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 924.9823 - val_loss: 1099.1852\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 881.0713 - val_loss: 1080.6593\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 842.9885 - val_loss: 1064.7534\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 823.5577 - val_loss: 1105.3025\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 796.0372 - val_loss: 1087.9111\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 768.3154 - val_loss: 1145.6927\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 738.8929 - val_loss: 1156.9409\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 732.7927 - val_loss: 1178.4443\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 691.2673 - val_loss: 1184.8041\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 666.6842 - val_loss: 1185.7888\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 643.5763 - val_loss: 1184.5824\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 673.3236 - val_loss: 1201.5609\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 603.6765 - val_loss: 1196.4414\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 598.2089 - val_loss: 1245.9794\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 599.5829 - val_loss: 1236.9872\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 567.9650 - val_loss: 1251.3501\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 569.2786 - val_loss: 1270.0146\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 529.8386 - val_loss: 1271.5081\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 511.4838 - val_loss: 1272.3789\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 506.0832 - val_loss: 1261.7406\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 504.4764 - val_loss: 1284.4871\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 481.0022 - val_loss: 1262.2433\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 484.9865 - val_loss: 1287.7583\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 548.3465 - val_loss: 1331.7755\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 487.3277 - val_loss: 1391.8927\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 442.2448 - val_loss: 1397.4568\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 452.8179 - val_loss: 1383.3524\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 460.3981 - val_loss: 1375.9556\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 425.2875 - val_loss: 1389.0538\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 396.0445 - val_loss: 1376.0979\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 414.4284 - val_loss: 1400.7957\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 401.3905 - val_loss: 1382.9176\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 395.7203 - val_loss: 1395.7506\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 392.0302 - val_loss: 1440.3646\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 371.7700 - val_loss: 1443.5404\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 364.3514 - val_loss: 1438.5884\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 376.6682 - val_loss: 1438.5979\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 372.7687 - val_loss: 1451.3726\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 354.6978 - val_loss: 1432.8380\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 361.8807 - val_loss: 1438.7274\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 355.9019 - val_loss: 1430.9310\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 353.9290 - val_loss: 1449.0699\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 365.6507 - val_loss: 1446.8392\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 361.1874 - val_loss: 1455.1028\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 357.5139 - val_loss: 1459.2070\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 352.9989 - val_loss: 1464.7048\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 350.1045 - val_loss: 1491.8276\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 350.2216 - val_loss: 1546.6158\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 345.4933 - val_loss: 1548.8794\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 344.8544 - val_loss: 1559.5657\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 342.6750 - val_loss: 1559.8408\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 339.3251 - val_loss: 1551.7385\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 338.0486 - val_loss: 1557.4048\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 330.6667 - val_loss: 1545.2991\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 327.8366 - val_loss: 1541.1841\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 331.3111 - val_loss: 1571.9830\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 329.3295 - val_loss: 1566.4266\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 330.3662 - val_loss: 1574.7889\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 325.0128 - val_loss: 1564.0161\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 323.3058 - val_loss: 1557.0413\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 336.1646 - val_loss: 1550.5880\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 334.1616 - val_loss: 1555.0073\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 317.1977 - val_loss: 1561.9087\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 314.9612 - val_loss: 1557.4104\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 313.7096 - val_loss: 1555.7739\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 312.8560 - val_loss: 1553.0989\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 323.7986 - val_loss: 1551.6222\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 322.0106 - val_loss: 1551.0634\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 327.8915 - val_loss: 1585.7719\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 324.2705 - val_loss: 1572.9679\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 323.7372 - val_loss: 1555.6787\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 320.0818 - val_loss: 1544.3314\n",
      "Epoch 115/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 310.8514 - val_loss: 1543.6530\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 317.6183 - val_loss: 1577.5161\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 312.1797 - val_loss: 1564.1963\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 322.2576 - val_loss: 1553.1993\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 315.1230 - val_loss: 1528.8076\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 308.9789 - val_loss: 1514.0645\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 307.8153 - val_loss: 1518.8953\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 305.6667 - val_loss: 1516.2224\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 303.3351 - val_loss: 1543.6405\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 296.0551 - val_loss: 1517.6897\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 304.6138 - val_loss: 1507.4039\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 308.7197 - val_loss: 1536.9326\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 305.8321 - val_loss: 1533.9224\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 292.6976 - val_loss: 1521.8787\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 290.7808 - val_loss: 1508.4640\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.7911 - val_loss: 1503.4922\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 288.7920 - val_loss: 1497.5553\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 287.7743 - val_loss: 1495.9795\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 286.6876 - val_loss: 1489.8340\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 285.2749 - val_loss: 1484.3126\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 284.2191 - val_loss: 1477.0614\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 282.8841 - val_loss: 1471.9293\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 281.2017 - val_loss: 1464.7699\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.9593 - val_loss: 1438.8468\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 281.4247 - val_loss: 1422.3617\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 286.1016 - val_loss: 1444.5974\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 283.0881 - val_loss: 1435.4154\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 279.8540 - val_loss: 1419.6884\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 289.8171 - val_loss: 1417.8850\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 291.4094 - val_loss: 1458.6775\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 297.2425 - val_loss: 1525.9254\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 303.6495 - val_loss: 1500.1187\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 305.5133 - val_loss: 1509.4386\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 292.8488 - val_loss: 1482.8994\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 280.7429 - val_loss: 1450.8972\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 275.9744 - val_loss: 1433.9247\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 274.4810 - val_loss: 1429.9500\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 272.1015 - val_loss: 1414.8125\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 270.8527 - val_loss: 1409.9495\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 268.9501 - val_loss: 1376.1377\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 277.2730 - val_loss: 1427.3738\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 270.5130 - val_loss: 1400.4791\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 264.2263 - val_loss: 1386.7109\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 263.1208 - val_loss: 1383.8789\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 262.0656 - val_loss: 1382.0743\n",
      "Epoch 160/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 261.3109 - val_loss: 1376.0123\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 260.2469 - val_loss: 1374.3630\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 259.1591 - val_loss: 1373.4751\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 258.3517 - val_loss: 1366.5242\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 269.4205 - val_loss: 1365.0697\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 268.1930 - val_loss: 1367.0690\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 267.4542 - val_loss: 1365.0918\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 266.0134 - val_loss: 1365.3276\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 267.0911 - val_loss: 1402.4978\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 262.6768 - val_loss: 1397.5319\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 258.9001 - val_loss: 1380.6235\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 254.7385 - val_loss: 1358.2135\n",
      "Epoch 172/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 264.9609 - val_loss: 1350.5344\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 263.6528 - val_loss: 1349.3075\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 261.1735 - val_loss: 1333.1471\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 258.2693 - val_loss: 1331.6688\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 257.3293 - val_loss: 1328.4495\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 263.3824 - val_loss: 1335.1338\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 254.8340 - val_loss: 1329.0289\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 253.5442 - val_loss: 1329.4498\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.5883 - val_loss: 1329.6879\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.4523 - val_loss: 1326.8771\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 250.6902 - val_loss: 1321.5242\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 250.0098 - val_loss: 1318.5743\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 265.1841 - val_loss: 1320.8696\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 266.2646 - val_loss: 1382.9703\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 261.0262 - val_loss: 1378.2098\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 259.8724 - val_loss: 1365.7139\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 259.0180 - val_loss: 1361.7703\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 257.9013 - val_loss: 1362.2982\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 256.9963 - val_loss: 1343.5840\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 275.0960 - val_loss: 1338.3752\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 273.8289 - val_loss: 1340.8564\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 264.3808 - val_loss: 1298.9008\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 275.0824 - val_loss: 1295.9330\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 268.0087 - val_loss: 1300.1625\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 267.0127 - val_loss: 1307.2255\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 264.4941 - val_loss: 1306.0219\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 288.8329 - val_loss: 1307.4275\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 286.7172 - val_loss: 1311.3486\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 286.5214 - val_loss: 1322.6801\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 280.8969 - val_loss: 1321.6318\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 256.7676 - val_loss: 1329.0156\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 255.3999 - val_loss: 1319.7424\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 254.5201 - val_loss: 1316.9191\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 253.2964 - val_loss: 1315.8401\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.8790 - val_loss: 1316.5857\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.4289 - val_loss: 1302.9318\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 282.8393 - val_loss: 1335.4537\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 273.4395 - val_loss: 1316.6755\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 267.1337 - val_loss: 1303.7573\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 264.6717 - val_loss: 1293.6678\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 263.1173 - val_loss: 1300.3917\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 261.8554 - val_loss: 1293.4918\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 300.0418 - val_loss: 1367.0812\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 326.1635 - val_loss: 1386.1136\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 313.3889 - val_loss: 1395.1241\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 293.3224 - val_loss: 1398.7362\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 286.4549 - val_loss: 1386.5603\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 309.3038 - val_loss: 1381.8073\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 307.9184 - val_loss: 1436.7500\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 284.7282 - val_loss: 1428.8031\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.4681 - val_loss: 1405.1388\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 290.5723 - val_loss: 1442.6729\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 277.6547 - val_loss: 1392.2510\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 287.4815 - val_loss: 1360.6913\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 280.0964 - val_loss: 1341.2679\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 276.1998 - val_loss: 1335.6940\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 272.0927 - val_loss: 1324.7701\n",
      "Epoch 229/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 239.0890 - val_loss: 1239.4985\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.4219 - val_loss: 1242.7133\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 255.7880 - val_loss: 1280.3188\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 253.9676 - val_loss: 1275.2750\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.6507 - val_loss: 1279.9185\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 250.9133 - val_loss: 1276.8815\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 249.3092 - val_loss: 1273.4086\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 244.8982 - val_loss: 1261.1555\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.6861 - val_loss: 1275.0820\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 253.1456 - val_loss: 1301.1331\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 246.9657 - val_loss: 1294.4390\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 245.4612 - val_loss: 1285.0775\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 260.5987 - val_loss: 1337.6996\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 253.5385 - val_loss: 1327.7096\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 250.6350 - val_loss: 1311.7753\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.8346 - val_loss: 1298.7352\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 245.2694 - val_loss: 1285.9723\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 242.2989 - val_loss: 1273.7394\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 238.8291 - val_loss: 1252.8500\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 244.1448 - val_loss: 1282.7711\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 237.1888 - val_loss: 1258.0870\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 234.4376 - val_loss: 1242.3705\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 230.7046 - val_loss: 1236.0244\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 229.6253 - val_loss: 1231.6759\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 228.4016 - val_loss: 1228.4005\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.7621 - val_loss: 1270.3918\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 234.8792 - val_loss: 1264.6716\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 232.1521 - val_loss: 1250.6184\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 230.9480 - val_loss: 1245.2976\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 230.1454 - val_loss: 1241.8073\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 229.1244 - val_loss: 1237.6539\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 228.1568 - val_loss: 1232.8956\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.2838 - val_loss: 1227.4640\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 226.5041 - val_loss: 1224.1105\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 225.7127 - val_loss: 1220.5911\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 225.5244 - val_loss: 1223.7783\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 225.5921 - val_loss: 1239.2048\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 230.8709 - val_loss: 1241.9733\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 225.0553 - val_loss: 1180.6840\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 296.0933 - val_loss: 1172.8599\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 287.6812 - val_loss: 1192.3973\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 281.0819 - val_loss: 1204.5188\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 280.2408 - val_loss: 1233.6401\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 268.0721 - val_loss: 1236.4626\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 267.2686 - val_loss: 1257.8560\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 260.6051 - val_loss: 1268.7642\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 238.1290 - val_loss: 1266.1306\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 256.2297 - val_loss: 1271.5771\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 254.8037 - val_loss: 1275.5913\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 253.6669 - val_loss: 1265.9135\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.4783 - val_loss: 1271.7683\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 249.8710 - val_loss: 1277.5967\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 248.5031 - val_loss: 1283.5640\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.3254 - val_loss: 1286.6334\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 246.2628 - val_loss: 1289.1603\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 245.5145 - val_loss: 1287.9458\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 260.9540 - val_loss: 1331.2913\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 248.3763 - val_loss: 1299.7241\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 243.3957 - val_loss: 1283.7605\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 248.0775 - val_loss: 1305.3511\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 245.2350 - val_loss: 1297.3175\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 241.0702 - val_loss: 1289.4550\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 239.7376 - val_loss: 1281.5292\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 240.1103 - val_loss: 1270.1218\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 270.8289 - val_loss: 1254.0793\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 273.4800 - val_loss: 1254.7571\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 236.9704 - val_loss: 1256.3160\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 236.1929 - val_loss: 1253.3270\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 236.8099 - val_loss: 1242.6188\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 269.4781 - val_loss: 1242.0352\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 266.4724 - val_loss: 1259.0211\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 263.6787 - val_loss: 1272.9060\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 261.0539 - val_loss: 1287.0671\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 258.9055 - val_loss: 1296.9553\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 258.2925 - val_loss: 1297.6455\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 256.6460 - val_loss: 1304.2780\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 255.2685 - val_loss: 1312.1144\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 254.2244 - val_loss: 1317.0463\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 253.5800 - val_loss: 1303.4994\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 253.6979 - val_loss: 1292.9713\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 251.5867 - val_loss: 1303.7545\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 250.5745 - val_loss: 1307.1399\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 249.7083 - val_loss: 1308.5140\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 248.7872 - val_loss: 1308.1495\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 248.4485 - val_loss: 1308.7864\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.5370 - val_loss: 1310.3282\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 246.7598 - val_loss: 1305.3864\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 246.2993 - val_loss: 1309.6144\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 245.0074 - val_loss: 1308.0653\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 244.2964 - val_loss: 1306.4236\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 243.5625 - val_loss: 1305.3916\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 242.8805 - val_loss: 1304.6631\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 242.2079 - val_loss: 1304.3274\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 241.5397 - val_loss: 1303.6804\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 240.8828 - val_loss: 1302.4767\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 240.3033 - val_loss: 1301.8263\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 239.6048 - val_loss: 1300.5883\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 238.9716 - val_loss: 1299.0138\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 238.3459 - val_loss: 1297.5031\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 237.7260 - val_loss: 1295.5488\n",
      "Epoch 329/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 237.1060 - val_loss: 1294.0378\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 236.4888 - val_loss: 1292.1052\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 235.8768 - val_loss: 1290.2007\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 235.2672 - val_loss: 1288.0895\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 234.6607 - val_loss: 1286.0067\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 234.0383 - val_loss: 1282.8611\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 233.1295 - val_loss: 1278.4548\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 232.4846 - val_loss: 1278.6599\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 247.0350 - val_loss: 1313.8673\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 231.2398 - val_loss: 1272.9052\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 230.9627 - val_loss: 1262.5118\n",
      "Epoch 340/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 265.6439 - val_loss: 1272.5203\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 249.4238 - val_loss: 1278.3827\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.7126 - val_loss: 1336.4905\n",
      "Epoch 343/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 233.8532 - val_loss: 1281.5626\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.7376 - val_loss: 1267.5476\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.1851 - val_loss: 1259.9755\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 261.0287 - val_loss: 1268.2552\n",
      "Epoch 347/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 258.7319 - val_loss: 1291.8816\n",
      "Epoch 348/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 227.9108 - val_loss: 1279.8285\n",
      "Epoch 349/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 225.0344 - val_loss: 1265.9407\n",
      "Epoch 350/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 224.4560 - val_loss: 1262.3875\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 223.8700 - val_loss: 1257.2600\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 223.2898 - val_loss: 1253.0245\n",
      "Epoch 353/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 222.7216 - val_loss: 1249.2870\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 222.1471 - val_loss: 1245.0227\n",
      "Epoch 355/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 221.5884 - val_loss: 1244.0712\n",
      "Epoch 356/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 220.9218 - val_loss: 1238.6547\n",
      "Epoch 357/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 226.3305 - val_loss: 1235.2236\n",
      "Epoch 358/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 254.4867 - val_loss: 1237.0155\n",
      "Epoch 359/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 252.4848 - val_loss: 1251.7128\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 250.1596 - val_loss: 1264.0442\n",
      "Epoch 361/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 248.2623 - val_loss: 1270.5563\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 245.1067 - val_loss: 1277.4232\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 219.3932 - val_loss: 1267.5814\n",
      "Epoch 364/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 217.5010 - val_loss: 1255.6958\n",
      "Epoch 365/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 228.6609 - val_loss: 1297.5826\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 224.1122 - val_loss: 1273.3647\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 222.8040 - val_loss: 1256.8564\n",
      "Epoch 368/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 215.7575 - val_loss: 1229.1924\n",
      "Epoch 369/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 213.8534 - val_loss: 1222.6924\n",
      "Epoch 370/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 213.2883 - val_loss: 1218.7115\n",
      "Epoch 371/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 212.7065 - val_loss: 1215.2932\n",
      "Epoch 372/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 212.1108 - val_loss: 1212.3872\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 211.5466 - val_loss: 1208.3761\n",
      "Epoch 374/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 210.9935 - val_loss: 1205.0308\n",
      "Epoch 375/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 210.4364 - val_loss: 1201.4565\n",
      "Epoch 376/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 209.8806 - val_loss: 1198.3418\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 209.3119 - val_loss: 1195.7666\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 208.7289 - val_loss: 1192.9056\n",
      "Epoch 379/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 208.1625 - val_loss: 1189.9359\n",
      "Epoch 380/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 207.5921 - val_loss: 1187.0306\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 207.0231 - val_loss: 1184.2083\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 206.5926 - val_loss: 1178.2957\n",
      "Epoch 383/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 205.7552 - val_loss: 1171.0128\n",
      "Epoch 384/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 205.2947 - val_loss: 1167.6344\n",
      "Epoch 385/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 204.4088 - val_loss: 1159.9819\n",
      "Epoch 386/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 203.6509 - val_loss: 1151.3673\n",
      "Epoch 387/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 203.2760 - val_loss: 1146.2411\n",
      "Epoch 388/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 202.5638 - val_loss: 1152.4624\n",
      "Epoch 389/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 201.9769 - val_loss: 1150.0487\n",
      "Epoch 390/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 201.3631 - val_loss: 1140.8278\n",
      "Epoch 391/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 200.9469 - val_loss: 1134.8604\n",
      "Epoch 392/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 200.2301 - val_loss: 1136.7977\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 199.8105 - val_loss: 1129.7263\n",
      "Epoch 394/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 201.6816 - val_loss: 1147.2638\n",
      "Epoch 395/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 198.6400 - val_loss: 1126.7217\n",
      "Epoch 396/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 198.1388 - val_loss: 1129.8259\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 197.3944 - val_loss: 1122.2781\n",
      "Epoch 398/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 196.8371 - val_loss: 1120.6742\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 196.2858 - val_loss: 1118.9048\n",
      "Epoch 400/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 195.7372 - val_loss: 1116.3026\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 195.1947 - val_loss: 1113.7021\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 194.6465 - val_loss: 1111.9648\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 194.0637 - val_loss: 1111.4435\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 193.6668 - val_loss: 1115.0276\n",
      "Epoch 405/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 193.0830 - val_loss: 1113.6526\n",
      "Epoch 406/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 192.5402 - val_loss: 1111.0646\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 192.0028 - val_loss: 1108.9277\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 191.4585 - val_loss: 1107.0822\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 190.9207 - val_loss: 1104.2175\n",
      "Epoch 410/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 190.3905 - val_loss: 1101.3804\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 189.8575 - val_loss: 1099.3137\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 189.3196 - val_loss: 1097.2686\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 188.7878 - val_loss: 1095.0571\n",
      "Epoch 414/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 188.2567 - val_loss: 1092.5366\n",
      "Epoch 415/500\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 187.7332 - val_loss: 1090.1125\n",
      "Epoch 416/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 187.2013 - val_loss: 1088.3177\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 186.6741 - val_loss: 1085.6129\n",
      "Epoch 418/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 186.1565 - val_loss: 1082.5173\n",
      "Epoch 419/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 185.6320 - val_loss: 1080.4209\n",
      "Epoch 420/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 185.1067 - val_loss: 1078.4491\n",
      "Epoch 421/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 184.5794 - val_loss: 1075.5708\n",
      "Epoch 422/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 184.0661 - val_loss: 1074.1588\n",
      "Epoch 423/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 183.5423 - val_loss: 1072.3678\n",
      "Epoch 424/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 183.0254 - val_loss: 1069.5161\n",
      "Epoch 425/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 182.4622 - val_loss: 1061.9877\n",
      "Epoch 426/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 175.4172 - val_loss: 1027.3934\n",
      "Epoch 427/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 181.7954 - val_loss: 1025.6104\n",
      "Epoch 428/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 181.0691 - val_loss: 1028.5671\n",
      "Epoch 429/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 180.3023 - val_loss: 1029.4806\n",
      "Epoch 430/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 179.5987 - val_loss: 1025.4078\n",
      "Epoch 431/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 172.0646 - val_loss: 978.2318\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 183.0730 - val_loss: 998.9536\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 178.4839 - val_loss: 1002.9436\n",
      "Epoch 434/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 177.4428 - val_loss: 1008.7405\n",
      "Epoch 435/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 176.5748 - val_loss: 1011.5751\n",
      "Epoch 436/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 175.8138 - val_loss: 1012.0164\n",
      "Epoch 437/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 175.1057 - val_loss: 1012.9036\n",
      "Epoch 438/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 174.4467 - val_loss: 1014.6507\n",
      "Epoch 439/500\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 173.8265 - val_loss: 1015.9536\n",
      "Epoch 440/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 173.2388 - val_loss: 1016.3640\n",
      "Epoch 441/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 172.6799 - val_loss: 1016.2357\n",
      "Epoch 442/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 172.1401 - val_loss: 1015.8220\n",
      "Epoch 443/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 171.6144 - val_loss: 1015.2032\n",
      "Epoch 444/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 171.1155 - val_loss: 1012.5698\n",
      "Epoch 445/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 170.6098 - val_loss: 1011.2728\n",
      "Epoch 446/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 170.1088 - val_loss: 1011.2107\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 169.6175 - val_loss: 1011.1049\n",
      "Epoch 448/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 169.2997 - val_loss: 1009.0510\n",
      "Epoch 449/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 168.7172 - val_loss: 1008.0344\n",
      "Epoch 450/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 168.2072 - val_loss: 1000.2939\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 183.2663 - val_loss: 1043.9023\n",
      "Epoch 452/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 174.3145 - val_loss: 1018.7592\n",
      "Epoch 453/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 167.4807 - val_loss: 1000.1102\n",
      "Epoch 454/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 166.6803 - val_loss: 996.0812\n",
      "Epoch 455/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 165.9035 - val_loss: 994.2223\n",
      "Epoch 456/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 165.4486 - val_loss: 993.0351\n",
      "Epoch 457/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 164.9909 - val_loss: 990.3615\n",
      "Epoch 458/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 164.5450 - val_loss: 992.7180\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 164.2126 - val_loss: 975.8469\n",
      "Epoch 460/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 209.7900 - val_loss: 966.9115\n",
      "Epoch 461/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 206.3364 - val_loss: 955.9666\n",
      "Epoch 462/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 276.6733 - val_loss: 997.0925\n",
      "Epoch 463/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 197.6410 - val_loss: 995.9362\n",
      "Epoch 464/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 259.5665 - val_loss: 1018.2173\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 210.3721 - val_loss: 1029.8705\n",
      "Epoch 466/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 247.1316 - val_loss: 1048.8103\n",
      "Epoch 467/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 228.6252 - val_loss: 1178.7690\n",
      "Epoch 468/500\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 209.2390 - val_loss: 1176.8430\n",
      "Epoch 469/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 207.3569 - val_loss: 1160.1934\n",
      "Epoch 470/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 202.5524 - val_loss: 1136.3591\n",
      "Epoch 471/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 198.9515 - val_loss: 1116.4512\n",
      "Epoch 472/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 196.2409 - val_loss: 1103.5894\n",
      "Epoch 473/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 194.9483 - val_loss: 1095.0627\n",
      "Epoch 474/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 194.2528 - val_loss: 1092.0496\n",
      "Epoch 475/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 193.6551 - val_loss: 1089.2860\n",
      "Epoch 476/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 189.8275 - val_loss: 1067.9469\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 184.3804 - val_loss: 1065.8958\n",
      "Epoch 478/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 184.2514 - val_loss: 1060.7166\n",
      "Epoch 479/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 184.2451 - val_loss: 1059.5585\n",
      "Epoch 480/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 206.0118 - val_loss: 1137.8926\n",
      "Epoch 481/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 193.9213 - val_loss: 1103.6946\n",
      "Epoch 482/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 190.2791 - val_loss: 1065.1854\n",
      "Epoch 483/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 181.9196 - val_loss: 1047.3414\n",
      "Epoch 484/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 181.0330 - val_loss: 1042.2762\n",
      "Epoch 485/500\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 200.0195 - val_loss: 1103.7140\n",
      "Epoch 486/500\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 253.5990 - val_loss: 1119.1654\n",
      "Epoch 487/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 245.4705 - val_loss: 1148.4410\n",
      "Epoch 488/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 229.5154 - val_loss: 1249.3636\n",
      "Epoch 489/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 211.5730 - val_loss: 1162.3391\n",
      "Epoch 490/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 201.7664 - val_loss: 1127.3989\n",
      "Epoch 491/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 198.0818 - val_loss: 1095.8010\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 182.6987 - val_loss: 1050.5692\n",
      "Epoch 493/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 179.0040 - val_loss: 1036.5789\n",
      "Epoch 494/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 177.8955 - val_loss: 1034.9271\n",
      "Epoch 495/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 177.7072 - val_loss: 1031.8623\n",
      "Epoch 496/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 176.4286 - val_loss: 1027.7908\n",
      "Epoch 497/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 176.4790 - val_loss: 1029.3145\n",
      "Epoch 498/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 175.5077 - val_loss: 1031.8827\n",
      "Epoch 499/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 175.0285 - val_loss: 1032.2823\n",
      "Epoch 500/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 174.4124 - val_loss: 1032.5704\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 455ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 126)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 126)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 186)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:150:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 7.18643137e+01, 0.00000000e+00, 7.24603922e+01,\n",
       "        7.12142484e+01, 7.09722316e+01, 7.17858823e+01, 7.10857703e+01,\n",
       "        7.08472689e+01, 1.45036131e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.07800420e+01, 3.02265940e-02, 7.08864846e+01, 7.44450980e+01,\n",
       "        8.38599100e-02, 7.07660364e+01, 7.28996078e+01, 7.22250980e+01,\n",
       "        4.22481810e-01, 1.26242206e-01, 0.00000000e+00, 6.96443939e+01,\n",
       "        3.49589199e-01, 0.00000000e+00, 6.50203168e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.18185272e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 8.81361067e-01, 1.09871614e+00, 2.54559070e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.05257757e-01, 3.85178387e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.19857386e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.03389311e+00,\n",
       "        9.91878286e-02, 8.78415287e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52.86327116, 52.8476942 , 52.83211724, 52.81654027, 52.80096331,\n",
       "       52.78538635, 52.76980939, 52.75423242, 52.73865546, 52.7230785 ,\n",
       "       52.70750154, 52.69192457, 52.67634761, 52.66077065, 52.64519369,\n",
       "       52.62961672, 52.61403976, 52.5984628 , 52.58288584, 52.56730887,\n",
       "       52.55173191, 52.53615495, 52.52057799, 52.50500102, 52.48942406,\n",
       "       52.4738471 , 52.45827014, 52.44269317, 52.42711621, 52.41153925,\n",
       "       52.39596229, 52.38038532, 52.36480836, 52.3492314 , 52.33365444,\n",
       "       52.31807747, 52.30250051, 52.28692355, 52.27134659, 52.25576962,\n",
       "       52.24019266, 52.2246157 , 52.20903874, 52.19346177, 52.17788481,\n",
       "       52.16230785, 52.14673089, 52.13115392, 52.11557696, 52.1       ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.89696543202543\n",
      "42.21769977586564\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
