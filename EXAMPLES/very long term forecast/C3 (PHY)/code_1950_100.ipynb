{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2045    69.752299\n",
       "2046    69.747164\n",
       "2047    69.742028\n",
       "2048    69.736893\n",
       "2049    69.731758\n",
       "Name: C3, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_1950_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "1945     0.091706\n",
       "1946     0.000000\n",
       "1947     0.000000\n",
       "1948     0.605774\n",
       "1949     0.000000\n",
       "Name: C3, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1950)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1, 251) (1500, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 2s 33ms/step - loss: 5668.3931 - val_loss: 3999.1912\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5454.7681 - val_loss: 3848.6074\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5339.8960 - val_loss: 3783.0237\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5232.1450 - val_loss: 3703.5679\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5138.7119 - val_loss: 3637.6995\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5039.8745 - val_loss: 3568.6272\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4948.6416 - val_loss: 3505.5022\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4860.0366 - val_loss: 3444.0698\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4773.3848 - val_loss: 3384.0969\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4688.4141 - val_loss: 3325.4263\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4604.9531 - val_loss: 3267.9609\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 4522.8945 - val_loss: 3211.6360\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 4442.1636 - val_loss: 3156.4038\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 4362.7046 - val_loss: 3102.2266\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4284.4761 - val_loss: 3049.0767\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 4207.4429 - val_loss: 2996.9275\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 4131.5771 - val_loss: 2945.7585\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4056.8530 - val_loss: 2895.5503\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3983.2488 - val_loss: 2846.2856\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3910.7451 - val_loss: 2797.9482\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3839.3237 - val_loss: 2750.5244\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3768.9680 - val_loss: 2703.9995\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 3699.6628 - val_loss: 2658.3608\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3631.3938 - val_loss: 2613.5962\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3564.1450 - val_loss: 2569.6931\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3497.9062 - val_loss: 2526.6399\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 3432.6631 - val_loss: 2484.4260\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3368.4031 - val_loss: 2443.0398\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3305.1140 - val_loss: 2402.4714\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3242.7861 - val_loss: 2362.7100\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3181.4070 - val_loss: 2323.7456\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3120.9646 - val_loss: 2285.5681\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3061.4504 - val_loss: 2248.1677\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3002.8521 - val_loss: 2211.5354\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2945.1599 - val_loss: 2175.6609\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 2888.3640 - val_loss: 2140.5349\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 2832.4536 - val_loss: 2106.1484\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 2777.4194 - val_loss: 2072.4929\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 2723.2517 - val_loss: 2039.5581\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 2669.9407 - val_loss: 2007.3363\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2617.4768 - val_loss: 1975.8184\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2565.8511 - val_loss: 1944.9948\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2515.0547 - val_loss: 1914.8585\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2465.0771 - val_loss: 1885.3989\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2415.9104 - val_loss: 1856.6091\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2367.5449 - val_loss: 1828.4805\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2319.9729 - val_loss: 1801.0042\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2273.1846 - val_loss: 1774.1721\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2227.1714 - val_loss: 1747.9762\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 2181.9248 - val_loss: 1722.4088\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2137.4368 - val_loss: 1697.4611\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2093.6982 - val_loss: 1673.1250\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2050.7009 - val_loss: 1649.3929\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2008.4364 - val_loss: 1626.2568\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1966.8965 - val_loss: 1603.7089\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1926.0734 - val_loss: 1581.7412\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1885.9584 - val_loss: 1560.3462\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1846.5436 - val_loss: 1539.5160\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1807.8210 - val_loss: 1519.2432\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1769.7825 - val_loss: 1499.5197\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1732.4202 - val_loss: 1480.3386\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1695.7269 - val_loss: 1461.6913\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1659.6936 - val_loss: 1443.5714\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1624.3138 - val_loss: 1425.9714\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1589.5791 - val_loss: 1408.8834\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1555.4817 - val_loss: 1392.3002\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1522.0145 - val_loss: 1376.2146\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1489.1694 - val_loss: 1360.6189\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1456.9393 - val_loss: 1345.5062\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1425.3165 - val_loss: 1330.8696\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1394.2939 - val_loss: 1316.7014\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1363.8635 - val_loss: 1302.9946\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1334.0188 - val_loss: 1289.7424\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1304.7515 - val_loss: 1276.9375\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1276.0554 - val_loss: 1264.5731\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1247.9229 - val_loss: 1252.6417\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1220.3462 - val_loss: 1241.1367\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1193.3192 - val_loss: 1230.0513\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1166.8336 - val_loss: 1219.3784\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1140.8835 - val_loss: 1209.1115\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1115.4615 - val_loss: 1199.2433\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1090.5608 - val_loss: 1189.7671\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1066.1740 - val_loss: 1180.6765\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1042.2944 - val_loss: 1171.9648\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1018.9156 - val_loss: 1163.6248\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 996.0301 - val_loss: 1155.6505\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 973.6316 - val_loss: 1148.0348\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 951.7128 - val_loss: 1140.7714\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 930.2675 - val_loss: 1133.8535\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 909.2889 - val_loss: 1127.2748\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 888.7706 - val_loss: 1121.0289\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 868.7059 - val_loss: 1115.1090\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 849.0877 - val_loss: 1109.5094\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 829.9100 - val_loss: 1104.2227\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 811.1664 - val_loss: 1099.2435\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 792.8501 - val_loss: 1094.5649\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 774.9547 - val_loss: 1090.1809\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 757.4741 - val_loss: 1086.0852\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 740.4017 - val_loss: 1082.2716\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 723.7313 - val_loss: 1078.7339\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 707.4568 - val_loss: 1075.4659\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 691.5717 - val_loss: 1072.4618\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 676.0698 - val_loss: 1069.7153\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 660.9453 - val_loss: 1067.2205\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 646.1917 - val_loss: 1064.9711\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 631.8029 - val_loss: 1062.9617\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 617.7730 - val_loss: 1061.1858\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 604.0964 - val_loss: 1059.6381\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 590.7663 - val_loss: 1058.3124\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 577.7773 - val_loss: 1057.2030\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 565.1234 - val_loss: 1056.3043\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 552.7988 - val_loss: 1055.6105\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 540.7975 - val_loss: 1055.1158\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 529.1140 - val_loss: 1054.8149\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 517.7422 - val_loss: 1054.7020\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 506.6766 - val_loss: 1054.7716\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 495.9119 - val_loss: 1055.0183\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 485.4419 - val_loss: 1055.4366\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 475.2613 - val_loss: 1056.0211\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 465.3645 - val_loss: 1056.7667\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 455.7462 - val_loss: 1057.6676\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 446.4008 - val_loss: 1058.7191\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 437.3230 - val_loss: 1059.9156\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 428.5074 - val_loss: 1061.2523\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 419.9486 - val_loss: 1062.7240\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 411.6414 - val_loss: 1064.3257\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 403.5809 - val_loss: 1066.0521\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 395.7614 - val_loss: 1067.8987\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 388.1781 - val_loss: 1069.8604\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 380.8260 - val_loss: 1071.9325\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 373.6999 - val_loss: 1074.1104\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 366.7947 - val_loss: 1076.3889\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 360.1059 - val_loss: 1078.7642\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 353.6284 - val_loss: 1081.2307\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 347.3574 - val_loss: 1083.7848\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 341.2880 - val_loss: 1086.4216\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 335.4157 - val_loss: 1089.1367\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 329.7358 - val_loss: 1091.9261\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 324.2436 - val_loss: 1094.7854\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 318.9346 - val_loss: 1097.7101\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 313.8044 - val_loss: 1100.6967\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 308.8482 - val_loss: 1103.7405\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 304.0621 - val_loss: 1106.8383\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 299.4415 - val_loss: 1109.9855\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 294.9821 - val_loss: 1113.1785\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 290.6799 - val_loss: 1116.4136\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 286.5306 - val_loss: 1119.6871\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 282.5302 - val_loss: 1122.9954\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 278.6745 - val_loss: 1126.3348\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 274.9597 - val_loss: 1129.7021\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 271.3818 - val_loss: 1133.0938\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 267.9372 - val_loss: 1136.5067\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 264.6217 - val_loss: 1139.9373\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 261.4317 - val_loss: 1143.3824\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 258.3636 - val_loss: 1146.8396\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 255.4139 - val_loss: 1150.3049\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 252.5791 - val_loss: 1153.7765\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 249.8554 - val_loss: 1157.2504\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 247.2396 - val_loss: 1160.7247\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 244.7283 - val_loss: 1164.1963\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 242.3183 - val_loss: 1167.6628\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 240.0064 - val_loss: 1171.1218\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 237.7892 - val_loss: 1174.5704\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 235.6639 - val_loss: 1178.0068\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 233.6273 - val_loss: 1181.4283\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 231.6765 - val_loss: 1184.8329\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 229.8085 - val_loss: 1188.2186\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 228.0206 - val_loss: 1191.5831\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 226.3101 - val_loss: 1194.9243\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 224.6741 - val_loss: 1198.2410\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 223.1100 - val_loss: 1201.5309\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 221.6152 - val_loss: 1204.7925\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 220.1873 - val_loss: 1208.0242\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 218.8236 - val_loss: 1211.2238\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 217.5221 - val_loss: 1214.3906\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 216.2801 - val_loss: 1217.5233\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 215.0954 - val_loss: 1220.6202\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 213.9660 - val_loss: 1223.6801\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 212.8896 - val_loss: 1226.7014\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 211.8641 - val_loss: 1229.6835\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 210.8877 - val_loss: 1232.6259\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 209.9580 - val_loss: 1235.5260\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 209.0734 - val_loss: 1238.3848\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 208.2322 - val_loss: 1241.2003\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 207.4321 - val_loss: 1243.9719\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 206.6718 - val_loss: 1246.6996\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 205.9493 - val_loss: 1249.3823\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 205.2632 - val_loss: 1252.0192\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 204.6118 - val_loss: 1254.6105\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 203.9936 - val_loss: 1257.1549\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 203.4072 - val_loss: 1259.6527\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 202.8511 - val_loss: 1262.1036\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 202.3239 - val_loss: 1264.5072\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 201.8244 - val_loss: 1266.8635\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 201.3512 - val_loss: 1269.1716\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 200.9032 - val_loss: 1271.4324\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 200.4790 - val_loss: 1273.6453\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 200.0777 - val_loss: 1275.8110\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 199.6980 - val_loss: 1277.9286\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 199.3390 - val_loss: 1279.9988\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 198.9996 - val_loss: 1282.0222\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 198.6788 - val_loss: 1283.9973\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 198.3759 - val_loss: 1285.9265\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 198.0898 - val_loss: 1287.8086\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 197.8197 - val_loss: 1289.6447\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 197.5647 - val_loss: 1291.4348\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 197.3241 - val_loss: 1293.1796\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 197.0972 - val_loss: 1294.8794\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 196.8832 - val_loss: 1296.5333\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 196.6814 - val_loss: 1298.1438\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 196.4913 - val_loss: 1299.7104\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 196.3122 - val_loss: 1301.2340\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 196.1434 - val_loss: 1302.7158\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 195.9845 - val_loss: 1304.1552\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 195.8347 - val_loss: 1305.5527\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 195.6938 - val_loss: 1306.9099\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 195.5611 - val_loss: 1308.2269\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 195.4364 - val_loss: 1309.5039\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 195.3189 - val_loss: 1310.7426\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 195.2085 - val_loss: 1311.9431\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 195.1045 - val_loss: 1313.1055\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 195.0068 - val_loss: 1314.2323\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.9149 - val_loss: 1315.3224\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 194.8284 - val_loss: 1316.3773\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.7472 - val_loss: 1317.3983\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 194.6708 - val_loss: 1318.3840\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.5991 - val_loss: 1319.3376\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.5316 - val_loss: 1320.2583\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.4682 - val_loss: 1321.1472\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 194.4086 - val_loss: 1322.0050\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 194.3526 - val_loss: 1322.8323\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 194.3001 - val_loss: 1323.6298\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 194.2506 - val_loss: 1324.3977\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 194.2041 - val_loss: 1325.1367\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.1605 - val_loss: 1325.8469\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 194.1195 - val_loss: 1326.5304\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.0810 - val_loss: 1325.9722\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.1415 - val_loss: 1327.9401\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 194.0106 - val_loss: 1328.5564\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.9784 - val_loss: 1329.1475\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.9484 - val_loss: 1329.7158\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.9202 - val_loss: 1330.2623\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.8937 - val_loss: 1330.7872\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.8688 - val_loss: 1331.2910\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.8454 - val_loss: 1331.7750\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.8233 - val_loss: 1332.2382\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.8027 - val_loss: 1332.6829\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.7834 - val_loss: 1333.1105\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.7652 - val_loss: 1333.5195\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.7480 - val_loss: 1333.9119\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.7317 - val_loss: 1334.2880\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.7166 - val_loss: 1334.6477\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.7023 - val_loss: 1334.9918\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.6889 - val_loss: 1335.3207\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.6763 - val_loss: 1335.6351\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 193.6644 - val_loss: 1335.9366\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.6533 - val_loss: 1336.2241\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.6429 - val_loss: 1336.4989\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 193.6330 - val_loss: 1336.7621\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.6238 - val_loss: 1337.0129\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.6151 - val_loss: 1337.2523\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.6068 - val_loss: 1337.4811\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5992 - val_loss: 1337.6992\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5919 - val_loss: 1337.9066\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5852 - val_loss: 1338.1045\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5788 - val_loss: 1338.2930\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5728 - val_loss: 1338.4727\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5672 - val_loss: 1338.6442\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5619 - val_loss: 1338.8071\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5569 - val_loss: 1338.9623\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5523 - val_loss: 1339.1097\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5480 - val_loss: 1339.2496\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5438 - val_loss: 1339.3829\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5401 - val_loss: 1339.5100\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5364 - val_loss: 1339.6301\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5331 - val_loss: 1339.7449\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5299 - val_loss: 1339.8530\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5270 - val_loss: 1339.9564\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5242 - val_loss: 1340.0547\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5216 - val_loss: 1340.1473\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5193 - val_loss: 1340.2350\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5171 - val_loss: 1340.3186\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5149 - val_loss: 1340.3975\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5130 - val_loss: 1340.4731\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5112 - val_loss: 1340.5435\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5095 - val_loss: 1340.6106\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5080 - val_loss: 1340.6742\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5065 - val_loss: 1340.7351\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5052 - val_loss: 1340.7919\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 193.5039 - val_loss: 1340.8453\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5028 - val_loss: 1340.8966\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5017 - val_loss: 1340.9446\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5007 - val_loss: 1340.9906\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4999 - val_loss: 1341.0334\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4990 - val_loss: 1341.0743\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4983 - val_loss: 1341.1141\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4976 - val_loss: 1341.1506\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4970 - val_loss: 1341.1847\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4965 - val_loss: 1341.2174\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4959 - val_loss: 1341.2485\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4954 - val_loss: 1341.2766\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4951 - val_loss: 1341.3046\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4947 - val_loss: 1341.3302\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4944 - val_loss: 1341.3544\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4941 - val_loss: 1341.3774\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4938 - val_loss: 1341.3988\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4937 - val_loss: 1341.4200\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4934 - val_loss: 1341.4387\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4934 - val_loss: 1341.4568\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4932 - val_loss: 1341.4742\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4932 - val_loss: 1341.4901\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4931 - val_loss: 1341.5059\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4930 - val_loss: 1341.5203\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4930 - val_loss: 1341.5330\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4930 - val_loss: 1341.5458\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4930 - val_loss: 1341.5575\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4931 - val_loss: 1341.5692\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4931 - val_loss: 1341.5792\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4932 - val_loss: 1341.5891\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 193.4933 - val_loss: 1341.5986\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4934 - val_loss: 1341.6074\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4936 - val_loss: 1341.6165\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4937 - val_loss: 1341.6234\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4939 - val_loss: 1341.6317\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4940 - val_loss: 1341.6388\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4941 - val_loss: 1341.6444\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4944 - val_loss: 1341.6509\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.4945 - val_loss: 1341.6561\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.4947 - val_loss: 1341.6620\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4949 - val_loss: 1341.6669\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4950 - val_loss: 1341.6722\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4953 - val_loss: 1341.6766\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4955 - val_loss: 1341.6807\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4957 - val_loss: 1341.6852\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4958 - val_loss: 1341.6886\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4960 - val_loss: 1341.6919\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4963 - val_loss: 1341.6954\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.4965 - val_loss: 1341.6985\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.4967 - val_loss: 1341.7013\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4969 - val_loss: 1341.7047\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4971 - val_loss: 1341.7073\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 193.4973 - val_loss: 1341.7096\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4975 - val_loss: 1341.7111\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4978 - val_loss: 1341.7128\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.4980 - val_loss: 1341.7156\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4982 - val_loss: 1341.7177\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4985 - val_loss: 1341.7191\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.4987 - val_loss: 1341.7213\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4989 - val_loss: 1341.7229\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4991 - val_loss: 1341.7246\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4993 - val_loss: 1341.7264\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.4995 - val_loss: 1341.7274\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4998 - val_loss: 1341.7294\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.4999 - val_loss: 1341.7301\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5002 - val_loss: 1341.7314\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5004 - val_loss: 1341.7325\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5006 - val_loss: 1341.7334\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5008 - val_loss: 1341.7340\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5011 - val_loss: 1341.7352\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5013 - val_loss: 1341.7368\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5014 - val_loss: 1341.7378\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5016 - val_loss: 1341.7388\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5018 - val_loss: 1341.7402\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5020 - val_loss: 1341.7408\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5022 - val_loss: 1341.7415\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 193.5024 - val_loss: 1341.7426\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5025 - val_loss: 1341.7432\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5027 - val_loss: 1341.7438\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5029 - val_loss: 1341.7443\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5031 - val_loss: 1341.7450\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5033 - val_loss: 1341.7454\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5034 - val_loss: 1341.7454\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5037 - val_loss: 1341.7458\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5038 - val_loss: 1341.7461\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5039 - val_loss: 1341.7468\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5041 - val_loss: 1341.7473\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5043 - val_loss: 1341.7473\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5045 - val_loss: 1341.7479\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5047 - val_loss: 1341.7485\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5047 - val_loss: 1341.7487\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5049 - val_loss: 1341.7489\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5050 - val_loss: 1341.7495\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5052 - val_loss: 1341.7502\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5054 - val_loss: 1341.7504\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5055 - val_loss: 1341.7506\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5056 - val_loss: 1341.7515\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5057 - val_loss: 1341.7515\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5059 - val_loss: 1341.7521\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5061 - val_loss: 1341.7522\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5062 - val_loss: 1341.7523\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 193.5063 - val_loss: 1341.7521\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 193.5065 - val_loss: 1341.7526\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5066 - val_loss: 1341.7526\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5068 - val_loss: 1341.7526\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5069 - val_loss: 1341.7532\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5070 - val_loss: 1341.7532\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5071 - val_loss: 1341.7532\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5073 - val_loss: 1341.7542\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5073 - val_loss: 1341.7544\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5075 - val_loss: 1341.7550\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5076 - val_loss: 1341.7550\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5077 - val_loss: 1341.7554\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5078 - val_loss: 1341.7555\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5079 - val_loss: 1341.7556\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5080 - val_loss: 1341.7561\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5081 - val_loss: 1341.7565\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5082 - val_loss: 1341.7567\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5084 - val_loss: 1341.7567\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5084 - val_loss: 1341.7567\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5086 - val_loss: 1341.7572\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5086 - val_loss: 1341.7573\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5087 - val_loss: 1341.7579\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5088 - val_loss: 1341.7582\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5088 - val_loss: 1341.7582\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 193.5089 - val_loss: 1341.7587\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5089 - val_loss: 1341.7582\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5091 - val_loss: 1341.7582\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5092 - val_loss: 1341.7582\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5093 - val_loss: 1341.7587\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5093 - val_loss: 1341.7583\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5095 - val_loss: 1341.7583\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5096 - val_loss: 1341.7587\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5096 - val_loss: 1341.7592\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5096 - val_loss: 1341.7587\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5098 - val_loss: 1341.7587\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5098 - val_loss: 1341.7587\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5099 - val_loss: 1341.7587\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5100 - val_loss: 1341.7587\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5101 - val_loss: 1341.7587\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5102 - val_loss: 1341.7589\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5103 - val_loss: 1341.7589\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5104 - val_loss: 1341.7590\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5104 - val_loss: 1341.7593\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5105 - val_loss: 1341.7589\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5106 - val_loss: 1341.7590\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5106 - val_loss: 1341.7594\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 193.5107 - val_loss: 1341.7594\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 193.5107 - val_loss: 1341.7599\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 193.5107 - val_loss: 1341.7596\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5108 - val_loss: 1341.7596\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5109 - val_loss: 1341.7603\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5109 - val_loss: 1341.7603\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5109 - val_loss: 1341.7603\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5110 - val_loss: 1341.7603\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5111 - val_loss: 1341.7604\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5111 - val_loss: 1341.7606\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5111 - val_loss: 1341.7614\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5111 - val_loss: 1341.7609\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5112 - val_loss: 1341.7606\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5112 - val_loss: 1341.7604\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5114 - val_loss: 1341.7606\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 193.5114 - val_loss: 1341.7606\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 193.5115 - val_loss: 1341.7610\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 193.5115 - val_loss: 1341.7617\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 193.5115 - val_loss: 1341.7617\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 193.5115 - val_loss: 1341.7616\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5116 - val_loss: 1341.7615\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5116 - val_loss: 1341.7614\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5117 - val_loss: 1341.7609\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5118 - val_loss: 1341.7617\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5118 - val_loss: 1341.7620\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5119 - val_loss: 1341.7621\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5119 - val_loss: 1341.7625\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5119 - val_loss: 1341.7625\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5119 - val_loss: 1341.7618\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5120 - val_loss: 1341.7620\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5120 - val_loss: 1341.7620\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5121 - val_loss: 1341.7625\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5121 - val_loss: 1341.7633\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5121 - val_loss: 1341.7633\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5121 - val_loss: 1341.7633\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5121 - val_loss: 1341.7633\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5122 - val_loss: 1341.7633\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5123 - val_loss: 1341.7633\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5123 - val_loss: 1341.7635\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5123 - val_loss: 1341.7645\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5124 - val_loss: 1341.7648\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 193.5123 - val_loss: 1341.7648\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 193.5123 - val_loss: 1341.7651\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5123 - val_loss: 1341.7651\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5123 - val_loss: 1341.7648\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5124 - val_loss: 1341.7643\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5124 - val_loss: 1341.7635\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5125 - val_loss: 1341.7633\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5126 - val_loss: 1341.7644\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5126 - val_loss: 1341.7645\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5126 - val_loss: 1341.7645\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5126 - val_loss: 1341.7644\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5126 - val_loss: 1341.7645\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5126 - val_loss: 1341.7645\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5127 - val_loss: 1341.7646\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5127 - val_loss: 1341.7646\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5127 - val_loss: 1341.7646\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5127 - val_loss: 1341.7646\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5127 - val_loss: 1341.7648\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5128 - val_loss: 1341.7651\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5128 - val_loss: 1341.7653\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5128 - val_loss: 1341.7654\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.5128 - val_loss: 1341.7649\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.5128 - val_loss: 1341.7649\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 462ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.44997339e+01, 7.44778852e+01, 7.44560364e+01, 7.44341877e+01,\n",
       "        7.44123389e+01, 7.43904902e+01, 7.43686415e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.28998980e-01, 5.08463920e-01,\n",
       "        0.00000000e+00, 7.50705929e+01, 7.49916013e+01, 7.49126097e+01,\n",
       "        7.48336181e+01, 7.47546265e+01, 7.46756349e+01, 7.45966433e+01,\n",
       "        7.45482866e+01, 7.45264379e+01, 7.45045892e+01, 7.44827404e+01,\n",
       "        7.44608917e+01, 7.44390430e+01, 7.44171942e+01, 7.43953455e+01,\n",
       "        7.43734967e+01, 7.80838235e+01, 7.78234360e+01, 7.74200747e+01,\n",
       "        7.70167134e+01, 7.66133520e+01, 7.62549953e+01, 7.60533147e+01,\n",
       "        7.58516340e+01, 7.56499533e+01, 9.95775300e-03, 0.00000000e+00,\n",
       "        2.75105417e-01, 0.00000000e+00, 1.47021383e-01, 2.32320845e-01,\n",
       "        3.95178497e-01, 1.04638457e+00, 3.85843426e-01, 7.44438982e+01,\n",
       "        7.44220495e+01, 7.44002007e+01, 7.43783520e+01, 7.81342437e+01,\n",
       "        7.79073529e+01, 7.75097105e+01, 7.71063492e+01, 7.67029879e+01,\n",
       "        7.62998133e+01, 7.60981326e+01, 7.58964519e+01, 7.56947712e+01,\n",
       "        0.00000000e+00, 3.39932400e-02, 7.68673203e+01, 7.64639589e+01,\n",
       "        7.61802988e+01, 7.59786181e+01, 7.57769374e+01, 7.55752568e+01,\n",
       "        7.53514519e+01, 7.51144771e+01, 7.48775023e+01, 5.90972530e-02,\n",
       "        4.47119743e-01, 5.52969475e+01, 5.18556535e-01, 2.49879092e-01,\n",
       "        7.02037811e-01, 0.00000000e+00, 2.20264018e-01, 0.00000000e+00,\n",
       "        6.85069580e+01, 0.00000000e+00, 4.47804123e-01, 3.11801523e-01,\n",
       "        5.75851202e-01, 8.64599705e-01, 0.00000000e+00, 1.63416767e+00,\n",
       "        6.49379253e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.88052022e-01, 0.00000000e+00, 7.79637158e-01,\n",
       "        4.89242792e-01, 0.00000000e+00, 1.18474197e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70.24016106, 70.23502568, 70.22989029, 70.2247549 , 70.21961951,\n",
       "       70.21448413, 70.20934874, 70.20421335, 70.19907796, 70.19394258,\n",
       "       70.18880719, 70.1836718 , 70.17853641, 70.17340103, 70.16826564,\n",
       "       70.16313025, 70.15799486, 70.15285948, 70.14772409, 70.1425887 ,\n",
       "       70.13745331, 70.13231793, 70.12718254, 70.12204715, 70.11691176,\n",
       "       70.11177638, 70.10664099, 70.1015056 , 70.09637021, 70.09123483,\n",
       "       70.08609944, 70.08096405, 70.07582866, 70.07069328, 70.06555789,\n",
       "       70.0604225 , 70.05528711, 70.05015173, 70.04501634, 70.03988095,\n",
       "       70.03474556, 70.02961018, 70.02447479, 70.0193394 , 70.01420401,\n",
       "       70.00906863, 70.00393324, 69.99879785, 69.99366246, 69.98852708,\n",
       "       69.98339169, 69.9782563 , 69.97312092, 69.96798553, 69.96285014,\n",
       "       69.95771475, 69.95257937, 69.94744398, 69.94230859, 69.9371732 ,\n",
       "       69.93203782, 69.92690243, 69.92176704, 69.91663165, 69.91149627,\n",
       "       69.90636088, 69.90122549, 69.8960901 , 69.89095472, 69.88581933,\n",
       "       69.88068394, 69.87554855, 69.87041317, 69.86527778, 69.86014239,\n",
       "       69.855007  , 69.84987162, 69.84473623, 69.83960084, 69.83446545,\n",
       "       69.82933007, 69.82419468, 69.81905929, 69.8139239 , 69.80878852,\n",
       "       69.80365313, 69.79851774, 69.79338235, 69.78824697, 69.78311158,\n",
       "       69.77797619, 69.7728408 , 69.76770542, 69.76257003, 69.75743464,\n",
       "       69.75229925, 69.74716387, 69.74202848, 69.73689309, 69.7317577 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.37818164295448\n",
      "33.72551560685329\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
