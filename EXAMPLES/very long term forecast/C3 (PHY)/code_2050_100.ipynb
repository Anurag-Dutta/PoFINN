{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2145    69.225046\n",
       "2146    69.218761\n",
       "2147    69.212475\n",
       "2148    69.206190\n",
       "2149    69.199904\n",
       "Name: C3, Length: 2150, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_2050_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2045     0.000000\n",
       "2046     0.779637\n",
       "2047     0.489243\n",
       "2048     0.000000\n",
       "2049     1.184742\n",
       "Name: C3, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2050)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 1, 251) (1600, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 25ms/step - loss: 5751.4541 - val_loss: 3511.1060\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5474.2773 - val_loss: 3349.2974\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5322.1655 - val_loss: 3259.4502\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5217.1548 - val_loss: 3201.0776\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5124.9468 - val_loss: 3146.1218\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5035.7354 - val_loss: 3093.0591\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4948.8418 - val_loss: 3041.5229\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4863.8271 - val_loss: 2991.3057\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4780.4341 - val_loss: 2942.2820\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4698.5044 - val_loss: 2894.3696\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4617.9307 - val_loss: 2847.5093\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4538.6387 - val_loss: 2801.6587\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4460.5693 - val_loss: 2756.7815\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4383.6782 - val_loss: 2712.8596\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4307.8779 - val_loss: 2669.4719\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4228.9678 - val_loss: 2623.2747\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4149.4604 - val_loss: 2579.0200\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4072.1392 - val_loss: 2536.2832\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3996.7473 - val_loss: 2494.8218\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3922.9595 - val_loss: 2454.4895\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3850.5867 - val_loss: 2415.2000\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3779.5137 - val_loss: 2376.8950\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3709.6633 - val_loss: 2339.5322\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3640.9792 - val_loss: 2303.0796\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3573.4172 - val_loss: 2267.5110\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3506.9438 - val_loss: 2232.8030\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3441.5288 - val_loss: 2198.9370\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3377.1477 - val_loss: 2165.8940\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3313.7781 - val_loss: 2133.6602\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3251.4009 - val_loss: 2102.2192\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3189.9968 - val_loss: 2071.5581\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3129.5503 - val_loss: 2041.6637\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3070.0457 - val_loss: 2012.5238\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3011.4688 - val_loss: 1984.1272\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2953.8057 - val_loss: 1956.4617\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2897.0442 - val_loss: 1929.5176\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2841.1704 - val_loss: 1903.2832\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2786.1741 - val_loss: 1877.7493\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2732.0427 - val_loss: 1852.9053\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2678.7659 - val_loss: 1828.7418\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2626.3328 - val_loss: 1805.2496\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 2574.7324 - val_loss: 1782.4183\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2523.9553 - val_loss: 1760.2395\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2473.9907 - val_loss: 1738.7043\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2424.8296 - val_loss: 1717.8033\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2376.4622 - val_loss: 1697.5283\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2328.8789 - val_loss: 1677.8704\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2282.0708 - val_loss: 1658.8213\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2236.0295 - val_loss: 1640.3718\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2190.7449 - val_loss: 1622.5146\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2146.2092 - val_loss: 1605.2412\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2102.4126 - val_loss: 1588.5430\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2059.3486 - val_loss: 1572.4124\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2017.0068 - val_loss: 1556.8412\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1975.3801 - val_loss: 1541.8215\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1934.4597 - val_loss: 1527.3453\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1894.2379 - val_loss: 1513.4050\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1854.7063 - val_loss: 1499.9927\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1815.8572 - val_loss: 1487.1006\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1777.6824 - val_loss: 1474.7219\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1740.1750 - val_loss: 1462.8483\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1703.3259 - val_loss: 1451.4724\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1667.1292 - val_loss: 1440.5865\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1631.5758 - val_loss: 1430.1836\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1596.6584 - val_loss: 1420.2559\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1562.3704 - val_loss: 1410.7970\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1528.7037 - val_loss: 1401.7985\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1495.6511 - val_loss: 1393.2535\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1463.2056 - val_loss: 1385.1550\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1431.3600 - val_loss: 1377.4958\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1400.1064 - val_loss: 1370.2689\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1369.4388 - val_loss: 1363.4668\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1339.3494 - val_loss: 1357.0828\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1309.8315 - val_loss: 1351.1096\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1280.8773 - val_loss: 1345.5404\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1252.4813 - val_loss: 1340.3684\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1224.6354 - val_loss: 1335.5862\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1197.3335 - val_loss: 1331.1875\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1170.5684 - val_loss: 1327.1650\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1144.3333 - val_loss: 1323.5120\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 1118.6218 - val_loss: 1320.2219\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1093.4272 - val_loss: 1317.2876\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1068.7426 - val_loss: 1314.7026\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1044.5614 - val_loss: 1312.4602\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1020.8773 - val_loss: 1310.5537\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 997.6838 - val_loss: 1308.9763\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 974.9741 - val_loss: 1307.7217\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 952.7420 - val_loss: 1306.7830\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 930.9808 - val_loss: 1306.1538\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 909.6844 - val_loss: 1305.8275\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 888.8468 - val_loss: 1305.7977\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 868.4608 - val_loss: 1306.0580\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 848.5207 - val_loss: 1306.6018\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 829.0202 - val_loss: 1307.4226\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 809.9531 - val_loss: 1308.5140\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 791.3132 - val_loss: 1309.8699\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 773.0940 - val_loss: 1311.4838\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 755.2902 - val_loss: 1313.3495\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 737.8950 - val_loss: 1315.4606\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 720.9025 - val_loss: 1317.8112\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 704.3068 - val_loss: 1320.3945\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 688.1017 - val_loss: 1323.2045\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 672.2816 - val_loss: 1326.2354\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 656.8403 - val_loss: 1329.4808\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 641.7723 - val_loss: 1332.9347\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 627.0714 - val_loss: 1336.5908\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 612.7317 - val_loss: 1340.4436\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 598.7474 - val_loss: 1344.4866\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 585.1131 - val_loss: 1348.7141\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 571.8229 - val_loss: 1353.1199\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 558.8710 - val_loss: 1357.6985\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 546.2516 - val_loss: 1362.4441\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 533.9596 - val_loss: 1367.3501\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 521.9890 - val_loss: 1372.4115\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 510.3343 - val_loss: 1377.6223\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 498.9902 - val_loss: 1382.9769\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 487.9507 - val_loss: 1388.4696\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 477.2109 - val_loss: 1394.0946\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 466.7651 - val_loss: 1399.8464\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 456.6080 - val_loss: 1405.7196\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 446.7340 - val_loss: 1411.7086\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 437.1381 - val_loss: 1417.8079\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 427.8148 - val_loss: 1424.0123\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 418.7591 - val_loss: 1430.3162\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 409.9655 - val_loss: 1436.7146\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 401.4292 - val_loss: 1443.2020\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 393.1448 - val_loss: 1449.7733\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 385.1073 - val_loss: 1456.4232\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 377.3116 - val_loss: 1463.1467\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 369.7528 - val_loss: 1469.9388\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 362.4259 - val_loss: 1476.7943\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 355.3260 - val_loss: 1483.7087\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 348.4479 - val_loss: 1490.6765\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 341.7875 - val_loss: 1497.6930\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 335.3394 - val_loss: 1504.7546\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 329.0991 - val_loss: 1511.8547\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 323.0618 - val_loss: 1518.9901\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 317.2227 - val_loss: 1526.1558\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 311.5775 - val_loss: 1533.3467\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 306.1217 - val_loss: 1540.5591\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 300.8505 - val_loss: 1547.7889\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 295.7595 - val_loss: 1555.0312\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 290.8444 - val_loss: 1562.2820\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 286.1009 - val_loss: 1569.5369\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 281.5244 - val_loss: 1576.7920\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 277.1109 - val_loss: 1584.0437\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 272.8560 - val_loss: 1591.2874\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 268.7558 - val_loss: 1598.5192\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 264.8061 - val_loss: 1605.7363\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 261.0027 - val_loss: 1612.9343\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 257.3417 - val_loss: 1620.1096\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 253.8193 - val_loss: 1627.2587\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 250.4316 - val_loss: 1634.3785\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 247.1746 - val_loss: 1641.4656\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 244.0447 - val_loss: 1648.5168\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 241.0381 - val_loss: 1655.5277\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 238.1513 - val_loss: 1662.4965\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 235.3805 - val_loss: 1669.4203\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 232.7224 - val_loss: 1676.2953\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 230.1736 - val_loss: 1683.1194\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 227.7304 - val_loss: 1689.8889\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 225.3896 - val_loss: 1696.6028\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 223.1479 - val_loss: 1703.2576\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 221.0022 - val_loss: 1709.8503\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 218.9492 - val_loss: 1716.3792\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 216.9860 - val_loss: 1722.8425\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 215.1093 - val_loss: 1729.2373\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 213.3163 - val_loss: 1735.5609\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 211.6039 - val_loss: 1741.8138\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 209.9694 - val_loss: 1747.9918\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 208.4101 - val_loss: 1754.0945\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 206.9231 - val_loss: 1760.1189\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 205.5059 - val_loss: 1766.0638\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 204.1559 - val_loss: 1771.9290\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 202.8705 - val_loss: 1777.7117\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 201.6472 - val_loss: 1783.4109\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 200.4837 - val_loss: 1789.0254\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 199.3777 - val_loss: 1794.5541\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 198.3266 - val_loss: 1799.9961\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 197.3286 - val_loss: 1805.3508\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 196.3813 - val_loss: 1810.6160\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 195.4826 - val_loss: 1815.7926\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 194.6307 - val_loss: 1820.8793\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 193.8233 - val_loss: 1825.8748\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 193.0587 - val_loss: 1830.7806\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 192.3349 - val_loss: 1835.5938\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 191.6503 - val_loss: 1840.3160\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 191.0029 - val_loss: 1844.9457\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 190.3912 - val_loss: 1849.4834\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 189.8135 - val_loss: 1853.9301\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 189.2682 - val_loss: 1858.2842\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 188.7538 - val_loss: 1862.5465\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 188.2688 - val_loss: 1866.7164\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 187.8118 - val_loss: 1870.7947\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 187.3816 - val_loss: 1874.7816\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 186.9766 - val_loss: 1878.6777\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 186.5957 - val_loss: 1882.4830\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 186.2377 - val_loss: 1886.1985\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 185.9014 - val_loss: 1889.8242\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 185.5856 - val_loss: 1893.3613\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 185.2894 - val_loss: 1896.8105\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 185.0116 - val_loss: 1900.1722\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 184.7512 - val_loss: 1903.4480\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 184.5074 - val_loss: 1906.6375\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 184.2791 - val_loss: 1909.7434\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 184.0655 - val_loss: 1912.7644\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 183.8659 - val_loss: 1915.7024\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 183.6794 - val_loss: 1918.5590\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 183.5053 - val_loss: 1921.3347\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 183.3428 - val_loss: 1924.0305\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 183.1913 - val_loss: 1926.6487\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 183.0501 - val_loss: 1929.1887\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 182.9185 - val_loss: 1931.6531\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 182.7962 - val_loss: 1934.0424\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 182.6822 - val_loss: 1936.3590\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 182.5763 - val_loss: 1938.6019\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 182.4780 - val_loss: 1940.7754\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 182.3867 - val_loss: 1942.8785\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 182.3019 - val_loss: 1944.9128\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 182.2233 - val_loss: 1946.8805\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 182.1505 - val_loss: 1948.7826\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 182.0830 - val_loss: 1950.6211\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 182.0205 - val_loss: 1952.3959\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.9628 - val_loss: 1954.1106\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.9093 - val_loss: 1955.7637\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.8601 - val_loss: 1957.3591\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.8144 - val_loss: 1958.8967\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.7725 - val_loss: 1960.3789\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.7337 - val_loss: 1961.8066\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.6979 - val_loss: 1963.1816\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.6650 - val_loss: 1964.5046\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.6347 - val_loss: 1965.7773\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.6069 - val_loss: 1967.0020\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.5813 - val_loss: 1968.1787\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.5577 - val_loss: 1969.3086\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.5360 - val_loss: 1970.3938\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.5163 - val_loss: 1971.4359\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.4981 - val_loss: 1972.4363\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.4814 - val_loss: 1973.3949\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.4661 - val_loss: 1974.3145\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.4521 - val_loss: 1975.1949\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.4393 - val_loss: 1976.0387\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.4276 - val_loss: 1976.8467\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.4169 - val_loss: 1977.6194\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.4072 - val_loss: 1978.3580\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3983 - val_loss: 1979.0657\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3902 - val_loss: 1979.7406\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 181.3828 - val_loss: 1980.3860\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 181.3761 - val_loss: 1981.0016\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3701 - val_loss: 1981.5911\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3645 - val_loss: 1982.1526\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3594 - val_loss: 1982.6875\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3549 - val_loss: 1983.1985\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3507 - val_loss: 1983.6843\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3471 - val_loss: 1984.1475\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3437 - val_loss: 1984.5879\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3407 - val_loss: 1985.0074\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3380 - val_loss: 1985.4060\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 181.3355 - val_loss: 1985.7852\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 181.3333 - val_loss: 1986.1461\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3314 - val_loss: 1986.4879\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3296 - val_loss: 1986.8121\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3282 - val_loss: 1987.1211\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3268 - val_loss: 1987.4137\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3255 - val_loss: 1987.6910\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3245 - val_loss: 1987.9539\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3236 - val_loss: 1988.2024\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3229 - val_loss: 1988.4381\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3222 - val_loss: 1988.6614\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3216 - val_loss: 1988.8730\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3211 - val_loss: 1989.0726\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3208 - val_loss: 1989.2620\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 181.3205 - val_loss: 1989.4407\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3203 - val_loss: 1989.6082\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3201 - val_loss: 1989.7683\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3200 - val_loss: 1989.9180\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3201 - val_loss: 1990.0605\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3201 - val_loss: 1990.1940\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3201 - val_loss: 1990.3207\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3203 - val_loss: 1990.4391\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3205 - val_loss: 1990.5508\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3206 - val_loss: 1990.6566\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3208 - val_loss: 1990.7549\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3211 - val_loss: 1990.8484\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3214 - val_loss: 1990.9368\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3217 - val_loss: 1991.0195\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3220 - val_loss: 1991.0964\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3224 - val_loss: 1991.1689\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3228 - val_loss: 1991.2373\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3232 - val_loss: 1991.3018\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3235 - val_loss: 1991.3617\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3239 - val_loss: 1991.4180\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3244 - val_loss: 1991.4709\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3249 - val_loss: 1991.5203\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3253 - val_loss: 1991.5668\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3258 - val_loss: 1991.6094\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3263 - val_loss: 1991.6504\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3267 - val_loss: 1991.6879\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3273 - val_loss: 1991.7230\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3277 - val_loss: 1991.7565\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3282 - val_loss: 1991.7875\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3288 - val_loss: 1991.8160\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 181.3293 - val_loss: 1991.8425\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3298 - val_loss: 1991.8678\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3303 - val_loss: 1991.8904\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3308 - val_loss: 1991.9127\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3313 - val_loss: 1991.9329\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3318 - val_loss: 1991.9515\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3323 - val_loss: 1991.9688\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3329 - val_loss: 1991.9854\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3334 - val_loss: 1992.0012\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3340 - val_loss: 1992.0159\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3344 - val_loss: 1992.0289\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3349 - val_loss: 1992.0403\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3355 - val_loss: 1992.0520\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3360 - val_loss: 1992.0613\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3365 - val_loss: 1992.0715\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3370 - val_loss: 1992.0804\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3376 - val_loss: 1992.0891\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3380 - val_loss: 1992.0973\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3385 - val_loss: 1992.1035\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3390 - val_loss: 1992.1100\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3396 - val_loss: 1992.1172\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3400 - val_loss: 1992.1224\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3405 - val_loss: 1992.1267\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3410 - val_loss: 1992.1324\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3414 - val_loss: 1992.1348\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3419 - val_loss: 1992.1393\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3424 - val_loss: 1992.1422\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3429 - val_loss: 1992.1465\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 181.3433 - val_loss: 1992.1497\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3438 - val_loss: 1992.1517\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3442 - val_loss: 1992.1550\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3447 - val_loss: 1992.1572\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3451 - val_loss: 1992.1592\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3456 - val_loss: 1992.1617\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3460 - val_loss: 1992.1641\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3465 - val_loss: 1992.1653\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3469 - val_loss: 1992.1666\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3474 - val_loss: 1992.1683\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3477 - val_loss: 1992.1697\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3482 - val_loss: 1992.1707\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3486 - val_loss: 1992.1719\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3490 - val_loss: 1992.1726\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3494 - val_loss: 1992.1735\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3497 - val_loss: 1992.1744\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3501 - val_loss: 1992.1750\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3505 - val_loss: 1992.1752\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3509 - val_loss: 1992.1752\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3513 - val_loss: 1992.1760\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3516 - val_loss: 1992.1761\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3519 - val_loss: 1992.1761\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3523 - val_loss: 1992.1770\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3526 - val_loss: 1992.1770\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3531 - val_loss: 1992.1765\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3534 - val_loss: 1992.1770\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3536 - val_loss: 1992.1765\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 181.3540 - val_loss: 1992.1755\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3543 - val_loss: 1992.1752\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3547 - val_loss: 1992.1748\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3550 - val_loss: 1992.1758\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3553 - val_loss: 1992.1754\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3557 - val_loss: 1992.1754\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3559 - val_loss: 1992.1755\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3562 - val_loss: 1992.1755\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3565 - val_loss: 1992.1754\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3568 - val_loss: 1992.1754\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3571 - val_loss: 1992.1754\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3574 - val_loss: 1992.1758\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3577 - val_loss: 1992.1761\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3579 - val_loss: 1992.1755\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3583 - val_loss: 1992.1758\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3585 - val_loss: 1992.1755\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3588 - val_loss: 1992.1761\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3590 - val_loss: 1992.1764\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3593 - val_loss: 1992.1761\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3595 - val_loss: 1992.1761\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3598 - val_loss: 1992.1758\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3600 - val_loss: 1992.1764\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3602 - val_loss: 1992.1768\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3605 - val_loss: 1992.1771\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3607 - val_loss: 1992.1780\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 181.3609 - val_loss: 1992.1785\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3611 - val_loss: 1992.1781\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3614 - val_loss: 1992.1801\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3616 - val_loss: 1992.1809\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3618 - val_loss: 1992.1816\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3620 - val_loss: 1992.1820\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3622 - val_loss: 1992.1836\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3624 - val_loss: 1992.1858\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3626 - val_loss: 1992.1892\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3629 - val_loss: 1992.1943\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3630 - val_loss: 1992.2008\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3631 - val_loss: 1992.2102\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3633 - val_loss: 1992.2346\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3620 - val_loss: 1992.2820\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3451 - val_loss: 1978.3199\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 175.2797 - val_loss: 1900.9646\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 184.8096 - val_loss: 1906.0808\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 184.4648 - val_loss: 1912.6755\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 184.0248 - val_loss: 1919.0066\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 183.6332 - val_loss: 1924.8756\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 183.2990 - val_loss: 1930.2864\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 183.0155 - val_loss: 1935.2703\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 182.7748 - val_loss: 1939.8574\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 182.5707 - val_loss: 1944.0789\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 182.3973 - val_loss: 1947.9622\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 182.2499 - val_loss: 1951.5338\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 182.1246 - val_loss: 1954.8164\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 182.0178 - val_loss: 1957.8336\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 181.9269 - val_loss: 1960.6067\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 181.8493 - val_loss: 1963.1539\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 181.7831 - val_loss: 1965.4922\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 181.7265 - val_loss: 1967.6390\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.6779 - val_loss: 1969.6107\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.6365 - val_loss: 1971.4193\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.6009 - val_loss: 1973.0798\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.5703 - val_loss: 1974.6041\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.5439 - val_loss: 1976.0016\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.5213 - val_loss: 1977.2828\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.5017 - val_loss: 1978.4594\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.4848 - val_loss: 1979.5359\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.4702 - val_loss: 1980.5240\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.4575 - val_loss: 1981.4301\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.4464 - val_loss: 1982.2594\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.4369 - val_loss: 1983.0195\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.4285 - val_loss: 1983.7158\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.4213 - val_loss: 1984.3555\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.4149 - val_loss: 1984.9398\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.4092 - val_loss: 1985.4758\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.4044 - val_loss: 1985.9662\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 181.4001 - val_loss: 1986.4176\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 181.3963 - val_loss: 1986.8293\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 181.3930 - val_loss: 1987.2054\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 181.3900 - val_loss: 1987.5511\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3874 - val_loss: 1987.8669\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3851 - val_loss: 1988.1553\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3830 - val_loss: 1988.4199\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3812 - val_loss: 1988.6625\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3797 - val_loss: 1988.8848\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3782 - val_loss: 1989.0873\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3769 - val_loss: 1989.2747\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3757 - val_loss: 1989.4437\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3747 - val_loss: 1989.6000\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3737 - val_loss: 1989.7410\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3730 - val_loss: 1989.8715\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3723 - val_loss: 1989.9916\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3716 - val_loss: 1990.1008\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3710 - val_loss: 1990.2004\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 181.3705 - val_loss: 1990.2930\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 181.3701 - val_loss: 1990.3757\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3696 - val_loss: 1990.4524\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3692 - val_loss: 1990.5219\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3689 - val_loss: 1990.5863\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3686 - val_loss: 1990.6449\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3684 - val_loss: 1990.6976\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3680 - val_loss: 1990.7458\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3680 - val_loss: 1990.7906\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3678 - val_loss: 1990.8324\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3675 - val_loss: 1990.8689\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3674 - val_loss: 1990.9027\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3672 - val_loss: 1990.9340\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3671 - val_loss: 1990.9631\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3671 - val_loss: 1990.9893\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3670 - val_loss: 1991.0131\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3669 - val_loss: 1991.0352\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3668 - val_loss: 1991.0544\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3668 - val_loss: 1991.0729\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3667 - val_loss: 1991.0895\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3666 - val_loss: 1991.1029\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3666 - val_loss: 1991.1172\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3666 - val_loss: 1991.1292\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 181.3666 - val_loss: 1991.1410\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 181.3665 - val_loss: 1991.1511\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3665 - val_loss: 1991.1595\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3665 - val_loss: 1991.1696\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3665 - val_loss: 1991.1761\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3666 - val_loss: 1991.1840\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3665 - val_loss: 1991.1895\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3666 - val_loss: 1991.1957\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3666 - val_loss: 1991.2019\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3666 - val_loss: 1991.2054\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3666 - val_loss: 1991.2113\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3667 - val_loss: 1991.2170\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3666 - val_loss: 1991.2207\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3667 - val_loss: 1991.2252\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3667 - val_loss: 1991.2285\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3667 - val_loss: 1991.2322\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3667 - val_loss: 1991.2347\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3667 - val_loss: 1991.2371\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3668 - val_loss: 1991.2395\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3668 - val_loss: 1991.2422\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3668 - val_loss: 1991.2429\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 181.3668 - val_loss: 1991.2445\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 181.3668 - val_loss: 1991.2463\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3668 - val_loss: 1991.2493\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3668 - val_loss: 1991.2504\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3670 - val_loss: 1991.2513\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.3669 - val_loss: 1991.2526\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.3669 - val_loss: 1991.2527\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 409ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.64788982e+01, 7.61877684e+01, 7.59860878e+01, 7.57844071e+01,\n",
       "        7.54206314e+01, 0.00000000e+00, 0.00000000e+00, 1.08811498e+00,\n",
       "        0.00000000e+00, 2.75084823e-01, 0.00000000e+00, 9.49467063e-01,\n",
       "        0.00000000e+00, 7.44584641e+01, 7.44366153e+01, 7.44147666e+01,\n",
       "        7.43929178e+01, 7.43710691e+01, 7.80586134e+01, 7.77786181e+01,\n",
       "        7.73752568e+01, 7.69718954e+01, 7.65685341e+01, 7.62325864e+01,\n",
       "        7.60309057e+01, 7.58292250e+01, 7.56275443e+01, 3.10590327e-01,\n",
       "        1.07672811e-01, 7.67328665e+01, 7.63295051e+01, 7.61130719e+01,\n",
       "        7.59113912e+01, 7.57097105e+01, 7.55080299e+01, 7.52724603e+01,\n",
       "        7.50354855e+01, 7.47985107e+01, 3.82775307e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.13238549e-01, 0.00000000e+00, 5.85591793e-01, 7.58740430e+01,\n",
       "        7.56723623e+01, 9.74150002e-01, 1.19662857e+00, 7.68225023e+01,\n",
       "        7.64191410e+01, 7.61578898e+01, 7.59562092e+01, 7.57545285e+01,\n",
       "        7.55528478e+01, 7.53251214e+01, 7.50881466e+01, 7.48511718e+01,\n",
       "        0.00000000e+00, 1.30534396e-01, 7.58366947e+01, 7.56350140e+01,\n",
       "        7.54216667e+01, 7.51846919e+01, 7.49477171e+01, 7.47107423e+01,\n",
       "        7.45361485e+01, 7.44706022e+01, 7.44040560e+01, 0.00000000e+00,\n",
       "        4.63116820e-01, 5.43902092e+01, 2.91360497e-01, 1.08286309e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.91354490e-02,\n",
       "        7.38344498e+01, 1.34486228e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.73844409e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.74834770e-01, 0.00000000e+00, 4.94680226e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.33389997e-01, 3.08715791e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.74664056e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.72662232, 69.72148693, 69.71635154, 69.71121615, 69.70608077,\n",
       "       69.70094538, 69.69580999, 69.6906746 , 69.68553922, 69.68040383,\n",
       "       69.67526844, 69.67013305, 69.66499767, 69.65986228, 69.65472689,\n",
       "       69.6495915 , 69.64445612, 69.63932073, 69.63418534, 69.62904995,\n",
       "       69.62391457, 69.61877918, 69.61364379, 69.6085084 , 69.60337302,\n",
       "       69.59823763, 69.59310224, 69.58796685, 69.58283147, 69.57769608,\n",
       "       69.57256069, 69.5674253 , 69.56228992, 69.55715453, 69.55201914,\n",
       "       69.54688375, 69.54174837, 69.53661298, 69.53147759, 69.5263422 ,\n",
       "       69.52120682, 69.51607143, 69.51093604, 69.50580065, 69.50066527,\n",
       "       69.49552988, 69.49039449, 69.4852591 , 69.48012372, 69.47498833,\n",
       "       69.46985294, 69.46471755, 69.45958217, 69.45444678, 69.44931139,\n",
       "       69.444176  , 69.43904062, 69.43390523, 69.42876984, 69.42363445,\n",
       "       69.41849907, 69.41336368, 69.40822829, 69.4030929 , 69.39795752,\n",
       "       69.39282213, 69.38768674, 69.38255135, 69.37741597, 69.37228058,\n",
       "       69.36714519, 69.3620098 , 69.35687442, 69.35173903, 69.34660364,\n",
       "       69.34146825, 69.33633287, 69.33119748, 69.32606209, 69.3209267 ,\n",
       "       69.31579132, 69.31065593, 69.30552054, 69.30038515, 69.29418597,\n",
       "       69.28790053, 69.28161509, 69.27532964, 69.2690442 , 69.26275876,\n",
       "       69.25647332, 69.25018788, 69.24390244, 69.237617  , 69.23133156,\n",
       "       69.22504612, 69.21876068, 69.21247523, 69.20618979, 69.19990435])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.13708400091257\n",
      "37.73513792713743\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
