{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "1845    60.734664\n",
       "1846    60.720658\n",
       "1847    60.706653\n",
       "1848    60.692647\n",
       "1849    60.678641\n",
       "Name: C8, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c8_interpolated_1750_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "1745     0.000000\n",
       "1746     0.144706\n",
       "1747     0.288644\n",
       "1748     0.229632\n",
       "1749     0.000000\n",
       "Name: C8, Length: 1750, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1750)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.987115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.774230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87.561345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.348459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.200000  0.000298\n",
       "1     87.987115  0.000298\n",
       "2     87.774230  0.000297\n",
       "3     87.561345  0.000297\n",
       "4     87.348459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 85.7336  # Value for C0\n",
    "K0 = -0.0020  # Value for K0\n",
    "K1 = 0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0125    # Value for b\n",
    "c = 2.3008    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.200000    87.987115    87.774230    87.561345    87.348459   \n",
      "351    87.987115    87.774230    87.561345    87.348459    87.135574   \n",
      "352    87.774230    87.561345    87.348459    87.135574    86.922689   \n",
      "353    87.561345    87.348459    87.135574    86.922689    86.709804   \n",
      "354    87.348459    87.135574    86.922689    86.709804    86.496919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.135574    86.922689    86.709804    86.496919    86.294538  ...   \n",
      "351    86.922689    86.709804    86.496919    86.294538    86.221709  ...   \n",
      "352    86.709804    86.496919    86.294538    86.221709    86.148880  ...   \n",
      "353    86.496919    86.294538    86.221709    86.148880    86.076050  ...   \n",
      "354    86.294538    86.221709    86.148880    86.076050    86.003221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   76.094351    0.000263   76.058870    0.000263   76.023389    0.000263   \n",
      "351   76.058870    0.000263   76.023389    0.000263   75.987909    0.000262   \n",
      "352   76.023389    0.000263   75.987909    0.000262   75.952428    0.000262   \n",
      "353   75.987909    0.000262   75.952428    0.000262   75.916947    0.000262   \n",
      "354   75.952428    0.000262   75.916947    0.000262   75.881466    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   75.987909    0.000262   75.952428    0.000262  \n",
      "351   75.952428    0.000262   75.916947    0.000262  \n",
      "352   75.916947    0.000262   75.881466    0.000262  \n",
      "353   75.881466    0.000262   75.845985    0.000262  \n",
      "354   75.845985    0.000262   75.810504    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 1, 251) (1300, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 2s 32ms/step - loss: 4915.7324 - val_loss: 3390.8455\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4842.2153 - val_loss: 3356.4556\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4795.9854 - val_loss: 3328.5000\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4750.9297 - val_loss: 3299.8127\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4694.7212 - val_loss: 3264.3142\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4641.2886 - val_loss: 3224.6328\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4580.7778 - val_loss: 3194.0278\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4531.2085 - val_loss: 3163.8247\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4482.6401 - val_loss: 3134.2273\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4434.9023 - val_loss: 3105.1172\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4387.8374 - val_loss: 3076.4170\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4341.3457 - val_loss: 3048.0803\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4295.3677 - val_loss: 3020.0767\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4249.8638 - val_loss: 2992.3850\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4204.8052 - val_loss: 2964.9910\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4160.1719 - val_loss: 2937.8823\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4115.9482 - val_loss: 2911.0505\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4072.1206 - val_loss: 2884.4875\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4028.6797 - val_loss: 2858.1875\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3985.6167 - val_loss: 2832.1462\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3942.9236 - val_loss: 2806.3579\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3900.5957 - val_loss: 2780.8188\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3858.6265 - val_loss: 2755.5259\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3817.0112 - val_loss: 2730.4758\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3775.7454 - val_loss: 2705.6653\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3734.8245 - val_loss: 2681.0920\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3694.2446 - val_loss: 2656.7532\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3654.0032 - val_loss: 2632.6467\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3614.0959 - val_loss: 2608.7698\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3574.5198 - val_loss: 2585.1204\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3535.2715 - val_loss: 2561.6970\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3496.3494 - val_loss: 2538.4971\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3457.7490 - val_loss: 2515.5195\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3419.4697 - val_loss: 2492.7615\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3381.5071 - val_loss: 2470.2219\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3343.8594 - val_loss: 2447.8987\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3306.5247 - val_loss: 2425.7908\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3269.5002 - val_loss: 2403.8960\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3232.7839 - val_loss: 2382.2131\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3196.3733 - val_loss: 2360.7405\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3160.2666 - val_loss: 2339.4763\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3124.4614 - val_loss: 2318.4189\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3088.9551 - val_loss: 2297.5679\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3053.7473 - val_loss: 2276.9204\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3018.8342 - val_loss: 2256.4766\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2984.2148 - val_loss: 2236.2341\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2949.8872 - val_loss: 2216.1917\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2915.8494 - val_loss: 2196.3479\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2882.0981 - val_loss: 2176.7014\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2848.6343 - val_loss: 2157.2512\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2815.4543 - val_loss: 2137.9956\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2782.5564 - val_loss: 2118.9336\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2749.9382 - val_loss: 2100.0640\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2717.6003 - val_loss: 2081.3855\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2685.5388 - val_loss: 2062.8965\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2653.7517 - val_loss: 2044.5962\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2622.2397 - val_loss: 2026.4829\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2590.9980 - val_loss: 2008.5558\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2560.0281 - val_loss: 1990.8136\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 2529.3259 - val_loss: 1973.2554\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2498.8909 - val_loss: 1955.8794\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2468.7214 - val_loss: 1938.6846\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2438.8152 - val_loss: 1921.6700\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2409.1707 - val_loss: 1904.8348\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2379.7876 - val_loss: 1888.1772\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2350.6636 - val_loss: 1871.6965\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2321.7959 - val_loss: 1855.3915\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2293.1851 - val_loss: 1839.2609\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2264.8284 - val_loss: 1823.3041\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2236.7246 - val_loss: 1807.5194\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2208.8723 - val_loss: 1791.9058\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2181.2695 - val_loss: 1776.4626\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2153.9148 - val_loss: 1761.1882\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2126.8069 - val_loss: 1746.0820\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2099.9451 - val_loss: 1731.1427\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2073.3262 - val_loss: 1716.3691\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2046.9500 - val_loss: 1701.7601\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2020.8147 - val_loss: 1687.3154\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1994.9198 - val_loss: 1673.0331\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1969.2623 - val_loss: 1658.9128\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1943.8423 - val_loss: 1644.9529\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1918.6573 - val_loss: 1631.1531\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1893.7065 - val_loss: 1617.5117\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1868.9882 - val_loss: 1604.0281\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1844.5015 - val_loss: 1590.7008\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1820.2437 - val_loss: 1577.5294\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1796.2148 - val_loss: 1564.5126\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1772.4136 - val_loss: 1551.6497\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1748.8379 - val_loss: 1538.9390\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1725.4868 - val_loss: 1526.3804\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1702.3585 - val_loss: 1513.9722\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1679.4525 - val_loss: 1501.7141\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1656.7668 - val_loss: 1489.6046\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1634.3007 - val_loss: 1477.6432\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1612.0524 - val_loss: 1465.8286\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1590.0206 - val_loss: 1454.1602\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1568.2045 - val_loss: 1442.6364\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1546.6022 - val_loss: 1431.2566\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1525.2129 - val_loss: 1420.0200\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1504.0352 - val_loss: 1408.9255\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1483.0674 - val_loss: 1397.9725\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1462.3091 - val_loss: 1387.1598\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1441.7583 - val_loss: 1376.4863\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1421.4141 - val_loss: 1365.9513\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1401.2754 - val_loss: 1355.5542\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1381.3407 - val_loss: 1345.2933\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1361.6091 - val_loss: 1335.1683\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1342.0787 - val_loss: 1325.1782\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1322.7494 - val_loss: 1315.3221\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1303.6188 - val_loss: 1305.5986\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1284.6863 - val_loss: 1296.0077\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1265.9506 - val_loss: 1286.5479\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1247.4105 - val_loss: 1277.2181\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1229.0651 - val_loss: 1268.0179\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1210.9125 - val_loss: 1258.9463\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1192.9521 - val_loss: 1250.0024\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1175.1830 - val_loss: 1241.1854\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1157.6030 - val_loss: 1232.4943\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1140.2119 - val_loss: 1223.9281\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1123.0082 - val_loss: 1215.4860\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1105.9905 - val_loss: 1207.1672\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1089.1581 - val_loss: 1198.9708\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1072.5098 - val_loss: 1190.8960\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1056.0439 - val_loss: 1182.9417\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1039.7595 - val_loss: 1175.1074\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1023.6559 - val_loss: 1167.3923\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1007.7318 - val_loss: 1159.7950\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 991.9858 - val_loss: 1152.3149\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 976.4166 - val_loss: 1144.9510\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 961.0233 - val_loss: 1137.7030\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 945.8054 - val_loss: 1130.5696\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 930.7607 - val_loss: 1123.5497\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 915.8887 - val_loss: 1116.6431\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 901.1882 - val_loss: 1109.8481\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 886.6581 - val_loss: 1103.1649\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 872.2970 - val_loss: 1096.5918\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 858.1042 - val_loss: 1090.1285\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 844.0786 - val_loss: 1083.7737\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 830.2183 - val_loss: 1077.5270\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 816.5234 - val_loss: 1071.3870\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 802.9921 - val_loss: 1065.3535\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 789.6234 - val_loss: 1059.4253\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 776.4163 - val_loss: 1053.6016\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 763.3695 - val_loss: 1047.8812\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 750.4822 - val_loss: 1042.2640\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 737.7533 - val_loss: 1036.7489\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 725.1813 - val_loss: 1031.3347\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 712.7654 - val_loss: 1026.0210\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 700.5046 - val_loss: 1020.8069\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 688.3978 - val_loss: 1015.6913\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 676.4437 - val_loss: 1010.6735\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 664.6415 - val_loss: 1005.7528\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 652.9902 - val_loss: 1000.9282\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 641.4885 - val_loss: 996.1989\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 630.1348 - val_loss: 991.5642\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 618.9293 - val_loss: 987.0230\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 607.8699 - val_loss: 982.5750\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 596.9559 - val_loss: 978.2186\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 586.1860 - val_loss: 973.9535\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 575.5593 - val_loss: 969.7788\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 565.0751 - val_loss: 965.6935\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 554.7318 - val_loss: 961.6972\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 544.5287 - val_loss: 957.7887\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 534.4647 - val_loss: 953.9674\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 524.5387 - val_loss: 950.2321\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 514.7496 - val_loss: 946.5824\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 505.0964 - val_loss: 943.0171\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 495.5776 - val_loss: 939.5356\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 486.1929 - val_loss: 936.1371\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 476.9408 - val_loss: 932.8204\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 467.8204 - val_loss: 929.5853\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 458.8306 - val_loss: 926.4307\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 449.9700 - val_loss: 923.3553\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 441.2379 - val_loss: 920.3589\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 432.6331 - val_loss: 917.4405\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 424.1548 - val_loss: 914.5993\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 415.8019 - val_loss: 911.8343\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 407.5732 - val_loss: 909.1447\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 399.4678 - val_loss: 906.5298\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 391.4845 - val_loss: 903.9887\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 383.6223 - val_loss: 901.5208\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 375.8804 - val_loss: 899.1249\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 368.2573 - val_loss: 896.8004\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 360.7524 - val_loss: 894.5465\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 353.3645 - val_loss: 892.3622\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 346.0923 - val_loss: 890.2470\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 338.9355 - val_loss: 888.1997\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 331.8922 - val_loss: 886.2194\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 324.9616 - val_loss: 884.3058\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 318.1427 - val_loss: 882.4576\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 311.4345 - val_loss: 880.6743\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 304.8361 - val_loss: 878.9547\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 298.3464 - val_loss: 877.2985\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 291.9641 - val_loss: 875.7043\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 285.6884 - val_loss: 874.1717\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 279.5184 - val_loss: 872.6998\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 273.4528 - val_loss: 871.2875\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 267.4906 - val_loss: 869.9343\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 261.6311 - val_loss: 868.6392\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 255.8728 - val_loss: 867.4015\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 250.2149 - val_loss: 866.2203\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 244.6564 - val_loss: 865.0948\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 239.1962 - val_loss: 864.0241\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 233.8331 - val_loss: 863.0075\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 228.5666 - val_loss: 862.0442\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 223.3952 - val_loss: 861.1332\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 218.3179 - val_loss: 860.2739\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 213.3338 - val_loss: 859.4653\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 208.4418 - val_loss: 858.7065\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 203.6411 - val_loss: 857.9972\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 198.9304 - val_loss: 857.3360\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 194.3086 - val_loss: 856.7224\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 189.7749 - val_loss: 856.1553\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 185.3282 - val_loss: 855.6343\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 180.9678 - val_loss: 855.1583\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 176.6922 - val_loss: 854.7266\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 172.5005 - val_loss: 854.3384\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 168.3919 - val_loss: 853.9928\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 164.3653 - val_loss: 853.6891\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 160.4196 - val_loss: 853.4264\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 156.5540 - val_loss: 853.2039\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 152.7671 - val_loss: 853.0209\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 149.0583 - val_loss: 852.8766\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 145.4267 - val_loss: 852.7703\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 141.8707 - val_loss: 852.7009\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 138.3899 - val_loss: 852.6678\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 134.9830 - val_loss: 852.6701\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 131.6490 - val_loss: 852.7072\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 128.3869 - val_loss: 852.7783\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 125.1960 - val_loss: 852.8823\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 122.0751 - val_loss: 853.0188\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 119.0233 - val_loss: 853.1869\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 116.0395 - val_loss: 853.3858\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 113.1228 - val_loss: 853.6148\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 110.2720 - val_loss: 853.8730\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 107.4864 - val_loss: 854.1599\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 104.7650 - val_loss: 854.4744\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 102.1069 - val_loss: 854.8159\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 99.5111 - val_loss: 855.1837\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 96.9764 - val_loss: 855.5770\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 94.5022 - val_loss: 855.9951\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 92.0873 - val_loss: 856.4371\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 89.7308 - val_loss: 856.9025\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 87.4319 - val_loss: 857.3906\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 85.1895 - val_loss: 857.9004\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 83.0029 - val_loss: 858.4313\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 80.8710 - val_loss: 858.9827\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 78.7928 - val_loss: 859.5536\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 76.7676 - val_loss: 860.1437\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 74.7945 - val_loss: 860.7520\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 72.8722 - val_loss: 861.3780\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 71.0002 - val_loss: 862.0209\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 69.1774 - val_loss: 862.6800\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 67.4031 - val_loss: 863.3546\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 65.6763 - val_loss: 864.0442\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 63.9962 - val_loss: 864.7479\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 62.3619 - val_loss: 865.4651\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 60.7725 - val_loss: 866.1952\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 59.2271 - val_loss: 866.9377\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 57.7248 - val_loss: 867.6918\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 56.2650 - val_loss: 868.4570\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 54.8467 - val_loss: 869.2325\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 53.4689 - val_loss: 870.0176\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 52.1312 - val_loss: 870.8120\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 50.8324 - val_loss: 871.6149\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 49.5719 - val_loss: 872.4257\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 48.3488 - val_loss: 873.2440\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 47.1622 - val_loss: 874.0690\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 46.0115 - val_loss: 874.9002\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 44.8959 - val_loss: 875.7371\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 43.8146 - val_loss: 876.5792\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 42.7668 - val_loss: 877.4258\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 41.7517 - val_loss: 878.2762\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 40.7688 - val_loss: 879.1304\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 39.8170 - val_loss: 879.9875\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 38.8958 - val_loss: 880.8470\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 38.0044 - val_loss: 881.7085\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 37.1421 - val_loss: 882.5715\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 36.3083 - val_loss: 883.4357\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 35.5020 - val_loss: 884.3001\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 34.7229 - val_loss: 885.1649\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.9700 - val_loss: 886.0291\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.2429 - val_loss: 886.8926\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.5408 - val_loss: 887.7546\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.8630 - val_loss: 888.6152\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.2090 - val_loss: 889.4736\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.5780 - val_loss: 890.3296\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.9694 - val_loss: 891.1828\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.3828 - val_loss: 892.0325\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 28.8174 - val_loss: 892.8787\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 28.2726 - val_loss: 893.7208\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 27.7479 - val_loss: 894.5586\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 27.2427 - val_loss: 895.3917\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 26.7565 - val_loss: 896.2200\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 26.2886 - val_loss: 897.0428\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.8386 - val_loss: 897.8598\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4058 - val_loss: 898.6711\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.9898 - val_loss: 899.4760\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.5902 - val_loss: 900.2746\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.2063 - val_loss: 901.0662\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.8376 - val_loss: 901.8512\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.4837 - val_loss: 902.6284\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.1442 - val_loss: 903.3983\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.8184 - val_loss: 904.1605\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.5062 - val_loss: 904.9150\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.2067 - val_loss: 905.6611\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.9198 - val_loss: 906.3990\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.6451 - val_loss: 907.1282\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 21.3820 - val_loss: 907.8489\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 21.1302 - val_loss: 908.5607\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.8892 - val_loss: 909.2634\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.6588 - val_loss: 909.9570\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.4384 - val_loss: 910.6412\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.2279 - val_loss: 911.3161\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.0267 - val_loss: 911.9816\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 19.8345 - val_loss: 912.6374\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.6511 - val_loss: 913.2833\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.4760 - val_loss: 913.9196\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.3090 - val_loss: 914.5458\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.1498 - val_loss: 915.1622\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.9980 - val_loss: 915.7686\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.8533 - val_loss: 916.3651\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 18.7155 - val_loss: 916.9510\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 18.5844 - val_loss: 917.5271\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.4595 - val_loss: 918.0930\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.3407 - val_loss: 918.6487\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.2277 - val_loss: 919.1942\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.1203 - val_loss: 919.7295\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.0182 - val_loss: 920.2546\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 17.9212 - val_loss: 920.7695\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 17.8291 - val_loss: 921.2744\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.7417 - val_loss: 921.7689\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.6587 - val_loss: 922.2535\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.5801 - val_loss: 922.7280\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.5054 - val_loss: 923.1927\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 17.4346 - val_loss: 923.6471\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 17.3677 - val_loss: 924.0918\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.3042 - val_loss: 924.5267\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 17.2441 - val_loss: 924.9516\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 17.1872 - val_loss: 925.3670\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.1333 - val_loss: 925.7728\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.0824 - val_loss: 926.1692\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 17.0343 - val_loss: 926.5561\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.9888 - val_loss: 926.9335\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.9458 - val_loss: 927.3017\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.9052 - val_loss: 927.6610\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8669 - val_loss: 928.0109\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8307 - val_loss: 928.3521\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.7965 - val_loss: 928.6843\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.7644 - val_loss: 929.0079\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.7340 - val_loss: 929.3225\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.7054 - val_loss: 929.6290\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6784 - val_loss: 929.9270\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 16.6530 - val_loss: 930.2168\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6291 - val_loss: 930.4985\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6066 - val_loss: 930.7724\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5854 - val_loss: 931.0384\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5655 - val_loss: 931.2968\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5467 - val_loss: 931.5474\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.5291 - val_loss: 931.7907\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5126 - val_loss: 932.0269\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4969 - val_loss: 932.2558\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4823 - val_loss: 932.4775\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4685 - val_loss: 932.6924\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.4557 - val_loss: 932.9009\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4435 - val_loss: 933.1027\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4321 - val_loss: 933.2979\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4215 - val_loss: 933.4866\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4114 - val_loss: 933.6695\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4020 - val_loss: 933.8462\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3932 - val_loss: 934.0166\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.3850 - val_loss: 934.1817\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.3772 - val_loss: 934.3412\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3699 - val_loss: 934.4947\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3632 - val_loss: 934.6434\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.3568 - val_loss: 934.7866\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.3508 - val_loss: 934.9246\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.3452 - val_loss: 935.0577\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.3400 - val_loss: 935.1859\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3352 - val_loss: 935.3097\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3306 - val_loss: 935.4288\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3263 - val_loss: 935.5436\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3223 - val_loss: 935.6540\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3186 - val_loss: 935.7601\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.3150 - val_loss: 935.8624\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.3117 - val_loss: 935.9603\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3087 - val_loss: 936.0548\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3058 - val_loss: 936.1454\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3032 - val_loss: 936.2324\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3007 - val_loss: 936.3159\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2983 - val_loss: 936.3959\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2962 - val_loss: 936.4728\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2942 - val_loss: 936.5464\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 16.2923 - val_loss: 936.6172\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.2905 - val_loss: 936.6849\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2889 - val_loss: 936.7495\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2874 - val_loss: 936.8116\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2860 - val_loss: 936.8712\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2846 - val_loss: 936.9279\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2835 - val_loss: 936.9821\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2824 - val_loss: 937.0342\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2813 - val_loss: 937.0837\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2803 - val_loss: 937.1312\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2794 - val_loss: 937.1763\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2786 - val_loss: 937.2194\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2779 - val_loss: 937.2608\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.2771 - val_loss: 937.3000\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2765 - val_loss: 937.3372\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2759 - val_loss: 937.3728\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2754 - val_loss: 937.4064\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2749 - val_loss: 937.4388\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2745 - val_loss: 937.4697\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2741 - val_loss: 937.4990\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2737 - val_loss: 937.5270\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2734 - val_loss: 937.5535\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2731 - val_loss: 937.5783\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2729 - val_loss: 937.6021\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2726 - val_loss: 937.6250\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2724 - val_loss: 937.6464\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2723 - val_loss: 937.6667\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2721 - val_loss: 937.6859\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2720 - val_loss: 937.7042\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2719 - val_loss: 937.7214\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2719 - val_loss: 937.7379\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2718 - val_loss: 937.7533\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2718 - val_loss: 937.7680\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2718 - val_loss: 937.7819\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2718 - val_loss: 937.7947\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.2718 - val_loss: 937.8073\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2718 - val_loss: 937.8187\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.2719 - val_loss: 937.8297\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.2720 - val_loss: 937.8399\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2720 - val_loss: 937.8497\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2721 - val_loss: 937.8587\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2722 - val_loss: 937.8676\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2723 - val_loss: 937.8754\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2725 - val_loss: 937.8831\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2726 - val_loss: 937.8902\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2727 - val_loss: 937.8971\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.2729 - val_loss: 937.9033\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.2730 - val_loss: 937.9091\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2732 - val_loss: 937.9146\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2734 - val_loss: 937.9197\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2736 - val_loss: 937.9245\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2737 - val_loss: 937.9291\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2739 - val_loss: 937.9330\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2741 - val_loss: 937.9370\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.2743 - val_loss: 937.9406\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.2745 - val_loss: 937.9437\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2747 - val_loss: 937.9468\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2750 - val_loss: 937.9495\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2752 - val_loss: 937.9523\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2754 - val_loss: 937.9549\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2756 - val_loss: 937.9569\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.2758 - val_loss: 937.9587\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.2761 - val_loss: 937.9608\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.2763 - val_loss: 937.9625\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2765 - val_loss: 937.9641\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2767 - val_loss: 937.9653\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2770 - val_loss: 937.9667\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2772 - val_loss: 937.9677\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2775 - val_loss: 937.9688\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2777 - val_loss: 937.9699\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2779 - val_loss: 937.9706\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.2782 - val_loss: 937.9716\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2784 - val_loss: 937.9722\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2786 - val_loss: 937.9728\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2788 - val_loss: 937.9731\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2791 - val_loss: 937.9734\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2794 - val_loss: 937.9739\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2796 - val_loss: 937.9742\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2798 - val_loss: 937.9745\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2800 - val_loss: 937.9746\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.2803 - val_loss: 937.9748\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.2805 - val_loss: 937.9747\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2808 - val_loss: 937.9749\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.2810 - val_loss: 937.9747\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2812 - val_loss: 937.9745\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2815 - val_loss: 937.9745\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2817 - val_loss: 937.9742\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2819 - val_loss: 937.9741\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2822 - val_loss: 937.9739\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2824 - val_loss: 937.9737\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.2826 - val_loss: 937.9736\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2828 - val_loss: 937.9733\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2831 - val_loss: 937.9730\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2833 - val_loss: 937.9725\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2835 - val_loss: 937.9724\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2837 - val_loss: 937.9720\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2839 - val_loss: 937.9717\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2842 - val_loss: 937.9711\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 16.2844 - val_loss: 937.9707\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2846 - val_loss: 937.9703\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2848 - val_loss: 937.9701\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2850 - val_loss: 937.9696\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2852 - val_loss: 937.9692\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2854 - val_loss: 937.9688\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2857 - val_loss: 937.9684\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2859 - val_loss: 937.9682\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2861 - val_loss: 937.9677\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(85.7336, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0020, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0125, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3008, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 338ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.77987745e+01, 6.76601191e+01, 6.75214636e+01, 6.73828081e+01,\n",
       "        6.72441527e+01, 6.71054972e+01, 6.69668417e+01, 0.00000000e+00,\n",
       "        2.61160940e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.51549834e-01, 6.90569561e+01, 6.89225023e+01, 6.87880485e+01,\n",
       "        6.86535948e+01, 6.85191410e+01, 6.83842087e+01, 6.82455532e+01,\n",
       "        6.81068978e+01, 6.79682423e+01, 6.78295868e+01, 6.76909314e+01,\n",
       "        6.75522759e+01, 6.74136204e+01, 6.72749650e+01, 6.71363095e+01,\n",
       "        6.69976541e+01, 6.68589986e+01, 6.67329248e+01, 6.66530929e+01,\n",
       "        6.65732610e+01, 6.64934290e+01, 6.64135971e+01, 6.63337652e+01,\n",
       "        6.62539332e+01, 6.61741013e+01, 6.60942694e+01, 6.60144374e+01,\n",
       "        0.00000000e+00, 6.57682478e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.75791919e-01, 0.00000000e+00, 6.74444328e+01,\n",
       "        6.73057773e+01, 6.71671219e+01, 6.70284664e+01, 6.68898109e+01,\n",
       "        6.67511555e+01, 6.66708333e+01, 6.65910014e+01, 6.65111695e+01,\n",
       "        6.64313375e+01, 6.63515056e+01, 6.62716737e+01, 6.61918417e+01,\n",
       "        6.61120098e+01, 6.60321779e+01, 6.59523459e+01, 6.58725140e+01,\n",
       "        6.57930672e+01, 6.57174370e+01, 6.56418067e+01, 6.55661765e+01,\n",
       "        6.54905462e+01, 6.54149160e+01, 6.53392857e+01, 6.52636555e+01,\n",
       "        6.51880252e+01, 7.22844544e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.20709970e-01, 0.00000000e+00,\n",
       "        5.13586121e+01, 0.00000000e+00, 8.12122822e-02, 3.59793186e-01,\n",
       "        0.00000000e+00, 1.21052124e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.76572734e-01, 2.88133472e-01, 2.49343425e-01, 6.77054167e-01,\n",
       "        1.43447533e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.13987127e-02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61.77679739, 61.76746032, 61.75812325, 61.74878618, 61.73944911,\n",
       "       61.73011204, 61.72077498, 61.71143791, 61.70210084, 61.69276377,\n",
       "       61.6834267 , 61.67408964, 61.66475257, 61.6554155 , 61.64607843,\n",
       "       61.63674136, 61.6274043 , 61.61806723, 61.60873016, 61.59939309,\n",
       "       61.59005602, 61.58071895, 61.57138189, 61.56204482, 61.55270775,\n",
       "       61.54337068, 61.53403361, 61.52469655, 61.51535948, 61.50602241,\n",
       "       61.49668534, 61.48734827, 61.4780112 , 61.46867414, 61.45933707,\n",
       "       61.45      , 61.44066293, 61.43132586, 61.4219888 , 61.41265173,\n",
       "       61.40331466, 61.39397759, 61.38464052, 61.37530345, 61.36596639,\n",
       "       61.35662932, 61.34729225, 61.33795518, 61.32861811, 61.31928105,\n",
       "       61.30994398, 61.30060691, 61.29126984, 61.28193277, 61.2725957 ,\n",
       "       61.26325864, 61.25392157, 61.2445845 , 61.23524743, 61.22591036,\n",
       "       61.2165733 , 61.20723623, 61.19684874, 61.18284314, 61.16883754,\n",
       "       61.15483193, 61.14082633, 61.12682073, 61.11281513, 61.09880952,\n",
       "       61.08480392, 61.07079832, 61.05679272, 61.04278711, 61.02878151,\n",
       "       61.01477591, 61.00077031, 60.98676471, 60.9727591 , 60.9587535 ,\n",
       "       60.9447479 , 60.9307423 , 60.91673669, 60.90273109, 60.88872549,\n",
       "       60.87471989, 60.86071429, 60.84670868, 60.83270308, 60.81869748,\n",
       "       60.80469188, 60.79068627, 60.77668067, 60.76267507, 60.74866947,\n",
       "       60.73466387, 60.72065826, 60.70665266, 60.69264706, 60.67864146])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.839277201977936\n",
      "26.633620178123834\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
