{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "2045    59.052299\n",
       "2046    59.047164\n",
       "2047    59.042028\n",
       "2048    59.036893\n",
       "2049    59.031758\n",
       "Name: C8, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c8_interpolated_1950_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "1945     0.000000\n",
       "1946     0.146881\n",
       "1947     0.000000\n",
       "1948     0.143897\n",
       "1949     0.427304\n",
       "Name: C8, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1950)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.987115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.774230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87.561345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.348459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.200000  0.000298\n",
       "1     87.987115  0.000298\n",
       "2     87.774230  0.000297\n",
       "3     87.561345  0.000297\n",
       "4     87.348459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 85.7336  # Value for C0\n",
    "K0 = -0.0020  # Value for K0\n",
    "K1 = 0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0125    # Value for b\n",
    "c = 2.3008    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.200000    87.987115    87.774230    87.561345    87.348459   \n",
      "351    87.987115    87.774230    87.561345    87.348459    87.135574   \n",
      "352    87.774230    87.561345    87.348459    87.135574    86.922689   \n",
      "353    87.561345    87.348459    87.135574    86.922689    86.709804   \n",
      "354    87.348459    87.135574    86.922689    86.709804    86.496919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.135574    86.922689    86.709804    86.496919    86.294538  ...   \n",
      "351    86.922689    86.709804    86.496919    86.294538    86.221709  ...   \n",
      "352    86.709804    86.496919    86.294538    86.221709    86.148880  ...   \n",
      "353    86.496919    86.294538    86.221709    86.148880    86.076050  ...   \n",
      "354    86.294538    86.221709    86.148880    86.076050    86.003221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   76.094351    0.000263   76.058870    0.000263   76.023389    0.000263   \n",
      "351   76.058870    0.000263   76.023389    0.000263   75.987909    0.000262   \n",
      "352   76.023389    0.000263   75.987909    0.000262   75.952428    0.000262   \n",
      "353   75.987909    0.000262   75.952428    0.000262   75.916947    0.000262   \n",
      "354   75.952428    0.000262   75.916947    0.000262   75.881466    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   75.987909    0.000262   75.952428    0.000262  \n",
      "351   75.952428    0.000262   75.916947    0.000262  \n",
      "352   75.916947    0.000262   75.881466    0.000262  \n",
      "353   75.881466    0.000262   75.845985    0.000262  \n",
      "354   75.845985    0.000262   75.810504    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1, 251) (1500, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 2s 25ms/step - loss: 4831.7920 - val_loss: 3806.5513\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4750.9004 - val_loss: 3759.7634\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4696.8477 - val_loss: 3695.2778\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4625.3560 - val_loss: 3646.5024\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4570.9292 - val_loss: 3598.3008\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4517.3027 - val_loss: 3550.8701\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4464.4390 - val_loss: 3504.0891\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4412.2231 - val_loss: 3457.8789\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4360.5859 - val_loss: 3412.1938\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4309.4844 - val_loss: 3367.0046\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4258.8936 - val_loss: 3322.2917\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4208.7915 - val_loss: 3278.0405\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4159.1689 - val_loss: 3234.2407\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4110.0112 - val_loss: 3190.8833\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4061.3120 - val_loss: 3147.9609\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4013.0620 - val_loss: 3105.4668\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3965.2559 - val_loss: 3063.3955\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3917.8887 - val_loss: 3021.7422\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3870.9534 - val_loss: 2980.5022\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3824.4468 - val_loss: 2939.6711\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3778.3638 - val_loss: 2899.2456\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3732.7012 - val_loss: 2859.2209\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3687.4541 - val_loss: 2819.5942\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3642.6201 - val_loss: 2780.3611\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3598.1946 - val_loss: 2741.5193\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3554.1741 - val_loss: 2703.0647\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3510.5549 - val_loss: 2664.9951\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3467.3362 - val_loss: 2627.3066\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3424.5127 - val_loss: 2589.9971\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3382.0818 - val_loss: 2553.0623\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3340.0410 - val_loss: 2516.5010\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3298.3867 - val_loss: 2480.3096\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3257.1169 - val_loss: 2444.4851\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3216.2285 - val_loss: 2409.0249\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3175.7180 - val_loss: 2373.9268\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3135.5842 - val_loss: 2339.1880\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3095.8232 - val_loss: 2304.8057\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 3056.4326 - val_loss: 2270.7769\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3017.4106 - val_loss: 2237.1003\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2978.7537 - val_loss: 2203.7729\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2940.4595 - val_loss: 2170.7917\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2902.5259 - val_loss: 2138.1541\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2864.9497 - val_loss: 2105.8591\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2827.7297 - val_loss: 2073.9028\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2790.8628 - val_loss: 2042.2837\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2754.3459 - val_loss: 2010.9988\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2718.1782 - val_loss: 1980.0463\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2682.3557 - val_loss: 1949.4237\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2646.8760 - val_loss: 1919.1288\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2611.7388 - val_loss: 1889.1589\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2576.9407 - val_loss: 1859.5123\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2542.4785 - val_loss: 1830.1866\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2508.3516 - val_loss: 1801.1796\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2474.5562 - val_loss: 1772.4894\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2441.0916 - val_loss: 1744.1132\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2407.9541 - val_loss: 1716.0491\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2375.1428 - val_loss: 1688.2952\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2342.6555 - val_loss: 1660.8489\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2310.4883 - val_loss: 1633.7084\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2278.6418 - val_loss: 1606.8718\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2247.1118 - val_loss: 1580.3369\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2215.8970 - val_loss: 1554.1014\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2184.9954 - val_loss: 1528.1631\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2154.4041 - val_loss: 1502.5208\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2124.1228 - val_loss: 1477.1715\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2094.1472 - val_loss: 1452.1138\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2064.4775 - val_loss: 1427.3456\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2035.1108 - val_loss: 1402.8647\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2006.0442 - val_loss: 1378.6689\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1977.2766 - val_loss: 1354.7571\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1948.8065 - val_loss: 1331.1267\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1920.6309 - val_loss: 1307.7759\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1892.7483 - val_loss: 1284.7028\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1865.1577 - val_loss: 1261.9055\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1837.8556 - val_loss: 1239.3818\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1810.8413 - val_loss: 1217.1299\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1784.1117 - val_loss: 1195.1483\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1757.6660 - val_loss: 1173.4351\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1731.5018 - val_loss: 1151.9879\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1705.6178 - val_loss: 1130.8054\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1680.0118 - val_loss: 1109.8854\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1654.6816 - val_loss: 1089.2262\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1629.6259 - val_loss: 1068.8257\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1604.8423 - val_loss: 1048.6829\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1580.3297 - val_loss: 1028.7950\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1556.0861 - val_loss: 1009.1606\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1532.1097 - val_loss: 989.7783\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1508.3982 - val_loss: 970.6455\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1484.9506 - val_loss: 951.7614\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1461.7648 - val_loss: 933.1231\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1438.8389 - val_loss: 914.7302\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1416.1716 - val_loss: 896.5795\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1393.7605 - val_loss: 878.6705\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1371.6046 - val_loss: 861.0012\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1349.7017 - val_loss: 843.5688\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1328.0500 - val_loss: 826.3727\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1306.6482 - val_loss: 809.4114\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1285.4946 - val_loss: 792.6821\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1264.5874 - val_loss: 776.1838\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1243.9249 - val_loss: 759.9144\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1223.5049 - val_loss: 743.8727\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1203.3264 - val_loss: 728.0568\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1183.3879 - val_loss: 712.4650\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1163.6876 - val_loss: 697.0957\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1144.2233 - val_loss: 681.9470\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1124.9940 - val_loss: 667.0179\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1105.9979 - val_loss: 652.3060\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1087.2333 - val_loss: 637.8098\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1068.6985 - val_loss: 623.5278\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1050.3921 - val_loss: 609.4586\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1032.3124 - val_loss: 595.6003\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1014.4578 - val_loss: 581.9507\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 996.8264 - val_loss: 568.5090\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 979.4169 - val_loss: 555.2733\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 962.2275 - val_loss: 542.2422\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 945.2572 - val_loss: 529.4135\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 928.5038 - val_loss: 516.7864\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 911.9661 - val_loss: 504.3583\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 895.6422 - val_loss: 492.1283\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 879.5311 - val_loss: 480.0952\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 863.6306 - val_loss: 468.2560\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 847.9395 - val_loss: 456.6108\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 832.4560 - val_loss: 445.1565\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 817.1790 - val_loss: 433.8925\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 802.1064 - val_loss: 422.8168\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 787.2373 - val_loss: 411.9275\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 772.5696 - val_loss: 401.2241\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 758.1019 - val_loss: 390.7039\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 743.8324 - val_loss: 380.3655\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 729.7602 - val_loss: 370.2079\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 715.8834 - val_loss: 360.2289\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 702.2007 - val_loss: 350.4275\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 688.7104 - val_loss: 340.8022\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 675.4111 - val_loss: 331.3504\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 662.3011 - val_loss: 322.0717\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 649.3793 - val_loss: 312.9639\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 636.6435 - val_loss: 304.0259\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 624.0930 - val_loss: 295.2551\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 611.7254 - val_loss: 286.6515\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 599.5400 - val_loss: 278.2121\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 587.5350 - val_loss: 269.9365\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 575.7090 - val_loss: 261.8228\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 564.0602 - val_loss: 253.8683\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 552.5872 - val_loss: 246.0730\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 541.2889 - val_loss: 238.4350\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 530.1635 - val_loss: 230.9519\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 519.2092 - val_loss: 223.6231\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 508.4254 - val_loss: 216.4470\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 497.8098 - val_loss: 209.4214\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 487.3614 - val_loss: 202.5452\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 477.0782 - val_loss: 195.8169\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 466.9592 - val_loss: 189.2344\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 457.0028 - val_loss: 182.7970\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 447.2075 - val_loss: 176.5025\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 437.5717 - val_loss: 170.3495\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 428.0941 - val_loss: 164.3369\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 418.7734 - val_loss: 158.4629\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 409.6080 - val_loss: 152.7257\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 400.5961 - val_loss: 147.1239\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 391.7367 - val_loss: 141.6561\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 383.0280 - val_loss: 136.3205\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 374.4687 - val_loss: 131.1156\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 366.0571 - val_loss: 126.0401\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 357.7921 - val_loss: 121.0923\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 349.6717 - val_loss: 116.2706\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 341.6949 - val_loss: 111.5737\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 333.8602 - val_loss: 106.9996\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 326.1660 - val_loss: 102.5472\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 318.6108 - val_loss: 98.2149\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 311.1932 - val_loss: 94.0011\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 303.9120 - val_loss: 89.9043\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 296.7656 - val_loss: 85.9229\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 289.7527 - val_loss: 82.0555\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 282.8712 - val_loss: 78.3002\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 276.1202 - val_loss: 74.6559\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 269.4981 - val_loss: 71.1208\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 263.0034 - val_loss: 67.6936\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 256.6350 - val_loss: 64.3726\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 250.3910 - val_loss: 61.1563\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 244.2702 - val_loss: 58.0431\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 238.2710 - val_loss: 55.0316\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 232.3922 - val_loss: 52.1204\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 226.6321 - val_loss: 49.3075\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 220.9893 - val_loss: 46.5919\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 215.4625 - val_loss: 43.9719\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 210.0502 - val_loss: 41.4461\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 204.7511 - val_loss: 39.0127\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 199.5636 - val_loss: 36.6704\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 194.4863 - val_loss: 34.4175\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 189.5175 - val_loss: 32.2528\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 184.6563 - val_loss: 30.1746\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 179.9011 - val_loss: 28.1814\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 175.2504 - val_loss: 26.2718\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 170.7028 - val_loss: 24.4442\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 166.2569 - val_loss: 22.6971\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 161.9112 - val_loss: 21.0290\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 157.6644 - val_loss: 19.4385\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 153.5150 - val_loss: 17.9242\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 149.4618 - val_loss: 16.4844\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 145.5031 - val_loss: 15.1178\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 141.6378 - val_loss: 13.8229\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 137.8642 - val_loss: 12.5982\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 134.1811 - val_loss: 11.4423\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 130.5872 - val_loss: 10.3538\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 127.0811 - val_loss: 9.3310\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 123.6613 - val_loss: 8.3727\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 120.3265 - val_loss: 7.4775\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 117.0753 - val_loss: 6.6438\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 113.9067 - val_loss: 5.8702\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 110.8188 - val_loss: 5.1556\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 107.8107 - val_loss: 4.4981\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 104.8806 - val_loss: 3.8965\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 102.0276 - val_loss: 3.3496\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 99.2501 - val_loss: 2.8558\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 96.5468 - val_loss: 2.4138\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 93.9164 - val_loss: 2.0222\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 91.3577 - val_loss: 1.6796\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 88.8693 - val_loss: 1.3848\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 86.4499 - val_loss: 1.1363\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 84.0981 - val_loss: 0.9328\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 81.8129 - val_loss: 0.7731\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 79.5928 - val_loss: 0.6558\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 77.4367 - val_loss: 0.5796\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 75.3433 - val_loss: 0.5432\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 73.3111 - val_loss: 0.5454\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 71.3393 - val_loss: 0.5848\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 69.4263 - val_loss: 0.6603\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 67.5711 - val_loss: 0.7705\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 65.7723 - val_loss: 0.9144\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 64.0288 - val_loss: 1.0905\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 62.3395 - val_loss: 1.2978\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 60.7031 - val_loss: 1.5351\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 59.1185 - val_loss: 1.8011\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 57.5846 - val_loss: 2.0947\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 56.1000 - val_loss: 2.4148\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 54.6638 - val_loss: 2.7602\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 53.2749 - val_loss: 3.1299\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 51.9320 - val_loss: 3.5226\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 50.6341 - val_loss: 3.9375\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 49.3800 - val_loss: 4.3732\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 48.1688 - val_loss: 4.8288\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 46.9993 - val_loss: 5.3033\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 45.8705 - val_loss: 5.7957\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 44.7814 - val_loss: 6.3049\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 43.7308 - val_loss: 6.8299\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 42.7180 - val_loss: 7.3698\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 41.7418 - val_loss: 7.9237\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 40.8011 - val_loss: 8.4905\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 39.8951 - val_loss: 9.0695\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 39.0228 - val_loss: 9.6596\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 38.1834 - val_loss: 10.2600\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 37.3758 - val_loss: 10.8698\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 36.5990 - val_loss: 11.4882\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 35.8524 - val_loss: 12.1144\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 35.1348 - val_loss: 12.7476\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 34.4455 - val_loss: 13.3869\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 33.7835 - val_loss: 14.0318\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.1482 - val_loss: 14.6813\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 32.5386 - val_loss: 15.3347\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 31.9539 - val_loss: 15.9915\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 31.3934 - val_loss: 16.6506\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 30.8562 - val_loss: 17.3119\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 30.3416 - val_loss: 17.9742\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.8489 - val_loss: 18.6373\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.3773 - val_loss: 19.3004\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 28.9260 - val_loss: 19.9629\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 28.4945 - val_loss: 20.6241\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 28.0820 - val_loss: 21.2839\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 27.6879 - val_loss: 21.9413\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 27.3114 - val_loss: 22.5961\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 26.9520 - val_loss: 23.2479\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 26.6090 - val_loss: 23.8958\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 26.2818 - val_loss: 24.5395\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 25.9699 - val_loss: 25.1788\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 25.6726 - val_loss: 25.8131\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 25.3894 - val_loss: 26.4422\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 25.1197 - val_loss: 27.0655\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 24.8630 - val_loss: 27.6828\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 24.6188 - val_loss: 28.2937\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 24.3866 - val_loss: 28.8980\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 24.1658 - val_loss: 29.4951\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 23.9562 - val_loss: 30.0850\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 23.7571 - val_loss: 30.6672\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 23.5681 - val_loss: 31.2419\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 23.3887 - val_loss: 31.8083\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 23.2187 - val_loss: 32.3666\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 23.0575 - val_loss: 32.9167\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.9047 - val_loss: 33.4583\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.7600 - val_loss: 33.9910\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.6231 - val_loss: 34.5146\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.4936 - val_loss: 35.0295\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.3710 - val_loss: 35.5351\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.2552 - val_loss: 36.0314\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.1458 - val_loss: 36.5183\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 22.0424 - val_loss: 36.9959\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 21.9449 - val_loss: 37.4642\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 21.8528 - val_loss: 37.9229\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 21.7659 - val_loss: 38.3719\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.6840 - val_loss: 38.8116\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.6069 - val_loss: 39.2415\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.5342 - val_loss: 39.6618\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.4658 - val_loss: 40.0726\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.4014 - val_loss: 40.4738\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 21.3409 - val_loss: 40.8655\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 21.2839 - val_loss: 41.2479\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 21.2304 - val_loss: 41.6207\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 21.1801 - val_loss: 41.9840\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.1329 - val_loss: 42.3382\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.0885 - val_loss: 42.6831\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.0469 - val_loss: 43.0188\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 21.0080 - val_loss: 43.3455\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 20.9714 - val_loss: 43.6630\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.9371 - val_loss: 43.9717\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.9050 - val_loss: 44.2717\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.8750 - val_loss: 44.5632\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 20.8468 - val_loss: 44.8462\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 20.8205 - val_loss: 45.1206\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.7958 - val_loss: 45.3869\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 20.7728 - val_loss: 45.6450\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.7513 - val_loss: 45.8950\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.7312 - val_loss: 46.1375\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.7124 - val_loss: 46.3719\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.6948 - val_loss: 46.5988\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.6784 - val_loss: 46.8183\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.6631 - val_loss: 47.0302\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.6489 - val_loss: 47.2353\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.6356 - val_loss: 47.4333\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.6232 - val_loss: 47.6244\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.6116 - val_loss: 47.8088\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.6009 - val_loss: 47.9869\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 20.5908 - val_loss: 48.1584\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 20.5815 - val_loss: 48.3239\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 20.5728 - val_loss: 48.4832\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 20.5647 - val_loss: 48.6365\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5572 - val_loss: 48.7841\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5502 - val_loss: 48.9263\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5437 - val_loss: 49.0628\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5376 - val_loss: 49.1939\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5320 - val_loss: 49.3200\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5268 - val_loss: 49.4412\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5219 - val_loss: 49.5576\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.5174 - val_loss: 49.6690\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5132 - val_loss: 49.7760\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5093 - val_loss: 49.8785\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5057 - val_loss: 49.9770\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5024 - val_loss: 50.0712\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 20.4993 - val_loss: 50.1614\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4964 - val_loss: 50.2478\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4937 - val_loss: 50.3303\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4913 - val_loss: 50.4091\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4890 - val_loss: 50.4845\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4869 - val_loss: 50.5565\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4850 - val_loss: 50.6257\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4832 - val_loss: 50.6914\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4815 - val_loss: 50.7540\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4800 - val_loss: 50.8137\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4786 - val_loss: 50.8706\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4774 - val_loss: 50.9249\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4762 - val_loss: 50.9764\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4751 - val_loss: 51.0258\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4741 - val_loss: 51.0726\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.4732 - val_loss: 51.1170\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4725 - val_loss: 51.1593\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4717 - val_loss: 51.1996\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 20.4710 - val_loss: 51.2378\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4704 - val_loss: 51.2740\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4699 - val_loss: 51.3084\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4694 - val_loss: 51.3409\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4689 - val_loss: 51.3719\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4686 - val_loss: 51.4014\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4682 - val_loss: 51.4289\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4679 - val_loss: 51.4551\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4677 - val_loss: 51.4798\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4675 - val_loss: 51.5034\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4673 - val_loss: 51.5255\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4672 - val_loss: 51.5465\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.4670 - val_loss: 51.5665\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4669 - val_loss: 51.5850\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 20.4669 - val_loss: 51.6025\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4669 - val_loss: 51.6191\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4669 - val_loss: 51.6352\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4669 - val_loss: 51.6500\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4669 - val_loss: 51.6638\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4670 - val_loss: 51.6769\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4670 - val_loss: 51.6890\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4672 - val_loss: 51.7008\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4673 - val_loss: 51.7119\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4674 - val_loss: 51.7219\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4675 - val_loss: 51.7316\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4677 - val_loss: 51.7405\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 20.4678 - val_loss: 51.7488\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4680 - val_loss: 51.7567\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4682 - val_loss: 51.7640\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4684 - val_loss: 51.7708\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4686 - val_loss: 51.7775\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4688 - val_loss: 51.7836\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4690 - val_loss: 51.7892\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4692 - val_loss: 51.7942\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4695 - val_loss: 51.7991\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4697 - val_loss: 51.8035\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4699 - val_loss: 51.8077\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4702 - val_loss: 51.8116\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4705 - val_loss: 51.8152\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4707 - val_loss: 51.8187\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4710 - val_loss: 51.8217\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.4712 - val_loss: 51.8248\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4715 - val_loss: 51.8273\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4718 - val_loss: 51.8298\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4720 - val_loss: 51.8321\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4723 - val_loss: 51.8340\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4726 - val_loss: 51.8356\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4729 - val_loss: 51.8375\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4731 - val_loss: 51.8390\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4734 - val_loss: 51.8406\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4736 - val_loss: 51.8416\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4740 - val_loss: 51.8429\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4743 - val_loss: 51.8441\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4745 - val_loss: 51.8450\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4748 - val_loss: 51.8458\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4750 - val_loss: 51.8464\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.4753 - val_loss: 51.8471\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4756 - val_loss: 51.8477\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4759 - val_loss: 51.8482\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4762 - val_loss: 51.8487\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4764 - val_loss: 51.8489\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4767 - val_loss: 51.8492\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4770 - val_loss: 51.8494\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4773 - val_loss: 51.8498\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4775 - val_loss: 51.8499\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4778 - val_loss: 51.8499\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4781 - val_loss: 51.8500\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4783 - val_loss: 51.8500\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4785 - val_loss: 51.8499\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4788 - val_loss: 51.8496\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 20.4791 - val_loss: 51.8496\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4793 - val_loss: 51.8494\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4796 - val_loss: 51.8494\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4798 - val_loss: 51.8490\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4800 - val_loss: 51.8488\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4803 - val_loss: 51.8486\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4805 - val_loss: 51.8484\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4808 - val_loss: 51.8480\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4810 - val_loss: 51.8476\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4813 - val_loss: 51.8475\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4815 - val_loss: 51.8471\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4818 - val_loss: 51.8470\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4819 - val_loss: 51.8464\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4822 - val_loss: 51.8462\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 20.4824 - val_loss: 51.8460\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4826 - val_loss: 51.8459\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4829 - val_loss: 51.8454\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4831 - val_loss: 51.8449\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4833 - val_loss: 51.8447\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4835 - val_loss: 51.8443\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4837 - val_loss: 51.8441\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4839 - val_loss: 51.8437\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4841 - val_loss: 51.8434\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4843 - val_loss: 51.8430\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4845 - val_loss: 51.8427\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4847 - val_loss: 51.8423\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4849 - val_loss: 51.8419\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.4851 - val_loss: 51.8415\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4853 - val_loss: 51.8413\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4855 - val_loss: 51.8409\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4857 - val_loss: 51.8405\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4858 - val_loss: 51.8402\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4860 - val_loss: 51.8400\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4862 - val_loss: 51.8396\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4863 - val_loss: 51.8393\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4865 - val_loss: 51.8390\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4867 - val_loss: 51.8387\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4868 - val_loss: 51.8382\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4870 - val_loss: 51.8379\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4872 - val_loss: 51.8377\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.4874 - val_loss: 51.8373\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4875 - val_loss: 51.8371\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4876 - val_loss: 51.8368\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4878 - val_loss: 51.8364\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4880 - val_loss: 51.8358\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4881 - val_loss: 51.8356\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4883 - val_loss: 51.8354\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4884 - val_loss: 51.8352\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4885 - val_loss: 51.8347\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4887 - val_loss: 51.8344\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4888 - val_loss: 51.8341\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4890 - val_loss: 51.8339\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.4891 - val_loss: 51.8335\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4892 - val_loss: 51.8333\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4894 - val_loss: 51.8331\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4895 - val_loss: 51.8328\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4896 - val_loss: 51.8325\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4897 - val_loss: 51.8324\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4899 - val_loss: 51.8322\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 20.4899 - val_loss: 51.8319\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4901 - val_loss: 51.8314\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4902 - val_loss: 51.8311\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4903 - val_loss: 51.8309\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4904 - val_loss: 51.8305\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 20.4905 - val_loss: 51.8300\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 20.4906 - val_loss: 51.8298\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(85.7336, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0020, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0125, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3008, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 366ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.36700280e+01, 6.36364146e+01, 6.36028011e+01, 6.35691877e+01,\n",
       "        6.35355742e+01, 6.35019608e+01, 6.34683473e+01, 6.34347339e+01,\n",
       "        6.34011205e+01, 6.33675070e+01, 6.33338936e+01, 6.33002801e+01,\n",
       "        6.32666667e+01, 6.32330532e+01, 6.31994398e+01, 6.31658263e+01,\n",
       "        6.31322129e+01, 6.30985994e+01, 6.30649860e+01, 6.30313726e+01,\n",
       "        6.29977591e+01, 6.29641457e+01, 6.29305322e+01, 6.28969188e+01,\n",
       "        6.28633053e+01, 6.28296919e+01, 6.27960784e+01, 6.27624650e+01,\n",
       "        6.27288515e+01, 6.26980159e+01, 6.26840103e+01, 6.26700047e+01,\n",
       "        6.26559991e+01, 6.26419935e+01, 6.26279879e+01, 6.26139823e+01,\n",
       "        6.25999767e+01, 6.25859711e+01, 6.25719655e+01, 6.25579599e+01,\n",
       "        6.25439542e+01, 6.25299487e+01, 6.25159430e+01, 6.25019374e+01,\n",
       "        6.24879318e+01, 6.24739262e+01, 6.24599206e+01, 6.24459150e+01,\n",
       "        6.24319094e+01, 6.24179038e+01, 6.24038982e+01, 6.23898926e+01,\n",
       "        6.23758870e+01, 6.23618814e+01, 6.23478758e+01, 6.23338702e+01,\n",
       "        6.23198646e+01, 6.23058590e+01, 6.22918534e+01, 6.22778478e+01,\n",
       "        6.22638422e+01, 6.22498366e+01, 6.22358310e+01, 6.22218254e+01,\n",
       "        6.22078198e+01, 6.21876284e+01, 6.21596172e+01, 6.21316060e+01,\n",
       "        6.21035948e+01, 6.20755836e+01, 6.20475724e+01, 6.20195612e+01,\n",
       "        6.19915499e+01, 6.19635387e+01, 6.19355275e+01, 6.19075163e+01,\n",
       "        6.18795051e+01, 6.18514939e+01, 6.18234827e+01, 6.17954715e+01,\n",
       "        7.00675430e+01, 1.45537212e-01, 3.87901336e-01, 3.55150253e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.08446628e-01, 1.78240418e-01,\n",
       "        9.24678892e-02, 0.00000000e+00, 1.13204098e+00, 0.00000000e+00,\n",
       "        2.78546482e-01, 0.00000000e+00, 1.32669955e-01, 2.63000011e-01,\n",
       "        0.00000000e+00, 1.86743855e-01, 1.53639466e-02, 8.11721534e-02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59.54016106, 59.53502568, 59.52989029, 59.5247549 , 59.51961951,\n",
       "       59.51448413, 59.50934874, 59.50421335, 59.49907796, 59.49394258,\n",
       "       59.48880719, 59.4836718 , 59.47853641, 59.47340103, 59.46826564,\n",
       "       59.46313025, 59.45799486, 59.45285948, 59.44772409, 59.4425887 ,\n",
       "       59.43745331, 59.43231793, 59.42718254, 59.42204715, 59.41691176,\n",
       "       59.41177638, 59.40664099, 59.4015056 , 59.39637021, 59.39123483,\n",
       "       59.38609944, 59.38096405, 59.37582866, 59.37069328, 59.36555789,\n",
       "       59.3604225 , 59.35528711, 59.35015173, 59.34501634, 59.33988095,\n",
       "       59.33474556, 59.32961018, 59.32447479, 59.3193394 , 59.31420401,\n",
       "       59.30906863, 59.30393324, 59.29879785, 59.29366246, 59.28852708,\n",
       "       59.28339169, 59.2782563 , 59.27312092, 59.26798553, 59.26285014,\n",
       "       59.25771475, 59.25257937, 59.24744398, 59.24230859, 59.2371732 ,\n",
       "       59.23203782, 59.22690243, 59.22176704, 59.21663165, 59.21149627,\n",
       "       59.20636088, 59.20122549, 59.1960901 , 59.19095472, 59.18581933,\n",
       "       59.18068394, 59.17554855, 59.17041317, 59.16527778, 59.16014239,\n",
       "       59.155007  , 59.14987162, 59.14473623, 59.13960084, 59.13446545,\n",
       "       59.12933007, 59.12419468, 59.11905929, 59.1139239 , 59.10878852,\n",
       "       59.10365313, 59.09851774, 59.09338235, 59.08824697, 59.08311158,\n",
       "       59.07797619, 59.0728408 , 59.06770542, 59.06257003, 59.05743464,\n",
       "       59.05229925, 59.04716387, 59.04202848, 59.03689309, 59.0317577 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.86918776272012\n",
      "13.940394636211538\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
