{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "2145    58.492457\n",
       "2146    58.483439\n",
       "2147    58.474421\n",
       "2148    58.465403\n",
       "2149    58.456385\n",
       "Name: C8, Length: 2150, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c8_interpolated_2050_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "2045     0.263000\n",
       "2046     0.000000\n",
       "2047     0.186744\n",
       "2048     0.015364\n",
       "2049     0.081172\n",
       "Name: C8, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2050)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.987115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.774230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87.561345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.348459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.200000  0.000298\n",
       "1     87.987115  0.000298\n",
       "2     87.774230  0.000297\n",
       "3     87.561345  0.000297\n",
       "4     87.348459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 85.7336  # Value for C0\n",
    "K0 = -0.0020  # Value for K0\n",
    "K1 = 0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0125    # Value for b\n",
    "c = 2.3008    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.200000    87.987115    87.774230    87.561345    87.348459   \n",
      "351    87.987115    87.774230    87.561345    87.348459    87.135574   \n",
      "352    87.774230    87.561345    87.348459    87.135574    86.922689   \n",
      "353    87.561345    87.348459    87.135574    86.922689    86.709804   \n",
      "354    87.348459    87.135574    86.922689    86.709804    86.496919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.135574    86.922689    86.709804    86.496919    86.294538  ...   \n",
      "351    86.922689    86.709804    86.496919    86.294538    86.221709  ...   \n",
      "352    86.709804    86.496919    86.294538    86.221709    86.148880  ...   \n",
      "353    86.496919    86.294538    86.221709    86.148880    86.076050  ...   \n",
      "354    86.294538    86.221709    86.148880    86.076050    86.003221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   76.094351    0.000263   76.058870    0.000263   76.023389    0.000263   \n",
      "351   76.058870    0.000263   76.023389    0.000263   75.987909    0.000262   \n",
      "352   76.023389    0.000263   75.987909    0.000262   75.952428    0.000262   \n",
      "353   75.987909    0.000262   75.952428    0.000262   75.916947    0.000262   \n",
      "354   75.952428    0.000262   75.916947    0.000262   75.881466    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   75.987909    0.000262   75.952428    0.000262  \n",
      "351   75.952428    0.000262   75.916947    0.000262  \n",
      "352   75.916947    0.000262   75.881466    0.000262  \n",
      "353   75.881466    0.000262   75.845985    0.000262  \n",
      "354   75.845985    0.000262   75.810504    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 1, 251) (1600, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 28ms/step - loss: 4622.3906 - val_loss: 3292.7395\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4522.1929 - val_loss: 3241.5930\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4456.5376 - val_loss: 3190.9673\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4391.5874 - val_loss: 3141.0347\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4327.4204 - val_loss: 3091.7651\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4263.1836 - val_loss: 3028.8584\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4181.3735 - val_loss: 2977.8345\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4105.2144 - val_loss: 2913.4973\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4030.7317 - val_loss: 2861.0457\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3963.4148 - val_loss: 2810.1709\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3897.8176 - val_loss: 2760.5510\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 3833.5820 - val_loss: 2711.9683\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3770.4954 - val_loss: 2664.2993\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3708.4336 - val_loss: 2617.4680\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3647.3179 - val_loss: 2571.4231\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3587.0942 - val_loss: 2526.1287\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3527.7231 - val_loss: 2481.5566\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3469.1746 - val_loss: 2437.6851\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3411.4238 - val_loss: 2394.4954\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3354.4517 - val_loss: 2351.9722\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3298.2388 - val_loss: 2310.1030\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3242.7732 - val_loss: 2268.8735\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3188.0396 - val_loss: 2228.2749\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3134.0261 - val_loss: 2188.2942\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3080.7239 - val_loss: 2148.9163\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3026.3164 - val_loss: 2103.1802\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2960.6860 - val_loss: 2055.0955\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2897.4321 - val_loss: 2009.6594\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2837.4204 - val_loss: 1966.4446\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2779.8228 - val_loss: 1924.8623\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2724.0405 - val_loss: 1884.5850\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2669.7373 - val_loss: 1845.4215\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2616.7117 - val_loss: 1807.2498\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2564.8306 - val_loss: 1769.9861\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2514.0005 - val_loss: 1733.5686\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2464.1516 - val_loss: 1697.9495\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2415.2295 - val_loss: 1663.0914\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2367.1917 - val_loss: 1628.9636\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2320.0020 - val_loss: 1595.5396\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2273.6304 - val_loss: 1562.7968\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2228.0513 - val_loss: 1530.7167\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2183.2415 - val_loss: 1499.2811\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2139.1819 - val_loss: 1468.4747\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2095.8540 - val_loss: 1438.2836\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2053.2419 - val_loss: 1408.6945\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2011.3303 - val_loss: 1379.6956\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1970.1064 - val_loss: 1351.2754\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1929.5566 - val_loss: 1323.4238\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1889.6696 - val_loss: 1296.1310\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1850.4338 - val_loss: 1269.3872\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1811.8389 - val_loss: 1243.1838\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1773.8748 - val_loss: 1217.5123\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1736.5320 - val_loss: 1192.3639\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1699.8011 - val_loss: 1167.7314\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1663.6735 - val_loss: 1143.6068\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1628.1410 - val_loss: 1119.9828\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1593.1945 - val_loss: 1096.8518\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1558.8271 - val_loss: 1074.2080\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1525.0305 - val_loss: 1052.0430\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1491.7975 - val_loss: 1030.3512\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1459.1206 - val_loss: 1009.1254\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1426.9926 - val_loss: 988.3597\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1395.4067 - val_loss: 968.0477\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1364.3562 - val_loss: 948.1830\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1333.8342 - val_loss: 928.7604\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1303.8344 - val_loss: 909.7726\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1274.3502 - val_loss: 891.2150\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1245.3757 - val_loss: 873.0814\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1216.9042 - val_loss: 855.3662\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1188.9298 - val_loss: 838.0630\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1161.4465 - val_loss: 821.1670\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1134.4479 - val_loss: 804.6733\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1107.9288 - val_loss: 788.5751\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1081.8832 - val_loss: 772.8678\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1056.3051 - val_loss: 757.5460\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1031.1890 - val_loss: 742.6042\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1006.5297 - val_loss: 728.0376\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 982.3211 - val_loss: 713.8408\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 958.5581 - val_loss: 700.0087\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 935.2346 - val_loss: 686.5361\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 912.3463 - val_loss: 673.4184\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 889.8869 - val_loss: 660.6495\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 867.8517 - val_loss: 648.2258\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 846.2355 - val_loss: 636.1421\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 825.0328 - val_loss: 624.3926\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 804.2393 - val_loss: 612.9734\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 783.8488 - val_loss: 601.8795\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 763.8566 - val_loss: 591.1060\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 744.2579 - val_loss: 580.6477\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 725.0474 - val_loss: 570.5003\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 706.2203 - val_loss: 560.6591\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 687.7716 - val_loss: 551.1194\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 669.6969 - val_loss: 541.8763\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 651.9910 - val_loss: 532.9259\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 634.6494 - val_loss: 524.2626\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 617.6664 - val_loss: 515.8830\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 601.0382 - val_loss: 507.7814\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 584.7597 - val_loss: 499.9537\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 568.8262 - val_loss: 492.3958\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 553.2333 - val_loss: 485.1027\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 537.9761 - val_loss: 478.0703\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 523.0500 - val_loss: 471.2940\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 508.4505 - val_loss: 464.7691\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 494.1727 - val_loss: 458.4918\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 480.2123 - val_loss: 452.4572\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 466.5649 - val_loss: 446.6612\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 453.2256 - val_loss: 441.0996\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 440.1907 - val_loss: 435.7678\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 427.4553 - val_loss: 430.6620\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 415.0149 - val_loss: 425.7773\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 402.8652 - val_loss: 421.1100\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 391.0016 - val_loss: 416.6555\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 379.4203 - val_loss: 412.4099\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 368.1166 - val_loss: 408.3689\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 357.0864 - val_loss: 404.5284\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 346.3251 - val_loss: 400.8840\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 335.8286 - val_loss: 397.4321\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 325.5930 - val_loss: 394.1682\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 315.6137 - val_loss: 391.0883\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 305.8866 - val_loss: 388.1885\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 296.4076 - val_loss: 385.4647\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 287.1725 - val_loss: 382.9128\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 278.1772 - val_loss: 380.5289\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 269.4177 - val_loss: 378.3092\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 260.8900 - val_loss: 376.2497\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 252.5898 - val_loss: 374.3464\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 244.5134 - val_loss: 372.5956\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 236.6565 - val_loss: 370.9931\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 229.0154 - val_loss: 369.5354\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 221.5858 - val_loss: 368.2188\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 214.3642 - val_loss: 367.0392\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 207.3465 - val_loss: 365.9931\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 200.5289 - val_loss: 365.0766\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 193.9074 - val_loss: 364.2860\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 187.4784 - val_loss: 363.6180\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 181.2381 - val_loss: 363.0687\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 175.1828 - val_loss: 362.6345\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 169.3086 - val_loss: 362.3118\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 163.6119 - val_loss: 362.0972\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 158.0890 - val_loss: 361.9872\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 152.7365 - val_loss: 361.9782\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 147.5506 - val_loss: 362.0668\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 142.5276 - val_loss: 362.2498\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 137.6640 - val_loss: 362.5236\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 132.9563 - val_loss: 362.8849\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 128.4014 - val_loss: 363.3305\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 123.9952 - val_loss: 363.8571\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 119.7347 - val_loss: 364.4616\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 115.6166 - val_loss: 365.1406\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 111.6372 - val_loss: 365.8912\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 107.7935 - val_loss: 366.7101\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 104.0821 - val_loss: 367.5943\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 100.4997 - val_loss: 368.5409\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 97.0433 - val_loss: 369.5468\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 93.7096 - val_loss: 370.6091\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 90.4954 - val_loss: 371.7250\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 87.3976 - val_loss: 372.8916\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 84.4133 - val_loss: 374.1061\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 81.5393 - val_loss: 375.3658\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 78.7729 - val_loss: 376.6679\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 76.1109 - val_loss: 378.0098\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 73.5506 - val_loss: 379.3890\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 71.0889 - val_loss: 380.8029\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 68.7233 - val_loss: 382.2488\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 66.4508 - val_loss: 383.7245\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 64.2688 - val_loss: 385.2274\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 62.1745 - val_loss: 386.7554\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 60.1654 - val_loss: 388.3060\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 58.2388 - val_loss: 389.8770\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 56.3922 - val_loss: 391.4661\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 54.6230 - val_loss: 393.0716\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 52.9288 - val_loss: 394.6908\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 51.3073 - val_loss: 396.3219\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 49.7560 - val_loss: 397.9631\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 48.2726 - val_loss: 399.6123\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 46.8549 - val_loss: 401.2676\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 45.5004 - val_loss: 402.9273\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 44.2072 - val_loss: 404.5897\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 42.9729 - val_loss: 406.2529\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 41.7957 - val_loss: 407.9156\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 40.6734 - val_loss: 409.5757\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 39.6039 - val_loss: 411.2320\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 38.5854 - val_loss: 412.8830\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 37.6158 - val_loss: 414.5273\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 36.6934 - val_loss: 416.1634\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 35.8164 - val_loss: 417.7899\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 34.9830 - val_loss: 419.4062\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 34.1913 - val_loss: 421.0103\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 33.4398 - val_loss: 422.6014\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 32.7268 - val_loss: 424.1785\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 32.0507 - val_loss: 425.7403\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 31.4100 - val_loss: 427.2859\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8033 - val_loss: 428.8143\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.2290 - val_loss: 430.3250\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 29.6856 - val_loss: 431.8168\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 29.1719 - val_loss: 433.2892\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 28.6865 - val_loss: 434.7412\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 28.2281 - val_loss: 436.1723\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 27.7956 - val_loss: 437.5820\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 27.3876 - val_loss: 438.9692\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 27.0030 - val_loss: 440.3340\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 26.6407 - val_loss: 441.6757\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 26.2997 - val_loss: 442.9936\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 25.9788 - val_loss: 444.2874\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 25.6772 - val_loss: 445.5573\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 25.3938 - val_loss: 446.8026\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 25.1276 - val_loss: 448.0227\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 24.8778 - val_loss: 449.2178\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 24.6436 - val_loss: 450.3876\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 24.4241 - val_loss: 451.5324\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 24.2184 - val_loss: 452.6513\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 24.0260 - val_loss: 453.7448\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 23.8460 - val_loss: 454.8125\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 23.6778 - val_loss: 455.8543\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 23.5207 - val_loss: 456.8708\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 23.3740 - val_loss: 457.8619\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.2372 - val_loss: 458.8276\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.1096 - val_loss: 459.7679\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.9908 - val_loss: 460.6828\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.8802 - val_loss: 461.5727\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.7773 - val_loss: 462.4378\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.6816 - val_loss: 463.2778\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.5929 - val_loss: 464.0942\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 22.5103 - val_loss: 464.8861\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 22.4338 - val_loss: 465.6548\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.3629 - val_loss: 466.3995\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.2971 - val_loss: 467.1212\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.2363 - val_loss: 467.8199\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 22.1800 - val_loss: 468.4961\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.1280 - val_loss: 469.1502\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.0799 - val_loss: 469.7820\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 22.0356 - val_loss: 470.3929\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.9947 - val_loss: 470.9832\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.9569 - val_loss: 471.5523\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.9221 - val_loss: 472.1014\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.8902 - val_loss: 472.6309\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.8607 - val_loss: 473.1413\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.8336 - val_loss: 473.6328\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.8087 - val_loss: 474.1053\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.7859 - val_loss: 474.5601\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.7650 - val_loss: 474.9974\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.7459 - val_loss: 475.4177\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.7283 - val_loss: 475.8214\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 21.7122 - val_loss: 476.2088\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.6974 - val_loss: 476.5806\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.6840 - val_loss: 476.9372\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.6717 - val_loss: 477.2787\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.6605 - val_loss: 477.6059\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.6502 - val_loss: 477.9186\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.6409 - val_loss: 478.2181\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 21.6324 - val_loss: 478.5044\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.6247 - val_loss: 478.7778\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.6177 - val_loss: 479.0390\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.6114 - val_loss: 479.2886\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.6056 - val_loss: 479.5265\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.6003 - val_loss: 479.7531\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.5956 - val_loss: 479.9691\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.5914 - val_loss: 480.1749\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.5875 - val_loss: 480.3707\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5840 - val_loss: 480.5570\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.5809 - val_loss: 480.7339\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5781 - val_loss: 480.9023\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.5756 - val_loss: 481.0620\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.5733 - val_loss: 481.2138\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.5713 - val_loss: 481.3578\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.5695 - val_loss: 481.4940\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.5680 - val_loss: 481.6231\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.5666 - val_loss: 481.7457\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.5653 - val_loss: 481.8610\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.5643 - val_loss: 481.9705\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.5633 - val_loss: 482.0738\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.5625 - val_loss: 482.1715\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.5618 - val_loss: 482.2636\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.5612 - val_loss: 482.3504\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5608 - val_loss: 482.4322\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 21.5604 - val_loss: 482.5097\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5601 - val_loss: 482.5820\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.5599 - val_loss: 482.6503\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.5597 - val_loss: 482.7150\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5596 - val_loss: 482.7755\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5596 - val_loss: 482.8323\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5596 - val_loss: 482.8854\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5596 - val_loss: 482.9351\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.5597 - val_loss: 482.9818\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5599 - val_loss: 483.0258\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5600 - val_loss: 483.0666\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5603 - val_loss: 483.1048\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5605 - val_loss: 483.1404\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5608 - val_loss: 483.1738\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5611 - val_loss: 483.2045\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5614 - val_loss: 483.2333\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5618 - val_loss: 483.2605\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5622 - val_loss: 483.2856\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5626 - val_loss: 483.3087\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5630 - val_loss: 483.3301\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5634 - val_loss: 483.3502\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5639 - val_loss: 483.3690\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5644 - val_loss: 483.3857\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5648 - val_loss: 483.4018\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5653 - val_loss: 483.4166\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5658 - val_loss: 483.4299\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5663 - val_loss: 483.4421\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5668 - val_loss: 483.4535\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5673 - val_loss: 483.4641\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5678 - val_loss: 483.4732\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5684 - val_loss: 483.4820\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5689 - val_loss: 483.4897\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5695 - val_loss: 483.4968\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5700 - val_loss: 483.5029\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5706 - val_loss: 483.5089\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5711 - val_loss: 483.5142\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5717 - val_loss: 483.5191\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5723 - val_loss: 483.5235\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5728 - val_loss: 483.5273\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5734 - val_loss: 483.5307\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5739 - val_loss: 483.5335\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5746 - val_loss: 483.5364\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5751 - val_loss: 483.5384\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5757 - val_loss: 483.5400\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5763 - val_loss: 483.5420\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5768 - val_loss: 483.5430\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5774 - val_loss: 483.5443\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5779 - val_loss: 483.5450\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5785 - val_loss: 483.5456\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5791 - val_loss: 483.5463\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5797 - val_loss: 483.5467\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5802 - val_loss: 483.5464\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5808 - val_loss: 483.5462\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5814 - val_loss: 483.5457\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5819 - val_loss: 483.5456\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5824 - val_loss: 483.5447\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5830 - val_loss: 483.5441\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5836 - val_loss: 483.5434\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5841 - val_loss: 483.5427\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.5847 - val_loss: 483.5417\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5852 - val_loss: 483.5409\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5858 - val_loss: 483.5396\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5863 - val_loss: 483.5386\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5869 - val_loss: 483.5378\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5874 - val_loss: 483.5367\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5879 - val_loss: 483.5356\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5884 - val_loss: 483.5343\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5890 - val_loss: 483.5329\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5895 - val_loss: 483.5319\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5900 - val_loss: 483.5307\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5905 - val_loss: 483.5295\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5910 - val_loss: 483.5283\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5915 - val_loss: 483.5268\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5920 - val_loss: 483.5255\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5925 - val_loss: 483.5239\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5930 - val_loss: 483.5229\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5935 - val_loss: 483.5215\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5940 - val_loss: 483.5204\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5944 - val_loss: 483.5190\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5950 - val_loss: 483.5179\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5953 - val_loss: 483.5162\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5958 - val_loss: 483.5149\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5963 - val_loss: 483.5136\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5967 - val_loss: 483.5119\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5972 - val_loss: 483.5107\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5976 - val_loss: 483.5094\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5981 - val_loss: 483.5081\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5985 - val_loss: 483.5065\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5989 - val_loss: 483.5051\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5994 - val_loss: 483.5037\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5998 - val_loss: 483.5026\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6002 - val_loss: 483.5013\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6006 - val_loss: 483.5003\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6010 - val_loss: 483.4993\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6014 - val_loss: 483.4978\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6018 - val_loss: 483.4966\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.6022 - val_loss: 483.4953\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6026 - val_loss: 483.4938\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6029 - val_loss: 483.4926\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6033 - val_loss: 483.4912\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6037 - val_loss: 483.4902\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6041 - val_loss: 483.4889\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6044 - val_loss: 483.4875\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6049 - val_loss: 483.4867\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6052 - val_loss: 483.4856\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6055 - val_loss: 483.4843\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6059 - val_loss: 483.4833\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6062 - val_loss: 483.4820\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6065 - val_loss: 483.4810\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6069 - val_loss: 483.4799\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6072 - val_loss: 483.4789\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6076 - val_loss: 483.4782\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6078 - val_loss: 483.4770\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6081 - val_loss: 483.4756\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6085 - val_loss: 483.4750\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6088 - val_loss: 483.4740\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6091 - val_loss: 483.4728\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.6094 - val_loss: 483.4722\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6096 - val_loss: 483.4710\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6099 - val_loss: 483.4699\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6102 - val_loss: 483.4689\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6105 - val_loss: 483.4682\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6108 - val_loss: 483.4674\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6111 - val_loss: 483.4664\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6113 - val_loss: 483.4654\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6116 - val_loss: 483.4646\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6119 - val_loss: 483.4638\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6121 - val_loss: 483.4630\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6124 - val_loss: 483.4622\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6126 - val_loss: 483.4615\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6129 - val_loss: 483.4606\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6131 - val_loss: 483.4597\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6134 - val_loss: 483.4590\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6135 - val_loss: 483.4581\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6138 - val_loss: 483.4574\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6140 - val_loss: 483.4565\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6142 - val_loss: 483.4559\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6145 - val_loss: 483.4553\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.6146 - val_loss: 483.4543\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6149 - val_loss: 483.4534\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6151 - val_loss: 483.4527\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6153 - val_loss: 483.4519\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6155 - val_loss: 483.4511\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6157 - val_loss: 483.4506\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6159 - val_loss: 483.4499\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6161 - val_loss: 483.4492\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6163 - val_loss: 483.4484\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6165 - val_loss: 483.4482\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6167 - val_loss: 483.4474\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6168 - val_loss: 483.4468\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6170 - val_loss: 483.4462\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6172 - val_loss: 483.4456\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6174 - val_loss: 483.4449\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6176 - val_loss: 483.4446\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6177 - val_loss: 483.4441\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6179 - val_loss: 483.4435\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6180 - val_loss: 483.4427\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.6181 - val_loss: 483.4419\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6183 - val_loss: 483.4411\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6185 - val_loss: 483.4408\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6187 - val_loss: 483.4404\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6188 - val_loss: 483.4400\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6190 - val_loss: 483.4398\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6191 - val_loss: 483.4394\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6192 - val_loss: 483.4390\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6193 - val_loss: 483.4384\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6195 - val_loss: 483.4381\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6196 - val_loss: 483.4374\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6197 - val_loss: 483.4371\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6199 - val_loss: 483.4365\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6200 - val_loss: 483.4363\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6202 - val_loss: 483.4362\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6202 - val_loss: 483.4355\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.6204 - val_loss: 483.4351\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6205 - val_loss: 483.4346\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6206 - val_loss: 483.4340\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6207 - val_loss: 483.4334\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6208 - val_loss: 483.4331\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6209 - val_loss: 483.4329\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6210 - val_loss: 483.4323\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6212 - val_loss: 483.4320\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6212 - val_loss: 483.4315\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6214 - val_loss: 483.4311\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6215 - val_loss: 483.4308\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6215 - val_loss: 483.4307\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6217 - val_loss: 483.4304\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6217 - val_loss: 483.4301\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6218 - val_loss: 483.4296\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6219 - val_loss: 483.4294\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.6220 - val_loss: 483.4290\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6221 - val_loss: 483.4286\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6222 - val_loss: 483.4285\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6223 - val_loss: 483.4284\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6223 - val_loss: 483.4278\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6224 - val_loss: 483.4276\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6225 - val_loss: 483.4274\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6226 - val_loss: 483.4272\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6227 - val_loss: 483.4268\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6228 - val_loss: 483.4268\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6228 - val_loss: 483.4267\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6229 - val_loss: 483.4265\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6230 - val_loss: 483.4264\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6230 - val_loss: 483.4256\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6231 - val_loss: 483.4254\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6231 - val_loss: 483.4250\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.6232 - val_loss: 483.4248\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6233 - val_loss: 483.4244\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6234 - val_loss: 483.4244\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6234 - val_loss: 483.4242\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6234 - val_loss: 483.4239\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6235 - val_loss: 483.4236\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6236 - val_loss: 483.4234\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6237 - val_loss: 483.4232\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6237 - val_loss: 483.4228\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.6237 - val_loss: 483.4222\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6239 - val_loss: 483.4224\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6239 - val_loss: 483.4219\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6239 - val_loss: 483.4217\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6240 - val_loss: 483.4214\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6240 - val_loss: 483.4210\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6241 - val_loss: 483.4209\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.6242 - val_loss: 483.4207\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6242 - val_loss: 483.4204\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6242 - val_loss: 483.4201\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6243 - val_loss: 483.4200\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(85.7336, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0020, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0125, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3008, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 322ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62.63732493, 62.62331933, 62.60931373, 62.59530812, 62.58130252,\n",
       "        62.56729692, 62.55329132, 62.53928571, 62.52528011, 62.51127451,\n",
       "        62.49726891, 62.48326331, 62.4692577 , 62.4552521 , 62.4412465 ,\n",
       "        62.4272409 , 62.41323529, 62.39922969, 62.38522409, 62.37121849,\n",
       "        62.35721289, 62.34320728, 62.32920168, 62.31519608, 62.30119048,\n",
       "        62.28718487, 62.27317927, 62.25917367, 62.24516807, 62.23116246,\n",
       "        62.21715686, 62.20315126, 62.17829132, 62.15028011, 62.12226891,\n",
       "        62.0942577 , 62.0662465 , 62.03823529, 62.01022409, 61.98221289,\n",
       "        61.95420168, 61.92619048, 61.89817927, 61.87016807, 61.84215686,\n",
       "        61.81414566, 61.78613445, 67.5214636 , 67.1054972 ,  0.26116094,\n",
       "         0.        , 69.0569561 , 68.6535948 , 68.2455532 , 67.8295868 ,\n",
       "        67.4136204 , 66.9976541 , 66.6530929 , 66.4135971 , 66.1741013 ,\n",
       "         0.        ,  0.        ,  0.67579192, 67.3057773 , 66.8898109 ,\n",
       "        66.5910014 , 66.3515056 , 66.1120098 , 65.872514  , 65.6418067 ,\n",
       "        65.411916  , 65.1820252 ,  0.        ,  0.92070997,  0.        ,\n",
       "         0.        ,  0.        ,  0.24934343,  0.        ,  0.        ,\n",
       "        48.75449371,  0.        ,  0.10682043,  0.09127009,  0.20754489,\n",
       "         0.37116298,  0.54462194,  0.22259322,  0.23137362,  0.        ,\n",
       "         0.42073947,  0.        ,  0.        ,  0.33442262,  0.        ,\n",
       "         0.12086651,  0.16419116,  0.32742044,  0.        ,  0.15073624]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59.02662232, 59.02148693, 59.01635154, 59.01121615, 59.00608077,\n",
       "       59.00094538, 58.99580999, 58.9906746 , 58.98553922, 58.98040383,\n",
       "       58.97526844, 58.97013305, 58.96499767, 58.95986228, 58.95472689,\n",
       "       58.9495915 , 58.94445612, 58.93932073, 58.93418534, 58.92904995,\n",
       "       58.92391457, 58.91877918, 58.91364379, 58.9085084 , 58.90337302,\n",
       "       58.89823763, 58.89310224, 58.88796685, 58.88283147, 58.87769608,\n",
       "       58.87256069, 58.8674253 , 58.86228992, 58.85715453, 58.85201914,\n",
       "       58.84688375, 58.84174837, 58.83661298, 58.83147759, 58.8263422 ,\n",
       "       58.82120682, 58.81607143, 58.81093604, 58.80580065, 58.80066527,\n",
       "       58.79552988, 58.79039449, 58.7852591 , 58.78012372, 58.77498833,\n",
       "       58.76985294, 58.76471755, 58.75958217, 58.75444678, 58.74931139,\n",
       "       58.744176  , 58.73904062, 58.73390523, 58.72876984, 58.72363445,\n",
       "       58.71849907, 58.71336368, 58.70822829, 58.7030929 , 58.69795752,\n",
       "       58.69282213, 58.68768674, 58.68255135, 58.67741597, 58.67228058,\n",
       "       58.66714519, 58.6620098 , 58.65687442, 58.65173903, 58.64660364,\n",
       "       58.64146825, 58.63633287, 58.63119748, 58.62606209, 58.6209267 ,\n",
       "       58.61579132, 58.61065593, 58.60552054, 58.60038515, 58.59165813,\n",
       "       58.58263989, 58.57362164, 58.5646034 , 58.55558516, 58.54656692,\n",
       "       58.53754868, 58.52853044, 58.5195122 , 58.51049395, 58.50147571,\n",
       "       58.49245747, 58.48343923, 58.47442099, 58.46540275, 58.45638451])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.348785214562035\n",
      "22.009556399299797\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
