{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1845    64.420798\n",
       "1846    64.412395\n",
       "1847    64.403992\n",
       "1848    64.395588\n",
       "1849    64.387185\n",
       "Name: C4, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_1750_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1745    65.261134\n",
       "1746    65.252731\n",
       "1747    65.244328\n",
       "1748    65.235924\n",
       "1749    65.227521\n",
       "Name: C4, Length: 1750, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1750)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.409524</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.219048</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.028571</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.838095</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.600000  0.000298\n",
       "1     88.409524  0.000298\n",
       "2     88.219048  0.000297\n",
       "3     88.028571  0.000297\n",
       "4     87.838095  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.600000    88.409524    88.219048    88.028571    87.838095   \n",
      "351    88.409524    88.219048    88.028571    87.838095    87.647619   \n",
      "352    88.219048    88.028571    87.838095    87.647619    87.457143   \n",
      "353    88.028571    87.838095    87.647619    87.457143    87.266667   \n",
      "354    87.838095    87.647619    87.457143    87.266667    87.076190   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.647619    87.457143    87.266667    87.076190    86.896218  ...   \n",
      "351    87.457143    87.266667    87.076190    86.896218    86.845798  ...   \n",
      "352    87.266667    87.076190    86.896218    86.845798    86.795378  ...   \n",
      "353    87.076190    86.896218    86.845798    86.795378    86.744958  ...   \n",
      "354    86.896218    86.845798    86.795378    86.744958    86.694538  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   78.880345    0.000263   78.856069    0.000263   78.831793    0.000263   \n",
      "351   78.856069    0.000263   78.831793    0.000263   78.807516    0.000262   \n",
      "352   78.831793    0.000263   78.807516    0.000262   78.783240    0.000262   \n",
      "353   78.807516    0.000262   78.783240    0.000262   78.758964    0.000262   \n",
      "354   78.783240    0.000262   78.758964    0.000262   78.734687    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   78.807516    0.000262   78.783240    0.000262  \n",
      "351   78.783240    0.000262   78.758964    0.000262  \n",
      "352   78.758964    0.000262   78.734687    0.000262  \n",
      "353   78.734687    0.000262   78.710411    0.000262  \n",
      "354   78.710411    0.000262   78.686134    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 1, 251) (1300, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 2s 31ms/step - loss: 5436.2471 - val_loss: 4541.5776\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5369.0864 - val_loss: 4485.6592\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5305.8428 - val_loss: 4428.4336\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5247.0713 - val_loss: 4378.6265\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5193.0894 - val_loss: 4329.5239\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5139.8672 - val_loss: 4281.1035\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5087.3135 - val_loss: 4233.2632\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5035.3345 - val_loss: 4185.9365\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4983.8687 - val_loss: 4139.0806\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4932.8794 - val_loss: 4092.6682\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4882.3423 - val_loss: 4046.6826\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4832.2397 - val_loss: 4001.1101\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4782.5596 - val_loss: 3955.9385\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4733.2905 - val_loss: 3911.1616\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4684.4253 - val_loss: 3866.7708\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4635.9561 - val_loss: 3822.7610\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4587.8784 - val_loss: 3779.1277\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4540.1875 - val_loss: 3735.8660\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4492.8770 - val_loss: 3692.9712\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4445.9438 - val_loss: 3650.4409\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4399.3843 - val_loss: 3608.2700\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 4353.1948 - val_loss: 3566.4563\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4307.3716 - val_loss: 3524.9963\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4261.9126 - val_loss: 3483.8875\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4216.8145 - val_loss: 3443.1270\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4172.0742 - val_loss: 3402.7112\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4127.6885 - val_loss: 3362.6392\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4083.6558 - val_loss: 3322.9075\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4039.9727 - val_loss: 3283.5134\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3996.6370 - val_loss: 3244.4551\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3953.6460 - val_loss: 3205.7300\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3910.9990 - val_loss: 3167.3364\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3868.6914 - val_loss: 3129.2710\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3826.7227 - val_loss: 3091.5322\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3785.0891 - val_loss: 3054.1174\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3743.7903 - val_loss: 3017.0256\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3702.8218 - val_loss: 2980.2544\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3662.1841 - val_loss: 2943.8000\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3621.8728 - val_loss: 2907.6631\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3581.8875 - val_loss: 2871.8394\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3542.2258 - val_loss: 2836.3286\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3502.8853 - val_loss: 2801.1277\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3463.8640 - val_loss: 2766.2349\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3425.1604 - val_loss: 2731.6487\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3386.7725 - val_loss: 2697.3672\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3348.6978 - val_loss: 2663.3879\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3310.9351 - val_loss: 2629.7100\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 3273.4827 - val_loss: 2596.3301\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3236.3376 - val_loss: 2563.2483\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3199.4988 - val_loss: 2530.4607\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3162.9644 - val_loss: 2497.9673\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3126.7327 - val_loss: 2465.7656\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3090.8018 - val_loss: 2433.8538\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3055.1689 - val_loss: 2402.2297\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3019.8342 - val_loss: 2370.8931\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2984.7952 - val_loss: 2339.8403\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2950.0500 - val_loss: 2309.0710\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2915.5959 - val_loss: 2278.5835\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2881.4329 - val_loss: 2248.3752\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2847.5581 - val_loss: 2218.4446\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2813.9709 - val_loss: 2188.7910\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2780.6685 - val_loss: 2159.4121\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2747.6501 - val_loss: 2130.3062\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2714.9133 - val_loss: 2101.4717\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2682.4575 - val_loss: 2072.9075\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2650.2803 - val_loss: 2044.6111\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2618.3799 - val_loss: 2016.5815\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2586.7549 - val_loss: 1988.8165\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 2555.4041 - val_loss: 1961.3164\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2524.3264 - val_loss: 1934.0775\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2493.5200 - val_loss: 1907.0990\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2462.9822 - val_loss: 1880.3800\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2432.7117 - val_loss: 1853.9181\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2402.7085 - val_loss: 1827.7120\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2372.9692 - val_loss: 1801.7601\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2343.4937 - val_loss: 1776.0612\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2314.2788 - val_loss: 1750.6140\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2285.3252 - val_loss: 1725.4159\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2256.6304 - val_loss: 1700.4672\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2228.1926 - val_loss: 1675.7646\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2200.0100 - val_loss: 1651.3081\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2172.0828 - val_loss: 1627.0951\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2144.4075 - val_loss: 1603.1249\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2116.9839 - val_loss: 1579.3955\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2089.8101 - val_loss: 1555.9059\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2062.8853 - val_loss: 1532.6549\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2025.4327 - val_loss: 1495.3397\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1990.6581 - val_loss: 1467.5175\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1959.1445 - val_loss: 1440.9490\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1928.9082 - val_loss: 1415.3466\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1899.6290 - val_loss: 1390.4805\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1871.0928 - val_loss: 1366.2123\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1843.1688 - val_loss: 1342.4561\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1815.7749 - val_loss: 1319.1544\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1788.8561 - val_loss: 1296.2673\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1762.3711 - val_loss: 1273.7650\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1736.2899 - val_loss: 1251.6241\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1710.5885 - val_loss: 1229.8273\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1685.2487 - val_loss: 1208.3583\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1660.2545 - val_loss: 1187.2061\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1635.5931 - val_loss: 1166.3585\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1611.2538 - val_loss: 1145.8075\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1587.2262 - val_loss: 1125.5454\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1563.5029 - val_loss: 1105.5646\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1540.0756 - val_loss: 1085.8588\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1516.9379 - val_loss: 1066.4221\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1494.0842 - val_loss: 1047.2498\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1471.5087 - val_loss: 1028.3373\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1449.2062 - val_loss: 1009.6798\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1427.1726 - val_loss: 991.2732\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1405.4034 - val_loss: 973.1136\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1383.8947 - val_loss: 955.1979\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1362.6427 - val_loss: 937.5226\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1341.6442 - val_loss: 920.0842\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1320.8948 - val_loss: 902.8798\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1300.3928 - val_loss: 885.9070\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1280.1339 - val_loss: 869.1623\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1260.1163 - val_loss: 852.6440\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1240.3368 - val_loss: 836.3481\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1220.7927 - val_loss: 820.2739\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1201.4812 - val_loss: 804.4174\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1182.4003 - val_loss: 788.7773\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1163.5477 - val_loss: 773.3510\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1144.9203 - val_loss: 758.1359\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1126.5170 - val_loss: 743.1312\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1108.3352 - val_loss: 728.3334\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1090.3717 - val_loss: 713.7408\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1072.6259 - val_loss: 699.3521\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1055.0953 - val_loss: 685.1652\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1037.7781 - val_loss: 671.1777\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1020.6720 - val_loss: 657.3876\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1003.7753 - val_loss: 643.7938\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 987.0861 - val_loss: 630.3944\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 970.6026 - val_loss: 617.1869\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 954.3232 - val_loss: 604.1706\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 938.2461 - val_loss: 591.3431\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 922.3691 - val_loss: 578.7028\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 906.6913 - val_loss: 566.2481\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 891.2103 - val_loss: 553.9770\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 875.9249 - val_loss: 541.8887\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 860.8331 - val_loss: 529.9807\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 845.9335 - val_loss: 518.2520\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 831.2247 - val_loss: 506.7008\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 816.7048 - val_loss: 495.3251\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 802.3720 - val_loss: 484.1240\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 788.2252 - val_loss: 473.0957\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 774.2629 - val_loss: 462.2386\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 760.4833 - val_loss: 451.5513\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 746.8849 - val_loss: 441.0319\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 733.4664 - val_loss: 430.6797\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 720.2262 - val_loss: 420.4927\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 707.1630 - val_loss: 410.4695\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 694.2753 - val_loss: 400.6086\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 681.5613 - val_loss: 390.9085\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 669.0200 - val_loss: 381.3678\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 656.6497 - val_loss: 371.9847\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 644.4486 - val_loss: 362.7581\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 632.4160 - val_loss: 353.6872\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 620.5505 - val_loss: 344.7697\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 608.8504 - val_loss: 336.0044\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 597.3140 - val_loss: 327.3900\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 585.9402 - val_loss: 318.9245\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 574.7278 - val_loss: 310.6076\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 563.6755 - val_loss: 302.4373\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 552.7817 - val_loss: 294.4120\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 542.0452 - val_loss: 286.5311\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 531.4645 - val_loss: 278.7923\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 521.0384 - val_loss: 271.1945\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 510.7653 - val_loss: 263.7368\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 500.6440 - val_loss: 256.4171\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 490.6732 - val_loss: 249.2346\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 480.8515 - val_loss: 242.1876\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 471.1779 - val_loss: 235.2751\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 461.6509 - val_loss: 228.4958\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 452.2690 - val_loss: 221.8481\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 443.0310 - val_loss: 215.3301\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 433.9355 - val_loss: 208.9413\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 424.9815 - val_loss: 202.6805\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 416.1673 - val_loss: 196.5454\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 407.4919 - val_loss: 190.5353\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 398.9537 - val_loss: 184.6489\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 390.5518 - val_loss: 178.8846\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 382.2848 - val_loss: 173.2411\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 374.1511 - val_loss: 167.7176\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 366.1500 - val_loss: 162.3122\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 358.2798 - val_loss: 157.0238\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 350.5392 - val_loss: 151.8508\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 342.9270 - val_loss: 146.7921\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 335.4420 - val_loss: 141.8468\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 328.0830 - val_loss: 137.0132\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 320.8487 - val_loss: 132.2895\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 313.7375 - val_loss: 127.6751\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 306.7487 - val_loss: 123.1689\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 299.8810 - val_loss: 118.7688\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 293.1327 - val_loss: 114.4742\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 286.5026 - val_loss: 110.2830\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 279.9897 - val_loss: 106.1946\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 273.5926 - val_loss: 102.2078\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 267.3103 - val_loss: 98.3206\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 261.1413 - val_loss: 94.5322\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 255.0845 - val_loss: 90.8415\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 249.1388 - val_loss: 87.2472\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 243.3026 - val_loss: 83.7471\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 237.5749 - val_loss: 80.3412\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 231.9546 - val_loss: 77.0274\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 226.4400 - val_loss: 73.8047\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 221.0304 - val_loss: 70.6717\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 215.7243 - val_loss: 67.6273\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 210.5207 - val_loss: 64.6703\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 205.4180 - val_loss: 61.7991\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 200.4151 - val_loss: 59.0125\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 195.5111 - val_loss: 56.3096\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 190.7045 - val_loss: 53.6888\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 185.9942 - val_loss: 51.1489\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 181.3790 - val_loss: 48.6890\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 176.8579 - val_loss: 46.3073\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 172.4292 - val_loss: 44.0030\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 168.0920 - val_loss: 41.7745\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 163.8451 - val_loss: 39.6209\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 159.6874 - val_loss: 37.5407\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 155.6175 - val_loss: 35.5328\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 151.6342 - val_loss: 33.5960\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 147.7368 - val_loss: 31.7291\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 143.9237 - val_loss: 29.9308\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 140.1937 - val_loss: 28.2000\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 136.5457 - val_loss: 26.5353\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 132.9788 - val_loss: 24.9357\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 129.4917 - val_loss: 23.3999\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 126.0831 - val_loss: 21.9267\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 122.7519 - val_loss: 20.5149\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 119.4969 - val_loss: 19.1633\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 116.3171 - val_loss: 17.8710\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 113.2114 - val_loss: 16.6364\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 110.1785 - val_loss: 15.4586\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 107.2173 - val_loss: 14.3364\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 104.3269 - val_loss: 13.2686\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 101.5059 - val_loss: 12.2540\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 98.7533 - val_loss: 11.2916\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 96.0679 - val_loss: 10.3802\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 93.4488 - val_loss: 9.5186\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 90.8947 - val_loss: 8.7058\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 88.4048 - val_loss: 7.9406\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 85.9777 - val_loss: 7.2219\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 83.6123 - val_loss: 6.5486\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 81.3079 - val_loss: 5.9197\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 79.0632 - val_loss: 5.3340\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 76.8771 - val_loss: 4.7905\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 74.7485 - val_loss: 4.2880\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 72.6766 - val_loss: 3.8256\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 70.6602 - val_loss: 3.4021\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 68.6983 - val_loss: 3.0166\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 66.7899 - val_loss: 2.6680\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 64.9340 - val_loss: 2.3553\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 63.1295 - val_loss: 2.0774\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 61.3754 - val_loss: 1.8334\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 59.6708 - val_loss: 1.6222\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 58.0146 - val_loss: 1.4429\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 56.4060 - val_loss: 1.2945\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 54.8438 - val_loss: 1.1759\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 53.3271 - val_loss: 1.0864\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 51.8551 - val_loss: 1.0249\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 50.4266 - val_loss: 0.9904\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 49.0411 - val_loss: 0.9822\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 47.6973 - val_loss: 0.9991\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 46.3945 - val_loss: 1.0404\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 45.1316 - val_loss: 1.1052\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 43.9078 - val_loss: 1.1926\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 42.7222 - val_loss: 1.3016\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 41.5739 - val_loss: 1.4315\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 40.4623 - val_loss: 1.5815\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 39.3861 - val_loss: 1.7506\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 38.3447 - val_loss: 1.9381\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 37.3372 - val_loss: 2.1432\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 36.3628 - val_loss: 2.3651\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 35.4208 - val_loss: 2.6029\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 34.5102 - val_loss: 2.8560\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.6303 - val_loss: 3.1235\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 32.7805 - val_loss: 3.4049\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.9596 - val_loss: 3.6992\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.1672 - val_loss: 4.0058\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.4024 - val_loss: 4.3241\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.6645 - val_loss: 4.6532\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 28.9528 - val_loss: 4.9927\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.2666 - val_loss: 5.3417\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 27.6051 - val_loss: 5.6998\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 26.9676 - val_loss: 6.0661\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.3535 - val_loss: 6.4401\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 25.7621 - val_loss: 6.8212\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.1929 - val_loss: 7.2089\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.6449 - val_loss: 7.6026\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.1178 - val_loss: 8.0017\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.6108 - val_loss: 8.4056\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23.1234 - val_loss: 8.8138\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.6549 - val_loss: 9.2259\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.2048 - val_loss: 9.6413\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.7724 - val_loss: 10.0595\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.3573 - val_loss: 10.4801\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9588 - val_loss: 10.9026\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.5764 - val_loss: 11.3266\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.2096 - val_loss: 11.7517\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.8579 - val_loss: 12.1774\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 19.5208 - val_loss: 12.6033\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.1977 - val_loss: 13.0291\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.8882 - val_loss: 13.4542\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.5919 - val_loss: 13.8786\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.3083 - val_loss: 14.3018\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.0368 - val_loss: 14.7232\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.7772 - val_loss: 15.1430\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.5288 - val_loss: 15.5606\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2914 - val_loss: 15.9756\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.0646 - val_loss: 16.3879\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8478 - val_loss: 16.7973\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.6409 - val_loss: 17.2033\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.4433 - val_loss: 17.6059\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2547 - val_loss: 18.0047\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.0749 - val_loss: 18.3997\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.9034 - val_loss: 18.7903\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 15.7398 - val_loss: 19.1767\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.5841 - val_loss: 19.5585\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.4356 - val_loss: 19.9358\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.2942 - val_loss: 20.3081\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.1596 - val_loss: 20.6756\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.0314 - val_loss: 21.0379\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.9095 - val_loss: 21.3949\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.7936 - val_loss: 21.7467\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.6833 - val_loss: 22.0928\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5786 - val_loss: 22.4335\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 14.4790 - val_loss: 22.7685\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.3845 - val_loss: 23.0978\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.2947 - val_loss: 23.4211\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.2094 - val_loss: 23.7387\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.1286 - val_loss: 24.0505\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.0518 - val_loss: 24.3562\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.9791 - val_loss: 24.6559\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.9101 - val_loss: 24.9498\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.8446 - val_loss: 25.2376\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7827 - val_loss: 25.5194\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 13.7239 - val_loss: 25.7953\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6683 - val_loss: 26.0651\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6156 - val_loss: 26.3286\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.5658 - val_loss: 26.5865\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.5186 - val_loss: 26.8383\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.4739 - val_loss: 27.0839\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.4318 - val_loss: 27.3237\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3919 - val_loss: 27.5576\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3541 - val_loss: 27.7858\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3184 - val_loss: 28.0081\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.2847 - val_loss: 28.2247\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.2529 - val_loss: 28.4356\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 13.2228 - val_loss: 28.6409\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 13.1944 - val_loss: 28.8406\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1675 - val_loss: 29.0348\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1422 - val_loss: 29.2235\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1182 - val_loss: 29.4069\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0957 - val_loss: 29.5847\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0744 - val_loss: 29.7578\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0543 - val_loss: 29.9255\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0353 - val_loss: 30.0885\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0174 - val_loss: 30.2462\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0006 - val_loss: 30.3990\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9847 - val_loss: 30.5470\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9697 - val_loss: 30.6904\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9555 - val_loss: 30.8292\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9422 - val_loss: 30.9636\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9296 - val_loss: 31.0933\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9178 - val_loss: 31.2192\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.9066 - val_loss: 31.3404\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8961 - val_loss: 31.4576\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8862 - val_loss: 31.5707\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8768 - val_loss: 31.6799\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8680 - val_loss: 31.7850\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.8597 - val_loss: 31.8865\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.8520 - val_loss: 31.9845\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8446 - val_loss: 32.0786\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8376 - val_loss: 32.1694\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8311 - val_loss: 32.2568\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8250 - val_loss: 32.3409\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8192 - val_loss: 32.4217\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8137 - val_loss: 32.4992\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.8086 - val_loss: 32.5738\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.8038 - val_loss: 32.6456\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.7992 - val_loss: 32.7145\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7950 - val_loss: 32.7808\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7909 - val_loss: 32.8440\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7871 - val_loss: 32.9048\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7836 - val_loss: 32.9632\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.7802 - val_loss: 33.0189\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7771 - val_loss: 33.0724\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7741 - val_loss: 33.1236\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7713 - val_loss: 33.1726\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7688 - val_loss: 33.2196\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7663 - val_loss: 33.2644\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7639 - val_loss: 33.3071\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.7618 - val_loss: 33.3478\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.7598 - val_loss: 33.3870\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7579 - val_loss: 33.4242\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7561 - val_loss: 33.4598\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.7544 - val_loss: 33.4935\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7529 - val_loss: 33.5260\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7514 - val_loss: 33.5567\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7500 - val_loss: 33.5859\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7487 - val_loss: 33.6139\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7476 - val_loss: 33.6404\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7465 - val_loss: 33.6657\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7454 - val_loss: 33.6898\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7444 - val_loss: 33.7126\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.7435 - val_loss: 33.7341\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7427 - val_loss: 33.7546\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7420 - val_loss: 33.7741\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7413 - val_loss: 33.7927\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7406 - val_loss: 33.8102\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7400 - val_loss: 33.8268\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7394 - val_loss: 33.8424\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.7390 - val_loss: 33.8574\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.7385 - val_loss: 33.8713\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7381 - val_loss: 33.8847\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7377 - val_loss: 33.8970\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.7374 - val_loss: 33.9090\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7370 - val_loss: 33.9202\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7368 - val_loss: 33.9308\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7365 - val_loss: 33.9407\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7363 - val_loss: 33.9501\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7361 - val_loss: 33.9587\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7360 - val_loss: 33.9670\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7358 - val_loss: 33.9748\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7358 - val_loss: 33.9819\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7357 - val_loss: 33.9890\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7356 - val_loss: 33.9956\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7356 - val_loss: 34.0016\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.7355 - val_loss: 34.0071\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7356 - val_loss: 34.0126\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7356 - val_loss: 34.0174\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7356 - val_loss: 34.0221\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7356 - val_loss: 34.0264\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7357 - val_loss: 34.0305\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.7357 - val_loss: 34.0343\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7358 - val_loss: 34.0378\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7360 - val_loss: 34.0411\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7360 - val_loss: 34.0441\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7361 - val_loss: 34.0468\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.7363 - val_loss: 34.0494\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 12.7364 - val_loss: 34.0517\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.7366 - val_loss: 34.0541\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7367 - val_loss: 34.0562\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7369 - val_loss: 34.0581\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7370 - val_loss: 34.0598\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7372 - val_loss: 34.0614\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7375 - val_loss: 34.0629\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7376 - val_loss: 34.0643\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7378 - val_loss: 34.0656\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7380 - val_loss: 34.0664\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7382 - val_loss: 34.0675\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.7384 - val_loss: 34.0683\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7386 - val_loss: 34.0691\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7388 - val_loss: 34.0697\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 12.7390 - val_loss: 34.0704\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.7393 - val_loss: 34.0710\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7395 - val_loss: 34.0715\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7397 - val_loss: 34.0719\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7399 - val_loss: 34.0722\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7402 - val_loss: 34.0725\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.7404 - val_loss: 34.0729\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7406 - val_loss: 34.0731\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7408 - val_loss: 34.0732\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7411 - val_loss: 34.0733\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7413 - val_loss: 34.0733\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7415 - val_loss: 34.0733\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7418 - val_loss: 34.0733\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.7420 - val_loss: 34.0731\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7423 - val_loss: 34.0729\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7425 - val_loss: 34.0728\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7428 - val_loss: 34.0728\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7430 - val_loss: 34.0726\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7432 - val_loss: 34.0724\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7435 - val_loss: 34.0723\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7437 - val_loss: 34.0722\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7439 - val_loss: 34.0720\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7441 - val_loss: 34.0716\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7444 - val_loss: 34.0716\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7446 - val_loss: 34.0712\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7449 - val_loss: 34.0710\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7451 - val_loss: 34.0707\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7453 - val_loss: 34.0704\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.7456 - val_loss: 34.0702\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7458 - val_loss: 34.0698\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7460 - val_loss: 34.0695\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7463 - val_loss: 34.0692\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7465 - val_loss: 34.0689\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7467 - val_loss: 34.0685\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7469 - val_loss: 34.0681\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7472 - val_loss: 34.0678\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7474 - val_loss: 34.0674\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7476 - val_loss: 34.0672\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7478 - val_loss: 34.0667\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7480 - val_loss: 34.0664\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7482 - val_loss: 34.0662\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.7484 - val_loss: 34.0658\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7486 - val_loss: 34.0654\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7489 - val_loss: 34.0650\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 12.7491 - val_loss: 34.0647\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 337ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70.00273109, 69.99432773, 69.98592437, 69.97752101, 69.96911765,\n",
       "        69.96071429, 69.95231092, 69.94390756, 69.9355042 , 69.92710084,\n",
       "        69.91869748, 69.91029412, 69.90189076, 69.89348739, 69.88508403,\n",
       "        69.87668067, 69.86827731, 69.85987395, 69.85147059, 69.84306723,\n",
       "        69.83466387, 69.8262605 , 69.81785714, 69.80945378, 69.80105042,\n",
       "        69.75098039, 69.69495798, 69.63893557, 69.58291317, 69.52689076,\n",
       "        69.47086835, 69.41484594, 69.35882353, 69.30280112, 69.24677871,\n",
       "        69.1907563 , 69.13473389, 69.07871148, 69.02268908, 68.96666667,\n",
       "        68.91064426, 68.85462185, 68.79859944, 68.74257703, 68.68655462,\n",
       "        68.63053221, 68.5745098 , 68.51848739, 68.46246499, 68.40644258,\n",
       "        68.35042017, 68.29439776, 68.23837535, 68.18235294, 68.12633053,\n",
       "        68.07030812, 68.01428571, 67.95826331, 67.9022409 , 67.84621849,\n",
       "        67.7947549 , 67.76478291, 67.73481092, 67.70483894, 67.67486695,\n",
       "        67.64489496, 67.61492297, 67.58495098, 67.55497899, 67.525007  ,\n",
       "        67.49503501, 67.46506303, 67.43509104, 67.40511905, 67.37514706,\n",
       "        67.34517507, 67.31520308, 67.28523109, 67.2552591 , 67.22528711,\n",
       "        74.65536499,  0.39063737,  0.        ,  0.37065786,  0.        ,\n",
       "         0.50724107,  0.59316951,  0.73384774,  0.        ,  0.58368158,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.74694359,  0.        ,  0.2152479 ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65.21911765, 65.21071429, 65.20231092, 65.19390756, 65.1855042 ,\n",
       "       65.17710084, 65.16869748, 65.16029412, 65.15189076, 65.14348739,\n",
       "       65.13508403, 65.12668067, 65.11827731, 65.10987395, 65.10147059,\n",
       "       65.09306723, 65.08466387, 65.0762605 , 65.06785714, 65.05945378,\n",
       "       65.05105042, 65.04264706, 65.0342437 , 65.02584034, 65.01743697,\n",
       "       65.00903361, 65.00063025, 64.99222689, 64.98382353, 64.97542017,\n",
       "       64.96701681, 64.95861345, 64.95021008, 64.94180672, 64.93340336,\n",
       "       64.925     , 64.91659664, 64.90819328, 64.89978992, 64.89138655,\n",
       "       64.88298319, 64.87457983, 64.86617647, 64.85777311, 64.84936975,\n",
       "       64.84096639, 64.83256303, 64.82415966, 64.8157563 , 64.80735294,\n",
       "       64.79894958, 64.79054622, 64.78214286, 64.7737395 , 64.76533613,\n",
       "       64.75693277, 64.74852941, 64.74012605, 64.73172269, 64.72331933,\n",
       "       64.71491597, 64.70651261, 64.69810924, 64.68970588, 64.68130252,\n",
       "       64.67289916, 64.6644958 , 64.65609244, 64.64768908, 64.63928571,\n",
       "       64.63088235, 64.62247899, 64.61407563, 64.60567227, 64.59726891,\n",
       "       64.58886555, 64.58046218, 64.57205882, 64.56365546, 64.5552521 ,\n",
       "       64.54684874, 64.53844538, 64.53004202, 64.52163866, 64.51323529,\n",
       "       64.50483193, 64.49642857, 64.48802521, 64.47962185, 64.47121849,\n",
       "       64.46281513, 64.45441176, 64.4460084 , 64.43760504, 64.42920168,\n",
       "       64.42079832, 64.41239496, 64.4039916 , 64.39558824, 64.38718487])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.250878843872677\n",
      "15.454844565673671\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
