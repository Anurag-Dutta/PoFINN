{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "2045    61.268079\n",
       "2046    61.248004\n",
       "2047    61.227930\n",
       "2048    61.207855\n",
       "2049    61.187780\n",
       "Name: C4, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_1950_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "1945     0.000000\n",
       "1946     0.000000\n",
       "1947     0.280281\n",
       "1948     0.040247\n",
       "1949     0.000000\n",
       "Name: C4, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1950)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.409524</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.219048</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.028571</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.838095</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.600000  0.000298\n",
       "1     88.409524  0.000298\n",
       "2     88.219048  0.000297\n",
       "3     88.028571  0.000297\n",
       "4     87.838095  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.600000    88.409524    88.219048    88.028571    87.838095   \n",
      "351    88.409524    88.219048    88.028571    87.838095    87.647619   \n",
      "352    88.219048    88.028571    87.838095    87.647619    87.457143   \n",
      "353    88.028571    87.838095    87.647619    87.457143    87.266667   \n",
      "354    87.838095    87.647619    87.457143    87.266667    87.076190   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.647619    87.457143    87.266667    87.076190    86.896218  ...   \n",
      "351    87.457143    87.266667    87.076190    86.896218    86.845798  ...   \n",
      "352    87.266667    87.076190    86.896218    86.845798    86.795378  ...   \n",
      "353    87.076190    86.896218    86.845798    86.795378    86.744958  ...   \n",
      "354    86.896218    86.845798    86.795378    86.744958    86.694538  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   78.880345    0.000263   78.856069    0.000263   78.831793    0.000263   \n",
      "351   78.856069    0.000263   78.831793    0.000263   78.807516    0.000262   \n",
      "352   78.831793    0.000263   78.807516    0.000262   78.783240    0.000262   \n",
      "353   78.807516    0.000262   78.783240    0.000262   78.758964    0.000262   \n",
      "354   78.783240    0.000262   78.758964    0.000262   78.734687    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   78.807516    0.000262   78.783240    0.000262  \n",
      "351   78.783240    0.000262   78.758964    0.000262  \n",
      "352   78.758964    0.000262   78.734687    0.000262  \n",
      "353   78.734687    0.000262   78.710411    0.000262  \n",
      "354   78.710411    0.000262   78.686134    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1, 251) (1500, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 2s 25ms/step - loss: 5384.3320 - val_loss: 4291.1489\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5304.3677 - val_loss: 4228.8433\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5235.0347 - val_loss: 4153.7690\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5150.4800 - val_loss: 4089.8672\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5079.2812 - val_loss: 4026.5259\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5009.0107 - val_loss: 3964.1541\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4939.7139 - val_loss: 3902.6484\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4871.2871 - val_loss: 3841.9329\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4803.6646 - val_loss: 3781.9653\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4736.8096 - val_loss: 3722.7188\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4670.6943 - val_loss: 3664.1733\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4605.3027 - val_loss: 3606.3154\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4540.6201 - val_loss: 3549.1333\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4476.6357 - val_loss: 3492.6179\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4413.3398 - val_loss: 3436.7605\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4350.7251 - val_loss: 3381.5532\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4288.7822 - val_loss: 3326.9895\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4227.5049 - val_loss: 3273.0630\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4166.8867 - val_loss: 3219.7666\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4106.9224 - val_loss: 3167.0952\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4047.6030 - val_loss: 3115.0425\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3988.9255 - val_loss: 3054.8657\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3918.3828 - val_loss: 2998.6387\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3854.7083 - val_loss: 2943.3735\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3792.7292 - val_loss: 2889.7217\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3732.3291 - val_loss: 2837.3347\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3673.1780 - val_loss: 2785.9932\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3615.0818 - val_loss: 2732.8730\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3552.1174 - val_loss: 2677.6284\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3489.2239 - val_loss: 2623.5608\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3428.2842 - val_loss: 2571.3125\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3369.1404 - val_loss: 2520.4929\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3311.4182 - val_loss: 2470.8516\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3254.8928 - val_loss: 2422.2407\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3199.4250 - val_loss: 2374.5627\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3144.9233 - val_loss: 2327.7507\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3091.3220 - val_loss: 2281.7549\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3038.5710 - val_loss: 2236.5383\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2986.6318 - val_loss: 2192.0671\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2935.4729 - val_loss: 2148.3176\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2885.0684 - val_loss: 2105.2668\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2835.3943 - val_loss: 2062.8965\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2786.4326 - val_loss: 2021.1907\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2738.0281 - val_loss: 1978.4358\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2685.5442 - val_loss: 1932.0962\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2631.9563 - val_loss: 1887.2240\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2580.3286 - val_loss: 1844.0359\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2530.3792 - val_loss: 1802.1592\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2481.7522 - val_loss: 1761.3650\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2434.2380 - val_loss: 1721.5181\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2387.7097 - val_loss: 1682.5320\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2342.0818 - val_loss: 1644.3451\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2297.2939 - val_loss: 1606.9124\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2253.3005 - val_loss: 1570.2001\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2210.0654 - val_loss: 1534.1769\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2167.5588 - val_loss: 1498.8220\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2125.7576 - val_loss: 1464.1135\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2084.6389 - val_loss: 1430.0339\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2044.1848 - val_loss: 1396.5676\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2004.3794 - val_loss: 1363.7007\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1965.2079 - val_loss: 1331.4199\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1926.6560 - val_loss: 1299.7131\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1888.7125 - val_loss: 1268.5714\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1851.3658 - val_loss: 1237.9823\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1814.6047 - val_loss: 1207.9376\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1778.4208 - val_loss: 1178.4290\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1742.8036 - val_loss: 1149.4464\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1707.7449 - val_loss: 1120.9833\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1673.2363 - val_loss: 1093.0306\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1639.2697 - val_loss: 1065.5809\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1605.8363 - val_loss: 1038.6276\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1572.9303 - val_loss: 1012.1630\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1540.5436 - val_loss: 986.1816\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1508.6698 - val_loss: 960.6761\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1477.3021 - val_loss: 935.6401\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1446.4346 - val_loss: 911.0682\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1416.0604 - val_loss: 886.9536\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1386.1737 - val_loss: 863.2907\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1356.7683 - val_loss: 840.0731\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1327.8370 - val_loss: 817.2958\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1299.3765 - val_loss: 794.9525\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1271.3793 - val_loss: 773.0390\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1243.8403 - val_loss: 751.5483\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1216.7545 - val_loss: 730.4767\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1190.1169 - val_loss: 709.8185\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1163.9218 - val_loss: 689.5685\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1138.1639 - val_loss: 669.7214\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1112.8383 - val_loss: 650.2718\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1087.9397 - val_loss: 631.2161\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1063.4642 - val_loss: 612.5485\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1039.4056 - val_loss: 594.2640\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1015.7596 - val_loss: 576.3582\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 992.5217 - val_loss: 558.8266\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 969.6870 - val_loss: 541.6640\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 947.2509 - val_loss: 524.8663\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 925.2084 - val_loss: 508.4283\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 903.5554 - val_loss: 492.3463\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 882.2874 - val_loss: 476.6155\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 861.3998 - val_loss: 461.2303\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 840.8876 - val_loss: 446.1876\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 820.7473 - val_loss: 431.4826\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 800.9744 - val_loss: 417.1111\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 781.5641 - val_loss: 403.0681\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 762.5123 - val_loss: 389.3500\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 743.8148 - val_loss: 375.9523\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 725.4672 - val_loss: 362.8705\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 707.4651 - val_loss: 350.1003\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 689.8051 - val_loss: 337.6382\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 672.4822 - val_loss: 325.4790\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 655.4930 - val_loss: 313.6195\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 638.8330 - val_loss: 302.0552\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 622.4978 - val_loss: 290.7816\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 606.4841 - val_loss: 279.7949\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 590.7874 - val_loss: 269.0910\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 575.4038 - val_loss: 258.6661\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 560.3297 - val_loss: 248.5160\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 545.5605 - val_loss: 238.6370\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 531.0928 - val_loss: 229.0246\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 516.9225 - val_loss: 219.6752\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 503.0459 - val_loss: 210.5845\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 489.4590 - val_loss: 201.7485\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 476.1574 - val_loss: 193.1639\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 463.1380 - val_loss: 184.8262\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 450.3969 - val_loss: 176.7320\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 437.9299 - val_loss: 168.8772\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 425.7336 - val_loss: 161.2579\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 413.8041 - val_loss: 153.8704\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 402.1378 - val_loss: 146.7108\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 390.7310 - val_loss: 139.7755\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 379.5799 - val_loss: 133.0609\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 368.6810 - val_loss: 126.5626\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 358.0303 - val_loss: 120.2774\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 347.6244 - val_loss: 114.2011\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 337.4598 - val_loss: 108.3307\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 327.5326 - val_loss: 102.6619\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 317.8393 - val_loss: 97.1915\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 308.3763 - val_loss: 91.9156\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 299.1404 - val_loss: 86.8306\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 290.1277 - val_loss: 81.9329\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 281.3348 - val_loss: 77.2190\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 272.7583 - val_loss: 72.6853\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 264.3943 - val_loss: 68.3281\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 256.2397 - val_loss: 64.1441\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 248.2912 - val_loss: 60.1294\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 240.5453 - val_loss: 56.2812\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 232.9983 - val_loss: 52.5956\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 225.6471 - val_loss: 49.0690\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 218.4881 - val_loss: 45.6984\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 211.5186 - val_loss: 42.4801\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 204.7347 - val_loss: 39.4109\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 198.1332 - val_loss: 36.4872\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.7108 - val_loss: 33.7059\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 185.4643 - val_loss: 31.0635\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 179.3905 - val_loss: 28.5569\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 173.4859 - val_loss: 26.1828\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 167.7479 - val_loss: 23.9376\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 162.1727 - val_loss: 21.8186\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 156.7577 - val_loss: 19.8225\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 151.4994 - val_loss: 17.9459\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 146.3947 - val_loss: 16.1858\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 141.4407 - val_loss: 14.5390\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 136.6342 - val_loss: 13.0025\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 131.9722 - val_loss: 11.5732\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 127.4517 - val_loss: 10.2483\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 123.0698 - val_loss: 9.0245\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 118.8232 - val_loss: 7.8989\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 114.7096 - val_loss: 6.8687\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 110.7259 - val_loss: 5.9309\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 106.8689 - val_loss: 5.0825\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 103.1359 - val_loss: 4.3209\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 99.5244 - val_loss: 3.6432\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 96.0312 - val_loss: 3.0465\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 92.6535 - val_loss: 2.5282\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 89.3889 - val_loss: 2.0855\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 86.2345 - val_loss: 1.7159\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 83.1879 - val_loss: 1.4165\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 80.2461 - val_loss: 1.1849\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 77.4065 - val_loss: 1.0184\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 74.6668 - val_loss: 0.9146\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 72.0244 - val_loss: 0.8709\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 69.4766 - val_loss: 0.8849\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 67.0211 - val_loss: 0.9541\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 64.6552 - val_loss: 1.0762\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 62.3765 - val_loss: 1.2489\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 60.1828 - val_loss: 1.4699\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 58.0719 - val_loss: 1.7368\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 56.0413 - val_loss: 2.0475\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 54.0886 - val_loss: 2.3999\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 52.2118 - val_loss: 2.7917\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 50.4086 - val_loss: 3.2209\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 48.6766 - val_loss: 3.6854\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.0139 - val_loss: 4.1833\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 45.4185 - val_loss: 4.7125\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 43.8880 - val_loss: 5.2712\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 42.4208 - val_loss: 5.8574\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 41.0148 - val_loss: 6.4693\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 39.6677 - val_loss: 7.1053\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 38.3779 - val_loss: 7.7634\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 37.1433 - val_loss: 8.4422\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 35.9622 - val_loss: 9.1397\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 34.8329 - val_loss: 9.8544\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.7536 - val_loss: 10.5849\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 32.7225 - val_loss: 11.3296\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.7378 - val_loss: 12.0869\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 30.7980 - val_loss: 12.8555\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.9015 - val_loss: 13.6339\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0467 - val_loss: 14.4209\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 28.2319 - val_loss: 15.2150\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 27.4558 - val_loss: 16.0153\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 26.7168 - val_loss: 16.8204\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 26.0136 - val_loss: 17.6291\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 25.3446 - val_loss: 18.4404\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 24.7086 - val_loss: 19.2528\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 24.1045 - val_loss: 20.0659\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 23.5306 - val_loss: 20.8783\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 22.9858 - val_loss: 21.6893\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.4690 - val_loss: 22.4979\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.9788 - val_loss: 23.3031\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.5144 - val_loss: 24.1041\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.0746 - val_loss: 24.9002\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.6581 - val_loss: 25.6907\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20.2641 - val_loss: 26.4747\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.8915 - val_loss: 27.2518\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.5393 - val_loss: 28.0212\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.2066 - val_loss: 28.7825\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.8925 - val_loss: 29.5349\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.5961 - val_loss: 30.2781\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.3166 - val_loss: 31.0114\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 18.0531 - val_loss: 31.7347\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.8049 - val_loss: 32.4471\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.5713 - val_loss: 33.1488\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.3514 - val_loss: 33.8388\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.1447 - val_loss: 34.5173\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.9503 - val_loss: 35.1836\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.7679 - val_loss: 35.8378\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.5965 - val_loss: 36.4797\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.4358 - val_loss: 37.1089\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 16.2850 - val_loss: 37.7253\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.1437 - val_loss: 38.3288\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 16.0113 - val_loss: 38.9189\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.8875 - val_loss: 39.4961\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.7716 - val_loss: 40.0598\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.6632 - val_loss: 40.6105\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.5620 - val_loss: 41.1476\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.4674 - val_loss: 41.6717\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.3791 - val_loss: 42.1822\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2967 - val_loss: 42.6796\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2198 - val_loss: 43.1635\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 15.1483 - val_loss: 43.6340\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.0817 - val_loss: 44.0919\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.0196 - val_loss: 44.5365\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.9619 - val_loss: 44.9682\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.9082 - val_loss: 45.3874\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.8583 - val_loss: 45.7936\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.8120 - val_loss: 46.1874\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.7689 - val_loss: 46.5689\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.7290 - val_loss: 46.9383\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6920 - val_loss: 47.2958\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6577 - val_loss: 47.6415\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6259 - val_loss: 47.9753\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5964 - val_loss: 48.2980\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5692 - val_loss: 48.6096\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5440 - val_loss: 48.9100\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.5206 - val_loss: 49.1998\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.4991 - val_loss: 49.4791\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.4792 - val_loss: 49.7481\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.4608 - val_loss: 50.0070\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.4438 - val_loss: 50.2562\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.4281 - val_loss: 50.4955\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.4137 - val_loss: 50.7254\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.4003 - val_loss: 50.9462\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3881 - val_loss: 51.1579\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3768 - val_loss: 51.3613\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3664 - val_loss: 51.5562\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3568 - val_loss: 51.7431\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3480 - val_loss: 51.9218\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3399 - val_loss: 52.0929\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3325 - val_loss: 52.2569\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3256 - val_loss: 52.4135\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3193 - val_loss: 52.5630\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 14.3135 - val_loss: 52.7058\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3083 - val_loss: 52.8420\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3034 - val_loss: 52.9720\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2989 - val_loss: 53.0958\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2949 - val_loss: 53.2139\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2911 - val_loss: 53.3262\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2877 - val_loss: 53.4333\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2846 - val_loss: 53.5348\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2817 - val_loss: 53.6317\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2791 - val_loss: 53.7236\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2767 - val_loss: 53.8104\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2745 - val_loss: 53.8930\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2726 - val_loss: 53.9714\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2708 - val_loss: 54.0456\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.2692 - val_loss: 54.1159\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2677 - val_loss: 54.1825\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2664 - val_loss: 54.2455\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2652 - val_loss: 54.3051\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2641 - val_loss: 54.3614\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2632 - val_loss: 54.4144\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2623 - val_loss: 54.4645\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2615 - val_loss: 54.5114\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2608 - val_loss: 54.5555\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2603 - val_loss: 54.5975\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2597 - val_loss: 54.6365\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2593 - val_loss: 54.6733\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2589 - val_loss: 54.7079\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2586 - val_loss: 54.7403\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2584 - val_loss: 54.7709\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2582 - val_loss: 54.7996\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2580 - val_loss: 54.8264\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2579 - val_loss: 54.8513\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2578 - val_loss: 54.8748\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2578 - val_loss: 54.8965\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2578 - val_loss: 54.9169\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.2578 - val_loss: 54.9359\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 14.2579 - val_loss: 54.9538\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2581 - val_loss: 54.9706\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2582 - val_loss: 54.9858\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2583 - val_loss: 55.0001\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2585 - val_loss: 55.0130\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2587 - val_loss: 55.0252\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2589 - val_loss: 55.0366\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2592 - val_loss: 55.0468\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2594 - val_loss: 55.0562\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2597 - val_loss: 55.0653\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2601 - val_loss: 55.0737\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2604 - val_loss: 55.0814\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2607 - val_loss: 55.0884\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2610 - val_loss: 55.0948\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2614 - val_loss: 55.1006\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2617 - val_loss: 55.1060\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 14.2621 - val_loss: 55.1107\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2625 - val_loss: 55.1149\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.2629 - val_loss: 55.1186\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2633 - val_loss: 55.1223\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2637 - val_loss: 55.1253\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2641 - val_loss: 55.1283\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2645 - val_loss: 55.1308\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2650 - val_loss: 55.1332\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2654 - val_loss: 55.1351\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2658 - val_loss: 55.1368\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2663 - val_loss: 55.1383\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2667 - val_loss: 55.1397\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2672 - val_loss: 55.1406\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2676 - val_loss: 55.1414\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2681 - val_loss: 55.1422\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2686 - val_loss: 55.1427\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2690 - val_loss: 55.1432\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.2695 - val_loss: 55.1433\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2700 - val_loss: 55.1433\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 14.2705 - val_loss: 55.1434\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2709 - val_loss: 55.1434\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2714 - val_loss: 55.1434\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2718 - val_loss: 55.1432\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.2723 - val_loss: 55.1430\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2728 - val_loss: 55.1424\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2733 - val_loss: 55.1420\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2738 - val_loss: 55.1414\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.2743 - val_loss: 55.1409\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2747 - val_loss: 55.1404\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2752 - val_loss: 55.1398\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2756 - val_loss: 55.1387\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.2761 - val_loss: 55.1377\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2766 - val_loss: 55.1369\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 14.2771 - val_loss: 55.1360\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2776 - val_loss: 55.1350\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2780 - val_loss: 55.1341\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2786 - val_loss: 55.1332\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.2790 - val_loss: 55.1324\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2795 - val_loss: 55.1313\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2799 - val_loss: 55.1305\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2804 - val_loss: 55.1294\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2809 - val_loss: 55.1284\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2814 - val_loss: 55.1278\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2818 - val_loss: 55.1266\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2822 - val_loss: 55.1257\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2826 - val_loss: 55.1243\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2831 - val_loss: 55.1235\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2836 - val_loss: 55.1222\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2840 - val_loss: 55.1211\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2845 - val_loss: 55.1201\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2849 - val_loss: 55.1188\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2854 - val_loss: 55.1180\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2858 - val_loss: 55.1170\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2863 - val_loss: 55.1160\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2867 - val_loss: 55.1150\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2871 - val_loss: 55.1139\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2876 - val_loss: 55.1129\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2880 - val_loss: 55.1120\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2884 - val_loss: 55.1112\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2888 - val_loss: 55.1099\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2892 - val_loss: 55.1090\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 14.2896 - val_loss: 55.1079\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2901 - val_loss: 55.1069\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2905 - val_loss: 55.1061\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2908 - val_loss: 55.1049\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2913 - val_loss: 55.1041\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2917 - val_loss: 55.1030\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2921 - val_loss: 55.1022\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2925 - val_loss: 55.1011\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2928 - val_loss: 55.1001\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2933 - val_loss: 55.0993\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2936 - val_loss: 55.0985\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.2940 - val_loss: 55.0974\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2944 - val_loss: 55.0965\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2947 - val_loss: 55.0957\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.2951 - val_loss: 55.0947\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2955 - val_loss: 55.0938\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2958 - val_loss: 55.0930\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2962 - val_loss: 55.0921\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2965 - val_loss: 55.0910\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2969 - val_loss: 55.0902\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2973 - val_loss: 55.0894\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2976 - val_loss: 55.0885\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2980 - val_loss: 55.0876\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2983 - val_loss: 55.0869\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2986 - val_loss: 55.0862\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2989 - val_loss: 55.0856\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 14.2993 - val_loss: 55.0847\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2996 - val_loss: 55.0841\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.2999 - val_loss: 55.0833\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3002 - val_loss: 55.0824\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3005 - val_loss: 55.0815\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3008 - val_loss: 55.0808\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3011 - val_loss: 55.0802\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3015 - val_loss: 55.0795\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3017 - val_loss: 55.0787\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3021 - val_loss: 55.0778\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3023 - val_loss: 55.0771\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.3026 - val_loss: 55.0765\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3030 - val_loss: 55.0758\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3032 - val_loss: 55.0749\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3035 - val_loss: 55.0743\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3038 - val_loss: 55.0737\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3040 - val_loss: 55.0730\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3043 - val_loss: 55.0722\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3046 - val_loss: 55.0714\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3049 - val_loss: 55.0707\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3051 - val_loss: 55.0704\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3053 - val_loss: 55.0698\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 14.3056 - val_loss: 55.0692\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3058 - val_loss: 55.0685\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3061 - val_loss: 55.0679\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3063 - val_loss: 55.0670\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3066 - val_loss: 55.0665\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3068 - val_loss: 55.0658\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3070 - val_loss: 55.0652\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3073 - val_loss: 55.0646\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3075 - val_loss: 55.0640\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3078 - val_loss: 55.0638\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3080 - val_loss: 55.0632\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3082 - val_loss: 55.0626\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.3084 - val_loss: 55.0623\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3086 - val_loss: 55.0616\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3088 - val_loss: 55.0610\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3090 - val_loss: 55.0605\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3092 - val_loss: 55.0601\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3095 - val_loss: 55.0597\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3096 - val_loss: 55.0592\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3098 - val_loss: 55.0587\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3100 - val_loss: 55.0578\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3102 - val_loss: 55.0575\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3104 - val_loss: 55.0571\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 14.3106 - val_loss: 55.0568\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3108 - val_loss: 55.0564\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3110 - val_loss: 55.0560\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3111 - val_loss: 55.0556\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3113 - val_loss: 55.0551\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3115 - val_loss: 55.0547\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3116 - val_loss: 55.0543\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3118 - val_loss: 55.0539\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3120 - val_loss: 55.0532\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3121 - val_loss: 55.0529\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 14.3123 - val_loss: 55.0524\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3124 - val_loss: 55.0521\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3126 - val_loss: 55.0516\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3127 - val_loss: 55.0512\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3129 - val_loss: 55.0508\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3130 - val_loss: 55.0506\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3132 - val_loss: 55.0504\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3133 - val_loss: 55.0501\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3134 - val_loss: 55.0497\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3136 - val_loss: 55.0493\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3137 - val_loss: 55.0490\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.3138 - val_loss: 55.0485\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3140 - val_loss: 55.0483\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3141 - val_loss: 55.0479\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3142 - val_loss: 55.0474\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3144 - val_loss: 55.0473\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3145 - val_loss: 55.0467\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3146 - val_loss: 55.0464\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3147 - val_loss: 55.0458\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3149 - val_loss: 55.0457\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3150 - val_loss: 55.0455\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3151 - val_loss: 55.0452\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3152 - val_loss: 55.0450\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.3153 - val_loss: 55.0449\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3154 - val_loss: 55.0447\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.3155 - val_loss: 55.0444\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 361ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.75949416e+01, 6.75649696e+01, 6.75349977e+01, 6.75050257e+01,\n",
       "        6.74750537e+01, 6.74450817e+01, 6.74151097e+01, 6.73851377e+01,\n",
       "        6.73551657e+01, 6.73251937e+01, 6.72952218e+01, 6.72652498e+01,\n",
       "        6.72352778e+01, 6.72053058e+01, 6.71753338e+01, 6.71453618e+01,\n",
       "        6.71153898e+01, 6.70854178e+01, 6.70554458e+01, 6.70254739e+01,\n",
       "        6.69955019e+01, 6.69655299e+01, 6.69355579e+01, 6.69055859e+01,\n",
       "        6.68756139e+01, 6.68456419e+01, 6.68156699e+01, 6.67856979e+01,\n",
       "        6.67557260e+01, 6.67255159e+01, 6.66938632e+01, 6.66622105e+01,\n",
       "        6.66305579e+01, 6.65989052e+01, 6.65672526e+01, 6.65355999e+01,\n",
       "        6.65039472e+01, 6.64722946e+01, 6.64406419e+01, 6.64089893e+01,\n",
       "        6.63773366e+01, 6.63456839e+01, 6.63140313e+01, 6.62823786e+01,\n",
       "        6.62507260e+01, 6.62190733e+01, 6.61874206e+01, 6.61557680e+01,\n",
       "        6.61241153e+01, 6.60924627e+01, 6.60608100e+01, 6.60291573e+01,\n",
       "        6.59975047e+01, 6.59658520e+01, 6.59341994e+01, 6.59025467e+01,\n",
       "        6.58708940e+01, 6.58392414e+01, 6.58075887e+01, 6.57759360e+01,\n",
       "        6.57442834e+01, 6.57126307e+01, 6.56809781e+01, 6.56493254e+01,\n",
       "        6.56176727e+01, 6.55888655e+01, 6.55636555e+01, 6.55384454e+01,\n",
       "        6.55132353e+01, 6.54880252e+01, 6.54628151e+01, 6.54376050e+01,\n",
       "        6.54123950e+01, 6.53871849e+01, 6.53619748e+01, 6.53367647e+01,\n",
       "        6.53115546e+01, 6.52863445e+01, 6.52611345e+01, 6.52359244e+01,\n",
       "        7.40859222e+01, 0.00000000e+00, 0.00000000e+00, 2.98334658e-01,\n",
       "        5.23181319e-01, 1.23923242e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.11629093e-01, 0.00000000e+00, 6.19401857e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.61624277e-01, 4.67639714e-01,\n",
       "        3.82391155e-01, 1.41221249e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63.17517507, 63.15510037, 63.13502568, 63.11495098, 63.09487628,\n",
       "       63.07480159, 63.05472689, 63.03465219, 63.0145775 , 62.9945028 ,\n",
       "       62.9744281 , 62.95435341, 62.93427871, 62.91420401, 62.89412932,\n",
       "       62.87405462, 62.85397993, 62.83390523, 62.81383053, 62.79375584,\n",
       "       62.77368114, 62.75360644, 62.73353175, 62.71345705, 62.69338235,\n",
       "       62.67330766, 62.65323296, 62.63315826, 62.61308357, 62.59300887,\n",
       "       62.57293417, 62.55285948, 62.53278478, 62.51271008, 62.49263539,\n",
       "       62.47256069, 62.45248599, 62.4324113 , 62.4123366 , 62.3922619 ,\n",
       "       62.37218721, 62.35211251, 62.33203782, 62.31196312, 62.29188842,\n",
       "       62.27181373, 62.25173903, 62.23166433, 62.21158964, 62.19151494,\n",
       "       62.17144024, 62.15136555, 62.13129085, 62.11121615, 62.09114146,\n",
       "       62.07106676, 62.05099206, 62.03091737, 62.01084267, 61.99076797,\n",
       "       61.97069328, 61.95061858, 61.93054388, 61.91046919, 61.89039449,\n",
       "       61.87031979, 61.8502451 , 61.8301704 , 61.8100957 , 61.79002101,\n",
       "       61.76994631, 61.74987162, 61.72979692, 61.70972222, 61.68964753,\n",
       "       61.66957283, 61.64949813, 61.62942344, 61.60934874, 61.58927404,\n",
       "       61.56919935, 61.54912465, 61.52904995, 61.50897526, 61.48890056,\n",
       "       61.46882586, 61.44875117, 61.42867647, 61.40860177, 61.38852708,\n",
       "       61.36845238, 61.34837768, 61.32830299, 61.30822829, 61.28815359,\n",
       "       61.2680789 , 61.2480042 , 61.22792951, 61.20785481, 61.18778011])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.923430357434466\n",
      "14.951444770163983\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
