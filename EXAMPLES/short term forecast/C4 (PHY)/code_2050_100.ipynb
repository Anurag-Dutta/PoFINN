{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "2145    59.353351\n",
       "2146    59.341053\n",
       "2147    59.328756\n",
       "2148    59.316458\n",
       "2149    59.304161\n",
       "Name: C4, Length: 2150, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_2050_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "2045    64.676314\n",
       "2046    64.645377\n",
       "2047    64.614441\n",
       "2048    64.583504\n",
       "2049    64.552567\n",
       "Name: C4, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2050)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.409524</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.219048</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.028571</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.838095</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.600000  0.000298\n",
       "1     88.409524  0.000298\n",
       "2     88.219048  0.000297\n",
       "3     88.028571  0.000297\n",
       "4     87.838095  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.600000    88.409524    88.219048    88.028571    87.838095   \n",
      "351    88.409524    88.219048    88.028571    87.838095    87.647619   \n",
      "352    88.219048    88.028571    87.838095    87.647619    87.457143   \n",
      "353    88.028571    87.838095    87.647619    87.457143    87.266667   \n",
      "354    87.838095    87.647619    87.457143    87.266667    87.076190   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.647619    87.457143    87.266667    87.076190    86.896218  ...   \n",
      "351    87.457143    87.266667    87.076190    86.896218    86.845798  ...   \n",
      "352    87.266667    87.076190    86.896218    86.845798    86.795378  ...   \n",
      "353    87.076190    86.896218    86.845798    86.795378    86.744958  ...   \n",
      "354    86.896218    86.845798    86.795378    86.744958    86.694538  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   78.880345    0.000263   78.856069    0.000263   78.831793    0.000263   \n",
      "351   78.856069    0.000263   78.831793    0.000263   78.807516    0.000262   \n",
      "352   78.831793    0.000263   78.807516    0.000262   78.783240    0.000262   \n",
      "353   78.807516    0.000262   78.783240    0.000262   78.758964    0.000262   \n",
      "354   78.783240    0.000262   78.758964    0.000262   78.734687    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   78.807516    0.000262   78.783240    0.000262  \n",
      "351   78.783240    0.000262   78.758964    0.000262  \n",
      "352   78.758964    0.000262   78.734687    0.000262  \n",
      "353   78.734687    0.000262   78.710411    0.000262  \n",
      "354   78.710411    0.000262   78.686134    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 1, 251) (1600, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 23ms/step - loss: 5330.7139 - val_loss: 4067.4062\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5231.6992 - val_loss: 3984.6008\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5137.3413 - val_loss: 3910.8992\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5050.0200 - val_loss: 3823.7957\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4950.2358 - val_loss: 3752.8237\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4867.1924 - val_loss: 3683.4011\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4785.8936 - val_loss: 3615.4583\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4706.0981 - val_loss: 3548.7781\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4627.6069 - val_loss: 3483.2336\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4550.2993 - val_loss: 3418.7466\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4474.1025 - val_loss: 3355.2683\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4398.9697 - val_loss: 3292.7622\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4324.8628 - val_loss: 3231.2004\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4251.7563 - val_loss: 3170.5623\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4179.6260 - val_loss: 3110.8284\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4108.4536 - val_loss: 3051.9834\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4038.2231 - val_loss: 2994.0125\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3968.9185 - val_loss: 2936.9038\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3900.5288 - val_loss: 2880.6440\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3833.0391 - val_loss: 2814.2219\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3750.4727 - val_loss: 2754.5825\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3671.8804 - val_loss: 2686.0032\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3593.2676 - val_loss: 2624.3423\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3519.6470 - val_loss: 2565.2683\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3448.6772 - val_loss: 2508.1826\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3379.7485 - val_loss: 2452.7026\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3312.5007 - val_loss: 2398.6060\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3246.7209 - val_loss: 2345.7534\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3182.2698 - val_loss: 2294.0513\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3119.0493 - val_loss: 2243.4280\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3056.9878 - val_loss: 2193.8315\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2996.0295 - val_loss: 2145.2190\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2936.1296 - val_loss: 2097.5552\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2877.2505 - val_loss: 2050.8110\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2819.3613 - val_loss: 2004.9606\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2762.4336 - val_loss: 1959.9814\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2706.4448 - val_loss: 1915.8541\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2651.3740 - val_loss: 1872.5593\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2597.2000 - val_loss: 1830.0823\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2543.9065 - val_loss: 1788.4059\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2491.4773 - val_loss: 1747.5168\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2439.8972 - val_loss: 1707.4011\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2389.1516 - val_loss: 1668.0471\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2339.2280 - val_loss: 1629.4417\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2290.1133 - val_loss: 1591.5741\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2241.7957 - val_loss: 1554.4329\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2194.2639 - val_loss: 1518.0082\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2147.5063 - val_loss: 1482.2887\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2101.5127 - val_loss: 1447.2649\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2056.2729 - val_loss: 1412.9275\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2011.7764 - val_loss: 1379.2671\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1968.0146 - val_loss: 1346.2743\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1924.9778 - val_loss: 1313.9409\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1882.6566 - val_loss: 1282.2571\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1835.2825 - val_loss: 1243.2317\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1786.6937 - val_loss: 1208.4792\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1741.2715 - val_loss: 1175.4270\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1697.7090 - val_loss: 1143.7021\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1655.5881 - val_loss: 1113.0627\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1614.6625 - val_loss: 1083.3712\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1574.7886 - val_loss: 1054.5403\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1535.8738 - val_loss: 1026.5110\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1497.8536 - val_loss: 999.2397\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1460.6791 - val_loss: 972.6922\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1424.3124 - val_loss: 946.8405\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1388.7230 - val_loss: 921.6608\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1353.8840 - val_loss: 897.1337\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1319.7738 - val_loss: 873.2405\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1286.3727 - val_loss: 849.9655\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1253.6621 - val_loss: 827.2939\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1221.6267 - val_loss: 805.2118\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1190.2506 - val_loss: 783.7062\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1159.5214 - val_loss: 762.7661\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1129.4258 - val_loss: 742.3795\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1099.9510 - val_loss: 722.5355\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1071.0865 - val_loss: 703.2236\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1042.8206 - val_loss: 684.4344\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1015.1431 - val_loss: 666.1584\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 988.0444 - val_loss: 648.3859\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 961.5143 - val_loss: 631.1080\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 935.5435 - val_loss: 614.3159\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 910.1230 - val_loss: 598.0011\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 885.2440 - val_loss: 582.1550\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 860.8976 - val_loss: 566.7692\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 837.0753 - val_loss: 551.8361\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 813.7693 - val_loss: 537.3478\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 790.9708 - val_loss: 523.2955\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 768.6725 - val_loss: 509.6727\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 746.8660 - val_loss: 496.4716\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 725.5444 - val_loss: 483.6844\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 704.6993 - val_loss: 471.3036\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 684.3240 - val_loss: 459.3223\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 664.4105 - val_loss: 447.7334\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 644.9518 - val_loss: 436.5293\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 625.9414 - val_loss: 425.7034\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 607.3714 - val_loss: 415.2486\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 589.2352 - val_loss: 405.1584\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 571.5259 - val_loss: 395.4252\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 554.2369 - val_loss: 386.0430\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 537.3611 - val_loss: 377.0046\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 520.8922 - val_loss: 368.3039\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 504.8232 - val_loss: 359.9338\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 489.1478 - val_loss: 351.8879\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 473.8594 - val_loss: 344.1600\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 458.9516 - val_loss: 336.7433\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 444.4183 - val_loss: 329.6318\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 430.2530 - val_loss: 322.8196\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 416.4496 - val_loss: 316.2993\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 403.0018 - val_loss: 310.0656\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 389.9033 - val_loss: 304.1121\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 377.1480 - val_loss: 298.4323\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 364.7303 - val_loss: 293.0206\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 352.6437 - val_loss: 287.8711\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 340.8828 - val_loss: 282.9775\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 329.4411 - val_loss: 278.3340\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 318.3131 - val_loss: 273.9346\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 307.4931 - val_loss: 269.7739\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 296.9750 - val_loss: 265.8456\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 286.7536 - val_loss: 262.1444\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 276.8228 - val_loss: 258.6643\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 267.1772 - val_loss: 255.3999\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 257.8111 - val_loss: 252.3456\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 248.7193 - val_loss: 249.4957\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 239.8960 - val_loss: 246.8448\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 231.3359 - val_loss: 244.3875\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 223.0338 - val_loss: 242.1183\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 214.9840 - val_loss: 240.0318\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 207.1815 - val_loss: 238.1230\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 199.6208 - val_loss: 236.3866\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 192.2970 - val_loss: 234.8172\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 185.2050 - val_loss: 233.4099\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 178.3396 - val_loss: 232.1594\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 171.6955 - val_loss: 231.0609\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 165.2681 - val_loss: 230.1093\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 159.0523 - val_loss: 229.2997\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 153.0431 - val_loss: 228.6273\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 147.2358 - val_loss: 228.0874\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 141.6257 - val_loss: 227.6750\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 136.2080 - val_loss: 227.3856\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 130.9779 - val_loss: 227.2146\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 125.9308 - val_loss: 227.1574\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 121.0624 - val_loss: 227.2095\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 116.3678 - val_loss: 227.3665\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 111.8427 - val_loss: 227.6241\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 107.4828 - val_loss: 227.9777\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 103.2835 - val_loss: 228.4235\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 99.2405 - val_loss: 228.9570\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 95.3500 - val_loss: 229.5743\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 91.6074 - val_loss: 230.2713\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 88.0088 - val_loss: 231.0440\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 84.5500 - val_loss: 231.8886\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 81.2271 - val_loss: 232.8011\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 78.0361 - val_loss: 233.7781\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 74.9729 - val_loss: 234.8156\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 72.0342 - val_loss: 235.9101\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 69.2158 - val_loss: 237.0581\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 66.5141 - val_loss: 238.2562\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 63.9256 - val_loss: 239.5010\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 61.4467 - val_loss: 240.7890\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 59.0738 - val_loss: 242.1174\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 56.8035 - val_loss: 243.4826\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 54.6325 - val_loss: 244.8817\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 52.5574 - val_loss: 246.3119\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 50.5750 - val_loss: 247.7701\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 48.6822 - val_loss: 249.2534\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 46.8758 - val_loss: 250.7594\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 45.1526 - val_loss: 252.2850\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 43.5098 - val_loss: 253.8280\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 41.9445 - val_loss: 255.3856\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 40.4538 - val_loss: 256.9551\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 39.0351 - val_loss: 258.5347\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 37.6854 - val_loss: 260.1222\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 36.4021 - val_loss: 261.7148\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 35.1827 - val_loss: 263.3110\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 34.0246 - val_loss: 264.9084\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 32.9255 - val_loss: 266.5051\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.8829 - val_loss: 268.0995\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8943 - val_loss: 269.6894\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 29.9578 - val_loss: 271.2730\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 29.0711 - val_loss: 272.8493\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 28.2320 - val_loss: 274.4164\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 27.4382 - val_loss: 275.9727\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 26.6881 - val_loss: 277.5167\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 25.9795 - val_loss: 279.0471\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 25.3107 - val_loss: 280.5630\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 24.6797 - val_loss: 282.0631\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 24.0848 - val_loss: 283.5458\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.5243 - val_loss: 285.0107\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.9966 - val_loss: 286.4562\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 22.5001 - val_loss: 287.8819\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 22.0332 - val_loss: 289.2866\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.5945 - val_loss: 290.6698\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 21.1825 - val_loss: 292.0304\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.7960 - val_loss: 293.3681\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.4335 - val_loss: 294.6819\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 20.0938 - val_loss: 295.9723\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7756 - val_loss: 297.2371\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.4780 - val_loss: 298.4774\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.1997 - val_loss: 299.6917\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.9396 - val_loss: 300.8806\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 18.6967 - val_loss: 302.0438\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.4700 - val_loss: 303.1802\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 18.2587 - val_loss: 304.2906\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 18.0618 - val_loss: 305.3743\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 17.8785 - val_loss: 306.4313\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.7080 - val_loss: 307.4616\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.5495 - val_loss: 308.4655\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.4022 - val_loss: 309.4428\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.2654 - val_loss: 310.3934\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.1386 - val_loss: 311.3178\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0211 - val_loss: 312.2157\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 16.9122 - val_loss: 313.0876\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.8115 - val_loss: 313.9332\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.7183 - val_loss: 314.7534\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.6323 - val_loss: 315.5484\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.5528 - val_loss: 316.3184\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.4795 - val_loss: 317.0636\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.4119 - val_loss: 317.7845\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.3496 - val_loss: 318.4813\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 16.2923 - val_loss: 319.1546\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 16.2395 - val_loss: 319.8049\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 16.1911 - val_loss: 320.4319\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 16.1466 - val_loss: 321.0363\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1058 - val_loss: 321.6192\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 16.0683 - val_loss: 322.1804\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 16.0340 - val_loss: 322.7206\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.0026 - val_loss: 323.2399\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.9739 - val_loss: 323.7396\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.9476 - val_loss: 324.2193\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.9237 - val_loss: 324.6800\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 15.9018 - val_loss: 325.1224\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.8818 - val_loss: 325.5458\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.8636 - val_loss: 325.9520\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.8471 - val_loss: 326.3410\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.8320 - val_loss: 326.7132\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.8183 - val_loss: 327.0694\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.8059 - val_loss: 327.4092\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7946 - val_loss: 327.7343\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7844 - val_loss: 328.0450\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7752 - val_loss: 328.3409\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7667 - val_loss: 328.6231\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7592 - val_loss: 328.8922\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7523 - val_loss: 329.1483\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7461 - val_loss: 329.3920\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7406 - val_loss: 329.6238\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7355 - val_loss: 329.8434\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7311 - val_loss: 330.0525\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7270 - val_loss: 330.2508\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7234 - val_loss: 330.4394\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7202 - val_loss: 330.6177\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7173 - val_loss: 330.7867\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 15.7147 - val_loss: 330.9471\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7124 - val_loss: 331.0986\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7103 - val_loss: 331.2418\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7085 - val_loss: 331.3765\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7070 - val_loss: 331.5045\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7056 - val_loss: 331.6250\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7043 - val_loss: 331.7385\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7033 - val_loss: 331.8456\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7023 - val_loss: 331.9460\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7016 - val_loss: 332.0407\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7009 - val_loss: 332.1295\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7003 - val_loss: 332.2130\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.6999 - val_loss: 332.2917\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.6995 - val_loss: 332.3654\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.6992 - val_loss: 332.4340\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.6990 - val_loss: 332.4987\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.6989 - val_loss: 332.5593\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.6988 - val_loss: 332.6155\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.6988 - val_loss: 332.6680\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 15.6988 - val_loss: 332.7170\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.6988 - val_loss: 332.7627\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.6990 - val_loss: 332.8055\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.6991 - val_loss: 332.8450\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.6993 - val_loss: 332.8814\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.6995 - val_loss: 332.9157\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.6998 - val_loss: 332.9474\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7001 - val_loss: 332.9768\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7004 - val_loss: 333.0041\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7007 - val_loss: 333.0290\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7011 - val_loss: 333.0520\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7015 - val_loss: 333.0735\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7019 - val_loss: 333.0935\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7023 - val_loss: 333.1114\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7028 - val_loss: 333.1280\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7032 - val_loss: 333.1436\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7036 - val_loss: 333.1571\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7041 - val_loss: 333.1698\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7046 - val_loss: 333.1815\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 15.7051 - val_loss: 333.1920\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7057 - val_loss: 333.2016\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 15.7061 - val_loss: 333.2096\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7067 - val_loss: 333.2178\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7072 - val_loss: 333.2248\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7078 - val_loss: 333.2308\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7083 - val_loss: 333.2361\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7089 - val_loss: 333.2413\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7095 - val_loss: 333.2454\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7100 - val_loss: 333.2493\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7106 - val_loss: 333.2528\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7112 - val_loss: 333.2558\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7117 - val_loss: 333.2578\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7124 - val_loss: 333.2600\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7129 - val_loss: 333.2613\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 15.7135 - val_loss: 333.2629\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7141 - val_loss: 333.2637\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7148 - val_loss: 333.2644\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7154 - val_loss: 333.2648\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7159 - val_loss: 333.2650\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7166 - val_loss: 333.2654\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7172 - val_loss: 333.2651\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7178 - val_loss: 333.2644\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7184 - val_loss: 333.2639\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7191 - val_loss: 333.2636\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7196 - val_loss: 333.2629\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7202 - val_loss: 333.2618\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7208 - val_loss: 333.2603\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7215 - val_loss: 333.2597\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7221 - val_loss: 333.2584\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7227 - val_loss: 333.2570\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7233 - val_loss: 333.2555\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 15.7239 - val_loss: 333.2539\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7245 - val_loss: 333.2530\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7251 - val_loss: 333.2512\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7257 - val_loss: 333.2494\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7264 - val_loss: 333.2479\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7270 - val_loss: 333.2464\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7275 - val_loss: 333.2443\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7281 - val_loss: 333.2427\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7288 - val_loss: 333.2407\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7293 - val_loss: 333.2388\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7300 - val_loss: 333.2372\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7305 - val_loss: 333.2352\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7312 - val_loss: 333.2336\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7317 - val_loss: 333.2317\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7323 - val_loss: 333.2300\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7329 - val_loss: 333.2279\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7335 - val_loss: 333.2261\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7340 - val_loss: 333.2240\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7346 - val_loss: 333.2220\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7352 - val_loss: 333.2201\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7358 - val_loss: 333.2180\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7363 - val_loss: 333.2165\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7369 - val_loss: 333.2140\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7375 - val_loss: 333.2122\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7380 - val_loss: 333.2103\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7386 - val_loss: 333.2088\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7391 - val_loss: 333.2069\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7397 - val_loss: 333.2051\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7402 - val_loss: 333.2031\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7407 - val_loss: 333.2012\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7413 - val_loss: 333.1989\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7418 - val_loss: 333.1971\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7423 - val_loss: 333.1953\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7429 - val_loss: 333.1937\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7433 - val_loss: 333.1919\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7439 - val_loss: 333.1896\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 15.7444 - val_loss: 333.1881\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7449 - val_loss: 333.1861\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7454 - val_loss: 333.1846\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7460 - val_loss: 333.1829\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 15.7464 - val_loss: 333.1815\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 15.7469 - val_loss: 333.1795\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 15.7474 - val_loss: 333.1779\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7479 - val_loss: 333.1760\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7484 - val_loss: 333.1746\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7488 - val_loss: 333.1729\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7493 - val_loss: 333.1715\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7497 - val_loss: 333.1696\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7503 - val_loss: 333.1683\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7507 - val_loss: 333.1666\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7511 - val_loss: 333.1648\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 15.7516 - val_loss: 333.1631\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7520 - val_loss: 333.1619\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7525 - val_loss: 333.1603\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7529 - val_loss: 333.1588\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7534 - val_loss: 333.1575\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7538 - val_loss: 333.1558\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7542 - val_loss: 333.1544\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7546 - val_loss: 333.1533\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7550 - val_loss: 333.1520\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7554 - val_loss: 333.1501\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7558 - val_loss: 333.1487\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7562 - val_loss: 333.1473\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7566 - val_loss: 333.1462\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7570 - val_loss: 333.1448\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7573 - val_loss: 333.1431\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 15.7578 - val_loss: 333.1420\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7581 - val_loss: 333.1403\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7585 - val_loss: 333.1393\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7589 - val_loss: 333.1382\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7592 - val_loss: 333.1367\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7596 - val_loss: 333.1354\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7600 - val_loss: 333.1345\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7603 - val_loss: 333.1332\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7606 - val_loss: 333.1320\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7610 - val_loss: 333.1304\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7613 - val_loss: 333.1294\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7616 - val_loss: 333.1283\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 15.7619 - val_loss: 333.1271\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7623 - val_loss: 333.1258\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7626 - val_loss: 333.1250\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7629 - val_loss: 333.1238\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7632 - val_loss: 333.1223\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7635 - val_loss: 333.1215\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7638 - val_loss: 333.1205\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7641 - val_loss: 333.1193\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7644 - val_loss: 333.1185\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7647 - val_loss: 333.1174\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7650 - val_loss: 333.1166\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7652 - val_loss: 333.1153\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7655 - val_loss: 333.1143\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7658 - val_loss: 333.1137\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 15.7661 - val_loss: 333.1130\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7663 - val_loss: 333.1118\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7666 - val_loss: 333.1112\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7668 - val_loss: 333.1099\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7671 - val_loss: 333.1091\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7674 - val_loss: 333.1085\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7676 - val_loss: 333.1079\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7678 - val_loss: 333.1068\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7681 - val_loss: 333.1062\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7683 - val_loss: 333.1052\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7685 - val_loss: 333.1042\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7688 - val_loss: 333.1032\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7690 - val_loss: 333.1024\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7692 - val_loss: 333.1019\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 15.7694 - val_loss: 333.1011\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7696 - val_loss: 333.1003\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7698 - val_loss: 333.0994\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7701 - val_loss: 333.0988\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7703 - val_loss: 333.0982\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7705 - val_loss: 333.0976\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7706 - val_loss: 333.0967\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7708 - val_loss: 333.0957\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7710 - val_loss: 333.0949\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7712 - val_loss: 333.0940\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7714 - val_loss: 333.0929\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7716 - val_loss: 333.0926\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7718 - val_loss: 333.0919\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7719 - val_loss: 333.0914\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7721 - val_loss: 333.0907\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 15.7723 - val_loss: 333.0904\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7724 - val_loss: 333.0895\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7726 - val_loss: 333.0891\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7728 - val_loss: 333.0883\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7729 - val_loss: 333.0877\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7731 - val_loss: 333.0870\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7732 - val_loss: 333.0865\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7734 - val_loss: 333.0861\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7736 - val_loss: 333.0858\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7737 - val_loss: 333.0854\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7738 - val_loss: 333.0844\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7740 - val_loss: 333.0840\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7741 - val_loss: 333.0836\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7742 - val_loss: 333.0829\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 15.7744 - val_loss: 333.0823\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7745 - val_loss: 333.0820\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7746 - val_loss: 333.0815\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7748 - val_loss: 333.0813\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7749 - val_loss: 333.0809\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7750 - val_loss: 333.0801\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7751 - val_loss: 333.0796\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7752 - val_loss: 333.0794\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7754 - val_loss: 333.0789\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7754 - val_loss: 333.0781\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7756 - val_loss: 333.0776\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7757 - val_loss: 333.0775\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7758 - val_loss: 333.0775\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7759 - val_loss: 333.0771\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7760 - val_loss: 333.0768\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7761 - val_loss: 333.0760\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7762 - val_loss: 333.0757\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 15.7763 - val_loss: 333.0753\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7765 - val_loss: 333.0754\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7765 - val_loss: 333.0750\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7766 - val_loss: 333.0746\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7767 - val_loss: 333.0748\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7767 - val_loss: 333.0743\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7768 - val_loss: 333.0736\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7769 - val_loss: 333.0732\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7770 - val_loss: 333.0728\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7771 - val_loss: 333.0726\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7772 - val_loss: 333.0721\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7773 - val_loss: 333.0716\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.7774 - val_loss: 333.0712\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7774 - val_loss: 333.0712\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7775 - val_loss: 333.0706\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7776 - val_loss: 333.0705\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 15.7777 - val_loss: 333.0703\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7777 - val_loss: 333.0699\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7778 - val_loss: 333.0699\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7779 - val_loss: 333.0695\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7779 - val_loss: 333.0692\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7780 - val_loss: 333.0687\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7780 - val_loss: 333.0682\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7781 - val_loss: 333.0681\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7782 - val_loss: 333.0680\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.7783 - val_loss: 333.0676\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 15.7783 - val_loss: 333.0674\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 339ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.65883543e+01, 6.65567017e+01, 6.65250490e+01, 6.64933964e+01,\n",
       "        6.64617437e+01, 6.64300910e+01, 6.63984384e+01, 6.63667857e+01,\n",
       "        6.63351330e+01, 6.63034804e+01, 6.62718277e+01, 6.62401751e+01,\n",
       "        6.62085224e+01, 6.61768697e+01, 6.61452171e+01, 6.61135644e+01,\n",
       "        6.60819118e+01, 6.60502591e+01, 6.60186064e+01, 6.59869538e+01,\n",
       "        6.59553011e+01, 6.59236485e+01, 6.58919958e+01, 6.58603431e+01,\n",
       "        6.58286905e+01, 6.57970378e+01, 6.57653852e+01, 6.57337325e+01,\n",
       "        6.57020798e+01, 6.56704272e+01, 6.56387745e+01, 6.56071218e+01,\n",
       "        6.55804622e+01, 6.55552521e+01, 6.55300420e+01, 6.55048319e+01,\n",
       "        6.54796219e+01, 6.54544118e+01, 6.54292017e+01, 6.54039916e+01,\n",
       "        6.53787815e+01, 6.53535714e+01, 6.53283613e+01, 6.53031513e+01,\n",
       "        6.52779412e+01, 6.52527311e+01, 6.52275210e+01, 6.99859244e+01,\n",
       "        6.99607143e+01, 6.99355042e+01, 6.99102941e+01, 6.98850840e+01,\n",
       "        6.98598739e+01, 6.98346639e+01, 6.98094538e+01, 6.96949580e+01,\n",
       "        6.95268908e+01, 6.93588235e+01, 6.91907563e+01, 6.90226891e+01,\n",
       "        6.88546219e+01, 6.86865546e+01, 6.85184874e+01, 6.83504202e+01,\n",
       "        6.81823529e+01, 6.80142857e+01, 6.78462185e+01, 6.77348109e+01,\n",
       "        6.76448950e+01, 6.75549790e+01, 6.74650630e+01, 6.73751471e+01,\n",
       "        6.72852311e+01, 7.46553650e+01, 3.70657860e-01, 5.93169510e-01,\n",
       "        5.83681580e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.98275833e+01, 8.11801493e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.47911329e-02, 0.00000000e+00, 7.16570556e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.12765867e-01, 0.00000000e+00, 2.65739322e-01,\n",
       "        1.01996183e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.26282585e-02, 6.21096611e-01, 7.91240275e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61.16770542, 61.14763072, 61.12755602, 61.10748133, 61.08740663,\n",
       "       61.06733193, 61.04725724, 61.02718254, 61.00710784, 60.98703315,\n",
       "       60.96695845, 60.94688375, 60.92680906, 60.90673436, 60.88665966,\n",
       "       60.86658497, 60.84651027, 60.82643557, 60.80636088, 60.78628618,\n",
       "       60.76621148, 60.74613679, 60.72606209, 60.70598739, 60.6859127 ,\n",
       "       60.665838  , 60.64576331, 60.62568861, 60.60561391, 60.58553922,\n",
       "       60.56546452, 60.54538982, 60.52531513, 60.50524043, 60.48516573,\n",
       "       60.46509104, 60.44501634, 60.42494164, 60.40486695, 60.38479225,\n",
       "       60.36471755, 60.34464286, 60.32456816, 60.30449346, 60.28441877,\n",
       "       60.26434407, 60.24426937, 60.22419468, 60.20411998, 60.18404528,\n",
       "       60.16397059, 60.14389589, 60.1238212 , 60.1037465 , 60.0836718 ,\n",
       "       60.06359711, 60.04352241, 60.02344771, 60.00337302, 59.98329832,\n",
       "       59.96322362, 59.94314893, 59.92307423, 59.90299953, 59.88292484,\n",
       "       59.86285014, 59.84277544, 59.82270075, 59.80262605, 59.78255135,\n",
       "       59.76247666, 59.74240196, 59.72232726, 59.70225257, 59.68217787,\n",
       "       59.66210317, 59.64202848, 59.62195378, 59.60187908, 59.58180439,\n",
       "       59.56172969, 59.541655  , 59.5215803 , 59.5015056 , 59.48862472,\n",
       "       59.47632712, 59.46402951, 59.45173191, 59.43943431, 59.42713671,\n",
       "       59.41483911, 59.4025415 , 59.3902439 , 59.3779463 , 59.3656487 ,\n",
       "       59.3533511 , 59.34105349, 59.32875589, 59.31645829, 59.30416069])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.220176697364185\n",
      "19.789638303241976\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
