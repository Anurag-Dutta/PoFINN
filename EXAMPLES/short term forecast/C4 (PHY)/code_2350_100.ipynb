{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "2445    55.664071\n",
       "2446    55.651773\n",
       "2447    55.639475\n",
       "2448    55.627178\n",
       "2449    55.614880\n",
       "Name: C4, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c4_interpolated_2350_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.600000\n",
       "1       88.409524\n",
       "2       88.219048\n",
       "3       88.028571\n",
       "4       87.838095\n",
       "          ...    \n",
       "2345     0.000000\n",
       "2346     0.074520\n",
       "2347     0.000000\n",
       "2348     0.320692\n",
       "2349     0.091184\n",
       "Name: C4, Length: 2350, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2350)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.409524</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.219048</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.028571</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.838095</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.600000  0.000298\n",
       "1     88.409524  0.000298\n",
       "2     88.219048  0.000297\n",
       "3     88.028571  0.000297\n",
       "4     87.838095  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6856  # Value for C0\n",
    "K0 = -0.0008  # Value for K0\n",
    "K1 = -0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0128    # Value for b\n",
    "c = -2.3003    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.600000    88.409524    88.219048    88.028571    87.838095   \n",
      "351    88.409524    88.219048    88.028571    87.838095    87.647619   \n",
      "352    88.219048    88.028571    87.838095    87.647619    87.457143   \n",
      "353    88.028571    87.838095    87.647619    87.457143    87.266667   \n",
      "354    87.838095    87.647619    87.457143    87.266667    87.076190   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.647619    87.457143    87.266667    87.076190    86.896218  ...   \n",
      "351    87.457143    87.266667    87.076190    86.896218    86.845798  ...   \n",
      "352    87.266667    87.076190    86.896218    86.845798    86.795378  ...   \n",
      "353    87.076190    86.896218    86.845798    86.795378    86.744958  ...   \n",
      "354    86.896218    86.845798    86.795378    86.744958    86.694538  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   78.880345    0.000263   78.856069    0.000263   78.831793    0.000263   \n",
      "351   78.856069    0.000263   78.831793    0.000263   78.807516    0.000262   \n",
      "352   78.831793    0.000263   78.807516    0.000262   78.783240    0.000262   \n",
      "353   78.807516    0.000262   78.783240    0.000262   78.758964    0.000262   \n",
      "354   78.783240    0.000262   78.758964    0.000262   78.734687    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   78.807516    0.000262   78.783240    0.000262  \n",
      "351   78.783240    0.000262   78.758964    0.000262  \n",
      "352   78.758964    0.000262   78.734687    0.000262  \n",
      "353   78.734687    0.000262   78.710411    0.000262  \n",
      "354   78.710411    0.000262   78.686134    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 1, 251) (1900, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 2s 22ms/step - loss: 5114.1187 - val_loss: 3381.1506\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4990.8120 - val_loss: 3324.4902\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4902.1807 - val_loss: 3269.2708\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4814.7769 - val_loss: 3215.1934\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4728.9028 - val_loss: 3162.1240\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 4644.3896 - val_loss: 3105.1443\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4543.4502 - val_loss: 3047.1951\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4456.0483 - val_loss: 2994.1257\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4370.9116 - val_loss: 2942.4111\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4287.6323 - val_loss: 2891.8208\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4205.9136 - val_loss: 2842.2339\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4125.6001 - val_loss: 2793.5818\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4046.6023 - val_loss: 2745.8198\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3968.8577 - val_loss: 2698.9170\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3892.3230 - val_loss: 2652.8491\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3816.9639 - val_loss: 2607.5959\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3742.7527 - val_loss: 2563.1409\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3669.6658 - val_loss: 2519.4695\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3597.6843 - val_loss: 2476.5684\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3526.7866 - val_loss: 2434.4255\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3456.9590 - val_loss: 2393.0291\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3388.1846 - val_loss: 2352.3691\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3320.4478 - val_loss: 2312.4360\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3253.7368 - val_loss: 2273.2190\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3188.0369 - val_loss: 2234.7095\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3123.3354 - val_loss: 2196.8979\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3059.6218 - val_loss: 2159.7761\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2996.8835 - val_loss: 2123.3354\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2935.1077 - val_loss: 2087.5679\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2874.2852 - val_loss: 2052.4646\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2814.4041 - val_loss: 2018.0183\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2755.4526 - val_loss: 1984.2206\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2697.4226 - val_loss: 1951.0645\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2640.3027 - val_loss: 1918.5416\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2584.0818 - val_loss: 1886.6453\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2528.7517 - val_loss: 1855.3674\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2474.3013 - val_loss: 1824.7009\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2420.7217 - val_loss: 1794.6390\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2368.0022 - val_loss: 1765.1747\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2316.1345 - val_loss: 1736.2997\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2265.1096 - val_loss: 1708.0082\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2214.9172 - val_loss: 1680.2932\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2165.5491 - val_loss: 1653.1478\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2116.9956 - val_loss: 1626.5648\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2069.2480 - val_loss: 1600.5382\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2022.2979 - val_loss: 1575.0607\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1976.1359 - val_loss: 1550.1265\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1930.7542 - val_loss: 1525.7283\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1886.1436 - val_loss: 1501.8604\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1842.2958 - val_loss: 1478.5160\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1799.2023 - val_loss: 1455.6885\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1756.8552 - val_loss: 1433.3721\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1715.2461 - val_loss: 1411.5601\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1674.3665 - val_loss: 1390.2461\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1634.2080 - val_loss: 1369.4243\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1594.7628 - val_loss: 1349.0885\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1556.0240 - val_loss: 1329.2328\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1517.9825 - val_loss: 1309.8511\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1480.6302 - val_loss: 1290.9369\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1443.9598 - val_loss: 1272.4846\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1407.9639 - val_loss: 1254.4883\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1372.6338 - val_loss: 1236.9417\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1337.9625 - val_loss: 1219.8390\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1303.9424 - val_loss: 1203.1747\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1270.5654 - val_loss: 1186.9427\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1237.8246 - val_loss: 1171.1370\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1205.7125 - val_loss: 1155.7524\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1174.2211 - val_loss: 1140.7828\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1143.3434 - val_loss: 1126.2227\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1113.0723 - val_loss: 1112.0662\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1083.4001 - val_loss: 1098.3079\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1054.3197 - val_loss: 1084.9417\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1025.8237 - val_loss: 1071.9622\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 997.9050 - val_loss: 1059.3641\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 970.5569 - val_loss: 1047.1415\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 943.7716 - val_loss: 1035.2892\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 917.5428 - val_loss: 1023.8013\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 891.8627 - val_loss: 1012.6727\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 866.7247 - val_loss: 1001.8975\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 842.1217 - val_loss: 991.4709\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 818.0469 - val_loss: 981.3867\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 794.4933 - val_loss: 971.6400\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 771.4541 - val_loss: 962.2252\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 748.9224 - val_loss: 953.1370\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 726.8914 - val_loss: 944.3702\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 705.3544 - val_loss: 935.9192\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 684.3046 - val_loss: 927.7789\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 663.7353 - val_loss: 919.9441\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 643.6398 - val_loss: 912.4092\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 624.0115 - val_loss: 905.1689\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 604.8435 - val_loss: 898.2184\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 586.1295 - val_loss: 891.5521\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 567.8630 - val_loss: 885.1652\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 550.0370 - val_loss: 879.0520\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 532.6454 - val_loss: 873.2076\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 515.6816 - val_loss: 867.6270\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 499.1389 - val_loss: 862.3047\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 483.0109 - val_loss: 857.2358\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 467.2915 - val_loss: 852.4154\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 451.9743 - val_loss: 847.8380\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 437.0524 - val_loss: 843.4988\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 422.5198 - val_loss: 839.3926\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 408.3703 - val_loss: 835.5146\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 394.5974 - val_loss: 831.8597\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 381.1951 - val_loss: 828.4230\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 368.1570 - val_loss: 825.1991\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 355.4767 - val_loss: 822.1837\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 343.1483 - val_loss: 819.3713\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 331.1656 - val_loss: 816.7573\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 319.5222 - val_loss: 814.3369\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 308.2123 - val_loss: 812.1050\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 297.2297 - val_loss: 810.0569\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 286.5684 - val_loss: 808.1878\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 276.2224 - val_loss: 806.4929\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 266.1858 - val_loss: 804.9673\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 256.4525 - val_loss: 803.6066\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 247.0167 - val_loss: 802.4057\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 237.8723 - val_loss: 801.3602\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 229.0136 - val_loss: 800.4653\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 220.4350 - val_loss: 799.7166\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 212.1303 - val_loss: 799.1092\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 204.0939 - val_loss: 798.6387\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 196.3203 - val_loss: 798.3007\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 188.8037 - val_loss: 798.0905\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 181.5386 - val_loss: 798.0038\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 174.5192 - val_loss: 798.0361\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 167.7399 - val_loss: 798.1830\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 161.1951 - val_loss: 798.4404\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 154.8794 - val_loss: 798.8038\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 148.7877 - val_loss: 799.2689\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 142.9144 - val_loss: 799.8316\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 137.2542 - val_loss: 800.4876\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 131.8018 - val_loss: 801.2330\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 126.5518 - val_loss: 802.0635\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 121.4993 - val_loss: 802.9753\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 116.6391 - val_loss: 803.9643\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 111.9660 - val_loss: 805.0265\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 107.4749 - val_loss: 806.1584\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 103.1609 - val_loss: 807.3558\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 99.0191 - val_loss: 808.6150\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 95.0448 - val_loss: 809.9324\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 91.2331 - val_loss: 811.3044\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 87.5791 - val_loss: 812.7275\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 84.0783 - val_loss: 814.1979\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 80.7261 - val_loss: 815.7123\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 77.5181 - val_loss: 817.2675\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 74.4494 - val_loss: 818.8599\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 71.5159 - val_loss: 820.4863\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 68.7131 - val_loss: 822.1437\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 66.0368 - val_loss: 823.8290\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 63.4826 - val_loss: 825.5391\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 61.0467 - val_loss: 827.2708\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 58.7248 - val_loss: 829.0216\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 56.5132 - val_loss: 830.7883\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 54.4077 - val_loss: 832.5685\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 52.4044 - val_loss: 834.3592\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 50.4999 - val_loss: 836.1582\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 48.6903 - val_loss: 837.9629\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 46.9719 - val_loss: 839.7708\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 45.3412 - val_loss: 841.5795\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 43.7949 - val_loss: 843.3871\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 42.3295 - val_loss: 845.1910\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 40.9418 - val_loss: 846.9893\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 39.6286 - val_loss: 848.7799\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 38.3867 - val_loss: 850.5609\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 37.2132 - val_loss: 852.3306\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 36.1051 - val_loss: 854.0869\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 35.0594 - val_loss: 855.8286\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 34.0734 - val_loss: 857.5533\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 33.1445 - val_loss: 859.2609\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 32.2697 - val_loss: 860.9485\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 31.4469 - val_loss: 862.6155\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 30.6732 - val_loss: 864.2607\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 29.9466 - val_loss: 865.8826\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 29.2645 - val_loss: 867.4801\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 28.6249 - val_loss: 869.0521\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 28.0255 - val_loss: 870.5982\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 27.4641 - val_loss: 872.1172\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 26.9389 - val_loss: 873.6082\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 26.4479 - val_loss: 875.0706\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.9893 - val_loss: 876.5035\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.5613 - val_loss: 877.9069\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.1621 - val_loss: 879.2797\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 24.7901 - val_loss: 880.6218\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 24.4438 - val_loss: 881.9328\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 24.1217 - val_loss: 883.2123\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.8223 - val_loss: 884.4601\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.5443 - val_loss: 885.6760\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.2863 - val_loss: 886.8599\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 23.0472 - val_loss: 888.0118\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 22.8257 - val_loss: 889.1319\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 22.6206 - val_loss: 890.2195\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 22.4311 - val_loss: 891.2755\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 22.2559 - val_loss: 892.2993\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 22.0943 - val_loss: 893.2917\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 21.9452 - val_loss: 894.2526\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 21.8079 - val_loss: 895.1826\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 21.6814 - val_loss: 896.0817\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 21.5651 - val_loss: 896.9505\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 21.4581 - val_loss: 897.7895\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 21.3598 - val_loss: 898.5986\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 21.2697 - val_loss: 899.3785\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 21.1871 - val_loss: 900.1298\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 21.1114 - val_loss: 900.8529\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 21.0421 - val_loss: 901.5486\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.9787 - val_loss: 902.2173\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.9208 - val_loss: 902.8589\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.8679 - val_loss: 903.4749\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 20.8196 - val_loss: 904.0651\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.7757 - val_loss: 904.6307\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 20.7356 - val_loss: 905.1721\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.6991 - val_loss: 905.6899\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 20.6660 - val_loss: 906.1854\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 20.6358 - val_loss: 906.6586\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.6084 - val_loss: 907.1100\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.5835 - val_loss: 907.5404\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.5610 - val_loss: 907.9509\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.5406 - val_loss: 908.3416\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.5221 - val_loss: 908.7131\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.5053 - val_loss: 909.0660\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4903 - val_loss: 909.4020\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4765 - val_loss: 909.7203\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4643 - val_loss: 910.0227\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.4530 - val_loss: 910.3087\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4430 - val_loss: 910.5798\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4340 - val_loss: 910.8362\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4260 - val_loss: 911.0788\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4186 - val_loss: 911.3080\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4120 - val_loss: 911.5239\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4062 - val_loss: 911.7279\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4010 - val_loss: 911.9200\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.3963 - val_loss: 912.1008\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3921 - val_loss: 912.2709\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3884 - val_loss: 912.4310\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.3850 - val_loss: 912.5811\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.3821 - val_loss: 912.7221\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3795 - val_loss: 912.8544\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3773 - val_loss: 912.9782\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3753 - val_loss: 913.0941\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.3736 - val_loss: 913.2022\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3721 - val_loss: 913.3031\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.3708 - val_loss: 913.3975\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3697 - val_loss: 913.4857\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3688 - val_loss: 913.5676\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3680 - val_loss: 913.6436\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3675 - val_loss: 913.7144\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3670 - val_loss: 913.7800\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.3667 - val_loss: 913.8409\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3665 - val_loss: 913.8973\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.3663 - val_loss: 913.9496\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3663 - val_loss: 913.9979\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3663 - val_loss: 914.0424\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3664 - val_loss: 914.0835\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3667 - val_loss: 914.1212\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3669 - val_loss: 914.1560\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3673 - val_loss: 914.1882\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3676 - val_loss: 914.2174\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.3681 - val_loss: 914.2443\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3685 - val_loss: 914.2689\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3691 - val_loss: 914.2913\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.3696 - val_loss: 914.3113\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3703 - val_loss: 914.3300\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3709 - val_loss: 914.3469\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3715 - val_loss: 914.3620\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3722 - val_loss: 914.3757\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3729 - val_loss: 914.3880\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3736 - val_loss: 914.3990\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3744 - val_loss: 914.4091\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3751 - val_loss: 914.4176\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3759 - val_loss: 914.4257\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3767 - val_loss: 914.4327\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3775 - val_loss: 914.4388\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3783 - val_loss: 914.4439\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.3792 - val_loss: 914.4484\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3800 - val_loss: 914.4521\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3809 - val_loss: 914.4555\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3817 - val_loss: 914.4583\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3826 - val_loss: 914.4605\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.3834 - val_loss: 914.4628\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3843 - val_loss: 914.4640\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.3852 - val_loss: 914.4653\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3860 - val_loss: 914.4657\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3869 - val_loss: 914.4662\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3878 - val_loss: 914.4664\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3886 - val_loss: 914.4661\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3896 - val_loss: 914.4656\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3904 - val_loss: 914.4653\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3913 - val_loss: 914.4647\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3922 - val_loss: 914.4637\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.3931 - val_loss: 914.4630\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3938 - val_loss: 914.4617\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3947 - val_loss: 914.4605\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3955 - val_loss: 914.4590\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3964 - val_loss: 914.4576\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3972 - val_loss: 914.4556\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.3981 - val_loss: 914.4539\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.3989 - val_loss: 914.4520\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3998 - val_loss: 914.4503\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.4005 - val_loss: 914.4482\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4014 - val_loss: 914.4463\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4022 - val_loss: 914.4444\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4030 - val_loss: 914.4426\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4038 - val_loss: 914.4406\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4045 - val_loss: 914.4387\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.4053 - val_loss: 914.4368\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4061 - val_loss: 914.4348\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4068 - val_loss: 914.4324\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4076 - val_loss: 914.4302\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4083 - val_loss: 914.4281\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4091 - val_loss: 914.4262\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4098 - val_loss: 914.4243\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4105 - val_loss: 914.4223\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.4112 - val_loss: 914.4202\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.4120 - val_loss: 914.4184\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4127 - val_loss: 914.4165\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4133 - val_loss: 914.4146\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4140 - val_loss: 914.4125\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4147 - val_loss: 914.4107\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4153 - val_loss: 914.4086\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4160 - val_loss: 914.4065\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4166 - val_loss: 914.4045\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4173 - val_loss: 914.4028\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4179 - val_loss: 914.4012\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4185 - val_loss: 914.3997\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4191 - val_loss: 914.3979\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4197 - val_loss: 914.3959\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4203 - val_loss: 914.3942\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4209 - val_loss: 914.3925\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 20.4215 - val_loss: 914.3904\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.4221 - val_loss: 914.3888\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4226 - val_loss: 914.3871\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4231 - val_loss: 914.3852\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4237 - val_loss: 914.3836\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4242 - val_loss: 914.3820\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 20.4248 - val_loss: 914.3807\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4253 - val_loss: 914.3791\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4258 - val_loss: 914.3774\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4263 - val_loss: 914.3762\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4268 - val_loss: 914.3745\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4273 - val_loss: 914.3730\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4278 - val_loss: 914.3719\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4282 - val_loss: 914.3704\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4286 - val_loss: 914.3690\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.4292 - val_loss: 914.3681\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4295 - val_loss: 914.3664\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4300 - val_loss: 914.3652\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4304 - val_loss: 914.3637\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4308 - val_loss: 914.3626\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4312 - val_loss: 914.3611\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4316 - val_loss: 914.3597\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4320 - val_loss: 914.3583\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4325 - val_loss: 914.3575\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4328 - val_loss: 914.3563\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4332 - val_loss: 914.3549\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4336 - val_loss: 914.3539\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4339 - val_loss: 914.3528\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4343 - val_loss: 914.3516\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.4347 - val_loss: 914.3511\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4350 - val_loss: 914.3497\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4353 - val_loss: 914.3487\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4357 - val_loss: 914.3478\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4360 - val_loss: 914.3470\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4363 - val_loss: 914.3459\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4366 - val_loss: 914.3450\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4370 - val_loss: 914.3441\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4372 - val_loss: 914.3430\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4375 - val_loss: 914.3421\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4378 - val_loss: 914.3411\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4381 - val_loss: 914.3400\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4383 - val_loss: 914.3392\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 20.4387 - val_loss: 914.3384\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.4389 - val_loss: 914.3372\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4392 - val_loss: 914.3365\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4394 - val_loss: 914.3359\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4397 - val_loss: 914.3350\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4400 - val_loss: 914.3347\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4401 - val_loss: 914.3337\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4404 - val_loss: 914.3328\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4406 - val_loss: 914.3320\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4409 - val_loss: 914.3312\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 20.4411 - val_loss: 914.3307\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4413 - val_loss: 914.3298\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4415 - val_loss: 914.3295\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4417 - val_loss: 914.3286\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 20.4419 - val_loss: 914.3281\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4421 - val_loss: 914.3276\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4424 - val_loss: 914.3272\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4425 - val_loss: 914.3267\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4427 - val_loss: 914.3262\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4429 - val_loss: 914.3257\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4430 - val_loss: 914.3250\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4432 - val_loss: 914.3248\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.4434 - val_loss: 914.3241\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4436 - val_loss: 914.3239\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4437 - val_loss: 914.3229\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4439 - val_loss: 914.3227\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4440 - val_loss: 914.3218\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4442 - val_loss: 914.3212\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.4444 - val_loss: 914.3207\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4445 - val_loss: 914.3201\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4446 - val_loss: 914.3195\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4448 - val_loss: 914.3189\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.4450 - val_loss: 914.3187\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4451 - val_loss: 914.3184\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4452 - val_loss: 914.3179\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4453 - val_loss: 914.3175\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4454 - val_loss: 914.3171\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4455 - val_loss: 914.3166\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4457 - val_loss: 914.3161\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4458 - val_loss: 914.3156\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4459 - val_loss: 914.3152\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.4461 - val_loss: 914.3151\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4461 - val_loss: 914.3144\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4463 - val_loss: 914.3141\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4464 - val_loss: 914.3139\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4465 - val_loss: 914.3137\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4465 - val_loss: 914.3132\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4466 - val_loss: 914.3127\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4468 - val_loss: 914.3124\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4468 - val_loss: 914.3120\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4470 - val_loss: 914.3118\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4470 - val_loss: 914.3115\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4471 - val_loss: 914.3114\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4472 - val_loss: 914.3113\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.4472 - val_loss: 914.3105\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4474 - val_loss: 914.3105\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.4475 - val_loss: 914.3102\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4476 - val_loss: 914.3101\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4476 - val_loss: 914.3097\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4477 - val_loss: 914.3094\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4477 - val_loss: 914.3092\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4478 - val_loss: 914.3088\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4479 - val_loss: 914.3085\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4480 - val_loss: 914.3083\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4480 - val_loss: 914.3080\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4481 - val_loss: 914.3079\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4482 - val_loss: 914.3076\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.4482 - val_loss: 914.3071\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4482 - val_loss: 914.3068\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.4484 - val_loss: 914.3066\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4484 - val_loss: 914.3065\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4484 - val_loss: 914.3061\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.4485 - val_loss: 914.3061\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4485 - val_loss: 914.3058\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4486 - val_loss: 914.3054\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4487 - val_loss: 914.3057\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4487 - val_loss: 914.3052\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4487 - val_loss: 914.3052\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4488 - val_loss: 914.3051\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4488 - val_loss: 914.3050\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4489 - val_loss: 914.3047\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4489 - val_loss: 914.3045\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4490 - val_loss: 914.3047\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4490 - val_loss: 914.3038\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4491 - val_loss: 914.3036\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4491 - val_loss: 914.3036\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.4492 - val_loss: 914.3035\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4492 - val_loss: 914.3033\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.4493 - val_loss: 914.3032\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4493 - val_loss: 914.3030\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4493 - val_loss: 914.3031\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4493 - val_loss: 914.3028\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4494 - val_loss: 914.3026\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4494 - val_loss: 914.3023\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4495 - val_loss: 914.3025\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4495 - val_loss: 914.3021\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4495 - val_loss: 914.3021\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4495 - val_loss: 914.3021\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.4496 - val_loss: 914.3019\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4496 - val_loss: 914.3020\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4496 - val_loss: 914.3021\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4496 - val_loss: 914.3021\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4496 - val_loss: 914.3018\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4496 - val_loss: 914.3015\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4497 - val_loss: 914.3015\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4498 - val_loss: 914.3012\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4498 - val_loss: 914.3012\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.4498 - val_loss: 914.3009\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4498 - val_loss: 914.3005\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4499 - val_loss: 914.3006\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4499 - val_loss: 914.3008\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4499 - val_loss: 914.3010\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4500 - val_loss: 914.3011\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4500 - val_loss: 914.3012\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4500 - val_loss: 914.3013\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4500 - val_loss: 914.3011\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4500 - val_loss: 914.3012\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4500 - val_loss: 914.3011\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4500 - val_loss: 914.3007\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4500 - val_loss: 914.3005\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.4500 - val_loss: 914.3004\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4501 - val_loss: 914.2999\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4501 - val_loss: 914.3004\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4501 - val_loss: 914.3005\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4501 - val_loss: 914.3004\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4501 - val_loss: 914.3002\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.4502 - val_loss: 914.3001\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4502 - val_loss: 914.2999\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4502 - val_loss: 914.2999\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4502 - val_loss: 914.3000\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6856, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0008, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0128, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(-2.3003, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 365ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66.7657166 , 66.6757614 , 66.5858435 , 66.4959255 , 66.4060076 ,\n",
       "        66.3160898 , 66.2261719 ,  0.7297765 ,  0.80151224,  0.54776281,\n",
       "         0.12395443,  0.22777341,  0.28028101, 67.5949416 , 67.5050257 ,\n",
       "        67.4151097 , 67.3251937 , 67.2352778 , 67.1453618 , 67.0554458 ,\n",
       "        66.9655299 , 66.8756139 , 66.7856979 , 66.6938632 , 66.599052  ,\n",
       "        66.5039472 , 66.4090893 , 66.3160313 , 66.2231367 , 66.13033   ,\n",
       "        66.0375231 , 65.9447144 , 65.8519046 , 65.7590948 , 65.666285  ,\n",
       "        65.5734752 , 65.4806654 , 65.3878556 , 65.2950458 , 65.202236  ,\n",
       "        65.1094262 , 65.0166164 , 64.9238066 , 64.8309968 , 64.738187  ,\n",
       "        64.6453772 , 64.5525674 , 71.7936975 ,  0.46305758,  0.25501093,\n",
       "         0.        , 70.257633  , 70.1820028 , 73.5080532 , 72.3483193 ,\n",
       "        70.9869748 , 72.9058123 , 71.6256303 , 70.627381  ,  0.08414401,\n",
       "         0.58485156,  0.        , 71.5415966 ,  0.46036336, 72.1802521 ,\n",
       "        70.8189076 , 70.4929272 , 71.457563  , 70.5993697 , 70.372479  ,\n",
       "         0.162238  ,  0.11527097,  0.        , 66.96854401,  0.56379801,\n",
       "         0.        ,  0.        ,  0.        ,  0.0849525 ,  0.        ,\n",
       "        46.28491211,  0.2597965 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.46846864,  0.        ,  0.        ,  0.        ,  0.16479929,\n",
       "         0.        ,  0.91266292,  0.47029522,  0.21254921,  0.34214646,\n",
       "         0.        ,  0.53074151,  0.        ,  0.76576823,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56.83234269, 56.82004509, 56.80774749, 56.79544989, 56.78315229,\n",
       "       56.77085468, 56.75855708, 56.74625948, 56.73396188, 56.72166428,\n",
       "       56.70936667, 56.69706907, 56.68477147, 56.67247387, 56.66017627,\n",
       "       56.64787866, 56.63558106, 56.62328346, 56.61098586, 56.59868826,\n",
       "       56.58639065, 56.57409305, 56.56179545, 56.54949785, 56.53720025,\n",
       "       56.52490264, 56.51260504, 56.50030744, 56.48800984, 56.47571224,\n",
       "       56.46341463, 56.45111703, 56.43881943, 56.42652183, 56.41422423,\n",
       "       56.40192662, 56.38962902, 56.37733142, 56.36503382, 56.35273622,\n",
       "       56.34043861, 56.32814101, 56.31584341, 56.30354581, 56.29124821,\n",
       "       56.2789506 , 56.266653  , 56.2543554 , 56.2420578 , 56.2297602 ,\n",
       "       56.21746259, 56.20516499, 56.19286739, 56.18056979, 56.16827219,\n",
       "       56.15597458, 56.14367698, 56.13137938, 56.11908178, 56.10678418,\n",
       "       56.09448658, 56.08218897, 56.06989137, 56.05759377, 56.04529617,\n",
       "       56.03299857, 56.02070096, 56.00840336, 55.99610576, 55.98380816,\n",
       "       55.97151056, 55.95921295, 55.94691535, 55.93461775, 55.92232015,\n",
       "       55.91002255, 55.89772494, 55.88542734, 55.87312974, 55.86083214,\n",
       "       55.84853454, 55.83623693, 55.82393933, 55.81164173, 55.79934413,\n",
       "       55.78704653, 55.77474892, 55.76245132, 55.75015372, 55.73785612,\n",
       "       55.72555852, 55.71326091, 55.70096331, 55.68866571, 55.67636811,\n",
       "       55.66407051, 55.6517729 , 55.6394753 , 55.6271777 , 55.6148801 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.76996730940694\n",
      "29.45044395719707\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
