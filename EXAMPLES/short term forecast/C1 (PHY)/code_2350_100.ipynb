{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2445    52.672228\n",
       "2446    52.663483\n",
       "2447    52.654738\n",
       "2448    52.645993\n",
       "2449    52.637248\n",
       "Name: C1, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_2350_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "2345     0.000000\n",
       "2346     0.000000\n",
       "2347     0.000000\n",
       "2348     0.000000\n",
       "2349     0.002856\n",
       "Name: C1, Length: 2350, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2350)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 1, 251) (1900, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 2s 23ms/step - loss: 4330.6553 - val_loss: 2849.9424\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4232.9741 - val_loss: 2806.7007\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4165.6270 - val_loss: 2765.4343\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4102.9570 - val_loss: 2725.2861\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4041.4746 - val_loss: 2685.9001\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3981.0112 - val_loss: 2647.0330\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3916.1829 - val_loss: 2604.6907\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3851.6370 - val_loss: 2564.5171\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3789.2668 - val_loss: 2525.3721\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 3728.3394 - val_loss: 2487.0332\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3668.5481 - val_loss: 2449.3838\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3609.7332 - val_loss: 2412.3608\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3551.8032 - val_loss: 2375.9241\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3494.7014 - val_loss: 2340.0466\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3438.3872 - val_loss: 2304.7092\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3382.8303 - val_loss: 2269.8955\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3328.0083 - val_loss: 2235.5930\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3273.9016 - val_loss: 2201.7905\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3220.4937 - val_loss: 2168.4780\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3167.7715 - val_loss: 2135.6453\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3115.7231 - val_loss: 2103.2686\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3061.8467 - val_loss: 2066.0518\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3002.0007 - val_loss: 2029.3636\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2945.2244 - val_loss: 1994.4535\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2890.6289 - val_loss: 1960.8051\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2837.5864 - val_loss: 1928.1079\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2785.7649 - val_loss: 1896.2021\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2734.9871 - val_loss: 1864.9963\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2685.1465 - val_loss: 1834.4310\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 2636.1711 - val_loss: 1804.4651\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2588.0095 - val_loss: 1775.0671\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2540.6228 - val_loss: 1746.2131\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2493.9800 - val_loss: 1717.8837\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2448.0557 - val_loss: 1690.0626\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2402.8291 - val_loss: 1662.7358\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2358.2820 - val_loss: 1635.8912\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2314.3989 - val_loss: 1609.5184\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2271.1648 - val_loss: 1583.6075\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2228.5679 - val_loss: 1558.1497\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2186.5964 - val_loss: 1533.1373\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2145.2393 - val_loss: 1508.5625\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2104.4871 - val_loss: 1484.4185\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2064.3301 - val_loss: 1460.6984\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2024.7603 - val_loss: 1437.3964\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1985.7688 - val_loss: 1414.5066\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1947.3481 - val_loss: 1392.0228\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1909.4905 - val_loss: 1369.9402\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1872.1899 - val_loss: 1348.2529\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1835.4380 - val_loss: 1326.9564\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1799.2288 - val_loss: 1306.0454\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1763.5554 - val_loss: 1285.5151\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1728.4122 - val_loss: 1265.3612\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1693.7922 - val_loss: 1245.5790\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1659.6899 - val_loss: 1226.1639\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1626.1005 - val_loss: 1207.1116\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1593.0172 - val_loss: 1188.4181\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1560.4348 - val_loss: 1170.0791\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1528.3479 - val_loss: 1152.0901\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1496.7510 - val_loss: 1134.4478\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1465.6387 - val_loss: 1117.1476\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1435.0060 - val_loss: 1100.1859\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1404.8484 - val_loss: 1083.5587\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1375.1603 - val_loss: 1067.2625\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1345.9371 - val_loss: 1051.2931\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1317.1738 - val_loss: 1035.6470\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1288.8656 - val_loss: 1020.3203\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1261.0078 - val_loss: 1005.3096\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1233.5958 - val_loss: 990.6115\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1206.6252 - val_loss: 976.2220\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1180.0908 - val_loss: 962.1379\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1153.9889 - val_loss: 948.3556\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1128.3147 - val_loss: 934.8712\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1103.0630 - val_loss: 921.6818\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1078.2306 - val_loss: 908.7839\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1053.8125 - val_loss: 896.1740\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1029.8046 - val_loss: 883.8486\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1006.2026 - val_loss: 871.8046\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 983.0020 - val_loss: 860.0386\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 960.1994 - val_loss: 848.5473\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 937.7898 - val_loss: 837.3275\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 915.7693 - val_loss: 826.3758\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 894.1340 - val_loss: 815.6891\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 872.8798 - val_loss: 805.2640\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 852.0024 - val_loss: 795.0973\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 831.4981 - val_loss: 785.1860\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 811.3624 - val_loss: 775.5267\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 791.5914 - val_loss: 766.1162\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 772.1816 - val_loss: 756.9517\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 753.1290 - val_loss: 748.0299\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 734.4294 - val_loss: 739.3473\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 716.0788 - val_loss: 730.9014\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 698.0737 - val_loss: 722.6889\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 680.4102 - val_loss: 714.7064\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 663.0840 - val_loss: 706.9509\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 646.0919 - val_loss: 699.4197\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 629.4295 - val_loss: 692.1094\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 613.0937 - val_loss: 685.0172\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 597.0801 - val_loss: 678.1397\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 581.3853 - val_loss: 671.4742\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 566.0052 - val_loss: 665.0176\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 550.9368 - val_loss: 658.7667\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 536.1755 - val_loss: 652.7188\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 521.7182 - val_loss: 646.8705\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 507.5611 - val_loss: 641.2192\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 493.7002 - val_loss: 635.7617\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 480.1322 - val_loss: 630.4948\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 466.8532 - val_loss: 625.4161\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 453.8596 - val_loss: 620.5220\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 441.1481 - val_loss: 615.8101\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 428.7146 - val_loss: 611.2772\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 416.5559 - val_loss: 606.9202\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 404.6680 - val_loss: 602.7364\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 393.0478 - val_loss: 598.7227\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 381.6913 - val_loss: 594.8763\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 370.5950 - val_loss: 591.1940\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 359.7556 - val_loss: 587.6732\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 349.1689 - val_loss: 584.3107\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 338.8319 - val_loss: 581.1038\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 328.7411 - val_loss: 578.0495\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 318.8930 - val_loss: 575.1450\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 309.2837 - val_loss: 572.3873\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 299.9101 - val_loss: 569.7737\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 290.7687 - val_loss: 567.3010\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 281.8560 - val_loss: 564.9666\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 273.1682 - val_loss: 562.7675\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 264.7018 - val_loss: 560.7008\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 256.4536 - val_loss: 558.7638\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 248.4203 - val_loss: 556.9536\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 240.5981 - val_loss: 555.2673\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 232.9839 - val_loss: 553.7020\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 225.5737 - val_loss: 552.2551\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 218.3648 - val_loss: 550.9236\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 211.3535 - val_loss: 549.7050\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 204.5365 - val_loss: 548.5961\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 197.9104 - val_loss: 547.5942\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 191.4715 - val_loss: 546.6968\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 185.2169 - val_loss: 545.9010\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 179.1432 - val_loss: 545.2040\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 173.2472 - val_loss: 544.6031\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 167.5254 - val_loss: 544.0956\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.9745 - val_loss: 543.6788\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 156.5912 - val_loss: 543.3499\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 151.3724 - val_loss: 543.1063\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 146.3145 - val_loss: 542.9454\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 141.4146 - val_loss: 542.8644\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 136.6694 - val_loss: 542.8610\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 132.0758 - val_loss: 542.9321\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 127.6304 - val_loss: 543.0754\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 123.3300 - val_loss: 543.2883\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 119.1718 - val_loss: 543.5682\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 115.1525 - val_loss: 543.9126\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 111.2689 - val_loss: 544.3189\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 107.5181 - val_loss: 544.7849\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 103.8969 - val_loss: 545.3077\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 100.4025 - val_loss: 545.8851\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 97.0315 - val_loss: 546.5148\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 93.7813 - val_loss: 547.1942\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 90.6488 - val_loss: 547.9210\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 87.6310 - val_loss: 548.6929\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 84.7251 - val_loss: 549.5075\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 81.9282 - val_loss: 550.3625\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 79.2375 - val_loss: 551.2558\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 76.6501 - val_loss: 552.1851\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 74.1631 - val_loss: 553.1483\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 71.7739 - val_loss: 554.1432\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 69.4798 - val_loss: 555.1675\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 67.2781 - val_loss: 556.2194\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 65.1661 - val_loss: 557.2967\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 63.1411 - val_loss: 558.3973\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 61.2006 - val_loss: 559.5195\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 59.3421 - val_loss: 560.6612\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 57.5629 - val_loss: 561.8206\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 55.8607 - val_loss: 562.9956\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 54.2329 - val_loss: 564.1846\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 52.6773 - val_loss: 565.3858\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 51.1914 - val_loss: 566.5975\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 49.7728 - val_loss: 567.8179\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 48.4194 - val_loss: 569.0455\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 47.1288 - val_loss: 570.2786\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 45.8989 - val_loss: 571.5158\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 44.7275 - val_loss: 572.7554\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 43.6124 - val_loss: 573.9960\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 42.5517 - val_loss: 575.2363\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 41.5433 - val_loss: 576.4747\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 40.5852 - val_loss: 577.7103\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 39.6755 - val_loss: 578.9413\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 38.8122 - val_loss: 580.1669\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 37.9935 - val_loss: 581.3858\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 37.2176 - val_loss: 582.5967\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 36.4828 - val_loss: 583.7987\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 35.7873 - val_loss: 584.9908\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 35.1295 - val_loss: 586.1719\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 34.5077 - val_loss: 587.3413\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 33.9204 - val_loss: 588.4978\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 33.3660 - val_loss: 589.6409\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 32.8429 - val_loss: 590.7695\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 32.3500 - val_loss: 591.8829\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 31.8856 - val_loss: 592.9807\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 31.4485 - val_loss: 594.0619\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 31.0374 - val_loss: 595.1263\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 30.6509 - val_loss: 596.1730\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 30.2878 - val_loss: 597.2016\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 29.9470 - val_loss: 598.2117\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 29.6274 - val_loss: 599.2028\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 29.3278 - val_loss: 600.1745\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 29.0472 - val_loss: 601.1267\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 28.7845 - val_loss: 602.0589\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 28.5389 - val_loss: 602.9708\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 28.3094 - val_loss: 603.8624\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 28.0950 - val_loss: 604.7334\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 27.8950 - val_loss: 605.5836\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 27.7084 - val_loss: 606.4131\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 27.5346 - val_loss: 607.2216\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 27.3727 - val_loss: 608.0093\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 27.2221 - val_loss: 608.7759\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 27.0821 - val_loss: 609.5219\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 26.9520 - val_loss: 610.2469\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 26.8313 - val_loss: 610.9510\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 26.7193 - val_loss: 611.6347\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 26.6154 - val_loss: 612.2980\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 26.5192 - val_loss: 612.9409\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 26.4302 - val_loss: 613.5637\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 26.3478 - val_loss: 614.1666\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 26.2716 - val_loss: 614.7500\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 26.2013 - val_loss: 615.3139\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 26.1364 - val_loss: 615.8587\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 26.0765 - val_loss: 616.3850\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 26.0213 - val_loss: 616.8926\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.9704 - val_loss: 617.3819\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.9236 - val_loss: 617.8534\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.8805 - val_loss: 618.3075\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.8410 - val_loss: 618.7442\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.8046 - val_loss: 619.1644\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.7712 - val_loss: 619.5682\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.7406 - val_loss: 619.9558\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.7125 - val_loss: 620.3278\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.6868 - val_loss: 620.6848\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.6632 - val_loss: 621.0267\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.6416 - val_loss: 621.3542\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 25.6219 - val_loss: 621.6677\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.6038 - val_loss: 621.9675\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.5874 - val_loss: 622.2542\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.5724 - val_loss: 622.5280\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.5586 - val_loss: 622.7894\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.5462 - val_loss: 623.0388\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.5348 - val_loss: 623.2766\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.5244 - val_loss: 623.5029\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.5149 - val_loss: 623.7185\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 25.5063 - val_loss: 623.9235\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4986 - val_loss: 624.1186\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4915 - val_loss: 624.3038\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4851 - val_loss: 624.4799\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4793 - val_loss: 624.6469\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 25.4740 - val_loss: 624.8049\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4693 - val_loss: 624.9551\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4649 - val_loss: 625.0970\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4611 - val_loss: 625.2314\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4576 - val_loss: 625.3586\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4545 - val_loss: 625.4787\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4517 - val_loss: 625.5922\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4492 - val_loss: 625.6993\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4469 - val_loss: 625.8005\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4449 - val_loss: 625.8956\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4432 - val_loss: 625.9851\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4416 - val_loss: 626.0697\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4402 - val_loss: 626.1491\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4391 - val_loss: 626.2239\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4380 - val_loss: 626.2940\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4371 - val_loss: 626.3595\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4363 - val_loss: 626.4213\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4357 - val_loss: 626.4791\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4352 - val_loss: 626.5332\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4347 - val_loss: 626.5838\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4344 - val_loss: 626.6313\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4342 - val_loss: 626.6756\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4340 - val_loss: 626.7166\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 25.4339 - val_loss: 626.7551\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4339 - val_loss: 626.7911\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4339 - val_loss: 626.8245\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4340 - val_loss: 626.8555\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4341 - val_loss: 626.8843\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4343 - val_loss: 626.9113\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4345 - val_loss: 626.9360\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4347 - val_loss: 626.9590\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4351 - val_loss: 626.9803\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4354 - val_loss: 626.9999\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4358 - val_loss: 627.0184\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4362 - val_loss: 627.0351\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4366 - val_loss: 627.0505\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4370 - val_loss: 627.0648\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4375 - val_loss: 627.0779\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4379 - val_loss: 627.0898\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4384 - val_loss: 627.1006\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4389 - val_loss: 627.1109\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4395 - val_loss: 627.1202\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4400 - val_loss: 627.1285\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4405 - val_loss: 627.1364\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4410 - val_loss: 627.1432\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4416 - val_loss: 627.1494\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 25.4421 - val_loss: 627.1549\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4428 - val_loss: 627.1602\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4433 - val_loss: 627.1648\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4439 - val_loss: 627.1688\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4444 - val_loss: 627.1723\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4450 - val_loss: 627.1756\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4456 - val_loss: 627.1783\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4462 - val_loss: 627.1809\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4467 - val_loss: 627.1830\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4473 - val_loss: 627.1851\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4479 - val_loss: 627.1866\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4485 - val_loss: 627.1879\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4490 - val_loss: 627.1890\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4496 - val_loss: 627.1899\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4502 - val_loss: 627.1906\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4508 - val_loss: 627.1912\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4513 - val_loss: 627.1916\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4518 - val_loss: 627.1918\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4524 - val_loss: 627.1920\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4529 - val_loss: 627.1918\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4535 - val_loss: 627.1917\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4540 - val_loss: 627.1912\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4545 - val_loss: 627.1910\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4551 - val_loss: 627.1903\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 25.4556 - val_loss: 627.1896\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4561 - val_loss: 627.1891\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4566 - val_loss: 627.1883\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4571 - val_loss: 627.1877\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4577 - val_loss: 627.1873\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4581 - val_loss: 627.1863\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4586 - val_loss: 627.1855\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4590 - val_loss: 627.1848\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4595 - val_loss: 627.1839\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4600 - val_loss: 627.1831\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4604 - val_loss: 627.1821\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4609 - val_loss: 627.1810\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4613 - val_loss: 627.1799\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4618 - val_loss: 627.1790\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4622 - val_loss: 627.1782\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4626 - val_loss: 627.1771\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4630 - val_loss: 627.1762\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4635 - val_loss: 627.1752\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4638 - val_loss: 627.1743\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4643 - val_loss: 627.1733\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4646 - val_loss: 627.1726\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4650 - val_loss: 627.1716\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 25.4654 - val_loss: 627.1706\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 25.4657 - val_loss: 627.1696\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4661 - val_loss: 627.1686\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4665 - val_loss: 627.1678\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4668 - val_loss: 627.1666\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4672 - val_loss: 627.1657\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4675 - val_loss: 627.1646\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4678 - val_loss: 627.1636\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4682 - val_loss: 627.1627\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4685 - val_loss: 627.1619\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4688 - val_loss: 627.1608\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4691 - val_loss: 627.1601\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4694 - val_loss: 627.1592\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4697 - val_loss: 627.1584\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4700 - val_loss: 627.1577\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4703 - val_loss: 627.1570\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4705 - val_loss: 627.1561\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4708 - val_loss: 627.1553\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4711 - val_loss: 627.1543\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 25.4714 - val_loss: 627.1534\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4717 - val_loss: 627.1530\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4719 - val_loss: 627.1520\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4721 - val_loss: 627.1512\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 25.4724 - val_loss: 627.1504\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4727 - val_loss: 627.1499\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4729 - val_loss: 627.1492\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4731 - val_loss: 627.1484\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4733 - val_loss: 627.1478\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4735 - val_loss: 627.1472\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4738 - val_loss: 627.1465\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4740 - val_loss: 627.1460\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4742 - val_loss: 627.1453\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4744 - val_loss: 627.1447\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4746 - val_loss: 627.1443\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4748 - val_loss: 627.1437\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4750 - val_loss: 627.1432\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4752 - val_loss: 627.1428\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4753 - val_loss: 627.1421\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4756 - val_loss: 627.1418\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4757 - val_loss: 627.1409\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4759 - val_loss: 627.1407\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4761 - val_loss: 627.1402\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4762 - val_loss: 627.1392\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4764 - val_loss: 627.1389\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4765 - val_loss: 627.1384\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4767 - val_loss: 627.1376\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 25.4769 - val_loss: 627.1373\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4770 - val_loss: 627.1368\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4772 - val_loss: 627.1365\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4773 - val_loss: 627.1362\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4775 - val_loss: 627.1358\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4776 - val_loss: 627.1353\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4777 - val_loss: 627.1349\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4778 - val_loss: 627.1346\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4780 - val_loss: 627.1342\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4781 - val_loss: 627.1337\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4782 - val_loss: 627.1335\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4783 - val_loss: 627.1331\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4784 - val_loss: 627.1328\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4785 - val_loss: 627.1324\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4786 - val_loss: 627.1321\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4788 - val_loss: 627.1317\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4788 - val_loss: 627.1312\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4790 - val_loss: 627.1311\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4791 - val_loss: 627.1307\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4792 - val_loss: 627.1306\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 25.4792 - val_loss: 627.1301\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4793 - val_loss: 627.1297\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4795 - val_loss: 627.1295\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4796 - val_loss: 627.1293\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4796 - val_loss: 627.1290\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4797 - val_loss: 627.1288\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4798 - val_loss: 627.1286\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4799 - val_loss: 627.1283\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4800 - val_loss: 627.1279\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4800 - val_loss: 627.1276\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4801 - val_loss: 627.1271\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4802 - val_loss: 627.1269\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4803 - val_loss: 627.1266\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4804 - val_loss: 627.1263\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4804 - val_loss: 627.1260\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4805 - val_loss: 627.1258\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4805 - val_loss: 627.1256\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 25.4806 - val_loss: 627.1254\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4807 - val_loss: 627.1251\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4808 - val_loss: 627.1248\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4808 - val_loss: 627.1248\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4809 - val_loss: 627.1246\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 25.4810 - val_loss: 627.1245\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4810 - val_loss: 627.1242\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4811 - val_loss: 627.1241\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4811 - val_loss: 627.1239\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4811 - val_loss: 627.1238\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4812 - val_loss: 627.1235\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4813 - val_loss: 627.1233\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4813 - val_loss: 627.1230\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4813 - val_loss: 627.1229\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4814 - val_loss: 627.1226\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4815 - val_loss: 627.1226\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4815 - val_loss: 627.1223\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4815 - val_loss: 627.1220\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4816 - val_loss: 627.1219\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4816 - val_loss: 627.1219\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4817 - val_loss: 627.1218\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4817 - val_loss: 627.1217\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4818 - val_loss: 627.1215\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4817 - val_loss: 627.1212\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4818 - val_loss: 627.1210\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4819 - val_loss: 627.1208\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 25.4819 - val_loss: 627.1210\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4819 - val_loss: 627.1207\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4820 - val_loss: 627.1204\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4820 - val_loss: 627.1204\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4821 - val_loss: 627.1204\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4821 - val_loss: 627.1203\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4821 - val_loss: 627.1203\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4821 - val_loss: 627.1201\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4821 - val_loss: 627.1199\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4822 - val_loss: 627.1197\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4822 - val_loss: 627.1198\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4823 - val_loss: 627.1196\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4823 - val_loss: 627.1196\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4823 - val_loss: 627.1195\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4823 - val_loss: 627.1194\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4824 - val_loss: 627.1193\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4824 - val_loss: 627.1193\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4824 - val_loss: 627.1191\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4824 - val_loss: 627.1190\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4824 - val_loss: 627.1188\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4825 - val_loss: 627.1188\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 25.4825 - val_loss: 627.1187\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4825 - val_loss: 627.1187\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4825 - val_loss: 627.1187\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4825 - val_loss: 627.1186\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4825 - val_loss: 627.1181\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4826 - val_loss: 627.1177\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4826 - val_loss: 627.1178\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4827 - val_loss: 627.1177\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4827 - val_loss: 627.1181\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4827 - val_loss: 627.1179\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4827 - val_loss: 627.1177\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4827 - val_loss: 627.1174\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4827 - val_loss: 627.1176\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4827 - val_loss: 627.1177\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4827 - val_loss: 627.1177\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4828 - val_loss: 627.1176\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4828 - val_loss: 627.1174\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4828 - val_loss: 627.1176\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4828 - val_loss: 627.1177\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4828 - val_loss: 627.1176\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4828 - val_loss: 627.1172\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 25.4828 - val_loss: 627.1171\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4829 - val_loss: 627.1171\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4829 - val_loss: 627.1172\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.4829 - val_loss: 627.1171\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 374ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.12713492e+01, 6.12144118e+01, 6.11387815e+01, 6.10631513e+01,\n",
       "        6.09875210e+01, 6.09118908e+01, 6.08362605e+01, 0.00000000e+00,\n",
       "        1.39610020e-01, 9.62131260e-01, 1.37028400e-01, 2.83495400e-01,\n",
       "        0.00000000e+00, 6.15348413e+01, 6.15062698e+01, 6.14776984e+01,\n",
       "        6.14491270e+01, 6.14205556e+01, 6.13919841e+01, 6.13634127e+01,\n",
       "        6.13348413e+01, 6.13062698e+01, 6.12776984e+01, 6.12312185e+01,\n",
       "        6.11555882e+01, 6.10799580e+01, 6.10043277e+01, 6.09286975e+01,\n",
       "        6.08530672e+01, 6.07774370e+01, 6.07018067e+01, 6.06261765e+01,\n",
       "        6.05505462e+01, 6.04749160e+01, 6.03992857e+01, 6.03414239e+01,\n",
       "        6.03027684e+01, 6.02641130e+01, 6.02254575e+01, 6.01868020e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.06146836e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.10967647e+01,\n",
       "        6.10211344e+01, 6.09455042e+01, 6.08698739e+01, 6.07942437e+01,\n",
       "        6.07186134e+01, 6.06429832e+01, 6.05673529e+01, 6.04917227e+01,\n",
       "        6.04160924e+01, 6.03500140e+01, 6.03113585e+01, 6.02727031e+01,\n",
       "        6.02340476e+01, 6.01953922e+01, 6.23619748e+01, 6.23367647e+01,\n",
       "        6.23115546e+01, 6.22044118e+01, 6.20279412e+01, 6.18514706e+01,\n",
       "        6.16750000e+01, 6.15507143e+01, 6.14650000e+01, 0.00000000e+00,\n",
       "        3.87423250e-01, 6.73441391e+01, 7.93554664e-01, 5.52420170e-02,\n",
       "        3.19308549e-01, 4.61831361e-01, 3.84850621e-01, 0.00000000e+00,\n",
       "        5.15804634e+01, 8.33904803e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.76697481e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.06405020e-01, 0.00000000e+00, 7.18795657e-02, 0.00000000e+00,\n",
       "        7.42261052e-01, 3.44342828e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.68902141e-02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53.50299925, 53.49425429, 53.48550933, 53.47676436, 53.4680194 ,\n",
       "       53.45927444, 53.45052948, 53.44178452, 53.43303956, 53.4242946 ,\n",
       "       53.41554963, 53.40680467, 53.39805971, 53.38931475, 53.38056979,\n",
       "       53.37182483, 53.36307987, 53.3543349 , 53.34558994, 53.33684498,\n",
       "       53.32810002, 53.31935506, 53.3106101 , 53.30186514, 53.29312017,\n",
       "       53.28437521, 53.27563025, 53.26688529, 53.25814033, 53.24939537,\n",
       "       53.24065041, 53.23190545, 53.22316048, 53.21441552, 53.20567056,\n",
       "       53.1969256 , 53.18818064, 53.17943568, 53.17069072, 53.16194575,\n",
       "       53.15320079, 53.14445583, 53.13571087, 53.12696591, 53.11822095,\n",
       "       53.10947599, 53.10073102, 53.09198606, 53.0832411 , 53.07449614,\n",
       "       53.06575118, 53.05700622, 53.04826126, 53.03951629, 53.03077133,\n",
       "       53.02202637, 53.01328141, 53.00453645, 52.99579149, 52.98704653,\n",
       "       52.97830156, 52.9695566 , 52.96081164, 52.95206668, 52.94332172,\n",
       "       52.93457676, 52.9258318 , 52.91708683, 52.90834187, 52.89959691,\n",
       "       52.89085195, 52.88210699, 52.87336203, 52.86461707, 52.8558721 ,\n",
       "       52.84712714, 52.83838218, 52.82963722, 52.82089226, 52.8121473 ,\n",
       "       52.80340234, 52.79465738, 52.78591241, 52.77716745, 52.76842249,\n",
       "       52.75967753, 52.75093257, 52.74218761, 52.73344265, 52.72469768,\n",
       "       52.71595272, 52.70720776, 52.6984628 , 52.68971784, 52.68097288,\n",
       "       52.67222792, 52.66348295, 52.65473799, 52.64599303, 52.63724807])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.91355559592825\n",
      "25.795492445096087\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
