{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1845    59.558754\n",
       "1846    59.548483\n",
       "1847    59.538212\n",
       "1848    59.527941\n",
       "1849    59.517670\n",
       "Name: C1, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c1_interpolated_1750_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.200000\n",
       "1       88.931092\n",
       "2       88.662185\n",
       "3       88.393277\n",
       "4       88.124370\n",
       "          ...    \n",
       "1745    60.186802\n",
       "1746    60.182507\n",
       "1747    60.178212\n",
       "1748    60.173917\n",
       "1749    60.169622\n",
       "Name: C1, Length: 1750, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1750)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.931092</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.662185</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.393277</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.124370</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.200000  0.000298\n",
       "1     88.931092  0.000298\n",
       "2     88.662185  0.000297\n",
       "3     88.393277  0.000297\n",
       "4     88.124370  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.6465  # Value for C0\n",
    "K0 = -0.0029  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0168    # Value for b\n",
    "c = 2.3581    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.200000    88.931092    88.662185    88.393277    88.124370   \n",
      "351    88.931092    88.662185    88.393277    88.124370    87.855462   \n",
      "352    88.662185    88.393277    88.124370    87.855462    87.586555   \n",
      "353    88.393277    88.124370    87.855462    87.586555    87.317647   \n",
      "354    88.124370    87.855462    87.586555    87.317647    87.048739   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.855462    87.586555    87.317647    87.048739    86.794538  ...   \n",
      "351    87.586555    87.317647    87.048739    86.794538    86.721709  ...   \n",
      "352    87.317647    87.048739    86.794538    86.721709    86.648880  ...   \n",
      "353    87.048739    86.794538    86.721709    86.648880    86.576050  ...   \n",
      "354    86.794538    86.721709    86.648880    86.576050    86.503221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   73.989683    0.000263   73.957937    0.000263   73.926190    0.000263   \n",
      "351   73.957937    0.000263   73.926190    0.000263   73.894444    0.000262   \n",
      "352   73.926190    0.000263   73.894444    0.000262   73.862698    0.000262   \n",
      "353   73.894444    0.000262   73.862698    0.000262   73.830952    0.000262   \n",
      "354   73.862698    0.000262   73.830952    0.000262   73.799206    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   73.894444    0.000262   73.862698    0.000262  \n",
      "351   73.862698    0.000262   73.830952    0.000262  \n",
      "352   73.830952    0.000262   73.799206    0.000262  \n",
      "353   73.799206    0.000262   73.767460    0.000262  \n",
      "354   73.767460    0.000262   73.735714    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 1, 251) (1300, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 3s 31ms/step - loss: 4569.1860 - val_loss: 3627.6514\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4455.0981 - val_loss: 3556.9468\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4385.2158 - val_loss: 3500.2490\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4322.5381 - val_loss: 3444.3838\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4260.8076 - val_loss: 3389.4141\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4199.8848 - val_loss: 3334.2822\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4137.4746 - val_loss: 3277.8459\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4074.8774 - val_loss: 3222.3242\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4013.4114 - val_loss: 3167.8760\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3953.0217 - val_loss: 3114.3618\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3893.5710 - val_loss: 3061.6829\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3834.9675 - val_loss: 3009.7756\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3777.1541 - val_loss: 2958.5994\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3720.0913 - val_loss: 2908.1245\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3663.7520 - val_loss: 2858.3291\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3608.1133 - val_loss: 2809.1956\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3553.1587 - val_loss: 2760.7085\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 3498.8735 - val_loss: 2712.8572\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3445.2451 - val_loss: 2665.6301\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3392.2629 - val_loss: 2619.0176\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3339.9175 - val_loss: 2573.0112\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3288.1997 - val_loss: 2527.6030\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3237.1016 - val_loss: 2482.7852\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3186.6162 - val_loss: 2438.5515\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3136.7351 - val_loss: 2394.8943\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 3087.4534 - val_loss: 2351.8079\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3038.7622 - val_loss: 2309.2861\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2990.6580 - val_loss: 2267.3228\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2943.1333 - val_loss: 2225.9121\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2896.1819 - val_loss: 2185.0493\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2849.8000 - val_loss: 2144.7288\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2803.9807 - val_loss: 2104.9443\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2758.7192 - val_loss: 2065.6924\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 2714.0098 - val_loss: 2026.9656\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2669.8481 - val_loss: 1988.7610\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 2626.2283 - val_loss: 1951.0731\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2583.1467 - val_loss: 1913.8971\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2540.5969 - val_loss: 1877.2279\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 2498.5752 - val_loss: 1841.0613\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2457.0771 - val_loss: 1805.3921\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 2416.0969 - val_loss: 1770.2164\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 2375.6313 - val_loss: 1735.5297\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 2335.6746 - val_loss: 1701.3267\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2296.2224 - val_loss: 1667.6042\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2257.2712 - val_loss: 1634.3557\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2218.8159 - val_loss: 1601.5796\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2180.8525 - val_loss: 1569.2703\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2143.3762 - val_loss: 1537.4226\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2106.3831 - val_loss: 1506.0344\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2069.8694 - val_loss: 1475.0994\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2033.8301 - val_loss: 1444.6144\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1998.2617 - val_loss: 1414.5754\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1963.1594 - val_loss: 1384.9789\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1928.5200 - val_loss: 1355.8193\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1894.3390 - val_loss: 1327.0936\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1860.6118 - val_loss: 1298.7975\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1827.3351 - val_loss: 1270.9269\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1794.5048 - val_loss: 1243.4784\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1762.1171 - val_loss: 1216.4473\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1730.1676 - val_loss: 1189.8307\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1698.6530 - val_loss: 1163.6234\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1667.5690 - val_loss: 1137.8229\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1636.9116 - val_loss: 1112.4241\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1606.6777 - val_loss: 1087.4244\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1576.8635 - val_loss: 1062.8198\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1547.4648 - val_loss: 1038.6061\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1518.4784 - val_loss: 1014.7791\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1489.8992 - val_loss: 991.3360\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1461.7245 - val_loss: 968.2725\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1433.9508 - val_loss: 945.5850\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1406.5743 - val_loss: 923.2708\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1379.5914 - val_loss: 901.3251\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1352.9983 - val_loss: 879.7445\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1326.7915 - val_loss: 858.5255\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1300.9669 - val_loss: 837.6650\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1275.5219 - val_loss: 817.1583\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1250.4523 - val_loss: 797.0029\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1225.7548 - val_loss: 777.1949\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1201.4258 - val_loss: 757.7303\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1177.4620 - val_loss: 738.6068\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1153.8596 - val_loss: 719.8192\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1130.6152 - val_loss: 701.3660\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1107.7261 - val_loss: 683.2420\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1085.1880 - val_loss: 665.4450\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1062.9979 - val_loss: 647.9712\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1041.1523 - val_loss: 630.8165\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1019.6478 - val_loss: 613.9788\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 998.4816 - val_loss: 597.4529\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 977.6494 - val_loss: 581.2375\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 957.1484 - val_loss: 565.3282\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 936.9750 - val_loss: 549.7214\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 917.1266 - val_loss: 534.4140\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 897.5992 - val_loss: 519.4033\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 878.3898 - val_loss: 504.6850\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 859.4952 - val_loss: 490.2568\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 840.9122 - val_loss: 476.1143\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 822.6372 - val_loss: 462.2550\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 804.6676 - val_loss: 448.6758\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 786.9999 - val_loss: 435.3727\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 769.6305 - val_loss: 422.3434\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 752.5569 - val_loss: 409.5842\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 735.7756 - val_loss: 397.0920\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 719.2837 - val_loss: 384.8631\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 703.0775 - val_loss: 372.8951\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 687.1546 - val_loss: 361.1848\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 671.5117 - val_loss: 349.7285\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 656.1452 - val_loss: 338.5235\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 641.0526 - val_loss: 327.5660\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 626.2302 - val_loss: 316.8534\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 611.6755 - val_loss: 306.3828\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 597.3853 - val_loss: 296.1511\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 583.3568 - val_loss: 286.1545\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 569.5862 - val_loss: 276.3909\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 556.0718 - val_loss: 266.8566\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 542.8094 - val_loss: 257.5486\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 529.7963 - val_loss: 248.4638\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 517.0299 - val_loss: 239.5998\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 504.5071 - val_loss: 230.9529\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 492.2246 - val_loss: 222.5202\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 480.1797 - val_loss: 214.2989\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 468.3695 - val_loss: 206.2856\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 456.7908 - val_loss: 198.4780\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 445.4412 - val_loss: 190.8731\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 434.3174 - val_loss: 183.4671\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 423.4167 - val_loss: 176.2578\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 412.7362 - val_loss: 169.2424\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 402.2733 - val_loss: 162.4176\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 392.0247 - val_loss: 155.7806\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 381.9875 - val_loss: 149.3286\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 372.1595 - val_loss: 143.0584\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 362.5374 - val_loss: 136.9676\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 353.1184 - val_loss: 131.0533\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 343.8998 - val_loss: 125.3120\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 334.8787 - val_loss: 119.7416\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 326.0527 - val_loss: 114.3391\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 317.4189 - val_loss: 109.1016\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 308.9745 - val_loss: 104.0268\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 300.7168 - val_loss: 99.1108\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 292.6429 - val_loss: 94.3520\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 284.7503 - val_loss: 89.7471\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 277.0364 - val_loss: 85.2938\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 269.4984 - val_loss: 80.9887\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 262.1338 - val_loss: 76.8298\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 254.9397 - val_loss: 72.8139\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 247.9136 - val_loss: 68.9385\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 241.0528 - val_loss: 65.2010\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 234.3549 - val_loss: 61.5987\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 227.8170 - val_loss: 58.1290\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 221.4368 - val_loss: 54.7895\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 215.2118 - val_loss: 51.5771\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 209.1391 - val_loss: 48.4896\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 203.2164 - val_loss: 45.5244\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 197.4412 - val_loss: 42.6791\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 191.8110 - val_loss: 39.9508\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 186.3234 - val_loss: 37.3372\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 180.9758 - val_loss: 34.8360\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 175.7657 - val_loss: 32.4442\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 170.6906 - val_loss: 30.1597\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 165.7484 - val_loss: 27.9804\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 160.9366 - val_loss: 25.9031\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 156.2526 - val_loss: 23.9262\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 151.6944 - val_loss: 22.0468\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 147.2592 - val_loss: 20.2626\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 142.9450 - val_loss: 18.5715\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 138.7496 - val_loss: 16.9711\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 134.6705 - val_loss: 15.4590\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 130.7053 - val_loss: 14.0330\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 126.8521 - val_loss: 12.6908\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 123.1084 - val_loss: 11.4303\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 119.4721 - val_loss: 10.2492\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 115.9410 - val_loss: 9.1453\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 112.5129 - val_loss: 8.1164\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 109.1856 - val_loss: 7.1604\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 105.9569 - val_loss: 6.2753\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 102.8249 - val_loss: 5.4589\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 99.7874 - val_loss: 4.7091\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 96.8423 - val_loss: 4.0240\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 93.9874 - val_loss: 3.4014\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 91.2211 - val_loss: 2.8395\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 88.5410 - val_loss: 2.3362\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 85.9455 - val_loss: 1.8897\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 83.4325 - val_loss: 1.4980\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 81.0000 - val_loss: 1.1592\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 78.6460 - val_loss: 0.8716\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 76.3688 - val_loss: 0.6331\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 74.1664 - val_loss: 0.4421\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 72.0371 - val_loss: 0.2967\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 69.9790 - val_loss: 0.1953\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 67.9904 - val_loss: 0.1361\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 66.0693 - val_loss: 0.1174\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 64.2142 - val_loss: 0.1375\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 62.4233 - val_loss: 0.1949\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 60.6948 - val_loss: 0.2879\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 59.0272 - val_loss: 0.4149\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 57.4188 - val_loss: 0.5744\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 55.8680 - val_loss: 0.7650\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 54.3731 - val_loss: 0.9850\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 52.9328 - val_loss: 1.2331\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 51.5453 - val_loss: 1.5078\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 50.2092 - val_loss: 1.8077\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 48.9231 - val_loss: 2.1316\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 47.6855 - val_loss: 2.4779\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 46.4949 - val_loss: 2.8455\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 45.3500 - val_loss: 3.2330\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 44.2492 - val_loss: 3.6393\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 43.1913 - val_loss: 4.0631\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 42.1750 - val_loss: 4.5032\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 41.1989 - val_loss: 4.9585\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 40.2619 - val_loss: 5.4279\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 39.3626 - val_loss: 5.9102\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 38.4998 - val_loss: 6.4045\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 37.6724 - val_loss: 6.9096\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 36.8790 - val_loss: 7.4246\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 36.1187 - val_loss: 7.9486\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 35.3903 - val_loss: 8.4806\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 34.6926 - val_loss: 9.0196\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 34.0248 - val_loss: 9.5649\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 33.3856 - val_loss: 10.1155\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 32.7741 - val_loss: 10.6706\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 32.1893 - val_loss: 11.2295\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 31.6302 - val_loss: 11.7913\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 31.0959 - val_loss: 12.3554\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 30.5856 - val_loss: 12.9210\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 30.0982 - val_loss: 13.4875\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 29.6329 - val_loss: 14.0543\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 29.1888 - val_loss: 14.6206\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.7651 - val_loss: 15.1859\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 28.3612 - val_loss: 15.7497\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.9761 - val_loss: 16.3113\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.6092 - val_loss: 16.8702\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.2596 - val_loss: 17.4261\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.9268 - val_loss: 17.9783\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.6100 - val_loss: 18.5265\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.3085 - val_loss: 19.0702\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 26.0217 - val_loss: 19.6092\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.7490 - val_loss: 20.1430\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.4898 - val_loss: 20.6712\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.2434 - val_loss: 21.1932\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.0095 - val_loss: 21.7093\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.7873 - val_loss: 22.2187\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.5765 - val_loss: 22.7214\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 24.3764 - val_loss: 23.2172\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.1865 - val_loss: 23.7056\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 24.0065 - val_loss: 24.1866\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 23.8358 - val_loss: 24.6601\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 23.6741 - val_loss: 25.1256\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.5209 - val_loss: 25.5833\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.3758 - val_loss: 26.0329\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 23.2383 - val_loss: 26.4742\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 23.1083 - val_loss: 26.9072\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.9853 - val_loss: 27.3319\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.8689 - val_loss: 27.7480\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.7589 - val_loss: 28.1556\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 22.6548 - val_loss: 28.5547\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.5565 - val_loss: 28.9452\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.4636 - val_loss: 29.3270\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.3757 - val_loss: 29.7001\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.2929 - val_loss: 30.0647\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.2146 - val_loss: 30.4206\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.1407 - val_loss: 30.7679\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.0710 - val_loss: 31.1065\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.0053 - val_loss: 31.4366\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.9432 - val_loss: 31.7584\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.8847 - val_loss: 32.0717\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.8296 - val_loss: 32.3768\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 21.7775 - val_loss: 32.6736\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 21.7285 - val_loss: 32.9621\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 21.6823 - val_loss: 33.2425\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 21.6388 - val_loss: 33.5149\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.5978 - val_loss: 33.7796\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 21.5591 - val_loss: 34.0363\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 21.5228 - val_loss: 34.2854\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 21.4885 - val_loss: 34.5271\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 21.4562 - val_loss: 34.7610\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.4259 - val_loss: 34.9877\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.3973 - val_loss: 35.2074\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 21.3704 - val_loss: 35.4199\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 21.3451 - val_loss: 35.6255\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.3212 - val_loss: 35.8243\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.2988 - val_loss: 36.0165\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.2777 - val_loss: 36.2021\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.2579 - val_loss: 36.3813\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.2392 - val_loss: 36.5543\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.2216 - val_loss: 36.7211\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.2051 - val_loss: 36.8820\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.1895 - val_loss: 37.0373\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.1749 - val_loss: 37.1866\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.1612 - val_loss: 37.3306\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.1482 - val_loss: 37.4690\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.1361 - val_loss: 37.6023\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.1247 - val_loss: 37.7307\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.1139 - val_loss: 37.8537\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.1038 - val_loss: 37.9722\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.0943 - val_loss: 38.0860\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 21.0853 - val_loss: 38.1951\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.0769 - val_loss: 38.2997\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.0690 - val_loss: 38.4004\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.0616 - val_loss: 38.4967\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.0547 - val_loss: 38.5892\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.0481 - val_loss: 38.6775\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.0419 - val_loss: 38.7622\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.0361 - val_loss: 38.8431\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.0307 - val_loss: 38.9208\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.0256 - val_loss: 38.9947\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.0208 - val_loss: 39.0655\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.0163 - val_loss: 39.1331\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.0121 - val_loss: 39.1977\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.0082 - val_loss: 39.2594\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.0045 - val_loss: 39.3184\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.0010 - val_loss: 39.3745\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9977 - val_loss: 39.4278\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9947 - val_loss: 39.4790\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9918 - val_loss: 39.5274\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9892 - val_loss: 39.5738\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9866 - val_loss: 39.6177\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9843 - val_loss: 39.6595\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 20.9821 - val_loss: 39.6992\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 20.9801 - val_loss: 39.7367\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.9782 - val_loss: 39.7726\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.9765 - val_loss: 39.8069\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.9748 - val_loss: 39.8390\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.9733 - val_loss: 39.8696\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9719 - val_loss: 39.8985\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.9706 - val_loss: 39.9261\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9694 - val_loss: 39.9520\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9682 - val_loss: 39.9764\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9672 - val_loss: 39.9996\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9663 - val_loss: 40.0214\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9655 - val_loss: 40.0422\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9647 - val_loss: 40.0618\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9640 - val_loss: 40.0804\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9633 - val_loss: 40.0978\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9627 - val_loss: 40.1139\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 20.9622 - val_loss: 40.1295\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9617 - val_loss: 40.1439\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9613 - val_loss: 40.1576\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9610 - val_loss: 40.1708\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9606 - val_loss: 40.1826\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9604 - val_loss: 40.1942\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9601 - val_loss: 40.2049\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9599 - val_loss: 40.2150\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9597 - val_loss: 40.2243\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9597 - val_loss: 40.2332\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9595 - val_loss: 40.2413\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9595 - val_loss: 40.2488\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9595 - val_loss: 40.2562\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9595 - val_loss: 40.2629\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9595 - val_loss: 40.2692\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9595 - val_loss: 40.2751\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9595 - val_loss: 40.2803\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9597 - val_loss: 40.2854\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9598 - val_loss: 40.2900\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9599 - val_loss: 40.2943\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 20.9601 - val_loss: 40.2983\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9603 - val_loss: 40.3020\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9605 - val_loss: 40.3056\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9607 - val_loss: 40.3087\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.9608 - val_loss: 40.3116\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9611 - val_loss: 40.3143\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9613 - val_loss: 40.3167\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9616 - val_loss: 40.3191\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9619 - val_loss: 40.3212\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9621 - val_loss: 40.3230\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 20.9624 - val_loss: 40.3246\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9627 - val_loss: 40.3261\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9630 - val_loss: 40.3277\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9632 - val_loss: 40.3287\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9636 - val_loss: 40.3298\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9639 - val_loss: 40.3308\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9642 - val_loss: 40.3315\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9645 - val_loss: 40.3324\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9648 - val_loss: 40.3331\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9652 - val_loss: 40.3334\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9656 - val_loss: 40.3338\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9659 - val_loss: 40.3342\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9662 - val_loss: 40.3347\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9666 - val_loss: 40.3350\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9669 - val_loss: 40.3351\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9673 - val_loss: 40.3351\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9676 - val_loss: 40.3352\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9680 - val_loss: 40.3352\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9683 - val_loss: 40.3350\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9687 - val_loss: 40.3350\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9690 - val_loss: 40.3350\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9693 - val_loss: 40.3348\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9697 - val_loss: 40.3341\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9701 - val_loss: 40.3341\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9704 - val_loss: 40.3339\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9708 - val_loss: 40.3335\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9711 - val_loss: 40.3333\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9715 - val_loss: 40.3329\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9718 - val_loss: 40.3324\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 20.9722 - val_loss: 40.3317\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9726 - val_loss: 40.3313\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9730 - val_loss: 40.3311\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9733 - val_loss: 40.3306\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9736 - val_loss: 40.3300\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9740 - val_loss: 40.3297\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9743 - val_loss: 40.3294\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9747 - val_loss: 40.3287\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9750 - val_loss: 40.3282\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9754 - val_loss: 40.3279\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9757 - val_loss: 40.3273\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9760 - val_loss: 40.3269\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9764 - val_loss: 40.3264\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9767 - val_loss: 40.3259\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9770 - val_loss: 40.3255\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9773 - val_loss: 40.3250\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9777 - val_loss: 40.3247\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9779 - val_loss: 40.3240\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9783 - val_loss: 40.3235\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 20.9786 - val_loss: 40.3229\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9789 - val_loss: 40.3224\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9792 - val_loss: 40.3219\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9795 - val_loss: 40.3213\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9798 - val_loss: 40.3207\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9801 - val_loss: 40.3203\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9804 - val_loss: 40.3196\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9808 - val_loss: 40.3193\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9810 - val_loss: 40.3187\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9814 - val_loss: 40.3184\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9816 - val_loss: 40.3177\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9819 - val_loss: 40.3172\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9822 - val_loss: 40.3166\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9824 - val_loss: 40.3160\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9827 - val_loss: 40.3152\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9831 - val_loss: 40.3148\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9833 - val_loss: 40.3143\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9836 - val_loss: 40.3140\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9839 - val_loss: 40.3134\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9841 - val_loss: 40.3128\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 20.9844 - val_loss: 40.3123\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9847 - val_loss: 40.3118\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9850 - val_loss: 40.3114\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9852 - val_loss: 40.3110\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9855 - val_loss: 40.3106\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9857 - val_loss: 40.3102\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9859 - val_loss: 40.3097\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9862 - val_loss: 40.3093\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9865 - val_loss: 40.3088\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9867 - val_loss: 40.3085\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9869 - val_loss: 40.3081\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9872 - val_loss: 40.3077\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9874 - val_loss: 40.3074\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9876 - val_loss: 40.3070\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9879 - val_loss: 40.3065\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9881 - val_loss: 40.3061\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9883 - val_loss: 40.3057\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9885 - val_loss: 40.3053\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9887 - val_loss: 40.3047\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 20.9889 - val_loss: 40.3043\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9892 - val_loss: 40.3039\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9894 - val_loss: 40.3035\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9896 - val_loss: 40.3032\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9898 - val_loss: 40.3026\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9900 - val_loss: 40.3021\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9902 - val_loss: 40.3017\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9904 - val_loss: 40.3013\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9906 - val_loss: 40.3007\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9908 - val_loss: 40.3005\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9910 - val_loss: 40.3002\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9912 - val_loss: 40.2997\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9914 - val_loss: 40.2994\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9916 - val_loss: 40.2989\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9917 - val_loss: 40.2986\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9919 - val_loss: 40.2982\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9921 - val_loss: 40.2979\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9923 - val_loss: 40.2975\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 20.9925 - val_loss: 40.2971\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9927 - val_loss: 40.2969\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9928 - val_loss: 40.2968\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9929 - val_loss: 40.2966\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9931 - val_loss: 40.2961\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9933 - val_loss: 40.2957\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9935 - val_loss: 40.2955\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9936 - val_loss: 40.2951\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9937 - val_loss: 40.2948\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9940 - val_loss: 40.2946\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9941 - val_loss: 40.2943\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9942 - val_loss: 40.2941\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9944 - val_loss: 40.2940\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9945 - val_loss: 40.2936\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9947 - val_loss: 40.2934\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9948 - val_loss: 40.2932\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9949 - val_loss: 40.2929\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9951 - val_loss: 40.2926\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9952 - val_loss: 40.2924\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9953 - val_loss: 40.2924\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9955 - val_loss: 40.2919\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9956 - val_loss: 40.2916\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9958 - val_loss: 40.2914\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9959 - val_loss: 40.2914\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9960 - val_loss: 40.2912\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9961 - val_loss: 40.2910\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9962 - val_loss: 40.2907\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9964 - val_loss: 40.2906\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9965 - val_loss: 40.2904\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9966 - val_loss: 40.2899\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.9967 - val_loss: 40.2897\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 20.9969 - val_loss: 40.2896\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.6465, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0029, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0168, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3581, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 332ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62.36757703, 62.36477591, 62.36197479, 62.35917367, 62.35637255,\n",
       "        62.35357143, 62.35077031, 62.34796919, 62.34516807, 62.34236695,\n",
       "        62.33956583, 62.33676471, 62.33396359, 62.33116246, 62.32836134,\n",
       "        62.32556022, 62.3227591 , 62.31995798, 62.31715686, 62.31435574,\n",
       "        62.31155462, 62.3087535 , 62.30595238, 62.30315126, 62.30035014,\n",
       "        62.28284314, 62.26323529, 62.24362745, 62.22401961, 62.20441176,\n",
       "        62.18480392, 62.16519608, 62.14558824, 62.12598039, 62.10637255,\n",
       "        62.08676471, 62.06715686, 62.04754902, 62.02794118, 62.00833333,\n",
       "        61.98872549, 61.96911765, 61.9495098 , 61.92990196, 61.91029412,\n",
       "        61.89068627, 61.87107843, 61.85147059, 61.83186275, 61.8122549 ,\n",
       "        61.79264706, 61.77303922, 61.75343137, 61.73382353, 61.71421569,\n",
       "        61.69460784, 61.675     , 61.65539216, 61.63578431, 61.61617647,\n",
       "        61.59833333, 61.58880952, 61.57928571, 61.5697619 , 61.5602381 ,\n",
       "        61.55071429, 61.54119048, 61.53166667, 61.52214286, 61.51261905,\n",
       "        61.50309524, 61.49357143, 61.48404762, 61.47452381, 61.465     ,\n",
       "        61.45547619, 61.44595238, 61.43642857, 61.42690476, 61.41738095,\n",
       "        68.32588196,  0.27336845,  0.50278026,  0.        ,  0.        ,\n",
       "         0.        ,  0.43412688,  0.31125778,  0.14499481,  0.83750647,\n",
       "         0.49588051,  0.67851889,  0.38742325,  0.45370549,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60.1653268 , 60.16103175, 60.15673669, 60.15244164, 60.14814659,\n",
       "       60.14385154, 60.13955649, 60.13526144, 60.13096639, 60.12667134,\n",
       "       60.12237628, 60.11808123, 60.11378618, 60.10949113, 60.10519608,\n",
       "       60.10090103, 60.09660598, 60.09231092, 60.08801587, 60.08372082,\n",
       "       60.07942577, 60.07513072, 60.07083567, 60.06654062, 60.06224556,\n",
       "       60.05795051, 60.05365546, 60.04936041, 60.04506536, 60.04077031,\n",
       "       60.03647526, 60.03218021, 60.02788515, 60.0235901 , 60.01929505,\n",
       "       60.015     , 60.01070495, 60.0064099 , 60.00211485, 59.99781979,\n",
       "       59.99352474, 59.98922969, 59.98493464, 59.98063959, 59.97634454,\n",
       "       59.97204949, 59.96775444, 59.96345938, 59.95916433, 59.95486928,\n",
       "       59.95057423, 59.94627918, 59.94198413, 59.93768908, 59.93339402,\n",
       "       59.92909897, 59.92480392, 59.92050887, 59.91621382, 59.91191877,\n",
       "       59.90762372, 59.90332866, 59.89768908, 59.8874183 , 59.87714753,\n",
       "       59.86687675, 59.85660598, 59.8463352 , 59.83606443, 59.82579365,\n",
       "       59.81552288, 59.8052521 , 59.79498133, 59.78471055, 59.77443978,\n",
       "       59.764169  , 59.75389823, 59.74362745, 59.73335668, 59.7230859 ,\n",
       "       59.71281513, 59.70254435, 59.69227358, 59.6820028 , 59.67173203,\n",
       "       59.66146125, 59.65119048, 59.6409197 , 59.63064893, 59.62037815,\n",
       "       59.61010738, 59.5998366 , 59.58956583, 59.57929505, 59.56902428,\n",
       "       59.5587535 , 59.54848273, 59.53821195, 59.52794118, 59.5176704 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.955295752992164\n",
      "12.947093256822495\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
