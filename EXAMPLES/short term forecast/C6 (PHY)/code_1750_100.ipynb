{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "1845    52.872619\n",
       "1846    52.856746\n",
       "1847    52.840873\n",
       "1848    52.825000\n",
       "1849    52.809127\n",
       "Name: C6, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_1750_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "1745     0.183813\n",
       "1746     0.323350\n",
       "1747     0.000000\n",
       "1748     0.963653\n",
       "1749     0.273746\n",
       "Name: C6, Length: 1750, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1750)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 1, 251) (1300, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 2s 33ms/step - loss: 4023.6125 - val_loss: 2595.6995\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3945.7920 - val_loss: 2562.1399\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3893.6787 - val_loss: 2532.4170\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3852.3960 - val_loss: 2506.4099\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3811.6182 - val_loss: 2480.9841\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3771.3396 - val_loss: 2455.9241\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3731.4993 - val_loss: 2431.1670\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3692.0549 - val_loss: 2406.6855\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3652.9807 - val_loss: 2382.4636\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3614.2583 - val_loss: 2358.4919\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3575.8760 - val_loss: 2334.7620\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3537.8245 - val_loss: 2311.2683\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3500.0964 - val_loss: 2288.0066\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3462.6868 - val_loss: 2264.9729\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3425.5906 - val_loss: 2242.1636\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3388.8030 - val_loss: 2219.5759\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3352.3203 - val_loss: 2197.2078\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3316.1406 - val_loss: 2175.0562\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3280.2595 - val_loss: 2153.1194\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3244.6750 - val_loss: 2131.3955\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3209.3840 - val_loss: 2109.8821\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3174.3838 - val_loss: 2088.5774\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3139.6721 - val_loss: 2067.4802\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3105.2473 - val_loss: 2046.5880\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3071.1069 - val_loss: 2025.9003\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3037.2483 - val_loss: 2005.4148\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 3003.6699 - val_loss: 1985.1300\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2970.3691 - val_loss: 1965.0446\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2937.3452 - val_loss: 1945.1571\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2904.5957 - val_loss: 1925.4659\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2872.1179 - val_loss: 1905.9700\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2839.9109 - val_loss: 1886.6678\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2807.9727 - val_loss: 1867.5580\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2776.3013 - val_loss: 1848.6392\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2744.8948 - val_loss: 1829.9102\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2713.7524 - val_loss: 1811.3698\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2682.8713 - val_loss: 1793.0162\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2652.2507 - val_loss: 1774.8490\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2621.8884 - val_loss: 1756.8663\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2591.7832 - val_loss: 1739.0669\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2561.9326 - val_loss: 1721.4500\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2532.3359 - val_loss: 1704.0139\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2502.9915 - val_loss: 1686.7581\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2473.8975 - val_loss: 1669.6807\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2445.0520 - val_loss: 1652.7806\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2416.4539 - val_loss: 1636.0571\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2388.1016 - val_loss: 1619.5088\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2359.9939 - val_loss: 1603.1345\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2332.1287 - val_loss: 1586.9331\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2304.5046 - val_loss: 1570.9036\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2277.1206 - val_loss: 1555.0447\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2249.9753 - val_loss: 1539.3553\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2223.0664 - val_loss: 1523.8347\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2196.3936 - val_loss: 1508.4813\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2169.9543 - val_loss: 1493.2942\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2143.7476 - val_loss: 1478.2722\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2117.7727 - val_loss: 1463.4147\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2092.0271 - val_loss: 1448.7201\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2066.5100 - val_loss: 1434.1875\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2041.2200 - val_loss: 1419.8159\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2016.1556 - val_loss: 1405.6046\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1991.3157 - val_loss: 1391.5519\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1966.6992 - val_loss: 1377.6573\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1942.3036 - val_loss: 1363.9198\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1918.1283 - val_loss: 1350.3381\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1894.1726 - val_loss: 1336.9109\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1870.4338 - val_loss: 1323.6378\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1846.9125 - val_loss: 1310.5178\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1823.6052 - val_loss: 1297.5498\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1800.5122 - val_loss: 1284.7323\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1777.6317 - val_loss: 1272.0647\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1754.9623 - val_loss: 1259.5463\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1732.5032 - val_loss: 1247.1758\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1710.2522 - val_loss: 1234.9524\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1688.2089 - val_loss: 1222.8751\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1666.3721 - val_loss: 1210.9430\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1644.7397 - val_loss: 1199.1548\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1623.3118 - val_loss: 1187.5103\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1602.0858 - val_loss: 1176.0076\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1581.0616 - val_loss: 1164.6464\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1560.2372 - val_loss: 1153.4258\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1539.6117 - val_loss: 1142.3446\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1519.1840 - val_loss: 1131.4020\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1498.9529 - val_loss: 1120.5970\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1478.9172 - val_loss: 1109.9286\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1459.0753 - val_loss: 1099.3965\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1439.4265 - val_loss: 1088.9989\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1419.9697 - val_loss: 1078.7355\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1400.7036 - val_loss: 1068.6053\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1381.6271 - val_loss: 1058.6073\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1362.7388 - val_loss: 1048.7410\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1344.0380 - val_loss: 1039.0048\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1325.5229 - val_loss: 1029.3982\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1307.1929 - val_loss: 1019.9205\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1289.0469 - val_loss: 1010.5706\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1271.0839 - val_loss: 1001.3477\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1253.3021 - val_loss: 992.2507\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1235.7006 - val_loss: 983.2791\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1218.2789 - val_loss: 974.4321\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1201.0355 - val_loss: 965.7083\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1183.9692 - val_loss: 957.1072\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1167.0792 - val_loss: 948.6278\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1150.3638 - val_loss: 940.2695\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1133.8225 - val_loss: 932.0312\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1117.4542 - val_loss: 923.9123\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1101.2574 - val_loss: 915.9118\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1085.2316 - val_loss: 908.0289\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1069.3760 - val_loss: 900.2627\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1053.6884 - val_loss: 892.6126\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1038.1686 - val_loss: 885.0775\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1022.8154 - val_loss: 877.6563\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1007.6273 - val_loss: 870.3491\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 992.6042 - val_loss: 863.1542\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 977.7441 - val_loss: 856.0711\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 963.0464 - val_loss: 849.0988\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 948.5099 - val_loss: 842.2365\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 934.1338 - val_loss: 835.4839\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 919.9169 - val_loss: 828.8393\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 905.8581 - val_loss: 822.3027\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 891.9570 - val_loss: 815.8730\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 878.2119 - val_loss: 809.5489\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 864.6218 - val_loss: 803.3301\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 851.1862 - val_loss: 797.2156\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 837.9040 - val_loss: 791.2047\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 824.7736 - val_loss: 785.2958\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 811.7946 - val_loss: 779.4885\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 798.9657 - val_loss: 773.7814\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 786.2859 - val_loss: 768.1722\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 773.7546 - val_loss: 762.6564\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 761.3705 - val_loss: 757.1944\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 747.5551 - val_loss: 748.9350\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 729.4071 - val_loss: 741.6959\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 713.7405 - val_loss: 734.9689\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 698.9828 - val_loss: 728.6888\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 684.9338 - val_loss: 722.7433\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 671.4155 - val_loss: 717.0629\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 658.3208 - val_loss: 711.6061\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 645.5834 - val_loss: 706.3454\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 633.1594 - val_loss: 701.2617\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 621.0181 - val_loss: 696.3411\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 609.1365 - val_loss: 691.5726\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 597.4971 - val_loss: 686.9482\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 586.0859 - val_loss: 682.4605\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 574.8912 - val_loss: 678.1038\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 563.9038 - val_loss: 673.8730\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 553.1152 - val_loss: 669.7637\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 542.5184 - val_loss: 665.7721\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 532.1072 - val_loss: 661.8948\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 521.8768 - val_loss: 658.1287\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 511.8212 - val_loss: 654.4710\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 501.9372 - val_loss: 650.9189\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 492.2197 - val_loss: 647.4701\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 482.6654 - val_loss: 644.1224\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 473.2712 - val_loss: 640.8737\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 464.0336 - val_loss: 637.7219\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 454.9495 - val_loss: 634.6652\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 446.0161 - val_loss: 631.7015\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 437.2311 - val_loss: 628.8297\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 428.5917 - val_loss: 626.0475\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 420.0958 - val_loss: 623.3536\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 411.7409 - val_loss: 620.7466\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 403.5248 - val_loss: 618.2249\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 395.4457 - val_loss: 615.7870\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 387.5013 - val_loss: 613.4315\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 379.6898 - val_loss: 611.1571\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 372.0092 - val_loss: 608.9624\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 364.4576 - val_loss: 606.8461\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 357.0334 - val_loss: 604.8071\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 349.7348 - val_loss: 602.8440\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 342.5601 - val_loss: 600.9555\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 335.5078 - val_loss: 599.1407\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 328.5764 - val_loss: 597.3981\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 321.7640 - val_loss: 595.7267\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 315.0693 - val_loss: 594.1254\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 308.4906 - val_loss: 592.5929\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 302.0265 - val_loss: 591.1282\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 295.6757 - val_loss: 589.7302\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 289.4366 - val_loss: 588.3977\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 283.3079 - val_loss: 587.1298\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 277.2881 - val_loss: 585.9254\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 271.3760 - val_loss: 584.7835\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 265.5704 - val_loss: 583.7028\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 259.8697 - val_loss: 582.6826\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 254.2726 - val_loss: 581.7216\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 248.7777 - val_loss: 580.8188\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 243.3839 - val_loss: 579.9735\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 238.0898 - val_loss: 579.1844\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 232.8943 - val_loss: 578.4506\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 227.7962 - val_loss: 577.7711\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 222.7939 - val_loss: 577.1449\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 217.8865 - val_loss: 576.5711\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 213.0727 - val_loss: 576.0488\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 208.3514 - val_loss: 575.5768\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 203.7214 - val_loss: 575.1545\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 199.1816 - val_loss: 574.7807\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 194.7307 - val_loss: 574.4546\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 190.3675 - val_loss: 574.1750\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 186.0909 - val_loss: 573.9413\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 181.8997 - val_loss: 573.7525\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 177.7928 - val_loss: 573.6074\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 173.7691 - val_loss: 573.5056\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 169.8274 - val_loss: 573.4457\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 165.9668 - val_loss: 573.4272\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 162.1861 - val_loss: 573.4488\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 158.4840 - val_loss: 573.5099\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 154.8597 - val_loss: 573.6096\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 151.3120 - val_loss: 573.7470\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 147.8397 - val_loss: 573.9211\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 144.4421 - val_loss: 574.1311\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 141.1177 - val_loss: 574.3763\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 137.8657 - val_loss: 574.6555\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 134.6850 - val_loss: 574.9681\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 131.5746 - val_loss: 575.3132\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 128.5332 - val_loss: 575.6900\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 125.5601 - val_loss: 576.0975\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 122.6542 - val_loss: 576.5351\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 119.8143 - val_loss: 577.0016\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 117.0396 - val_loss: 577.4966\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 114.3289 - val_loss: 578.0190\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 111.6815 - val_loss: 578.5682\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 109.0960 - val_loss: 579.1432\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 106.5718 - val_loss: 579.7433\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 104.1077 - val_loss: 580.3676\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 101.7028 - val_loss: 581.0154\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 99.3561 - val_loss: 581.6860\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 97.0667 - val_loss: 582.3785\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 94.8335 - val_loss: 583.0921\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 92.6556 - val_loss: 583.8262\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 90.5322 - val_loss: 584.5799\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 88.4622 - val_loss: 585.3524\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 86.4448 - val_loss: 586.1430\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 84.4790 - val_loss: 586.9512\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 82.5639 - val_loss: 587.7758\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 80.6985 - val_loss: 588.6165\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 78.8820 - val_loss: 589.4724\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 77.1135 - val_loss: 590.3427\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 75.3921 - val_loss: 591.2268\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 73.7169 - val_loss: 592.1241\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 72.0871 - val_loss: 593.0338\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 70.5017 - val_loss: 593.9553\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 68.9598 - val_loss: 594.8879\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 67.4608 - val_loss: 595.8308\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 66.0036 - val_loss: 596.7834\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 64.5876 - val_loss: 597.7451\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 63.2118 - val_loss: 598.7153\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 61.8754 - val_loss: 599.6934\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 60.5776 - val_loss: 600.6785\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 59.3176 - val_loss: 601.6702\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 58.0946 - val_loss: 602.6680\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 56.9078 - val_loss: 603.6710\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 55.7566 - val_loss: 604.6788\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 54.6398 - val_loss: 605.6909\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 53.5570 - val_loss: 606.7065\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 52.5073 - val_loss: 607.7253\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 51.4901 - val_loss: 608.7468\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 50.5044 - val_loss: 609.7701\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 49.5497 - val_loss: 610.7949\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 48.6251 - val_loss: 611.8206\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 47.7300 - val_loss: 612.8466\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 46.8637 - val_loss: 613.8728\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 46.0255 - val_loss: 614.8980\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 45.2147 - val_loss: 615.9226\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 44.4306 - val_loss: 616.9454\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 43.6725 - val_loss: 617.9662\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 42.9400 - val_loss: 618.9847\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 42.2321 - val_loss: 620.0003\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 41.5482 - val_loss: 621.0123\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 40.8880 - val_loss: 622.0211\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 40.2504 - val_loss: 623.0255\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 39.6353 - val_loss: 624.0253\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 39.0417 - val_loss: 625.0204\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 38.4691 - val_loss: 626.0101\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 37.9170 - val_loss: 626.9941\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 37.3849 - val_loss: 627.9722\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 36.8721 - val_loss: 628.9440\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 36.3780 - val_loss: 629.9090\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 35.9022 - val_loss: 630.8671\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 35.4442 - val_loss: 631.8179\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 35.0033 - val_loss: 632.7610\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 34.5791 - val_loss: 633.6967\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 34.1710 - val_loss: 634.6238\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 33.7786 - val_loss: 635.5425\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 33.4015 - val_loss: 636.4528\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.0390 - val_loss: 637.3537\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.6909 - val_loss: 638.2459\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 32.3565 - val_loss: 639.1287\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.0354 - val_loss: 640.0018\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.7274 - val_loss: 640.8652\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 31.4318 - val_loss: 641.7185\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.1483 - val_loss: 642.5619\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.8765 - val_loss: 643.3948\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 30.6160 - val_loss: 644.2173\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.3664 - val_loss: 645.0295\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.1273 - val_loss: 645.8306\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 29.8984 - val_loss: 646.6210\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.6792 - val_loss: 647.4004\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.4695 - val_loss: 648.1688\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 29.2689 - val_loss: 648.9259\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.0771 - val_loss: 649.6718\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.8938 - val_loss: 650.4065\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 28.7185 - val_loss: 651.1296\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.5511 - val_loss: 651.8414\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.3912 - val_loss: 652.5416\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 28.2386 - val_loss: 653.2304\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.0929 - val_loss: 653.9074\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.9540 - val_loss: 654.5729\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.8214 - val_loss: 655.2269\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.6951 - val_loss: 655.8691\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.5746 - val_loss: 656.4996\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.4599 - val_loss: 657.1187\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.3506 - val_loss: 657.7264\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.2465 - val_loss: 658.3223\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.1474 - val_loss: 658.9067\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.0532 - val_loss: 659.4797\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.9635 - val_loss: 660.0413\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 26.8782 - val_loss: 660.5914\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.7971 - val_loss: 661.1301\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.7201 - val_loss: 661.6577\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.6469 - val_loss: 662.1738\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 26.5774 - val_loss: 662.6793\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 26.5113 - val_loss: 663.1736\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.4487 - val_loss: 663.6570\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.3892 - val_loss: 664.1295\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.3328 - val_loss: 664.5912\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.2793 - val_loss: 665.0421\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.2286 - val_loss: 665.4826\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.1805 - val_loss: 665.9128\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.1349 - val_loss: 666.3326\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.0918 - val_loss: 666.7422\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.0509 - val_loss: 667.1417\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.0122 - val_loss: 667.5312\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.9756 - val_loss: 667.9109\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.9409 - val_loss: 668.2806\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.9082 - val_loss: 668.6415\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.8771 - val_loss: 668.9924\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 25.8478 - val_loss: 669.3341\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.8201 - val_loss: 669.6666\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.7939 - val_loss: 669.9904\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.7691 - val_loss: 670.3053\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.7457 - val_loss: 670.6115\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.7236 - val_loss: 670.9090\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.7028 - val_loss: 671.1983\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.6831 - val_loss: 671.4791\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.6645 - val_loss: 671.7520\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.6470 - val_loss: 672.0168\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.6304 - val_loss: 672.2739\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.6148 - val_loss: 672.5234\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.6000 - val_loss: 672.7652\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5862 - val_loss: 673.0001\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5731 - val_loss: 673.2274\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5607 - val_loss: 673.4476\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5491 - val_loss: 673.6611\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5381 - val_loss: 673.8682\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5277 - val_loss: 674.0682\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5180 - val_loss: 674.2620\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 25.5088 - val_loss: 674.4494\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5002 - val_loss: 674.6307\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4921 - val_loss: 674.8062\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4844 - val_loss: 674.9756\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4772 - val_loss: 675.1392\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4704 - val_loss: 675.2974\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4640 - val_loss: 675.4505\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4580 - val_loss: 675.5982\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4523 - val_loss: 675.7405\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4470 - val_loss: 675.8780\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4420 - val_loss: 676.0103\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4373 - val_loss: 676.1381\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4328 - val_loss: 676.2613\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4287 - val_loss: 676.3801\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.4247 - val_loss: 676.4944\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4211 - val_loss: 676.6046\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4176 - val_loss: 676.7108\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4144 - val_loss: 676.8129\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4113 - val_loss: 676.9111\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4085 - val_loss: 677.0056\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.4058 - val_loss: 677.0963\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4032 - val_loss: 677.1837\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.4009 - val_loss: 677.2676\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 25.3986 - val_loss: 677.3484\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3965 - val_loss: 677.4258\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3946 - val_loss: 677.5000\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3927 - val_loss: 677.5713\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3911 - val_loss: 677.6400\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3894 - val_loss: 677.7056\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3880 - val_loss: 677.7686\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3865 - val_loss: 677.8290\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3852 - val_loss: 677.8871\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3840 - val_loss: 677.9426\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3829 - val_loss: 677.9958\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3818 - val_loss: 678.0466\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3808 - val_loss: 678.0954\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3799 - val_loss: 678.1422\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3790 - val_loss: 678.1868\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3782 - val_loss: 678.2295\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3775 - val_loss: 678.2704\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3768 - val_loss: 678.3093\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3762 - val_loss: 678.3464\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3756 - val_loss: 678.3820\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 25.3751 - val_loss: 678.4160\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3746 - val_loss: 678.4484\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3742 - val_loss: 678.4794\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3737 - val_loss: 678.5089\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3734 - val_loss: 678.5370\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3730 - val_loss: 678.5639\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3727 - val_loss: 678.5893\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3724 - val_loss: 678.6138\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3722 - val_loss: 678.6368\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3720 - val_loss: 678.6588\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3718 - val_loss: 678.6799\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3716 - val_loss: 678.7000\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3715 - val_loss: 678.7189\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3714 - val_loss: 678.7372\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3713 - val_loss: 678.7546\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3712 - val_loss: 678.7708\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3711 - val_loss: 678.7861\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3711 - val_loss: 678.8008\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3711 - val_loss: 678.8146\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 25.3711 - val_loss: 678.8279\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3711 - val_loss: 678.8406\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3711 - val_loss: 678.8524\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3712 - val_loss: 678.8638\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3712 - val_loss: 678.8743\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3713 - val_loss: 678.8845\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3713 - val_loss: 678.8940\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3714 - val_loss: 678.9030\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3715 - val_loss: 678.9116\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3716 - val_loss: 678.9197\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3717 - val_loss: 678.9273\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3718 - val_loss: 678.9345\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3719 - val_loss: 678.9411\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3721 - val_loss: 678.9476\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3722 - val_loss: 678.9534\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3724 - val_loss: 678.9590\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3725 - val_loss: 678.9645\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3727 - val_loss: 678.9697\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 25.3728 - val_loss: 678.9743\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3730 - val_loss: 678.9788\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3731 - val_loss: 678.9830\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3733 - val_loss: 678.9868\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3735 - val_loss: 678.9904\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3737 - val_loss: 678.9939\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3739 - val_loss: 678.9973\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3740 - val_loss: 679.0001\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 25.3742 - val_loss: 679.0029\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3744 - val_loss: 679.0057\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3746 - val_loss: 679.0082\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3748 - val_loss: 679.0103\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3750 - val_loss: 679.0126\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3752 - val_loss: 679.0144\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3754 - val_loss: 679.0163\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3756 - val_loss: 679.0179\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 25.3758 - val_loss: 679.0193\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3759 - val_loss: 679.0209\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3762 - val_loss: 679.0221\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3764 - val_loss: 679.0233\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3766 - val_loss: 679.0244\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3768 - val_loss: 679.0254\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3770 - val_loss: 679.0262\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3771 - val_loss: 679.0270\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3774 - val_loss: 679.0278\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 25.3775 - val_loss: 679.0285\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3777 - val_loss: 679.0292\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3779 - val_loss: 679.0296\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 25.3781 - val_loss: 679.0302\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 25.3783 - val_loss: 679.0305\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 25.3785 - val_loss: 679.0308\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3787 - val_loss: 679.0312\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3789 - val_loss: 679.0312\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3791 - val_loss: 679.0313\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3793 - val_loss: 679.0314\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3795 - val_loss: 679.0317\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3797 - val_loss: 679.0318\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3799 - val_loss: 679.0319\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3801 - val_loss: 679.0320\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3802 - val_loss: 679.0320\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3804 - val_loss: 679.0322\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3806 - val_loss: 679.0322\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3808 - val_loss: 679.0321\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3810 - val_loss: 679.0320\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3811 - val_loss: 679.0320\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3813 - val_loss: 679.0320\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 25.3815 - val_loss: 679.0319\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3816 - val_loss: 679.0317\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3818 - val_loss: 679.0316\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3820 - val_loss: 679.0314\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 25.3821 - val_loss: 679.0312\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 25.3823 - val_loss: 679.0308\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 25.3824 - val_loss: 679.0306\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.3826 - val_loss: 679.0304\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3827 - val_loss: 679.0299\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3830 - val_loss: 679.0295\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3831 - val_loss: 679.0293\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 25.3832 - val_loss: 679.0287\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3834 - val_loss: 679.0286\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3836 - val_loss: 679.0283\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3837 - val_loss: 679.0282\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3839 - val_loss: 679.0279\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.3839 - val_loss: 679.0274\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3842 - val_loss: 679.0270\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.3843 - val_loss: 679.0268\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 392ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.94712418e+01, 5.93031746e+01, 5.91351074e+01, 5.89670402e+01,\n",
       "        5.87989729e+01, 5.86309057e+01, 5.84628385e+01, 4.40685360e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.19980810e-01, 6.12264939e+01, 6.10164099e+01, 6.08063259e+01,\n",
       "        6.05962418e+01, 6.03861578e+01, 6.01808590e+01, 6.00127918e+01,\n",
       "        5.98447246e+01, 5.96766573e+01, 5.95085901e+01, 5.93405229e+01,\n",
       "        5.91724557e+01, 5.90043884e+01, 5.88363212e+01, 5.86682540e+01,\n",
       "        5.85001867e+01, 5.83321195e+01, 5.81910131e+01, 5.81489963e+01,\n",
       "        5.81069795e+01, 5.80649626e+01, 5.80229458e+01, 5.79809290e+01,\n",
       "        5.79389122e+01, 5.78968954e+01, 5.78548786e+01, 5.78128618e+01,\n",
       "        0.00000000e+00, 2.31229650e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.39091580e-01, 2.40039390e-01, 5.90417367e+01,\n",
       "        5.88736695e+01, 5.87056022e+01, 5.85375350e+01, 5.83694678e+01,\n",
       "        5.82014006e+01, 5.81583333e+01, 5.81163165e+01, 5.80742997e+01,\n",
       "        5.80322829e+01, 5.79902661e+01, 5.79482493e+01, 5.79062325e+01,\n",
       "        5.78642157e+01, 5.78221989e+01, 5.77801821e+01, 5.77381653e+01,\n",
       "        5.76961485e+01, 5.76541316e+01, 5.76121148e+01, 5.75700980e+01,\n",
       "        5.75280812e+01, 5.74860644e+01, 5.74440476e+01, 5.74020308e+01,\n",
       "        5.73600140e+01, 6.55019760e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.95466381e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.18863983e+01, 0.00000000e+00, 2.25151926e-01, 0.00000000e+00,\n",
       "        1.00199604e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.29751810e-01, 0.00000000e+00,\n",
       "        7.91867256e-01, 1.30121957e-03, 7.62066305e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.31329113e-01, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53.91911765, 53.91071429, 53.90231092, 53.89390756, 53.8855042 ,\n",
       "       53.87710084, 53.86869748, 53.86029412, 53.85189076, 53.84348739,\n",
       "       53.83508403, 53.82668067, 53.81827731, 53.80987395, 53.80147059,\n",
       "       53.79306723, 53.78466387, 53.7762605 , 53.76785714, 53.75945378,\n",
       "       53.75105042, 53.74264706, 53.7342437 , 53.72584034, 53.71743697,\n",
       "       53.70903361, 53.70063025, 53.69222689, 53.68382353, 53.67542017,\n",
       "       53.66701681, 53.65861345, 53.65021008, 53.64180672, 53.63340336,\n",
       "       53.625     , 53.61659664, 53.60819328, 53.59978992, 53.59138655,\n",
       "       53.58298319, 53.57457983, 53.56617647, 53.55777311, 53.54936975,\n",
       "       53.54096639, 53.53256303, 53.52415966, 53.5157563 , 53.50735294,\n",
       "       53.49894958, 53.49054622, 53.48214286, 53.4737395 , 53.46533613,\n",
       "       53.45693277, 53.44852941, 53.44012605, 53.43172269, 53.42331933,\n",
       "       53.41491597, 53.40651261, 53.39642857, 53.38055556, 53.36468254,\n",
       "       53.34880952, 53.33293651, 53.31706349, 53.30119048, 53.28531746,\n",
       "       53.26944444, 53.25357143, 53.23769841, 53.2218254 , 53.20595238,\n",
       "       53.19007937, 53.17420635, 53.15833333, 53.14246032, 53.1265873 ,\n",
       "       53.11071429, 53.09484127, 53.07896825, 53.06309524, 53.04722222,\n",
       "       53.03134921, 53.01547619, 52.99960317, 52.98373016, 52.96785714,\n",
       "       52.95198413, 52.93611111, 52.9202381 , 52.90436508, 52.88849206,\n",
       "       52.87261905, 52.85674603, 52.84087302, 52.825     , 52.80912698])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.994069395257505\n",
      "23.30688884002852\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
