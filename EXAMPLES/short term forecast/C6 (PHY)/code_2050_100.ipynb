{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2145    48.682681\n",
       "2146    48.672843\n",
       "2147    48.663005\n",
       "2148    48.653167\n",
       "2149    48.643329\n",
       "Name: C6, Length: 2150, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_2050_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2045     0.746107\n",
       "2046     0.000000\n",
       "2047     0.212183\n",
       "2048     0.560725\n",
       "2049     0.799287\n",
       "Name: C6, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2050)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 1, 251) (1600, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 23ms/step - loss: 3764.7993 - val_loss: 2546.4863\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3687.8647 - val_loss: 2504.1931\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3623.9160 - val_loss: 2455.0728\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3567.9292 - val_loss: 2412.9424\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3513.3020 - val_loss: 2371.5686\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3459.5129 - val_loss: 2330.8770\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3406.4746 - val_loss: 2290.8142\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3354.1328 - val_loss: 2251.3491\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3302.4531 - val_loss: 2212.4602\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3251.4133 - val_loss: 2174.1335\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3200.9985 - val_loss: 2136.3574\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3151.1958 - val_loss: 2099.1230\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3101.9946 - val_loss: 2062.4219\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3053.3870 - val_loss: 2026.2473\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3005.3645 - val_loss: 1990.5922\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2957.9209 - val_loss: 1955.4512\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2911.0491 - val_loss: 1920.8177\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2864.7417 - val_loss: 1886.6873\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2818.9954 - val_loss: 1853.0537\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2773.8020 - val_loss: 1819.9124\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2729.1577 - val_loss: 1787.2576\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2685.0564 - val_loss: 1755.0856\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2641.4932 - val_loss: 1723.3909\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2598.4631 - val_loss: 1692.1692\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2555.9607 - val_loss: 1661.4156\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2513.9817 - val_loss: 1631.1255\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2472.5210 - val_loss: 1601.2950\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2431.5747 - val_loss: 1571.9191\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2391.1370 - val_loss: 1542.9938\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2351.2036 - val_loss: 1514.5146\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2311.7705 - val_loss: 1486.4775\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2272.8330 - val_loss: 1458.8782\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2234.3872 - val_loss: 1431.7126\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2196.4282 - val_loss: 1404.9769\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2158.9517 - val_loss: 1378.6663\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2121.9536 - val_loss: 1352.7772\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2085.4294 - val_loss: 1327.3054\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2049.3755 - val_loss: 1302.2471\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2013.7874 - val_loss: 1277.5983\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1978.6609 - val_loss: 1253.3551\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1943.9919 - val_loss: 1229.5139\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1909.7766 - val_loss: 1206.0701\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1876.0110 - val_loss: 1183.0206\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1842.6912 - val_loss: 1160.3615\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1809.8131 - val_loss: 1138.0886\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1777.3730 - val_loss: 1116.1986\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1745.3668 - val_loss: 1094.6880\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1713.7910 - val_loss: 1073.5524\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1682.6414 - val_loss: 1052.7887\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1651.9144 - val_loss: 1032.3928\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1621.6062 - val_loss: 1012.3619\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1591.7131 - val_loss: 992.6913\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1562.2313 - val_loss: 973.3785\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1533.1576 - val_loss: 954.4193\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1504.4878 - val_loss: 935.8102\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1476.2185 - val_loss: 917.5480\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1448.3461 - val_loss: 899.6290\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1420.8669 - val_loss: 882.0496\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1393.7773 - val_loss: 864.8068\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1367.0742 - val_loss: 847.8966\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1340.7537 - val_loss: 831.3159\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1314.8123 - val_loss: 815.0616\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1289.2472 - val_loss: 799.1302\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1264.0541 - val_loss: 783.5179\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1239.2303 - val_loss: 768.2220\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1214.7720 - val_loss: 753.2386\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1190.6755 - val_loss: 738.5645\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1166.9379 - val_loss: 724.1968\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1143.5557 - val_loss: 710.1318\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1120.5256 - val_loss: 696.3663\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1097.8444 - val_loss: 682.8972\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1075.5083 - val_loss: 669.7211\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1053.5143 - val_loss: 656.8351\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1031.8599 - val_loss: 644.2358\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1010.5408 - val_loss: 631.9199\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 989.5543 - val_loss: 619.8844\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 968.8972 - val_loss: 608.1262\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 948.5665 - val_loss: 596.6418\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 928.5584 - val_loss: 585.4285\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 908.8699 - val_loss: 574.4830\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 889.4984 - val_loss: 563.8020\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 870.4404 - val_loss: 553.3827\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 851.6934 - val_loss: 543.2220\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 833.2531 - val_loss: 533.3164\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 815.1171 - val_loss: 523.6635\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 797.2825 - val_loss: 514.2597\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 779.7460 - val_loss: 505.1021\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 762.5043 - val_loss: 496.1876\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 745.5546 - val_loss: 487.5133\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 728.8939 - val_loss: 479.0763\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 712.5195 - val_loss: 470.8734\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 696.4280 - val_loss: 462.9019\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 680.6168 - val_loss: 455.1583\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 665.0826 - val_loss: 447.6399\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 649.8226 - val_loss: 440.3438\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 634.8334 - val_loss: 433.2670\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 620.1127 - val_loss: 426.4063\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 605.6572 - val_loss: 419.7593\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 591.4642 - val_loss: 413.3228\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 577.5306 - val_loss: 407.0933\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 563.8535 - val_loss: 401.0687\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 550.4303 - val_loss: 395.2459\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 537.2581 - val_loss: 389.6220\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 524.3337 - val_loss: 384.1938\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 511.6545 - val_loss: 378.9587\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 499.2178 - val_loss: 373.9138\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 487.0205 - val_loss: 369.0561\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 475.0598 - val_loss: 364.3828\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 463.3331 - val_loss: 359.8911\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 451.8371 - val_loss: 355.5781\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 440.5696 - val_loss: 351.4412\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 429.5276 - val_loss: 347.4771\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 418.7084 - val_loss: 343.6833\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 408.1090 - val_loss: 340.0571\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 397.7271 - val_loss: 336.5955\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 387.5593 - val_loss: 333.2955\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 377.6033 - val_loss: 330.1546\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 367.8564 - val_loss: 327.1702\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 358.3156 - val_loss: 324.3390\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 348.9784 - val_loss: 321.6586\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 339.8421 - val_loss: 319.1263\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 330.9039 - val_loss: 316.7391\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 322.1612 - val_loss: 314.4943\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 313.6113 - val_loss: 312.3894\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 305.2517 - val_loss: 310.4215\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 297.0796 - val_loss: 308.5879\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 289.0923 - val_loss: 306.8858\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 281.2873 - val_loss: 305.3129\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 273.6619 - val_loss: 303.8660\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 266.2136 - val_loss: 302.5428\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 258.9395 - val_loss: 301.3404\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 251.8374 - val_loss: 300.2563\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 244.9045 - val_loss: 299.2878\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 238.1383 - val_loss: 298.4324\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 231.5361 - val_loss: 297.6872\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 225.0954 - val_loss: 297.0499\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 218.8138 - val_loss: 296.5176\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 212.6886 - val_loss: 296.0880\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 206.7175 - val_loss: 295.7584\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 200.8977 - val_loss: 295.5261\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 195.2270 - val_loss: 295.3889\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 189.7026 - val_loss: 295.3440\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 184.3222 - val_loss: 295.3889\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 179.0835 - val_loss: 295.5212\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 173.9840 - val_loss: 295.7384\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 169.0211 - val_loss: 296.0379\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 164.1925 - val_loss: 296.4174\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 159.4956 - val_loss: 296.8745\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 154.9282 - val_loss: 297.4066\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 150.4881 - val_loss: 298.0113\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 146.1725 - val_loss: 298.6863\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 141.9793 - val_loss: 299.4293\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 137.9062 - val_loss: 300.2378\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 133.9509 - val_loss: 301.1096\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 130.1106 - val_loss: 302.0423\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 126.3838 - val_loss: 303.0336\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 122.7678 - val_loss: 304.0813\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 119.2605 - val_loss: 305.1830\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 115.8594 - val_loss: 306.3366\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 112.5626 - val_loss: 307.5400\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 109.3678 - val_loss: 308.7908\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 106.2727 - val_loss: 310.0869\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 103.2752 - val_loss: 311.4264\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 100.3732 - val_loss: 312.8067\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 97.5646 - val_loss: 314.2261\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 94.8470 - val_loss: 315.6826\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 92.2188 - val_loss: 317.1738\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 89.6776 - val_loss: 318.6980\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 87.2214 - val_loss: 320.2531\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 84.8481 - val_loss: 321.8371\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 82.5560 - val_loss: 323.4482\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 80.3429 - val_loss: 325.0844\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 78.2070 - val_loss: 326.7439\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 76.1461 - val_loss: 328.4250\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 74.1584 - val_loss: 330.1255\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 72.2421 - val_loss: 331.8443\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 70.3950 - val_loss: 333.5792\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 68.6157 - val_loss: 335.3283\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 66.9022 - val_loss: 337.0901\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 65.2528 - val_loss: 338.8633\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 63.6656 - val_loss: 340.6459\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 62.1389 - val_loss: 342.4364\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 60.6710 - val_loss: 344.2332\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 59.2602 - val_loss: 346.0350\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 57.9050 - val_loss: 347.8403\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 56.6034 - val_loss: 349.6476\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 55.3540 - val_loss: 351.4555\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 54.1551 - val_loss: 353.2626\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 53.0054 - val_loss: 355.0678\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 51.9032 - val_loss: 356.8696\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 50.8470 - val_loss: 358.6666\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 49.8353 - val_loss: 360.4579\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 48.8667 - val_loss: 362.2424\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 47.9398 - val_loss: 364.0185\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 47.0532 - val_loss: 365.7852\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 46.2056 - val_loss: 367.5419\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 45.3956 - val_loss: 369.2874\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 44.6217 - val_loss: 371.0206\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 43.8830 - val_loss: 372.7403\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 43.1779 - val_loss: 374.4462\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 42.5053 - val_loss: 376.1368\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 41.8642 - val_loss: 377.8116\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 41.2533 - val_loss: 379.4699\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 40.6714 - val_loss: 381.1106\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 40.1175 - val_loss: 382.7334\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 39.5905 - val_loss: 384.3375\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 39.0892 - val_loss: 385.9223\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 38.6126 - val_loss: 387.4869\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 38.1600 - val_loss: 389.0307\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 37.7301 - val_loss: 390.5536\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 37.3222 - val_loss: 392.0551\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 36.9352 - val_loss: 393.5343\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 36.5683 - val_loss: 394.9909\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 36.2207 - val_loss: 396.4248\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 35.8914 - val_loss: 397.8356\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 35.5797 - val_loss: 399.2227\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 35.2849 - val_loss: 400.5861\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 35.0061 - val_loss: 401.9252\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 34.7426 - val_loss: 403.2402\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 34.4938 - val_loss: 404.5304\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 34.2589 - val_loss: 405.7963\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 34.0373 - val_loss: 407.0374\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 33.8283 - val_loss: 408.2536\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 33.6313 - val_loss: 409.4444\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 33.4458 - val_loss: 410.6104\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 33.2712 - val_loss: 411.7511\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 33.1069 - val_loss: 412.8672\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 32.9524 - val_loss: 413.9582\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 32.8072 - val_loss: 415.0242\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 32.6708 - val_loss: 416.0653\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 32.5428 - val_loss: 417.0817\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 32.4228 - val_loss: 418.0736\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 32.3101 - val_loss: 419.0409\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 32.2046 - val_loss: 419.9837\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 32.1058 - val_loss: 420.9023\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 32.0134 - val_loss: 421.7971\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 31.9268 - val_loss: 422.6683\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.8459 - val_loss: 423.5158\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.7704 - val_loss: 424.3398\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.6998 - val_loss: 425.1415\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.6339 - val_loss: 425.9201\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.5725 - val_loss: 426.6766\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.5152 - val_loss: 427.4109\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 31.4619 - val_loss: 428.1234\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.4122 - val_loss: 428.8141\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 31.3659 - val_loss: 429.4841\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.3229 - val_loss: 430.1334\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.2830 - val_loss: 430.7621\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.2458 - val_loss: 431.3709\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.2113 - val_loss: 431.9600\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.1793 - val_loss: 432.5298\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 31.1497 - val_loss: 433.0807\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.1222 - val_loss: 433.6134\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.0967 - val_loss: 434.1276\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.0731 - val_loss: 434.6243\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.0513 - val_loss: 435.1039\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 31.0311 - val_loss: 435.5663\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.0124 - val_loss: 436.0125\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 30.9952 - val_loss: 436.4426\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.9793 - val_loss: 436.8568\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.9646 - val_loss: 437.2555\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.9511 - val_loss: 437.6393\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.9386 - val_loss: 438.0089\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.9271 - val_loss: 438.3643\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.9165 - val_loss: 438.7056\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.9068 - val_loss: 439.0333\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8979 - val_loss: 439.3485\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8897 - val_loss: 439.6509\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8822 - val_loss: 439.9412\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8752 - val_loss: 440.2199\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8689 - val_loss: 440.4867\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8631 - val_loss: 440.7426\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8578 - val_loss: 440.9879\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8529 - val_loss: 441.2223\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8485 - val_loss: 441.4471\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8444 - val_loss: 441.6620\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8408 - val_loss: 441.8671\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8374 - val_loss: 442.0636\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8343 - val_loss: 442.2509\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8316 - val_loss: 442.4302\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8291 - val_loss: 442.6012\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8268 - val_loss: 442.7644\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8247 - val_loss: 442.9201\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 30.8228 - val_loss: 443.0682\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8212 - val_loss: 443.2093\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8197 - val_loss: 443.3438\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8184 - val_loss: 443.4720\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8172 - val_loss: 443.5939\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8161 - val_loss: 443.7101\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8151 - val_loss: 443.8203\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8143 - val_loss: 443.9250\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8136 - val_loss: 444.0247\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8130 - val_loss: 444.1192\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8124 - val_loss: 444.2088\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8119 - val_loss: 444.2936\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8116 - val_loss: 444.3742\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8113 - val_loss: 444.4503\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8111 - val_loss: 444.5230\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8108 - val_loss: 444.5915\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8107 - val_loss: 444.6566\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8106 - val_loss: 444.7180\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8105 - val_loss: 444.7758\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8105 - val_loss: 444.8307\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8106 - val_loss: 444.8825\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8106 - val_loss: 444.9312\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 30.8107 - val_loss: 444.9774\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8109 - val_loss: 445.0211\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8110 - val_loss: 445.0622\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8112 - val_loss: 445.1007\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8114 - val_loss: 445.1369\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8117 - val_loss: 445.1716\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8119 - val_loss: 445.2038\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8122 - val_loss: 445.2341\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8124 - val_loss: 445.2623\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8127 - val_loss: 445.2890\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8130 - val_loss: 445.3140\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8134 - val_loss: 445.3374\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8137 - val_loss: 445.3596\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8140 - val_loss: 445.3805\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8144 - val_loss: 445.3997\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8147 - val_loss: 445.4180\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8151 - val_loss: 445.4347\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8155 - val_loss: 445.4506\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8158 - val_loss: 445.4652\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8162 - val_loss: 445.4789\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8166 - val_loss: 445.4916\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8170 - val_loss: 445.5035\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 30.8174 - val_loss: 445.5146\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8178 - val_loss: 445.5250\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8182 - val_loss: 445.5349\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8186 - val_loss: 445.5435\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8190 - val_loss: 445.5517\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8194 - val_loss: 445.5593\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8199 - val_loss: 445.5665\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8203 - val_loss: 445.5733\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8207 - val_loss: 445.5793\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8211 - val_loss: 445.5847\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8215 - val_loss: 445.5898\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8219 - val_loss: 445.5947\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8223 - val_loss: 445.5986\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8227 - val_loss: 445.6029\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8231 - val_loss: 445.6066\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8235 - val_loss: 445.6095\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8239 - val_loss: 445.6125\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8243 - val_loss: 445.6152\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8247 - val_loss: 445.6177\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8251 - val_loss: 445.6202\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8255 - val_loss: 445.6220\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 30.8259 - val_loss: 445.6240\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8263 - val_loss: 445.6257\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8266 - val_loss: 445.6270\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8270 - val_loss: 445.6280\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8274 - val_loss: 445.6288\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8277 - val_loss: 445.6294\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8281 - val_loss: 445.6301\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8285 - val_loss: 445.6310\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8289 - val_loss: 445.6316\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8292 - val_loss: 445.6317\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8296 - val_loss: 445.6317\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8300 - val_loss: 445.6320\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8303 - val_loss: 445.6322\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8306 - val_loss: 445.6319\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8310 - val_loss: 445.6316\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8313 - val_loss: 445.6314\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8316 - val_loss: 445.6313\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8320 - val_loss: 445.6310\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8324 - val_loss: 445.6309\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8326 - val_loss: 445.6308\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8330 - val_loss: 445.6306\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8333 - val_loss: 445.6301\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8336 - val_loss: 445.6295\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 30.8339 - val_loss: 445.6292\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8342 - val_loss: 445.6285\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8345 - val_loss: 445.6278\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8348 - val_loss: 445.6273\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8351 - val_loss: 445.6266\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8354 - val_loss: 445.6259\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8357 - val_loss: 445.6255\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8359 - val_loss: 445.6246\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8362 - val_loss: 445.6241\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8365 - val_loss: 445.6234\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8367 - val_loss: 445.6224\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8371 - val_loss: 445.6218\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8373 - val_loss: 445.6213\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8376 - val_loss: 445.6208\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8378 - val_loss: 445.6199\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8380 - val_loss: 445.6192\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8383 - val_loss: 445.6185\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8385 - val_loss: 445.6175\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8388 - val_loss: 445.6167\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 30.8390 - val_loss: 445.6160\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8393 - val_loss: 445.6155\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8395 - val_loss: 445.6147\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8397 - val_loss: 445.6139\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8399 - val_loss: 445.6131\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8401 - val_loss: 445.6123\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8404 - val_loss: 445.6116\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8406 - val_loss: 445.6109\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8407 - val_loss: 445.6102\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8410 - val_loss: 445.6097\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8412 - val_loss: 445.6087\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8414 - val_loss: 445.6081\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8416 - val_loss: 445.6074\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8418 - val_loss: 445.6070\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8420 - val_loss: 445.6064\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8422 - val_loss: 445.6061\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8423 - val_loss: 445.6055\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8425 - val_loss: 445.6047\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8427 - val_loss: 445.6041\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 30.8428 - val_loss: 445.6032\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8430 - val_loss: 445.6026\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8432 - val_loss: 445.6021\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8434 - val_loss: 445.6014\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8435 - val_loss: 445.6006\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8437 - val_loss: 445.5999\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8438 - val_loss: 445.5992\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8440 - val_loss: 445.5990\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8441 - val_loss: 445.5986\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8443 - val_loss: 445.5982\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8445 - val_loss: 445.5980\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8446 - val_loss: 445.5978\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8447 - val_loss: 445.5974\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8448 - val_loss: 445.5966\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8450 - val_loss: 445.5959\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8451 - val_loss: 445.5956\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8453 - val_loss: 445.5951\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8454 - val_loss: 445.5948\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8455 - val_loss: 445.5943\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 30.8457 - val_loss: 445.5934\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8458 - val_loss: 445.5928\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8459 - val_loss: 445.5922\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8460 - val_loss: 445.5920\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8461 - val_loss: 445.5917\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8462 - val_loss: 445.5911\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8464 - val_loss: 445.5905\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8465 - val_loss: 445.5904\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8466 - val_loss: 445.5898\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8467 - val_loss: 445.5894\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8468 - val_loss: 445.5889\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8469 - val_loss: 445.5887\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8470 - val_loss: 445.5879\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8471 - val_loss: 445.5873\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8472 - val_loss: 445.5866\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8473 - val_loss: 445.5866\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8474 - val_loss: 445.5864\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8475 - val_loss: 445.5861\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8476 - val_loss: 445.5858\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 30.8477 - val_loss: 445.5856\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8477 - val_loss: 445.5853\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8478 - val_loss: 445.5846\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8479 - val_loss: 445.5843\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8480 - val_loss: 445.5836\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8481 - val_loss: 445.5834\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8482 - val_loss: 445.5835\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8482 - val_loss: 445.5833\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8484 - val_loss: 445.5834\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8484 - val_loss: 445.5831\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8485 - val_loss: 445.5829\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8485 - val_loss: 445.5824\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8487 - val_loss: 445.5823\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8487 - val_loss: 445.5821\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 30.8488 - val_loss: 445.5820\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8488 - val_loss: 445.5815\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8489 - val_loss: 445.5811\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8489 - val_loss: 445.5806\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8490 - val_loss: 445.5805\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8491 - val_loss: 445.5800\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8492 - val_loss: 445.5799\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8492 - val_loss: 445.5798\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8492 - val_loss: 445.5796\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8493 - val_loss: 445.5794\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8493 - val_loss: 445.5790\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8494 - val_loss: 445.5789\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8494 - val_loss: 445.5786\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8495 - val_loss: 445.5783\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8496 - val_loss: 445.5782\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8496 - val_loss: 445.5777\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 30.8496 - val_loss: 445.5769\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8498 - val_loss: 445.5768\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8498 - val_loss: 445.5765\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8498 - val_loss: 445.5763\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8499 - val_loss: 445.5762\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8500 - val_loss: 445.5762\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8500 - val_loss: 445.5762\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8500 - val_loss: 445.5757\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8501 - val_loss: 445.5756\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8501 - val_loss: 445.5755\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8501 - val_loss: 445.5754\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8501 - val_loss: 445.5752\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8502 - val_loss: 445.5748\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8503 - val_loss: 445.5746\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8503 - val_loss: 445.5742\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8503 - val_loss: 445.5738\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8504 - val_loss: 445.5741\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 30.8504 - val_loss: 445.5739\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8504 - val_loss: 445.5734\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8505 - val_loss: 445.5733\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8505 - val_loss: 445.5733\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 30.8506 - val_loss: 445.5735\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8506 - val_loss: 445.5734\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 325ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54.82478992, 54.80798319, 54.79117647, 54.77436975, 54.75756303,\n",
       "        54.7407563 , 54.72394958, 54.70714286, 54.69033613, 54.67352941,\n",
       "        54.65672269, 54.63991597, 54.62310924, 54.60630252, 54.5894958 ,\n",
       "        54.57268908, 54.55588235, 54.53907563, 54.52226891, 54.50546218,\n",
       "        54.48865546, 54.47184874, 54.45504202, 54.43823529, 54.42142857,\n",
       "        54.40462185, 54.38781513, 54.3710084 , 54.35420168, 54.33739496,\n",
       "        54.32058824, 54.30378151, 54.28046218, 54.2552521 , 54.23004202,\n",
       "        54.20483193, 54.17962185, 54.15441176, 54.12920168, 54.1039916 ,\n",
       "        54.07878151, 54.05357143, 54.02836134, 54.00315126, 53.97794118,\n",
       "        53.95273109, 53.92752101, 59.1351074 , 58.6309057 ,  0.        ,\n",
       "         0.        , 61.0164099 , 60.3861578 , 59.8447246 , 59.3405229 ,\n",
       "        58.8363212 , 58.3321195 , 58.1069795 , 57.980929  , 57.8348786 ,\n",
       "         0.23122965,  0.        , 59.0417367 , 58.537535  , 58.1583333 ,\n",
       "        58.0322829 , 57.9062325 , 57.7801821 , 57.6541316 , 57.5280812 ,\n",
       "        57.4020308 ,  0.        ,  0.49546638, 51.8863983 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.79186726,  0.        ,  0.        ,\n",
       "        48.18274689,  0.32067588,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.08696176,  0.09165882,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.18712984,  0.        ,  0.49284434,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49.92473156, 49.91119281, 49.89765406, 49.88411531, 49.87057656,\n",
       "       49.85703782, 49.84349907, 49.82996032, 49.81642157, 49.80288282,\n",
       "       49.78934407, 49.77580532, 49.76226657, 49.74872782, 49.73518908,\n",
       "       49.72165033, 49.70811158, 49.69457283, 49.68103408, 49.66749533,\n",
       "       49.65395658, 49.64041783, 49.62687908, 49.61334034, 49.59980159,\n",
       "       49.58626284, 49.57272409, 49.55918534, 49.54564659, 49.53210784,\n",
       "       49.51856909, 49.50503035, 49.4914916 , 49.47795285, 49.4644141 ,\n",
       "       49.45087535, 49.4373366 , 49.42379785, 49.4102591 , 49.39672035,\n",
       "       49.38318161, 49.36964286, 49.35610411, 49.34256536, 49.32902661,\n",
       "       49.31548786, 49.30194911, 49.28841036, 49.27487162, 49.26133287,\n",
       "       49.24779412, 49.23425537, 49.22071662, 49.20717787, 49.19363912,\n",
       "       49.18010037, 49.16656162, 49.15302288, 49.13948413, 49.12594538,\n",
       "       49.11240663, 49.09886788, 49.08532913, 49.07179038, 49.05825163,\n",
       "       49.04471289, 49.03117414, 49.01763539, 49.00409664, 48.99055789,\n",
       "       48.97701914, 48.96348039, 48.94994164, 48.93640289, 48.92286415,\n",
       "       48.9093254 , 48.89578665, 48.8822479 , 48.86870915, 48.8551704 ,\n",
       "       48.84163165, 48.8280929 , 48.81455415, 48.80101541, 48.79089977,\n",
       "       48.78106169, 48.77122361, 48.76138553, 48.75154745, 48.74170937,\n",
       "       48.73187129, 48.7220332 , 48.71219512, 48.70235704, 48.69251896,\n",
       "       48.68268088, 48.6728428 , 48.66300471, 48.65316663, 48.64332855])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.67045585414456\n",
      "19.29607333122777\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
