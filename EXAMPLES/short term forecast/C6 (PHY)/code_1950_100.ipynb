{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2045    49.992425\n",
       "2046    49.978887\n",
       "2047    49.965348\n",
       "2048    49.951809\n",
       "2049    49.938270\n",
       "Name: C6, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_1950_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "1945     0.246545\n",
       "1946     0.000000\n",
       "1947     1.303285\n",
       "1948     0.196369\n",
       "1949     0.317360\n",
       "Name: C6, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1950)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1, 251) (1500, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 4s 41ms/step - loss: 3811.7788 - val_loss: 2818.6311\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3739.6045 - val_loss: 2760.0410\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3662.5632 - val_loss: 2704.8889\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3607.8230 - val_loss: 2658.3896\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3554.6279 - val_loss: 2612.8892\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 3500.5125 - val_loss: 2555.9805\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3435.4246 - val_loss: 2509.1023\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3381.5120 - val_loss: 2463.2258\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3328.7964 - val_loss: 2418.3931\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3277.1299 - val_loss: 2374.4282\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3226.3462 - val_loss: 2331.2234\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3170.0413 - val_loss: 2275.0789\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3109.1384 - val_loss: 2229.4839\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3056.5188 - val_loss: 2185.2427\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3005.3276 - val_loss: 2142.1509\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2955.2905 - val_loss: 2099.9988\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2906.2139 - val_loss: 2058.6646\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2857.9834 - val_loss: 2018.0729\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2810.5286 - val_loss: 1978.1752\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2763.8008 - val_loss: 1938.9358\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2717.7637 - val_loss: 1900.3278\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2672.3911 - val_loss: 1862.3292\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2627.6602 - val_loss: 1824.9231\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2583.5525 - val_loss: 1788.0944\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2540.0535 - val_loss: 1751.8300\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2497.1499 - val_loss: 1716.1196\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2454.8296 - val_loss: 1680.9514\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 2413.0815 - val_loss: 1646.3174\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2371.8967 - val_loss: 1612.2090\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2331.2666 - val_loss: 1578.6177\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2291.1824 - val_loss: 1545.5364\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2251.6357 - val_loss: 1512.9583\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2212.6213 - val_loss: 1480.8761\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2174.1311 - val_loss: 1449.2843\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2136.1587 - val_loss: 1418.1760\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2098.6973 - val_loss: 1387.5463\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2061.7422 - val_loss: 1357.3887\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2025.2865 - val_loss: 1327.6979\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1989.3252 - val_loss: 1298.4688\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1953.8519 - val_loss: 1269.6958\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1918.8623 - val_loss: 1241.3741\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1884.3508 - val_loss: 1213.4989\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1850.3129 - val_loss: 1186.0649\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1816.7426 - val_loss: 1159.0677\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1783.6359 - val_loss: 1132.5022\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1750.9877 - val_loss: 1106.3640\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1718.7936 - val_loss: 1080.6490\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1687.0488 - val_loss: 1055.3523\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1655.7488 - val_loss: 1030.4692\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1624.8892 - val_loss: 1005.9956\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1594.4656 - val_loss: 981.9277\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1564.4734 - val_loss: 958.2606\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1534.9092 - val_loss: 934.9901\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1505.7681 - val_loss: 912.1127\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1477.0452 - val_loss: 889.6234\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1448.7375 - val_loss: 867.5187\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1420.8412 - val_loss: 845.7947\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1393.3512 - val_loss: 824.4473\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1366.2644 - val_loss: 803.4721\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1339.5760 - val_loss: 782.8657\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1313.2832 - val_loss: 762.6241\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1287.3810 - val_loss: 742.7432\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1261.8657 - val_loss: 723.2194\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1236.7343 - val_loss: 704.0486\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1211.9825 - val_loss: 685.2275\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1187.6062 - val_loss: 666.7523\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1163.6027 - val_loss: 648.6192\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1139.9675 - val_loss: 630.8243\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1116.6967 - val_loss: 613.3640\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1093.7872 - val_loss: 596.2350\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1071.2354 - val_loss: 579.4330\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1049.0375 - val_loss: 562.9554\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1027.1901 - val_loss: 546.7975\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1005.6891 - val_loss: 530.9565\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 984.5320 - val_loss: 515.4288\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 963.7145 - val_loss: 500.2105\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 943.2335 - val_loss: 485.2989\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 923.0858 - val_loss: 470.6898\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 903.2673 - val_loss: 456.3797\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 883.7748 - val_loss: 442.3656\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 864.6052 - val_loss: 428.6438\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 845.7549 - val_loss: 415.2108\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 827.2204 - val_loss: 402.0636\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 808.9984 - val_loss: 389.1988\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 791.0861 - val_loss: 376.6125\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 773.4794 - val_loss: 364.3018\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 756.1757 - val_loss: 352.2634\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 739.1716 - val_loss: 340.4938\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 722.4638 - val_loss: 328.9899\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 706.0488 - val_loss: 317.7482\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 689.9236 - val_loss: 306.7657\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 674.0851 - val_loss: 296.0388\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 658.5298 - val_loss: 285.5647\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 643.2549 - val_loss: 275.3397\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 628.2570 - val_loss: 265.3612\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 613.5333 - val_loss: 255.6252\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 599.0800 - val_loss: 246.1292\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 584.8945 - val_loss: 236.8695\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 570.9736 - val_loss: 227.8433\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 557.3142 - val_loss: 219.0476\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 543.9133 - val_loss: 210.4788\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 530.7678 - val_loss: 202.1339\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 517.8745 - val_loss: 194.0100\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 505.2307 - val_loss: 186.1040\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 492.8331 - val_loss: 178.4127\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 480.6789 - val_loss: 170.9331\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 468.7648 - val_loss: 163.6618\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 457.0881 - val_loss: 156.5960\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 445.6458 - val_loss: 149.7329\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 434.4346 - val_loss: 143.0690\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 423.4518 - val_loss: 136.6016\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 412.6946 - val_loss: 130.3277\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 402.1600 - val_loss: 124.2440\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 391.8451 - val_loss: 118.3478\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 381.7469 - val_loss: 112.6363\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 371.8625 - val_loss: 107.1059\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 362.1892 - val_loss: 101.7542\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 352.7241 - val_loss: 96.5781\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 343.4642 - val_loss: 91.5747\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 334.4067 - val_loss: 86.7412\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 325.5489 - val_loss: 82.0744\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 316.8878 - val_loss: 77.5716\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 308.4208 - val_loss: 73.2299\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 300.1450 - val_loss: 69.0465\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 292.0578 - val_loss: 65.0184\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 284.1562 - val_loss: 61.1429\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 276.4377 - val_loss: 57.4173\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 268.8992 - val_loss: 53.8382\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 261.5381 - val_loss: 50.4035\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 254.3519 - val_loss: 47.1100\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 247.3376 - val_loss: 43.9550\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 240.4928 - val_loss: 40.9359\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 233.8147 - val_loss: 38.0499\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 227.3006 - val_loss: 35.2942\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 220.9479 - val_loss: 32.6659\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 214.7540 - val_loss: 30.1628\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 208.7162 - val_loss: 27.7818\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 202.8320 - val_loss: 25.5205\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 197.0989 - val_loss: 23.3759\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.5139 - val_loss: 21.3456\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 186.0749 - val_loss: 19.4271\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 180.7791 - val_loss: 17.6175\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 175.6241 - val_loss: 15.9145\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 170.6074 - val_loss: 14.3153\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 165.7263 - val_loss: 12.8175\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 160.9785 - val_loss: 11.4186\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 156.3616 - val_loss: 10.1159\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 151.8728 - val_loss: 8.9071\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 147.5102 - val_loss: 7.7896\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 143.2710 - val_loss: 6.7610\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 139.1529 - val_loss: 5.8190\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 135.1535 - val_loss: 4.9609\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 131.2704 - val_loss: 4.1846\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 127.5015 - val_loss: 3.4876\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 123.8442 - val_loss: 2.8675\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 120.2963 - val_loss: 2.3221\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 116.8556 - val_loss: 1.8490\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 113.5197 - val_loss: 1.4460\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 110.2864 - val_loss: 1.1109\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 107.1535 - val_loss: 0.8413\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 104.1188 - val_loss: 0.6351\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 101.1800 - val_loss: 0.4901\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 98.3351 - val_loss: 0.4042\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 95.5820 - val_loss: 0.3752\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 92.9184 - val_loss: 0.4011\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 90.3424 - val_loss: 0.4798\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 87.8517 - val_loss: 0.6091\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 85.4444 - val_loss: 0.7873\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 83.1183 - val_loss: 1.0121\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 80.8717 - val_loss: 1.2818\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 78.7025 - val_loss: 1.5942\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 76.6088 - val_loss: 1.9477\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 74.5885 - val_loss: 2.3402\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 72.6399 - val_loss: 2.7700\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 70.7609 - val_loss: 3.2352\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 68.9498 - val_loss: 3.7341\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 67.2047 - val_loss: 4.2649\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 65.5239 - val_loss: 4.8260\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 63.9055 - val_loss: 5.4155\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 62.3481 - val_loss: 6.0320\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 60.8495 - val_loss: 6.6737\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 59.4083 - val_loss: 7.3393\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 58.0226 - val_loss: 8.0268\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 56.6911 - val_loss: 8.7350\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 55.4119 - val_loss: 9.4624\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 54.1837 - val_loss: 10.2075\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 53.0046 - val_loss: 10.9690\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 51.8733 - val_loss: 11.7453\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 50.7883 - val_loss: 12.5353\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 49.7480 - val_loss: 13.3375\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 48.7510 - val_loss: 14.1508\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.7960 - val_loss: 14.9739\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 46.8815 - val_loss: 15.8055\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 46.0063 - val_loss: 16.6445\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 45.1689 - val_loss: 17.4899\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 44.3680 - val_loss: 18.3404\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 43.6025 - val_loss: 19.1951\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 42.8710 - val_loss: 20.0528\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 42.1724 - val_loss: 20.9128\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 41.5054 - val_loss: 21.7738\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 40.8689 - val_loss: 22.6351\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 40.2618 - val_loss: 23.4960\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 39.6828 - val_loss: 24.3551\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 39.1313 - val_loss: 25.2120\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 38.6058 - val_loss: 26.0658\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 38.1055 - val_loss: 26.9157\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 37.6294 - val_loss: 27.7611\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 37.1766 - val_loss: 28.6014\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 36.7459 - val_loss: 29.4356\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 36.3366 - val_loss: 30.2633\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 35.9478 - val_loss: 31.0840\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 35.5786 - val_loss: 31.8970\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 35.2283 - val_loss: 32.7017\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 34.8959 - val_loss: 33.4979\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 34.5808 - val_loss: 34.2848\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 34.2821 - val_loss: 35.0621\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.9992 - val_loss: 35.8294\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.7314 - val_loss: 36.5864\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.4779 - val_loss: 37.3328\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.2381 - val_loss: 38.0683\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.0113 - val_loss: 38.7920\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 32.7971 - val_loss: 39.5044\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 32.5947 - val_loss: 40.2048\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 32.4036 - val_loss: 40.8933\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 32.2232 - val_loss: 41.5694\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 32.0531 - val_loss: 42.2329\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.8927 - val_loss: 42.8840\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.7416 - val_loss: 43.5221\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.5993 - val_loss: 44.1477\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.4652 - val_loss: 44.7603\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.3391 - val_loss: 45.3599\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.2205 - val_loss: 45.9464\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.1089 - val_loss: 46.5199\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.0041 - val_loss: 47.0802\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.9056 - val_loss: 47.6274\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.8132 - val_loss: 48.1616\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.7264 - val_loss: 48.6829\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 30.6450 - val_loss: 49.1912\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.5687 - val_loss: 49.6866\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.4971 - val_loss: 50.1692\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.4301 - val_loss: 50.6389\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.3673 - val_loss: 51.0959\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.3086 - val_loss: 51.5404\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.2536 - val_loss: 51.9728\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.2022 - val_loss: 52.3928\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.1541 - val_loss: 52.8008\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.1092 - val_loss: 53.1967\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.0673 - val_loss: 53.5810\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.0280 - val_loss: 53.9535\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.9914 - val_loss: 54.3144\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.9573 - val_loss: 54.6644\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.9254 - val_loss: 55.0031\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.8957 - val_loss: 55.3310\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.8680 - val_loss: 55.6480\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.8422 - val_loss: 55.9547\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.8182 - val_loss: 56.2510\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.7958 - val_loss: 56.5373\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.7750 - val_loss: 56.8137\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.7556 - val_loss: 57.0805\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.7376 - val_loss: 57.3378\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.7208 - val_loss: 57.5862\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.7052 - val_loss: 57.8256\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.6907 - val_loss: 58.0560\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.6772 - val_loss: 58.2778\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 29.6647 - val_loss: 58.4916\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 29.6531 - val_loss: 58.6971\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.6423 - val_loss: 58.8947\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.6323 - val_loss: 59.0847\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.6229 - val_loss: 59.2673\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.6143 - val_loss: 59.4425\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.6063 - val_loss: 59.6108\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5989 - val_loss: 59.7723\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5920 - val_loss: 59.9271\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5856 - val_loss: 60.0755\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5798 - val_loss: 60.2178\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5743 - val_loss: 60.3540\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5692 - val_loss: 60.4844\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5646 - val_loss: 60.6092\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5602 - val_loss: 60.7285\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5562 - val_loss: 60.8426\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5525 - val_loss: 60.9515\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5492 - val_loss: 61.0558\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5460 - val_loss: 61.1552\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5431 - val_loss: 61.2501\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5404 - val_loss: 61.3405\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5380 - val_loss: 61.4269\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 29.5357 - val_loss: 61.5089\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5336 - val_loss: 61.5873\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5317 - val_loss: 61.6618\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5300 - val_loss: 61.7330\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5284 - val_loss: 61.8004\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5269 - val_loss: 61.8647\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5256 - val_loss: 61.9258\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5244 - val_loss: 61.9838\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5233 - val_loss: 62.0390\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5223 - val_loss: 62.0913\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5214 - val_loss: 62.1409\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 29.5206 - val_loss: 62.1880\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5199 - val_loss: 62.2325\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5193 - val_loss: 62.2747\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5187 - val_loss: 62.3145\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5182 - val_loss: 62.3526\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5178 - val_loss: 62.3882\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5174 - val_loss: 62.4219\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5171 - val_loss: 62.4540\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5169 - val_loss: 62.4842\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5167 - val_loss: 62.5128\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 29.5165 - val_loss: 62.5398\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5164 - val_loss: 62.5652\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5163 - val_loss: 62.5891\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5162 - val_loss: 62.6117\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5163 - val_loss: 62.6331\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5162 - val_loss: 62.6529\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5163 - val_loss: 62.6719\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5164 - val_loss: 62.6896\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5165 - val_loss: 62.7061\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5166 - val_loss: 62.7219\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5168 - val_loss: 62.7366\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 29.5170 - val_loss: 62.7504\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5172 - val_loss: 62.7634\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5174 - val_loss: 62.7754\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5176 - val_loss: 62.7868\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5179 - val_loss: 62.7974\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5181 - val_loss: 62.8072\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5183 - val_loss: 62.8166\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5187 - val_loss: 62.8251\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5190 - val_loss: 62.8332\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5193 - val_loss: 62.8407\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5196 - val_loss: 62.8476\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5199 - val_loss: 62.8541\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 29.5202 - val_loss: 62.8601\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5206 - val_loss: 62.8656\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5209 - val_loss: 62.8709\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5213 - val_loss: 62.8757\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5216 - val_loss: 62.8801\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5220 - val_loss: 62.8842\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5224 - val_loss: 62.8881\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5227 - val_loss: 62.8914\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5231 - val_loss: 62.8947\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5235 - val_loss: 62.8976\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5238 - val_loss: 62.9004\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5242 - val_loss: 62.9026\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5246 - val_loss: 62.9050\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5250 - val_loss: 62.9071\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5254 - val_loss: 62.9090\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5258 - val_loss: 62.9105\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5262 - val_loss: 62.9121\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5265 - val_loss: 62.9132\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5270 - val_loss: 62.9144\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5274 - val_loss: 62.9158\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5277 - val_loss: 62.9167\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5281 - val_loss: 62.9176\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5285 - val_loss: 62.9182\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5288 - val_loss: 62.9190\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5292 - val_loss: 62.9195\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5296 - val_loss: 62.9196\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 29.5300 - val_loss: 62.9199\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5304 - val_loss: 62.9202\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5307 - val_loss: 62.9204\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 29.5311 - val_loss: 62.9205\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 29.5315 - val_loss: 62.9206\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5319 - val_loss: 62.9207\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5322 - val_loss: 62.9208\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5326 - val_loss: 62.9208\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5329 - val_loss: 62.9207\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 29.5333 - val_loss: 62.9204\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5336 - val_loss: 62.9202\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5340 - val_loss: 62.9201\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5343 - val_loss: 62.9199\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5347 - val_loss: 62.9198\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5350 - val_loss: 62.9197\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5353 - val_loss: 62.9194\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5356 - val_loss: 62.9189\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5360 - val_loss: 62.9184\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5363 - val_loss: 62.9181\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 29.5367 - val_loss: 62.9177\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 29.5370 - val_loss: 62.9173\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5373 - val_loss: 62.9168\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5376 - val_loss: 62.9164\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5379 - val_loss: 62.9158\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5382 - val_loss: 62.9155\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5385 - val_loss: 62.9150\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5388 - val_loss: 62.9146\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5391 - val_loss: 62.9141\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5394 - val_loss: 62.9137\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5396 - val_loss: 62.9130\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5399 - val_loss: 62.9124\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.5402 - val_loss: 62.9120\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5405 - val_loss: 62.9117\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5408 - val_loss: 62.9111\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5410 - val_loss: 62.9105\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5413 - val_loss: 62.9100\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5415 - val_loss: 62.9095\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5418 - val_loss: 62.9090\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5421 - val_loss: 62.9086\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5423 - val_loss: 62.9083\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5425 - val_loss: 62.9077\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5428 - val_loss: 62.9071\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5431 - val_loss: 62.9068\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 29.5433 - val_loss: 62.9064\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5435 - val_loss: 62.9059\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5438 - val_loss: 62.9055\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5440 - val_loss: 62.9050\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5442 - val_loss: 62.9047\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5444 - val_loss: 62.9042\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 29.5446 - val_loss: 62.9038\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5448 - val_loss: 62.9033\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5451 - val_loss: 62.9030\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5452 - val_loss: 62.9026\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5455 - val_loss: 62.9024\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5456 - val_loss: 62.9018\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5458 - val_loss: 62.9015\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5460 - val_loss: 62.9010\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5462 - val_loss: 62.9007\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 29.5464 - val_loss: 62.9003\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5466 - val_loss: 62.9001\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5468 - val_loss: 62.8993\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5470 - val_loss: 62.8991\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5472 - val_loss: 62.8988\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5473 - val_loss: 62.8985\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5475 - val_loss: 62.8983\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 29.5477 - val_loss: 62.8977\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 29.5478 - val_loss: 62.8972\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5480 - val_loss: 62.8968\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5482 - val_loss: 62.8966\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5483 - val_loss: 62.8963\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5485 - val_loss: 62.8958\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5486 - val_loss: 62.8954\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5488 - val_loss: 62.8949\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5489 - val_loss: 62.8947\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.5491 - val_loss: 62.8943\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5492 - val_loss: 62.8937\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5494 - val_loss: 62.8934\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5495 - val_loss: 62.8931\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5497 - val_loss: 62.8930\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5498 - val_loss: 62.8926\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5499 - val_loss: 62.8923\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5501 - val_loss: 62.8919\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5502 - val_loss: 62.8916\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5503 - val_loss: 62.8915\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5505 - val_loss: 62.8913\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5505 - val_loss: 62.8908\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 29.5507 - val_loss: 62.8904\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5508 - val_loss: 62.8900\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5510 - val_loss: 62.8898\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.5510 - val_loss: 62.8896\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5512 - val_loss: 62.8893\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5512 - val_loss: 62.8890\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5514 - val_loss: 62.8889\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5515 - val_loss: 62.8887\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.5516 - val_loss: 62.8886\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5517 - val_loss: 62.8884\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 29.5518 - val_loss: 62.8881\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5519 - val_loss: 62.8880\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.5519 - val_loss: 62.8876\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.5521 - val_loss: 62.8874\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.5522 - val_loss: 62.8872\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.5523 - val_loss: 62.8871\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 29.5524 - val_loss: 62.8869\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.5525 - val_loss: 62.8868\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5525 - val_loss: 62.8865\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.5526 - val_loss: 62.8863\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.5527 - val_loss: 62.8862\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5528 - val_loss: 62.8857\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5529 - val_loss: 62.8855\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5530 - val_loss: 62.8854\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5531 - val_loss: 62.8854\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5532 - val_loss: 62.8854\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 29.5532 - val_loss: 62.8854\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5532 - val_loss: 62.8849\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5534 - val_loss: 62.8849\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5534 - val_loss: 62.8848\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5535 - val_loss: 62.8847\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5536 - val_loss: 62.8846\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5536 - val_loss: 62.8842\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5537 - val_loss: 62.8842\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.5538 - val_loss: 62.8839\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5539 - val_loss: 62.8839\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5539 - val_loss: 62.8836\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5540 - val_loss: 62.8834\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.5541 - val_loss: 62.8834\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5541 - val_loss: 62.8834\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5541 - val_loss: 62.8831\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5542 - val_loss: 62.8831\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5542 - val_loss: 62.8830\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5543 - val_loss: 62.8829\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5544 - val_loss: 62.8828\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5544 - val_loss: 62.8827\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5545 - val_loss: 62.8827\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 29.5546 - val_loss: 62.8826\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5546 - val_loss: 62.8823\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5547 - val_loss: 62.8823\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5547 - val_loss: 62.8822\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5548 - val_loss: 62.8822\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5548 - val_loss: 62.8822\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 29.5548 - val_loss: 62.8819\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5549 - val_loss: 62.8819\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5549 - val_loss: 62.8817\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5550 - val_loss: 62.8817\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.5550 - val_loss: 62.8816\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 349ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.54658497e+01, 5.54462418e+01, 5.54266340e+01, 5.54070261e+01,\n",
       "        5.53874183e+01, 5.53678105e+01, 5.53482026e+01, 5.53285948e+01,\n",
       "        5.53089869e+01, 5.52893791e+01, 5.52697712e+01, 5.52501634e+01,\n",
       "        5.52305556e+01, 5.52109477e+01, 5.51913399e+01, 5.51717320e+01,\n",
       "        5.51521242e+01, 5.51325163e+01, 5.51129085e+01, 5.50933007e+01,\n",
       "        5.50736928e+01, 5.50540850e+01, 5.50344771e+01, 5.50148693e+01,\n",
       "        5.49952614e+01, 5.49756536e+01, 5.49560458e+01, 5.49364379e+01,\n",
       "        5.49168301e+01, 5.48976191e+01, 5.48808123e+01, 5.48640056e+01,\n",
       "        5.48471989e+01, 5.48303922e+01, 5.48135854e+01, 5.47967787e+01,\n",
       "        5.47799720e+01, 5.47631653e+01, 5.47463585e+01, 5.47295518e+01,\n",
       "        5.47127451e+01, 5.46959384e+01, 5.46791317e+01, 5.46623249e+01,\n",
       "        5.46455182e+01, 5.46287115e+01, 5.46119048e+01, 5.45950980e+01,\n",
       "        5.45782913e+01, 5.45614846e+01, 5.45446779e+01, 5.45278712e+01,\n",
       "        5.45110644e+01, 5.44942577e+01, 5.44774510e+01, 5.44606443e+01,\n",
       "        5.44438375e+01, 5.44270308e+01, 5.44102241e+01, 5.43934174e+01,\n",
       "        5.43766106e+01, 5.43598039e+01, 5.43429972e+01, 5.43261905e+01,\n",
       "        5.43093838e+01, 5.42888655e+01, 5.42636555e+01, 5.42384454e+01,\n",
       "        5.42132353e+01, 5.41880252e+01, 5.41628151e+01, 5.41376050e+01,\n",
       "        5.41123950e+01, 5.40871849e+01, 5.40619748e+01, 5.40367647e+01,\n",
       "        5.40115546e+01, 5.39863445e+01, 5.39611345e+01, 5.39359244e+01,\n",
       "        6.28420219e+01, 3.37765515e-01, 1.29428238e-01, 3.81504953e-01,\n",
       "        2.86526829e-01, 8.96330327e-02, 4.23922651e-02, 4.75062817e-01,\n",
       "        1.12474418e+00, 7.58284330e-01, 0.00000000e+00, 2.49006376e-01,\n",
       "        6.48473263e-01, 0.00000000e+00, 1.95190489e-01, 7.46107101e-01,\n",
       "        0.00000000e+00, 2.12183177e-01, 5.60725451e-01, 7.99287319e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51.27860644, 51.26506769, 51.25152894, 51.2379902 , 51.22445145,\n",
       "       51.2109127 , 51.19737395, 51.1838352 , 51.17029645, 51.1567577 ,\n",
       "       51.14321895, 51.12968021, 51.11614146, 51.10260271, 51.08906396,\n",
       "       51.07552521, 51.06198646, 51.04844771, 51.03490896, 51.02137021,\n",
       "       51.00783147, 50.99429272, 50.98075397, 50.96721522, 50.95367647,\n",
       "       50.94013772, 50.92659897, 50.91306022, 50.89952148, 50.88598273,\n",
       "       50.87244398, 50.85890523, 50.84536648, 50.83182773, 50.81828898,\n",
       "       50.80475023, 50.79121148, 50.77767274, 50.76413399, 50.75059524,\n",
       "       50.73705649, 50.72351774, 50.70997899, 50.69644024, 50.68290149,\n",
       "       50.66936275, 50.655824  , 50.64228525, 50.6287465 , 50.61520775,\n",
       "       50.601669  , 50.58813025, 50.5745915 , 50.56105275, 50.54751401,\n",
       "       50.53397526, 50.52043651, 50.50689776, 50.49335901, 50.47982026,\n",
       "       50.46628151, 50.45274276, 50.43920401, 50.42566527, 50.41212652,\n",
       "       50.39858777, 50.38504902, 50.37151027, 50.35797152, 50.34443277,\n",
       "       50.33089402, 50.31735528, 50.30381653, 50.29027778, 50.27673903,\n",
       "       50.26320028, 50.24966153, 50.23612278, 50.22258403, 50.20904528,\n",
       "       50.19550654, 50.18196779, 50.16842904, 50.15489029, 50.14135154,\n",
       "       50.12781279, 50.11427404, 50.10073529, 50.08719655, 50.0736578 ,\n",
       "       50.06011905, 50.0465803 , 50.03304155, 50.0195028 , 50.00596405,\n",
       "       49.9924253 , 49.97888655, 49.96534781, 49.95180906, 49.93827031])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.98709631995553\n",
      "12.752072238890403\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
