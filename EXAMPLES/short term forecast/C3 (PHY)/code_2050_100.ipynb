{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2145    69.225046\n",
       "2146    69.218761\n",
       "2147    69.212475\n",
       "2148    69.206190\n",
       "2149    69.199904\n",
       "Name: C3, Length: 2150, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_2050_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2045     0.399315\n",
       "2046     0.389210\n",
       "2047     0.000000\n",
       "2048     0.000000\n",
       "2049     0.476624\n",
       "Name: C3, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2050)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 1, 251) (1600, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 25ms/step - loss: 5874.5928 - val_loss: 4760.2720\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5809.3604 - val_loss: 4709.1372\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5751.1089 - val_loss: 4658.3467\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5693.2407 - val_loss: 4607.9478\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5635.7915 - val_loss: 4557.9531\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5578.7666 - val_loss: 4508.3643\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5522.1670 - val_loss: 4459.1807\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5465.9912 - val_loss: 4410.3999\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5410.2393 - val_loss: 4362.0210\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5354.9072 - val_loss: 4314.0425\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5299.9946 - val_loss: 4266.4619\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5245.5000 - val_loss: 4219.2764\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5191.4180 - val_loss: 4172.4844\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5137.7495 - val_loss: 4126.0830\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5084.4907 - val_loss: 4080.0715\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5031.6377 - val_loss: 4034.4446\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4979.1890 - val_loss: 3989.2024\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4927.1445 - val_loss: 3944.3406\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4875.4980 - val_loss: 3899.8599\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4824.2505 - val_loss: 3855.7546\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4773.3975 - val_loss: 3812.0247\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4722.9375 - val_loss: 3768.6665\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4672.8687 - val_loss: 3725.6785\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4623.1870 - val_loss: 3683.0586\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4573.8916 - val_loss: 3640.8040\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4524.9795 - val_loss: 3598.9126\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4476.4473 - val_loss: 3557.3821\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4428.2954 - val_loss: 3516.2104\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4380.5195 - val_loss: 3475.3958\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4333.1182 - val_loss: 3434.9348\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4286.0889 - val_loss: 3394.8269\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4239.4297 - val_loss: 3355.0688\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4193.1377 - val_loss: 3315.6589\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 4147.2114 - val_loss: 3276.5945\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4101.6484 - val_loss: 3237.8740\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4056.4458 - val_loss: 3199.4956\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4011.6028 - val_loss: 3161.4565\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3967.1172 - val_loss: 3123.7551\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3922.9856 - val_loss: 3086.3894\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3879.2070 - val_loss: 3049.3569\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3835.7788 - val_loss: 3012.6567\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3792.6992 - val_loss: 2976.2856\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3749.9668 - val_loss: 2940.2417\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3707.5786 - val_loss: 2904.5242\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3665.5332 - val_loss: 2869.1304\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3623.8274 - val_loss: 2834.0581\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3582.4614 - val_loss: 2799.3057\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3541.4304 - val_loss: 2764.8718\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3500.7356 - val_loss: 2730.7532\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3460.3723 - val_loss: 2696.9487\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3420.3403 - val_loss: 2663.4575\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3380.6375 - val_loss: 2630.2761\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3341.2610 - val_loss: 2597.4036\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3302.2102 - val_loss: 2564.8381\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3263.4829 - val_loss: 2532.5774\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3225.0764 - val_loss: 2500.6196\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3186.9897 - val_loss: 2468.9639\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3149.2209 - val_loss: 2437.6077\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3111.7678 - val_loss: 2406.5496\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3074.6292 - val_loss: 2375.7876\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3037.8022 - val_loss: 2345.3206\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3001.2871 - val_loss: 2315.1460\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2965.0811 - val_loss: 2285.2622\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2929.1812 - val_loss: 2255.6675\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2893.5864 - val_loss: 2226.3606\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2858.2959 - val_loss: 2197.3403\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2823.3074 - val_loss: 2168.6040\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2788.6189 - val_loss: 2140.1499\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2754.2290 - val_loss: 2111.9775\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2720.1365 - val_loss: 2084.0840\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 2686.3389 - val_loss: 2056.4692\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2652.8350 - val_loss: 2029.1293\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2619.6230 - val_loss: 2002.0651\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2586.7012 - val_loss: 1975.2728\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2554.0688 - val_loss: 1948.7529\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2521.7234 - val_loss: 1922.5023\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2489.6636 - val_loss: 1896.5208\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2457.8875 - val_loss: 1870.8054\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2426.3938 - val_loss: 1845.3555\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2395.1816 - val_loss: 1820.1689\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2364.2485 - val_loss: 1795.2449\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2333.5930 - val_loss: 1770.5813\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2303.2144 - val_loss: 1746.1775\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2273.1106 - val_loss: 1722.0309\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 2243.2793 - val_loss: 1698.1409\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2213.7207 - val_loss: 1674.5046\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2184.4316 - val_loss: 1651.1221\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2155.4111 - val_loss: 1627.9915\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2126.6584 - val_loss: 1605.1106\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2098.1714 - val_loss: 1582.4791\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2069.9482 - val_loss: 1560.0944\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2041.9885 - val_loss: 1537.9558\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2014.2898 - val_loss: 1516.0616\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1986.8516 - val_loss: 1494.4114\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1959.6721 - val_loss: 1473.0022\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1932.7496 - val_loss: 1451.8333\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1906.0828 - val_loss: 1430.9036\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1879.6707 - val_loss: 1410.2117\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1853.5115 - val_loss: 1389.7550\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1827.6033 - val_loss: 1369.5336\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1801.9465 - val_loss: 1349.5455\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1776.5377 - val_loss: 1329.7894\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1751.3770 - val_loss: 1310.2639\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1726.4617 - val_loss: 1290.9673\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1701.7916 - val_loss: 1271.8982\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1677.3645 - val_loss: 1253.0569\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1653.1799 - val_loss: 1234.4398\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1629.2358 - val_loss: 1216.0472\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 1605.5310 - val_loss: 1197.8766\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1582.0643 - val_loss: 1179.9274\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1558.8347 - val_loss: 1162.1979\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1535.8401 - val_loss: 1144.6876\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1513.0800 - val_loss: 1127.3939\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1490.5529 - val_loss: 1110.3167\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1468.2568 - val_loss: 1093.4531\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1446.1913 - val_loss: 1076.8037\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1424.3547 - val_loss: 1060.3658\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1402.7456 - val_loss: 1044.1389\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1381.3632 - val_loss: 1028.1215\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1360.2054 - val_loss: 1012.3121\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1339.2722 - val_loss: 996.7092\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1318.5608 - val_loss: 981.3121\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1298.0713 - val_loss: 966.1198\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1277.8020 - val_loss: 951.1294\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1257.7507 - val_loss: 936.3420\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1237.9178 - val_loss: 921.7541\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1218.3011 - val_loss: 907.3660\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1198.8997 - val_loss: 893.1757\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1179.7120 - val_loss: 879.1819\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1160.7365 - val_loss: 865.3830\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1141.9724 - val_loss: 851.7783\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1123.4182 - val_loss: 838.3673\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1105.0737 - val_loss: 825.1476\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1086.9370 - val_loss: 812.1188\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1069.0070 - val_loss: 799.2784\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1051.2816 - val_loss: 786.6256\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1033.7601 - val_loss: 774.1597\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1016.4417 - val_loss: 761.8791\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 999.3249 - val_loss: 749.7825\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 982.4087 - val_loss: 737.8692\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 965.6916 - val_loss: 726.1368\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 949.1724 - val_loss: 714.5850\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 932.8499 - val_loss: 703.2120\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 916.7228 - val_loss: 692.0174\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 900.7903 - val_loss: 680.9990\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 885.0510 - val_loss: 670.1559\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 869.5037 - val_loss: 659.4872\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 854.1469 - val_loss: 648.9912\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 838.9800 - val_loss: 638.6666\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 824.0010 - val_loss: 628.5123\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 809.2097 - val_loss: 618.5275\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 794.6044 - val_loss: 608.7104\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 780.1837 - val_loss: 599.0597\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 765.9467 - val_loss: 589.5749\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 751.8922 - val_loss: 580.2538\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 738.0189 - val_loss: 571.0954\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 724.3258 - val_loss: 562.0997\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 710.8118 - val_loss: 553.2632\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 697.4750 - val_loss: 544.5864\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 684.3149 - val_loss: 536.0672\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 671.3300 - val_loss: 527.7047\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 658.5192 - val_loss: 519.4973\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 645.8809 - val_loss: 511.4438\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 633.4143 - val_loss: 503.5437\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 621.1186 - val_loss: 495.7946\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 608.9921 - val_loss: 488.1962\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 597.0338 - val_loss: 480.7469\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 585.2424 - val_loss: 473.4452\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 573.6169 - val_loss: 466.2902\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 562.1559 - val_loss: 459.2804\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 550.8583 - val_loss: 452.4146\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 539.7228 - val_loss: 445.6913\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 528.7480 - val_loss: 439.1094\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 517.9329 - val_loss: 432.6679\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 507.2766 - val_loss: 426.3651\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 496.7778 - val_loss: 420.2000\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 486.4354 - val_loss: 414.1714\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 476.2480 - val_loss: 408.2774\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 466.2140 - val_loss: 402.5175\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 456.3325 - val_loss: 396.8898\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 446.6025 - val_loss: 391.3936\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 437.0230 - val_loss: 386.0270\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 427.5920 - val_loss: 380.7890\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 418.3090 - val_loss: 375.6785\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 409.1724 - val_loss: 370.6937\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 400.1814 - val_loss: 365.8340\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 391.3344 - val_loss: 361.0974\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 382.6302 - val_loss: 356.4824\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 374.0674 - val_loss: 351.9885\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 365.6452 - val_loss: 347.6140\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 357.3622 - val_loss: 343.3578\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 349.2174 - val_loss: 339.2182\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 341.2092 - val_loss: 335.1940\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 333.3365 - val_loss: 331.2841\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 325.5982 - val_loss: 327.4868\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 317.9930 - val_loss: 323.8011\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 310.5194 - val_loss: 320.2255\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 303.1764 - val_loss: 316.7587\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 295.9630 - val_loss: 313.3994\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 288.8775 - val_loss: 310.1462\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 281.9189 - val_loss: 306.9977\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 275.0862 - val_loss: 303.9529\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 268.3777 - val_loss: 301.0101\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 261.7925 - val_loss: 298.1681\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 255.3294 - val_loss: 295.4255\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 248.9871 - val_loss: 292.7810\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 242.7641 - val_loss: 290.2333\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 236.6592 - val_loss: 287.7808\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 230.6711 - val_loss: 285.4222\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 224.7989 - val_loss: 283.1564\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 219.0411 - val_loss: 280.9820\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 213.3966 - val_loss: 278.8973\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 207.8639 - val_loss: 276.9012\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 202.4419 - val_loss: 274.9924\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 197.1294 - val_loss: 273.1693\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 191.9250 - val_loss: 271.4306\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 186.8272 - val_loss: 269.7751\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 181.8352 - val_loss: 268.2013\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 176.9475 - val_loss: 266.7078\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 172.1632 - val_loss: 265.2932\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 167.4806 - val_loss: 263.9565\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 162.8986 - val_loss: 262.6959\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 158.4160 - val_loss: 261.5101\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 154.0312 - val_loss: 260.3978\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 149.7433 - val_loss: 259.3577\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 145.5511 - val_loss: 258.3884\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 141.4531 - val_loss: 257.4885\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 137.4482 - val_loss: 256.6566\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 133.5350 - val_loss: 255.8914\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 129.7121 - val_loss: 255.1915\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 125.9787 - val_loss: 254.5555\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 122.3333 - val_loss: 253.9821\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 118.7746 - val_loss: 253.4700\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 115.3012 - val_loss: 253.0177\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 111.9122 - val_loss: 252.6239\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 108.6061 - val_loss: 252.2874\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 105.3816 - val_loss: 252.0065\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 102.2378 - val_loss: 251.7802\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 99.1731 - val_loss: 251.6071\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 96.1862 - val_loss: 251.4857\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 93.2760 - val_loss: 251.4148\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 90.4414 - val_loss: 251.3930\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 87.6810 - val_loss: 251.4192\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 84.9937 - val_loss: 251.4917\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 82.3782 - val_loss: 251.6095\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 79.8334 - val_loss: 251.7712\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 77.3577 - val_loss: 251.9754\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 74.9501 - val_loss: 252.2210\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 72.6095 - val_loss: 252.5066\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 70.3346 - val_loss: 252.8308\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 68.1241 - val_loss: 253.1927\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 65.9769 - val_loss: 253.5906\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 63.8919 - val_loss: 254.0236\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 61.8678 - val_loss: 254.4903\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 59.9034 - val_loss: 254.9894\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 57.9977 - val_loss: 255.5198\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 56.1494 - val_loss: 256.0801\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 54.3575 - val_loss: 256.6693\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 52.6205 - val_loss: 257.2862\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 50.9374 - val_loss: 257.9295\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 49.3071 - val_loss: 258.5981\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 47.7286 - val_loss: 259.2907\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 46.2007 - val_loss: 260.0063\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 44.7223 - val_loss: 260.7437\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 43.2921 - val_loss: 261.5019\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 41.9092 - val_loss: 262.2796\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 40.5725 - val_loss: 263.0759\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 39.2809 - val_loss: 263.8893\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 38.0334 - val_loss: 264.7194\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 36.8287 - val_loss: 265.5646\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 35.6661 - val_loss: 266.4240\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 34.5443 - val_loss: 267.2966\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 33.4625 - val_loss: 268.1814\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 32.4195 - val_loss: 269.0775\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 31.4143 - val_loss: 269.9837\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 30.4461 - val_loss: 270.8993\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 29.5137 - val_loss: 271.8232\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 28.6163 - val_loss: 272.7544\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 27.7530 - val_loss: 273.6922\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 26.9225 - val_loss: 274.6354\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 26.1243 - val_loss: 275.5836\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 25.3572 - val_loss: 276.5355\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 24.6204 - val_loss: 277.4905\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.9130 - val_loss: 278.4478\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.2342 - val_loss: 279.4064\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.5831 - val_loss: 280.3656\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.9588 - val_loss: 281.3248\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.3604 - val_loss: 282.2833\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.7873 - val_loss: 283.2402\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.2385 - val_loss: 284.1947\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7133 - val_loss: 285.1465\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.2109 - val_loss: 286.0948\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.7306 - val_loss: 287.0388\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 18.2716 - val_loss: 287.9778\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.8331 - val_loss: 288.9116\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 17.4145 - val_loss: 289.8394\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0151 - val_loss: 290.7607\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.6342 - val_loss: 291.6747\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.2711 - val_loss: 292.5815\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.9251 - val_loss: 293.4801\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 15.5957 - val_loss: 294.3702\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 15.2822 - val_loss: 295.2515\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.9839 - val_loss: 296.1234\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 14.7003 - val_loss: 296.9852\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 14.4309 - val_loss: 297.8373\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 14.1750 - val_loss: 298.6787\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 13.9322 - val_loss: 299.5093\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 13.7018 - val_loss: 300.3286\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 13.4833 - val_loss: 301.1368\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 13.2763 - val_loss: 301.9330\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 13.0803 - val_loss: 302.7173\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 12.8948 - val_loss: 303.4892\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 12.7193 - val_loss: 304.2488\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 12.5534 - val_loss: 304.9958\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 12.3966 - val_loss: 305.7300\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 12.2486 - val_loss: 306.4513\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 12.1090 - val_loss: 307.1592\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 11.9773 - val_loss: 307.8538\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 11.8531 - val_loss: 308.5352\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 11.7361 - val_loss: 309.2033\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 11.6260 - val_loss: 309.8575\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 11.5225 - val_loss: 310.4984\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 11.4251 - val_loss: 311.1255\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 11.3337 - val_loss: 311.7391\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 11.2477 - val_loss: 312.3388\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 11.1671 - val_loss: 312.9250\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 11.0915 - val_loss: 313.4973\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 11.0207 - val_loss: 314.0562\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.9543 - val_loss: 314.6017\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.8922 - val_loss: 315.1337\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.8341 - val_loss: 315.6519\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.7798 - val_loss: 316.1570\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.7291 - val_loss: 316.6487\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.6817 - val_loss: 317.1274\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.6376 - val_loss: 317.5930\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.5964 - val_loss: 318.0459\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.5580 - val_loss: 318.4860\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.5222 - val_loss: 318.9131\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.4890 - val_loss: 319.3279\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.4581 - val_loss: 319.7305\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.4294 - val_loss: 320.1207\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 10.4027 - val_loss: 320.4993\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.3780 - val_loss: 320.8660\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.3550 - val_loss: 321.2211\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.3338 - val_loss: 321.5645\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.3141 - val_loss: 321.8968\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.2959 - val_loss: 322.2183\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.2790 - val_loss: 322.5287\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.2635 - val_loss: 322.8288\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.2491 - val_loss: 323.1183\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.2358 - val_loss: 323.3974\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.2236 - val_loss: 323.6667\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.2123 - val_loss: 323.9267\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.2019 - val_loss: 324.1765\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 10.1924 - val_loss: 324.4175\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1836 - val_loss: 324.6490\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1756 - val_loss: 324.8723\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1681 - val_loss: 325.0867\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1614 - val_loss: 325.2929\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1551 - val_loss: 325.4908\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1494 - val_loss: 325.6807\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1442 - val_loss: 325.8629\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1394 - val_loss: 326.0374\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1350 - val_loss: 326.2049\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1310 - val_loss: 326.3652\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 10.1274 - val_loss: 326.5186\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1241 - val_loss: 326.6653\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1210 - val_loss: 326.8056\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 10.1183 - val_loss: 326.9396\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1158 - val_loss: 327.0679\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1135 - val_loss: 327.1903\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1115 - val_loss: 327.3072\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1096 - val_loss: 327.4183\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1080 - val_loss: 327.5247\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1064 - val_loss: 327.6257\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1050 - val_loss: 327.7215\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1038 - val_loss: 327.8136\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1027 - val_loss: 327.9004\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1017 - val_loss: 327.9833\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1008 - val_loss: 328.0622\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1000 - val_loss: 328.1367\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 10.0993 - val_loss: 328.2076\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 10.0987 - val_loss: 328.2747\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0981 - val_loss: 328.3383\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0977 - val_loss: 328.3984\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.0972 - val_loss: 328.4555\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0969 - val_loss: 328.5096\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0966 - val_loss: 328.5606\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0964 - val_loss: 328.6091\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0961 - val_loss: 328.6544\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0960 - val_loss: 328.6975\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.0958 - val_loss: 328.7380\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0957 - val_loss: 328.7763\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0957 - val_loss: 328.8122\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0956 - val_loss: 328.8460\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0956 - val_loss: 328.8779\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 10.0956 - val_loss: 328.9078\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0956 - val_loss: 328.9358\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0957 - val_loss: 328.9624\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0958 - val_loss: 328.9871\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0959 - val_loss: 329.0104\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0959 - val_loss: 329.0320\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0960 - val_loss: 329.0523\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0962 - val_loss: 329.0714\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0963 - val_loss: 329.0890\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0965 - val_loss: 329.1057\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0967 - val_loss: 329.1211\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0969 - val_loss: 329.1356\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0971 - val_loss: 329.1491\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0972 - val_loss: 329.1613\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.0974 - val_loss: 329.1729\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 10.0976 - val_loss: 329.1836\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.0979 - val_loss: 329.1937\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.0981 - val_loss: 329.2029\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0983 - val_loss: 329.2115\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0985 - val_loss: 329.2193\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 10.0988 - val_loss: 329.2266\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0990 - val_loss: 329.2331\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0993 - val_loss: 329.2389\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0995 - val_loss: 329.2447\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0998 - val_loss: 329.2497\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1000 - val_loss: 329.2545\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1003 - val_loss: 329.2591\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1005 - val_loss: 329.2629\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1008 - val_loss: 329.2665\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1011 - val_loss: 329.2697\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 10.1014 - val_loss: 329.2728\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1016 - val_loss: 329.2755\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1019 - val_loss: 329.2777\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1022 - val_loss: 329.2799\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1025 - val_loss: 329.2821\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1027 - val_loss: 329.2838\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1030 - val_loss: 329.2852\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1033 - val_loss: 329.2867\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1035 - val_loss: 329.2878\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1038 - val_loss: 329.2889\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1041 - val_loss: 329.2896\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1044 - val_loss: 329.2902\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 10.1047 - val_loss: 329.2908\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1049 - val_loss: 329.2914\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1052 - val_loss: 329.2917\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1055 - val_loss: 329.2919\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1057 - val_loss: 329.2919\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1060 - val_loss: 329.2919\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1063 - val_loss: 329.2919\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1065 - val_loss: 329.2915\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1068 - val_loss: 329.2913\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1071 - val_loss: 329.2910\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1074 - val_loss: 329.2906\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1076 - val_loss: 329.2901\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1079 - val_loss: 329.2896\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 10.1081 - val_loss: 329.2891\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1084 - val_loss: 329.2886\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1087 - val_loss: 329.2880\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1089 - val_loss: 329.2872\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1092 - val_loss: 329.2868\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1094 - val_loss: 329.2863\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1097 - val_loss: 329.2856\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1100 - val_loss: 329.2847\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1102 - val_loss: 329.2843\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1105 - val_loss: 329.2836\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1107 - val_loss: 329.2831\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1110 - val_loss: 329.2824\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 10.1112 - val_loss: 329.2816\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1115 - val_loss: 329.2811\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1117 - val_loss: 329.2806\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1119 - val_loss: 329.2797\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1122 - val_loss: 329.2792\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1124 - val_loss: 329.2787\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1126 - val_loss: 329.2779\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1128 - val_loss: 329.2769\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1131 - val_loss: 329.2765\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1133 - val_loss: 329.2757\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1136 - val_loss: 329.2748\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1138 - val_loss: 329.2744\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1140 - val_loss: 329.2736\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1142 - val_loss: 329.2729\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 10.1144 - val_loss: 329.2721\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1147 - val_loss: 329.2712\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1149 - val_loss: 329.2708\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1150 - val_loss: 329.2699\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1153 - val_loss: 329.2691\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1155 - val_loss: 329.2682\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1156 - val_loss: 329.2673\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1159 - val_loss: 329.2669\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1161 - val_loss: 329.2665\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1163 - val_loss: 329.2659\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1165 - val_loss: 329.2651\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1167 - val_loss: 329.2644\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 10.1169 - val_loss: 329.2639\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1170 - val_loss: 329.2632\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1172 - val_loss: 329.2625\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1175 - val_loss: 329.2624\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.1176 - val_loss: 329.2616\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1178 - val_loss: 329.2608\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1180 - val_loss: 329.2602\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1181 - val_loss: 329.2597\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1183 - val_loss: 329.2591\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1185 - val_loss: 329.2587\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1186 - val_loss: 329.2586\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 443ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.17874650e+01, 7.17846639e+01, 7.17818628e+01, 7.17790616e+01,\n",
       "        7.17762605e+01, 7.17734594e+01, 7.17706583e+01, 7.17678571e+01,\n",
       "        7.17650560e+01, 7.17622549e+01, 7.17594538e+01, 7.17566527e+01,\n",
       "        7.17538515e+01, 7.17510504e+01, 7.17482493e+01, 7.17454482e+01,\n",
       "        7.17426471e+01, 7.17398459e+01, 7.17370448e+01, 7.17342437e+01,\n",
       "        7.17314426e+01, 7.17286415e+01, 7.17258403e+01, 7.17230392e+01,\n",
       "        7.17202381e+01, 7.17174370e+01, 7.17146358e+01, 7.17118347e+01,\n",
       "        7.17090336e+01, 7.17062325e+01, 7.17034314e+01, 7.17006303e+01,\n",
       "        7.16891457e+01, 7.16751401e+01, 7.16611345e+01, 7.16471289e+01,\n",
       "        7.16331232e+01, 7.16191177e+01, 7.16051120e+01, 7.15911064e+01,\n",
       "        7.15771008e+01, 7.15630952e+01, 7.15490896e+01, 7.15350840e+01,\n",
       "        7.15210784e+01, 7.15070728e+01, 7.14930672e+01, 7.41098739e+01,\n",
       "        7.40678571e+01, 7.40258403e+01, 7.39838235e+01, 7.39418067e+01,\n",
       "        7.38997899e+01, 7.38577731e+01, 7.38157563e+01, 7.37317227e+01,\n",
       "        7.36224790e+01, 7.35132353e+01, 7.34039916e+01, 7.32947479e+01,\n",
       "        7.31855042e+01, 7.30762605e+01, 7.29670168e+01, 7.28577731e+01,\n",
       "        7.27485294e+01, 7.26392857e+01, 7.25300420e+01, 7.24573529e+01,\n",
       "        7.23965294e+01, 7.23347059e+01, 7.22728823e+01, 7.22110588e+01,\n",
       "        7.21492335e+01, 7.81376648e+01, 0.00000000e+00, 6.95797324e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.74138810e-02, 0.00000000e+00,\n",
       "        6.86222229e+01, 0.00000000e+00, 3.17817740e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.75635889e-02, 1.51692092e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.50910020e-02, 2.38962546e-01,\n",
       "        1.83566958e-02, 4.10388082e-01, 6.18291497e-01, 0.00000000e+00,\n",
       "        1.97618544e-01, 0.00000000e+00, 2.75135487e-02, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.72662232, 69.72148693, 69.71635154, 69.71121615, 69.70608077,\n",
       "       69.70094538, 69.69580999, 69.6906746 , 69.68553922, 69.68040383,\n",
       "       69.67526844, 69.67013305, 69.66499767, 69.65986228, 69.65472689,\n",
       "       69.6495915 , 69.64445612, 69.63932073, 69.63418534, 69.62904995,\n",
       "       69.62391457, 69.61877918, 69.61364379, 69.6085084 , 69.60337302,\n",
       "       69.59823763, 69.59310224, 69.58796685, 69.58283147, 69.57769608,\n",
       "       69.57256069, 69.5674253 , 69.56228992, 69.55715453, 69.55201914,\n",
       "       69.54688375, 69.54174837, 69.53661298, 69.53147759, 69.5263422 ,\n",
       "       69.52120682, 69.51607143, 69.51093604, 69.50580065, 69.50066527,\n",
       "       69.49552988, 69.49039449, 69.4852591 , 69.48012372, 69.47498833,\n",
       "       69.46985294, 69.46471755, 69.45958217, 69.45444678, 69.44931139,\n",
       "       69.444176  , 69.43904062, 69.43390523, 69.42876984, 69.42363445,\n",
       "       69.41849907, 69.41336368, 69.40822829, 69.4030929 , 69.39795752,\n",
       "       69.39282213, 69.38768674, 69.38255135, 69.37741597, 69.37228058,\n",
       "       69.36714519, 69.3620098 , 69.35687442, 69.35173903, 69.34660364,\n",
       "       69.34146825, 69.33633287, 69.33119748, 69.32606209, 69.3209267 ,\n",
       "       69.31579132, 69.31065593, 69.30552054, 69.30038515, 69.29418597,\n",
       "       69.28790053, 69.28161509, 69.27532964, 69.2690442 , 69.26275876,\n",
       "       69.25647332, 69.25018788, 69.24390244, 69.237617  , 69.23133156,\n",
       "       69.22504612, 69.21876068, 69.21247523, 69.20618979, 69.19990435])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.68347805100106\n",
      "19.3508426032318\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
