{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "1845    70.951821\n",
       "1846    70.944351\n",
       "1847    70.936881\n",
       "1848    70.929412\n",
       "1849    70.921942\n",
       "Name: C3, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_1750_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "1745    71.511741\n",
       "1746    71.507073\n",
       "1747    71.502404\n",
       "1748    71.497736\n",
       "1749    71.493067\n",
       "Name: C3, Length: 1750, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1750)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 1, 251) (1300, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 2s 29ms/step - loss: 5932.2163 - val_loss: 5129.7295\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5858.2793 - val_loss: 5065.3857\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5791.5918 - val_loss: 5007.6143\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5729.8804 - val_loss: 4950.3213\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5668.7510 - val_loss: 4893.6226\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5608.2192 - val_loss: 4837.4819\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5548.2451 - val_loss: 4781.8662\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5488.8008 - val_loss: 4726.7544\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5429.8662 - val_loss: 4672.1328\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5371.4302 - val_loss: 4617.9907\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5313.4810 - val_loss: 4564.3203\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5245.2319 - val_loss: 4496.5415\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5181.1973 - val_loss: 4439.4019\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5120.2935 - val_loss: 4383.4521\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5060.5562 - val_loss: 4328.4878\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5001.7622 - val_loss: 4274.3354\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4943.7622 - val_loss: 4220.8882\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4886.4604 - val_loss: 4168.0801\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4829.8013 - val_loss: 4115.8682\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4773.7441 - val_loss: 4064.2222\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4718.2598 - val_loss: 4013.1182\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4663.3267 - val_loss: 3962.5393\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4608.9268 - val_loss: 3912.4712\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4555.0474 - val_loss: 3862.9016\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4501.6777 - val_loss: 3813.8210\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4448.8062 - val_loss: 3765.2212\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4396.4258 - val_loss: 3717.0940\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4344.5283 - val_loss: 3669.4326\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4293.1069 - val_loss: 3622.2307\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4242.1558 - val_loss: 3575.4836\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4191.6685 - val_loss: 3529.1851\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4141.6406 - val_loss: 3483.3311\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4092.0664 - val_loss: 3437.9170\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4042.9429 - val_loss: 3392.9375\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3994.2644 - val_loss: 3348.3899\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3946.0266 - val_loss: 3304.2690\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3898.2266 - val_loss: 3260.5725\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3850.8599 - val_loss: 3217.2949\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3803.9233 - val_loss: 3174.4343\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3757.4126 - val_loss: 3131.9873\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3711.3250 - val_loss: 3089.9482\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3658.8438 - val_loss: 3035.8213\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3603.7163 - val_loss: 2988.4392\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3552.7026 - val_loss: 2942.6226\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3503.2642 - val_loss: 2898.0918\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3455.0508 - val_loss: 2854.5623\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3407.8086 - val_loss: 2811.8582\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3361.3843 - val_loss: 2769.8726\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3315.6812 - val_loss: 2728.5366\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3270.6340 - val_loss: 2687.7981\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3226.1958 - val_loss: 2647.6235\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3182.3330 - val_loss: 2607.9849\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3139.0166 - val_loss: 2568.8579\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3096.2253 - val_loss: 2530.2261\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3053.9412 - val_loss: 2492.0730\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3012.1494 - val_loss: 2454.3865\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2970.8367 - val_loss: 2417.1555\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2929.9919 - val_loss: 2380.3699\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2889.6038 - val_loss: 2344.0198\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2849.6653 - val_loss: 2308.0996\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2810.1667 - val_loss: 2272.5984\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2771.1021 - val_loss: 2237.5129\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2732.4636 - val_loss: 2202.8359\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2694.2456 - val_loss: 2168.5615\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2656.4426 - val_loss: 2134.6846\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2619.0488 - val_loss: 2101.2007\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2582.0583 - val_loss: 2068.1035\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2545.4680 - val_loss: 2035.3909\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2509.2720 - val_loss: 2003.0555\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2473.4666 - val_loss: 1971.0959\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2438.0471 - val_loss: 1939.5071\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2403.0095 - val_loss: 1908.2854\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2368.3506 - val_loss: 1877.4266\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2334.0654 - val_loss: 1846.9266\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2300.1519 - val_loss: 1816.7843\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2266.6055 - val_loss: 1786.9945\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2233.4238 - val_loss: 1757.5553\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2200.6025 - val_loss: 1728.4619\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2168.1387 - val_loss: 1699.7122\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2136.0298 - val_loss: 1671.3031\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2104.2725 - val_loss: 1643.2312\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2072.8628 - val_loss: 1615.4944\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2041.7993 - val_loss: 1588.0884\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2011.0780 - val_loss: 1561.0127\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1980.6969 - val_loss: 1534.2627\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1950.6523 - val_loss: 1507.8358\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1920.9421 - val_loss: 1481.7300\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1891.5645 - val_loss: 1455.9424\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1862.5154 - val_loss: 1430.4709\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1833.7927 - val_loss: 1405.3124\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1805.3942 - val_loss: 1380.4647\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1777.3168 - val_loss: 1355.9248\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1749.5586 - val_loss: 1331.6902\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1722.1168 - val_loss: 1307.7596\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1694.9888 - val_loss: 1284.1298\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1668.1727 - val_loss: 1260.7983\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1641.6659 - val_loss: 1237.7628\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1615.4653 - val_loss: 1215.0209\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1589.5701 - val_loss: 1192.5706\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1563.9766 - val_loss: 1170.4092\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1538.6826 - val_loss: 1148.5345\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1513.6865 - val_loss: 1126.9448\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1488.9858 - val_loss: 1105.6371\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1464.5781 - val_loss: 1084.6095\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1440.4611 - val_loss: 1063.8596\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1416.6329 - val_loss: 1043.3865\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1393.0914 - val_loss: 1023.1855\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1369.8341 - val_loss: 1003.2567\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1346.8594 - val_loss: 983.5967\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1324.1642 - val_loss: 964.2047\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1301.7473 - val_loss: 945.0762\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1279.6064 - val_loss: 926.2115\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1257.7393 - val_loss: 907.6081\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1236.1439 - val_loss: 889.2629\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1214.8180 - val_loss: 871.1739\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1193.7598 - val_loss: 853.3399\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1172.9670 - val_loss: 835.7583\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1152.4379 - val_loss: 818.4276\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1132.1699 - val_loss: 801.3447\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1112.1613 - val_loss: 784.5081\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1092.4102 - val_loss: 767.9158\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1072.9144 - val_loss: 751.5655\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1053.6721 - val_loss: 735.4565\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1034.6814 - val_loss: 719.5853\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1015.9401 - val_loss: 703.9509\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 997.4465 - val_loss: 688.5508\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 979.1985 - val_loss: 673.3825\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 961.1942 - val_loss: 658.4451\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 943.4315 - val_loss: 643.7366\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 925.9088 - val_loss: 629.2545\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 908.6238 - val_loss: 614.9969\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 891.5750 - val_loss: 600.9618\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 874.7601 - val_loss: 587.1479\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 858.1776 - val_loss: 573.5524\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 841.8251 - val_loss: 560.1743\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 825.7009 - val_loss: 547.0111\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 809.8033 - val_loss: 534.0604\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 794.1304 - val_loss: 521.3213\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 778.6801 - val_loss: 508.7912\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 763.4506 - val_loss: 496.4689\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 748.4405 - val_loss: 484.3524\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 733.6474 - val_loss: 472.4389\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 719.0699 - val_loss: 460.7276\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 704.7054 - val_loss: 449.2154\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 690.5526 - val_loss: 437.9022\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 676.6099 - val_loss: 426.7846\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 662.8750 - val_loss: 415.8616\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 649.3463 - val_loss: 405.1306\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 636.0219 - val_loss: 394.5904\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 622.8999 - val_loss: 384.2388\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 609.9789 - val_loss: 374.0740\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 597.2565 - val_loss: 364.0937\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 584.7311 - val_loss: 354.2976\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 572.4012 - val_loss: 344.6823\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 560.2648 - val_loss: 335.2463\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 548.3203 - val_loss: 325.9884\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 536.5658 - val_loss: 316.9064\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 524.9991 - val_loss: 307.9981\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 513.6190 - val_loss: 299.2623\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 502.4236 - val_loss: 290.6967\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 491.4104 - val_loss: 282.2993\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 480.5785 - val_loss: 274.0693\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 469.9261 - val_loss: 266.0038\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 459.4509 - val_loss: 258.1016\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 449.1519 - val_loss: 250.3610\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 439.0265 - val_loss: 242.7793\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 429.0734 - val_loss: 235.3560\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 419.2910 - val_loss: 228.0885\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 409.6772 - val_loss: 220.9749\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 400.2304 - val_loss: 214.0139\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 390.9490 - val_loss: 207.2039\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 381.8311 - val_loss: 200.5423\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 372.8750 - val_loss: 194.0275\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 364.0788 - val_loss: 187.6581\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 355.4410 - val_loss: 181.4324\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 346.9601 - val_loss: 175.3486\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 338.6341 - val_loss: 169.4046\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 330.4613 - val_loss: 163.5988\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 322.4397 - val_loss: 157.9296\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 314.5682 - val_loss: 152.3949\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 306.8446 - val_loss: 146.9930\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 299.2672 - val_loss: 141.7225\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 291.8346 - val_loss: 136.5815\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 284.5447 - val_loss: 131.5678\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 277.3961 - val_loss: 126.6802\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 270.3871 - val_loss: 121.9169\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 263.5162 - val_loss: 117.2762\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 256.7816 - val_loss: 112.7563\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 250.1812 - val_loss: 108.3553\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 243.7136 - val_loss: 104.0719\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 237.3774 - val_loss: 99.9040\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 231.1708 - val_loss: 95.8499\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 225.0919 - val_loss: 91.9082\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 219.1395 - val_loss: 88.0770\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 213.3117 - val_loss: 84.3548\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 207.6066 - val_loss: 80.7395\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 202.0228 - val_loss: 77.2297\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 196.5588 - val_loss: 73.8239\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 191.2130 - val_loss: 70.5201\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 185.9832 - val_loss: 67.3165\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 180.8683 - val_loss: 64.2118\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 175.8666 - val_loss: 61.2046\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 170.9767 - val_loss: 58.2927\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 166.1966 - val_loss: 55.4748\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 161.5249 - val_loss: 52.7489\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 156.9599 - val_loss: 50.1137\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 152.5001 - val_loss: 47.5674\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 148.1440 - val_loss: 45.1084\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 143.8897 - val_loss: 42.7352\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 139.7359 - val_loss: 40.4460\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 135.6810 - val_loss: 38.2395\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 131.7236 - val_loss: 36.1141\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 127.8621 - val_loss: 34.0681\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 124.0947 - val_loss: 32.0997\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 120.4200 - val_loss: 30.2077\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 116.8364 - val_loss: 28.3902\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 113.3427 - val_loss: 26.6462\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 109.9374 - val_loss: 24.9738\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 106.6186 - val_loss: 23.3715\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 103.3849 - val_loss: 21.8377\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 100.2350 - val_loss: 20.3709\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 97.1672 - val_loss: 18.9699\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 94.1803 - val_loss: 17.6330\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 91.2728 - val_loss: 16.3589\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 88.4434 - val_loss: 15.1460\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 85.6904 - val_loss: 13.9928\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 83.0124 - val_loss: 12.8980\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 80.4081 - val_loss: 11.8599\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 77.8758 - val_loss: 10.8776\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 75.4145 - val_loss: 9.9491\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 73.0227 - val_loss: 9.0734\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 70.6987 - val_loss: 8.2489\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 68.4414 - val_loss: 7.4745\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 66.2496 - val_loss: 6.7487\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 64.1219 - val_loss: 6.0700\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 62.0568 - val_loss: 5.4374\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 60.0531 - val_loss: 4.8494\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 58.1093 - val_loss: 4.3048\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 56.2244 - val_loss: 3.8022\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 54.3971 - val_loss: 3.3404\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 52.6260 - val_loss: 2.9182\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 50.9100 - val_loss: 2.5342\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 49.2477 - val_loss: 2.1874\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 47.6379 - val_loss: 1.8765\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 46.0795 - val_loss: 1.6002\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 44.5711 - val_loss: 1.3575\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 43.1117 - val_loss: 1.1471\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 41.7001 - val_loss: 0.9680\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 40.3351 - val_loss: 0.8190\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 39.0157 - val_loss: 0.6990\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 37.7405 - val_loss: 0.6069\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 36.5088 - val_loss: 0.5416\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 35.3191 - val_loss: 0.5021\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 34.1704 - val_loss: 0.4873\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.0617 - val_loss: 0.4963\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.9918 - val_loss: 0.5280\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.9599 - val_loss: 0.5814\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.9650 - val_loss: 0.6556\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.0060 - val_loss: 0.7496\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 28.0818 - val_loss: 0.8625\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 27.1915 - val_loss: 0.9934\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 26.3341 - val_loss: 1.1413\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 25.5088 - val_loss: 1.3055\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.7146 - val_loss: 1.4850\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.9506 - val_loss: 1.6791\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.2159 - val_loss: 1.8868\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.5095 - val_loss: 2.1075\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.8306 - val_loss: 2.3403\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 21.1785 - val_loss: 2.5844\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.5522 - val_loss: 2.8392\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.9511 - val_loss: 3.1039\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 19.3741 - val_loss: 3.3778\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 18.8208 - val_loss: 3.6602\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.2901 - val_loss: 3.9503\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.7813 - val_loss: 4.2478\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2939 - val_loss: 4.5518\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8270 - val_loss: 4.8616\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3800 - val_loss: 5.1769\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.9521 - val_loss: 5.4969\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.5426 - val_loss: 5.8212\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.1511 - val_loss: 6.1491\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 14.7767 - val_loss: 6.4802\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.4190 - val_loss: 6.8141\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.0771 - val_loss: 7.1501\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7506 - val_loss: 7.4878\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 13.4390 - val_loss: 7.8267\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1417 - val_loss: 8.1666\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8580 - val_loss: 8.5069\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.5876 - val_loss: 8.8471\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.3298 - val_loss: 9.1872\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.0842 - val_loss: 9.5265\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.8502 - val_loss: 9.8648\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.6275 - val_loss: 10.2016\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.4155 - val_loss: 10.5370\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2139 - val_loss: 10.8702\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.0222 - val_loss: 11.2010\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.8400 - val_loss: 11.5294\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.6668 - val_loss: 11.8551\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.5023 - val_loss: 12.1775\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3462 - val_loss: 12.4969\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1980 - val_loss: 12.8127\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.0574 - val_loss: 13.1247\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.9241 - val_loss: 13.4331\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.7977 - val_loss: 13.7372\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 9.6779 - val_loss: 14.0375\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 9.5645 - val_loss: 14.3333\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.4570 - val_loss: 14.6246\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.3553 - val_loss: 14.9113\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 9.2590 - val_loss: 15.1933\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 9.1680 - val_loss: 15.4706\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.0819 - val_loss: 15.7429\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.0006 - val_loss: 16.0101\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.9238 - val_loss: 16.2725\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.8512 - val_loss: 16.5298\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.7827 - val_loss: 16.7819\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.7180 - val_loss: 17.0288\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.6569 - val_loss: 17.2704\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5993 - val_loss: 17.5067\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5451 - val_loss: 17.7379\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.4939 - val_loss: 17.9638\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 8.4457 - val_loss: 18.1843\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.4003 - val_loss: 18.3996\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.3575 - val_loss: 18.6095\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.3172 - val_loss: 18.8143\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.2793 - val_loss: 19.0141\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.2436 - val_loss: 19.2084\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.2100 - val_loss: 19.3976\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.1785 - val_loss: 19.5818\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.1488 - val_loss: 19.7609\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1209 - val_loss: 19.9351\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0947 - val_loss: 20.1041\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 8.0701 - val_loss: 20.2683\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.0469 - val_loss: 20.4275\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.0252 - val_loss: 20.5820\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.0048 - val_loss: 20.7321\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.9856 - val_loss: 20.8772\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.9676 - val_loss: 21.0179\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.9507 - val_loss: 21.1539\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 7.9349 - val_loss: 21.2855\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.9200 - val_loss: 21.4129\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.9061 - val_loss: 21.5362\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.8930 - val_loss: 21.6550\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.8807 - val_loss: 21.7700\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.8692 - val_loss: 21.8808\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.8584 - val_loss: 21.9879\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.8483 - val_loss: 22.0909\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.8388 - val_loss: 22.1903\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.8299 - val_loss: 22.2859\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.8216 - val_loss: 22.3782\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.8138 - val_loss: 22.4669\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.8065 - val_loss: 22.5523\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7996 - val_loss: 22.6342\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7932 - val_loss: 22.7131\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7871 - val_loss: 22.7889\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 7.7815 - val_loss: 22.8617\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.7762 - val_loss: 22.9314\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.7712 - val_loss: 22.9984\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7666 - val_loss: 23.0626\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 7.7622 - val_loss: 23.1238\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 7.7582 - val_loss: 23.1829\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 7.7543 - val_loss: 23.2391\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 7.7508 - val_loss: 23.2930\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7474 - val_loss: 23.3445\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7443 - val_loss: 23.3937\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7413 - val_loss: 23.4405\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7386 - val_loss: 23.4854\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.7361 - val_loss: 23.5282\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7337 - val_loss: 23.5690\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 7.7314 - val_loss: 23.6078\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7294 - val_loss: 23.6450\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7274 - val_loss: 23.6803\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7256 - val_loss: 23.7142\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7239 - val_loss: 23.7462\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7223 - val_loss: 23.7766\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.7208 - val_loss: 23.8054\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7194 - val_loss: 23.8328\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7181 - val_loss: 23.8589\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.7169 - val_loss: 23.8836\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7158 - val_loss: 23.9072\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7148 - val_loss: 23.9292\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7138 - val_loss: 23.9504\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7129 - val_loss: 23.9702\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7121 - val_loss: 23.9890\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7114 - val_loss: 24.0068\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 7.7107 - val_loss: 24.0237\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 7.7100 - val_loss: 24.0395\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 7.7094 - val_loss: 24.0546\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7089 - val_loss: 24.0686\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7084 - val_loss: 24.0821\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7079 - val_loss: 24.0945\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7075 - val_loss: 24.1064\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7072 - val_loss: 24.1175\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7068 - val_loss: 24.1278\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7065 - val_loss: 24.1375\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7063 - val_loss: 24.1467\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7060 - val_loss: 24.1553\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7058 - val_loss: 24.1634\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7056 - val_loss: 24.1711\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7055 - val_loss: 24.1779\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 7.7054 - val_loss: 24.1847\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7053 - val_loss: 24.1908\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7052 - val_loss: 24.1966\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7051 - val_loss: 24.2020\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7051 - val_loss: 24.2071\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7050 - val_loss: 24.2116\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7050 - val_loss: 24.2159\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7051 - val_loss: 24.2200\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7051 - val_loss: 24.2237\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7051 - val_loss: 24.2271\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7052 - val_loss: 24.2305\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7053 - val_loss: 24.2334\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7053 - val_loss: 24.2359\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 7.7054 - val_loss: 24.2384\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7055 - val_loss: 24.2409\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7056 - val_loss: 24.2432\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 7.7057 - val_loss: 24.2450\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7059 - val_loss: 24.2468\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7060 - val_loss: 24.2482\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7062 - val_loss: 24.2498\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7063 - val_loss: 24.2511\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7065 - val_loss: 24.2526\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7067 - val_loss: 24.2535\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7068 - val_loss: 24.2546\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7070 - val_loss: 24.2556\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7072 - val_loss: 24.2563\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7074 - val_loss: 24.2569\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7076 - val_loss: 24.2576\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 7.7078 - val_loss: 24.2582\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.7079 - val_loss: 24.2584\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 7.7082 - val_loss: 24.2589\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7084 - val_loss: 24.2593\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.7086 - val_loss: 24.2595\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 7.7088 - val_loss: 24.2597\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7090 - val_loss: 24.2600\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7092 - val_loss: 24.2601\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7094 - val_loss: 24.2601\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7096 - val_loss: 24.2601\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7099 - val_loss: 24.2599\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7101 - val_loss: 24.2597\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7104 - val_loss: 24.2595\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7106 - val_loss: 24.2595\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7108 - val_loss: 24.2594\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7111 - val_loss: 24.2592\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7113 - val_loss: 24.2591\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7115 - val_loss: 24.2588\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7118 - val_loss: 24.2584\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7120 - val_loss: 24.2583\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7123 - val_loss: 24.2580\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7125 - val_loss: 24.2577\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7127 - val_loss: 24.2574\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 7.7130 - val_loss: 24.2570\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7132 - val_loss: 24.2567\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7134 - val_loss: 24.2563\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7137 - val_loss: 24.2559\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7140 - val_loss: 24.2557\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7142 - val_loss: 24.2553\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7144 - val_loss: 24.2547\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7147 - val_loss: 24.2545\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7149 - val_loss: 24.2541\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7151 - val_loss: 24.2535\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.7154 - val_loss: 24.2532\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7157 - val_loss: 24.2530\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7158 - val_loss: 24.2523\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7161 - val_loss: 24.2519\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7164 - val_loss: 24.2515\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7166 - val_loss: 24.2510\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7169 - val_loss: 24.2507\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7171 - val_loss: 24.2504\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 7.7173 - val_loss: 24.2499\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7176 - val_loss: 24.2495\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7178 - val_loss: 24.2492\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7181 - val_loss: 24.2488\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7182 - val_loss: 24.2483\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7185 - val_loss: 24.2480\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7187 - val_loss: 24.2476\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7189 - val_loss: 24.2470\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7192 - val_loss: 24.2468\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7194 - val_loss: 24.2461\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7197 - val_loss: 24.2458\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7199 - val_loss: 24.2455\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7201 - val_loss: 24.2450\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7204 - val_loss: 24.2446\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7206 - val_loss: 24.2441\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7208 - val_loss: 24.2435\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7210 - val_loss: 24.2432\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.7213 - val_loss: 24.2429\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7215 - val_loss: 24.2422\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7218 - val_loss: 24.2420\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7219 - val_loss: 24.2417\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7222 - val_loss: 24.2410\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7224 - val_loss: 24.2409\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7226 - val_loss: 24.2403\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7228 - val_loss: 24.2399\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7230 - val_loss: 24.2396\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7233 - val_loss: 24.2392\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7235 - val_loss: 24.2386\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7237 - val_loss: 24.2383\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7239 - val_loss: 24.2380\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7241 - val_loss: 24.2375\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7243 - val_loss: 24.2371\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 357ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.41378852e+01, 7.41238795e+01, 7.41098739e+01, 7.40958684e+01,\n",
       "        7.40818627e+01, 7.40678571e+01, 7.40538515e+01, 7.40398459e+01,\n",
       "        7.40258403e+01, 7.40118347e+01, 7.39978291e+01, 7.39838235e+01,\n",
       "        7.39698179e+01, 7.39558123e+01, 7.39418067e+01, 7.39278011e+01,\n",
       "        7.39137955e+01, 7.38997899e+01, 7.38857843e+01, 7.38717787e+01,\n",
       "        7.38577731e+01, 7.38437675e+01, 7.38297619e+01, 7.38157563e+01,\n",
       "        7.38017507e+01, 7.37681372e+01, 7.37317227e+01, 7.36953081e+01,\n",
       "        7.36588936e+01, 7.36224790e+01, 7.35860644e+01, 7.35496499e+01,\n",
       "        7.35132353e+01, 7.34768207e+01, 7.34404062e+01, 7.34039916e+01,\n",
       "        7.33675770e+01, 7.33311625e+01, 7.32947479e+01, 7.32583333e+01,\n",
       "        7.32219188e+01, 7.31855042e+01, 7.31490896e+01, 7.31126751e+01,\n",
       "        7.30762605e+01, 7.30398459e+01, 7.30034314e+01, 7.29670168e+01,\n",
       "        7.29306022e+01, 7.28941877e+01, 7.28577731e+01, 7.28213585e+01,\n",
       "        7.27849440e+01, 7.27485294e+01, 7.27121149e+01, 7.26757003e+01,\n",
       "        7.26392857e+01, 7.26028711e+01, 7.25664566e+01, 7.25300420e+01,\n",
       "        7.24965686e+01, 7.24769608e+01, 7.24573529e+01, 7.24377451e+01,\n",
       "        7.24181373e+01, 7.23985294e+01, 7.23789216e+01, 7.23593137e+01,\n",
       "        7.23397059e+01, 7.23200980e+01, 7.23004902e+01, 7.22808823e+01,\n",
       "        7.22612745e+01, 7.22416667e+01, 7.22220588e+01, 7.22024510e+01,\n",
       "        7.21828431e+01, 7.21632353e+01, 7.21436274e+01, 7.21240196e+01,\n",
       "        7.81376648e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.97830337e-01, 1.91479445e-01, 6.95797324e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.58582163e-02, 4.14856046e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.74138814e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.22182474e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71.48839869, 71.48373016, 71.47906162, 71.47439309, 71.46972456,\n",
       "       71.46505602, 71.46038749, 71.45571895, 71.45105042, 71.44638189,\n",
       "       71.44171335, 71.43704482, 71.43237628, 71.42770775, 71.42303922,\n",
       "       71.41837068, 71.41370215, 71.40903361, 71.40436508, 71.39969655,\n",
       "       71.39502801, 71.39035948, 71.38569094, 71.38102241, 71.37635387,\n",
       "       71.37168534, 71.36701681, 71.36234827, 71.35767974, 71.3530112 ,\n",
       "       71.34834267, 71.34367414, 71.3390056 , 71.33433707, 71.32966853,\n",
       "       71.325     , 71.32033147, 71.31566293, 71.3109944 , 71.30632586,\n",
       "       71.30165733, 71.2969888 , 71.29232026, 71.28765173, 71.28298319,\n",
       "       71.27831466, 71.27364613, 71.26897759, 71.26430906, 71.25964052,\n",
       "       71.25497199, 71.25030345, 71.24563492, 71.24096639, 71.23629785,\n",
       "       71.23162932, 71.22696078, 71.22229225, 71.21762372, 71.21295518,\n",
       "       71.20828665, 71.20361811, 71.19831933, 71.19084967, 71.18338002,\n",
       "       71.17591036, 71.16844071, 71.16097106, 71.1535014 , 71.14603175,\n",
       "       71.13856209, 71.13109244, 71.12362278, 71.11615313, 71.10868347,\n",
       "       71.10121382, 71.09374416, 71.08627451, 71.07880486, 71.0713352 ,\n",
       "       71.06386555, 71.05639589, 71.04892624, 71.04145658, 71.03398693,\n",
       "       71.02651727, 71.01904762, 71.01157796, 71.00410831, 70.99663866,\n",
       "       70.989169  , 70.98169935, 70.97422969, 70.96676004, 70.95929038,\n",
       "       70.95182073, 70.94435107, 70.93688142, 70.92941176, 70.92194211])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.956666696827373\n",
      "15.05672648541266\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
