{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2045    69.752299\n",
       "2046    69.747164\n",
       "2047    69.742028\n",
       "2048    69.736893\n",
       "2049    69.731758\n",
       "Name: C3, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_1950_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "1945     0.079004\n",
       "1946     0.320036\n",
       "1947     0.278152\n",
       "1948     0.000000\n",
       "1949     0.000000\n",
       "Name: C3, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1950)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1, 251) (1500, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 2s 25ms/step - loss: 5965.0410 - val_loss: 5058.9912\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5886.6528 - val_loss: 5006.8423\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5830.3452 - val_loss: 4954.9233\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5774.4614 - val_loss: 4903.4971\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5719.0806 - val_loss: 4852.5386\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5664.0723 - val_loss: 4801.0591\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5595.9761 - val_loss: 4732.1929\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5530.2026 - val_loss: 4674.4937\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5468.5342 - val_loss: 4618.4277\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5408.4004 - val_loss: 4563.5791\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5349.4043 - val_loss: 4509.6665\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5291.3096 - val_loss: 4456.5293\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5233.9761 - val_loss: 4404.0703\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5177.3203 - val_loss: 4352.2290\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5121.2852 - val_loss: 4300.9604\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5065.8296 - val_loss: 4250.2334\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5010.9248 - val_loss: 4200.0239\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4956.5464 - val_loss: 4150.3125\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4902.6763 - val_loss: 4101.0840\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4849.2988 - val_loss: 4052.3262\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4793.9253 - val_loss: 3998.2217\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4734.4360 - val_loss: 3944.1626\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4676.3174 - val_loss: 3891.7534\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4619.7783 - val_loss: 3840.6038\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4564.4277 - val_loss: 3790.4287\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4510.0215 - val_loss: 3741.0649\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4456.4189 - val_loss: 3692.4133\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4403.5298 - val_loss: 3644.4092\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4351.2939 - val_loss: 3597.0049\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4299.6694 - val_loss: 3550.1682\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4248.6230 - val_loss: 3503.8716\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 4198.1279 - val_loss: 3458.0945\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4148.1650 - val_loss: 3412.8193\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4098.7153 - val_loss: 3368.0317\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4049.7659 - val_loss: 3323.7180\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4001.3042 - val_loss: 3279.8701\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3953.3184 - val_loss: 3236.4758\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3905.8000 - val_loss: 3193.5288\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3858.7395 - val_loss: 3151.0193\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3812.1304 - val_loss: 3108.9424\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3765.9639 - val_loss: 3067.2905\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3720.2351 - val_loss: 3026.0579\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3674.9375 - val_loss: 2985.2395\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3630.0642 - val_loss: 2944.8291\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3585.6125 - val_loss: 2904.8235\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3541.5754 - val_loss: 2865.2163\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3497.9495 - val_loss: 2826.0049\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3454.7302 - val_loss: 2787.1846\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3411.9121 - val_loss: 2748.7512\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3369.4929 - val_loss: 2710.7012\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3327.4675 - val_loss: 2673.0308\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3285.8333 - val_loss: 2635.7368\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3244.5862 - val_loss: 2598.8154\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3203.7222 - val_loss: 2562.2629\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3163.2383 - val_loss: 2526.0776\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3123.1318 - val_loss: 2490.2549\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3083.3989 - val_loss: 2454.7925\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3044.0374 - val_loss: 2419.6875\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3005.0437 - val_loss: 2384.9377\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2966.4148 - val_loss: 2350.5386\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2928.1482 - val_loss: 2316.4885\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2890.2410 - val_loss: 2282.7852\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2852.6899 - val_loss: 2249.4250\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2815.4934 - val_loss: 2216.4055\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2778.6484 - val_loss: 2183.7258\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2742.1516 - val_loss: 2151.3816\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2706.0022 - val_loss: 2119.3704\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2670.1956 - val_loss: 2087.6907\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2634.7310 - val_loss: 2056.3398\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2599.6050 - val_loss: 2025.3149\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2564.8152 - val_loss: 1994.6146\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2530.3608 - val_loss: 1964.2361\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2496.2373 - val_loss: 1934.1769\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2462.4448 - val_loss: 1904.4351\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2428.9795 - val_loss: 1875.0083\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2395.8384 - val_loss: 1845.8942\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2363.0210 - val_loss: 1817.0919\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2330.5249 - val_loss: 1788.5975\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2298.3474 - val_loss: 1760.4100\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2266.4861 - val_loss: 1732.5266\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2234.9397 - val_loss: 1704.9459\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2203.7056 - val_loss: 1677.6656\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2172.7822 - val_loss: 1650.6837\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2142.1670 - val_loss: 1623.9982\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2111.8586 - val_loss: 1597.6068\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2081.8545 - val_loss: 1571.5082\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2052.1528 - val_loss: 1545.7000\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2022.7521 - val_loss: 1520.1804\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1993.6495 - val_loss: 1494.9475\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1964.8435 - val_loss: 1469.9991\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1936.3325 - val_loss: 1445.3335\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1908.1144 - val_loss: 1420.9487\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1880.1873 - val_loss: 1396.8433\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1852.5496 - val_loss: 1373.0150\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1825.1990 - val_loss: 1349.4620\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1798.1335 - val_loss: 1326.1824\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1771.3517 - val_loss: 1303.1749\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1744.8519 - val_loss: 1280.4368\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1718.6318 - val_loss: 1257.9674\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1692.6902 - val_loss: 1235.7639\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1667.0253 - val_loss: 1213.8247\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1641.6345 - val_loss: 1192.1489\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1616.5167 - val_loss: 1170.7335\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1591.6705 - val_loss: 1149.5784\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1567.0936 - val_loss: 1128.6804\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1542.7847 - val_loss: 1108.0380\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1518.7417 - val_loss: 1087.6500\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1494.9629 - val_loss: 1067.5145\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1471.4468 - val_loss: 1047.6293\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1448.1915 - val_loss: 1027.9935\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1425.1959 - val_loss: 1008.6050\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1402.4578 - val_loss: 989.4618\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1379.9755 - val_loss: 970.5626\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1357.7473 - val_loss: 951.9059\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1335.7716 - val_loss: 933.4898\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1314.0470 - val_loss: 915.3123\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1292.5719 - val_loss: 897.3723\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1271.3442 - val_loss: 879.6683\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1250.3630 - val_loss: 862.1983\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1229.6265 - val_loss: 844.9605\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1209.1328 - val_loss: 827.9540\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1188.8802 - val_loss: 811.1760\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1168.8673 - val_loss: 794.6266\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1149.0928 - val_loss: 778.3024\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1129.5548 - val_loss: 762.2024\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1110.2517 - val_loss: 746.3255\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1091.1819 - val_loss: 730.6700\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1072.3440 - val_loss: 715.2340\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1053.7368 - val_loss: 700.0156\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1035.3579 - val_loss: 685.0138\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1017.2058 - val_loss: 670.2267\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 999.2802 - val_loss: 655.6531\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 981.5783 - val_loss: 641.2906\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 964.0986 - val_loss: 627.1390\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 946.8402 - val_loss: 613.1959\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 929.8011 - val_loss: 599.4586\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 912.9797 - val_loss: 585.9272\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 896.3754 - val_loss: 572.6007\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 879.9860 - val_loss: 559.4756\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 863.8098 - val_loss: 546.5515\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 847.8454 - val_loss: 533.8269\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 832.0919 - val_loss: 521.2997\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 816.5469 - val_loss: 508.9684\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 801.2094 - val_loss: 496.8319\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 786.0775 - val_loss: 484.8876\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 771.1497 - val_loss: 473.1358\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 756.4251 - val_loss: 461.5738\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 741.9019 - val_loss: 450.2001\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 727.5784 - val_loss: 439.0127\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 713.4531 - val_loss: 428.0108\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 699.5247 - val_loss: 417.1923\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 685.7914 - val_loss: 406.5564\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 672.2523 - val_loss: 396.1011\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 658.9060 - val_loss: 385.8254\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 645.7504 - val_loss: 375.7268\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 632.7839 - val_loss: 365.8046\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 620.0055 - val_loss: 356.0567\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 607.4135 - val_loss: 346.4816\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 595.0066 - val_loss: 337.0783\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 582.7833 - val_loss: 327.8448\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 570.7418 - val_loss: 318.7799\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 558.8809 - val_loss: 309.8817\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 547.1989 - val_loss: 301.1490\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 535.6946 - val_loss: 292.5800\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 524.3663 - val_loss: 284.1729\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 513.2126 - val_loss: 275.9271\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 502.2321 - val_loss: 267.8402\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 491.4233 - val_loss: 259.9111\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 480.7848 - val_loss: 252.1379\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 470.3148 - val_loss: 244.5198\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 460.0120 - val_loss: 237.0539\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 449.8751 - val_loss: 229.7403\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 439.9026 - val_loss: 222.5765\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 430.0929 - val_loss: 215.5611\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 420.4446 - val_loss: 208.6926\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 410.9560 - val_loss: 201.9695\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 401.6256 - val_loss: 195.3902\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 392.4524 - val_loss: 188.9533\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 383.4347 - val_loss: 182.6576\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 374.5708 - val_loss: 176.5003\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 365.8595 - val_loss: 170.4810\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 357.2995 - val_loss: 164.5985\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 348.8891 - val_loss: 158.8506\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 340.6268 - val_loss: 153.2354\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 332.5112 - val_loss: 147.7520\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 324.5407 - val_loss: 142.3986\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 316.7140 - val_loss: 137.1737\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 309.0294 - val_loss: 132.0757\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 301.4856 - val_loss: 127.1027\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 294.0810 - val_loss: 122.2541\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 286.8142 - val_loss: 117.5277\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 279.6837 - val_loss: 112.9221\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 272.6880 - val_loss: 108.4356\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 265.8257 - val_loss: 104.0667\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 259.0954 - val_loss: 99.8141\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 252.4954 - val_loss: 95.6763\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 246.0246 - val_loss: 91.6514\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 239.6812 - val_loss: 87.7382\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 233.4639 - val_loss: 83.9348\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 227.3714 - val_loss: 80.2401\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 221.4018 - val_loss: 76.6521\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 215.5538 - val_loss: 73.1698\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 209.8261 - val_loss: 69.7911\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 204.2171 - val_loss: 66.5148\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 198.7254 - val_loss: 63.3393\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.3493 - val_loss: 60.2630\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 188.0876 - val_loss: 57.2845\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 182.9388 - val_loss: 54.4022\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 177.9015 - val_loss: 51.6146\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 172.9739 - val_loss: 48.9202\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.1550 - val_loss: 46.3171\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 163.4429 - val_loss: 43.8045\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 158.8365 - val_loss: 41.3801\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 154.3341 - val_loss: 39.0429\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 149.9345 - val_loss: 36.7915\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 145.6363 - val_loss: 34.6240\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 141.4379 - val_loss: 32.5390\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 137.3378 - val_loss: 30.5350\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 133.3347 - val_loss: 28.6106\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 129.4270 - val_loss: 26.7645\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 125.6136 - val_loss: 24.9947\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 121.8928 - val_loss: 23.3001\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 118.2632 - val_loss: 21.6792\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 114.7235 - val_loss: 20.1304\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 111.2721 - val_loss: 18.6520\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 107.9077 - val_loss: 17.2430\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 104.6290 - val_loss: 15.9019\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 101.4345 - val_loss: 14.6268\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 98.3228 - val_loss: 13.4167\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 95.2926 - val_loss: 12.2699\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 92.3424 - val_loss: 11.1851\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 89.4708 - val_loss: 10.1608\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 86.6764 - val_loss: 9.1957\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 83.9580 - val_loss: 8.2883\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 81.3142 - val_loss: 7.4371\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 78.7434 - val_loss: 6.6408\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 76.2446 - val_loss: 5.8981\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 73.8163 - val_loss: 5.2075\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 71.4571 - val_loss: 4.5677\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 69.1659 - val_loss: 3.9774\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 66.9412 - val_loss: 3.4350\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 64.7817 - val_loss: 2.9395\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 62.6862 - val_loss: 2.4894\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 60.6534 - val_loss: 2.0834\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 58.6820 - val_loss: 1.7201\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 56.7707 - val_loss: 1.3984\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 54.9182 - val_loss: 1.1169\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 53.1233 - val_loss: 0.8744\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51.3848 - val_loss: 0.6695\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 49.7013 - val_loss: 0.5011\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 48.0718 - val_loss: 0.3679\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 46.4949 - val_loss: 0.2688\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 44.9696 - val_loss: 0.2024\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 43.4946 - val_loss: 0.1676\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 42.0687 - val_loss: 0.1633\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 40.6908 - val_loss: 0.1883\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 39.3596 - val_loss: 0.2415\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 38.0741 - val_loss: 0.3216\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 36.8332 - val_loss: 0.4277\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 35.6356 - val_loss: 0.5586\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 34.4805 - val_loss: 0.7131\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.3665 - val_loss: 0.8904\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 32.2926 - val_loss: 1.0893\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.2580 - val_loss: 1.3087\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.2614 - val_loss: 1.5478\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.3019 - val_loss: 1.8053\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 28.3784 - val_loss: 2.0806\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 27.4898 - val_loss: 2.3724\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 26.6352 - val_loss: 2.6800\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 25.8137 - val_loss: 3.0023\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 25.0242 - val_loss: 3.3385\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 24.2659 - val_loss: 3.6877\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 23.5378 - val_loss: 4.0490\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 22.8390 - val_loss: 4.4217\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 22.1686 - val_loss: 4.8047\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.5258 - val_loss: 5.1975\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.9095 - val_loss: 5.5990\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.3191 - val_loss: 6.0088\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.7536 - val_loss: 6.4258\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.2122 - val_loss: 6.8494\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.6942 - val_loss: 7.2791\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 18.1988 - val_loss: 7.7138\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.7252 - val_loss: 8.1532\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.2726 - val_loss: 8.5965\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.8403 - val_loss: 9.0430\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.4276 - val_loss: 9.4923\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 16.0339 - val_loss: 9.9435\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.6582 - val_loss: 10.3963\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.3001 - val_loss: 10.8501\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.9589 - val_loss: 11.3042\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6340 - val_loss: 11.7586\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.3246 - val_loss: 12.2122\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.0302 - val_loss: 12.6648\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 13.7503 - val_loss: 13.1158\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 13.4841 - val_loss: 13.5651\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 13.2313 - val_loss: 14.0121\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 12.9912 - val_loss: 14.4565\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 12.7633 - val_loss: 14.8975\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 12.5472 - val_loss: 15.3353\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 12.3422 - val_loss: 15.7691\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 12.1480 - val_loss: 16.1991\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 11.9640 - val_loss: 16.6245\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11.7899 - val_loss: 17.0453\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 11.6251 - val_loss: 17.4612\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11.4693 - val_loss: 17.8720\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 11.3220 - val_loss: 18.2773\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 11.1828 - val_loss: 18.6769\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 11.0515 - val_loss: 19.0708\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 10.9275 - val_loss: 19.4587\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 10.8105 - val_loss: 19.8403\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 10.7003 - val_loss: 20.2155\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10.5965 - val_loss: 20.5843\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 10.4987 - val_loss: 20.9465\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10.4067 - val_loss: 21.3021\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10.3201 - val_loss: 21.6508\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 10.2387 - val_loss: 21.9928\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 10.1621 - val_loss: 22.3276\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 10.0903 - val_loss: 22.6551\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 10.0229 - val_loss: 22.9759\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.9597 - val_loss: 23.2893\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.9004 - val_loss: 23.5958\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.8449 - val_loss: 23.8949\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 9.7928 - val_loss: 24.1870\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.7441 - val_loss: 24.4720\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9.6985 - val_loss: 24.7497\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.6559 - val_loss: 25.0206\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.6160 - val_loss: 25.2842\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.5788 - val_loss: 25.5407\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.5441 - val_loss: 25.7901\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.5116 - val_loss: 26.0327\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.4814 - val_loss: 26.2684\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.4532 - val_loss: 26.4973\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.4269 - val_loss: 26.7194\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.4024 - val_loss: 26.9347\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.3797 - val_loss: 27.1435\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 9.3585 - val_loss: 27.3460\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.3388 - val_loss: 27.5418\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.3205 - val_loss: 27.7312\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.3034 - val_loss: 27.9148\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.2876 - val_loss: 28.0921\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.2730 - val_loss: 28.2634\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.2593 - val_loss: 28.4290\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.2467 - val_loss: 28.5888\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.2349 - val_loss: 28.7426\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.2241 - val_loss: 28.8914\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.2140 - val_loss: 29.0343\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 9.2048 - val_loss: 29.1722\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1961 - val_loss: 29.3050\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.1881 - val_loss: 29.4326\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 9.1808 - val_loss: 29.5554\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 9.1739 - val_loss: 29.6732\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.1676 - val_loss: 29.7863\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1618 - val_loss: 29.8951\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1564 - val_loss: 29.9994\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1515 - val_loss: 30.0994\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1469 - val_loss: 30.1951\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1427 - val_loss: 30.2870\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1388 - val_loss: 30.3749\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1352 - val_loss: 30.4591\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1319 - val_loss: 30.5395\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 9.1289 - val_loss: 30.6164\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1260 - val_loss: 30.6899\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1235 - val_loss: 30.7600\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1211 - val_loss: 30.8268\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1189 - val_loss: 30.8905\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1169 - val_loss: 30.9513\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1150 - val_loss: 31.0092\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1134 - val_loss: 31.0642\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1118 - val_loss: 31.1165\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1104 - val_loss: 31.1663\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1091 - val_loss: 31.2136\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1079 - val_loss: 31.2587\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1068 - val_loss: 31.3014\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1059 - val_loss: 31.3420\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 9.1050 - val_loss: 31.3802\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1042 - val_loss: 31.4167\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1034 - val_loss: 31.4510\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1028 - val_loss: 31.4836\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1022 - val_loss: 31.5143\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1017 - val_loss: 31.5434\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1012 - val_loss: 31.5710\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1008 - val_loss: 31.5968\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1004 - val_loss: 31.6215\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1000 - val_loss: 31.6448\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.0998 - val_loss: 31.6665\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0995 - val_loss: 31.6869\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9.0993 - val_loss: 31.7062\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0992 - val_loss: 31.7243\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0990 - val_loss: 31.7415\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 9.0988 - val_loss: 31.7573\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.0988 - val_loss: 31.7723\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0987 - val_loss: 31.7863\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.0987 - val_loss: 31.7996\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0987 - val_loss: 31.8118\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0987 - val_loss: 31.8235\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0987 - val_loss: 31.8343\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0987 - val_loss: 31.8444\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0988 - val_loss: 31.8535\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0989 - val_loss: 31.8623\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0990 - val_loss: 31.8705\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0991 - val_loss: 31.8781\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0992 - val_loss: 31.8849\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0993 - val_loss: 31.8915\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.0995 - val_loss: 31.8977\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 9.0996 - val_loss: 31.9032\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.0998 - val_loss: 31.9085\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1000 - val_loss: 31.9132\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1001 - val_loss: 31.9175\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1003 - val_loss: 31.9216\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1005 - val_loss: 31.9253\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1007 - val_loss: 31.9288\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1009 - val_loss: 31.9319\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1012 - val_loss: 31.9346\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1014 - val_loss: 31.9370\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1016 - val_loss: 31.9395\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1019 - val_loss: 31.9417\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1021 - val_loss: 31.9437\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1023 - val_loss: 31.9453\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1026 - val_loss: 31.9468\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1028 - val_loss: 31.9481\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 9.1031 - val_loss: 31.9494\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1033 - val_loss: 31.9505\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1036 - val_loss: 31.9516\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1039 - val_loss: 31.9524\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1041 - val_loss: 31.9530\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1044 - val_loss: 31.9538\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1047 - val_loss: 31.9542\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1050 - val_loss: 31.9545\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1052 - val_loss: 31.9549\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1055 - val_loss: 31.9552\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1058 - val_loss: 31.9553\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1061 - val_loss: 31.9555\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1063 - val_loss: 31.9555\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1066 - val_loss: 31.9555\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 9.1069 - val_loss: 31.9555\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1072 - val_loss: 31.9555\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1075 - val_loss: 31.9555\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1077 - val_loss: 31.9552\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1080 - val_loss: 31.9549\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1083 - val_loss: 31.9545\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1086 - val_loss: 31.9542\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1088 - val_loss: 31.9540\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1091 - val_loss: 31.9538\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1094 - val_loss: 31.9533\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1097 - val_loss: 31.9530\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1100 - val_loss: 31.9527\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1102 - val_loss: 31.9522\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1105 - val_loss: 31.9518\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1108 - val_loss: 31.9516\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1110 - val_loss: 31.9510\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1113 - val_loss: 31.9506\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1116 - val_loss: 31.9501\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1119 - val_loss: 31.9496\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1121 - val_loss: 31.9490\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1124 - val_loss: 31.9486\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1127 - val_loss: 31.9481\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1129 - val_loss: 31.9476\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1132 - val_loss: 31.9470\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.1135 - val_loss: 31.9466\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1137 - val_loss: 31.9462\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1140 - val_loss: 31.9456\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 9.1142 - val_loss: 31.9449\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.1145 - val_loss: 31.9444\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.1148 - val_loss: 31.9441\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1150 - val_loss: 31.9433\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.1152 - val_loss: 31.9428\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.1155 - val_loss: 31.9425\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.1157 - val_loss: 31.9419\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.1160 - val_loss: 31.9413\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1162 - val_loss: 31.9407\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1165 - val_loss: 31.9402\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 9.1167 - val_loss: 31.9395\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1170 - val_loss: 31.9392\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1172 - val_loss: 31.9389\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1174 - val_loss: 31.9382\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1177 - val_loss: 31.9378\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 9.1179 - val_loss: 31.9373\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1181 - val_loss: 31.9369\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1183 - val_loss: 31.9364\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1186 - val_loss: 31.9357\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1188 - val_loss: 31.9352\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1190 - val_loss: 31.9348\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1192 - val_loss: 31.9344\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1195 - val_loss: 31.9339\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1197 - val_loss: 31.9333\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 9.1199 - val_loss: 31.9328\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1201 - val_loss: 31.9325\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1203 - val_loss: 31.9320\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1205 - val_loss: 31.9317\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1208 - val_loss: 31.9312\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1209 - val_loss: 31.9306\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1211 - val_loss: 31.9301\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1214 - val_loss: 31.9297\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1215 - val_loss: 31.9294\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1218 - val_loss: 31.9290\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1219 - val_loss: 31.9284\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 9.1221 - val_loss: 31.9279\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1223 - val_loss: 31.9275\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1225 - val_loss: 31.9272\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1227 - val_loss: 31.9266\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 344ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.23658497e+01, 7.23462418e+01, 7.23266340e+01, 7.23070261e+01,\n",
       "        7.22874183e+01, 7.22678105e+01, 7.22482026e+01, 7.22285948e+01,\n",
       "        7.22089869e+01, 7.21893791e+01, 7.21697712e+01, 7.21501634e+01,\n",
       "        7.21305556e+01, 7.21109477e+01, 7.20913399e+01, 7.20717320e+01,\n",
       "        7.20521242e+01, 7.20325163e+01, 7.20129085e+01, 7.19933006e+01,\n",
       "        7.19736928e+01, 7.19540850e+01, 7.19344771e+01, 7.19148693e+01,\n",
       "        7.18952614e+01, 7.18756536e+01, 7.18560458e+01, 7.18364379e+01,\n",
       "        7.18168301e+01, 7.17996032e+01, 7.17968020e+01, 7.17940009e+01,\n",
       "        7.17911998e+01, 7.17883987e+01, 7.17855976e+01, 7.17827965e+01,\n",
       "        7.17799953e+01, 7.17771942e+01, 7.17743931e+01, 7.17715920e+01,\n",
       "        7.17687909e+01, 7.17659897e+01, 7.17631886e+01, 7.17603875e+01,\n",
       "        7.17575864e+01, 7.17547852e+01, 7.17519841e+01, 7.17491830e+01,\n",
       "        7.17463819e+01, 7.17435808e+01, 7.17407796e+01, 7.17379785e+01,\n",
       "        7.17351774e+01, 7.17323763e+01, 7.17295752e+01, 7.17267740e+01,\n",
       "        7.17239729e+01, 7.17211718e+01, 7.17183707e+01, 7.17155696e+01,\n",
       "        7.17127684e+01, 7.17099673e+01, 7.17071662e+01, 7.17043651e+01,\n",
       "        7.17015640e+01, 7.16938142e+01, 7.16798086e+01, 7.16658030e+01,\n",
       "        7.16517974e+01, 7.16377918e+01, 7.16237862e+01, 7.16097806e+01,\n",
       "        7.15957750e+01, 7.15817694e+01, 7.15677638e+01, 7.15537582e+01,\n",
       "        7.15397526e+01, 7.15257470e+01, 7.15117414e+01, 7.14977358e+01,\n",
       "        7.76459885e+01, 0.00000000e+00, 0.00000000e+00, 4.20036279e-02,\n",
       "        1.10221237e-01, 8.16303492e-03, 0.00000000e+00, 4.65328842e-02,\n",
       "        2.32614577e-01, 7.46001244e-01, 6.42434508e-02, 5.92746615e-01,\n",
       "        1.45638764e-01, 0.00000000e+00, 0.00000000e+00, 3.99314523e-01,\n",
       "        3.89210403e-01, 0.00000000e+00, 0.00000000e+00, 4.76623833e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70.24016106, 70.23502568, 70.22989029, 70.2247549 , 70.21961951,\n",
       "       70.21448413, 70.20934874, 70.20421335, 70.19907796, 70.19394258,\n",
       "       70.18880719, 70.1836718 , 70.17853641, 70.17340103, 70.16826564,\n",
       "       70.16313025, 70.15799486, 70.15285948, 70.14772409, 70.1425887 ,\n",
       "       70.13745331, 70.13231793, 70.12718254, 70.12204715, 70.11691176,\n",
       "       70.11177638, 70.10664099, 70.1015056 , 70.09637021, 70.09123483,\n",
       "       70.08609944, 70.08096405, 70.07582866, 70.07069328, 70.06555789,\n",
       "       70.0604225 , 70.05528711, 70.05015173, 70.04501634, 70.03988095,\n",
       "       70.03474556, 70.02961018, 70.02447479, 70.0193394 , 70.01420401,\n",
       "       70.00906863, 70.00393324, 69.99879785, 69.99366246, 69.98852708,\n",
       "       69.98339169, 69.9782563 , 69.97312092, 69.96798553, 69.96285014,\n",
       "       69.95771475, 69.95257937, 69.94744398, 69.94230859, 69.9371732 ,\n",
       "       69.93203782, 69.92690243, 69.92176704, 69.91663165, 69.91149627,\n",
       "       69.90636088, 69.90122549, 69.8960901 , 69.89095472, 69.88581933,\n",
       "       69.88068394, 69.87554855, 69.87041317, 69.86527778, 69.86014239,\n",
       "       69.855007  , 69.84987162, 69.84473623, 69.83960084, 69.83446545,\n",
       "       69.82933007, 69.82419468, 69.81905929, 69.8139239 , 69.80878852,\n",
       "       69.80365313, 69.79851774, 69.79338235, 69.78824697, 69.78311158,\n",
       "       69.77797619, 69.7728408 , 69.76770542, 69.76257003, 69.75743464,\n",
       "       69.75229925, 69.74716387, 69.74202848, 69.73689309, 69.7317577 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.394339172662356\n",
      "14.749663203910172\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
