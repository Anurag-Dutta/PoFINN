{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2445    67.339414\n",
       "2446    67.333128\n",
       "2447    67.326843\n",
       "2448    67.320557\n",
       "2449    67.314272\n",
       "Name: C3, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_2350_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2345     0.513488\n",
       "2346     0.000000\n",
       "2347     0.754345\n",
       "2348     0.000000\n",
       "2349     0.000000\n",
       "Name: C3, Length: 2350, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2350)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 1, 251) (1900, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 2s 21ms/step - loss: 5864.3618 - val_loss: 4043.4990\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5755.6514 - val_loss: 3982.9448\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5661.4736 - val_loss: 3923.3892\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5568.4438 - val_loss: 3864.6741\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5476.5942 - val_loss: 3806.7659\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5385.8975 - val_loss: 3749.6477\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5296.3340 - val_loss: 3693.3076\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5198.5923 - val_loss: 3628.1382\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5102.2549 - val_loss: 3569.0547\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5010.7041 - val_loss: 3511.6477\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4921.2373 - val_loss: 3455.5408\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4833.4487 - val_loss: 3400.5300\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4747.1284 - val_loss: 3346.5093\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4662.1606 - val_loss: 3293.4131\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4578.4712 - val_loss: 3241.2000\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4496.0093 - val_loss: 3189.8374\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4414.7349 - val_loss: 3139.3010\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4334.6216 - val_loss: 3089.5718\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4255.6411 - val_loss: 3040.6318\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4177.7720 - val_loss: 2992.4670\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4100.9971 - val_loss: 2945.0652\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4025.2964 - val_loss: 2898.4128\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3950.6565 - val_loss: 2852.5000\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3877.0625 - val_loss: 2807.3164\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3804.5000 - val_loss: 2762.8523\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3732.9568 - val_loss: 2719.0986\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3662.4207 - val_loss: 2676.0459\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 3592.8799 - val_loss: 2633.6865\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3524.3210 - val_loss: 2592.0115\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3456.7356 - val_loss: 2551.0139\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3390.1118 - val_loss: 2510.6853\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3324.4397 - val_loss: 2471.0178\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3259.7085 - val_loss: 2432.0044\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3195.9092 - val_loss: 2393.6382\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3133.0295 - val_loss: 2355.9114\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3071.0623 - val_loss: 2318.8176\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3009.9980 - val_loss: 2282.3496\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2949.8259 - val_loss: 2246.5010\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2890.5386 - val_loss: 2211.2646\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2832.1257 - val_loss: 2176.6343\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2774.5784 - val_loss: 2142.6030\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2717.8879 - val_loss: 2109.1646\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2662.0469 - val_loss: 2076.3130\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2607.0454 - val_loss: 2044.0417\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2552.8752 - val_loss: 2012.3441\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2499.5276 - val_loss: 1981.2148\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2446.9963 - val_loss: 1950.6477\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2395.2710 - val_loss: 1920.6359\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2344.3438 - val_loss: 1891.1738\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2294.2070 - val_loss: 1862.2556\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2244.8528 - val_loss: 1833.8755\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2196.2729 - val_loss: 1806.0276\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2148.4604 - val_loss: 1778.7065\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 2101.4070 - val_loss: 1751.9061\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2055.1050 - val_loss: 1725.6208\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2009.5470 - val_loss: 1699.8451\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1964.7250 - val_loss: 1674.5730\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1920.6320 - val_loss: 1649.7993\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1877.2600 - val_loss: 1625.5186\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1834.6023 - val_loss: 1601.7250\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1792.6510 - val_loss: 1578.4133\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1751.3993 - val_loss: 1555.5778\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1710.8389 - val_loss: 1533.2135\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1670.9644 - val_loss: 1511.3152\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1631.7675 - val_loss: 1489.8773\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1593.2413 - val_loss: 1468.8945\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1555.3783 - val_loss: 1448.3612\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1518.1724 - val_loss: 1428.2728\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1481.6163 - val_loss: 1408.6241\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1445.7030 - val_loss: 1389.4104\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1410.4263 - val_loss: 1370.5334\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1372.1487 - val_loss: 1348.1284\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1331.3368 - val_loss: 1326.7971\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1292.7815 - val_loss: 1306.7979\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1255.9994 - val_loss: 1287.7263\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1220.5624 - val_loss: 1269.4016\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1186.2449 - val_loss: 1251.7288\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1152.9142 - val_loss: 1234.6476\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1120.4847 - val_loss: 1218.1161\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1088.8937 - val_loss: 1202.1041\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1058.0950 - val_loss: 1186.5863\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1028.0508 - val_loss: 1171.5426\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 998.7309 - val_loss: 1156.9561\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 970.1094 - val_loss: 1142.8116\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 942.1641 - val_loss: 1129.0963\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 914.8758 - val_loss: 1115.7983\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 888.2265 - val_loss: 1102.9069\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 862.2004 - val_loss: 1090.4120\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 836.7829 - val_loss: 1078.3042\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 811.9601 - val_loss: 1066.5748\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 787.7194 - val_loss: 1055.2155\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 764.0487 - val_loss: 1044.2183\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 740.9366 - val_loss: 1033.5754\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 718.3723 - val_loss: 1023.2800\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 696.3456 - val_loss: 1013.3248\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 674.8461 - val_loss: 1003.7025\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 653.8641 - val_loss: 994.4067\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 633.3910 - val_loss: 985.4311\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 613.4167 - val_loss: 976.7689\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 593.9329 - val_loss: 968.4140\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 574.9310 - val_loss: 960.3606\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 556.4025 - val_loss: 952.6023\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 538.3389 - val_loss: 945.1334\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 520.7324 - val_loss: 937.9479\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 503.5748 - val_loss: 931.0402\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 486.8584 - val_loss: 924.4044\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 470.5754 - val_loss: 918.0353\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 454.7185 - val_loss: 911.9268\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 439.2796 - val_loss: 906.0740\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 424.2520 - val_loss: 900.4711\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 409.6279 - val_loss: 895.1129\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 395.4003 - val_loss: 889.9941\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 381.5625 - val_loss: 885.1094\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 368.1067 - val_loss: 880.4536\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 355.0264 - val_loss: 876.0214\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 342.3146 - val_loss: 871.8080\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 329.9646 - val_loss: 867.8082\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 317.9695 - val_loss: 864.0168\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 306.3226 - val_loss: 860.4289\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 295.0171 - val_loss: 857.0396\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 284.0467 - val_loss: 853.8439\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 273.4048 - val_loss: 850.8369\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 263.0847 - val_loss: 848.0135\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 253.0802 - val_loss: 845.3698\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 243.3851 - val_loss: 842.9000\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 233.9927 - val_loss: 840.5999\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 224.8969 - val_loss: 838.4647\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 216.0917 - val_loss: 836.4896\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 207.5700 - val_loss: 834.6700\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 199.3268 - val_loss: 833.0016\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 191.3558 - val_loss: 831.4796\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 183.6505 - val_loss: 830.0996\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 176.2055 - val_loss: 828.8572\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 169.0146 - val_loss: 827.7477\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 162.0721 - val_loss: 826.7672\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 155.3719 - val_loss: 825.9108\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 148.9087 - val_loss: 825.1747\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 142.6765 - val_loss: 824.5544\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 136.6695 - val_loss: 824.0457\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 130.8825 - val_loss: 823.6443\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 125.3097 - val_loss: 823.3466\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 119.9456 - val_loss: 823.1479\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 114.7851 - val_loss: 823.0446\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 109.8226 - val_loss: 823.0326\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 105.0529 - val_loss: 823.1080\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 100.4706 - val_loss: 823.2670\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 96.0708 - val_loss: 823.5057\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 91.8480 - val_loss: 823.8206\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 87.7974 - val_loss: 824.2077\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 83.9141 - val_loss: 824.6634\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 80.1931 - val_loss: 825.1842\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 76.6293 - val_loss: 825.7668\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 73.2184 - val_loss: 826.4074\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 69.9551 - val_loss: 827.1027\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 66.8351 - val_loss: 827.8497\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 63.8537 - val_loss: 828.6446\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 61.0065 - val_loss: 829.4846\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 58.2892 - val_loss: 830.3663\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 55.6971 - val_loss: 831.2869\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 53.2262 - val_loss: 832.2435\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 50.8721 - val_loss: 833.2327\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 48.6308 - val_loss: 834.2522\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 46.4983 - val_loss: 835.2988\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 44.4704 - val_loss: 836.3702\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 42.5435 - val_loss: 837.4635\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 40.7137 - val_loss: 838.5760\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 38.9773 - val_loss: 839.7057\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 37.3307 - val_loss: 840.8497\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 35.7702 - val_loss: 842.0061\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 34.2923 - val_loss: 843.1725\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 32.8938 - val_loss: 844.3466\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 31.5714 - val_loss: 845.5264\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 30.3219 - val_loss: 846.7098\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 29.1418 - val_loss: 847.8954\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 28.0284 - val_loss: 849.0809\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 26.9785 - val_loss: 850.2644\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 25.9896 - val_loss: 851.4443\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.0586 - val_loss: 852.6191\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 24.1829 - val_loss: 853.7872\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.3598 - val_loss: 854.9474\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 22.5867 - val_loss: 856.0978\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 21.8614 - val_loss: 857.2377\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 21.1812 - val_loss: 858.3655\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 20.5441 - val_loss: 859.4799\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.9477 - val_loss: 860.5801\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.3899 - val_loss: 861.6652\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 18.8687 - val_loss: 862.7337\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 18.3820 - val_loss: 863.7851\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 17.9281 - val_loss: 864.8191\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 17.5050 - val_loss: 865.8342\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 17.1109 - val_loss: 866.8302\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 16.7444 - val_loss: 867.8061\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 16.4036 - val_loss: 868.7616\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 16.0872 - val_loss: 869.6965\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 15.7936 - val_loss: 870.6098\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 15.5214 - val_loss: 871.5015\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 15.2694 - val_loss: 872.3712\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 15.0362 - val_loss: 873.2191\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 14.8205 - val_loss: 874.0447\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 14.6213 - val_loss: 874.8477\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 14.4376 - val_loss: 875.6278\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 14.2682 - val_loss: 876.3857\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 14.1122 - val_loss: 877.1209\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 13.9687 - val_loss: 877.8336\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 13.8367 - val_loss: 878.5236\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 13.7155 - val_loss: 879.1913\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 13.6044 - val_loss: 879.8369\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 13.5025 - val_loss: 880.4605\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 13.4092 - val_loss: 881.0625\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 13.3238 - val_loss: 881.6431\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 13.2458 - val_loss: 882.2021\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 13.1745 - val_loss: 882.7405\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 13.1095 - val_loss: 883.2582\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 13.0503 - val_loss: 883.7561\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.9963 - val_loss: 884.2339\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.9472 - val_loss: 884.6923\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.9026 - val_loss: 885.1317\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.8621 - val_loss: 885.5526\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.8253 - val_loss: 885.9553\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 12.7919 - val_loss: 886.3403\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.7617 - val_loss: 886.7079\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.7344 - val_loss: 887.0590\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.7097 - val_loss: 887.3939\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.6874 - val_loss: 887.7129\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.6673 - val_loss: 888.0166\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.6491 - val_loss: 888.3054\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.6328 - val_loss: 888.5798\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.6180 - val_loss: 888.8406\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.6048 - val_loss: 889.0878\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5929 - val_loss: 889.3223\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5822 - val_loss: 889.5446\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5726 - val_loss: 889.7546\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5641 - val_loss: 889.9534\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5563 - val_loss: 890.1407\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5495 - val_loss: 890.3177\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5433 - val_loss: 890.4844\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5379 - val_loss: 890.6417\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 12.5330 - val_loss: 890.7895\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5287 - val_loss: 890.9283\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5248 - val_loss: 891.0589\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5214 - val_loss: 891.1815\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5184 - val_loss: 891.2966\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5158 - val_loss: 891.4044\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5134 - val_loss: 891.5048\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5114 - val_loss: 891.5987\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5097 - val_loss: 891.6864\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5081 - val_loss: 891.7682\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5068 - val_loss: 891.8445\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5057 - val_loss: 891.9158\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5048 - val_loss: 891.9818\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5040 - val_loss: 892.0431\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5034 - val_loss: 892.1000\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5028 - val_loss: 892.1528\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 12.5024 - val_loss: 892.2012\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5022 - val_loss: 892.2464\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5020 - val_loss: 892.2883\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5019 - val_loss: 892.3262\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5019 - val_loss: 892.3615\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5019 - val_loss: 892.3940\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5020 - val_loss: 892.4235\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5022 - val_loss: 892.4507\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5025 - val_loss: 892.4756\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5028 - val_loss: 892.4984\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5032 - val_loss: 892.5192\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5036 - val_loss: 892.5383\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5040 - val_loss: 892.5554\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5044 - val_loss: 892.5707\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5050 - val_loss: 892.5845\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5055 - val_loss: 892.5970\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 12.5061 - val_loss: 892.6086\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5067 - val_loss: 892.6189\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5073 - val_loss: 892.6278\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5079 - val_loss: 892.6359\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5086 - val_loss: 892.6432\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5092 - val_loss: 892.6494\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5099 - val_loss: 892.6548\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5106 - val_loss: 892.6595\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5114 - val_loss: 892.6636\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5121 - val_loss: 892.6671\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5128 - val_loss: 892.6702\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5136 - val_loss: 892.6725\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5143 - val_loss: 892.6743\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5152 - val_loss: 892.6759\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5160 - val_loss: 892.6773\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5167 - val_loss: 892.6779\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 12.5176 - val_loss: 892.6785\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5183 - val_loss: 892.6790\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5191 - val_loss: 892.6790\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5200 - val_loss: 892.6786\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5208 - val_loss: 892.6780\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5216 - val_loss: 892.6776\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5224 - val_loss: 892.6766\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5233 - val_loss: 892.6755\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5242 - val_loss: 892.6743\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5249 - val_loss: 892.6731\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5258 - val_loss: 892.6717\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5266 - val_loss: 892.6702\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5274 - val_loss: 892.6686\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5283 - val_loss: 892.6671\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5291 - val_loss: 892.6652\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5300 - val_loss: 892.6636\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 12.5308 - val_loss: 892.6619\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5316 - val_loss: 892.6600\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5324 - val_loss: 892.6579\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5333 - val_loss: 892.6559\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5341 - val_loss: 892.6543\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5349 - val_loss: 892.6520\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5357 - val_loss: 892.6501\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5365 - val_loss: 892.6483\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5373 - val_loss: 892.6462\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5382 - val_loss: 892.6442\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5389 - val_loss: 892.6423\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5398 - val_loss: 892.6401\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5405 - val_loss: 892.6382\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5413 - val_loss: 892.6359\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5421 - val_loss: 892.6340\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 12.5429 - val_loss: 892.6319\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5436 - val_loss: 892.6298\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5445 - val_loss: 892.6276\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5452 - val_loss: 892.6257\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5460 - val_loss: 892.6238\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5467 - val_loss: 892.6216\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5474 - val_loss: 892.6194\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5482 - val_loss: 892.6174\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5490 - val_loss: 892.6155\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5497 - val_loss: 892.6135\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5504 - val_loss: 892.6118\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5511 - val_loss: 892.6097\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5518 - val_loss: 892.6078\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5526 - val_loss: 892.6061\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5532 - val_loss: 892.6039\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 12.5539 - val_loss: 892.6018\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5547 - val_loss: 892.6000\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5553 - val_loss: 892.5982\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5560 - val_loss: 892.5964\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5567 - val_loss: 892.5948\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5573 - val_loss: 892.5933\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5580 - val_loss: 892.5913\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5586 - val_loss: 892.5897\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5593 - val_loss: 892.5880\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5599 - val_loss: 892.5862\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5605 - val_loss: 892.5846\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5611 - val_loss: 892.5827\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5618 - val_loss: 892.5814\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5623 - val_loss: 892.5798\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 12.5629 - val_loss: 892.5779\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5635 - val_loss: 892.5767\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5641 - val_loss: 892.5750\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5647 - val_loss: 892.5736\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5652 - val_loss: 892.5722\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5657 - val_loss: 892.5706\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5663 - val_loss: 892.5692\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5669 - val_loss: 892.5676\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5674 - val_loss: 892.5661\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5680 - val_loss: 892.5649\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5684 - val_loss: 892.5634\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5690 - val_loss: 892.5620\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5694 - val_loss: 892.5604\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5700 - val_loss: 892.5594\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 12.5705 - val_loss: 892.5579\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5709 - val_loss: 892.5566\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5714 - val_loss: 892.5549\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5719 - val_loss: 892.5536\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5723 - val_loss: 892.5522\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5728 - val_loss: 892.5511\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5732 - val_loss: 892.5497\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5737 - val_loss: 892.5487\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5741 - val_loss: 892.5476\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5746 - val_loss: 892.5467\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5750 - val_loss: 892.5455\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5753 - val_loss: 892.5443\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5757 - val_loss: 892.5431\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5762 - val_loss: 892.5419\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 12.5766 - val_loss: 892.5413\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5769 - val_loss: 892.5400\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5773 - val_loss: 892.5390\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5777 - val_loss: 892.5380\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 12.5781 - val_loss: 892.5374\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5784 - val_loss: 892.5362\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5788 - val_loss: 892.5353\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5791 - val_loss: 892.5343\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5794 - val_loss: 892.5334\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5797 - val_loss: 892.5322\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5801 - val_loss: 892.5314\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5804 - val_loss: 892.5305\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5808 - val_loss: 892.5299\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 12.5810 - val_loss: 892.5291\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5813 - val_loss: 892.5280\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5816 - val_loss: 892.5275\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5819 - val_loss: 892.5261\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5822 - val_loss: 892.5256\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5825 - val_loss: 892.5250\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5828 - val_loss: 892.5241\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5830 - val_loss: 892.5232\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5833 - val_loss: 892.5223\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5836 - val_loss: 892.5217\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5838 - val_loss: 892.5209\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5841 - val_loss: 892.5206\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5843 - val_loss: 892.5199\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 12.5846 - val_loss: 892.5191\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5848 - val_loss: 892.5183\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5851 - val_loss: 892.5181\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5852 - val_loss: 892.5176\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5855 - val_loss: 892.5170\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5857 - val_loss: 892.5161\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5859 - val_loss: 892.5156\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5861 - val_loss: 892.5151\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5863 - val_loss: 892.5144\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5865 - val_loss: 892.5140\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5867 - val_loss: 892.5132\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5869 - val_loss: 892.5128\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5871 - val_loss: 892.5123\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5873 - val_loss: 892.5118\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5875 - val_loss: 892.5114\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5876 - val_loss: 892.5105\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5878 - val_loss: 892.5102\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 12.5880 - val_loss: 892.5096\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5882 - val_loss: 892.5094\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5883 - val_loss: 892.5092\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5884 - val_loss: 892.5085\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5886 - val_loss: 892.5084\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5888 - val_loss: 892.5078\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5889 - val_loss: 892.5071\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5891 - val_loss: 892.5067\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5892 - val_loss: 892.5064\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5894 - val_loss: 892.5060\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5895 - val_loss: 892.5059\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5896 - val_loss: 892.5056\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5897 - val_loss: 892.5051\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5899 - val_loss: 892.5046\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5900 - val_loss: 892.5043\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5901 - val_loss: 892.5038\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 12.5902 - val_loss: 892.5034\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5903 - val_loss: 892.5028\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5904 - val_loss: 892.5024\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5906 - val_loss: 892.5021\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5907 - val_loss: 892.5018\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5909 - val_loss: 892.5018\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5909 - val_loss: 892.5018\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5910 - val_loss: 892.5014\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5911 - val_loss: 892.5012\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5913 - val_loss: 892.5013\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5913 - val_loss: 892.5009\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5914 - val_loss: 892.5004\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5915 - val_loss: 892.5002\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5916 - val_loss: 892.5002\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5917 - val_loss: 892.5002\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 12.5917 - val_loss: 892.4996\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5918 - val_loss: 892.4995\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 12.5919 - val_loss: 892.4993\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5920 - val_loss: 892.4990\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5920 - val_loss: 892.4987\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5922 - val_loss: 892.4987\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5922 - val_loss: 892.4982\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5923 - val_loss: 892.4980\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5923 - val_loss: 892.4978\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5924 - val_loss: 892.4977\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5925 - val_loss: 892.4976\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5926 - val_loss: 892.4974\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5927 - val_loss: 892.4976\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 12.5927 - val_loss: 892.4970\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 12.5927 - val_loss: 892.4966\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5928 - val_loss: 892.4965\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5929 - val_loss: 892.4962\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5929 - val_loss: 892.4960\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5930 - val_loss: 892.4960\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5930 - val_loss: 892.4957\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5931 - val_loss: 892.4957\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5931 - val_loss: 892.4954\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5932 - val_loss: 892.4954\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5932 - val_loss: 892.4952\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5933 - val_loss: 892.4950\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5934 - val_loss: 892.4951\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5934 - val_loss: 892.4949\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5935 - val_loss: 892.4948\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5935 - val_loss: 892.4948\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5935 - val_loss: 892.4945\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5936 - val_loss: 892.4943\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 12.5937 - val_loss: 892.4944\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5937 - val_loss: 892.4944\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5937 - val_loss: 892.4943\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5938 - val_loss: 892.4943\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5938 - val_loss: 892.4941\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5938 - val_loss: 892.4939\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5938 - val_loss: 892.4938\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5939 - val_loss: 892.4939\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5939 - val_loss: 892.4938\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5940 - val_loss: 892.4938\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5940 - val_loss: 892.4938\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5940 - val_loss: 892.4934\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5941 - val_loss: 892.4934\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5940 - val_loss: 892.4931\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5941 - val_loss: 892.4929\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5941 - val_loss: 892.4929\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 12.5942 - val_loss: 892.4929\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 12.5942 - val_loss: 892.4929\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5942 - val_loss: 892.4929\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5942 - val_loss: 892.4929\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5943 - val_loss: 892.4929\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.5943 - val_loss: 892.4927\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 366ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.18233660e+01, 7.17949346e+01, 7.17865313e+01, 7.17781279e+01,\n",
       "        7.17697246e+01, 7.17613212e+01, 7.17529178e+01, 0.00000000e+00,\n",
       "        1.14750028e-01, 0.00000000e+00, 0.00000000e+00, 7.00237230e-02,\n",
       "        2.78152108e-01, 7.23658497e+01, 7.23070261e+01, 7.22482026e+01,\n",
       "        7.21893791e+01, 7.21305556e+01, 7.20717320e+01, 7.20129085e+01,\n",
       "        7.19540850e+01, 7.18952614e+01, 7.18364379e+01, 7.17968020e+01,\n",
       "        7.17883987e+01, 7.17799953e+01, 7.17715920e+01, 7.16318860e+01,\n",
       "        7.15478520e+01, 7.14638190e+01, 7.13797850e+01, 7.12977520e+01,\n",
       "        7.12117180e+01, 7.11276840e+01, 7.10436510e+01, 7.07980860e+01,\n",
       "        7.03779180e+01, 6.99577500e+01, 6.95375820e+01, 6.91174140e+01,\n",
       "        0.00000000e+00, 1.10221237e-01, 4.65328840e-02, 6.42434510e-02,\n",
       "        0.00000000e+00, 3.89210403e-01, 4.76623833e-01, 7.17818628e+01,\n",
       "        7.17734594e+01, 7.17650560e+01, 7.17566527e+01, 7.17482493e+01,\n",
       "        7.17398459e+01, 7.17314426e+01, 7.17230392e+01, 7.17146358e+01,\n",
       "        7.17062325e+01, 7.16891457e+01, 7.16471289e+01, 7.16051120e+01,\n",
       "        7.15630952e+01, 7.15210784e+01, 7.41098739e+01, 7.39838235e+01,\n",
       "        7.38577731e+01, 7.36224790e+01, 7.32947479e+01, 7.29670168e+01,\n",
       "        7.26392857e+01, 7.23965294e+01, 7.22130588e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.86222229e+01, 0.00000000e+00, 1.75635890e-02,\n",
       "        0.00000000e+00, 1.83566960e-02, 0.00000000e+00, 2.75135490e-02,\n",
       "        5.17735062e+01, 4.96371053e-02, 9.77881551e-02, 0.00000000e+00,\n",
       "        1.18597463e-01, 0.00000000e+00, 1.25325294e-02, 0.00000000e+00,\n",
       "        1.97437748e-01, 0.00000000e+00, 1.08522129e+00, 1.28528282e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.36604603e-02, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([67.93653071, 67.93024527, 67.92395983, 67.91767439, 67.91138895,\n",
       "       67.9051035 , 67.89881806, 67.89253262, 67.88624718, 67.87996174,\n",
       "       67.8736763 , 67.86739086, 67.86110542, 67.85481998, 67.84853454,\n",
       "       67.84224909, 67.83596365, 67.82967821, 67.82339277, 67.81710733,\n",
       "       67.81082189, 67.80453645, 67.79825101, 67.79196557, 67.78568013,\n",
       "       67.77939468, 67.77310924, 67.7668238 , 67.76053836, 67.75425292,\n",
       "       67.74796748, 67.74168204, 67.7353966 , 67.72911116, 67.72282572,\n",
       "       67.71654027, 67.71025483, 67.70396939, 67.69768395, 67.69139851,\n",
       "       67.68511307, 67.67882763, 67.67254219, 67.66625675, 67.65997131,\n",
       "       67.65368586, 67.64740042, 67.64111498, 67.63482954, 67.6285441 ,\n",
       "       67.62225866, 67.61597322, 67.60968778, 67.60340234, 67.5971169 ,\n",
       "       67.59083145, 67.58454601, 67.57826057, 67.57197513, 67.56568969,\n",
       "       67.55940425, 67.55311881, 67.54683337, 67.54054793, 67.53426249,\n",
       "       67.52797704, 67.5216916 , 67.51540616, 67.50912072, 67.50283528,\n",
       "       67.49654984, 67.4902644 , 67.48397896, 67.47769352, 67.47140808,\n",
       "       67.46512263, 67.45883719, 67.45255175, 67.44626631, 67.43998087,\n",
       "       67.43369543, 67.42740999, 67.42112455, 67.41483911, 67.40855367,\n",
       "       67.40226822, 67.39598278, 67.38969734, 67.3834119 , 67.37712646,\n",
       "       67.37084102, 67.36455558, 67.35827014, 67.3519847 , 67.34569926,\n",
       "       67.33941381, 67.33312837, 67.32684293, 67.32055749, 67.31427205])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.79864165503057\n",
      "29.52856247680649\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
