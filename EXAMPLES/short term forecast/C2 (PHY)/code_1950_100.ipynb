{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "2045    60.143732\n",
       "2046    60.117122\n",
       "2047    60.090511\n",
       "2048    60.063901\n",
       "2049    60.037290\n",
       "Name: C2, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c2_interpolated_1950_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "1945     0.000000\n",
       "1946     0.300215\n",
       "1947     0.000000\n",
       "1948     0.000000\n",
       "1949     0.000000\n",
       "Name: C2, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1950)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.500000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.275910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.051821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.827731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.603641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     90.500000  0.000298\n",
       "1     90.275910  0.000298\n",
       "2     90.051821  0.000297\n",
       "3     89.827731  0.000297\n",
       "4     89.603641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.1552  # Value for C0\n",
    "K0 = -0.0026  # Value for K0\n",
    "K1 = -0.0004  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0102    # Value for b\n",
    "c = 2.8734    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    90.500000    90.275910    90.051821    89.827731    89.603641   \n",
      "351    90.275910    90.051821    89.827731    89.603641    89.379552   \n",
      "352    90.051821    89.827731    89.603641    89.379552    89.155462   \n",
      "353    89.827731    89.603641    89.379552    89.155462    88.931373   \n",
      "354    89.603641    89.379552    89.155462    88.931373    88.707283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.379552    89.155462    88.931373    88.707283    88.494958  ...   \n",
      "351    89.155462    88.931373    88.707283    88.494958    88.427731  ...   \n",
      "352    88.931373    88.707283    88.494958    88.427731    88.360504  ...   \n",
      "353    88.707283    88.494958    88.427731    88.360504    88.293277  ...   \n",
      "354    88.494958    88.427731    88.360504    88.293277    88.226050  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.071008    0.000263   79.054202    0.000263   79.037395    0.000263   \n",
      "351   79.054202    0.000263   79.037395    0.000263   79.020588    0.000262   \n",
      "352   79.037395    0.000263   79.020588    0.000262   79.003782    0.000262   \n",
      "353   79.020588    0.000262   79.003782    0.000262   78.986975    0.000262   \n",
      "354   79.003782    0.000262   78.986975    0.000262   78.970168    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.020588    0.000262   79.003782    0.000262  \n",
      "351   79.003782    0.000262   78.986975    0.000262  \n",
      "352   78.986975    0.000262   78.970168    0.000262  \n",
      "353   78.970168    0.000262   78.953361    0.000262  \n",
      "354   78.953361    0.000262   78.936555    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1, 251) (1500, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 2s 25ms/step - loss: 5399.2441 - val_loss: 4360.2759\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5310.0610 - val_loss: 4301.1152\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5231.5962 - val_loss: 4223.2808\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5157.5786 - val_loss: 4162.3960\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5090.5762 - val_loss: 4102.3730\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5024.4634 - val_loss: 4043.1528\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4959.1528 - val_loss: 3984.6604\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4894.5767 - val_loss: 3926.8484\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4830.6953 - val_loss: 3869.6897\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4767.4834 - val_loss: 3813.1650\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4704.9238 - val_loss: 3757.2612\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4643.0015 - val_loss: 3701.9675\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4574.4229 - val_loss: 3637.4263\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4507.6338 - val_loss: 3578.7329\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4442.8926 - val_loss: 3521.4866\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4379.5625 - val_loss: 3465.3958\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4317.3633 - val_loss: 3410.2664\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4256.1226 - val_loss: 3355.9846\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4195.7412 - val_loss: 3302.4822\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4136.1548 - val_loss: 3249.7104\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4077.3203 - val_loss: 3197.6382\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4019.2041 - val_loss: 3146.2385\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3961.7817 - val_loss: 3095.4917\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3905.0334 - val_loss: 3045.3806\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3848.9421 - val_loss: 2995.8926\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3793.4946 - val_loss: 2947.0146\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3738.6775 - val_loss: 2898.7366\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3684.4807 - val_loss: 2851.0481\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3630.8962 - val_loss: 2803.9419\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3577.9141 - val_loss: 2757.4099\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3525.5249 - val_loss: 2711.4441\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3473.7236 - val_loss: 2666.0376\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3422.5015 - val_loss: 2621.1846\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3371.8530 - val_loss: 2576.8787\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3321.7710 - val_loss: 2533.1135\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3272.2500 - val_loss: 2489.8843\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3223.2839 - val_loss: 2447.1851\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3174.8679 - val_loss: 2405.0103\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3126.9966 - val_loss: 2363.3557\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3079.6638 - val_loss: 2322.2156\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3032.8667 - val_loss: 2281.5854\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2986.5979 - val_loss: 2241.4604\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2940.8535 - val_loss: 2201.8367\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2895.6292 - val_loss: 2162.7085\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2850.9211 - val_loss: 2124.0725\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2806.7231 - val_loss: 2085.9241\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2763.0327 - val_loss: 2048.2593\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2719.8440 - val_loss: 2011.0729\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2677.1536 - val_loss: 1974.3615\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2634.9570 - val_loss: 1938.1204\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2593.2495 - val_loss: 1902.3469\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2552.0286 - val_loss: 1867.0354\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2511.2891 - val_loss: 1832.1833\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2471.0273 - val_loss: 1797.7860\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2431.2395 - val_loss: 1763.8391\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2391.9216 - val_loss: 1730.3409\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2353.0703 - val_loss: 1697.2858\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2314.6812 - val_loss: 1664.6697\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2276.7507 - val_loss: 1632.4904\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2239.2754 - val_loss: 1600.7438\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2202.2517 - val_loss: 1569.4258\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2165.6755 - val_loss: 1538.5336\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2129.5432 - val_loss: 1508.0626\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2093.8521 - val_loss: 1478.0100\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2058.5972 - val_loss: 1448.3721\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2023.7766 - val_loss: 1419.1458\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1989.3862 - val_loss: 1390.3270\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1955.4219 - val_loss: 1361.9122\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1921.8809 - val_loss: 1333.8987\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1888.7600 - val_loss: 1306.2827\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1856.0554 - val_loss: 1279.0610\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1823.7633 - val_loss: 1252.2300\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1791.8821 - val_loss: 1225.7877\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1760.4073 - val_loss: 1199.7288\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1729.3356 - val_loss: 1174.0509\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1698.6637 - val_loss: 1148.7511\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1668.3888 - val_loss: 1123.8257\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1638.5077 - val_loss: 1099.2719\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1609.0167 - val_loss: 1075.0858\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1579.9128 - val_loss: 1051.2649\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1551.1929 - val_loss: 1027.8063\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1522.8540 - val_loss: 1004.7058\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1494.8932 - val_loss: 981.9615\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1467.3071 - val_loss: 959.5684\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1440.0922 - val_loss: 937.5258\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1413.2461 - val_loss: 915.8290\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1386.7651 - val_loss: 894.4758\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1360.6473 - val_loss: 873.4625\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1334.8883 - val_loss: 852.7857\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1309.4860 - val_loss: 832.4437\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1284.4371 - val_loss: 812.4324\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1259.7388 - val_loss: 792.7495\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1235.3882 - val_loss: 773.3916\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1211.3820 - val_loss: 754.3561\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1187.7173 - val_loss: 735.6394\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1164.3917 - val_loss: 717.2389\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1141.4016 - val_loss: 699.1513\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1118.7444 - val_loss: 681.3746\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1096.4174 - val_loss: 663.9048\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1074.4175 - val_loss: 646.7401\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1052.7424 - val_loss: 629.8766\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1031.3883 - val_loss: 613.3120\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1010.3529 - val_loss: 597.0428\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 989.6334 - val_loss: 581.0673\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 969.2269 - val_loss: 565.3810\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 949.1305 - val_loss: 549.9826\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 929.3414 - val_loss: 534.8687\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 909.8568 - val_loss: 520.0352\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 890.6740 - val_loss: 505.4816\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 871.7906 - val_loss: 491.2034\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 853.2034 - val_loss: 477.1980\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 834.9096 - val_loss: 463.4637\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 816.9068 - val_loss: 449.9967\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 799.1920 - val_loss: 436.7941\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 781.7625 - val_loss: 423.8533\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 764.6155 - val_loss: 411.1717\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 747.7484 - val_loss: 398.7467\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 731.1587 - val_loss: 386.5754\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 714.8434 - val_loss: 374.6548\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 698.8000 - val_loss: 362.9821\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 683.0257 - val_loss: 351.5545\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 667.5179 - val_loss: 340.3701\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 652.2741 - val_loss: 329.4251\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 637.2911 - val_loss: 318.7175\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 622.5667 - val_loss: 308.2446\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 608.0984 - val_loss: 298.0030\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 593.8834 - val_loss: 287.9905\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 579.9186 - val_loss: 278.2046\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 566.2019 - val_loss: 268.6421\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 552.7309 - val_loss: 259.3004\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 539.5022 - val_loss: 250.1770\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 526.5137 - val_loss: 241.2690\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 513.7629 - val_loss: 232.5743\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 501.2470 - val_loss: 224.0897\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 488.9637 - val_loss: 215.8122\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 476.9099 - val_loss: 207.7400\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 465.0835 - val_loss: 199.8700\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 453.4818 - val_loss: 192.1996\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 442.1020 - val_loss: 184.7260\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 430.9421 - val_loss: 177.4472\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 419.9992 - val_loss: 170.3590\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 409.2703 - val_loss: 163.4605\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 398.7535 - val_loss: 156.7486\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 388.4460 - val_loss: 150.2204\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 378.3455 - val_loss: 143.8731\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 368.4490 - val_loss: 137.7043\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 358.7543 - val_loss: 131.7118\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 349.2589 - val_loss: 125.8923\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 339.9603 - val_loss: 120.2441\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 330.8563 - val_loss: 114.7642\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 321.9442 - val_loss: 109.4495\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 313.2212 - val_loss: 104.2981\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 304.6851 - val_loss: 99.3069\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 296.3330 - val_loss: 94.4741\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 288.1632 - val_loss: 89.7963\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 280.1725 - val_loss: 85.2714\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 272.3589 - val_loss: 80.8971\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 264.7199 - val_loss: 76.6704\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 257.2532 - val_loss: 72.5892\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 249.9561 - val_loss: 68.6505\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 242.8262 - val_loss: 64.8521\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 235.8611 - val_loss: 61.1916\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 229.0585 - val_loss: 57.6663\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 222.4158 - val_loss: 54.2736\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 215.9307 - val_loss: 51.0116\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 209.6013 - val_loss: 47.8773\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 203.4245 - val_loss: 44.8685\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 197.3982 - val_loss: 41.9827\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 191.5203 - val_loss: 39.2173\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 185.7881 - val_loss: 36.5702\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 180.1994 - val_loss: 34.0388\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 174.7521 - val_loss: 31.6207\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 169.4435 - val_loss: 29.3137\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 164.2716 - val_loss: 27.1152\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 159.2340 - val_loss: 25.0229\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 154.3283 - val_loss: 23.0344\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 149.5522 - val_loss: 21.1474\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 144.9035 - val_loss: 19.3597\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 140.3802 - val_loss: 17.6689\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 135.9798 - val_loss: 16.0728\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 131.7001 - val_loss: 14.5688\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 127.5389 - val_loss: 13.1550\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 123.4941 - val_loss: 11.8290\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 119.5634 - val_loss: 10.5885\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 115.7445 - val_loss: 9.4314\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 112.0356 - val_loss: 8.3555\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 108.4343 - val_loss: 7.3587\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 104.9387 - val_loss: 6.4386\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 101.5465 - val_loss: 5.5932\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 98.2557 - val_loss: 4.8204\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 95.0641 - val_loss: 4.1179\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 91.9696 - val_loss: 3.4839\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 88.9703 - val_loss: 2.9161\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 86.0641 - val_loss: 2.4125\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 83.2490 - val_loss: 1.9712\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 80.5230 - val_loss: 1.5900\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 77.8841 - val_loss: 1.2671\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 75.3304 - val_loss: 1.0004\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 72.8598 - val_loss: 0.7879\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 70.4705 - val_loss: 0.6279\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 68.1606 - val_loss: 0.5184\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 65.9282 - val_loss: 0.4576\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 63.7717 - val_loss: 0.4435\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 61.6885 - val_loss: 0.4744\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 59.6776 - val_loss: 0.5485\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 57.7368 - val_loss: 0.6640\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 55.8644 - val_loss: 0.8191\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 54.0586 - val_loss: 1.0122\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 52.3179 - val_loss: 1.2416\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 50.6404 - val_loss: 1.5056\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 49.0244 - val_loss: 1.8025\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.4681 - val_loss: 2.1308\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 45.9702 - val_loss: 2.4889\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 44.5287 - val_loss: 2.8752\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 43.1423 - val_loss: 3.2883\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 41.8093 - val_loss: 3.7266\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 40.5281 - val_loss: 4.1887\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 39.2973 - val_loss: 4.6732\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 38.1153 - val_loss: 5.1786\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 36.9808 - val_loss: 5.7035\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 35.8922 - val_loss: 6.2468\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 34.8480 - val_loss: 6.8069\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.8471 - val_loss: 7.3829\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 32.8879 - val_loss: 7.9732\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.9690 - val_loss: 8.5767\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.0892 - val_loss: 9.1922\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.2473 - val_loss: 9.8186\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.4419 - val_loss: 10.4549\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 28.6717 - val_loss: 11.0998\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 27.9357 - val_loss: 11.7524\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 27.2325 - val_loss: 12.4114\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 26.5612 - val_loss: 13.0764\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 25.9203 - val_loss: 13.7458\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 25.3090 - val_loss: 14.4192\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 24.7260 - val_loss: 15.0951\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 24.1705 - val_loss: 15.7733\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 23.6412 - val_loss: 16.4526\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 23.1373 - val_loss: 17.1320\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 22.6578 - val_loss: 17.8114\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.2016 - val_loss: 18.4893\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.7679 - val_loss: 19.1654\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.3558 - val_loss: 19.8393\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.9643 - val_loss: 20.5098\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.5927 - val_loss: 21.1765\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20.2401 - val_loss: 21.8388\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9058 - val_loss: 22.4963\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.5888 - val_loss: 23.1483\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19.2885 - val_loss: 23.7944\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.0042 - val_loss: 24.4338\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18.7351 - val_loss: 25.0667\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.4806 - val_loss: 25.6923\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.2399 - val_loss: 26.3103\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.0125 - val_loss: 26.9201\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.7977 - val_loss: 27.5216\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.5950 - val_loss: 28.1143\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17.4038 - val_loss: 28.6980\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.2234 - val_loss: 29.2726\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.0535 - val_loss: 29.8377\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 16.8934 - val_loss: 30.3930\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16.7428 - val_loss: 30.9385\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 16.6010 - val_loss: 31.4740\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.4676 - val_loss: 31.9992\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 16.3423 - val_loss: 32.5140\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.2246 - val_loss: 33.0181\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.1141 - val_loss: 33.5118\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.0104 - val_loss: 33.9948\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.9132 - val_loss: 34.4670\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.8220 - val_loss: 34.9284\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.7367 - val_loss: 35.3790\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15.6567 - val_loss: 35.8190\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.5819 - val_loss: 36.2483\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.5119 - val_loss: 36.6668\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.4464 - val_loss: 37.0744\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.3853 - val_loss: 37.4712\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.3282 - val_loss: 37.8576\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2749 - val_loss: 38.2333\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2251 - val_loss: 38.5984\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.1788 - val_loss: 38.9531\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.1356 - val_loss: 39.2978\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.0953 - val_loss: 39.6320\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.0579 - val_loss: 39.9562\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.0230 - val_loss: 40.2706\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 14.9905 - val_loss: 40.5752\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.9603 - val_loss: 40.8702\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.9322 - val_loss: 41.1556\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.9062 - val_loss: 41.4314\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.8820 - val_loss: 41.6981\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.8596 - val_loss: 41.9558\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.8387 - val_loss: 42.2048\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.8194 - val_loss: 42.4447\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.8015 - val_loss: 42.6765\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.7850 - val_loss: 42.8999\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.7696 - val_loss: 43.1149\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.7554 - val_loss: 43.3222\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.7422 - val_loss: 43.5216\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.7301 - val_loss: 43.7137\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.7187 - val_loss: 43.8980\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.7084 - val_loss: 44.0752\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6988 - val_loss: 44.2456\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6899 - val_loss: 44.4091\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6816 - val_loss: 44.5657\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6741 - val_loss: 44.7161\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.6671 - val_loss: 44.8602\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6607 - val_loss: 44.9985\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6547 - val_loss: 45.1305\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6492 - val_loss: 45.2571\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 14.6442 - val_loss: 45.3778\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6396 - val_loss: 45.4930\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6353 - val_loss: 45.6034\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6313 - val_loss: 45.7085\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6277 - val_loss: 45.8090\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6244 - val_loss: 45.9050\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6214 - val_loss: 45.9963\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6186 - val_loss: 46.0834\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6160 - val_loss: 46.1664\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6136 - val_loss: 46.2450\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6115 - val_loss: 46.3197\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6096 - val_loss: 46.3913\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6077 - val_loss: 46.4588\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6061 - val_loss: 46.5230\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.6046 - val_loss: 46.5837\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6032 - val_loss: 46.6416\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6020 - val_loss: 46.6961\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6009 - val_loss: 46.7479\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5999 - val_loss: 46.7971\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5990 - val_loss: 46.8432\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5982 - val_loss: 46.8873\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5975 - val_loss: 46.9288\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.5968 - val_loss: 46.9680\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5962 - val_loss: 47.0050\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5957 - val_loss: 47.0397\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 14.5953 - val_loss: 47.0725\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5949 - val_loss: 47.1034\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.5946 - val_loss: 47.1325\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5943 - val_loss: 47.1598\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5941 - val_loss: 47.1854\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5939 - val_loss: 47.2095\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.5938 - val_loss: 47.2322\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5937 - val_loss: 47.2532\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.5937 - val_loss: 47.2733\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5936 - val_loss: 47.2919\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.5936 - val_loss: 47.3093\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5937 - val_loss: 47.3256\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5937 - val_loss: 47.3408\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5938 - val_loss: 47.3550\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5939 - val_loss: 47.3681\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5940 - val_loss: 47.3802\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5942 - val_loss: 47.3918\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5944 - val_loss: 47.4025\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.5946 - val_loss: 47.4124\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5948 - val_loss: 47.4216\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5950 - val_loss: 47.4303\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5953 - val_loss: 47.4380\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 14.5955 - val_loss: 47.4452\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5958 - val_loss: 47.4517\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5961 - val_loss: 47.4581\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5964 - val_loss: 47.4637\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5967 - val_loss: 47.4691\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5970 - val_loss: 47.4738\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5973 - val_loss: 47.4780\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5976 - val_loss: 47.4821\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.5980 - val_loss: 47.4858\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5983 - val_loss: 47.4888\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5987 - val_loss: 47.4918\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5990 - val_loss: 47.4946\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.5994 - val_loss: 47.4970\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.5997 - val_loss: 47.4990\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6001 - val_loss: 47.5010\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6005 - val_loss: 47.5026\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6009 - val_loss: 47.5041\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6013 - val_loss: 47.5054\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6017 - val_loss: 47.5063\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6021 - val_loss: 47.5076\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6024 - val_loss: 47.5083\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6028 - val_loss: 47.5090\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6033 - val_loss: 47.5096\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6036 - val_loss: 47.5099\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 14.6041 - val_loss: 47.5104\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6045 - val_loss: 47.5106\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6049 - val_loss: 47.5107\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6052 - val_loss: 47.5107\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6056 - val_loss: 47.5107\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6060 - val_loss: 47.5105\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6065 - val_loss: 47.5105\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6069 - val_loss: 47.5103\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6073 - val_loss: 47.5101\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6077 - val_loss: 47.5098\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6081 - val_loss: 47.5096\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6084 - val_loss: 47.5090\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6088 - val_loss: 47.5085\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6093 - val_loss: 47.5081\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6097 - val_loss: 47.5078\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6100 - val_loss: 47.5071\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6104 - val_loss: 47.5062\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6108 - val_loss: 47.5055\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6112 - val_loss: 47.5050\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6116 - val_loss: 47.5043\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6120 - val_loss: 47.5038\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6124 - val_loss: 47.5032\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 14.6127 - val_loss: 47.5023\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6132 - val_loss: 47.5016\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6135 - val_loss: 47.5008\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6139 - val_loss: 47.5001\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6143 - val_loss: 47.4992\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6147 - val_loss: 47.4986\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6150 - val_loss: 47.4977\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6154 - val_loss: 47.4972\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6157 - val_loss: 47.4964\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6161 - val_loss: 47.4955\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6165 - val_loss: 47.4949\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6169 - val_loss: 47.4944\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6172 - val_loss: 47.4937\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6175 - val_loss: 47.4926\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6179 - val_loss: 47.4920\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6183 - val_loss: 47.4911\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6186 - val_loss: 47.4903\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6189 - val_loss: 47.4896\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6193 - val_loss: 47.4887\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6196 - val_loss: 47.4882\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6200 - val_loss: 47.4875\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 14.6203 - val_loss: 47.4868\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6206 - val_loss: 47.4858\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6209 - val_loss: 47.4851\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6213 - val_loss: 47.4843\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6216 - val_loss: 47.4836\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6219 - val_loss: 47.4830\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6222 - val_loss: 47.4824\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6225 - val_loss: 47.4815\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6228 - val_loss: 47.4807\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6231 - val_loss: 47.4799\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6234 - val_loss: 47.4792\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6237 - val_loss: 47.4783\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6240 - val_loss: 47.4780\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6243 - val_loss: 47.4772\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6246 - val_loss: 47.4764\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6249 - val_loss: 47.4760\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6252 - val_loss: 47.4754\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6254 - val_loss: 47.4746\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6257 - val_loss: 47.4740\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6260 - val_loss: 47.4734\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6263 - val_loss: 47.4728\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 14.6265 - val_loss: 47.4723\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6268 - val_loss: 47.4715\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6271 - val_loss: 47.4711\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6273 - val_loss: 47.4705\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6275 - val_loss: 47.4697\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6279 - val_loss: 47.4692\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.6281 - val_loss: 47.4685\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6283 - val_loss: 47.4679\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6286 - val_loss: 47.4676\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6288 - val_loss: 47.4672\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.6290 - val_loss: 47.4669\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6293 - val_loss: 47.4660\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6295 - val_loss: 47.4656\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6297 - val_loss: 47.4650\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6300 - val_loss: 47.4645\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6302 - val_loss: 47.4641\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6304 - val_loss: 47.4635\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6306 - val_loss: 47.4631\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.6308 - val_loss: 47.4625\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6310 - val_loss: 47.4622\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6312 - val_loss: 47.4616\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6315 - val_loss: 47.4612\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6316 - val_loss: 47.4606\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 14.6318 - val_loss: 47.4601\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.6320 - val_loss: 47.4596\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6323 - val_loss: 47.4591\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6324 - val_loss: 47.4586\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6326 - val_loss: 47.4580\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14.6328 - val_loss: 47.4574\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6330 - val_loss: 47.4571\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6332 - val_loss: 47.4567\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6334 - val_loss: 47.4564\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6335 - val_loss: 47.4556\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6337 - val_loss: 47.4554\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6339 - val_loss: 47.4550\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6341 - val_loss: 47.4547\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6342 - val_loss: 47.4543\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6344 - val_loss: 47.4538\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6346 - val_loss: 47.4536\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6347 - val_loss: 47.4534\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6349 - val_loss: 47.4531\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6350 - val_loss: 47.4524\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6352 - val_loss: 47.4520\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 14.6353 - val_loss: 47.4518\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6354 - val_loss: 47.4516\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6357 - val_loss: 47.4515\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6357 - val_loss: 47.4509\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6359 - val_loss: 47.4504\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6360 - val_loss: 47.4501\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6362 - val_loss: 47.4498\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6363 - val_loss: 47.4495\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6364 - val_loss: 47.4492\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6365 - val_loss: 47.4487\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.6367 - val_loss: 47.4486\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6368 - val_loss: 47.4481\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6370 - val_loss: 47.4478\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6371 - val_loss: 47.4476\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.6372 - val_loss: 47.4472\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.6373 - val_loss: 47.4469\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.1552, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0026, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0004, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0102, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.8734, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 414ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.82041783e+01, 6.81901727e+01, 6.81761671e+01, 6.81621615e+01,\n",
       "        6.81481559e+01, 6.81341503e+01, 6.81201447e+01, 6.81061391e+01,\n",
       "        6.80921335e+01, 6.80781279e+01, 6.80641223e+01, 6.80501167e+01,\n",
       "        6.80361111e+01, 6.80221055e+01, 6.80080999e+01, 6.79940943e+01,\n",
       "        6.79800887e+01, 6.79660831e+01, 6.79520775e+01, 6.79380719e+01,\n",
       "        6.79240663e+01, 6.79100607e+01, 6.78960551e+01, 6.78820495e+01,\n",
       "        6.78680439e+01, 6.78540383e+01, 6.78400327e+01, 6.78260271e+01,\n",
       "        6.78120215e+01, 6.77960317e+01, 6.77680205e+01, 6.77400093e+01,\n",
       "        6.77119981e+01, 6.76839869e+01, 6.76559757e+01, 6.76279645e+01,\n",
       "        6.75999533e+01, 6.75719421e+01, 6.75439309e+01, 6.75159197e+01,\n",
       "        6.74879085e+01, 6.74598973e+01, 6.74318861e+01, 6.74038749e+01,\n",
       "        6.73758637e+01, 6.73478525e+01, 6.73198413e+01, 6.72918301e+01,\n",
       "        6.72638189e+01, 6.72358077e+01, 6.72077965e+01, 6.71797852e+01,\n",
       "        6.71517740e+01, 6.71237628e+01, 6.70957516e+01, 6.70677404e+01,\n",
       "        6.70397292e+01, 6.70117180e+01, 6.69837068e+01, 6.69556956e+01,\n",
       "        6.69276844e+01, 6.68996732e+01, 6.68716620e+01, 6.68436508e+01,\n",
       "        6.68156396e+01, 6.67901027e+01, 6.67676937e+01, 6.67452848e+01,\n",
       "        6.67228758e+01, 6.67004668e+01, 6.66780579e+01, 6.66556489e+01,\n",
       "        6.66332400e+01, 6.66108310e+01, 6.65884220e+01, 6.65660131e+01,\n",
       "        6.65436041e+01, 6.65211951e+01, 6.64987862e+01, 6.64763772e+01,\n",
       "        7.45072708e+01, 0.00000000e+00, 0.00000000e+00, 9.37796474e-01,\n",
       "        4.27014828e-01, 0.00000000e+00, 4.91072565e-01, 3.46764952e-01,\n",
       "        1.08217075e-01, 0.00000000e+00, 1.63135916e-01, 5.74381828e-01,\n",
       "        0.00000000e+00, 1.79473370e-01, 3.96684676e-01, 5.44387817e-01,\n",
       "        0.00000000e+00, 6.10786796e-01, 5.28757274e-02, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([62.6717437 , 62.64513305, 62.61852241, 62.59191176, 62.56530112,\n",
       "       62.53869048, 62.51207983, 62.48546919, 62.45885854, 62.4322479 ,\n",
       "       62.40563725, 62.37902661, 62.35241597, 62.32580532, 62.29919468,\n",
       "       62.27258403, 62.24597339, 62.21936275, 62.1927521 , 62.16614146,\n",
       "       62.13953081, 62.11292017, 62.08630952, 62.05969888, 62.03308824,\n",
       "       62.00647759, 61.97986695, 61.9532563 , 61.92664566, 61.90003501,\n",
       "       61.87342437, 61.84681373, 61.82020308, 61.79359244, 61.76698179,\n",
       "       61.74037115, 61.7137605 , 61.68714986, 61.66053922, 61.63392857,\n",
       "       61.60731793, 61.58070728, 61.55409664, 61.52748599, 61.50087535,\n",
       "       61.47426471, 61.44765406, 61.42104342, 61.39443277, 61.36782213,\n",
       "       61.34121148, 61.31460084, 61.2879902 , 61.26137955, 61.23476891,\n",
       "       61.20815826, 61.18154762, 61.15493697, 61.12832633, 61.10171569,\n",
       "       61.07510504, 61.0484944 , 61.02188375, 60.99527311, 60.96866246,\n",
       "       60.94205182, 60.91544118, 60.88883053, 60.86221989, 60.83560924,\n",
       "       60.8089986 , 60.78238796, 60.75577731, 60.72916667, 60.70255602,\n",
       "       60.67594538, 60.64933473, 60.62272409, 60.59611345, 60.5695028 ,\n",
       "       60.54289216, 60.51628151, 60.48967087, 60.46306022, 60.43644958,\n",
       "       60.40983894, 60.38322829, 60.35661765, 60.330007  , 60.30339636,\n",
       "       60.27678571, 60.25017507, 60.22356443, 60.19695378, 60.17034314,\n",
       "       60.14373249, 60.11712185, 60.0905112 , 60.06390056, 60.03728992])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.711911174723742\n",
      "16.194844360375892\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
