{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "2445    52.941156\n",
       "2446    52.925579\n",
       "2447    52.910002\n",
       "2448    52.894425\n",
       "2449    52.878848\n",
       "Name: C2, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c2_interpolated_2350_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       90.500000\n",
       "1       90.275910\n",
       "2       90.051821\n",
       "3       89.827731\n",
       "4       89.603641\n",
       "          ...    \n",
       "2345     0.205871\n",
       "2346     0.323240\n",
       "2347     0.000000\n",
       "2348     0.232633\n",
       "2349     0.000000\n",
       "Name: C2, Length: 2350, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2350)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.500000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.275910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.051821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.827731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.603641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     90.500000  0.000298\n",
       "1     90.275910  0.000298\n",
       "2     90.051821  0.000297\n",
       "3     89.827731  0.000297\n",
       "4     89.603641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.1552  # Value for C0\n",
    "K0 = -0.0026  # Value for K0\n",
    "K1 = -0.0004  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0102    # Value for b\n",
    "c = 2.8734    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    90.500000    90.275910    90.051821    89.827731    89.603641   \n",
      "351    90.275910    90.051821    89.827731    89.603641    89.379552   \n",
      "352    90.051821    89.827731    89.603641    89.379552    89.155462   \n",
      "353    89.827731    89.603641    89.379552    89.155462    88.931373   \n",
      "354    89.603641    89.379552    89.155462    88.931373    88.707283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.379552    89.155462    88.931373    88.707283    88.494958  ...   \n",
      "351    89.155462    88.931373    88.707283    88.494958    88.427731  ...   \n",
      "352    88.931373    88.707283    88.494958    88.427731    88.360504  ...   \n",
      "353    88.707283    88.494958    88.427731    88.360504    88.293277  ...   \n",
      "354    88.494958    88.427731    88.360504    88.293277    88.226050  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.071008    0.000263   79.054202    0.000263   79.037395    0.000263   \n",
      "351   79.054202    0.000263   79.037395    0.000263   79.020588    0.000262   \n",
      "352   79.037395    0.000263   79.020588    0.000262   79.003782    0.000262   \n",
      "353   79.020588    0.000262   79.003782    0.000262   78.986975    0.000262   \n",
      "354   79.003782    0.000262   78.986975    0.000262   78.970168    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.020588    0.000262   79.003782    0.000262  \n",
      "351   79.003782    0.000262   78.986975    0.000262  \n",
      "352   78.986975    0.000262   78.970168    0.000262  \n",
      "353   78.970168    0.000262   78.953361    0.000262  \n",
      "354   78.953361    0.000262   78.936555    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 1, 251) (1900, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 2s 21ms/step - loss: 5212.6460 - val_loss: 3544.8105\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 5107.0903 - val_loss: 3487.5840\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5028.4746 - val_loss: 3439.3606\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4944.5815 - val_loss: 3380.1609\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4854.8945 - val_loss: 3330.1421\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4774.8330 - val_loss: 3281.3384\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4696.4365 - val_loss: 3233.5315\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4619.3926 - val_loss: 3186.5637\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 4543.5249 - val_loss: 3140.3545\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4468.7393 - val_loss: 3094.8579\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4394.9795 - val_loss: 3050.0435\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4322.2061 - val_loss: 3005.8889\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4250.3916 - val_loss: 2962.3782\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4179.5146 - val_loss: 2919.4980\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4109.5542 - val_loss: 2877.2361\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4040.4961 - val_loss: 2835.5830\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3972.3259 - val_loss: 2794.5300\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3905.0315 - val_loss: 2754.0684\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3838.6013 - val_loss: 2714.1904\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3773.0254 - val_loss: 2674.8892\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3708.2908 - val_loss: 2636.1580\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3644.3904 - val_loss: 2597.9895\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3581.3137 - val_loss: 2560.3779\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3519.0532 - val_loss: 2523.3171\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3457.5994 - val_loss: 2486.8013\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3396.9438 - val_loss: 2450.8250\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3337.0784 - val_loss: 2415.3813\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3277.9954 - val_loss: 2380.4658\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3219.6868 - val_loss: 2346.0730\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3162.1450 - val_loss: 2312.1980\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3105.3628 - val_loss: 2278.8345\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3049.3335 - val_loss: 2245.9780\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2994.0486 - val_loss: 2213.6228\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2939.5012 - val_loss: 2181.7654\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2885.6853 - val_loss: 2150.3992\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2832.5918 - val_loss: 2119.5200\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2780.2166 - val_loss: 2089.1235\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2728.5508 - val_loss: 2059.2043\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2677.5884 - val_loss: 2029.7576\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2627.3232 - val_loss: 2000.7791\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2577.7488 - val_loss: 1972.2642\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2528.8582 - val_loss: 1944.2084\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2480.6453 - val_loss: 1916.6069\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2433.1033 - val_loss: 1889.4558\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2386.2273 - val_loss: 1862.7501\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2340.0093 - val_loss: 1836.4858\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2294.4453 - val_loss: 1810.6587\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2249.5276 - val_loss: 1785.2637\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2205.2505 - val_loss: 1760.2970\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2161.6077 - val_loss: 1735.7544\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 2118.5945 - val_loss: 1711.6321\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2076.2041 - val_loss: 1687.9252\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2034.4313 - val_loss: 1664.6304\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1993.2698 - val_loss: 1641.7428\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1952.7148 - val_loss: 1619.2589\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1912.7594 - val_loss: 1597.1742\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1873.3988 - val_loss: 1575.4849\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1834.6266 - val_loss: 1554.1869\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1796.4385 - val_loss: 1533.2766\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1758.8281 - val_loss: 1512.7499\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1721.7908 - val_loss: 1492.6029\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1685.3206 - val_loss: 1472.8313\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1649.4114 - val_loss: 1453.4318\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1614.0588 - val_loss: 1434.4000\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1579.2574 - val_loss: 1415.7328\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1545.0024 - val_loss: 1397.4260\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1511.2882 - val_loss: 1379.4757\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1478.1089 - val_loss: 1361.8783\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1445.4602 - val_loss: 1344.6304\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1413.3368 - val_loss: 1327.7283\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1381.7338 - val_loss: 1311.1676\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1350.6455 - val_loss: 1294.9449\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1320.0676 - val_loss: 1279.0569\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1289.9944 - val_loss: 1263.4996\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1260.4213 - val_loss: 1248.2698\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1231.3431 - val_loss: 1233.3635\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1202.7554 - val_loss: 1218.7776\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1174.6536 - val_loss: 1204.5077\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1147.0311 - val_loss: 1190.5508\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1119.8846 - val_loss: 1176.9034\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1093.2089 - val_loss: 1163.5619\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1066.9989 - val_loss: 1150.5225\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1041.2500 - val_loss: 1137.7817\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1015.9574 - val_loss: 1125.3365\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 991.1169 - val_loss: 1113.1836\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 966.7228 - val_loss: 1101.3182\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 942.7706 - val_loss: 1089.7380\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 919.2561 - val_loss: 1078.4393\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 896.1747 - val_loss: 1067.4187\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 873.5214 - val_loss: 1056.6727\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 851.2916 - val_loss: 1046.1979\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 829.4811 - val_loss: 1035.9908\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 808.0848 - val_loss: 1026.0480\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 787.0980 - val_loss: 1016.3664\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 766.5166 - val_loss: 1006.9420\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 746.3359 - val_loss: 997.7720\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 726.5513 - val_loss: 988.8532\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 707.1586 - val_loss: 980.1818\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 688.1525 - val_loss: 971.7542\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 669.5293 - val_loss: 963.5674\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 651.2838 - val_loss: 955.6183\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 633.4122 - val_loss: 947.9030\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 615.9094 - val_loss: 940.4186\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 598.7719 - val_loss: 933.1617\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 581.9944 - val_loss: 926.1290\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 565.5731 - val_loss: 919.3170\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 549.5028 - val_loss: 912.7227\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 533.7799 - val_loss: 906.3424\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 518.3998 - val_loss: 900.1733\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 503.3577 - val_loss: 894.2119\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 488.6494 - val_loss: 888.4543\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 474.2708 - val_loss: 882.8985\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 460.2175 - val_loss: 877.5402\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 446.4850 - val_loss: 872.3764\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 433.0690 - val_loss: 867.4037\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 419.9648 - val_loss: 862.6193\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 407.1691 - val_loss: 858.0199\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 394.6767 - val_loss: 853.6016\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 382.4833 - val_loss: 849.3618\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 370.5854 - val_loss: 845.2971\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 358.9780 - val_loss: 841.4041\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 347.6571 - val_loss: 837.6799\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 336.6187 - val_loss: 834.1210\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 325.8583 - val_loss: 830.7245\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 315.3716 - val_loss: 827.4868\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 305.1540 - val_loss: 824.4050\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 295.2018 - val_loss: 821.4756\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 285.5108 - val_loss: 818.6960\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 276.0768 - val_loss: 816.0624\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 266.8953 - val_loss: 813.5722\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 257.9625 - val_loss: 811.2217\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 249.2742 - val_loss: 809.0081\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 240.8260 - val_loss: 806.9281\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 232.6141 - val_loss: 804.9789\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 224.6342 - val_loss: 803.1570\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 216.8824 - val_loss: 801.4594\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 209.3540 - val_loss: 799.8831\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 202.0457 - val_loss: 798.4251\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 194.9532 - val_loss: 797.0822\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 188.0721 - val_loss: 795.8511\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 181.3986 - val_loss: 794.7294\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 174.9287 - val_loss: 793.7136\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 168.6587 - val_loss: 792.8008\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 162.5843 - val_loss: 791.9880\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 156.7016 - val_loss: 791.2723\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 151.0067 - val_loss: 790.6508\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 145.4956 - val_loss: 790.1204\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 140.1646 - val_loss: 789.6783\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 135.0096 - val_loss: 789.3217\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 130.0271 - val_loss: 789.0474\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 125.2131 - val_loss: 788.8529\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 120.5638 - val_loss: 788.7352\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.0756 - val_loss: 788.6915\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 111.7442 - val_loss: 788.7192\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 107.5663 - val_loss: 788.8153\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 103.5385 - val_loss: 788.9773\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 99.6566 - val_loss: 789.2021\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 95.9174 - val_loss: 789.4877\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 92.3170 - val_loss: 789.8308\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 88.8520 - val_loss: 790.2292\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 85.5190 - val_loss: 790.6802\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 82.3143 - val_loss: 791.1814\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 79.2344 - val_loss: 791.7303\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 76.2760 - val_loss: 792.3242\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 73.4356 - val_loss: 792.9606\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 70.7103 - val_loss: 793.6375\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 68.0963 - val_loss: 794.3523\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 65.5907 - val_loss: 795.1027\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 63.1901 - val_loss: 795.8864\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 60.8915 - val_loss: 796.7012\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 58.6918 - val_loss: 797.5450\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 56.5874 - val_loss: 798.4156\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 54.5758 - val_loss: 799.3107\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 52.6538 - val_loss: 800.2285\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 50.8185 - val_loss: 801.1667\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 49.0671 - val_loss: 802.1238\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 47.3968 - val_loss: 803.0973\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 45.8045 - val_loss: 804.0858\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 44.2878 - val_loss: 805.0873\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 42.8437 - val_loss: 806.1000\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 41.4698 - val_loss: 807.1219\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 40.1636 - val_loss: 808.1520\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 38.9221 - val_loss: 809.1882\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 37.7434 - val_loss: 810.2288\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 36.6248 - val_loss: 811.2727\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 35.5638 - val_loss: 812.3180\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 34.5585 - val_loss: 813.3638\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 33.6062 - val_loss: 814.4083\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 32.7049 - val_loss: 815.4505\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 31.8525 - val_loss: 816.4886\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 31.0470 - val_loss: 817.5220\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 30.2861 - val_loss: 818.5495\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 29.5680 - val_loss: 819.5695\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 28.8908 - val_loss: 820.5815\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 28.2526 - val_loss: 821.5842\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 27.6515 - val_loss: 822.5768\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 27.0859 - val_loss: 823.5585\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 26.5541 - val_loss: 824.5281\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 26.0544 - val_loss: 825.4852\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.5852 - val_loss: 826.4293\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.1449 - val_loss: 827.3589\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 24.7323 - val_loss: 828.2742\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 24.3456 - val_loss: 829.1740\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.9838 - val_loss: 830.0580\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.6454 - val_loss: 830.9258\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 23.3291 - val_loss: 831.7768\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.0339 - val_loss: 832.6108\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 22.7583 - val_loss: 833.4275\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 22.5014 - val_loss: 834.2263\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 22.2621 - val_loss: 835.0069\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 22.0394 - val_loss: 835.7696\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 21.8323 - val_loss: 836.5137\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 21.6398 - val_loss: 837.2393\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 21.4610 - val_loss: 837.9459\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 21.2953 - val_loss: 838.6340\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 21.1416 - val_loss: 839.3035\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.9993 - val_loss: 839.9542\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.8674 - val_loss: 840.5860\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.7456 - val_loss: 841.1990\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.6331 - val_loss: 841.7939\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 20.5291 - val_loss: 842.3700\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.4332 - val_loss: 842.9278\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3448 - val_loss: 843.4675\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.2634 - val_loss: 843.9891\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.1885 - val_loss: 844.4929\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.1197 - val_loss: 844.9792\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.0564 - val_loss: 845.4485\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.9983 - val_loss: 845.9004\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.9450 - val_loss: 846.3359\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.8961 - val_loss: 846.7548\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.8514 - val_loss: 847.1580\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.8104 - val_loss: 847.5448\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.7730 - val_loss: 847.9165\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.7388 - val_loss: 848.2731\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.7075 - val_loss: 848.6150\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.6789 - val_loss: 848.9422\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.6529 - val_loss: 849.2556\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.6292 - val_loss: 849.5552\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.6077 - val_loss: 849.8421\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.5880 - val_loss: 850.1157\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.5701 - val_loss: 850.3767\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.5539 - val_loss: 850.6257\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.5392 - val_loss: 850.8632\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.5258 - val_loss: 851.0890\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.5137 - val_loss: 851.3040\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.5027 - val_loss: 851.5083\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4928 - val_loss: 851.7026\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 19.4838 - val_loss: 851.8868\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4757 - val_loss: 852.0615\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4683 - val_loss: 852.2272\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4617 - val_loss: 852.3839\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4558 - val_loss: 852.5322\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4505 - val_loss: 852.6727\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4456 - val_loss: 852.8052\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4413 - val_loss: 852.9304\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4374 - val_loss: 853.0483\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4340 - val_loss: 853.1594\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4310 - val_loss: 853.2645\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4282 - val_loss: 853.3630\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4258 - val_loss: 853.4558\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4236 - val_loss: 853.5428\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4217 - val_loss: 853.6243\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4200 - val_loss: 853.7009\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4186 - val_loss: 853.7727\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4174 - val_loss: 853.8400\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4163 - val_loss: 853.9027\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4153 - val_loss: 853.9614\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4145 - val_loss: 854.0161\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4139 - val_loss: 854.0671\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4135 - val_loss: 854.1148\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4130 - val_loss: 854.1591\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4128 - val_loss: 854.2003\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 19.4126 - val_loss: 854.2388\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4124 - val_loss: 854.2744\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4124 - val_loss: 854.3075\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4124 - val_loss: 854.3380\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4126 - val_loss: 854.3662\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4127 - val_loss: 854.3925\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4130 - val_loss: 854.4165\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4132 - val_loss: 854.4387\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4136 - val_loss: 854.4593\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4139 - val_loss: 854.4780\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4143 - val_loss: 854.4954\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4147 - val_loss: 854.5114\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4152 - val_loss: 854.5258\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4157 - val_loss: 854.5390\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4162 - val_loss: 854.5508\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4168 - val_loss: 854.5618\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4173 - val_loss: 854.5715\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4179 - val_loss: 854.5804\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4185 - val_loss: 854.5886\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4191 - val_loss: 854.5959\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4198 - val_loss: 854.6024\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4205 - val_loss: 854.6082\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4211 - val_loss: 854.6136\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4218 - val_loss: 854.6182\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 19.4225 - val_loss: 854.6222\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4232 - val_loss: 854.6260\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4239 - val_loss: 854.6290\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4246 - val_loss: 854.6317\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4253 - val_loss: 854.6340\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4260 - val_loss: 854.6361\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4267 - val_loss: 854.6378\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4274 - val_loss: 854.6390\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4282 - val_loss: 854.6401\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4289 - val_loss: 854.6409\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4296 - val_loss: 854.6417\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4303 - val_loss: 854.6420\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4311 - val_loss: 854.6420\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4318 - val_loss: 854.6420\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4325 - val_loss: 854.6420\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4332 - val_loss: 854.6417\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4340 - val_loss: 854.6413\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4346 - val_loss: 854.6409\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4353 - val_loss: 854.6401\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4360 - val_loss: 854.6392\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4368 - val_loss: 854.6381\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4374 - val_loss: 854.6373\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 19.4381 - val_loss: 854.6363\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4388 - val_loss: 854.6354\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4395 - val_loss: 854.6342\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 19.4402 - val_loss: 854.6330\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4409 - val_loss: 854.6321\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4415 - val_loss: 854.6305\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4422 - val_loss: 854.6293\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4428 - val_loss: 854.6283\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4434 - val_loss: 854.6269\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4441 - val_loss: 854.6252\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4447 - val_loss: 854.6240\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4453 - val_loss: 854.6227\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4460 - val_loss: 854.6215\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4466 - val_loss: 854.6199\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4472 - val_loss: 854.6188\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4478 - val_loss: 854.6176\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4483 - val_loss: 854.6162\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4489 - val_loss: 854.6150\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4495 - val_loss: 854.6135\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4501 - val_loss: 854.6124\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4506 - val_loss: 854.6108\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4512 - val_loss: 854.6094\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 19.4517 - val_loss: 854.6082\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 19.4523 - val_loss: 854.6071\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4528 - val_loss: 854.6058\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4533 - val_loss: 854.6047\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4538 - val_loss: 854.6033\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 19.4543 - val_loss: 854.6021\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4548 - val_loss: 854.6010\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4553 - val_loss: 854.5999\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4558 - val_loss: 854.5985\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4563 - val_loss: 854.5975\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4567 - val_loss: 854.5962\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4572 - val_loss: 854.5948\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 19.4577 - val_loss: 854.5938\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4581 - val_loss: 854.5924\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4585 - val_loss: 854.5912\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4590 - val_loss: 854.5903\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4594 - val_loss: 854.5890\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4598 - val_loss: 854.5881\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4602 - val_loss: 854.5869\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4607 - val_loss: 854.5857\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4610 - val_loss: 854.5848\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4614 - val_loss: 854.5837\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4618 - val_loss: 854.5828\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4622 - val_loss: 854.5818\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4626 - val_loss: 854.5811\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4629 - val_loss: 854.5802\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4633 - val_loss: 854.5793\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4636 - val_loss: 854.5786\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 19.4639 - val_loss: 854.5774\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4643 - val_loss: 854.5765\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4647 - val_loss: 854.5757\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4649 - val_loss: 854.5746\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4653 - val_loss: 854.5737\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4656 - val_loss: 854.5730\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4659 - val_loss: 854.5718\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 19.4662 - val_loss: 854.5710\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4666 - val_loss: 854.5704\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 19.4668 - val_loss: 854.5696\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 19.4671 - val_loss: 854.5687\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4674 - val_loss: 854.5679\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4676 - val_loss: 854.5673\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4679 - val_loss: 854.5665\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4682 - val_loss: 854.5656\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4684 - val_loss: 854.5648\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4687 - val_loss: 854.5638\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4689 - val_loss: 854.5633\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4692 - val_loss: 854.5621\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4695 - val_loss: 854.5618\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4696 - val_loss: 854.5611\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4699 - val_loss: 854.5602\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4701 - val_loss: 854.5597\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4703 - val_loss: 854.5592\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4705 - val_loss: 854.5582\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4708 - val_loss: 854.5577\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4710 - val_loss: 854.5573\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4712 - val_loss: 854.5568\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4714 - val_loss: 854.5563\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4716 - val_loss: 854.5557\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 19.4718 - val_loss: 854.5554\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 19.4719 - val_loss: 854.5547\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 19.4721 - val_loss: 854.5538\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 19.4723 - val_loss: 854.5535\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 19.4725 - val_loss: 854.5530\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 19.4727 - val_loss: 854.5524\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4728 - val_loss: 854.5519\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4730 - val_loss: 854.5513\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4731 - val_loss: 854.5511\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4733 - val_loss: 854.5505\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4734 - val_loss: 854.5500\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4736 - val_loss: 854.5493\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4738 - val_loss: 854.5490\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4739 - val_loss: 854.5487\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4740 - val_loss: 854.5483\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4742 - val_loss: 854.5479\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4743 - val_loss: 854.5472\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4744 - val_loss: 854.5466\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4746 - val_loss: 854.5462\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4747 - val_loss: 854.5459\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 19.4748 - val_loss: 854.5454\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4749 - val_loss: 854.5449\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4751 - val_loss: 854.5444\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4752 - val_loss: 854.5441\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4753 - val_loss: 854.5436\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4754 - val_loss: 854.5431\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4755 - val_loss: 854.5427\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4756 - val_loss: 854.5423\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4758 - val_loss: 854.5419\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4759 - val_loss: 854.5417\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4759 - val_loss: 854.5414\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4760 - val_loss: 854.5412\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4761 - val_loss: 854.5406\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 19.4762 - val_loss: 854.5403\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4763 - val_loss: 854.5398\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4764 - val_loss: 854.5394\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4765 - val_loss: 854.5390\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4766 - val_loss: 854.5388\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 19.4766 - val_loss: 854.5383\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4767 - val_loss: 854.5380\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4768 - val_loss: 854.5376\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 19.4769 - val_loss: 854.5372\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4770 - val_loss: 854.5370\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4770 - val_loss: 854.5364\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4771 - val_loss: 854.5362\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4772 - val_loss: 854.5358\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4772 - val_loss: 854.5357\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4772 - val_loss: 854.5351\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4773 - val_loss: 854.5345\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 19.4774 - val_loss: 854.5343\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4775 - val_loss: 854.5342\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4776 - val_loss: 854.5341\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4776 - val_loss: 854.5337\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4777 - val_loss: 854.5334\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 19.4778 - val_loss: 854.5331\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4778 - val_loss: 854.5329\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4779 - val_loss: 854.5327\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4779 - val_loss: 854.5326\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4779 - val_loss: 854.5324\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 19.4780 - val_loss: 854.5322\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 19.4780 - val_loss: 854.5317\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 19.4781 - val_loss: 854.5315\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 19.4782 - val_loss: 854.5314\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4782 - val_loss: 854.5312\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4782 - val_loss: 854.5312\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4783 - val_loss: 854.5309\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4783 - val_loss: 854.5307\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4784 - val_loss: 854.5305\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4784 - val_loss: 854.5303\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4785 - val_loss: 854.5301\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 19.4784 - val_loss: 854.5294\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4786 - val_loss: 854.5295\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4786 - val_loss: 854.5292\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4786 - val_loss: 854.5289\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4786 - val_loss: 854.5286\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4787 - val_loss: 854.5282\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4787 - val_loss: 854.5280\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4787 - val_loss: 854.5277\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4788 - val_loss: 854.5276\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4788 - val_loss: 854.5275\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4788 - val_loss: 854.5273\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 19.4788 - val_loss: 854.5270\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4789 - val_loss: 854.5267\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4789 - val_loss: 854.5265\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4790 - val_loss: 854.5263\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4789 - val_loss: 854.5259\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4790 - val_loss: 854.5254\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4791 - val_loss: 854.5253\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4790 - val_loss: 854.5251\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4791 - val_loss: 854.5248\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4791 - val_loss: 854.5247\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4791 - val_loss: 854.5245\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 19.4791 - val_loss: 854.5242\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4792 - val_loss: 854.5240\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 19.4792 - val_loss: 854.5239\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 19.4792 - val_loss: 854.5236\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4792 - val_loss: 854.5232\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 19.4793 - val_loss: 854.5229\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4793 - val_loss: 854.5228\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4793 - val_loss: 854.5225\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.4794 - val_loss: 854.5223\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 19.4794 - val_loss: 854.5222\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.1552, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0026, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0004, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0102, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.8734, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 430ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.78166900e+01, 6.77493464e+01, 6.76653128e+01, 6.75812792e+01,\n",
       "        6.74972456e+01, 6.74132120e+01, 6.73291783e+01, 0.00000000e+00,\n",
       "        8.63967690e-02, 0.00000000e+00, 8.28129411e-01, 2.15592802e-01,\n",
       "        0.00000000e+00, 6.82041783e+01, 6.81621615e+01, 6.81201447e+01,\n",
       "        6.80781279e+01, 6.80361111e+01, 6.79940943e+01, 6.79520775e+01,\n",
       "        6.79100607e+01, 6.78680439e+01, 6.78260271e+01, 6.77802805e+01,\n",
       "        6.77200190e+01, 6.76600442e+01, 6.76000688e+01, 6.75400934e+01,\n",
       "        6.74801180e+01, 6.74201426e+01, 6.73601672e+01, 6.73001918e+01,\n",
       "        6.72402164e+01, 6.71802410e+01, 6.71202656e+01, 6.70602902e+01,\n",
       "        6.70003148e+01, 6.69403394e+01, 6.68803640e+01, 6.68203886e+01,\n",
       "        6.67604132e+01, 0.00000000e+00, 4.27014828e-01, 3.46764952e-01,\n",
       "        1.63135916e-01, 1.79473370e-01, 0.00000000e+00, 6.76186275e+01,\n",
       "        6.75345938e+01, 6.74505602e+01, 6.73665266e+01, 6.72824930e+01,\n",
       "        6.71984594e+01, 6.71144258e+01, 6.70303922e+01, 6.69463585e+01,\n",
       "        6.68623249e+01, 6.67826331e+01, 6.67154062e+01, 6.66481793e+01,\n",
       "        6.65809524e+01, 6.65137255e+01, 7.03338235e+01, 7.01573529e+01,\n",
       "        6.99818824e+01, 6.96815126e+01, 6.92781513e+01, 6.88747899e+01,\n",
       "        6.84714286e+01, 6.82275210e+01, 6.81014706e+01, 1.93370014e-01,\n",
       "        3.61841950e-02, 6.70672073e+01, 3.18134546e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.63562191e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.02764244e+01, 7.83210099e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.37593853e-01, 2.37655729e-01, 0.00000000e+00,\n",
       "        3.82995367e-01, 2.88465977e-01, 0.00000000e+00, 2.76154373e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.88551557e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.36976424e-02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54.42096741, 54.40539045, 54.38981349, 54.37423652, 54.35865956,\n",
       "       54.3430826 , 54.32750564, 54.31192867, 54.29635171, 54.28077475,\n",
       "       54.26519779, 54.24962082, 54.23404386, 54.2184669 , 54.20288994,\n",
       "       54.18731297, 54.17173601, 54.15615905, 54.14058209, 54.12500512,\n",
       "       54.10942816, 54.0938512 , 54.07827424, 54.06269727, 54.04712031,\n",
       "       54.03154335, 54.01596639, 54.00038942, 53.98481246, 53.9692355 ,\n",
       "       53.95365854, 53.93808157, 53.92250461, 53.90692765, 53.89135069,\n",
       "       53.87577372, 53.86019676, 53.8446198 , 53.82904284, 53.81346587,\n",
       "       53.79788891, 53.78231195, 53.76673499, 53.75115802, 53.73558106,\n",
       "       53.7200041 , 53.70442714, 53.68885017, 53.67327321, 53.65769625,\n",
       "       53.64211929, 53.62654232, 53.61096536, 53.5953884 , 53.57981144,\n",
       "       53.56423447, 53.54865751, 53.53308055, 53.51750359, 53.50192662,\n",
       "       53.48634966, 53.4707727 , 53.45519574, 53.43961877, 53.42404181,\n",
       "       53.40846485, 53.39288789, 53.37731092, 53.36173396, 53.346157  ,\n",
       "       53.33058004, 53.31500307, 53.29942611, 53.28384915, 53.26827219,\n",
       "       53.25269522, 53.23711826, 53.2215413 , 53.20596434, 53.19038737,\n",
       "       53.17481041, 53.15923345, 53.14365649, 53.12807952, 53.11250256,\n",
       "       53.0969256 , 53.08134864, 53.06577167, 53.05019471, 53.03461775,\n",
       "       53.01904079, 53.00346382, 52.98788686, 52.9723099 , 52.95673294,\n",
       "       52.94115597, 52.92557901, 52.91000205, 52.89442509, 52.87884812])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.93983860015028\n",
      "29.087384479151382\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
