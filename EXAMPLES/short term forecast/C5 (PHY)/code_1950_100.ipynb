{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2045    63.116772\n",
       "2046    63.109769\n",
       "2047    63.102766\n",
       "2048    63.095763\n",
       "2049    63.088760\n",
       "Name: C5, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_1950_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "1945     0.000000\n",
       "1946     0.000000\n",
       "1947     0.000000\n",
       "1948     0.789334\n",
       "1949     0.114160\n",
       "Name: C5, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1950)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1, 251) (1500, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 3s 26ms/step - loss: 5267.9365 - val_loss: 4189.2515\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5216.8716 - val_loss: 4149.8169\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5172.9165 - val_loss: 4110.5527\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5129.1616 - val_loss: 4071.5129\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5085.6445 - val_loss: 4032.7134\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5042.3779 - val_loss: 3994.1609\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4999.3691 - val_loss: 3955.8604\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 4956.6221 - val_loss: 3917.8149\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4914.1392 - val_loss: 3880.0254\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4871.9204 - val_loss: 3842.4907\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4829.9663 - val_loss: 3805.2124\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4788.2759 - val_loss: 3768.1892\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4746.8511 - val_loss: 3731.4197\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4705.6875 - val_loss: 3694.9038\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4664.7861 - val_loss: 3658.6399\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4624.1450 - val_loss: 3622.6284\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4583.7651 - val_loss: 3586.8657\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4543.6436 - val_loss: 3551.3521\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4503.7783 - val_loss: 3516.0867\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4464.1709 - val_loss: 3481.0686\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4424.8174 - val_loss: 3446.2947\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4385.7183 - val_loss: 3411.7661\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4346.8716 - val_loss: 3377.4795\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4308.2769 - val_loss: 3343.4353\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4269.9312 - val_loss: 3309.6313\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4231.8359 - val_loss: 3276.0667\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4193.9863 - val_loss: 3242.7395\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4156.3843 - val_loss: 3209.6499\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4119.0264 - val_loss: 3176.7959\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4081.9128 - val_loss: 3144.1760\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4045.0417 - val_loss: 3111.7893\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 4008.4121 - val_loss: 3079.6345\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3972.0225 - val_loss: 3047.7109\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3935.8708 - val_loss: 3016.0159\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3899.9580 - val_loss: 2984.5505\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3864.2812 - val_loss: 2953.3115\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3828.8403 - val_loss: 2922.2988\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3793.6328 - val_loss: 2891.5107\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3758.6592 - val_loss: 2860.9468\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3723.9158 - val_loss: 2830.6050\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3689.4033 - val_loss: 2800.4841\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3655.1201 - val_loss: 2770.5842\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3621.0649 - val_loss: 2740.9033\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3587.2375 - val_loss: 2711.4404\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3553.6357 - val_loss: 2682.1943\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3519.8809 - val_loss: 2643.7983\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3473.0066 - val_loss: 2608.1946\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3432.3660 - val_loss: 2573.5090\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3393.3203 - val_loss: 2540.2405\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3355.6418 - val_loss: 2507.9724\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3318.9377 - val_loss: 2476.4504\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3282.9790 - val_loss: 2445.5298\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3247.6326 - val_loss: 2415.1201\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3212.8130 - val_loss: 2385.1614\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3178.4614 - val_loss: 2355.6113\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3144.5361 - val_loss: 2326.4380\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3111.0044 - val_loss: 2297.6184\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3077.8433 - val_loss: 2269.1328\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3045.0327 - val_loss: 2240.9651\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3012.5559 - val_loss: 2213.1038\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2979.2173 - val_loss: 2177.3054\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2935.4243 - val_loss: 2143.1343\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2896.2568 - val_loss: 2110.3040\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2858.8577 - val_loss: 2078.9141\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2822.8630 - val_loss: 2048.5515\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2787.8875 - val_loss: 2018.9702\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2753.7068 - val_loss: 1990.0286\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2720.1870 - val_loss: 1961.6365\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2687.2397 - val_loss: 1933.7321\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2654.8057 - val_loss: 1906.2712\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2622.8389 - val_loss: 1879.2208\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2591.3062 - val_loss: 1852.5552\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2560.1804 - val_loss: 1826.2538\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2529.4387 - val_loss: 1800.2981\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2499.0647 - val_loss: 1774.6731\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2469.0410 - val_loss: 1749.3688\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2439.3557 - val_loss: 1724.3727\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2409.9978 - val_loss: 1699.6758\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2380.9561 - val_loss: 1675.2704\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2352.2227 - val_loss: 1651.1489\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2323.7893 - val_loss: 1627.3035\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2295.6489 - val_loss: 1603.7302\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2267.7949 - val_loss: 1580.4219\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2240.2222 - val_loss: 1557.3739\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2212.9241 - val_loss: 1534.5823\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2185.8970 - val_loss: 1512.0422\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2159.1355 - val_loss: 1489.7504\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2132.6350 - val_loss: 1467.7015\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2106.3926 - val_loss: 1445.8936\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2080.4033 - val_loss: 1424.3226\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2054.6653 - val_loss: 1402.9849\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2029.1733 - val_loss: 1381.8796\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2003.9257 - val_loss: 1361.0018\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1978.9189 - val_loss: 1340.3494\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1954.1498 - val_loss: 1319.9208\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1929.6162 - val_loss: 1299.7123\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1905.3149 - val_loss: 1279.7217\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1881.2440 - val_loss: 1259.9471\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1857.4006 - val_loss: 1240.3864\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1833.7830 - val_loss: 1221.0374\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1810.3883 - val_loss: 1201.8984\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1787.2156 - val_loss: 1182.9670\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1764.2621 - val_loss: 1164.2412\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1741.5254 - val_loss: 1145.7196\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1719.0043 - val_loss: 1127.4005\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1696.6962 - val_loss: 1109.2816\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1674.6002 - val_loss: 1091.3619\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1652.7140 - val_loss: 1073.6392\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1631.0360 - val_loss: 1056.1119\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1609.5643 - val_loss: 1038.7786\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1588.2972 - val_loss: 1021.6382\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1567.2339 - val_loss: 1004.6885\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1546.3721 - val_loss: 987.9283\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1525.7106 - val_loss: 971.3561\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1505.2476 - val_loss: 954.9706\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1484.9822 - val_loss: 938.7704\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1464.9126 - val_loss: 922.7538\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1445.0375 - val_loss: 906.9204\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1425.3552 - val_loss: 891.2681\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1405.8647 - val_loss: 875.7952\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1386.5652 - val_loss: 860.5015\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1367.4542 - val_loss: 845.3847\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1348.5310 - val_loss: 830.4443\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1329.7947 - val_loss: 815.6786\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1311.2434 - val_loss: 801.0872\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1292.8768 - val_loss: 786.6678\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1274.6926 - val_loss: 772.4202\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1256.6906 - val_loss: 758.3430\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1238.8688 - val_loss: 744.4338\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1221.2263 - val_loss: 730.6934\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1203.7625 - val_loss: 717.1190\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1186.4750 - val_loss: 703.7106\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1169.3636 - val_loss: 690.4664\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1152.4274 - val_loss: 677.3862\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1135.6649 - val_loss: 664.4687\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1119.0752 - val_loss: 651.7108\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1102.6570 - val_loss: 639.1146\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1086.4094 - val_loss: 626.6771\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1070.3314 - val_loss: 614.3972\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1054.4213 - val_loss: 602.2745\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1038.6786 - val_loss: 590.3082\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1023.1019 - val_loss: 578.4955\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1007.6909 - val_loss: 566.8375\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 992.4440 - val_loss: 555.3322\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 977.3602 - val_loss: 543.9785\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 962.4385 - val_loss: 532.7759\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 947.6785 - val_loss: 521.7234\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 933.0787 - val_loss: 510.8193\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 918.6380 - val_loss: 500.0629\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 904.3557 - val_loss: 489.4534\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 890.2307 - val_loss: 478.9898\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 876.2621 - val_loss: 468.6711\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 862.4491 - val_loss: 458.4960\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 848.7904 - val_loss: 448.4640\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 835.2852 - val_loss: 438.5734\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 821.9323 - val_loss: 428.8245\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 808.7314 - val_loss: 419.2152\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 795.6808 - val_loss: 409.7446\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 782.7799 - val_loss: 400.4125\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 770.0283 - val_loss: 391.2180\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 757.4249 - val_loss: 382.1592\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 744.9682 - val_loss: 373.2355\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 732.6573 - val_loss: 364.4456\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 720.4912 - val_loss: 355.7893\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 708.4697 - val_loss: 347.2654\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 696.5911 - val_loss: 338.8730\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 684.8553 - val_loss: 330.6107\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 673.2609 - val_loss: 322.4783\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 661.8074 - val_loss: 314.4744\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 650.4931 - val_loss: 306.5979\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 639.3180 - val_loss: 298.8481\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 628.2805 - val_loss: 291.2242\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 617.3801 - val_loss: 283.7253\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 606.6155 - val_loss: 276.3495\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 595.9863 - val_loss: 269.0972\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 585.4913 - val_loss: 261.9668\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 575.1293 - val_loss: 254.9571\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 564.9003 - val_loss: 248.0678\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 554.8029 - val_loss: 241.2977\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 544.8361 - val_loss: 234.6457\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 534.9993 - val_loss: 228.1112\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 525.2913 - val_loss: 221.6931\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 515.7115 - val_loss: 215.3904\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 506.2588 - val_loss: 209.2017\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 496.9321 - val_loss: 203.1269\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 487.7311 - val_loss: 197.1648\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 478.6548 - val_loss: 191.3145\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 469.7020 - val_loss: 185.5748\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 460.8720 - val_loss: 179.9448\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 452.1636 - val_loss: 174.4234\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 443.5763 - val_loss: 169.0104\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 435.1091 - val_loss: 163.7041\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 426.7612 - val_loss: 158.5038\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 418.5314 - val_loss: 153.4087\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 410.4193 - val_loss: 148.4177\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 402.4236 - val_loss: 143.5300\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 394.5438 - val_loss: 138.7444\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 386.7785 - val_loss: 134.0601\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 379.1271 - val_loss: 129.4761\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 371.5890 - val_loss: 124.9914\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 364.1628 - val_loss: 120.6055\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 356.8481 - val_loss: 116.3171\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 349.6438 - val_loss: 112.1254\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 342.5488 - val_loss: 108.0289\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 335.5623 - val_loss: 104.0272\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 328.6837 - val_loss: 100.1192\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 321.9118 - val_loss: 96.3038\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 315.2461 - val_loss: 92.5805\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 308.6854 - val_loss: 88.9478\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 302.2289 - val_loss: 85.4054\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 295.8757 - val_loss: 81.9514\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 289.6246 - val_loss: 78.5854\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 283.4752 - val_loss: 75.3065\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 277.4262 - val_loss: 72.1132\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 271.4767 - val_loss: 69.0051\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 265.6260 - val_loss: 65.9811\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 259.8734 - val_loss: 63.0403\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 254.2177 - val_loss: 60.1815\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 248.6582 - val_loss: 57.4039\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 243.1938 - val_loss: 54.7063\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 237.8235 - val_loss: 52.0881\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 232.5467 - val_loss: 49.5479\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 227.3624 - val_loss: 47.0850\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 222.2697 - val_loss: 44.6984\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 217.2675 - val_loss: 42.3868\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 212.3550 - val_loss: 40.1496\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 207.5314 - val_loss: 37.9858\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 202.7955 - val_loss: 35.8941\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 198.1470 - val_loss: 33.8739\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 193.5846 - val_loss: 31.9241\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 189.1075 - val_loss: 30.0435\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 184.7145 - val_loss: 28.2314\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 180.4050 - val_loss: 26.4866\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 176.1779 - val_loss: 24.8081\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 172.0324 - val_loss: 23.1953\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 167.9676 - val_loss: 21.6467\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 163.9827 - val_loss: 20.1617\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 160.0767 - val_loss: 18.7390\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 156.2485 - val_loss: 17.3778\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 152.4973 - val_loss: 16.0771\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 148.8223 - val_loss: 14.8358\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 145.2223 - val_loss: 13.6530\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 141.6969 - val_loss: 12.5279\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 138.2449 - val_loss: 11.4591\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 134.8652 - val_loss: 10.4459\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 131.5570 - val_loss: 9.4872\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 128.3195 - val_loss: 8.5821\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 125.1518 - val_loss: 7.7296\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 122.0532 - val_loss: 6.9287\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 119.0222 - val_loss: 6.1784\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 116.0583 - val_loss: 5.4776\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 113.1604 - val_loss: 4.8256\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 110.3279 - val_loss: 4.2213\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 107.5597 - val_loss: 3.6636\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 104.8551 - val_loss: 3.1517\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 102.2128 - val_loss: 2.6846\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 99.6321 - val_loss: 2.2612\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 97.1121 - val_loss: 1.8807\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 94.6520 - val_loss: 1.5420\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 92.2508 - val_loss: 1.2443\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 89.9075 - val_loss: 0.9865\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 87.6216 - val_loss: 0.7676\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 85.3916 - val_loss: 0.5868\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 83.2172 - val_loss: 0.4432\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 81.0973 - val_loss: 0.3357\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 79.0308 - val_loss: 0.2634\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 77.0173 - val_loss: 0.2254\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 75.0555 - val_loss: 0.2207\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 73.1448 - val_loss: 0.2485\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 71.2842 - val_loss: 0.3078\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 69.4727 - val_loss: 0.3978\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 67.7098 - val_loss: 0.5174\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 65.9944 - val_loss: 0.6658\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 64.3256 - val_loss: 0.8421\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 62.7027 - val_loss: 1.0454\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 61.1247 - val_loss: 1.2749\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 59.5909 - val_loss: 1.5296\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 58.1004 - val_loss: 1.8087\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 56.6524 - val_loss: 2.1113\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 55.2462 - val_loss: 2.4365\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 53.8807 - val_loss: 2.7836\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 52.5553 - val_loss: 3.1517\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 51.2691 - val_loss: 3.5398\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 50.0213 - val_loss: 3.9473\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 48.8112 - val_loss: 4.3733\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.6379 - val_loss: 4.8170\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 46.5007 - val_loss: 5.2776\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 45.3987 - val_loss: 5.7543\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 44.3313 - val_loss: 6.2463\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 43.2977 - val_loss: 6.7529\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 42.2970 - val_loss: 7.2733\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 41.3285 - val_loss: 7.8068\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 40.3914 - val_loss: 8.3526\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 39.4851 - val_loss: 8.9099\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 38.6089 - val_loss: 9.4781\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 37.7620 - val_loss: 10.0566\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 36.9436 - val_loss: 10.6444\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 36.1534 - val_loss: 11.2410\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 35.3901 - val_loss: 11.8458\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 34.6535 - val_loss: 12.4579\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.9427 - val_loss: 13.0768\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.2570 - val_loss: 13.7019\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 32.5959 - val_loss: 14.3326\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.9586 - val_loss: 14.9682\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 31.3445 - val_loss: 15.6081\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.7530 - val_loss: 16.2517\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.1835 - val_loss: 16.8985\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.6352 - val_loss: 17.5480\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.1077 - val_loss: 18.1994\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 28.6004 - val_loss: 18.8525\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 28.1125 - val_loss: 19.5063\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 27.6436 - val_loss: 20.1608\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 27.1933 - val_loss: 20.8153\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 26.7606 - val_loss: 21.4692\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 26.3453 - val_loss: 22.1223\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 25.9468 - val_loss: 22.7740\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 25.5644 - val_loss: 23.4239\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 25.1978 - val_loss: 24.0715\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 24.8463 - val_loss: 24.7163\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24.5096 - val_loss: 25.3582\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 24.1871 - val_loss: 25.9966\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 23.8784 - val_loss: 26.6311\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 23.5829 - val_loss: 27.2616\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 23.3002 - val_loss: 27.8874\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23.0299 - val_loss: 28.5085\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 22.7716 - val_loss: 29.1243\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 22.5248 - val_loss: 29.7347\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 22.2890 - val_loss: 30.3396\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.0640 - val_loss: 30.9383\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.8492 - val_loss: 31.5307\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.6444 - val_loss: 32.1166\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.4491 - val_loss: 32.6959\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.2629 - val_loss: 33.2681\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.0856 - val_loss: 33.8331\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.9168 - val_loss: 34.3907\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.7561 - val_loss: 34.9407\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.6032 - val_loss: 35.4831\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4578 - val_loss: 36.0175\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.3196 - val_loss: 36.5441\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.1883 - val_loss: 37.0626\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.0635 - val_loss: 37.5727\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9451 - val_loss: 38.0746\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.8327 - val_loss: 38.5678\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19.7260 - val_loss: 39.0525\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.6250 - val_loss: 39.5287\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 19.5292 - val_loss: 39.9962\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.4384 - val_loss: 40.4549\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 19.3524 - val_loss: 40.9048\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.2712 - val_loss: 41.3461\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.1942 - val_loss: 41.7785\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.1213 - val_loss: 42.2020\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.0525 - val_loss: 42.6167\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.9875 - val_loss: 43.0226\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.9260 - val_loss: 43.4196\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 18.8680 - val_loss: 43.8077\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.8133 - val_loss: 44.1871\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.7617 - val_loss: 44.5580\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.7129 - val_loss: 44.9199\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 18.6670 - val_loss: 45.2733\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.6237 - val_loss: 45.6179\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.5830 - val_loss: 45.9541\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.5447 - val_loss: 46.2817\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.5085 - val_loss: 46.6011\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 18.4746 - val_loss: 46.9121\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.4426 - val_loss: 47.2150\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.4126 - val_loss: 47.5097\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.3844 - val_loss: 47.7963\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.3578 - val_loss: 48.0750\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 18.3329 - val_loss: 48.3457\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.3096 - val_loss: 48.6090\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 18.2876 - val_loss: 48.8648\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.2671 - val_loss: 49.1130\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.2478 - val_loss: 49.3541\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.2296 - val_loss: 49.5875\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.2127 - val_loss: 49.8140\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.1968 - val_loss: 50.0337\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.1819 - val_loss: 50.2464\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 18.1679 - val_loss: 50.4524\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 18.1549 - val_loss: 50.6515\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.1426 - val_loss: 50.8443\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.1312 - val_loss: 51.0309\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.1206 - val_loss: 51.2111\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.1106 - val_loss: 51.3854\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.1012 - val_loss: 51.5539\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.0925 - val_loss: 51.7165\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.0843 - val_loss: 51.8733\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 18.0767 - val_loss: 52.0247\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 18.0696 - val_loss: 52.1711\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 18.0629 - val_loss: 52.3117\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.0567 - val_loss: 52.4473\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.0509 - val_loss: 52.5780\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 18.0455 - val_loss: 52.7036\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.0405 - val_loss: 52.8246\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.0358 - val_loss: 52.9411\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 18.0314 - val_loss: 53.0531\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.0273 - val_loss: 53.1608\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.0235 - val_loss: 53.2643\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.0200 - val_loss: 53.3638\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.0166 - val_loss: 53.4591\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.0136 - val_loss: 53.5507\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.0107 - val_loss: 53.6384\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.0081 - val_loss: 53.7227\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.0056 - val_loss: 53.8036\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 18.0033 - val_loss: 53.8811\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.0011 - val_loss: 53.9551\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9992 - val_loss: 54.0263\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 17.9973 - val_loss: 54.0938\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9956 - val_loss: 54.1590\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9941 - val_loss: 54.2213\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9926 - val_loss: 54.2809\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9912 - val_loss: 54.3376\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 17.9900 - val_loss: 54.3920\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 17.9888 - val_loss: 54.4437\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9877 - val_loss: 54.4930\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9868 - val_loss: 54.5399\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9858 - val_loss: 54.5851\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9850 - val_loss: 54.6277\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9843 - val_loss: 54.6689\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9835 - val_loss: 54.7077\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9829 - val_loss: 54.7448\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 17.9823 - val_loss: 54.7802\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9818 - val_loss: 54.8137\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9813 - val_loss: 54.8455\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9809 - val_loss: 54.8759\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9805 - val_loss: 54.9047\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9801 - val_loss: 54.9321\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9798 - val_loss: 54.9583\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9795 - val_loss: 54.9828\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9792 - val_loss: 55.0061\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17.9791 - val_loss: 55.0284\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9788 - val_loss: 55.0493\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9787 - val_loss: 55.0694\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17.9786 - val_loss: 55.0884\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9784 - val_loss: 55.1059\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9784 - val_loss: 55.1229\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9783 - val_loss: 55.1390\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 17.9783 - val_loss: 55.1540\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9783 - val_loss: 55.1682\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9783 - val_loss: 55.1818\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9783 - val_loss: 55.1945\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9783 - val_loss: 55.2066\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9783 - val_loss: 55.2181\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9784 - val_loss: 55.2289\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9784 - val_loss: 55.2387\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9785 - val_loss: 55.2484\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 17.9786 - val_loss: 55.2571\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 17.9787 - val_loss: 55.2655\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9788 - val_loss: 55.2734\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9789 - val_loss: 55.2811\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9790 - val_loss: 55.2881\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9792 - val_loss: 55.2947\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9793 - val_loss: 55.3007\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 17.9794 - val_loss: 55.3064\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 17.9796 - val_loss: 55.3119\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 17.9797 - val_loss: 55.3166\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 17.9799 - val_loss: 55.3212\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9801 - val_loss: 55.3256\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9802 - val_loss: 55.3296\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9804 - val_loss: 55.3332\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9806 - val_loss: 55.3368\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9808 - val_loss: 55.3402\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9809 - val_loss: 55.3433\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9811 - val_loss: 55.3460\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9813 - val_loss: 55.3487\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9815 - val_loss: 55.3512\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9817 - val_loss: 55.3536\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9819 - val_loss: 55.3558\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9821 - val_loss: 55.3577\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9823 - val_loss: 55.3593\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9825 - val_loss: 55.3608\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9827 - val_loss: 55.3624\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9829 - val_loss: 55.3638\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 17.9831 - val_loss: 55.3652\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9833 - val_loss: 55.3665\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9835 - val_loss: 55.3677\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9837 - val_loss: 55.3688\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9839 - val_loss: 55.3697\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9841 - val_loss: 55.3703\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9843 - val_loss: 55.3711\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9845 - val_loss: 55.3719\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9847 - val_loss: 55.3728\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 17.9849 - val_loss: 55.3734\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9851 - val_loss: 55.3739\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9853 - val_loss: 55.3744\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9854 - val_loss: 55.3749\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 17.9856 - val_loss: 55.3750\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9859 - val_loss: 55.3754\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.9860 - val_loss: 55.3755\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 17.9862 - val_loss: 55.3757\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9864 - val_loss: 55.3757\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9865 - val_loss: 55.3757\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9867 - val_loss: 55.3754\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9869 - val_loss: 55.3757\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9871 - val_loss: 55.3757\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9873 - val_loss: 55.3755\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9874 - val_loss: 55.3754\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 17.9877 - val_loss: 55.3754\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.9878 - val_loss: 55.3752\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 17.9880 - val_loss: 55.3752\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 17.9881 - val_loss: 55.3751\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 451ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.65466853e+01, 6.65242764e+01, 6.65018674e+01, 6.64794584e+01,\n",
       "        6.64570495e+01, 6.64346405e+01, 6.64122316e+01, 6.63898226e+01,\n",
       "        6.63674136e+01, 6.63450047e+01, 6.63225957e+01, 6.63001867e+01,\n",
       "        6.62777778e+01, 6.62553688e+01, 6.62329599e+01, 6.62105509e+01,\n",
       "        6.61881419e+01, 6.61657330e+01, 6.61433240e+01, 6.61209150e+01,\n",
       "        6.60985061e+01, 6.60760971e+01, 6.60536881e+01, 6.60312792e+01,\n",
       "        6.60088702e+01, 6.59864613e+01, 6.59640523e+01, 6.59416433e+01,\n",
       "        6.59192344e+01, 6.58996032e+01, 6.58968021e+01, 6.58940009e+01,\n",
       "        6.58911998e+01, 6.58883987e+01, 6.58855976e+01, 6.58827965e+01,\n",
       "        6.58799953e+01, 6.58771942e+01, 6.58743931e+01, 6.58715920e+01,\n",
       "        6.58687908e+01, 6.58659897e+01, 6.58631886e+01, 6.58603875e+01,\n",
       "        6.58575864e+01, 6.58547853e+01, 6.58519841e+01, 6.58491830e+01,\n",
       "        6.58463819e+01, 6.58435808e+01, 6.58407797e+01, 6.58379785e+01,\n",
       "        6.58351774e+01, 6.58323763e+01, 6.58295752e+01, 6.58267740e+01,\n",
       "        6.58239729e+01, 6.58211718e+01, 6.58183707e+01, 6.58155696e+01,\n",
       "        6.58127684e+01, 6.58099673e+01, 6.58071662e+01, 6.58043651e+01,\n",
       "        6.58015640e+01, 6.57913399e+01, 6.57717320e+01, 6.57521242e+01,\n",
       "        6.57325163e+01, 6.57129085e+01, 6.56933006e+01, 6.56736928e+01,\n",
       "        6.56540850e+01, 6.56344771e+01, 6.56148693e+01, 6.55952614e+01,\n",
       "        6.55756536e+01, 6.55560457e+01, 6.55364379e+01, 6.55168301e+01,\n",
       "        7.35689087e+01, 3.73059139e-02, 0.00000000e+00, 5.07184267e-01,\n",
       "        0.00000000e+00, 9.59888771e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.87390983e-01, 1.70714315e-02, 4.39866573e-01, 2.59176046e-01,\n",
       "        0.00000000e+00, 5.85228086e-01, 2.84863412e-01, 0.00000000e+00,\n",
       "        2.09774360e-01, 0.00000000e+00, 0.00000000e+00, 1.65288001e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63.78203782, 63.77503501, 63.76803221, 63.76102941, 63.75402661,\n",
       "       63.74702381, 63.74002101, 63.73301821, 63.72601541, 63.71901261,\n",
       "       63.7120098 , 63.705007  , 63.6980042 , 63.6910014 , 63.6839986 ,\n",
       "       63.6769958 , 63.669993  , 63.6629902 , 63.65598739, 63.64898459,\n",
       "       63.64198179, 63.63497899, 63.62797619, 63.62097339, 63.61397059,\n",
       "       63.60696779, 63.59996499, 63.59296218, 63.58595938, 63.57895658,\n",
       "       63.57195378, 63.56495098, 63.55794818, 63.55094538, 63.54394258,\n",
       "       63.53693978, 63.52993697, 63.52293417, 63.51593137, 63.50892857,\n",
       "       63.50192577, 63.49492297, 63.48792017, 63.48091737, 63.47391457,\n",
       "       63.46691176, 63.45990896, 63.45290616, 63.44590336, 63.43890056,\n",
       "       63.43189776, 63.42489496, 63.41789216, 63.41088936, 63.40388655,\n",
       "       63.39688375, 63.38988095, 63.38287815, 63.37587535, 63.36887255,\n",
       "       63.36186975, 63.35486695, 63.34786415, 63.34086134, 63.33385854,\n",
       "       63.32685574, 63.31985294, 63.31285014, 63.30584734, 63.29884454,\n",
       "       63.29184174, 63.28483894, 63.27783613, 63.27083333, 63.26383053,\n",
       "       63.25682773, 63.24982493, 63.24282213, 63.23581933, 63.22881653,\n",
       "       63.22181373, 63.21481092, 63.20780812, 63.20080532, 63.19380252,\n",
       "       63.18679972, 63.17979692, 63.17279412, 63.16579132, 63.15878852,\n",
       "       63.15178571, 63.14478291, 63.13778011, 63.13077731, 63.12377451,\n",
       "       63.11677171, 63.10976891, 63.10276611, 63.09576331, 63.0887605 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.57005021040853\n",
      "14.031958304712392\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
