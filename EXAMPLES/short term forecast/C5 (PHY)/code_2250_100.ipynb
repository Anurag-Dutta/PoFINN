{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2345    60.820469\n",
       "2346    60.812544\n",
       "2347    60.804618\n",
       "2348    60.796693\n",
       "2349    60.788768\n",
       "Name: C5, Length: 2350, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_2250_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2245     0.688693\n",
       "2246     0.000000\n",
       "2247     0.642658\n",
       "2248     0.296472\n",
       "2249     0.000000\n",
       "Name: C5, Length: 2250, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2250)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 1, 251) (1800, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "23/23 [==============================] - 3s 21ms/step - loss: 4943.2432 - val_loss: 2687.5725\n",
      "Epoch 2/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4671.1182 - val_loss: 2576.4233\n",
      "Epoch 3/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4564.8369 - val_loss: 2522.0903\n",
      "Epoch 4/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4463.9717 - val_loss: 2465.5833\n",
      "Epoch 5/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4369.3335 - val_loss: 2415.8254\n",
      "Epoch 6/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4279.1650 - val_loss: 2368.2129\n",
      "Epoch 7/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 4191.7451 - val_loss: 2322.2629\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4095.7473 - val_loss: 2268.0881\n",
      "Epoch 9/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4003.4966 - val_loss: 2223.2168\n",
      "Epoch 10/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3917.9302 - val_loss: 2179.6453\n",
      "Epoch 11/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3834.7048 - val_loss: 2135.4883\n",
      "Epoch 12/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3740.6785 - val_loss: 2089.3667\n",
      "Epoch 13/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3655.9893 - val_loss: 2047.8691\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3574.1316 - val_loss: 2008.1592\n",
      "Epoch 15/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3494.6956 - val_loss: 1969.9753\n",
      "Epoch 16/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3417.2979 - val_loss: 1933.1674\n",
      "Epoch 17/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3341.7227 - val_loss: 1897.6436\n",
      "Epoch 18/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3267.8323 - val_loss: 1863.3292\n",
      "Epoch 19/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3195.5295 - val_loss: 1830.1697\n",
      "Epoch 20/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3124.7427 - val_loss: 1798.1509\n",
      "Epoch 21/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 3055.4146 - val_loss: 1767.2216\n",
      "Epoch 22/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2987.4976 - val_loss: 1737.3523\n",
      "Epoch 23/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2920.9497 - val_loss: 1708.5155\n",
      "Epoch 24/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2855.7366 - val_loss: 1680.6875\n",
      "Epoch 25/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2791.8254 - val_loss: 1653.8446\n",
      "Epoch 26/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2729.1890 - val_loss: 1627.9656\n",
      "Epoch 27/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2667.7991 - val_loss: 1603.0311\n",
      "Epoch 28/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2607.6321 - val_loss: 1579.0214\n",
      "Epoch 29/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2548.6648 - val_loss: 1555.9185\n",
      "Epoch 30/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2490.8752 - val_loss: 1533.7045\n",
      "Epoch 31/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2434.2432 - val_loss: 1512.3627\n",
      "Epoch 32/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2378.7490 - val_loss: 1491.8766\n",
      "Epoch 33/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2324.3733 - val_loss: 1472.2297\n",
      "Epoch 34/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2271.0981 - val_loss: 1453.4065\n",
      "Epoch 35/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2218.9055 - val_loss: 1435.3922\n",
      "Epoch 36/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2167.7791 - val_loss: 1418.1710\n",
      "Epoch 37/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2117.7012 - val_loss: 1401.7286\n",
      "Epoch 38/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2068.6562 - val_loss: 1386.0503\n",
      "Epoch 39/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2020.6283 - val_loss: 1371.1222\n",
      "Epoch 40/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1973.6023 - val_loss: 1356.9296\n",
      "Epoch 41/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1927.5620 - val_loss: 1343.4591\n",
      "Epoch 42/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1882.4935 - val_loss: 1330.6969\n",
      "Epoch 43/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1838.3820 - val_loss: 1318.6299\n",
      "Epoch 44/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1795.2126 - val_loss: 1307.2439\n",
      "Epoch 45/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1752.9716 - val_loss: 1296.5266\n",
      "Epoch 46/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1711.6455 - val_loss: 1286.4644\n",
      "Epoch 47/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1671.2198 - val_loss: 1277.0444\n",
      "Epoch 48/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1631.6810 - val_loss: 1268.2538\n",
      "Epoch 49/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1593.0165 - val_loss: 1260.0801\n",
      "Epoch 50/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1555.2122 - val_loss: 1252.5106\n",
      "Epoch 51/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1518.2556 - val_loss: 1245.5330\n",
      "Epoch 52/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1482.1335 - val_loss: 1239.1345\n",
      "Epoch 53/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1446.8334 - val_loss: 1233.3036\n",
      "Epoch 54/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1412.3428 - val_loss: 1228.0273\n",
      "Epoch 55/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1378.6490 - val_loss: 1223.2942\n",
      "Epoch 56/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1345.7396 - val_loss: 1219.0919\n",
      "Epoch 57/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1313.6028 - val_loss: 1215.4084\n",
      "Epoch 58/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1282.2258 - val_loss: 1212.2323\n",
      "Epoch 59/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1251.5972 - val_loss: 1209.5516\n",
      "Epoch 60/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1221.7051 - val_loss: 1207.3550\n",
      "Epoch 61/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1192.5375 - val_loss: 1205.6306\n",
      "Epoch 62/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1164.0829 - val_loss: 1204.3671\n",
      "Epoch 63/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1136.3295 - val_loss: 1203.5531\n",
      "Epoch 64/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1109.2659 - val_loss: 1203.1775\n",
      "Epoch 65/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1082.8809 - val_loss: 1203.2285\n",
      "Epoch 66/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1057.1633 - val_loss: 1203.6956\n",
      "Epoch 67/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1032.1016 - val_loss: 1204.5674\n",
      "Epoch 68/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1007.6849 - val_loss: 1205.8328\n",
      "Epoch 69/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 983.9022 - val_loss: 1207.4807\n",
      "Epoch 70/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 960.7424 - val_loss: 1209.5007\n",
      "Epoch 71/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 938.1949 - val_loss: 1211.8815\n",
      "Epoch 72/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 916.2488 - val_loss: 1214.6130\n",
      "Epoch 73/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 894.8935 - val_loss: 1217.6841\n",
      "Epoch 74/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 874.1187 - val_loss: 1221.0840\n",
      "Epoch 75/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 853.9133 - val_loss: 1224.8029\n",
      "Epoch 76/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 834.2675 - val_loss: 1228.8298\n",
      "Epoch 77/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 815.1704 - val_loss: 1233.1545\n",
      "Epoch 78/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 796.6122 - val_loss: 1237.7667\n",
      "Epoch 79/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 778.5827 - val_loss: 1242.6561\n",
      "Epoch 80/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 761.0716 - val_loss: 1247.8129\n",
      "Epoch 81/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 744.0689 - val_loss: 1253.2267\n",
      "Epoch 82/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 727.5646 - val_loss: 1258.8866\n",
      "Epoch 83/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 711.5492 - val_loss: 1264.7841\n",
      "Epoch 84/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 696.0127 - val_loss: 1270.9076\n",
      "Epoch 85/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 680.9453 - val_loss: 1277.2462\n",
      "Epoch 86/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 666.3376 - val_loss: 1283.7874\n",
      "Epoch 87/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 652.1800 - val_loss: 1290.5125\n",
      "Epoch 88/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 638.4633 - val_loss: 1297.3715\n",
      "Epoch 89/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 625.1774 - val_loss: 1304.0114\n",
      "Epoch 90/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 612.3115 - val_loss: 1271.8098\n",
      "Epoch 91/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 682.8108 - val_loss: 1277.0347\n",
      "Epoch 92/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 681.3826 - val_loss: 1283.8102\n",
      "Epoch 93/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 665.9343 - val_loss: 1290.8540\n",
      "Epoch 94/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 650.9611 - val_loss: 1298.1151\n",
      "Epoch 95/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 636.4957 - val_loss: 1305.5787\n",
      "Epoch 96/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 622.5292 - val_loss: 1313.2328\n",
      "Epoch 97/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 609.0486 - val_loss: 1321.0663\n",
      "Epoch 98/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 596.0412 - val_loss: 1329.0675\n",
      "Epoch 99/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 583.4940 - val_loss: 1337.2260\n",
      "Epoch 100/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 571.3947 - val_loss: 1345.5308\n",
      "Epoch 101/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 559.7310 - val_loss: 1353.9713\n",
      "Epoch 102/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 548.4911 - val_loss: 1362.5380\n",
      "Epoch 103/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 537.6632 - val_loss: 1371.2198\n",
      "Epoch 104/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 527.2357 - val_loss: 1380.0074\n",
      "Epoch 105/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 517.1976 - val_loss: 1388.8911\n",
      "Epoch 106/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 507.5376 - val_loss: 1397.8612\n",
      "Epoch 107/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 498.2451 - val_loss: 1406.9084\n",
      "Epoch 108/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 489.3091 - val_loss: 1416.0242\n",
      "Epoch 109/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 480.7198 - val_loss: 1425.1986\n",
      "Epoch 110/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 472.4666 - val_loss: 1434.4244\n",
      "Epoch 111/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 464.5395 - val_loss: 1443.6915\n",
      "Epoch 112/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 456.9286 - val_loss: 1452.9927\n",
      "Epoch 113/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 449.6245 - val_loss: 1462.3191\n",
      "Epoch 114/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 442.6177 - val_loss: 1471.6637\n",
      "Epoch 115/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 435.8988 - val_loss: 1481.0182\n",
      "Epoch 116/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 429.4588 - val_loss: 1490.3750\n",
      "Epoch 117/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 423.2890 - val_loss: 1499.7271\n",
      "Epoch 118/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 417.3806 - val_loss: 1509.0670\n",
      "Epoch 119/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 411.7250 - val_loss: 1518.3878\n",
      "Epoch 120/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 406.3140 - val_loss: 1527.6833\n",
      "Epoch 121/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 401.1394 - val_loss: 1536.9465\n",
      "Epoch 122/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 396.1930 - val_loss: 1546.1714\n",
      "Epoch 123/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 391.4672 - val_loss: 1555.3511\n",
      "Epoch 124/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 386.9544 - val_loss: 1564.4811\n",
      "Epoch 125/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 382.6469 - val_loss: 1573.5543\n",
      "Epoch 126/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 378.5375 - val_loss: 1582.5659\n",
      "Epoch 127/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 374.6191 - val_loss: 1591.5100\n",
      "Epoch 128/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 370.8849 - val_loss: 1600.3832\n",
      "Epoch 129/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 367.3277 - val_loss: 1609.1780\n",
      "Epoch 130/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 363.9411 - val_loss: 1617.8917\n",
      "Epoch 131/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 360.7186 - val_loss: 1626.5190\n",
      "Epoch 132/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 357.6539 - val_loss: 1635.0560\n",
      "Epoch 133/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 354.7409 - val_loss: 1643.4979\n",
      "Epoch 134/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 351.9735 - val_loss: 1651.8422\n",
      "Epoch 135/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 349.3459 - val_loss: 1660.0842\n",
      "Epoch 136/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 346.8524 - val_loss: 1668.2205\n",
      "Epoch 137/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 344.4875 - val_loss: 1676.2487\n",
      "Epoch 138/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 342.2458 - val_loss: 1684.1641\n",
      "Epoch 139/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 340.1223 - val_loss: 1691.9653\n",
      "Epoch 140/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 338.1118 - val_loss: 1699.6484\n",
      "Epoch 141/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 336.2094 - val_loss: 1707.2126\n",
      "Epoch 142/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 334.4103 - val_loss: 1714.6549\n",
      "Epoch 143/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 332.7098 - val_loss: 1721.9724\n",
      "Epoch 144/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 331.1038 - val_loss: 1729.1649\n",
      "Epoch 145/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 329.5876 - val_loss: 1736.2286\n",
      "Epoch 146/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 328.1573 - val_loss: 1743.1644\n",
      "Epoch 147/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 326.8087 - val_loss: 1749.9683\n",
      "Epoch 148/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 325.5381 - val_loss: 1756.6414\n",
      "Epoch 149/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 324.3415 - val_loss: 1763.1818\n",
      "Epoch 150/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 323.2155 - val_loss: 1769.5881\n",
      "Epoch 151/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 322.1564 - val_loss: 1775.8613\n",
      "Epoch 152/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 321.1610 - val_loss: 1781.9993\n",
      "Epoch 153/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 320.2260 - val_loss: 1788.0032\n",
      "Epoch 154/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 319.3482 - val_loss: 1793.8722\n",
      "Epoch 155/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 318.5248 - val_loss: 1799.6057\n",
      "Epoch 156/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 317.7528 - val_loss: 1805.2048\n",
      "Epoch 157/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 317.0296 - val_loss: 1810.6707\n",
      "Epoch 158/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 316.3523 - val_loss: 1816.0013\n",
      "Epoch 159/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 315.7186 - val_loss: 1821.1991\n",
      "Epoch 160/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 315.1260 - val_loss: 1826.2643\n",
      "Epoch 161/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 314.5721 - val_loss: 1831.1965\n",
      "Epoch 162/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 314.0550 - val_loss: 1836.0012\n",
      "Epoch 163/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 313.5721 - val_loss: 1840.6731\n",
      "Epoch 164/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 313.1219 - val_loss: 1845.2180\n",
      "Epoch 165/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 312.7023 - val_loss: 1849.6348\n",
      "Epoch 166/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 312.3112 - val_loss: 1853.9269\n",
      "Epoch 167/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 311.9473 - val_loss: 1858.0936\n",
      "Epoch 168/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 311.6087 - val_loss: 1862.1375\n",
      "Epoch 169/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 311.2939 - val_loss: 1866.0616\n",
      "Epoch 170/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 311.0014 - val_loss: 1869.8651\n",
      "Epoch 171/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 310.7299 - val_loss: 1873.5507\n",
      "Epoch 172/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 310.4778 - val_loss: 1877.1208\n",
      "Epoch 173/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 310.2441 - val_loss: 1880.5785\n",
      "Epoch 174/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 310.0274 - val_loss: 1883.9236\n",
      "Epoch 175/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 309.8268 - val_loss: 1887.1578\n",
      "Epoch 176/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 309.6411 - val_loss: 1890.2850\n",
      "Epoch 177/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 309.4694 - val_loss: 1893.3071\n",
      "Epoch 178/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 309.3105 - val_loss: 1896.2253\n",
      "Epoch 179/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 309.1638 - val_loss: 1899.0424\n",
      "Epoch 180/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 309.0282 - val_loss: 1901.7603\n",
      "Epoch 181/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 308.9033 - val_loss: 1904.3809\n",
      "Epoch 182/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 308.7880 - val_loss: 1906.9073\n",
      "Epoch 183/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 308.6817 - val_loss: 1909.3417\n",
      "Epoch 184/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 308.5838 - val_loss: 1911.6847\n",
      "Epoch 185/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 308.4937 - val_loss: 1913.9412\n",
      "Epoch 186/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 308.4108 - val_loss: 1916.1122\n",
      "Epoch 187/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 308.3345 - val_loss: 1918.1995\n",
      "Epoch 188/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 308.2644 - val_loss: 1920.2061\n",
      "Epoch 189/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 308.2001 - val_loss: 1922.1332\n",
      "Epoch 190/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 308.1410 - val_loss: 1923.9852\n",
      "Epoch 191/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 308.0866 - val_loss: 1925.7615\n",
      "Epoch 192/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 308.0370 - val_loss: 1927.4667\n",
      "Epoch 193/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.9914 - val_loss: 1929.1017\n",
      "Epoch 194/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.9497 - val_loss: 1930.6693\n",
      "Epoch 195/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.9115 - val_loss: 1932.1715\n",
      "Epoch 196/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.8765 - val_loss: 1933.6094\n",
      "Epoch 197/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.8445 - val_loss: 1934.9860\n",
      "Epoch 198/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.8153 - val_loss: 1936.3033\n",
      "Epoch 199/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.7886 - val_loss: 1937.5645\n",
      "Epoch 200/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.7642 - val_loss: 1938.7686\n",
      "Epoch 201/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.7421 - val_loss: 1939.9199\n",
      "Epoch 202/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.7217 - val_loss: 1941.0197\n",
      "Epoch 203/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.7033 - val_loss: 1942.0704\n",
      "Epoch 204/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.6864 - val_loss: 1943.0728\n",
      "Epoch 205/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.6712 - val_loss: 1944.0305\n",
      "Epoch 206/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.6572 - val_loss: 1944.9421\n",
      "Epoch 207/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.6446 - val_loss: 1945.8114\n",
      "Epoch 208/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.6331 - val_loss: 1946.6389\n",
      "Epoch 209/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.6227 - val_loss: 1947.4290\n",
      "Epoch 210/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.6131 - val_loss: 1948.1802\n",
      "Epoch 211/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.6045 - val_loss: 1948.8940\n",
      "Epoch 212/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5968 - val_loss: 1949.5747\n",
      "Epoch 213/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5898 - val_loss: 1950.2203\n",
      "Epoch 214/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5836 - val_loss: 1950.8354\n",
      "Epoch 215/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5779 - val_loss: 1951.4199\n",
      "Epoch 216/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5728 - val_loss: 1951.9746\n",
      "Epoch 217/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5681 - val_loss: 1952.5016\n",
      "Epoch 218/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5639 - val_loss: 1953.0007\n",
      "Epoch 219/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5602 - val_loss: 1953.4744\n",
      "Epoch 220/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5570 - val_loss: 1953.9236\n",
      "Epoch 221/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5539 - val_loss: 1954.3496\n",
      "Epoch 222/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5514 - val_loss: 1954.7533\n",
      "Epoch 223/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5491 - val_loss: 1955.1357\n",
      "Epoch 224/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5470 - val_loss: 1955.4976\n",
      "Epoch 225/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5452 - val_loss: 1955.8408\n",
      "Epoch 226/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.5436 - val_loss: 1956.1649\n",
      "Epoch 227/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5423 - val_loss: 1956.4716\n",
      "Epoch 228/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5412 - val_loss: 1956.7615\n",
      "Epoch 229/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5401 - val_loss: 1957.0349\n",
      "Epoch 230/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5393 - val_loss: 1957.2925\n",
      "Epoch 231/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5385 - val_loss: 1957.5356\n",
      "Epoch 232/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5381 - val_loss: 1957.7653\n",
      "Epoch 233/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5376 - val_loss: 1957.9810\n",
      "Epoch 234/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5373 - val_loss: 1958.1841\n",
      "Epoch 235/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5370 - val_loss: 1958.3750\n",
      "Epoch 236/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5369 - val_loss: 1958.5543\n",
      "Epoch 237/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5369 - val_loss: 1958.7212\n",
      "Epoch 238/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5369 - val_loss: 1958.8771\n",
      "Epoch 239/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5369 - val_loss: 1959.0193\n",
      "Epoch 240/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5371 - val_loss: 1959.1448\n",
      "Epoch 241/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5374 - val_loss: 1959.2411\n",
      "Epoch 242/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5377 - val_loss: 1959.1505\n",
      "Epoch 243/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 308.1311 - val_loss: 1965.1711\n",
      "Epoch 244/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5912 - val_loss: 1965.1534\n",
      "Epoch 245/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5598 - val_loss: 1964.9491\n",
      "Epoch 246/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5522 - val_loss: 1964.7378\n",
      "Epoch 247/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.5490 - val_loss: 1964.5365\n",
      "Epoch 248/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5476 - val_loss: 1964.3469\n",
      "Epoch 249/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5469 - val_loss: 1964.1674\n",
      "Epoch 250/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5468 - val_loss: 1963.9993\n",
      "Epoch 251/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5469 - val_loss: 1963.8420\n",
      "Epoch 252/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5474 - val_loss: 1963.6948\n",
      "Epoch 253/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5479 - val_loss: 1963.5563\n",
      "Epoch 254/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5486 - val_loss: 1963.4265\n",
      "Epoch 255/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5494 - val_loss: 1963.3051\n",
      "Epoch 256/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5502 - val_loss: 1963.1924\n",
      "Epoch 257/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5511 - val_loss: 1963.0861\n",
      "Epoch 258/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5520 - val_loss: 1962.9863\n",
      "Epoch 259/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5529 - val_loss: 1962.8934\n",
      "Epoch 260/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5538 - val_loss: 1962.8069\n",
      "Epoch 261/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5548 - val_loss: 1962.7261\n",
      "Epoch 262/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5556 - val_loss: 1962.6498\n",
      "Epoch 263/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5565 - val_loss: 1962.5789\n",
      "Epoch 264/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5574 - val_loss: 1962.5115\n",
      "Epoch 265/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5583 - val_loss: 1962.4495\n",
      "Epoch 266/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5591 - val_loss: 1962.3905\n",
      "Epoch 267/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5601 - val_loss: 1962.3364\n",
      "Epoch 268/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.5609 - val_loss: 1962.2861\n",
      "Epoch 269/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5617 - val_loss: 1962.2389\n",
      "Epoch 270/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5625 - val_loss: 1962.1941\n",
      "Epoch 271/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5634 - val_loss: 1962.1517\n",
      "Epoch 272/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5641 - val_loss: 1962.1132\n",
      "Epoch 273/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5649 - val_loss: 1962.0774\n",
      "Epoch 274/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5656 - val_loss: 1962.0435\n",
      "Epoch 275/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5663 - val_loss: 1962.0118\n",
      "Epoch 276/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5672 - val_loss: 1961.9822\n",
      "Epoch 277/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5679 - val_loss: 1961.9557\n",
      "Epoch 278/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5685 - val_loss: 1961.9301\n",
      "Epoch 279/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5691 - val_loss: 1961.9052\n",
      "Epoch 280/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5697 - val_loss: 1961.8827\n",
      "Epoch 281/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5705 - val_loss: 1961.8613\n",
      "Epoch 282/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5710 - val_loss: 1961.8418\n",
      "Epoch 283/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5717 - val_loss: 1961.8229\n",
      "Epoch 284/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5723 - val_loss: 1961.8052\n",
      "Epoch 285/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5729 - val_loss: 1961.7892\n",
      "Epoch 286/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.5734 - val_loss: 1961.7739\n",
      "Epoch 287/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5740 - val_loss: 1961.7600\n",
      "Epoch 288/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5746 - val_loss: 1961.7467\n",
      "Epoch 289/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5751 - val_loss: 1961.7343\n",
      "Epoch 290/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5756 - val_loss: 1961.7225\n",
      "Epoch 291/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5760 - val_loss: 1961.7109\n",
      "Epoch 292/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5766 - val_loss: 1961.7006\n",
      "Epoch 293/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5771 - val_loss: 1961.6909\n",
      "Epoch 294/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5775 - val_loss: 1961.6825\n",
      "Epoch 295/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5780 - val_loss: 1961.6736\n",
      "Epoch 296/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5786 - val_loss: 1961.6660\n",
      "Epoch 297/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5791 - val_loss: 1961.6591\n",
      "Epoch 298/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5794 - val_loss: 1961.6526\n",
      "Epoch 299/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5799 - val_loss: 1961.6459\n",
      "Epoch 300/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5803 - val_loss: 1961.6398\n",
      "Epoch 301/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.5807 - val_loss: 1961.6348\n",
      "Epoch 302/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5811 - val_loss: 1961.6287\n",
      "Epoch 303/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5815 - val_loss: 1961.6239\n",
      "Epoch 304/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5820 - val_loss: 1961.6198\n",
      "Epoch 305/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5822 - val_loss: 1961.6144\n",
      "Epoch 306/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5827 - val_loss: 1961.6101\n",
      "Epoch 307/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5830 - val_loss: 1961.6064\n",
      "Epoch 308/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5834 - val_loss: 1961.6029\n",
      "Epoch 309/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5837 - val_loss: 1961.5991\n",
      "Epoch 310/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5841 - val_loss: 1961.5966\n",
      "Epoch 311/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5844 - val_loss: 1961.5930\n",
      "Epoch 312/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5847 - val_loss: 1961.5906\n",
      "Epoch 313/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5851 - val_loss: 1961.5885\n",
      "Epoch 314/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5854 - val_loss: 1961.5867\n",
      "Epoch 315/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5856 - val_loss: 1961.5847\n",
      "Epoch 316/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5859 - val_loss: 1961.5819\n",
      "Epoch 317/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 307.5862 - val_loss: 1961.5801\n",
      "Epoch 318/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5865 - val_loss: 1961.5778\n",
      "Epoch 319/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5868 - val_loss: 1961.5765\n",
      "Epoch 320/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5870 - val_loss: 1961.5748\n",
      "Epoch 321/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.5873 - val_loss: 1961.5731\n",
      "Epoch 322/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5876 - val_loss: 1961.5719\n",
      "Epoch 323/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5879 - val_loss: 1961.5714\n",
      "Epoch 324/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5880 - val_loss: 1961.5687\n",
      "Epoch 325/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5883 - val_loss: 1961.5679\n",
      "Epoch 326/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5885 - val_loss: 1961.5659\n",
      "Epoch 327/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.5889 - val_loss: 1961.5654\n",
      "Epoch 328/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5891 - val_loss: 1961.5642\n",
      "Epoch 329/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5893 - val_loss: 1961.5634\n",
      "Epoch 330/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5895 - val_loss: 1961.5626\n",
      "Epoch 331/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5897 - val_loss: 1961.5616\n",
      "Epoch 332/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 307.5900 - val_loss: 1961.5608\n",
      "Epoch 333/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5901 - val_loss: 1961.5593\n",
      "Epoch 334/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5903 - val_loss: 1961.5581\n",
      "Epoch 335/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5905 - val_loss: 1961.5568\n",
      "Epoch 336/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5907 - val_loss: 1961.5563\n",
      "Epoch 337/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5909 - val_loss: 1961.5554\n",
      "Epoch 338/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5910 - val_loss: 1961.5538\n",
      "Epoch 339/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5913 - val_loss: 1961.5530\n",
      "Epoch 340/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5914 - val_loss: 1961.5515\n",
      "Epoch 341/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5916 - val_loss: 1961.5510\n",
      "Epoch 342/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5918 - val_loss: 1961.5500\n",
      "Epoch 343/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5920 - val_loss: 1961.5497\n",
      "Epoch 344/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5921 - val_loss: 1961.5490\n",
      "Epoch 345/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5923 - val_loss: 1961.5488\n",
      "Epoch 346/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5924 - val_loss: 1961.5476\n",
      "Epoch 347/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5926 - val_loss: 1961.5470\n",
      "Epoch 348/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.5928 - val_loss: 1961.5469\n",
      "Epoch 349/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5929 - val_loss: 1961.5465\n",
      "Epoch 350/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5931 - val_loss: 1961.5464\n",
      "Epoch 351/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5931 - val_loss: 1961.5458\n",
      "Epoch 352/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5933 - val_loss: 1961.5443\n",
      "Epoch 353/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5934 - val_loss: 1961.5447\n",
      "Epoch 354/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5935 - val_loss: 1961.5441\n",
      "Epoch 355/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5937 - val_loss: 1961.5436\n",
      "Epoch 356/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5939 - val_loss: 1961.5437\n",
      "Epoch 357/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5939 - val_loss: 1961.5431\n",
      "Epoch 358/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5940 - val_loss: 1961.5411\n",
      "Epoch 359/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5942 - val_loss: 1961.5416\n",
      "Epoch 360/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5944 - val_loss: 1961.5415\n",
      "Epoch 361/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.5944 - val_loss: 1961.5406\n",
      "Epoch 362/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5945 - val_loss: 1961.5399\n",
      "Epoch 363/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5947 - val_loss: 1961.5404\n",
      "Epoch 364/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5948 - val_loss: 1961.5406\n",
      "Epoch 365/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5948 - val_loss: 1961.5399\n",
      "Epoch 366/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5949 - val_loss: 1961.5396\n",
      "Epoch 367/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5950 - val_loss: 1961.5392\n",
      "Epoch 368/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5951 - val_loss: 1961.5386\n",
      "Epoch 369/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5952 - val_loss: 1961.5382\n",
      "Epoch 370/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5953 - val_loss: 1961.5375\n",
      "Epoch 371/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5954 - val_loss: 1961.5375\n",
      "Epoch 372/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5956 - val_loss: 1961.5383\n",
      "Epoch 373/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5957 - val_loss: 1961.5394\n",
      "Epoch 374/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5957 - val_loss: 1961.5396\n",
      "Epoch 375/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5958 - val_loss: 1961.5394\n",
      "Epoch 376/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5958 - val_loss: 1961.5389\n",
      "Epoch 377/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.5959 - val_loss: 1961.5389\n",
      "Epoch 378/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5961 - val_loss: 1961.5398\n",
      "Epoch 379/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5961 - val_loss: 1961.5403\n",
      "Epoch 380/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5961 - val_loss: 1961.5392\n",
      "Epoch 381/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.5962 - val_loss: 1961.5391\n",
      "Epoch 382/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.5962 - val_loss: 1961.5382\n",
      "Epoch 383/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.5963 - val_loss: 1961.5375\n",
      "Epoch 384/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.5964 - val_loss: 1961.5377\n",
      "Epoch 385/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.5966 - val_loss: 1961.5383\n",
      "Epoch 386/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5966 - val_loss: 1961.5378\n",
      "Epoch 387/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5966 - val_loss: 1961.5377\n",
      "Epoch 388/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5966 - val_loss: 1961.5374\n",
      "Epoch 389/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5968 - val_loss: 1961.5380\n",
      "Epoch 390/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5967 - val_loss: 1961.5383\n",
      "Epoch 391/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.5969 - val_loss: 1961.5391\n",
      "Epoch 392/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5970 - val_loss: 1961.5402\n",
      "Epoch 393/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5970 - val_loss: 1961.5399\n",
      "Epoch 394/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5970 - val_loss: 1961.5399\n",
      "Epoch 395/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5970 - val_loss: 1961.5383\n",
      "Epoch 396/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5971 - val_loss: 1961.5382\n",
      "Epoch 397/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5971 - val_loss: 1961.5374\n",
      "Epoch 398/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5972 - val_loss: 1961.5374\n",
      "Epoch 399/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5973 - val_loss: 1961.5369\n",
      "Epoch 400/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5972 - val_loss: 1961.5365\n",
      "Epoch 401/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5973 - val_loss: 1961.5359\n",
      "Epoch 402/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.5974 - val_loss: 1961.5354\n",
      "Epoch 403/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5974 - val_loss: 1961.5353\n",
      "Epoch 404/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5975 - val_loss: 1961.5354\n",
      "Epoch 405/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5976 - val_loss: 1961.5356\n",
      "Epoch 406/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5976 - val_loss: 1961.5361\n",
      "Epoch 407/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.5976 - val_loss: 1961.5363\n",
      "Epoch 408/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5976 - val_loss: 1961.5361\n",
      "Epoch 409/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5976 - val_loss: 1961.5359\n",
      "Epoch 410/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5977 - val_loss: 1961.5353\n",
      "Epoch 411/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5978 - val_loss: 1961.5353\n",
      "Epoch 412/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.5977 - val_loss: 1961.5345\n",
      "Epoch 413/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5978 - val_loss: 1961.5338\n",
      "Epoch 414/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.5978 - val_loss: 1961.5333\n",
      "Epoch 415/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.5978 - val_loss: 1961.5332\n",
      "Epoch 416/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5979 - val_loss: 1961.5330\n",
      "Epoch 417/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5980 - val_loss: 1961.5330\n",
      "Epoch 418/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5980 - val_loss: 1961.5332\n",
      "Epoch 419/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5981 - val_loss: 1961.5333\n",
      "Epoch 420/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5981 - val_loss: 1961.5330\n",
      "Epoch 421/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.5980 - val_loss: 1961.5317\n",
      "Epoch 422/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5981 - val_loss: 1961.5317\n",
      "Epoch 423/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5981 - val_loss: 1961.5314\n",
      "Epoch 424/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5981 - val_loss: 1961.5302\n",
      "Epoch 425/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5981 - val_loss: 1961.5299\n",
      "Epoch 426/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5981 - val_loss: 1961.5293\n",
      "Epoch 427/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5981 - val_loss: 1961.5281\n",
      "Epoch 428/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5982 - val_loss: 1961.5269\n",
      "Epoch 429/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5982 - val_loss: 1961.5269\n",
      "Epoch 430/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5983 - val_loss: 1961.5262\n",
      "Epoch 431/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5983 - val_loss: 1961.5260\n",
      "Epoch 432/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5984 - val_loss: 1961.5264\n",
      "Epoch 433/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5984 - val_loss: 1961.5267\n",
      "Epoch 434/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5984 - val_loss: 1961.5272\n",
      "Epoch 435/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5984 - val_loss: 1961.5271\n",
      "Epoch 436/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5984 - val_loss: 1961.5267\n",
      "Epoch 437/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.5984 - val_loss: 1961.5260\n",
      "Epoch 438/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5984 - val_loss: 1961.5256\n",
      "Epoch 439/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5984 - val_loss: 1961.5254\n",
      "Epoch 440/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5984 - val_loss: 1961.5248\n",
      "Epoch 441/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5984 - val_loss: 1961.5247\n",
      "Epoch 442/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5984 - val_loss: 1961.5236\n",
      "Epoch 443/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5985 - val_loss: 1961.5234\n",
      "Epoch 444/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5985 - val_loss: 1961.5234\n",
      "Epoch 445/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5986 - val_loss: 1961.5233\n",
      "Epoch 446/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5986 - val_loss: 1961.5239\n",
      "Epoch 447/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5986 - val_loss: 1961.5238\n",
      "Epoch 448/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5986 - val_loss: 1961.5236\n",
      "Epoch 449/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5986 - val_loss: 1961.5231\n",
      "Epoch 450/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5987 - val_loss: 1961.5229\n",
      "Epoch 451/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5987 - val_loss: 1961.5234\n",
      "Epoch 452/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.5987 - val_loss: 1961.5234\n",
      "Epoch 453/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5987 - val_loss: 1961.5234\n",
      "Epoch 454/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5987 - val_loss: 1961.5233\n",
      "Epoch 455/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5987 - val_loss: 1961.5231\n",
      "Epoch 456/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5988 - val_loss: 1961.5236\n",
      "Epoch 457/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5988 - val_loss: 1961.5236\n",
      "Epoch 458/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5988 - val_loss: 1961.5233\n",
      "Epoch 459/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5988 - val_loss: 1961.5234\n",
      "Epoch 460/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5988 - val_loss: 1961.5233\n",
      "Epoch 461/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5988 - val_loss: 1961.5227\n",
      "Epoch 462/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5988 - val_loss: 1961.5222\n",
      "Epoch 463/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5988 - val_loss: 1961.5219\n",
      "Epoch 464/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5988 - val_loss: 1961.5215\n",
      "Epoch 465/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5988 - val_loss: 1961.5214\n",
      "Epoch 466/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.5988 - val_loss: 1961.5206\n",
      "Epoch 467/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5988 - val_loss: 1961.5205\n",
      "Epoch 468/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5988 - val_loss: 1961.5197\n",
      "Epoch 469/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5988 - val_loss: 1961.5197\n",
      "Epoch 470/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5988 - val_loss: 1961.5194\n",
      "Epoch 471/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5988 - val_loss: 1961.5197\n",
      "Epoch 472/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.5989 - val_loss: 1961.5200\n",
      "Epoch 473/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 307.5989 - val_loss: 1961.5200\n",
      "Epoch 474/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 307.5989 - val_loss: 1961.5198\n",
      "Epoch 475/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5989 - val_loss: 1961.5197\n",
      "Epoch 476/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5990 - val_loss: 1961.5194\n",
      "Epoch 477/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5990 - val_loss: 1961.5200\n",
      "Epoch 478/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5989 - val_loss: 1961.5198\n",
      "Epoch 479/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5989 - val_loss: 1961.5197\n",
      "Epoch 480/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 307.5990 - val_loss: 1961.5194\n",
      "Epoch 481/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5990 - val_loss: 1961.5194\n",
      "Epoch 482/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5991 - val_loss: 1961.5200\n",
      "Epoch 483/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5990 - val_loss: 1961.5201\n",
      "Epoch 484/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5990 - val_loss: 1961.5209\n",
      "Epoch 485/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5990 - val_loss: 1961.5210\n",
      "Epoch 486/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.5990 - val_loss: 1961.5205\n",
      "Epoch 487/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5990 - val_loss: 1961.5200\n",
      "Epoch 488/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5991 - val_loss: 1961.5190\n",
      "Epoch 489/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5991 - val_loss: 1961.5188\n",
      "Epoch 490/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5990 - val_loss: 1961.5178\n",
      "Epoch 491/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5991 - val_loss: 1961.5177\n",
      "Epoch 492/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5991 - val_loss: 1961.5176\n",
      "Epoch 493/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5991 - val_loss: 1961.5173\n",
      "Epoch 494/500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 307.5991 - val_loss: 1961.5170\n",
      "Epoch 495/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5991 - val_loss: 1961.5168\n",
      "Epoch 496/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5991 - val_loss: 1961.5167\n",
      "Epoch 497/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5991 - val_loss: 1961.5164\n",
      "Epoch 498/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5991 - val_loss: 1961.5161\n",
      "Epoch 499/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5991 - val_loss: 1961.5160\n",
      "Epoch 500/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.5991 - val_loss: 1961.5156\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 342ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.97488795e+01, 6.96969188e+01, 6.95960784e+01, 6.94952381e+01,\n",
       "        7.56711883e+01, 0.00000000e+00, 0.00000000e+00, 7.19164540e-02,\n",
       "        8.54255438e-01, 0.00000000e+00, 1.97798982e-01, 0.00000000e+00,\n",
       "        3.59862149e-01, 7.19840383e+01, 7.19789963e+01, 7.19739543e+01,\n",
       "        6.11796200e-01, 0.00000000e+00, 7.04867647e+01, 7.00077731e+01,\n",
       "        6.98609244e+01, 6.98105042e+01, 6.97600840e+01, 6.97096639e+01,\n",
       "        6.96184874e+01, 6.95176471e+01, 6.94168067e+01, 0.00000000e+00,\n",
       "        5.38560090e-01, 6.97806256e+01, 6.97302054e+01, 6.96595705e+01,\n",
       "        6.95587302e+01, 6.94578898e+01, 7.32506536e+01, 7.21918301e+01,\n",
       "        7.08947946e+01, 0.00000000e+00, 0.00000000e+00, 3.83580270e-01,\n",
       "        0.00000000e+00, 3.43769310e-01, 2.39154880e-01, 0.00000000e+00,\n",
       "        6.61508080e-01, 0.00000000e+00, 0.00000000e+00, 6.95400560e+01,\n",
       "        6.94392157e+01, 0.00000000e+00, 0.00000000e+00, 6.97918301e+01,\n",
       "        6.97414099e+01, 6.96819795e+01, 6.95811391e+01, 6.94802988e+01,\n",
       "        7.34859477e+01, 7.24271242e+01, 7.12141223e+01, 0.00000000e+00,\n",
       "        2.06821650e-01, 0.00000000e+00, 6.95213819e+01, 6.94205415e+01,\n",
       "        7.28584967e+01, 7.17995565e+01, 7.03625817e+01, 7.22964052e+01,\n",
       "        7.21036718e+01, 7.19868394e+01, 0.00000000e+00, 3.09567900e-01,\n",
       "        4.72652300e-01, 6.92632141e+01, 1.20388903e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.21908500e-03, 3.13862383e-01,\n",
       "        6.81857224e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.93289155e-01, 3.29637855e-01, 1.84754193e-01, 0.00000000e+00,\n",
       "        9.67586040e-01, 2.29455024e-01, 6.35351896e-01, 4.79979366e-01,\n",
       "        5.80257058e-01, 2.61133388e-02, 3.94952774e-01, 1.58226490e+00,\n",
       "        0.00000000e+00, 8.04931998e-01, 2.01332867e-02, 2.69504964e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61.5733552 , 61.56543007, 61.55750495, 61.54957983, 61.54165471,\n",
       "       61.53372959, 61.52580447, 61.51787935, 61.50995423, 61.5020291 ,\n",
       "       61.49410398, 61.48617886, 61.47825374, 61.47032862, 61.4624035 ,\n",
       "       61.45447838, 61.44655326, 61.43862813, 61.43070301, 61.42277789,\n",
       "       61.41485277, 61.40692765, 61.39900253, 61.39107741, 61.38315229,\n",
       "       61.37522716, 61.36730204, 61.35937692, 61.3514518 , 61.34352668,\n",
       "       61.33560156, 61.32767644, 61.31975132, 61.31182619, 61.30390107,\n",
       "       61.29597595, 61.28805083, 61.28012571, 61.27220059, 61.26427547,\n",
       "       61.25635035, 61.24842522, 61.2405001 , 61.23257498, 61.22464986,\n",
       "       61.21672474, 61.20879962, 61.2008745 , 61.19294937, 61.18502425,\n",
       "       61.17709913, 61.16917401, 61.16124889, 61.15332377, 61.14539865,\n",
       "       61.13747353, 61.1295484 , 61.12162328, 61.11369816, 61.10577304,\n",
       "       61.09784792, 61.0899228 , 61.08199768, 61.07407256, 61.06614743,\n",
       "       61.05822231, 61.05029719, 61.04237207, 61.03444695, 61.02652183,\n",
       "       61.01859671, 61.01067159, 61.00274646, 60.99482134, 60.98689622,\n",
       "       60.9789711 , 60.97104598, 60.96312086, 60.95519574, 60.94727062,\n",
       "       60.93934549, 60.93142037, 60.92349525, 60.91557013, 60.90764501,\n",
       "       60.89971989, 60.89179477, 60.88386965, 60.87594452, 60.8680194 ,\n",
       "       60.86009428, 60.85216916, 60.84424404, 60.83631892, 60.8283938 ,\n",
       "       60.82046868, 60.81254355, 60.80461843, 60.79669331, 60.78876819])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.59007654783532\n",
      "37.66286774066848\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
