{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2145    62.405493\n",
       "2146    62.397568\n",
       "2147    62.389643\n",
       "2148    62.381718\n",
       "2149    62.373792\n",
       "Name: C5, Length: 2150, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_2050_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2045     0.000000\n",
       "2046     0.209774\n",
       "2047     0.000000\n",
       "2048     0.000000\n",
       "2049     0.000000\n",
       "Name: C5, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2050)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 1, 251) (1600, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 24ms/step - loss: 5114.3750 - val_loss: 4101.2275\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5017.6680 - val_loss: 4043.8469\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4954.2817 - val_loss: 3986.9746\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4891.6128 - val_loss: 3930.8508\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4820.4712 - val_loss: 3859.2180\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4748.6440 - val_loss: 3800.8899\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4684.4380 - val_loss: 3743.7480\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4621.4165 - val_loss: 3687.6030\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4559.3677 - val_loss: 3632.2969\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4498.1553 - val_loss: 3577.7402\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 4437.7007 - val_loss: 3523.8796\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4377.9595 - val_loss: 3470.6821\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4318.8940 - val_loss: 3418.1223\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4260.4858 - val_loss: 3366.1812\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4202.7158 - val_loss: 3314.8450\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4145.5679 - val_loss: 3264.1016\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4089.0312 - val_loss: 3213.9404\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4033.0962 - val_loss: 3164.3528\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3977.7532 - val_loss: 3115.3311\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3922.9934 - val_loss: 3066.8674\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3868.8110 - val_loss: 3018.9551\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3815.1987 - val_loss: 2971.5884\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3762.1499 - val_loss: 2924.7607\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3709.4734 - val_loss: 2874.7659\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3650.5181 - val_loss: 2822.9260\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3592.4048 - val_loss: 2772.3367\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3536.0964 - val_loss: 2723.3521\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3481.3296 - val_loss: 2675.5815\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3427.7500 - val_loss: 2628.7949\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3375.1555 - val_loss: 2582.8625\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3323.4297 - val_loss: 2537.7009\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3272.4949 - val_loss: 2493.2551\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3222.2976 - val_loss: 2449.4844\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3172.7983 - val_loss: 2406.3586\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3123.9683 - val_loss: 2363.8535\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3075.7812 - val_loss: 2321.9497\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 3028.2175 - val_loss: 2280.6292\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2981.2607 - val_loss: 2239.8784\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2934.8970 - val_loss: 2199.6860\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2889.1125 - val_loss: 2160.0391\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2843.8960 - val_loss: 2120.9287\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2799.2388 - val_loss: 2082.3467\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2755.1301 - val_loss: 2044.2836\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2711.5618 - val_loss: 2006.7324\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2668.5266 - val_loss: 1969.6852\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2626.0161 - val_loss: 1933.1360\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2584.0247 - val_loss: 1897.0787\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2542.5454 - val_loss: 1861.5066\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2501.5713 - val_loss: 1826.4141\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2461.0972 - val_loss: 1791.7957\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2421.1182 - val_loss: 1757.6461\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2381.6272 - val_loss: 1723.9603\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2342.6199 - val_loss: 1690.7328\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2304.0916 - val_loss: 1657.9600\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2266.0366 - val_loss: 1625.6365\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2228.4512 - val_loss: 1593.7574\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2191.3296 - val_loss: 1562.3187\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2154.6677 - val_loss: 1531.3158\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2118.4617 - val_loss: 1500.7451\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2082.7065 - val_loss: 1470.6014\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2047.3982 - val_loss: 1440.8809\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 2012.5330 - val_loss: 1411.5801\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1978.1062 - val_loss: 1382.6946\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1944.1140 - val_loss: 1354.2218\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1910.5530 - val_loss: 1326.1555\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1877.4192 - val_loss: 1298.4939\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1844.7080 - val_loss: 1271.2319\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1812.4160 - val_loss: 1244.3669\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1780.5403 - val_loss: 1217.8950\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1749.0759 - val_loss: 1191.8120\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1718.0208 - val_loss: 1166.1149\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1687.3699 - val_loss: 1140.8003\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1657.1211 - val_loss: 1115.8645\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1627.2698 - val_loss: 1091.3035\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1597.8129 - val_loss: 1067.1154\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1568.7471 - val_loss: 1043.2952\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1540.0688 - val_loss: 1019.8405\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1511.7751 - val_loss: 996.7477\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1483.8627 - val_loss: 974.0134\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1456.3274 - val_loss: 951.6345\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1429.1669 - val_loss: 929.6074\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1402.3778 - val_loss: 907.9301\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1375.9568 - val_loss: 886.5977\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1349.9008 - val_loss: 865.6081\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1324.2065 - val_loss: 844.9576\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1298.8705 - val_loss: 824.6434\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1273.8901 - val_loss: 804.6627\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1249.2623 - val_loss: 785.0115\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1224.9838 - val_loss: 765.6877\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1201.0515 - val_loss: 746.6879\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1177.4626 - val_loss: 728.0085\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1154.2142 - val_loss: 709.6475\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1131.3030 - val_loss: 691.6007\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1108.7262 - val_loss: 673.8658\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1086.4806 - val_loss: 656.4403\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1064.5631 - val_loss: 639.3201\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1042.9719 - val_loss: 622.5034\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1021.7030 - val_loss: 605.9864\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1000.7537 - val_loss: 589.7665\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 980.1211 - val_loss: 573.8405\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 959.8029 - val_loss: 558.2060\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 939.7953 - val_loss: 542.8597\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 920.0965 - val_loss: 527.7990\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 900.7028 - val_loss: 513.0213\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 881.6119 - val_loss: 498.5229\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 862.8209 - val_loss: 484.3010\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 844.3268 - val_loss: 470.3536\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 826.1270 - val_loss: 456.6777\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 808.2186 - val_loss: 443.2695\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 790.5990 - val_loss: 430.1274\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 773.2657 - val_loss: 417.2481\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 756.2153 - val_loss: 404.6285\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 739.4456 - val_loss: 392.2665\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 722.9536 - val_loss: 380.1586\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 706.7368 - val_loss: 368.3027\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 690.7923 - val_loss: 356.6954\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 675.1174 - val_loss: 345.3344\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 659.7097 - val_loss: 334.2167\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 644.5665 - val_loss: 323.3397\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 629.6848 - val_loss: 312.7004\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 615.0621 - val_loss: 302.2965\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 600.6954 - val_loss: 292.1250\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 586.5829 - val_loss: 282.1829\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 572.7214 - val_loss: 272.4682\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 559.1080 - val_loss: 262.9776\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 545.7407 - val_loss: 253.7089\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 532.6166 - val_loss: 244.6589\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 519.7327 - val_loss: 235.8247\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 507.0871 - val_loss: 227.2047\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 494.6771 - val_loss: 218.7955\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 482.4996 - val_loss: 210.5943\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 470.5526 - val_loss: 202.5987\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 458.8329 - val_loss: 194.8058\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 447.3383 - val_loss: 187.2131\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 436.0661 - val_loss: 179.8176\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 425.0137 - val_loss: 172.6173\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 414.1786 - val_loss: 165.6091\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 403.5583 - val_loss: 158.7905\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 393.1506 - val_loss: 152.1589\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 382.9524 - val_loss: 145.7118\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 372.9614 - val_loss: 139.4461\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 363.1748 - val_loss: 133.3595\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 353.1355 - val_loss: 126.1349\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 340.7157 - val_loss: 118.4569\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 328.6884 - val_loss: 111.4810\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 317.5738 - val_loss: 105.0447\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 307.1260 - val_loss: 99.0176\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 297.1866 - val_loss: 93.3273\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 287.6665 - val_loss: 87.9302\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 278.5108 - val_loss: 82.7967\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 269.6820 - val_loss: 77.9055\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 261.1536 - val_loss: 73.2408\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 252.9045 - val_loss: 68.7890\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 244.9181 - val_loss: 64.5394\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 237.1809 - val_loss: 60.4827\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 229.6817 - val_loss: 56.6107\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 222.4101 - val_loss: 52.9161\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 215.3576 - val_loss: 49.3923\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 208.5162 - val_loss: 46.0330\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 201.8785 - val_loss: 42.8329\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 195.4384 - val_loss: 39.7868\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 189.1897 - val_loss: 36.8893\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 183.1266 - val_loss: 34.1360\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 177.2439 - val_loss: 31.5226\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 171.5366 - val_loss: 29.0446\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 166.0002 - val_loss: 26.6980\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 160.6299 - val_loss: 24.4787\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 155.4215 - val_loss: 22.3830\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 150.3708 - val_loss: 20.4073\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 145.4738 - val_loss: 18.5479\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 140.7269 - val_loss: 16.8014\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 136.1261 - val_loss: 15.1642\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 131.6678 - val_loss: 13.6333\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 127.3487 - val_loss: 12.2052\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 123.1652 - val_loss: 10.8768\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 119.1140 - val_loss: 9.6451\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 115.1920 - val_loss: 8.5071\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 111.3959 - val_loss: 7.4596\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 107.7226 - val_loss: 6.4998\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 104.1690 - val_loss: 5.6249\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 100.7323 - val_loss: 4.8321\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 97.4095 - val_loss: 4.1184\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 94.1976 - val_loss: 3.4815\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 91.0940 - val_loss: 2.9184\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 88.0958 - val_loss: 2.4266\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 85.2006 - val_loss: 2.0037\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 82.4055 - val_loss: 1.6469\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 79.7079 - val_loss: 1.3540\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 77.1053 - val_loss: 1.1223\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 74.5951 - val_loss: 0.9496\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 72.1750 - val_loss: 0.8335\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 69.8425 - val_loss: 0.7717\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 67.5952 - val_loss: 0.7620\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 65.4308 - val_loss: 0.8020\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 63.3469 - val_loss: 0.8897\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 61.3415 - val_loss: 1.0229\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 59.4121 - val_loss: 1.1995\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 57.5566 - val_loss: 1.4175\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 55.7729 - val_loss: 1.6748\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 54.0589 - val_loss: 1.9695\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 52.4124 - val_loss: 2.2997\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 50.8316 - val_loss: 2.6633\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 49.3143 - val_loss: 3.0587\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 47.8586 - val_loss: 3.4840\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 46.4627 - val_loss: 3.9374\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 45.1247 - val_loss: 4.4171\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 43.8426 - val_loss: 4.9217\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 42.6147 - val_loss: 5.4493\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 41.4392 - val_loss: 5.9983\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 40.3145 - val_loss: 6.5673\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 39.2387 - val_loss: 7.1546\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 38.2102 - val_loss: 7.7589\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 37.2275 - val_loss: 8.3785\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 36.2889 - val_loss: 9.0123\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 35.3928 - val_loss: 9.6588\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 34.5378 - val_loss: 10.3167\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 33.7223 - val_loss: 10.9846\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 32.9450 - val_loss: 11.6614\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 32.2044 - val_loss: 12.3459\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 31.4991 - val_loss: 13.0370\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.8278 - val_loss: 13.7334\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.1892 - val_loss: 14.4342\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 29.5819 - val_loss: 15.1382\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 29.0049 - val_loss: 15.8447\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 28.4567 - val_loss: 16.5524\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 27.9363 - val_loss: 17.2606\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 27.4426 - val_loss: 17.9684\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 26.9744 - val_loss: 18.6747\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 26.5307 - val_loss: 19.3790\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 26.1103 - val_loss: 20.0806\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 25.7124 - val_loss: 20.7784\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 25.3359 - val_loss: 21.4719\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 24.9798 - val_loss: 22.1604\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 24.6433 - val_loss: 22.8436\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 24.3254 - val_loss: 23.5204\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 24.0253 - val_loss: 24.1906\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.7422 - val_loss: 24.8536\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 23.4752 - val_loss: 25.5086\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.2237 - val_loss: 26.1557\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.9868 - val_loss: 26.7940\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.7639 - val_loss: 27.4234\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 22.5542 - val_loss: 28.0435\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.3570 - val_loss: 28.6537\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 22.1717 - val_loss: 29.2542\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.9978 - val_loss: 29.8443\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.8346 - val_loss: 30.4237\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.6816 - val_loss: 30.9926\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5382 - val_loss: 31.5505\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 21.4039 - val_loss: 32.0972\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 21.2782 - val_loss: 32.6328\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.1606 - val_loss: 33.1568\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.0506 - val_loss: 33.6695\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 20.9479 - val_loss: 34.1707\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.8521 - val_loss: 34.6600\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.7626 - val_loss: 35.1377\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.6792 - val_loss: 35.6036\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.6016 - val_loss: 36.0577\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 20.5292 - val_loss: 36.5004\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 20.4619 - val_loss: 36.9312\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.3993 - val_loss: 37.3505\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 20.3412 - val_loss: 37.7584\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.2871 - val_loss: 38.1549\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.2370 - val_loss: 38.5397\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.1904 - val_loss: 38.9136\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 20.1473 - val_loss: 39.2761\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 20.1074 - val_loss: 39.6274\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 20.0704 - val_loss: 39.9681\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 20.0362 - val_loss: 40.2979\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 20.0046 - val_loss: 40.6169\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.9754 - val_loss: 40.9256\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.9485 - val_loss: 41.2240\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.9236 - val_loss: 41.5123\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.9006 - val_loss: 41.7908\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.8795 - val_loss: 42.0594\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.8601 - val_loss: 42.3187\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.8422 - val_loss: 42.5684\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.8257 - val_loss: 42.8092\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.8106 - val_loss: 43.0409\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7967 - val_loss: 43.2639\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 19.7840 - val_loss: 43.4785\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7722 - val_loss: 43.6848\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7615 - val_loss: 43.8828\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7517 - val_loss: 44.0730\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7427 - val_loss: 44.2558\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7345 - val_loss: 44.4309\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7270 - val_loss: 44.5988\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.7202 - val_loss: 44.7595\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.7139 - val_loss: 44.9134\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7082 - val_loss: 45.0605\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7031 - val_loss: 45.2015\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6984 - val_loss: 45.3363\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6941 - val_loss: 45.4649\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6901 - val_loss: 45.5876\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6867 - val_loss: 45.7047\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6835 - val_loss: 45.8166\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 19.6806 - val_loss: 45.9232\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6780 - val_loss: 46.0250\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6756 - val_loss: 46.1217\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6735 - val_loss: 46.2136\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6717 - val_loss: 46.3014\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6699 - val_loss: 46.3845\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6684 - val_loss: 46.4633\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6671 - val_loss: 46.5384\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6659 - val_loss: 46.6094\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6648 - val_loss: 46.6770\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6639 - val_loss: 46.7412\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6631 - val_loss: 46.8017\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6624 - val_loss: 46.8593\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6618 - val_loss: 46.9137\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6613 - val_loss: 46.9649\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6608 - val_loss: 47.0134\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6605 - val_loss: 47.0592\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6601 - val_loss: 47.1022\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 19.6599 - val_loss: 47.1432\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6598 - val_loss: 47.1816\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6597 - val_loss: 47.2178\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6596 - val_loss: 47.2519\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.6596 - val_loss: 47.2841\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.6596 - val_loss: 47.3140\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6597 - val_loss: 47.3425\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.6598 - val_loss: 47.3692\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.6599 - val_loss: 47.3942\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.6600 - val_loss: 47.4176\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6602 - val_loss: 47.4396\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.6604 - val_loss: 47.4604\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6606 - val_loss: 47.4795\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6609 - val_loss: 47.4975\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6612 - val_loss: 47.5143\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6615 - val_loss: 47.5299\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 19.6618 - val_loss: 47.5447\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6621 - val_loss: 47.5581\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6625 - val_loss: 47.5708\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6628 - val_loss: 47.5826\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6632 - val_loss: 47.5938\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6635 - val_loss: 47.6040\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6639 - val_loss: 47.6134\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6643 - val_loss: 47.6221\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6647 - val_loss: 47.6303\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6651 - val_loss: 47.6377\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6655 - val_loss: 47.6446\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6659 - val_loss: 47.6508\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6664 - val_loss: 47.6567\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6668 - val_loss: 47.6620\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.6672 - val_loss: 47.6667\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6677 - val_loss: 47.6715\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6681 - val_loss: 47.6755\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6686 - val_loss: 47.6793\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6690 - val_loss: 47.6826\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6694 - val_loss: 47.6858\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6699 - val_loss: 47.6884\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6704 - val_loss: 47.6910\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6708 - val_loss: 47.6932\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6713 - val_loss: 47.6954\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6718 - val_loss: 47.6973\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6722 - val_loss: 47.6990\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6727 - val_loss: 47.7003\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6732 - val_loss: 47.7015\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.6736 - val_loss: 47.7026\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6741 - val_loss: 47.7036\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6745 - val_loss: 47.7044\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6750 - val_loss: 47.7049\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.6754 - val_loss: 47.7054\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6759 - val_loss: 47.7057\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6764 - val_loss: 47.7062\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6768 - val_loss: 47.7066\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6773 - val_loss: 47.7068\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6777 - val_loss: 47.7068\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6782 - val_loss: 47.7068\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6786 - val_loss: 47.7065\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.6791 - val_loss: 47.7065\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6795 - val_loss: 47.7063\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6799 - val_loss: 47.7059\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6803 - val_loss: 47.7055\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6808 - val_loss: 47.7051\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6812 - val_loss: 47.7048\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6817 - val_loss: 47.7046\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 19.6821 - val_loss: 47.7040\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6825 - val_loss: 47.7034\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6829 - val_loss: 47.7029\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6833 - val_loss: 47.7023\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6837 - val_loss: 47.7017\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6841 - val_loss: 47.7011\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6846 - val_loss: 47.7005\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6850 - val_loss: 47.7000\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6854 - val_loss: 47.6995\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6858 - val_loss: 47.6987\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6862 - val_loss: 47.6981\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6866 - val_loss: 47.6977\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6869 - val_loss: 47.6968\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6873 - val_loss: 47.6964\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.6876 - val_loss: 47.6956\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6881 - val_loss: 47.6951\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6884 - val_loss: 47.6943\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6887 - val_loss: 47.6933\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6891 - val_loss: 47.6927\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6895 - val_loss: 47.6919\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6898 - val_loss: 47.6911\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6902 - val_loss: 47.6905\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6906 - val_loss: 47.6901\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6909 - val_loss: 47.6894\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6913 - val_loss: 47.6887\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6916 - val_loss: 47.6881\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.6919 - val_loss: 47.6875\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6922 - val_loss: 47.6868\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6925 - val_loss: 47.6861\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6929 - val_loss: 47.6854\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6932 - val_loss: 47.6848\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6935 - val_loss: 47.6843\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6938 - val_loss: 47.6835\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6941 - val_loss: 47.6828\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6944 - val_loss: 47.6823\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6947 - val_loss: 47.6816\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6950 - val_loss: 47.6812\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6953 - val_loss: 47.6803\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.6956 - val_loss: 47.6799\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6959 - val_loss: 47.6795\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6962 - val_loss: 47.6791\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6964 - val_loss: 47.6782\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6967 - val_loss: 47.6778\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 19.6969 - val_loss: 47.6771\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.6973 - val_loss: 47.6766\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6975 - val_loss: 47.6762\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6977 - val_loss: 47.6752\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6980 - val_loss: 47.6747\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.6982 - val_loss: 47.6743\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.6985 - val_loss: 47.6736\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6987 - val_loss: 47.6730\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6990 - val_loss: 47.6727\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6992 - val_loss: 47.6719\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6994 - val_loss: 47.6715\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6996 - val_loss: 47.6710\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 19.6999 - val_loss: 47.6703\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7001 - val_loss: 47.6701\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7004 - val_loss: 47.6697\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7006 - val_loss: 47.6695\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7007 - val_loss: 47.6690\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7010 - val_loss: 47.6684\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7012 - val_loss: 47.6681\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7014 - val_loss: 47.6678\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7016 - val_loss: 47.6673\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7018 - val_loss: 47.6668\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7020 - val_loss: 47.6664\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7022 - val_loss: 47.6662\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7023 - val_loss: 47.6657\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7025 - val_loss: 47.6650\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7027 - val_loss: 47.6648\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.7029 - val_loss: 47.6644\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7031 - val_loss: 47.6641\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7033 - val_loss: 47.6640\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.7034 - val_loss: 47.6636\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.7036 - val_loss: 47.6632\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7037 - val_loss: 47.6629\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7039 - val_loss: 47.6626\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7041 - val_loss: 47.6620\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7042 - val_loss: 47.6615\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7044 - val_loss: 47.6614\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7045 - val_loss: 47.6612\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7047 - val_loss: 47.6610\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7048 - val_loss: 47.6604\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7050 - val_loss: 47.6601\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 19.7051 - val_loss: 47.6597\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7053 - val_loss: 47.6596\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 19.7054 - val_loss: 47.6594\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7055 - val_loss: 47.6591\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7056 - val_loss: 47.6585\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7058 - val_loss: 47.6583\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7060 - val_loss: 47.6582\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.7061 - val_loss: 47.6580\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7062 - val_loss: 47.6579\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7063 - val_loss: 47.6577\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7064 - val_loss: 47.6573\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 19.7065 - val_loss: 47.6570\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.7066 - val_loss: 47.6566\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.7067 - val_loss: 47.6564\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7069 - val_loss: 47.6562\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7070 - val_loss: 47.6561\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7071 - val_loss: 47.6558\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7072 - val_loss: 47.6553\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.7073 - val_loss: 47.6548\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 19.7074 - val_loss: 47.6547\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7075 - val_loss: 47.6545\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7076 - val_loss: 47.6544\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7077 - val_loss: 47.6542\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 19.7078 - val_loss: 47.6542\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.7079 - val_loss: 47.6540\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.7080 - val_loss: 47.6538\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7081 - val_loss: 47.6535\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7081 - val_loss: 47.6533\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7083 - val_loss: 47.6533\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7083 - val_loss: 47.6532\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7084 - val_loss: 47.6532\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7085 - val_loss: 47.6529\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7086 - val_loss: 47.6525\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7087 - val_loss: 47.6524\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.7088 - val_loss: 47.6523\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7088 - val_loss: 47.6518\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7089 - val_loss: 47.6517\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.7089 - val_loss: 47.6515\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7091 - val_loss: 47.6515\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.7091 - val_loss: 47.6514\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 383ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.58874650e+01, 6.58846639e+01, 6.58818627e+01, 6.58790616e+01,\n",
       "        6.58762605e+01, 6.58734594e+01, 6.58706583e+01, 6.58678571e+01,\n",
       "        6.58650560e+01, 6.58622549e+01, 6.58594538e+01, 6.58566527e+01,\n",
       "        6.58538515e+01, 6.58510504e+01, 6.58482493e+01, 6.58454482e+01,\n",
       "        6.58426471e+01, 6.58398459e+01, 6.58370448e+01, 6.58342437e+01,\n",
       "        6.58314426e+01, 6.58286415e+01, 6.58258403e+01, 6.58230392e+01,\n",
       "        6.58202381e+01, 6.58174370e+01, 6.58146359e+01, 6.58118347e+01,\n",
       "        6.58090336e+01, 6.58062325e+01, 6.58034314e+01, 6.58006302e+01,\n",
       "        6.57848039e+01, 6.57651961e+01, 6.57455882e+01, 6.57259804e+01,\n",
       "        6.57063725e+01, 6.56867647e+01, 6.56671569e+01, 6.56475490e+01,\n",
       "        6.56279412e+01, 6.56083333e+01, 6.55887255e+01, 6.55691176e+01,\n",
       "        6.55495098e+01, 6.55299020e+01, 6.55102941e+01, 6.88817227e+01,\n",
       "        6.87892857e+01, 6.86968487e+01, 6.86044118e+01, 6.85119748e+01,\n",
       "        6.84195378e+01, 6.83271008e+01, 6.82346639e+01, 6.81212185e+01,\n",
       "        6.80051681e+01, 6.79091177e+01, 6.78130672e+01, 6.77170168e+01,\n",
       "        6.76209664e+01, 6.75249156e+01, 6.74288640e+01, 6.73328124e+01,\n",
       "        6.72367608e+01, 6.71407092e+01, 6.70446576e+01, 6.69486060e+01,\n",
       "        6.68525544e+01, 6.67565028e+01, 6.66604512e+01, 6.65643996e+01,\n",
       "        6.64683480e+01, 6.63722964e+01, 6.62762448e+01, 6.61801932e+01,\n",
       "        6.60841416e+01, 6.59880900e+01, 6.58920384e+01, 6.57959868e+01,\n",
       "        7.32098160e+01, 0.00000000e+00, 0.00000000e+00, 3.24641019e-02,\n",
       "        0.00000000e+00, 4.57060337e-01, 0.00000000e+00, 2.07480013e-01,\n",
       "        0.00000000e+00, 6.82716072e-01, 6.90850139e-01, 0.00000000e+00,\n",
       "        8.46212447e-01, 0.00000000e+00, 4.71494406e-01, 1.20992875e+00,\n",
       "        7.10071027e-01, 2.04438478e-01, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63.0817577 , 63.0747549 , 63.0677521 , 63.0607493 , 63.0537465 ,\n",
       "       63.0467437 , 63.0397409 , 63.0327381 , 63.02573529, 63.01873249,\n",
       "       63.01172969, 63.00472689, 62.99772409, 62.99072129, 62.98371849,\n",
       "       62.97671569, 62.96971289, 62.96271008, 62.95570728, 62.94870448,\n",
       "       62.94170168, 62.93469888, 62.92769608, 62.92069328, 62.91369048,\n",
       "       62.90668768, 62.89968487, 62.89268207, 62.88567927, 62.87867647,\n",
       "       62.87167367, 62.86467087, 62.85766807, 62.85066527, 62.84366246,\n",
       "       62.83665966, 62.82965686, 62.82265406, 62.81565126, 62.80864846,\n",
       "       62.80164566, 62.79464286, 62.78764006, 62.78063725, 62.77363445,\n",
       "       62.76663165, 62.75962885, 62.75262605, 62.74562325, 62.73862045,\n",
       "       62.73161765, 62.72461485, 62.71761204, 62.71060924, 62.70360644,\n",
       "       62.69660364, 62.68960084, 62.68259804, 62.67559524, 62.66859244,\n",
       "       62.66158964, 62.65458683, 62.64758403, 62.64058123, 62.63357843,\n",
       "       62.62657563, 62.61957283, 62.61257003, 62.60556723, 62.59856443,\n",
       "       62.59156162, 62.58455882, 62.57755602, 62.57055322, 62.56355042,\n",
       "       62.55654762, 62.54954482, 62.54254202, 62.53553922, 62.52853641,\n",
       "       62.52153361, 62.51453081, 62.50752801, 62.50052521, 62.49266926,\n",
       "       62.48474414, 62.47681902, 62.4688939 , 62.46096878, 62.45304366,\n",
       "       62.44511854, 62.43719341, 62.42926829, 62.42134317, 62.41341805,\n",
       "       62.40549293, 62.39756781, 62.38964269, 62.38171757, 62.37379244])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.323196487810385\n",
      "14.811415123872099\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
