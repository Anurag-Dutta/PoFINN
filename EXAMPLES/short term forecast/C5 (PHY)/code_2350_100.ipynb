{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2445    60.027957\n",
       "2446    60.020031\n",
       "2447    60.012106\n",
       "2448    60.004181\n",
       "2449    59.996256\n",
       "Name: C5, Length: 2450, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_2350_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2345     0.026113\n",
       "2346     0.394953\n",
       "2347     1.582265\n",
       "2348     0.000000\n",
       "2349     0.804932\n",
       "Name: C5, Length: 2350, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2350)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 1, 251) (1900, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 3s 21ms/step - loss: 5085.2212 - val_loss: 3618.8381\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4982.0547 - val_loss: 3557.7754\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4905.6445 - val_loss: 3508.7375\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4838.0278 - val_loss: 3460.5925\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4771.5034 - val_loss: 3413.1997\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4705.8945 - val_loss: 3366.4658\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4641.0977 - val_loss: 3320.3418\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4577.0581 - val_loss: 3274.7993\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4513.7407 - val_loss: 3229.8184\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4451.1240 - val_loss: 3185.3857\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4389.1880 - val_loss: 3141.4880\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4327.9248 - val_loss: 3098.1121\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4266.5723 - val_loss: 3049.8306\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4196.3652 - val_loss: 3001.6960\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4130.0698 - val_loss: 2955.1770\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4065.4460 - val_loss: 2899.1724\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3983.5798 - val_loss: 2849.3738\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3914.9604 - val_loss: 2801.5823\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3848.9827 - val_loss: 2755.5920\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3785.0161 - val_loss: 2710.9233\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3722.5784 - val_loss: 2667.3237\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3661.4106 - val_loss: 2624.6499\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3601.3599 - val_loss: 2582.8098\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3542.3220 - val_loss: 2541.7393\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3484.2246 - val_loss: 2501.3914\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3427.0142 - val_loss: 2461.7300\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3370.6479 - val_loss: 2422.7261\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3315.0920 - val_loss: 2384.3560\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3260.3181 - val_loss: 2346.6001\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3206.3013 - val_loss: 2309.4402\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3153.0237 - val_loss: 2272.8625\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3100.4644 - val_loss: 2236.8530\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3048.6101 - val_loss: 2201.3989\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2997.4443 - val_loss: 2166.4907\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2946.9563 - val_loss: 2132.1155\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2897.1328 - val_loss: 2098.2612\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2847.9639 - val_loss: 2064.9016\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2799.1042 - val_loss: 2024.1450\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2735.7720 - val_loss: 1985.8531\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2680.3672 - val_loss: 1949.1689\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2627.4924 - val_loss: 1914.1135\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2576.5259 - val_loss: 1880.2302\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2526.9780 - val_loss: 1847.2866\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2478.5955 - val_loss: 1815.1548\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2431.2317 - val_loss: 1783.7529\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2384.7896 - val_loss: 1753.0265\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2339.2019 - val_loss: 1722.9348\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2294.4192 - val_loss: 1693.4464\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2250.4014 - val_loss: 1664.5365\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2207.1177 - val_loss: 1636.1842\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2164.5415 - val_loss: 1608.3721\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2122.6514 - val_loss: 1581.0858\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2081.4285 - val_loss: 1554.3114\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2040.8546 - val_loss: 1528.0366\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2000.8911 - val_loss: 1501.6964\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1957.0662 - val_loss: 1470.8849\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1910.6505 - val_loss: 1441.6890\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1866.6874 - val_loss: 1414.0024\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1824.5492 - val_loss: 1387.4109\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1783.7755 - val_loss: 1361.7017\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1744.1235 - val_loss: 1336.7556\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1705.4515 - val_loss: 1312.4965\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1667.6658 - val_loss: 1288.8718\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1630.6993 - val_loss: 1265.8430\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1594.5034 - val_loss: 1243.3785\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1559.0385 - val_loss: 1221.4546\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1524.2719 - val_loss: 1200.0497\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1490.1772 - val_loss: 1179.1471\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1456.7321 - val_loss: 1158.7311\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1423.9172 - val_loss: 1138.7880\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1391.7141 - val_loss: 1119.3058\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1360.1080 - val_loss: 1100.2738\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1329.0845 - val_loss: 1081.6813\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1298.6299 - val_loss: 1063.5189\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1268.7330 - val_loss: 1045.7782\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1239.3831 - val_loss: 1028.4507\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1210.5690 - val_loss: 1011.5292\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1182.2817 - val_loss: 995.0060\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1154.5117 - val_loss: 978.8734\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1127.2499 - val_loss: 963.1258\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1100.4883 - val_loss: 947.7559\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1074.2189 - val_loss: 932.7581\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1048.4340 - val_loss: 918.1255\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1023.1264 - val_loss: 903.8535\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 998.2891 - val_loss: 889.9356\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 973.9153 - val_loss: 876.3666\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 949.9983 - val_loss: 863.1409\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 926.5308 - val_loss: 850.2535\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 903.5075 - val_loss: 837.6990\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 880.9217 - val_loss: 825.4728\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 858.7680 - val_loss: 813.5696\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 837.0402 - val_loss: 801.9846\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 815.7321 - val_loss: 790.7128\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 794.8383 - val_loss: 779.7497\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 774.3533 - val_loss: 769.0909\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 754.2721 - val_loss: 758.7318\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 734.5891 - val_loss: 748.6678\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 715.2988 - val_loss: 738.8942\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 696.3961 - val_loss: 729.4070\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 677.8760 - val_loss: 720.2017\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 659.7333 - val_loss: 711.2737\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 641.9634 - val_loss: 702.6193\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 624.5609 - val_loss: 694.2338\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 607.5209 - val_loss: 686.1132\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 590.8391 - val_loss: 678.2534\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 574.5101 - val_loss: 670.6499\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 558.5297 - val_loss: 663.2993\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 542.8929 - val_loss: 656.1971\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 527.5953 - val_loss: 649.3390\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 512.6319 - val_loss: 642.7216\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 497.9984 - val_loss: 636.3403\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 483.6904 - val_loss: 630.1916\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 469.7030 - val_loss: 624.2712\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 456.0320 - val_loss: 618.5754\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 442.6729 - val_loss: 613.1002\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 429.6213 - val_loss: 607.8419\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 416.8729 - val_loss: 602.7962\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 404.4231 - val_loss: 597.9597\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 392.2678 - val_loss: 593.3283\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 380.4025 - val_loss: 588.8984\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 368.8234 - val_loss: 584.6660\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 357.5256 - val_loss: 580.6274\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 346.5052 - val_loss: 576.7787\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 335.7575 - val_loss: 573.1164\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 325.2789 - val_loss: 569.6364\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 315.0652 - val_loss: 566.3354\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 305.1121 - val_loss: 563.2095\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 295.4155 - val_loss: 560.2549\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 285.9710 - val_loss: 557.4681\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 276.7750 - val_loss: 554.8452\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 267.8231 - val_loss: 552.3828\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 259.1111 - val_loss: 550.0770\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 250.6352 - val_loss: 547.9245\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 242.3915 - val_loss: 545.9214\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 234.3760 - val_loss: 544.0644\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 226.5844 - val_loss: 542.3497\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 219.0127 - val_loss: 540.7739\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 211.6572 - val_loss: 539.3333\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 204.5140 - val_loss: 538.0244\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 197.5790 - val_loss: 536.8437\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 190.8486 - val_loss: 535.7877\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 184.3186 - val_loss: 534.8531\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 177.9854 - val_loss: 534.0363\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 171.8447 - val_loss: 533.3339\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 165.8931 - val_loss: 532.7424\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 160.1268 - val_loss: 532.2585\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 154.5420 - val_loss: 531.8790\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 149.1350 - val_loss: 531.6003\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 143.9020 - val_loss: 531.4192\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 138.8393 - val_loss: 531.3323\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 133.9433 - val_loss: 531.3365\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 129.2103 - val_loss: 531.4285\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 124.6366 - val_loss: 531.6050\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 120.2186 - val_loss: 531.8629\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 115.9530 - val_loss: 532.1990\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 111.8360 - val_loss: 532.6102\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 107.8642 - val_loss: 533.0934\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 104.0340 - val_loss: 533.6456\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 100.3421 - val_loss: 534.2635\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 96.7851 - val_loss: 534.9445\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 93.3593 - val_loss: 535.6853\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 90.0617 - val_loss: 536.4832\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 86.8889 - val_loss: 537.3352\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 83.8375 - val_loss: 538.2385\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 80.9043 - val_loss: 539.1902\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 78.0861 - val_loss: 540.1877\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 75.3795 - val_loss: 541.2281\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 72.7816 - val_loss: 542.3089\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 70.2893 - val_loss: 543.4275\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 67.8994 - val_loss: 544.5809\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 65.6090 - val_loss: 545.7671\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 63.4149 - val_loss: 546.9832\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 61.3142 - val_loss: 548.2270\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 59.3043 - val_loss: 549.4958\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 57.3822 - val_loss: 550.7876\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 55.5450 - val_loss: 552.0999\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 53.7899 - val_loss: 553.4305\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 52.1142 - val_loss: 554.7773\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 50.5152 - val_loss: 556.1379\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 48.9905 - val_loss: 557.5104\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 47.5373 - val_loss: 558.8928\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 46.1532 - val_loss: 560.2832\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 44.8357 - val_loss: 561.6794\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 43.5822 - val_loss: 563.0801\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 42.3904 - val_loss: 564.4829\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 41.2580 - val_loss: 565.8864\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 40.1829 - val_loss: 567.2886\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 39.1626 - val_loss: 568.6883\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 38.1950 - val_loss: 570.0836\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 37.2780 - val_loss: 571.4732\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 36.4096 - val_loss: 572.8558\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 35.5877 - val_loss: 574.2296\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 34.8104 - val_loss: 575.5935\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 34.0756 - val_loss: 576.9465\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 33.3816 - val_loss: 578.2873\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 32.7266 - val_loss: 579.6143\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 32.1089 - val_loss: 580.9271\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 31.5266 - val_loss: 582.2242\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 30.9782 - val_loss: 583.5047\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 30.4621 - val_loss: 584.7679\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 29.9768 - val_loss: 586.0130\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 29.5206 - val_loss: 587.2388\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 29.0922 - val_loss: 588.4455\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 28.6902 - val_loss: 589.6316\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 28.3132 - val_loss: 590.7968\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 27.9599 - val_loss: 591.9403\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 27.6293 - val_loss: 593.0623\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 27.3197 - val_loss: 594.1613\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 27.0305 - val_loss: 595.2377\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 26.7603 - val_loss: 596.2908\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 26.5080 - val_loss: 597.3204\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 26.2728 - val_loss: 598.3262\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 26.0536 - val_loss: 599.3085\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.8493 - val_loss: 600.2663\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.6593 - val_loss: 601.2003\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.4826 - val_loss: 602.1098\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.3184 - val_loss: 602.9951\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 25.1660 - val_loss: 603.8561\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.0246 - val_loss: 604.6927\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 24.8936 - val_loss: 605.5054\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 24.7722 - val_loss: 606.2941\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 24.6598 - val_loss: 607.0590\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 24.5560 - val_loss: 607.7999\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 24.4599 - val_loss: 608.5176\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 24.3713 - val_loss: 609.2124\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 24.2894 - val_loss: 609.8837\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 24.2141 - val_loss: 610.5330\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 24.1445 - val_loss: 611.1595\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 24.0806 - val_loss: 611.7642\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 24.0217 - val_loss: 612.3470\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.9676 - val_loss: 612.9089\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.9179 - val_loss: 613.4499\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.8723 - val_loss: 613.9703\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.8304 - val_loss: 614.4705\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.7921 - val_loss: 614.9512\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.7570 - val_loss: 615.4130\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 23.7248 - val_loss: 615.8558\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 23.6953 - val_loss: 616.2805\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 23.6684 - val_loss: 616.6873\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.6439 - val_loss: 617.0769\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.6215 - val_loss: 617.4495\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.6010 - val_loss: 617.8059\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.5824 - val_loss: 618.1464\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.5654 - val_loss: 618.4713\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.5499 - val_loss: 618.7815\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.5358 - val_loss: 619.0770\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.5230 - val_loss: 619.3588\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.5114 - val_loss: 619.6269\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.5009 - val_loss: 619.8820\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4913 - val_loss: 620.1243\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4827 - val_loss: 620.3551\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4749 - val_loss: 620.5739\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4678 - val_loss: 620.7814\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4613 - val_loss: 620.9785\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4555 - val_loss: 621.1646\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4503 - val_loss: 621.3409\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 23.4457 - val_loss: 621.5079\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4414 - val_loss: 621.6655\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4376 - val_loss: 621.8142\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4343 - val_loss: 621.9551\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4312 - val_loss: 622.0876\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4285 - val_loss: 622.2123\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4261 - val_loss: 622.3298\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4240 - val_loss: 622.4407\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4222 - val_loss: 622.5451\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4205 - val_loss: 622.6425\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4191 - val_loss: 622.7344\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4178 - val_loss: 622.8205\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4168 - val_loss: 622.9014\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4159 - val_loss: 622.9771\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4151 - val_loss: 623.0479\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4146 - val_loss: 623.1141\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4141 - val_loss: 623.1759\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 23.4136 - val_loss: 623.2338\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4134 - val_loss: 623.2877\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4131 - val_loss: 623.3380\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4130 - val_loss: 623.3845\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4130 - val_loss: 623.4280\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4131 - val_loss: 623.4684\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4132 - val_loss: 623.5060\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4134 - val_loss: 623.5412\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4135 - val_loss: 623.5734\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4138 - val_loss: 623.6031\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4141 - val_loss: 623.6306\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4145 - val_loss: 623.6563\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4149 - val_loss: 623.6796\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4153 - val_loss: 623.7014\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4158 - val_loss: 623.7211\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4163 - val_loss: 623.7393\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 23.4168 - val_loss: 623.7560\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4174 - val_loss: 623.7716\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4179 - val_loss: 623.7856\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4185 - val_loss: 623.7985\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4191 - val_loss: 623.8103\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4197 - val_loss: 623.8207\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4204 - val_loss: 623.8303\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4210 - val_loss: 623.8390\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4217 - val_loss: 623.8469\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4223 - val_loss: 623.8539\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4230 - val_loss: 623.8601\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4237 - val_loss: 623.8660\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4244 - val_loss: 623.8711\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4251 - val_loss: 623.8753\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4258 - val_loss: 623.8793\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4265 - val_loss: 623.8830\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 23.4271 - val_loss: 623.8856\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4279 - val_loss: 623.8884\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4286 - val_loss: 623.8907\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4293 - val_loss: 623.8924\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4300 - val_loss: 623.8936\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4308 - val_loss: 623.8951\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4314 - val_loss: 623.8959\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4322 - val_loss: 623.8971\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4328 - val_loss: 623.8976\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4336 - val_loss: 623.8984\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4342 - val_loss: 623.8986\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4349 - val_loss: 623.8987\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4356 - val_loss: 623.8986\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4362 - val_loss: 623.8981\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4369 - val_loss: 623.8977\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4376 - val_loss: 623.8970\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4382 - val_loss: 623.8964\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 23.4389 - val_loss: 623.8953\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4396 - val_loss: 623.8945\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4402 - val_loss: 623.8934\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4408 - val_loss: 623.8925\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4415 - val_loss: 623.8914\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4420 - val_loss: 623.8902\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4427 - val_loss: 623.8889\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4433 - val_loss: 623.8879\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4439 - val_loss: 623.8869\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4445 - val_loss: 623.8858\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4450 - val_loss: 623.8842\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4457 - val_loss: 623.8831\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4462 - val_loss: 623.8817\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4467 - val_loss: 623.8804\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4473 - val_loss: 623.8791\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 23.4479 - val_loss: 623.8778\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4484 - val_loss: 623.8763\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4489 - val_loss: 623.8751\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4495 - val_loss: 623.8741\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4500 - val_loss: 623.8725\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4505 - val_loss: 623.8713\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4510 - val_loss: 623.8701\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 23.4515 - val_loss: 623.8690\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 23.4520 - val_loss: 623.8677\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4524 - val_loss: 623.8665\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4529 - val_loss: 623.8654\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4534 - val_loss: 623.8641\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4538 - val_loss: 623.8630\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4543 - val_loss: 623.8615\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 23.4547 - val_loss: 623.8605\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4552 - val_loss: 623.8591\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4556 - val_loss: 623.8581\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4560 - val_loss: 623.8570\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4564 - val_loss: 623.8558\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4568 - val_loss: 623.8544\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4572 - val_loss: 623.8533\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4576 - val_loss: 623.8524\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4580 - val_loss: 623.8514\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4583 - val_loss: 623.8503\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4587 - val_loss: 623.8491\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4591 - val_loss: 623.8482\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4594 - val_loss: 623.8474\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4598 - val_loss: 623.8462\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 23.4601 - val_loss: 623.8452\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4605 - val_loss: 623.8442\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4608 - val_loss: 623.8433\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4611 - val_loss: 623.8424\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4615 - val_loss: 623.8417\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4618 - val_loss: 623.8408\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4620 - val_loss: 623.8398\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4623 - val_loss: 623.8390\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4627 - val_loss: 623.8378\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4630 - val_loss: 623.8369\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4632 - val_loss: 623.8360\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4635 - val_loss: 623.8353\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4637 - val_loss: 623.8344\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 23.4640 - val_loss: 623.8333\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4643 - val_loss: 623.8323\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4646 - val_loss: 623.8320\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4648 - val_loss: 623.8311\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4651 - val_loss: 623.8308\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4653 - val_loss: 623.8301\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4655 - val_loss: 623.8290\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4658 - val_loss: 623.8286\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4660 - val_loss: 623.8278\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4662 - val_loss: 623.8272\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4664 - val_loss: 623.8265\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4667 - val_loss: 623.8259\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4669 - val_loss: 623.8253\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4671 - val_loss: 623.8246\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 23.4673 - val_loss: 623.8242\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4675 - val_loss: 623.8237\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4676 - val_loss: 623.8231\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4678 - val_loss: 623.8221\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4680 - val_loss: 623.8218\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4683 - val_loss: 623.8214\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4684 - val_loss: 623.8208\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4685 - val_loss: 623.8199\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4687 - val_loss: 623.8193\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4689 - val_loss: 623.8188\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4690 - val_loss: 623.8184\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 23.4692 - val_loss: 623.8177\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4693 - val_loss: 623.8173\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4695 - val_loss: 623.8168\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4697 - val_loss: 623.8165\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4698 - val_loss: 623.8157\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4700 - val_loss: 623.8152\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4701 - val_loss: 623.8149\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 23.4702 - val_loss: 623.8144\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4704 - val_loss: 623.8140\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4704 - val_loss: 623.8133\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4706 - val_loss: 623.8130\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4707 - val_loss: 623.8124\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4708 - val_loss: 623.8120\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4710 - val_loss: 623.8118\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4711 - val_loss: 623.8115\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4712 - val_loss: 623.8113\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4713 - val_loss: 623.8107\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4714 - val_loss: 623.8103\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4716 - val_loss: 623.8103\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4716 - val_loss: 623.8100\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4718 - val_loss: 623.8098\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4718 - val_loss: 623.8095\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4719 - val_loss: 623.8092\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4720 - val_loss: 623.8089\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4721 - val_loss: 623.8086\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4722 - val_loss: 623.8083\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 23.4723 - val_loss: 623.8080\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4723 - val_loss: 623.8077\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4725 - val_loss: 623.8074\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4726 - val_loss: 623.8070\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4726 - val_loss: 623.8068\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4727 - val_loss: 623.8063\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4728 - val_loss: 623.8064\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4729 - val_loss: 623.8061\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4729 - val_loss: 623.8056\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4730 - val_loss: 623.8054\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4731 - val_loss: 623.8054\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4731 - val_loss: 623.8052\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4732 - val_loss: 623.8051\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4732 - val_loss: 623.8046\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4733 - val_loss: 623.8043\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4734 - val_loss: 623.8040\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4735 - val_loss: 623.8040\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4735 - val_loss: 623.8038\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4736 - val_loss: 623.8033\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4736 - val_loss: 623.8028\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4737 - val_loss: 623.8027\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 23.4737 - val_loss: 623.8027\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4738 - val_loss: 623.8025\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4738 - val_loss: 623.8022\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4739 - val_loss: 623.8019\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4739 - val_loss: 623.8015\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4740 - val_loss: 623.8014\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4740 - val_loss: 623.8013\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4741 - val_loss: 623.8012\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4741 - val_loss: 623.8011\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4741 - val_loss: 623.8005\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4742 - val_loss: 623.8003\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4742 - val_loss: 623.7998\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4743 - val_loss: 623.7997\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4743 - val_loss: 623.7993\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4744 - val_loss: 623.7995\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4745 - val_loss: 623.7994\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 23.4745 - val_loss: 623.7993\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4745 - val_loss: 623.7993\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4745 - val_loss: 623.7990\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4746 - val_loss: 623.7988\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4746 - val_loss: 623.7985\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4746 - val_loss: 623.7983\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4747 - val_loss: 623.7986\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4747 - val_loss: 623.7985\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4747 - val_loss: 623.7985\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4747 - val_loss: 623.7982\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4748 - val_loss: 623.7980\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4748 - val_loss: 623.7979\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4749 - val_loss: 623.7978\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4749 - val_loss: 623.7977\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4749 - val_loss: 623.7976\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4749 - val_loss: 623.7974\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4749 - val_loss: 623.7971\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4749 - val_loss: 623.7969\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4750 - val_loss: 623.7964\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4751 - val_loss: 623.7968\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 23.4751 - val_loss: 623.7968\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4750 - val_loss: 623.7967\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4751 - val_loss: 623.7963\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4751 - val_loss: 623.7961\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4752 - val_loss: 623.7960\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4752 - val_loss: 623.7959\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4752 - val_loss: 623.7959\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4752 - val_loss: 623.7958\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4752 - val_loss: 623.7957\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4752 - val_loss: 623.7956\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4752 - val_loss: 623.7955\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4753 - val_loss: 623.7955\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4753 - val_loss: 623.7954\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.4753 - val_loss: 623.7954\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 428ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.59267040e+01, 6.58949346e+01, 6.58865313e+01, 6.58781279e+01,\n",
       "        6.58697246e+01, 6.58613120e+01, 6.58529178e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.45789182e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.65466853e+01, 6.64794584e+01, 6.64122316e+01,\n",
       "        6.63450047e+01, 6.62777778e+01, 6.62105509e+01, 6.61433240e+01,\n",
       "        6.60760971e+01, 6.60088702e+01, 6.59416433e+01, 6.58968021e+01,\n",
       "        6.58883987e+01, 6.58799953e+01, 6.58715920e+01, 6.58631886e+01,\n",
       "        6.58547853e+01, 6.58463832e+01, 6.58379785e+01, 6.58295752e+01,\n",
       "        6.58211718e+01, 6.58127684e+01, 6.58043651e+01, 6.57717320e+01,\n",
       "        6.57129085e+01, 6.56540850e+01, 6.55952614e+01, 6.55364379e+01,\n",
       "        3.73059140e-02, 0.00000000e+00, 0.00000000e+00, 4.39866573e-01,\n",
       "        5.85228086e-01, 2.09774360e-01, 0.00000000e+00, 6.58818627e+01,\n",
       "        6.58734594e+01, 6.58650559e+01, 6.58566527e+01, 6.58482493e+01,\n",
       "        6.58398459e+01, 6.58314426e+01, 6.58230392e+01, 6.58146359e+01,\n",
       "        6.58062325e+01, 6.57848039e+01, 6.57259804e+01, 6.56671569e+01,\n",
       "        6.56083333e+01, 6.55495098e+01, 6.88817227e+01, 6.86044118e+01,\n",
       "        6.83271008e+01, 6.80051681e+01, 6.77170168e+01, 6.74288640e+01,\n",
       "        6.71407092e+01, 6.68525544e+01, 6.65643996e+01, 6.62762448e+01,\n",
       "        6.59880900e+01, 7.32098160e+01, 3.24641020e-02, 0.00000000e+00,\n",
       "        6.82716072e-01, 8.46212447e-01, 1.20992875e+00, 0.00000000e+00,\n",
       "        6.40868454e+01, 0.00000000e+00, 0.00000000e+00, 1.20349765e+00,\n",
       "        0.00000000e+00, 6.62251770e-01, 8.49326968e-01, 7.79961199e-02,\n",
       "        1.96450144e-01, 1.74010456e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.88107230e-03, 2.87670821e-01, 0.00000000e+00,\n",
       "        6.85558319e-01, 0.00000000e+00, 2.96425223e-01, 1.59096912e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60.78084307, 60.77291795, 60.76499283, 60.75706771, 60.74914258,\n",
       "       60.74121746, 60.73329234, 60.72536722, 60.7174421 , 60.70951698,\n",
       "       60.70159186, 60.69366673, 60.68574161, 60.67781649, 60.66989137,\n",
       "       60.66196625, 60.65404113, 60.64611601, 60.63819089, 60.63026576,\n",
       "       60.62234064, 60.61441552, 60.6064904 , 60.59856528, 60.59064016,\n",
       "       60.58271504, 60.57478992, 60.56686479, 60.55893967, 60.55101455,\n",
       "       60.54308943, 60.53516431, 60.52723919, 60.51931407, 60.51138895,\n",
       "       60.50346382, 60.4955387 , 60.48761358, 60.47968846, 60.47176334,\n",
       "       60.46383822, 60.4559131 , 60.44798798, 60.44006285, 60.43213773,\n",
       "       60.42421261, 60.41628749, 60.40836237, 60.40043725, 60.39251213,\n",
       "       60.38458701, 60.37666188, 60.36873676, 60.36081164, 60.35288652,\n",
       "       60.3449614 , 60.33703628, 60.32911116, 60.32118604, 60.31326091,\n",
       "       60.30533579, 60.29741067, 60.28948555, 60.28156043, 60.27363531,\n",
       "       60.26571019, 60.25778507, 60.24985994, 60.24193482, 60.2340097 ,\n",
       "       60.22608458, 60.21815946, 60.21023434, 60.20230922, 60.1943841 ,\n",
       "       60.18645897, 60.17853385, 60.17060873, 60.16268361, 60.15475849,\n",
       "       60.14683337, 60.13890825, 60.13098312, 60.123058  , 60.11513288,\n",
       "       60.10720776, 60.09928264, 60.09135752, 60.0834324 , 60.07550728,\n",
       "       60.06758215, 60.05965703, 60.05173191, 60.04380679, 60.03588167,\n",
       "       60.02795655, 60.02003143, 60.01210631, 60.00418118, 59.99625606])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.287457397413036\n",
      "26.392006312682625\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
