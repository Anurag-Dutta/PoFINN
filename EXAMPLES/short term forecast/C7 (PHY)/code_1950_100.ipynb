{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2045    66.063480\n",
       "2046    66.053676\n",
       "2047    66.043873\n",
       "2048    66.034069\n",
       "2049    66.024265\n",
       "Name: C7, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c7_interpolated_1950_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "1945     0.532064\n",
       "1946     0.462526\n",
       "1947     0.000000\n",
       "1948     0.000000\n",
       "1949     0.000000\n",
       "Name: C7, Length: 1950, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1950)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.387115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.174230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.961345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.748459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     92.600000  0.000298\n",
       "1     92.387115  0.000298\n",
       "2     92.174230  0.000297\n",
       "3     91.961345  0.000297\n",
       "4     91.748459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 89.3180  # Value for C0\n",
    "K0 = -0.0010  # Value for K0\n",
    "K1 = 0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = -0.0204    # Value for b\n",
    "c = 2.2194    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    92.600000    92.387115    92.174230    91.961345    91.748459   \n",
      "351    92.387115    92.174230    91.961345    91.748459    91.535574   \n",
      "352    92.174230    91.961345    91.748459    91.535574    91.322689   \n",
      "353    91.961345    91.748459    91.535574    91.322689    91.109804   \n",
      "354    91.748459    91.535574    91.322689    91.109804    90.896919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    91.535574    91.322689    91.109804    90.896919    90.691597  ...   \n",
      "351    91.322689    91.109804    90.896919    90.691597    90.579552  ...   \n",
      "352    91.109804    90.896919    90.691597    90.579552    90.467507  ...   \n",
      "353    90.896919    90.691597    90.579552    90.467507    90.355462  ...   \n",
      "354    90.691597    90.579552    90.467507    90.355462    90.243417  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   80.261671    0.000263   80.252334    0.000263   80.242997    0.000263   \n",
      "351   80.252334    0.000263   80.242997    0.000263   80.233660    0.000262   \n",
      "352   80.242997    0.000263   80.233660    0.000262   80.224323    0.000262   \n",
      "353   80.233660    0.000262   80.224323    0.000262   80.214986    0.000262   \n",
      "354   80.224323    0.000262   80.214986    0.000262   80.205649    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   80.233660    0.000262   80.224323    0.000262  \n",
      "351   80.224323    0.000262   80.214986    0.000262  \n",
      "352   80.214986    0.000262   80.205649    0.000262  \n",
      "353   80.205649    0.000262   80.196312    0.000262  \n",
      "354   80.196312    0.000262   80.186975    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1, 251) (1500, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 2s 24ms/step - loss: 5613.1255 - val_loss: 4508.0186\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5527.3848 - val_loss: 4446.5679\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5465.3413 - val_loss: 4392.0430\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5405.0498 - val_loss: 4338.0542\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5345.3408 - val_loss: 4284.6216\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5286.1973 - val_loss: 4231.7153\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5227.5923 - val_loss: 4179.3140\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5158.4219 - val_loss: 4113.4375\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5094.2686 - val_loss: 4058.0166\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 5033.0752 - val_loss: 4003.7422\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4973.0044 - val_loss: 3950.3892\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4913.8340 - val_loss: 3897.8013\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4855.4263 - val_loss: 3845.8870\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4797.6987 - val_loss: 3794.5908\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4740.6035 - val_loss: 3743.8774\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4684.1050 - val_loss: 3693.7200\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4628.1792 - val_loss: 3644.1001\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4572.8071 - val_loss: 3595.0029\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 4517.9746 - val_loss: 3546.4163\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4463.6689 - val_loss: 3498.3301\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4409.8794 - val_loss: 3450.7344\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4356.5996 - val_loss: 3403.6233\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4303.8198 - val_loss: 3356.9900\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4251.5327 - val_loss: 3310.8274\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4199.7344 - val_loss: 3265.1311\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4148.4170 - val_loss: 3219.8943\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4097.5757 - val_loss: 3175.1125\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4047.2063 - val_loss: 3130.7822\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3997.3042 - val_loss: 3086.8987\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3947.8633 - val_loss: 3043.4573\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3898.8821 - val_loss: 3000.4541\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3850.3533 - val_loss: 2957.8862\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3802.2754 - val_loss: 2915.7485\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3754.6438 - val_loss: 2874.0386\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3707.4546 - val_loss: 2832.7524\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3660.7051 - val_loss: 2791.8870\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3614.3916 - val_loss: 2751.4375\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3568.5095 - val_loss: 2711.4038\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3523.0576 - val_loss: 2671.7791\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3478.0308 - val_loss: 2632.5625\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3433.4268 - val_loss: 2593.7507\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3389.2422 - val_loss: 2555.3398\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3345.4741 - val_loss: 2517.3281\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3302.1199 - val_loss: 2479.7117\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3259.1755 - val_loss: 2442.4878\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3216.6399 - val_loss: 2405.6538\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3174.5083 - val_loss: 2369.2070\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3132.7791 - val_loss: 2333.1450\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3091.4487 - val_loss: 2297.4639\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3050.5144 - val_loss: 2262.1619\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3009.9736 - val_loss: 2227.2366\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2969.8242 - val_loss: 2192.6843\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2930.0627 - val_loss: 2158.5029\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2890.6868 - val_loss: 2124.6897\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2851.6936 - val_loss: 2091.2417\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2813.0808 - val_loss: 2058.1575\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2774.8459 - val_loss: 2025.4340\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2736.9866 - val_loss: 1993.0685\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2699.5000 - val_loss: 1961.0587\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2662.3828 - val_loss: 1929.4023\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2625.6338 - val_loss: 1898.0964\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2589.2502 - val_loss: 1867.1388\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2553.2297 - val_loss: 1836.5273\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2517.5688 - val_loss: 1806.2588\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2482.2666 - val_loss: 1776.3317\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2447.3203 - val_loss: 1746.7440\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2412.7271 - val_loss: 1717.4927\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2378.4851 - val_loss: 1688.5754\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2344.5916 - val_loss: 1659.9907\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2311.0449 - val_loss: 1631.7355\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2277.8423 - val_loss: 1603.8069\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2244.9810 - val_loss: 1576.2040\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2212.4595 - val_loss: 1548.9240\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2180.2756 - val_loss: 1521.9641\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2148.4268 - val_loss: 1495.3236\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2116.9104 - val_loss: 1468.9987\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2085.7251 - val_loss: 1442.9877\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2054.8684 - val_loss: 1417.2892\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2024.3381 - val_loss: 1391.9000\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1994.1318 - val_loss: 1366.8186\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1964.2482 - val_loss: 1342.0425\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1934.6840 - val_loss: 1317.5695\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1905.4375 - val_loss: 1293.3987\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1876.5071 - val_loss: 1269.5260\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1847.8900 - val_loss: 1245.9508\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1819.5844 - val_loss: 1222.6707\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1791.5885 - val_loss: 1199.6831\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1763.9004 - val_loss: 1176.9861\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1736.5175 - val_loss: 1154.5786\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1709.4379 - val_loss: 1132.4575\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1682.6598 - val_loss: 1110.6215\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1656.1809 - val_loss: 1089.0675\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1629.9996 - val_loss: 1067.7947\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1604.1136 - val_loss: 1046.8013\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1578.5216 - val_loss: 1026.0841\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1553.2206 - val_loss: 1005.6418\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1528.2091 - val_loss: 985.4724\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1503.4850 - val_loss: 965.5729\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1479.0468 - val_loss: 945.9432\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1454.8922 - val_loss: 926.5805\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1431.0193 - val_loss: 907.4824\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1407.4260 - val_loss: 888.6474\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1384.1113 - val_loss: 870.0739\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1361.0723 - val_loss: 851.7590\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1338.3073 - val_loss: 833.7020\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1315.8146 - val_loss: 815.9003\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1293.5924 - val_loss: 798.3510\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1271.6385 - val_loss: 781.0549\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1249.9520 - val_loss: 764.0076\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1228.5299 - val_loss: 747.2090\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1207.3711 - val_loss: 730.6554\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1186.4730 - val_loss: 714.3465\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1165.8339 - val_loss: 698.2795\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1145.4528 - val_loss: 682.4526\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1125.3267 - val_loss: 666.8637\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1105.4548 - val_loss: 651.5125\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1085.8348 - val_loss: 636.3951\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1066.4648 - val_loss: 621.5116\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1047.3433 - val_loss: 606.8585\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1028.4685 - val_loss: 592.4348\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1009.8384 - val_loss: 578.2388\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 991.4515 - val_loss: 564.2683\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 973.3058 - val_loss: 550.5215\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 955.3996 - val_loss: 536.9966\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 937.7314 - val_loss: 523.6921\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 920.2988 - val_loss: 510.6058\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 903.1003 - val_loss: 497.7359\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 886.1347 - val_loss: 485.0810\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 869.3992 - val_loss: 472.6385\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 852.8926 - val_loss: 460.4080\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 836.6135 - val_loss: 448.3856\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 820.5595 - val_loss: 436.5719\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 804.7296 - val_loss: 424.9631\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 789.1216 - val_loss: 413.5584\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 773.7334 - val_loss: 402.3559\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 758.5639 - val_loss: 391.3539\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 743.6113 - val_loss: 380.5502\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 728.8734 - val_loss: 369.9432\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 714.3488 - val_loss: 359.5312\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 700.0358 - val_loss: 349.3125\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 685.9327 - val_loss: 339.2855\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 672.0378 - val_loss: 329.4478\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 658.3492 - val_loss: 319.7980\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 644.8652 - val_loss: 310.3342\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 631.5847 - val_loss: 301.0550\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 618.5050 - val_loss: 291.9583\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 605.6254 - val_loss: 283.0425\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 592.9435 - val_loss: 274.3051\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 580.4576 - val_loss: 265.7453\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 568.1664 - val_loss: 257.3616\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 556.0684 - val_loss: 249.1508\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 544.1610 - val_loss: 241.1122\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 532.4431 - val_loss: 233.2437\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 520.9130 - val_loss: 225.5434\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 509.5687 - val_loss: 218.0099\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 498.4087 - val_loss: 210.6410\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 487.4314 - val_loss: 203.4356\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 476.6352 - val_loss: 196.3912\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 466.0183 - val_loss: 189.5067\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 455.5793 - val_loss: 182.7798\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 445.3156 - val_loss: 176.2089\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 435.2265 - val_loss: 169.7922\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 425.3099 - val_loss: 163.5283\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 415.5643 - val_loss: 157.4151\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 405.9879 - val_loss: 151.4507\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 396.5789 - val_loss: 145.6338\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 387.3357 - val_loss: 139.9621\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 378.2567 - val_loss: 134.4345\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 369.3401 - val_loss: 129.0483\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 360.5844 - val_loss: 123.8026\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 351.9880 - val_loss: 118.6955\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 343.5492 - val_loss: 113.7251\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 335.2659 - val_loss: 108.8892\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 327.1366 - val_loss: 104.1867\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 319.1602 - val_loss: 99.6157\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 311.3342 - val_loss: 95.1741\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 303.6574 - val_loss: 90.8606\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 296.1284 - val_loss: 86.6734\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 288.7453 - val_loss: 82.6105\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 281.5061 - val_loss: 78.6702\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 274.4092 - val_loss: 74.8508\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 267.4534 - val_loss: 71.1505\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 260.6367 - val_loss: 67.5674\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 253.9570 - val_loss: 64.1003\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 247.4137 - val_loss: 60.7471\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 241.0046 - val_loss: 57.5061\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 234.7280 - val_loss: 54.3753\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 228.5825 - val_loss: 51.3536\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 222.5662 - val_loss: 48.4385\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 216.6775 - val_loss: 45.6291\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 210.9148 - val_loss: 42.9228\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 205.2764 - val_loss: 40.3185\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 199.7606 - val_loss: 37.8141\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 194.3660 - val_loss: 35.4081\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 189.0909 - val_loss: 33.0989\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 183.9335 - val_loss: 30.8844\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 178.8923 - val_loss: 28.7632\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 173.9659 - val_loss: 26.7335\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 169.1524 - val_loss: 24.7938\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 164.4503 - val_loss: 22.9419\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 159.8577 - val_loss: 21.1764\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 155.3732 - val_loss: 19.4960\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 150.9957 - val_loss: 17.8986\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 146.7230 - val_loss: 16.3824\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 142.5534 - val_loss: 14.9460\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 138.4859 - val_loss: 13.5876\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 134.5184 - val_loss: 12.3057\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 130.6498 - val_loss: 11.0984\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126.8779 - val_loss: 9.9643\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 123.2017 - val_loss: 8.9017\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 119.6193 - val_loss: 7.9088\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 116.1291 - val_loss: 6.9842\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 112.7300 - val_loss: 6.1262\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 109.4201 - val_loss: 5.3331\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 106.1977 - val_loss: 4.6034\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 103.0617 - val_loss: 3.9355\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 100.0103 - val_loss: 3.3279\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 97.0421 - val_loss: 2.7789\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 94.1556 - val_loss: 2.2870\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 91.3493 - val_loss: 1.8506\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 88.6214 - val_loss: 1.4682\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 85.9709 - val_loss: 1.1383\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 83.3961 - val_loss: 0.8593\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 80.8955 - val_loss: 0.6299\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 78.4678 - val_loss: 0.4483\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 76.1114 - val_loss: 0.3133\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 73.8249 - val_loss: 0.2233\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 71.6069 - val_loss: 0.1768\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 69.4560 - val_loss: 0.1725\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 67.3709 - val_loss: 0.2089\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 65.3500 - val_loss: 0.2845\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 63.3920 - val_loss: 0.3981\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 61.4957 - val_loss: 0.5482\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 59.6593 - val_loss: 0.7333\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 57.8820 - val_loss: 0.9523\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 56.1620 - val_loss: 1.2038\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 54.4982 - val_loss: 1.4863\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 52.8894 - val_loss: 1.7988\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 51.3342 - val_loss: 2.1397\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 49.8314 - val_loss: 2.5080\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 48.3795 - val_loss: 2.9023\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 46.9775 - val_loss: 3.3214\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 45.6240 - val_loss: 3.7639\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 44.3179 - val_loss: 4.2290\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 43.0580 - val_loss: 4.7153\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 41.8428 - val_loss: 5.2217\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 40.6715 - val_loss: 5.7470\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 39.5428 - val_loss: 6.2900\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 38.4556 - val_loss: 6.8499\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 37.4085 - val_loss: 7.4253\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 36.4007 - val_loss: 8.0154\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 35.4310 - val_loss: 8.6192\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 34.4984 - val_loss: 9.2352\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.6018 - val_loss: 9.8630\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 32.7401 - val_loss: 10.5013\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.9122 - val_loss: 11.1493\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 31.1172 - val_loss: 11.8059\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.3541 - val_loss: 12.4704\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.6219 - val_loss: 13.1418\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 28.9197 - val_loss: 13.8193\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 28.2464 - val_loss: 14.5021\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 27.6010 - val_loss: 15.1894\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 26.9830 - val_loss: 15.8803\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 26.3912 - val_loss: 16.5738\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 25.8248 - val_loss: 17.2694\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 25.2830 - val_loss: 17.9667\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 24.7648 - val_loss: 18.6645\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 24.2694 - val_loss: 19.3626\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 23.7962 - val_loss: 20.0599\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 23.3443 - val_loss: 20.7561\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 22.9129 - val_loss: 21.4503\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 22.5012 - val_loss: 22.1421\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 22.1087 - val_loss: 22.8311\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.7345 - val_loss: 23.5163\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.3778 - val_loss: 24.1977\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.0383 - val_loss: 24.8743\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 20.7150 - val_loss: 25.5459\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.4075 - val_loss: 26.2122\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.1150 - val_loss: 26.8725\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.8369 - val_loss: 27.5267\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.5727 - val_loss: 28.1743\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.3217 - val_loss: 28.8146\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.0836 - val_loss: 29.4476\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.8576 - val_loss: 30.0727\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.6433 - val_loss: 30.6901\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.4402 - val_loss: 31.2994\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.2477 - val_loss: 31.8999\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.0655 - val_loss: 32.4917\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.8930 - val_loss: 33.0743\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.7299 - val_loss: 33.6478\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.5757 - val_loss: 34.2117\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.4299 - val_loss: 34.7663\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.2922 - val_loss: 35.3111\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.1622 - val_loss: 35.8461\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.0395 - val_loss: 36.3710\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.9238 - val_loss: 36.8858\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.8147 - val_loss: 37.3904\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 16.7120 - val_loss: 37.8848\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.6152 - val_loss: 38.3691\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.5241 - val_loss: 38.8428\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.4383 - val_loss: 39.3063\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.3577 - val_loss: 39.7594\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.2819 - val_loss: 40.2020\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.2108 - val_loss: 40.6345\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.1439 - val_loss: 41.0565\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.0811 - val_loss: 41.4681\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.0222 - val_loss: 41.8695\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.9670 - val_loss: 42.2609\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.9152 - val_loss: 42.6419\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.8668 - val_loss: 43.0126\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.8214 - val_loss: 43.3736\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.7789 - val_loss: 43.7248\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.7392 - val_loss: 44.0659\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.7020 - val_loss: 44.3976\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.6672 - val_loss: 44.7196\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.6347 - val_loss: 45.0321\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.6044 - val_loss: 45.3351\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.5761 - val_loss: 45.6289\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.5497 - val_loss: 45.9136\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.5251 - val_loss: 46.1895\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 15.5021 - val_loss: 46.4565\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.4807 - val_loss: 46.7149\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.4607 - val_loss: 46.9650\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.4422 - val_loss: 47.2065\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.4249 - val_loss: 47.4402\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.4088 - val_loss: 47.6658\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.3938 - val_loss: 47.8834\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.3799 - val_loss: 48.0935\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.3669 - val_loss: 48.2960\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.3549 - val_loss: 48.4913\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.3437 - val_loss: 48.6793\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.3333 - val_loss: 48.8605\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.3236 - val_loss: 49.0346\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.3147 - val_loss: 49.2025\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.3064 - val_loss: 49.3640\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2987 - val_loss: 49.5187\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2915 - val_loss: 49.6677\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2849 - val_loss: 49.8108\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 15.2787 - val_loss: 49.9479\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2731 - val_loss: 50.0795\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2678 - val_loss: 50.2056\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2629 - val_loss: 50.3265\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2584 - val_loss: 50.4423\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2542 - val_loss: 50.5531\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2504 - val_loss: 50.6592\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2468 - val_loss: 50.7604\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2435 - val_loss: 50.8573\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2404 - val_loss: 50.9500\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2376 - val_loss: 51.0386\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2350 - val_loss: 51.1230\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2326 - val_loss: 51.2033\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2304 - val_loss: 51.2801\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2284 - val_loss: 51.3533\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2265 - val_loss: 51.4231\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2248 - val_loss: 51.4895\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2232 - val_loss: 51.5524\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 15.2218 - val_loss: 51.6125\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2205 - val_loss: 51.6696\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2193 - val_loss: 51.7238\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2182 - val_loss: 51.7753\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2172 - val_loss: 51.8242\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2162 - val_loss: 51.8705\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2154 - val_loss: 51.9146\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2146 - val_loss: 51.9560\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2140 - val_loss: 51.9957\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2134 - val_loss: 52.0330\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15.2128 - val_loss: 52.0682\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2124 - val_loss: 52.1016\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2119 - val_loss: 52.1330\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2116 - val_loss: 52.1627\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2112 - val_loss: 52.1908\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2110 - val_loss: 52.2175\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2107 - val_loss: 52.2422\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2105 - val_loss: 52.2657\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 15.2104 - val_loss: 52.2877\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2102 - val_loss: 52.3087\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2102 - val_loss: 52.3283\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2101 - val_loss: 52.3468\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2101 - val_loss: 52.3640\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2101 - val_loss: 52.3806\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2101 - val_loss: 52.3957\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2101 - val_loss: 52.4103\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2102 - val_loss: 52.4234\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2103 - val_loss: 52.4362\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2104 - val_loss: 52.4478\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2105 - val_loss: 52.4588\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2106 - val_loss: 52.4690\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2108 - val_loss: 52.4786\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2109 - val_loss: 52.4876\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2111 - val_loss: 52.4956\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2113 - val_loss: 52.5029\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 15.2115 - val_loss: 52.5104\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2117 - val_loss: 52.5171\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2120 - val_loss: 52.5235\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2122 - val_loss: 52.5288\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2125 - val_loss: 52.5344\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2127 - val_loss: 52.5394\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2129 - val_loss: 52.5436\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2133 - val_loss: 52.5479\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2135 - val_loss: 52.5515\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2138 - val_loss: 52.5551\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2141 - val_loss: 52.5586\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 15.2144 - val_loss: 52.5615\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2146 - val_loss: 52.5642\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2149 - val_loss: 52.5666\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2152 - val_loss: 52.5688\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2155 - val_loss: 52.5707\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2159 - val_loss: 52.5727\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 15.2162 - val_loss: 52.5744\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2165 - val_loss: 52.5761\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2168 - val_loss: 52.5773\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2171 - val_loss: 52.5785\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2174 - val_loss: 52.5795\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2178 - val_loss: 52.5805\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2180 - val_loss: 52.5816\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2184 - val_loss: 52.5820\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2187 - val_loss: 52.5829\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2190 - val_loss: 52.5834\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2193 - val_loss: 52.5836\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2197 - val_loss: 52.5841\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 15.2199 - val_loss: 52.5845\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2203 - val_loss: 52.5848\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2206 - val_loss: 52.5849\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2209 - val_loss: 52.5850\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2212 - val_loss: 52.5851\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 15.2215 - val_loss: 52.5851\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 15.2218 - val_loss: 52.5850\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2222 - val_loss: 52.5849\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2225 - val_loss: 52.5849\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2228 - val_loss: 52.5847\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2231 - val_loss: 52.5843\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2234 - val_loss: 52.5839\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2237 - val_loss: 52.5837\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2240 - val_loss: 52.5835\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2243 - val_loss: 52.5833\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2246 - val_loss: 52.5830\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2250 - val_loss: 52.5828\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2253 - val_loss: 52.5825\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2255 - val_loss: 52.5822\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2258 - val_loss: 52.5819\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 15.2261 - val_loss: 52.5816\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2264 - val_loss: 52.5808\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2267 - val_loss: 52.5803\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2269 - val_loss: 52.5798\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2272 - val_loss: 52.5792\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2275 - val_loss: 52.5787\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2278 - val_loss: 52.5784\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2281 - val_loss: 52.5783\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2284 - val_loss: 52.5776\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2286 - val_loss: 52.5772\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2289 - val_loss: 52.5769\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2292 - val_loss: 52.5764\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2294 - val_loss: 52.5761\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 15.2296 - val_loss: 52.5755\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2299 - val_loss: 52.5753\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2302 - val_loss: 52.5749\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2304 - val_loss: 52.5742\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2307 - val_loss: 52.5739\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2309 - val_loss: 52.5737\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2311 - val_loss: 52.5732\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2314 - val_loss: 52.5729\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2317 - val_loss: 52.5724\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2319 - val_loss: 52.5722\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2321 - val_loss: 52.5716\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2323 - val_loss: 52.5709\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 15.2326 - val_loss: 52.5707\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 15.2328 - val_loss: 52.5703\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 15.2330 - val_loss: 52.5700\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2332 - val_loss: 52.5693\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2334 - val_loss: 52.5690\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2336 - val_loss: 52.5686\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2339 - val_loss: 52.5682\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2341 - val_loss: 52.5678\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2343 - val_loss: 52.5675\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2345 - val_loss: 52.5670\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2347 - val_loss: 52.5665\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2349 - val_loss: 52.5659\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2351 - val_loss: 52.5655\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2353 - val_loss: 52.5653\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2355 - val_loss: 52.5645\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 15.2357 - val_loss: 52.5643\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2359 - val_loss: 52.5642\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2360 - val_loss: 52.5639\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2362 - val_loss: 52.5636\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2364 - val_loss: 52.5632\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2366 - val_loss: 52.5628\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2367 - val_loss: 52.5625\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2369 - val_loss: 52.5622\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2371 - val_loss: 52.5617\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2373 - val_loss: 52.5613\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2374 - val_loss: 52.5610\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2376 - val_loss: 52.5607\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2377 - val_loss: 52.5605\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2379 - val_loss: 52.5601\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 15.2381 - val_loss: 52.5595\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2383 - val_loss: 52.5594\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2384 - val_loss: 52.5593\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2385 - val_loss: 52.5590\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.2387 - val_loss: 52.5588\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2388 - val_loss: 52.5585\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(89.3180, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0010, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(-0.0204, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.2194, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 344ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.93658497e+01, 6.93462418e+01, 6.93266340e+01, 6.93070261e+01,\n",
       "        6.92874183e+01, 6.92678105e+01, 6.92482026e+01, 6.92285948e+01,\n",
       "        6.92089869e+01, 6.91893791e+01, 6.91697712e+01, 6.91501634e+01,\n",
       "        6.91305556e+01, 6.91109477e+01, 6.90913399e+01, 6.90717320e+01,\n",
       "        6.90521242e+01, 6.90325163e+01, 6.90129085e+01, 6.89933006e+01,\n",
       "        6.89736928e+01, 6.89540850e+01, 6.89344771e+01, 6.89148693e+01,\n",
       "        6.88952614e+01, 6.88756536e+01, 6.88560458e+01, 6.88364379e+01,\n",
       "        6.88168301e+01, 6.87996032e+01, 6.87968020e+01, 6.87940009e+01,\n",
       "        6.87911998e+01, 6.87883987e+01, 6.87855976e+01, 6.87827965e+01,\n",
       "        6.87799953e+01, 6.87771942e+01, 6.87743931e+01, 6.87715920e+01,\n",
       "        6.87687909e+01, 6.87659897e+01, 6.87631886e+01, 6.87603875e+01,\n",
       "        6.87575864e+01, 6.87547852e+01, 6.87519841e+01, 6.87491830e+01,\n",
       "        6.87463819e+01, 6.87435808e+01, 6.87407796e+01, 6.87379785e+01,\n",
       "        6.87351774e+01, 6.87323763e+01, 6.87295752e+01, 6.87267740e+01,\n",
       "        6.87239729e+01, 6.87211718e+01, 6.87183707e+01, 6.87155696e+01,\n",
       "        6.87127684e+01, 6.87099673e+01, 6.87071662e+01, 6.87043651e+01,\n",
       "        6.87015640e+01, 6.86975257e+01, 6.86919234e+01, 6.86863212e+01,\n",
       "        6.86807189e+01, 6.86751167e+01, 6.86695145e+01, 6.86639122e+01,\n",
       "        6.86583100e+01, 6.86527078e+01, 6.86471055e+01, 6.86415033e+01,\n",
       "        6.86359010e+01, 6.86302988e+01, 6.86246965e+01, 6.86190943e+01,\n",
       "        7.62621536e+01, 6.57019556e-01, 6.48319602e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.85755324e-01, 4.60117221e-01, 1.29119039e-01,\n",
       "        1.31787643e-01, 1.97250485e-01, 0.00000000e+00, 6.64164007e-01,\n",
       "        1.50189400e-02, 0.00000000e+00, 6.79823518e-01, 6.54026628e-01,\n",
       "        3.83702815e-01, 0.00000000e+00, 0.00000000e+00, 1.60945788e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66.99485294, 66.98504902, 66.9752451 , 66.96544118, 66.95563725,\n",
       "       66.94583333, 66.93602941, 66.92622549, 66.91642157, 66.90661765,\n",
       "       66.89681373, 66.8870098 , 66.87720588, 66.86740196, 66.85759804,\n",
       "       66.84779412, 66.8379902 , 66.82818627, 66.81838235, 66.80857843,\n",
       "       66.79877451, 66.78897059, 66.77916667, 66.76936275, 66.75955882,\n",
       "       66.7497549 , 66.73995098, 66.73014706, 66.72034314, 66.71053922,\n",
       "       66.70073529, 66.69093137, 66.68112745, 66.67132353, 66.66151961,\n",
       "       66.65171569, 66.64191176, 66.63210784, 66.62230392, 66.6125    ,\n",
       "       66.60269608, 66.59289216, 66.58308824, 66.57328431, 66.56348039,\n",
       "       66.55367647, 66.54387255, 66.53406863, 66.52426471, 66.51446078,\n",
       "       66.50465686, 66.49485294, 66.48504902, 66.4752451 , 66.46544118,\n",
       "       66.45563725, 66.44583333, 66.43602941, 66.42622549, 66.41642157,\n",
       "       66.40661765, 66.39681373, 66.3870098 , 66.37720588, 66.36740196,\n",
       "       66.35759804, 66.34779412, 66.3379902 , 66.32818627, 66.31838235,\n",
       "       66.30857843, 66.29877451, 66.28897059, 66.27916667, 66.26936275,\n",
       "       66.25955882, 66.2497549 , 66.23995098, 66.23014706, 66.22034314,\n",
       "       66.21053922, 66.20073529, 66.19093137, 66.18112745, 66.17132353,\n",
       "       66.16151961, 66.15171569, 66.14191176, 66.13210784, 66.12230392,\n",
       "       66.1125    , 66.10269608, 66.09289216, 66.08308824, 66.07328431,\n",
       "       66.06348039, 66.05367647, 66.04387255, 66.03406863, 66.02426471])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.785271926362583\n",
      "14.408587351511992\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
