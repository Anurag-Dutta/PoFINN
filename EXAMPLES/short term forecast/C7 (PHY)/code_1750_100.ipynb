{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "1845    68.127731\n",
       "1846    68.116527\n",
       "1847    68.105322\n",
       "1848    68.094118\n",
       "1849    68.082913\n",
       "Name: C7, Length: 1850, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c7_interpolated_1750_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "1645    68.755719\n",
       "1646    68.754785\n",
       "1647    68.753852\n",
       "1648    68.752918\n",
       "1649    68.751984\n",
       "Name: C7, Length: 1650, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1650)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.387115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.174230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.961345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.748459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     92.600000  0.000298\n",
       "1     92.387115  0.000298\n",
       "2     92.174230  0.000297\n",
       "3     91.961345  0.000297\n",
       "4     91.748459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnOElEQVR4nO3deXhV5bn+8e+TGUISyMQ8gyg4gIRJAbW2ilZFW2sRxzpQtba1tqcHj+d0sNPP054OVqrVqnXCuVa0KtoKKihIQOZBQhhCmAJhHgJJnt8fe6HbNAFChrWT3J/rWlfWfteQZ68r7Ju13rXfZe6OiIhIdeLCLkBERGKXQkJERGqkkBARkRopJEREpEYKCRERqVFC2AXUp+zsbO/Ro0fYZYiINClz587d6u451S1rViHRo0cP8vPzwy5DRKRJMbO1NS3T5SYREamRQkJERGqkkBARkRopJEREpEYKCRERqZFCQkREaqSQEBGRGikkgDlrSrn3zeVo2HQRkc9TSAALinbwwPRV7Nx/KOxSRERiikICaJ+eAsCW3WUhVyIiElsUEkBuWjIAW3YpJEREoikkgNzgTGLzrgMhVyIiElsUEkSdSehyk4jI5ygkgNTkBFKT4tmyW2cSIiLRFBKB9ukpOpMQEalCIRHISUtmi/okREQ+RyERyNWZhIjIv6mXkDCzMWa2wswKzGxiNctHm9k8Mys3s8uj2gea2YdmtsTMFprZ16OW/dXMVpvZ/GAaWB+11iQ3LZktu8r0rWsRkSh1fnypmcUDk4AvAeuBOWY2xd2XRq22Drge+EGVzfcB17r7SjPrBMw1s6nuviNY/h/u/mJdazwWuWnJ7D9UwZ6yctJSEhvjV4qIxLz6eMb1UKDA3QsBzOxZYCzwaUi4+5pgWWX0hu7+SdT8BjPbAuQAO+qhrlrJTf/sNliFhIhIRH1cbuoMFEW9Xh+01YqZDQWSgFVRzb8ILkP9zsyS61bmkbVP0xfqRESqiomOazPrCDwJfMPdD59t3AWcCAwBMoH/rGHbCWaWb2b5JSUlx13D4TOJEnVei4h8qj5CohjoGvW6S9B2TMwsHfgHcLe7zzrc7u4bPaIMeIzIZa1/4+4PuXueu+fl5OQc1xsAyAnOJDR+k4jIZ+ojJOYAfc2sp5klAeOAKceyYbD+y8ATVTuog7MLzMyAS4HF9VBrjdJTEkhOiNO3rkVEotQ5JNy9HLgdmAosA5539yVmdo+ZXQJgZkPMbD3wNeDPZrYk2PwKYDRwfTW3uj5tZouARUA28PO61nokZkZuerK+KyEiEqU+7m7C3V8HXq/S9qOo+TlELkNV3e4p4Kka9vmF+qitNnLTUtRxLSISJSY6rmNFe51JiIh8jkIiStfM1qwv3c+hisqjrywi0gIoJKKc1CGdgxWVFJbsDbsUEZGYoJCIclLHdACWbdwVciUiIrFBIRGlV04qSfFxCgkRkYBCIkpifBx9ctuwbNPusEsREYkJCokqTuqYrjMJEZGAQqKKkzqmUbK7jK17dCusiIhCoorDndfLN+qSk4iIQqKKEzukAbrDSUQEFBL/JqtNMrlpySzbpJAQEVFIVCPSea3LTSIiColqnNQxnYItuzlYruE5RKRlU0hU46SOaRyqcAq37gm7FBGRUCkkqqHhOUREIhQS1eiVnUpSQpz6JUSkxVNIVCMhPo4T2rfRmYSItHgKiRqc2CFyh5O7h12KiEhoFBI1GNozk617ynhj8aawSxERCY1CogZfGdSZ/h3T+emrS9hTVh52OSIioaiXkDCzMWa2wswKzGxiNctHm9k8Mys3s8urLLvOzFYG03VR7YPNbFGwz/vMzOqj1mOVEB/HLy47mS27y/jtW5805q8WEYkZdQ4JM4sHJgEXAP2BK82sf5XV1gHXA5OrbJsJ/BgYBgwFfmxm7YLFDwA3A32DaUxda62tQd3aMX5oN/76wWoWF+9s7F8vIhK6+jiTGAoUuHuhux8EngXGRq/g7mvcfSFQ9SvM5wNvu3upu28H3gbGmFlHIN3dZ3mk5/gJ4NJ6qLXWfnj+iWSmJnH33xdTUalObBFpWeojJDoDRVGv1wdtddm2czB/1H2a2QQzyzez/JKSkmMu+lhltE7k7i+fxIKiHTzz0bp637+ISCxr8h3X7v6Qu+e5e15OTk6D/I5LB3ZmRK8s7n1zOSW79TAiEWk56iMkioGuUa+7BG112bY4mD+efdY7M+Pnl51M2aFKfvGPpWGVISLS6OojJOYAfc2sp5klAeOAKce47VTgPDNrF3RYnwdMdfeNwC4zGx7c1XQt8Eo91Hrceue04ZazevH3+Rv4oGBrmKWIiDSaOoeEu5cDtxP5wF8GPO/uS8zsHjO7BMDMhpjZeuBrwJ/NbEmwbSnwMyJBMwe4J2gDuA34C1AArALeqGutdXXbOX3oltma//77YsrKK8IuR0SkwVlzGnYiLy/P8/PzG/R3TF+xhesfm8PVw7vxo4sGkJTQ5Lt1RKSFM7O57p5X3TJ9wtXS2f1y+caZPXhq1jounTST5XrMqYg0YwqJ4/Djiwfw0DWD2bL7ABf/cQaTphVQXqGn2IlI86OQOE7nDejAW987i/MGdODXU1fw1Qc/pGCLnmQnIs2LQqIOMlOTmDT+dO4fP4h12/by5fve55EZqzW8uIg0GwqJenDRqZ2Y+r3RjOqbzc9eW8rUJRpeXESaB4VEPclNS+HBqwfTr30av3h9GQcO6RZZEWn6FBL1KCE+jh9f3J+i0v08MmN12OWIiNSZQqKendEnm/P6t2fStAI27zoQdjkiInWikGgAd3/5JMornP99c0XYpYiI1IlCogF0z0rlhpE9eWneehYU7Qi7HBGR46aQaCC3f6EP2W2S+emrS3RLrIg0WQqJBtImOYEfnt+Peet2MGXBhrDLERE5LgqJBnT54C6c0jmDX72+nH0Hy8MuR0Sk1hQSDSguzvjRxf3ZtOsAD75bGHY5IiK1ppBoYEN6ZHLRqR3587urWL99X9jliIjUikKiEdx14UkATHxpEXvKdNlJRJoOhUQj6Ny2FT+5ZAAfrNrKpZNmsqpEo8WKSNOgkGgkVw7txlM3DqN070HG3j9TgwCKSJOgkGhEZ/TJ5tVvj6RXTirffHIuv5m6gopKfYdCRGKXQqKRdW7biue/OYIr8rpw/7QCbvjrHHbsOxh2WSIi1aqXkDCzMWa2wswKzGxiNcuTzey5YPlsM+sRtF9lZvOjpkozGxgsmx7s8/Cy3PqoNRakJMZz71dP5ZeXncIHq7Zy8f0zWLpBz8oWkdhT55Aws3hgEnAB0B+40sz6V1ntRmC7u/cBfgfcC+DuT7v7QHcfCFwDrHb3+VHbXXV4ubtvqWutscTMGD+sG899cwQHyyv5ygMz+fvHxWGXJSLyOfVxJjEUKHD3Qnc/CDwLjK2yzljg8WD+ReBcM7Mq61wZbNuinN6tHa99exSndmnLHc/N56evLuFQRWXYZYmIAPUTEp2BoqjX64O2atdx93JgJ5BVZZ2vA89UaXssuNT0P9WECgBmNsHM8s0sv6Sk5HjfQ6hy0pJ5+qZh3HBmTx6buYarHp7Nlt16FoWIhC8mOq7NbBiwz90XRzVf5e6nAKOC6ZrqtnX3h9w9z93zcnJyGqHahpEYH8ePLu7P778+kIXFO7j4jzOYu3Z72GWJSAtXHyFRDHSNet0laKt2HTNLADKAbVHLx1HlLMLdi4Ofu4HJRC5rNXuXDurM3249k6SEOMY99CFPz16rocZFJDT1ERJzgL5m1tPMkoh84E+pss4U4Lpg/nLgHQ8++cwsDriCqP4IM0sws+xgPhG4CFhMC9G/Uzqv3j6SM3pnc/fLi/n+8wvYfeBQ2GWJSAtU55AI+hhuB6YCy4Dn3X2Jmd1jZpcEqz0CZJlZAXAnEH2b7GigyN2jh0lNBqaa2UJgPpEzkYfrWmtT0rZ1Eo9eP4Q7vtiXv88v5sL73mfu2tKwyxKRFsaa06WMvLw8z8/PD7uMejd3bSl3PDef4u37uf2cPnz73L4kxsdEd5KINANmNtfd86pbpk+aJmBw90xe/84oLh3UmfveKeBrD37Imq17wy5LRFoAhUQTkZaSyG+vGMj94wdRWLKHC+97n+fnFKlTW0QalEKiibno1E68ecdoTu2SwQ9fWsitT81j+16N/SQiDUMh0QR1atuKyTcN564LTuRfyzcz5g/vMWPl1rDLEpFmSCHRRMXFGd88qzcv33YmaSmJXP3IbH722lIOHKoIuzQRaUYUEk3cyZ0zePX2kVw7ojuPzFjNpZNmsmLT7rDLEpFmQiHRDLRKiueesSfz6PV5bN1TxsX3z+CxmavVqS0idaaQaEa+cGJ73rxjNCP7ZPPTV5dy3WNz2LJLAwWKyPFTSDQz2W2SeeS6PH526cl8tHobY/7wPm/pedoicpwUEs2QmXHN8O689u1RdMxIYcKTc7nrbwvZd7A87NJEpIlRSDRjfXLb8PJtZ3LLWb15dk4RX75vBguKdoRdlog0IQqJZi4pIY6JF5zI5JuGc+BQBV994ANemrs+7LJEpIlQSLQQI3pn8eZ3RzO0Zyb/8eICXpmv52mLyNEpJFqQjNaJPHLdEIb0yOTO5xfw+qKNYZckIjFOIdHCtEqK59HrhzCoa1u+88zHuvNJRI5IIdECpSYn8Ng3hnBy5wy+NXke7yzfHHZJIhKjFBItVFpKIo/fMJR+HdK45cl5vPtJSdgliUgMUki0YBmtEnnqxmH0zm3DhCfy+aBAI8mKyOcpJFq4tq2TeOrGoXTPas2Nj+czu3Bb2CWJSAxRSAhZbZJ5+qbhdGqbwjf+Ooe5a0vDLklEYkS9hISZjTGzFWZWYGYTq1mebGbPBctnm1mPoL2Hme03s/nB9GDUNoPNbFGwzX1mZvVRq1QvJy2ZZ24eTvv0FK5/dA7z9c1sEaEeQsLM4oFJwAVAf+BKM+tfZbUbge3u3gf4HXBv1LJV7j4wmG6Jan8AuBnoG0xj6lqrHFluegqTbx5Gu9Qkrn1kNouLd4ZdkoiErD7OJIYCBe5e6O4HgWeBsVXWGQs8Hsy/CJx7pDMDM+sIpLv7LI88FOEJ4NJ6qFWOomNGKybfPOzTp90t27gr7JJEJET1ERKdgaKo1+uDtmrXcfdyYCeQFSzraWYfm9m7ZjYqav3oAYaq2ycAZjbBzPLNLL+kRLdx1ocu7VrzzM3DSUmI56q/zOaTzXrSnUhLFXbH9Uagm7sPAu4EJptZem124O4PuXueu+fl5OQ0SJEtUbes1jwzYTgJccb4h2ezqmRP2CWJSAjqIySKga5Rr7sEbdWuY2YJQAawzd3L3H0bgLvPBVYBJwTrdznKPqWB9cxOZfLNwwBn/MOzWLN1b9gliUgjq4+QmAP0NbOeZpYEjAOmVFlnCnBdMH858I67u5nlBB3fmFkvIh3Uhe6+EdhlZsODvotrgVfqoVappT65aTx903AOllcy/uFZFJXuC7skEWlEdQ6JoI/hdmAqsAx43t2XmNk9ZnZJsNojQJaZFRC5rHT4NtnRwEIzm0+kQ/sWdz98k/5twF+AAiJnGG/UtVY5Pv06RIJi78EKxj00i3XbFBQiLYVFbh5qHvLy8jw/Pz/sMpqtxcU7ufqR2bROjOfZCSPoltU67JJEpB6Y2Vx3z6tuWdgd19KEnNw5g6dvGsa+QxWMe+hD1m5TH4VIc6eQkFoZ0Ck6KGbpC3cizZxCQmptQKcMJt80nLLySi764wyuePBDpizYwMHyyrBLE5F6pj4JOW479h3khfz1PDV7LWu37SO7TRLjhnTjymHd6Ny2VdjlicgxOlKfhEJC6qyy0nm/YCtPfriGfy3fggFfPKk914zozpm9s4mL09iMIrHsSCGR0NjFSPMTF2ecdUIOZ52QQ1HpPp75aB3PzSniraWb6ZmdylXDuvG1wV3JaJ0YdqkiUks6k5AGUVZewZuLN/HEh2uZu3Y7KYlxjD2tM9eM6M7JnTPCLk9Eouhyk4RqyYadPDVrHX//uJj9hyoY2LUt1wzvzpdP7UhKYnzY5Ym0eAoJiQm7DhzipbnreXLWWgpL9tKudSJXDOnK1cO60zVTX8wTCYtCQmKKu/Phqm08OWstby3dTKU7Z5+QwzUjujOqbw6J8bozW6QxKSQkZm3aeYDJH63jmY/WUbK7jOSEOAZ0Sue0rm0ZGEzdMlujp9eKNByFhMS8QxWVvLN8C3NWl7Jg/Q4WFe/kwKHIl/Patk7ktC6fhcapXTLIapMccsUizYdugZWYlxgfx/kDOnD+gA4AlFdU8snmPcwv2sGCoh0sWL+DP76zksrg/zRdM1sxsGs7TuuSwcCubRnQKYNWSeoEF6lvOpOQJmNvWTmLi3dGgmP9DhYU7aR4x34A4uOMfu3TGNitLQO7tOW0rm3pk9uGeH2RT+SodLlJmq0tuw+wsOiz4JhftIPdB8oBSEtJ4OZRvZgwupdutRU5AoWEtBiVlc6abXtZsH4HbyzaxFtLN9O5bSsmXnAiF53aUR3gItVQSEiL9eGqbfzstaUs3biLvO7t+NHF/Tm1S9uwyxKJKXrokLRYI3pn8eq3R3LvV09hzba9XHL/TL7//AI27zoQdmkiTYJCQpq9+Djj60O6Me0HZ3PLWb15dcEGzvnNdO5/ZyUHDlWEXZ5ITFNISIuRlpLIxAtO5O07RzO6bw6/eesTzv2/d3lt4Qaa02VXkfpULyFhZmPMbIWZFZjZxGqWJ5vZc8Hy2WbWI2j/kpnNNbNFwc8vRG0zPdjn/GDKrY9aRbpnpfLgNYOZfPMw0lslcvvkj7nizx+yaL0exSpSVZ1DwszigUnABUB/4Eoz619ltRuB7e7eB/gdcG/QvhW42N1PAa4Dnqyy3VXuPjCYttS1VpFoZ/TO5rVvj+RXXzmFwpK9XDJpBj94YQFb1F8h8qn6OJMYChS4e6G7HwSeBcZWWWcs8Hgw/yJwrpmZu3/s7huC9iVAKzPTeAvSaOLjjCuHdmPaf5zNhFG9eGV+MWf/ZjqTphWov0KE+gmJzkBR1Ov1QVu167h7ObATyKqyzleBee5eFtX2WHCp6X+shhvczWyCmeWbWX5JSUld3oe0YOkpidx14Um8/b2zGNknm19PXcEXf/su/1i4Uf0V0qLFRMe1mQ0gcgnqm1HNVwWXoUYF0zXVbevuD7l7nrvn5eTkNHyx0qz1yE7loWvzmHzTMNokJ/CtyfP4+p9nsbhY/RXSMtVHSBQDXaNedwnaql3HzBKADGBb8LoL8DJwrbuvOryBuxcHP3cDk4lc1hJpFGf0yeYf3xnFLy87hVUle7j4/hnc8uRcXpq7nq17yo6+A5Fmoj5GgZ0D9DWznkTCYBwwvso6U4h0TH8IXA684+5uZm2BfwAT3X3m4ZWDIGnr7lvNLBG4CPhnPdQqcszi44zxw7px0WkdmTStgJfmFvPmkk2YwamdMzi7Xy7nnJjLqZ0ziNNAgtJM1cuwHGZ2IfB7IB541N1/YWb3APnuPsXMUojcuTQIKAXGuXuhmf03cBewMmp35wF7gfeAxGCf/wTudPcj9iRqWA5pSJWVztKNu5i2fAvTVmzh46IduENWahJnnZDDWf1yOOuEHNq2Tgq7VJFa0dhNIg2gdO9B3l9ZwvQVJUxfsYXt+w4RZzCoWzvO6ZfD2f1yGdApXYMKSsxTSIg0sIpKZ+H6HUwLAmNh8MW83LRkzu6Xwzn9cjmzbzbpKYkhVyry7xQSIo2sZHcZ734SCYz3Pilh14FyEuKMwd3bcc6JuZzTL5cT2rfRWYbEBIWESIjKKyr5uGhH0JdRwrKNu4DII1hvPLMn44Z200ORJFQKCZEYsmnnAaav2MJL89YzZ812ctKSmTCqF+OHdSM1WY+dl8ankBCJUbMKt3H/OwXMKNhKu9aJ3DSqF9eM6K6+C2lUCgmRGDd37XYmTSvgneVbSE9J4Poze3LDmT10O600CoWESBOxuHgn979TwJtLNpGaFM81I3pw06ieZLfRuJfScBQSIk3Mik27mTStgNcWbiApIY7xQ7szYXQvOmSkhF2aNEMKCZEmqrBkD3+avoqXPy4m3owrhnThlrN606Vd67BLk2ZEISHSxBWV7uOBd1fxQn4R7vCV0ztz29l96JGdGnZp0gwoJESaiY079/Pndwt55qN1HKqo5JLTOnH7F/rQJzct7NKkCVNIiDQzW3Yf4C/vr+apWWvZf6iCC07uwJ1f6kef3DZhlyZNkEJCpJkq3XuQR2es5vEP1uDA/eMHcXa/3LDLkibmSCERE0+mE5Hjk5maxA/O78fbd55Ft8zW3Ph4Pk/PXht2WdKMKCREmoEOGSk8f8sIRvfN5u6XF/PL15dRWdl8rhJIeBQSIs1Em+QEHr42j2tHdOeh9wq57el57D94xOd0iRyVQkKkGUmIj+Onlwzgfy7qz9Slmxj38CxKduuZ3HL8FBIizYyZcePInjx49WBWbNrFpZNmsnLz7rDLkiZKISHSTJ0/oAPPf3MEZeWVfOWBD5hZsDXskqQJqpeQMLMxZrbCzArMbGI1y5PN7Llg+Wwz6xG17K6gfYWZnX+s+xSRozu1S1v+/q0z6JiRwnWPfsTzc4rCLkmamDqHhJnFA5OAC4D+wJVm1r/KajcC2929D/A74N5g2/7AOGAAMAb4k5nFH+M+ReQYdGnXmhdvPYMRvbP44UsL+fXU5brzSY5ZfZxJDAUK3L3Q3Q8CzwJjq6wzFng8mH8RONciD/cdCzzr7mXuvhooCPZ3LPsUkWOUnpLIo9cPYdyQrkyatorvPjefA4d055McXX2ERGcg+hx2fdBW7TruXg7sBLKOsO2x7FNEaiExPo5ffeUU/nPMiby6YANX/WU2pXsPhl2WxLgm33FtZhPMLN/M8ktKSsIuRySmmRm3nt2bSeNPZ1HxTi7700wKS/aEXZbEsPoIiWKga9TrLkFbteuYWQKQAWw7wrbHsk8A3P0hd89z97ycnJw6vA2RluPLp3bkmZuHs/tAOZf96QNmF24LuySJUfUREnOAvmbW08ySiHRET6myzhTgumD+cuAdj4wsOAUYF9z91BPoC3x0jPsUkToY3L0dL992Blltkrj6kdm680mqVeeQCPoYbgemAsuA5919iZndY2aXBKs9AmSZWQFwJzAx2HYJ8DywFHgT+Ja7V9S0z7rWKiKf1z0rlZdvPZNhPSN3Pv38taVU6M4niaKhwkWE8opKfv6PZfz1gzWcdUIOfxw/iPSUxLDLkkaiocJF5IgS4uP4ySUD+OVlpzCzYCuXTprJ0g27wi5LYoBCQkQ+NX5YN568cRg79x3ioj++z11/W8TWPRogsCVTSIjI54zoncU73z+b68/oyQv5RZzz6+k8/F4hB8srwy5NQqCQEJF/k9E6kR9d3J837xjN4B7t+MXryzj/9+/xz6WbaU79mHJ0CgkRqVGf3Db89RtDeewbQ4gzuOmJfK599CM+0dDjLYZCQkSO6px+ubx5x2h+dFF/FhTt4II/vM+PXlnMdg3r0ewpJETkmCTGx3HDyJ5M/49zGD+0G0/NWsvZv5nOYzNXc6hC/RXNlUJCRGolMzWJn116Mm98dzSndM7gp68u5YI/vM/0FVvCLk0agEJCRI5Lvw5pPHnjUB6+No/yikquf2wON/x1Dqs0YGCzopAQkeNmZnypf3umfm80/3XhicxZXcr5v3uPn722lJ37D4VdntQDhYSI1FlyQjwTRvfmnR+czdfyuvDozNWc85vpPDVrLeXqr2jSNHaTiNS7xcU7uee1pXy0upQTO6Rxy1m96dchjZ7ZqaQkxoddnlRxpLGbFBIi0iDcnTcWb+KXry9j/fb9AJhBp4xW9MpJpXdOG3pmp9IrJ5VeOW3omJ5CXJyFXHXLdKSQSGjsYkSkZTAzLjylI1/q356Vm/ewqmQPhSV7Kdwa+flCfhF7D372nO2UxDh6ZreJBEh2JDgOh0iaRqQNjUJCRBpUYnwc/Tul079T+ufa3Z2S3WWsigqOwpI9LC7eyRuLNhL9WIuctGR6BcHROycSHAO7tiMzNamR303Lo5AQkVCYGbnpKeSmpzCid9bnlpWVV7Bu2z5Wlexl9dZIeBRu3cubizeyfd9nd00N6JTOyD7ZjOybzZAemervaADqkxCRJmX73oOs3LKH2YXbmFGwlXnrtnOowklKiGNIj3ac2SebUX1y6N8pnXj1cRwTdVyLSLO1t6ycj9aUMmPlVmYWbGX5psjgg21bJ3JG7yxG9slhZJ9sumW1DrnS2KWOaxFptlKTEzinXy7n9MsFYMvuA3xQEDnLmLFyK68v2gRAt8zWnNknm5F9sjmjdxbt1J9xTHQmISLNlruzqmQvMwu28v7Krcwq3MaesnLM4OROGYzsGwmNwd3btej+jAa73GRmmcBzQA9gDXCFu2+vZr3rgP8OXv7c3R83s9bAC0BvoAJ41d0nButfD/waKA62ud/d/3K0ehQSInIk5RWVLFi/gxkrtzGjoISP1+2gvNLJTE3i1rN6c/Xw7rRKanlh0ZAh8b9Aqbv/PzObCLRz9/+ssk4mkA/kAQ7MBQYDZcAwd59mZknAv4BfuvsbQUjkufvttalHISEitbGnrJxZq7bx+IdreH/lVnLSkvnW2b25clg3khNaTlgcKSTqOnbTWODxYP5x4NJq1jkfeNvdS4OzjLeBMe6+z92nAbj7QWAe0KWO9YiIHLM2yQl8sX97nrxxGM9/cwQ9s1P5yatLOefX05k8e52ek0HdQ6K9u28M5jcB7atZpzNQFPV6fdD2KTNrC1xM5GzisK+a2UIze9HMutZUgJlNMLN8M8svKSk5nvcgIsLQnpk8N2E4T904jPYZKfzXy4v4wv9N58W561v0IIVHDQkz+6eZLa5mGhu9nkeuW9X62pWZJQDPAPe5e2HQ/CrQw91PJXLm8XhN27v7Q+6e5+55OTk5tf31IiKfMjNG9s3mb7eewWPXDyGjVSI/eGEB5/3uPaYs2EBlZfO50edYHTUk3P2L7n5yNdMrwGYz6wgQ/Kzu0VTFQPSZQBc+65AGeAhY6e6/j/qd29y9LHj5FyJ9GCIijcLMOOfEXF69fSQPXj2YxPg4vvPMx1zwh/d5c/EmmtNdoUdT18tNU4DrgvnrgFeqWWcqcJ6ZtTOzdsB5QRtm9nMgA7gjeoPDwRO4BFhWxzpFRGrNzBhzcgfe+O4o7rtyEIcqK7nlqblcfP8M3lm+uUWERV3vbsoCnge6AWuJ3AJbamZ5wC3uflOw3g3AfwWb/cLdHzOzLkT6KpYTudMJgltdzexXRMKhHCgFbnX35UerR3c3iUhDKq+o5JX5G/jDv1ayrnQfg7q15ftf6seZfbIwa7pDgGhYDhGRenSoopIX567nj/9ayYadBxjaM5Pvf+kEhvXKOvrGMUghISLSAMrKK3j2oyImTStgy+4yRvXN5jvn9mVwt3ZN6gFKCgkRkQZ04FAFT81ay5+mr6J070EyU5MY3iuT4b2yGN4ri765bWL6cpRCQkSkEewtK2fqkk3MCMaJ2rDzAACZqUkM6/n50IilMw2FhIhII3N31m/fz4eF25hVuI3ZhaUU74g86zvWQkNDhYuINDIzo2tma7pmtuaKvMhXxYpK9zGrcBuzCkuZVbiNNxZHhjGPtdCIppAQEWkkh0Pja8cQGkN7ZDK8VyaDu2eS0SqRlMQ4UpLiSUmIJzHeGq2PQyEhIhKS6kJj9urSIDi28eaSTdVuF2fQKjGelGBKTozjji+ewCWndar3GhUSIiIx4nBoXD44MiB2Uek+FhfvZO/BCg4cip4qIz/LK9h/sJID5RW0a53YIDUpJEREYtTh0AhTXcduEhGRZkwhISIiNVJIiIhIjRQSIiJSI4WEiIjUSCEhIiI1UkiIiEiNFBIiIlKjZjUKrJmVEHmM6vHIBrbWYzmNpanWDU23dtXduFR3w+vu7jnVLWhWIVEXZpZf01C5sayp1g1Nt3bV3bhUd7h0uUlERGqkkBARkRopJD7zUNgFHKemWjc03dpVd+NS3SFSn4SIiNRIZxIiIlIjhYSIiNRIIQGY2RgzW2FmBWY2Mex6oplZVzObZmZLzWyJmX03aP+JmRWb2fxgujBqm7uC97LCzM4PsfY1ZrYoqC8/aMs0s7fNbGXws13QbmZ2X1D3QjM7PaSa+0Ud0/lmtsvM7ojF421mj5rZFjNbHNVW6+NrZtcF6680s+tCqvvXZrY8qO1lM2sbtPcws/1Rx/3BqG0GB39fBcF7a/CHPtdQe63/NmL5M+ffuHuLnoB4YBXQC0gCFgD9w64rqr6OwOnBfBrwCdAf+Anwg2rW7x+8h2SgZ/De4kOqfQ2QXaXtf4GJwfxE4N5g/kLgDcCA4cDsGDj28cAmoHssHm9gNHA6sPh4jy+QCRQGP9sF8+1CqPs8ICGYvzeq7h7R61XZz0fBe7HgvV0Q0jGv1d9GrH/mVJ10JgFDgQJ3L3T3g8CzwNiQa/qUu29093nB/G5gGdD5CJuMBZ519zJ3Xw0UEHmPsWIs8Hgw/zhwaVT7Ex4xC2hrZh1DqC/aucAqdz/St/hDO97u/h5QWk09tTm+5wNvu3upu28H3gbGNHbd7v6Wu5cHL2cBXY60j6D2dHef5ZFP5Cf47L02mBqOeU1q+tuI6c+cqhQSkQ/coqjX6znyh3BozKwHMAiYHTTdHpyeP3r4sgKx9X4ceMvM5prZhKCtvbtvDOY3Ae2D+Viq+7BxwDNRr2P9eEPtj2+s1Q9wA5Ezg8N6mtnHZvaumY0K2joTqfWwsOuuzd9GLB7zGikkmggzawO8BNzh7ruAB4DewEBgI/B/4VVXo5HufjpwAfAtMxsdvTD4H2BM3oNtZknAJcALQVNTON6fE8vHtyZmdjdQDjwdNG0Eurn7IOBOYLKZpYdVXw2a3N9GbSgkoBjoGvW6S9AWM8wskUhAPO3ufwNw983uXuHulcDDfHaJI2bej7sXBz+3AC8TqXHz4ctIwc8tweoxU3fgAmCeu2+GpnG8A7U9vjFTv5ldD1wEXBUEHMGlmm3B/Fwi1/JPCGqMviQV5t95bf82YuaYHwuFBMwB+ppZz+B/j+OAKSHX9Kngjo1HgGXu/tuo9ujr9ZcBh++2mAKMM7NkM+sJ9CXSwdeozCzVzNIOzxPpmFwc1Hf4DprrgFeC+SnAtcFdOMOBnVGXTcJwJVGXmmL9eEep7fGdCpxnZu2CyyTnBW2NyszGAD8ELnH3fVHtOWYWH8z3InJ8C4Pad5nZ8ODfyLV89l4b1XH8bcT0Z86/CbvnPBYmInd+fELkfyl3h11PldpGErlksBCYH0wXAk8Ci4L2KUDHqG3uDt7LChrhjo8a6u5F5K6NBcCSw8cVyAL+BawE/glkBu0GTArqXgTkhXjMU4FtQEZUW8wdbyIhthE4ROS69o3Hc3yJ9AEUBNM3Qqq7gMh1+sN/4w8G6341+PuZD8wDLo7aTx6RD+RVwP0EI0iEUHut/zZi+TOn6qRhOUREpEa63CQiIjVSSIiISI0UEiIiUiOFhIiI1EghISIiNVJIiIhIjRQSIiJSo/8PDQVfq3HqvCsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 89.3180  # Value for C0\n",
    "K0 = -0.0010  # Value for K0\n",
    "K1 = 0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = -0.0204    # Value for b\n",
    "c = 2.2194    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    92.600000    92.387115    92.174230    91.961345    91.748459   \n",
      "351    92.387115    92.174230    91.961345    91.748459    91.535574   \n",
      "352    92.174230    91.961345    91.748459    91.535574    91.322689   \n",
      "353    91.961345    91.748459    91.535574    91.322689    91.109804   \n",
      "354    91.748459    91.535574    91.322689    91.109804    90.896919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    91.535574    91.322689    91.109804    90.896919    90.691597  ...   \n",
      "351    91.322689    91.109804    90.896919    90.691597    90.579552  ...   \n",
      "352    91.109804    90.896919    90.691597    90.579552    90.467507  ...   \n",
      "353    90.896919    90.691597    90.579552    90.467507    90.355462  ...   \n",
      "354    90.691597    90.579552    90.467507    90.355462    90.243417  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   80.261671    0.000263   80.252334    0.000263   80.242997    0.000263   \n",
      "351   80.252334    0.000263   80.242997    0.000263   80.233660    0.000262   \n",
      "352   80.242997    0.000263   80.233660    0.000262   80.224323    0.000262   \n",
      "353   80.233660    0.000262   80.224323    0.000262   80.214986    0.000262   \n",
      "354   80.224323    0.000262   80.214986    0.000262   80.205649    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   80.233660    0.000262   80.224323    0.000262  \n",
      "351   80.224323    0.000262   80.214986    0.000262  \n",
      "352   80.214986    0.000262   80.205649    0.000262  \n",
      "353   80.205649    0.000262   80.196312    0.000262  \n",
      "354   80.196312    0.000262   80.186975    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 1, 251) (1200, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "15/15 [==============================] - 2s 31ms/step - loss: 5899.8301 - val_loss: 4894.3804\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5832.2959 - val_loss: 4848.1719\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5780.1475 - val_loss: 4796.4204\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5723.8687 - val_loss: 4747.0103\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5669.8594 - val_loss: 4697.9438\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5616.5254 - val_loss: 4649.6313\n",
      "Epoch 7/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5563.9531 - val_loss: 4601.9766\n",
      "Epoch 8/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5512.0254 - val_loss: 4554.8818\n",
      "Epoch 9/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5448.6406 - val_loss: 4493.9663\n",
      "Epoch 10/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5390.8774 - val_loss: 4438.5688\n",
      "Epoch 11/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 5330.2373 - val_loss: 4386.3442\n",
      "Epoch 12/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5273.3535 - val_loss: 4335.1582\n",
      "Epoch 13/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5217.6982 - val_loss: 4285.0869\n",
      "Epoch 14/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5163.1338 - val_loss: 4235.9219\n",
      "Epoch 15/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5109.4546 - val_loss: 4187.5107\n",
      "Epoch 16/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5056.5229 - val_loss: 4139.7529\n",
      "Epoch 17/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5004.2466 - val_loss: 4092.5825\n",
      "Epoch 18/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4952.5654 - val_loss: 4045.9536\n",
      "Epoch 19/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4901.4355 - val_loss: 3999.8318\n",
      "Epoch 20/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4850.8252 - val_loss: 3954.1907\n",
      "Epoch 21/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4800.7061 - val_loss: 3909.0105\n",
      "Epoch 22/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4751.0605 - val_loss: 3864.2749\n",
      "Epoch 23/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4701.8716 - val_loss: 3819.9695\n",
      "Epoch 24/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4653.1265 - val_loss: 3776.0833\n",
      "Epoch 25/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4604.8115 - val_loss: 3732.6064\n",
      "Epoch 26/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4556.9189 - val_loss: 3689.5308\n",
      "Epoch 27/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4509.4385 - val_loss: 3646.8474\n",
      "Epoch 28/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4462.3643 - val_loss: 3604.5510\n",
      "Epoch 29/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4415.6875 - val_loss: 3562.6350\n",
      "Epoch 30/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4369.4033 - val_loss: 3521.0935\n",
      "Epoch 31/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4323.5059 - val_loss: 3479.9224\n",
      "Epoch 32/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4277.9893 - val_loss: 3439.1157\n",
      "Epoch 33/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4232.8496 - val_loss: 3398.6709\n",
      "Epoch 34/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4188.0820 - val_loss: 3358.5815\n",
      "Epoch 35/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4143.6841 - val_loss: 3318.8467\n",
      "Epoch 36/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4099.6479 - val_loss: 3279.4602\n",
      "Epoch 37/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4055.9734 - val_loss: 3240.4204\n",
      "Epoch 38/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4012.6565 - val_loss: 3201.7222\n",
      "Epoch 39/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3969.6926 - val_loss: 3163.3645\n",
      "Epoch 40/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3927.0798 - val_loss: 3125.3428\n",
      "Epoch 41/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3884.8135 - val_loss: 3087.6553\n",
      "Epoch 42/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3842.8923 - val_loss: 3050.2983\n",
      "Epoch 43/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3801.3123 - val_loss: 3013.2700\n",
      "Epoch 44/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3760.0718 - val_loss: 2976.5671\n",
      "Epoch 45/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3719.1672 - val_loss: 2940.1875\n",
      "Epoch 46/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3678.5972 - val_loss: 2904.1289\n",
      "Epoch 47/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3638.3582 - val_loss: 2868.3879\n",
      "Epoch 48/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3598.4480 - val_loss: 2832.9636\n",
      "Epoch 49/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3558.8638 - val_loss: 2797.8530\n",
      "Epoch 50/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3519.6042 - val_loss: 2763.0532\n",
      "Epoch 51/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3480.6665 - val_loss: 2728.5635\n",
      "Epoch 52/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3442.0481 - val_loss: 2694.3806\n",
      "Epoch 53/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3403.7471 - val_loss: 2660.5027\n",
      "Epoch 54/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3365.7615 - val_loss: 2626.9280\n",
      "Epoch 55/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3328.0896 - val_loss: 2593.6541\n",
      "Epoch 56/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3290.7288 - val_loss: 2560.6787\n",
      "Epoch 57/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3253.6760 - val_loss: 2528.0002\n",
      "Epoch 58/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3216.9314 - val_loss: 2495.6167\n",
      "Epoch 59/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3180.4912 - val_loss: 2463.5271\n",
      "Epoch 60/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3144.3545 - val_loss: 2431.7278\n",
      "Epoch 61/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3108.5193 - val_loss: 2400.2178\n",
      "Epoch 62/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3072.9829 - val_loss: 2368.9956\n",
      "Epoch 63/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3037.7444 - val_loss: 2338.0586\n",
      "Epoch 64/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3002.8010 - val_loss: 2307.4053\n",
      "Epoch 65/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2968.1523 - val_loss: 2277.0344\n",
      "Epoch 66/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2933.7952 - val_loss: 2246.9438\n",
      "Epoch 67/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2899.7280 - val_loss: 2217.1306\n",
      "Epoch 68/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2865.9492 - val_loss: 2187.5950\n",
      "Epoch 69/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2832.4578 - val_loss: 2158.3347\n",
      "Epoch 70/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2799.2507 - val_loss: 2129.3479\n",
      "Epoch 71/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2766.3276 - val_loss: 2100.6326\n",
      "Epoch 72/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2733.6858 - val_loss: 2072.1863\n",
      "Epoch 73/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2701.3237 - val_loss: 2044.0093\n",
      "Epoch 74/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2669.2400 - val_loss: 2016.0991\n",
      "Epoch 75/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2637.4333 - val_loss: 1988.4534\n",
      "Epoch 76/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2605.9014 - val_loss: 1961.0714\n",
      "Epoch 77/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2574.6418 - val_loss: 1933.9510\n",
      "Epoch 78/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2543.6550 - val_loss: 1907.0914\n",
      "Epoch 79/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2512.9380 - val_loss: 1880.4900\n",
      "Epoch 80/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2482.4895 - val_loss: 1854.1451\n",
      "Epoch 81/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2452.3079 - val_loss: 1828.0560\n",
      "Epoch 82/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2422.3906 - val_loss: 1802.2207\n",
      "Epoch 83/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2392.7385 - val_loss: 1776.6383\n",
      "Epoch 84/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2363.3479 - val_loss: 1751.3073\n",
      "Epoch 85/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2334.2185 - val_loss: 1726.2249\n",
      "Epoch 86/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2305.3481 - val_loss: 1701.3903\n",
      "Epoch 87/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2276.7356 - val_loss: 1676.8025\n",
      "Epoch 88/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2248.3792 - val_loss: 1652.4589\n",
      "Epoch 89/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2220.2773 - val_loss: 1628.3591\n",
      "Epoch 90/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2192.4287 - val_loss: 1604.5009\n",
      "Epoch 91/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2164.8318 - val_loss: 1580.8839\n",
      "Epoch 92/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2137.4854 - val_loss: 1557.5052\n",
      "Epoch 93/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2110.3879 - val_loss: 1534.3651\n",
      "Epoch 94/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2083.5381 - val_loss: 1511.4603\n",
      "Epoch 95/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2056.9341 - val_loss: 1488.7905\n",
      "Epoch 96/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2030.5741 - val_loss: 1466.3539\n",
      "Epoch 97/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2004.4576 - val_loss: 1444.1489\n",
      "Epoch 98/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1978.5829 - val_loss: 1422.1744\n",
      "Epoch 99/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1952.9479 - val_loss: 1400.4288\n",
      "Epoch 100/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1927.5520 - val_loss: 1378.9104\n",
      "Epoch 101/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1902.3934 - val_loss: 1357.6195\n",
      "Epoch 102/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1877.4714 - val_loss: 1336.5524\n",
      "Epoch 103/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1852.7838 - val_loss: 1315.7090\n",
      "Epoch 104/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1828.3297 - val_loss: 1295.0883\n",
      "Epoch 105/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1804.1082 - val_loss: 1274.6880\n",
      "Epoch 106/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1780.1169 - val_loss: 1254.5071\n",
      "Epoch 107/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1756.3549 - val_loss: 1234.5435\n",
      "Epoch 108/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1732.8206 - val_loss: 1214.7976\n",
      "Epoch 109/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1709.5128 - val_loss: 1195.2672\n",
      "Epoch 110/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1686.4305 - val_loss: 1175.9500\n",
      "Epoch 111/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1663.5723 - val_loss: 1156.8462\n",
      "Epoch 112/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1638.7478 - val_loss: 1129.7042\n",
      "Epoch 113/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1606.4108 - val_loss: 1106.7406\n",
      "Epoch 114/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1579.2860 - val_loss: 1084.5325\n",
      "Epoch 115/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1553.2091 - val_loss: 1063.2358\n",
      "Epoch 116/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1528.0765 - val_loss: 1042.6562\n",
      "Epoch 117/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1503.6798 - val_loss: 1022.6482\n",
      "Epoch 118/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1479.8776 - val_loss: 1003.1204\n",
      "Epoch 119/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1456.5815 - val_loss: 984.0140\n",
      "Epoch 120/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1433.7308 - val_loss: 965.2863\n",
      "Epoch 121/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1411.2843 - val_loss: 946.9089\n",
      "Epoch 122/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1389.2107 - val_loss: 928.8580\n",
      "Epoch 123/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1367.4866 - val_loss: 911.1169\n",
      "Epoch 124/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1346.0933 - val_loss: 893.6703\n",
      "Epoch 125/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1325.0151 - val_loss: 876.5070\n",
      "Epoch 126/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1304.2399 - val_loss: 859.6164\n",
      "Epoch 127/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1283.7571 - val_loss: 842.9904\n",
      "Epoch 128/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1263.5562 - val_loss: 826.6208\n",
      "Epoch 129/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1243.6309 - val_loss: 810.5020\n",
      "Epoch 130/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1223.9728 - val_loss: 794.6269\n",
      "Epoch 131/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1204.5760 - val_loss: 778.9916\n",
      "Epoch 132/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1185.4351 - val_loss: 763.5903\n",
      "Epoch 133/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1166.5447 - val_loss: 748.4187\n",
      "Epoch 134/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1147.8995 - val_loss: 733.4721\n",
      "Epoch 135/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1129.4957 - val_loss: 718.7477\n",
      "Epoch 136/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1111.3296 - val_loss: 704.2420\n",
      "Epoch 137/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1093.3966 - val_loss: 689.9509\n",
      "Epoch 138/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1075.6935 - val_loss: 675.8717\n",
      "Epoch 139/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1058.2170 - val_loss: 662.0009\n",
      "Epoch 140/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1040.9640 - val_loss: 648.3362\n",
      "Epoch 141/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1023.9311 - val_loss: 634.8743\n",
      "Epoch 142/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1007.1156 - val_loss: 621.6134\n",
      "Epoch 143/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 990.5149 - val_loss: 608.5508\n",
      "Epoch 144/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 974.1267 - val_loss: 595.6830\n",
      "Epoch 145/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 957.9479 - val_loss: 583.0092\n",
      "Epoch 146/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 941.9764 - val_loss: 570.5262\n",
      "Epoch 147/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 926.2100 - val_loss: 558.2322\n",
      "Epoch 148/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 910.6459 - val_loss: 546.1250\n",
      "Epoch 149/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 895.2823 - val_loss: 534.2024\n",
      "Epoch 150/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 880.1169 - val_loss: 522.4618\n",
      "Epoch 151/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 865.1477 - val_loss: 510.9028\n",
      "Epoch 152/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 850.3726 - val_loss: 499.5223\n",
      "Epoch 153/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 835.7897 - val_loss: 488.3180\n",
      "Epoch 154/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 821.3967 - val_loss: 477.2890\n",
      "Epoch 155/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 807.1923 - val_loss: 466.4333\n",
      "Epoch 156/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 793.1746 - val_loss: 455.7489\n",
      "Epoch 157/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 779.3412 - val_loss: 445.2340\n",
      "Epoch 158/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 765.6907 - val_loss: 434.8875\n",
      "Epoch 159/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 752.2217 - val_loss: 424.7065\n",
      "Epoch 160/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 738.9317 - val_loss: 414.6904\n",
      "Epoch 161/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 725.8195 - val_loss: 404.8365\n",
      "Epoch 162/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 712.8834 - val_loss: 395.1445\n",
      "Epoch 163/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 700.1216 - val_loss: 385.6120\n",
      "Epoch 164/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 687.5325 - val_loss: 376.2372\n",
      "Epoch 165/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 675.1146 - val_loss: 367.0191\n",
      "Epoch 166/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 662.8662 - val_loss: 357.9558\n",
      "Epoch 167/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 650.7857 - val_loss: 349.0455\n",
      "Epoch 168/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 638.8718 - val_loss: 340.2870\n",
      "Epoch 169/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 627.1227 - val_loss: 331.6788\n",
      "Epoch 170/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 615.5369 - val_loss: 323.2193\n",
      "Epoch 171/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 604.1129 - val_loss: 314.9068\n",
      "Epoch 172/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 592.8494 - val_loss: 306.7404\n",
      "Epoch 173/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 581.7448 - val_loss: 298.7177\n",
      "Epoch 174/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 570.7977 - val_loss: 290.8385\n",
      "Epoch 175/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 560.0065 - val_loss: 283.0998\n",
      "Epoch 176/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 549.3698 - val_loss: 275.5018\n",
      "Epoch 177/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 538.8861 - val_loss: 268.0421\n",
      "Epoch 178/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 528.5543 - val_loss: 260.7193\n",
      "Epoch 179/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 518.3730 - val_loss: 253.5320\n",
      "Epoch 180/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 508.3402 - val_loss: 246.4794\n",
      "Epoch 181/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 498.4551 - val_loss: 239.5591\n",
      "Epoch 182/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 488.7162 - val_loss: 232.7702\n",
      "Epoch 183/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 479.1216 - val_loss: 226.1110\n",
      "Epoch 184/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 469.6706 - val_loss: 219.5814\n",
      "Epoch 185/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 460.3619 - val_loss: 213.1787\n",
      "Epoch 186/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 451.1940 - val_loss: 206.9021\n",
      "Epoch 187/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 442.1655 - val_loss: 200.7498\n",
      "Epoch 188/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 433.2747 - val_loss: 194.7207\n",
      "Epoch 189/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 424.5204 - val_loss: 188.8139\n",
      "Epoch 190/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 415.9018 - val_loss: 183.0269\n",
      "Epoch 191/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 407.4171 - val_loss: 177.3596\n",
      "Epoch 192/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 399.0651 - val_loss: 171.8101\n",
      "Epoch 193/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 390.8449 - val_loss: 166.3774\n",
      "Epoch 194/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 382.7548 - val_loss: 161.0600\n",
      "Epoch 195/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 374.7935 - val_loss: 155.8556\n",
      "Epoch 196/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 366.9594 - val_loss: 150.7644\n",
      "Epoch 197/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 359.2518 - val_loss: 145.7846\n",
      "Epoch 198/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 351.6692 - val_loss: 140.9145\n",
      "Epoch 199/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 344.2103 - val_loss: 136.1534\n",
      "Epoch 200/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 336.8741 - val_loss: 131.4997\n",
      "Epoch 201/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 329.6591 - val_loss: 126.9521\n",
      "Epoch 202/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 322.5641 - val_loss: 122.5089\n",
      "Epoch 203/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 315.5875 - val_loss: 118.1695\n",
      "Epoch 204/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 308.7284 - val_loss: 113.9323\n",
      "Epoch 205/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 301.9858 - val_loss: 109.7964\n",
      "Epoch 206/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 295.3582 - val_loss: 105.7597\n",
      "Epoch 207/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 288.8442 - val_loss: 101.8219\n",
      "Epoch 208/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 282.4428 - val_loss: 97.9816\n",
      "Epoch 209/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 276.1529 - val_loss: 94.2368\n",
      "Epoch 210/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 269.9729 - val_loss: 90.5870\n",
      "Epoch 211/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 263.9020 - val_loss: 87.0307\n",
      "Epoch 212/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 257.9385 - val_loss: 83.5663\n",
      "Epoch 213/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 252.0814 - val_loss: 80.1930\n",
      "Epoch 214/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 246.3297 - val_loss: 76.9091\n",
      "Epoch 215/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 240.6817 - val_loss: 73.7144\n",
      "Epoch 216/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 235.1370 - val_loss: 70.6067\n",
      "Epoch 217/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 229.6940 - val_loss: 67.5850\n",
      "Epoch 218/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 224.3513 - val_loss: 64.6482\n",
      "Epoch 219/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 219.1079 - val_loss: 61.7951\n",
      "Epoch 220/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 213.9630 - val_loss: 59.0245\n",
      "Epoch 221/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 208.9148 - val_loss: 56.3352\n",
      "Epoch 222/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 203.9624 - val_loss: 53.7259\n",
      "Epoch 223/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 199.1048 - val_loss: 51.1952\n",
      "Epoch 224/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 194.3405 - val_loss: 48.7427\n",
      "Epoch 225/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 189.6687 - val_loss: 46.3661\n",
      "Epoch 226/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 185.0879 - val_loss: 44.0650\n",
      "Epoch 227/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 180.5972 - val_loss: 41.8382\n",
      "Epoch 228/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 176.1954 - val_loss: 39.6839\n",
      "Epoch 229/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 171.8813 - val_loss: 37.6016\n",
      "Epoch 230/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 167.6536 - val_loss: 35.5898\n",
      "Epoch 231/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 163.5115 - val_loss: 33.6476\n",
      "Epoch 232/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 159.4537 - val_loss: 31.7733\n",
      "Epoch 233/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 155.4789 - val_loss: 29.9667\n",
      "Epoch 234/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 151.5867 - val_loss: 28.2256\n",
      "Epoch 235/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 147.7753 - val_loss: 26.5496\n",
      "Epoch 236/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 144.0435 - val_loss: 24.9372\n",
      "Epoch 237/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 140.3908 - val_loss: 23.3876\n",
      "Epoch 238/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 136.8157 - val_loss: 21.8991\n",
      "Epoch 239/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 133.3170 - val_loss: 20.4712\n",
      "Epoch 240/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 129.8942 - val_loss: 19.1025\n",
      "Epoch 241/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 126.5456 - val_loss: 17.7919\n",
      "Epoch 242/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 123.2703 - val_loss: 16.5383\n",
      "Epoch 243/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 120.0674 - val_loss: 15.3407\n",
      "Epoch 244/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 116.9358 - val_loss: 14.1979\n",
      "Epoch 245/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 113.8743 - val_loss: 13.1089\n",
      "Epoch 246/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 110.8817 - val_loss: 12.0726\n",
      "Epoch 247/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 107.9572 - val_loss: 11.0879\n",
      "Epoch 248/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 105.0999 - val_loss: 10.1537\n",
      "Epoch 249/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 102.3083 - val_loss: 9.2690\n",
      "Epoch 250/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 99.5816 - val_loss: 8.4328\n",
      "Epoch 251/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 96.9190 - val_loss: 7.6440\n",
      "Epoch 252/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 94.3193 - val_loss: 6.9016\n",
      "Epoch 253/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 91.7815 - val_loss: 6.2045\n",
      "Epoch 254/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 89.3045 - val_loss: 5.5517\n",
      "Epoch 255/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 86.8873 - val_loss: 4.9423\n",
      "Epoch 256/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 84.5288 - val_loss: 4.3751\n",
      "Epoch 257/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 82.2283 - val_loss: 3.8492\n",
      "Epoch 258/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 79.9845 - val_loss: 3.3636\n",
      "Epoch 259/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 77.7968 - val_loss: 2.9174\n",
      "Epoch 260/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 75.6640 - val_loss: 2.5096\n",
      "Epoch 261/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 73.5852 - val_loss: 2.1392\n",
      "Epoch 262/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 71.5594 - val_loss: 1.8051\n",
      "Epoch 263/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 69.5858 - val_loss: 1.5066\n",
      "Epoch 264/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 67.6632 - val_loss: 1.2426\n",
      "Epoch 265/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 65.7908 - val_loss: 1.0122\n",
      "Epoch 266/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 63.9678 - val_loss: 0.8146\n",
      "Epoch 267/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 62.1931 - val_loss: 0.6487\n",
      "Epoch 268/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 60.4658 - val_loss: 0.5136\n",
      "Epoch 269/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 58.7853 - val_loss: 0.4086\n",
      "Epoch 270/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 57.1501 - val_loss: 0.3326\n",
      "Epoch 271/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 55.5599 - val_loss: 0.2849\n",
      "Epoch 272/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 54.0135 - val_loss: 0.2644\n",
      "Epoch 273/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 52.5100 - val_loss: 0.2705\n",
      "Epoch 274/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 51.0489 - val_loss: 0.3022\n",
      "Epoch 275/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 49.6290 - val_loss: 0.3587\n",
      "Epoch 276/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 48.2494 - val_loss: 0.4392\n",
      "Epoch 277/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 46.9096 - val_loss: 0.5429\n",
      "Epoch 278/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 45.6085 - val_loss: 0.6689\n",
      "Epoch 279/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 44.3453 - val_loss: 0.8164\n",
      "Epoch 280/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 43.1194 - val_loss: 0.9847\n",
      "Epoch 281/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 41.9297 - val_loss: 1.1730\n",
      "Epoch 282/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 40.7757 - val_loss: 1.3806\n",
      "Epoch 283/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 39.6564 - val_loss: 1.6066\n",
      "Epoch 284/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 38.5712 - val_loss: 1.8503\n",
      "Epoch 285/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 37.5191 - val_loss: 2.1111\n",
      "Epoch 286/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 36.4995 - val_loss: 2.3881\n",
      "Epoch 287/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 35.5116 - val_loss: 2.6807\n",
      "Epoch 288/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 34.5548 - val_loss: 2.9881\n",
      "Epoch 289/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 33.6281 - val_loss: 3.3097\n",
      "Epoch 290/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 32.7311 - val_loss: 3.6449\n",
      "Epoch 291/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 31.8630 - val_loss: 3.9928\n",
      "Epoch 292/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 31.0229 - val_loss: 4.3530\n",
      "Epoch 293/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 30.2103 - val_loss: 4.7248\n",
      "Epoch 294/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 29.4243 - val_loss: 5.1074\n",
      "Epoch 295/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 28.6645 - val_loss: 5.5004\n",
      "Epoch 296/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 27.9302 - val_loss: 5.9031\n",
      "Epoch 297/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 27.2207 - val_loss: 6.3148\n",
      "Epoch 298/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 26.5353 - val_loss: 6.7351\n",
      "Epoch 299/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 25.8734 - val_loss: 7.1633\n",
      "Epoch 300/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 25.2343 - val_loss: 7.5991\n",
      "Epoch 301/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 24.6175 - val_loss: 8.0416\n",
      "Epoch 302/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 24.0224 - val_loss: 8.4905\n",
      "Epoch 303/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 23.4484 - val_loss: 8.9451\n",
      "Epoch 304/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 22.8949 - val_loss: 9.4051\n",
      "Epoch 305/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 22.3614 - val_loss: 9.8699\n",
      "Epoch 306/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 21.8471 - val_loss: 10.3388\n",
      "Epoch 307/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 21.3517 - val_loss: 10.8117\n",
      "Epoch 308/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 20.8746 - val_loss: 11.2880\n",
      "Epoch 309/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 20.4153 - val_loss: 11.7672\n",
      "Epoch 310/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.9731 - val_loss: 12.2490\n",
      "Epoch 311/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 19.5476 - val_loss: 12.7329\n",
      "Epoch 312/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 19.1384 - val_loss: 13.2182\n",
      "Epoch 313/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 18.7449 - val_loss: 13.7049\n",
      "Epoch 314/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 18.3667 - val_loss: 14.1924\n",
      "Epoch 315/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 18.0032 - val_loss: 14.6804\n",
      "Epoch 316/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 17.6540 - val_loss: 15.1688\n",
      "Epoch 317/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 17.3187 - val_loss: 15.6567\n",
      "Epoch 318/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 16.9968 - val_loss: 16.1441\n",
      "Epoch 319/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 16.6878 - val_loss: 16.6303\n",
      "Epoch 320/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 16.3915 - val_loss: 17.1155\n",
      "Epoch 321/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 16.1073 - val_loss: 17.5993\n",
      "Epoch 322/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 15.8348 - val_loss: 18.0811\n",
      "Epoch 323/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 15.5737 - val_loss: 18.5611\n",
      "Epoch 324/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 15.3235 - val_loss: 19.0383\n",
      "Epoch 325/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 15.0839 - val_loss: 19.5131\n",
      "Epoch 326/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 14.8545 - val_loss: 19.9849\n",
      "Epoch 327/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 14.6350 - val_loss: 20.4536\n",
      "Epoch 328/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 14.4250 - val_loss: 20.9187\n",
      "Epoch 329/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 14.2242 - val_loss: 21.3806\n",
      "Epoch 330/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 14.0322 - val_loss: 21.8384\n",
      "Epoch 331/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 13.8487 - val_loss: 22.2923\n",
      "Epoch 332/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 13.6735 - val_loss: 22.7420\n",
      "Epoch 333/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 13.5061 - val_loss: 23.1872\n",
      "Epoch 334/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 13.3464 - val_loss: 23.6280\n",
      "Epoch 335/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 13.1939 - val_loss: 24.0639\n",
      "Epoch 336/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 13.0485 - val_loss: 24.4950\n",
      "Epoch 337/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12.9099 - val_loss: 24.9212\n",
      "Epoch 338/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 12.7778 - val_loss: 25.3421\n",
      "Epoch 339/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 12.6519 - val_loss: 25.7578\n",
      "Epoch 340/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12.5320 - val_loss: 26.1680\n",
      "Epoch 341/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 12.4179 - val_loss: 26.5729\n",
      "Epoch 342/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 12.3093 - val_loss: 26.9720\n",
      "Epoch 343/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 12.2060 - val_loss: 27.3653\n",
      "Epoch 344/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 12.1078 - val_loss: 27.7530\n",
      "Epoch 345/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 12.0144 - val_loss: 28.1349\n",
      "Epoch 346/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 11.9257 - val_loss: 28.5107\n",
      "Epoch 347/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.8415 - val_loss: 28.8807\n",
      "Epoch 348/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 11.7615 - val_loss: 29.2446\n",
      "Epoch 349/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 11.6856 - val_loss: 29.6026\n",
      "Epoch 350/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.6135 - val_loss: 29.9542\n",
      "Epoch 351/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.5453 - val_loss: 30.2997\n",
      "Epoch 352/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 11.4806 - val_loss: 30.6391\n",
      "Epoch 353/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 11.4193 - val_loss: 30.9723\n",
      "Epoch 354/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 11.3612 - val_loss: 31.2991\n",
      "Epoch 355/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.3063 - val_loss: 31.6198\n",
      "Epoch 356/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 11.2543 - val_loss: 31.9345\n",
      "Epoch 357/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.2051 - val_loss: 32.2425\n",
      "Epoch 358/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.1587 - val_loss: 32.5447\n",
      "Epoch 359/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 11.1147 - val_loss: 32.8406\n",
      "Epoch 360/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 11.0732 - val_loss: 33.1302\n",
      "Epoch 361/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.0340 - val_loss: 33.4137\n",
      "Epoch 362/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.9970 - val_loss: 33.6913\n",
      "Epoch 363/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.9621 - val_loss: 33.9625\n",
      "Epoch 364/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.9292 - val_loss: 34.2280\n",
      "Epoch 365/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.8982 - val_loss: 34.4872\n",
      "Epoch 366/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.8689 - val_loss: 34.7404\n",
      "Epoch 367/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.8414 - val_loss: 34.9877\n",
      "Epoch 368/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.8155 - val_loss: 35.2293\n",
      "Epoch 369/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.7911 - val_loss: 35.4651\n",
      "Epoch 370/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.7682 - val_loss: 35.6949\n",
      "Epoch 371/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.7466 - val_loss: 35.9191\n",
      "Epoch 372/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.7263 - val_loss: 36.1377\n",
      "Epoch 373/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.7073 - val_loss: 36.3506\n",
      "Epoch 374/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.6894 - val_loss: 36.5581\n",
      "Epoch 375/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.6726 - val_loss: 36.7600\n",
      "Epoch 376/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.6569 - val_loss: 36.9566\n",
      "Epoch 377/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.6422 - val_loss: 37.1479\n",
      "Epoch 378/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.6283 - val_loss: 37.3342\n",
      "Epoch 379/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.6154 - val_loss: 37.5152\n",
      "Epoch 380/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.6032 - val_loss: 37.6912\n",
      "Epoch 381/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 10.5919 - val_loss: 37.8621\n",
      "Epoch 382/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 10.5812 - val_loss: 38.0284\n",
      "Epoch 383/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.5713 - val_loss: 38.1895\n",
      "Epoch 384/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.5620 - val_loss: 38.3463\n",
      "Epoch 385/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.5533 - val_loss: 38.4983\n",
      "Epoch 386/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.5452 - val_loss: 38.6457\n",
      "Epoch 387/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.5376 - val_loss: 38.7885\n",
      "Epoch 388/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.5306 - val_loss: 38.9272\n",
      "Epoch 389/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.5239 - val_loss: 39.0615\n",
      "Epoch 390/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.5178 - val_loss: 39.1918\n",
      "Epoch 391/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.5120 - val_loss: 39.3177\n",
      "Epoch 392/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.5067 - val_loss: 39.4398\n",
      "Epoch 393/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.5017 - val_loss: 39.5575\n",
      "Epoch 394/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4971 - val_loss: 39.6719\n",
      "Epoch 395/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4928 - val_loss: 39.7824\n",
      "Epoch 396/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4888 - val_loss: 39.8892\n",
      "Epoch 397/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4850 - val_loss: 39.9922\n",
      "Epoch 398/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4816 - val_loss: 40.0916\n",
      "Epoch 399/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4784 - val_loss: 40.1880\n",
      "Epoch 400/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4754 - val_loss: 40.2807\n",
      "Epoch 401/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4726 - val_loss: 40.3704\n",
      "Epoch 402/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4700 - val_loss: 40.4568\n",
      "Epoch 403/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 10.4676 - val_loss: 40.5401\n",
      "Epoch 404/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4654 - val_loss: 40.6205\n",
      "Epoch 405/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4634 - val_loss: 40.6977\n",
      "Epoch 406/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4615 - val_loss: 40.7723\n",
      "Epoch 407/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4597 - val_loss: 40.8442\n",
      "Epoch 408/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4581 - val_loss: 40.9130\n",
      "Epoch 409/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4566 - val_loss: 40.9797\n",
      "Epoch 410/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4552 - val_loss: 41.0436\n",
      "Epoch 411/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4540 - val_loss: 41.1050\n",
      "Epoch 412/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4528 - val_loss: 41.1641\n",
      "Epoch 413/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4517 - val_loss: 41.2207\n",
      "Epoch 414/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4507 - val_loss: 41.2753\n",
      "Epoch 415/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4498 - val_loss: 41.3277\n",
      "Epoch 416/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4490 - val_loss: 41.3782\n",
      "Epoch 417/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4481 - val_loss: 41.4263\n",
      "Epoch 418/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4474 - val_loss: 41.4726\n",
      "Epoch 419/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 10.4468 - val_loss: 41.5169\n",
      "Epoch 420/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4462 - val_loss: 41.5592\n",
      "Epoch 421/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4457 - val_loss: 41.6002\n",
      "Epoch 422/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4452 - val_loss: 41.6391\n",
      "Epoch 423/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4447 - val_loss: 41.6764\n",
      "Epoch 424/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4443 - val_loss: 41.7122\n",
      "Epoch 425/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4439 - val_loss: 41.7461\n",
      "Epoch 426/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4436 - val_loss: 41.7788\n",
      "Epoch 427/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4433 - val_loss: 41.8101\n",
      "Epoch 428/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4430 - val_loss: 41.8400\n",
      "Epoch 429/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4428 - val_loss: 41.8688\n",
      "Epoch 430/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4425 - val_loss: 41.8959\n",
      "Epoch 431/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4423 - val_loss: 41.9219\n",
      "Epoch 432/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4422 - val_loss: 41.9467\n",
      "Epoch 433/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4420 - val_loss: 41.9703\n",
      "Epoch 434/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4419 - val_loss: 41.9927\n",
      "Epoch 435/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4418 - val_loss: 42.0142\n",
      "Epoch 436/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4416 - val_loss: 42.0346\n",
      "Epoch 437/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4416 - val_loss: 42.0541\n",
      "Epoch 438/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4415 - val_loss: 42.0725\n",
      "Epoch 439/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 10.4415 - val_loss: 42.0900\n",
      "Epoch 440/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4415 - val_loss: 42.1066\n",
      "Epoch 441/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4415 - val_loss: 42.1229\n",
      "Epoch 442/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4414 - val_loss: 42.1377\n",
      "Epoch 443/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4414 - val_loss: 42.1523\n",
      "Epoch 444/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4414 - val_loss: 42.1659\n",
      "Epoch 445/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4414 - val_loss: 42.1787\n",
      "Epoch 446/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4414 - val_loss: 42.1907\n",
      "Epoch 447/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4415 - val_loss: 42.2025\n",
      "Epoch 448/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4415 - val_loss: 42.2135\n",
      "Epoch 449/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4416 - val_loss: 42.2238\n",
      "Epoch 450/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4416 - val_loss: 42.2337\n",
      "Epoch 451/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4417 - val_loss: 42.2430\n",
      "Epoch 452/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4417 - val_loss: 42.2518\n",
      "Epoch 453/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4418 - val_loss: 42.2600\n",
      "Epoch 454/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4419 - val_loss: 42.2680\n",
      "Epoch 455/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4420 - val_loss: 42.2754\n",
      "Epoch 456/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4421 - val_loss: 42.2825\n",
      "Epoch 457/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4422 - val_loss: 42.2891\n",
      "Epoch 458/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 10.4423 - val_loss: 42.2954\n",
      "Epoch 459/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4423 - val_loss: 42.3012\n",
      "Epoch 460/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4424 - val_loss: 42.3067\n",
      "Epoch 461/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4426 - val_loss: 42.3120\n",
      "Epoch 462/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4426 - val_loss: 42.3167\n",
      "Epoch 463/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4427 - val_loss: 42.3213\n",
      "Epoch 464/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4429 - val_loss: 42.3254\n",
      "Epoch 465/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4430 - val_loss: 42.3296\n",
      "Epoch 466/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4431 - val_loss: 42.3332\n",
      "Epoch 467/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4432 - val_loss: 42.3367\n",
      "Epoch 468/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4434 - val_loss: 42.3400\n",
      "Epoch 469/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4435 - val_loss: 42.3432\n",
      "Epoch 470/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4436 - val_loss: 42.3464\n",
      "Epoch 471/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4438 - val_loss: 42.3488\n",
      "Epoch 472/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4439 - val_loss: 42.3515\n",
      "Epoch 473/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4440 - val_loss: 42.3534\n",
      "Epoch 474/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4442 - val_loss: 42.3558\n",
      "Epoch 475/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4443 - val_loss: 42.3582\n",
      "Epoch 476/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4444 - val_loss: 42.3599\n",
      "Epoch 477/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 10.4446 - val_loss: 42.3616\n",
      "Epoch 478/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4447 - val_loss: 42.3631\n",
      "Epoch 479/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4449 - val_loss: 42.3647\n",
      "Epoch 480/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4450 - val_loss: 42.3661\n",
      "Epoch 481/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4451 - val_loss: 42.3673\n",
      "Epoch 482/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4453 - val_loss: 42.3685\n",
      "Epoch 483/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4454 - val_loss: 42.3694\n",
      "Epoch 484/500\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 10.4456 - val_loss: 42.3703\n",
      "Epoch 485/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4458 - val_loss: 42.3716\n",
      "Epoch 486/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4459 - val_loss: 42.3724\n",
      "Epoch 487/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 10.4461 - val_loss: 42.3732\n",
      "Epoch 488/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4462 - val_loss: 42.3737\n",
      "Epoch 489/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4464 - val_loss: 42.3747\n",
      "Epoch 490/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4465 - val_loss: 42.3752\n",
      "Epoch 491/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4466 - val_loss: 42.3754\n",
      "Epoch 492/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4468 - val_loss: 42.3760\n",
      "Epoch 493/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4470 - val_loss: 42.3764\n",
      "Epoch 494/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4471 - val_loss: 42.3765\n",
      "Epoch 495/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 10.4473 - val_loss: 42.3767\n",
      "Epoch 496/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4474 - val_loss: 42.3769\n",
      "Epoch 497/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4476 - val_loss: 42.3773\n",
      "Epoch 498/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.4478 - val_loss: 42.3774\n",
      "Epoch 499/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4479 - val_loss: 42.3779\n",
      "Epoch 500/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 10.4480 - val_loss: 42.3781\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(89.3180, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0010, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(-0.0204, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.2194, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 381ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71.83769608, 71.82677171, 71.81584734, 71.80492297, 71.7939986 ,\n",
       "        71.78307423, 71.77214986, 71.76122549, 71.75030112, 71.73937675,\n",
       "        71.72845238, 71.71752801, 71.70660364, 71.69567927, 71.6847549 ,\n",
       "        71.67383053, 71.66290616, 71.65198179, 71.64105742, 71.63013305,\n",
       "        71.61920868, 71.60828431, 71.59526144, 71.57565359, 71.55604575,\n",
       "        71.53643791, 71.51683007, 71.49722222, 71.47761438, 71.45800654,\n",
       "        71.43839869, 71.41879085, 71.39918301, 71.37957516, 71.35996732,\n",
       "        71.34035948, 71.32075163, 71.30114379, 71.28153595, 71.2619281 ,\n",
       "        71.24232026, 71.22271242, 71.20310458, 71.18349673, 71.16388889,\n",
       "        71.14428105, 71.1246732 , 71.10506536, 71.08545752, 71.06584967,\n",
       "        71.04624183, 71.02663399, 71.00702614, 70.9874183 , 70.96781046,\n",
       "        70.94820261, 70.92859477, 70.90898693, 70.87875817, 70.83954248,\n",
       "        70.8003268 , 70.76111111, 70.72189542, 70.68267974, 70.64346405,\n",
       "        70.60424837, 70.56503268, 70.52581699, 70.48660131, 70.44738562,\n",
       "        70.40816993, 70.36895425, 70.32973856, 70.29052288, 70.25130719,\n",
       "        70.2120915 , 70.17287582, 70.13366013, 70.09444444, 70.05522876,\n",
       "        77.64771271,  0.10156969,  0.17090581,  0.48216146,  0.        ,\n",
       "         0.23905164,  0.57305247,  0.328962  ,  0.        ,  0.        ,\n",
       "         0.36483926,  0.58905131,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.57974106,  0.33458245,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68.61535948, 68.61349206, 68.61162465, 68.60975724, 68.60788982,\n",
       "       68.60602241, 68.604155  , 68.60228758, 68.60042017, 68.59855275,\n",
       "       68.59668534, 68.59481793, 68.59295051, 68.5910831 , 68.58921569,\n",
       "       68.58734827, 68.58548086, 68.58361345, 68.58174603, 68.57987862,\n",
       "       68.5780112 , 68.57614379, 68.57427638, 68.57240896, 68.57054155,\n",
       "       68.56867414, 68.56680672, 68.56493931, 68.5630719 , 68.56120448,\n",
       "       68.55933707, 68.55746965, 68.55560224, 68.55373483, 68.55186741,\n",
       "       68.55      , 68.54813259, 68.54626517, 68.54439776, 68.54253035,\n",
       "       68.54066293, 68.53879552, 68.5369281 , 68.53506069, 68.53319328,\n",
       "       68.53132586, 68.52945845, 68.52759104, 68.52572362, 68.52385621,\n",
       "       68.5219888 , 68.52012138, 68.51825397, 68.51638655, 68.51451914,\n",
       "       68.51265173, 68.51078431, 68.5089169 , 68.50704949, 68.50518207,\n",
       "       68.50331466, 68.50144725, 68.49747899, 68.48627451, 68.47507003,\n",
       "       68.46386555, 68.45266106, 68.44145658, 68.4302521 , 68.41904762,\n",
       "       68.40784314, 68.39663866, 68.38543417, 68.37422969, 68.36302521,\n",
       "       68.35182073, 68.34061625, 68.32941176, 68.31820728, 68.3070028 ,\n",
       "       68.29579832, 68.28459384, 68.27338936, 68.26218487, 68.25098039,\n",
       "       68.23977591, 68.22857143, 68.21736695, 68.20616246, 68.19495798,\n",
       "       68.1837535 , 68.17254902, 68.16134454, 68.15014006, 68.13893557,\n",
       "       68.12773109, 68.11652661, 68.10532213, 68.09411765, 68.08291317])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.745779232651586\n",
      "15.124740803168567\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
