{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2145    65.108752\n",
       "2146    65.101100\n",
       "2147    65.093448\n",
       "2148    65.085796\n",
       "2149    65.078144\n",
       "Name: C7, Length: 2150, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c7_interpolated_2050_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2045     0.532064\n",
       "2046     0.462526\n",
       "2047     0.000000\n",
       "2048     0.000000\n",
       "2049     0.000000\n",
       "Name: C7, Length: 2050, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2050)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.387115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.174230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.961345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.748459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     92.600000  0.000298\n",
       "1     92.387115  0.000298\n",
       "2     92.174230  0.000297\n",
       "3     91.961345  0.000297\n",
       "4     91.748459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsPElEQVR4nO3deXxU9b3/8dcnO0kIZCMsARI2MYiyhEVQ1AoIdcGtFrWCGy4tVWt7W3q9rf5s7a29vXWpS8UVtYLWlV5RiihqRZAgOwgEZN8CYY8QAt/fHzmJQ0wgyUxyJsn7+XjMY2a+55yZTw7hvHO+37OYcw4REZHKRPhdgIiIhC+FhIiIVEkhISIiVVJIiIhIlRQSIiJSpSi/CwiltLQ0l5WV5XcZIiINyvz583c659Irm9aoQiIrK4u8vDy/yxARaVDMbH1V09TdJCIiVVJIiIhIlRQSIiJSJYWEiIhUSSEhIiJVUkiIiEiVFBIiIlIlhQQwb10hD77/FbpsuojI8RQSwKKNe3hy1hr2HSrxuxQRkbCikABSEmIAKDxY7HMlIiLhRSEBJCskREQqpZAAUhUSIiKVUkgAyfGlIbFbISEichyFBJCa6O1JFCkkREQCKSSAZtGRxEZFqLtJRKQChQRgZqQkxCgkREQqUEh4FBIiIt8VkpAwsxFmttLM8s1sQiXTh5jZl2ZWYmZXBrT3MrPPzWyZmS02sx8GTHvBzL42s4Xeo1coaq2KQkJE5LuCvn2pmUUCjwPDgE3APDOb6pxbHjDbBuB64BcVFi8CxjjnVptZW2C+mU13zu3xpv+Hc+71YGusjpSEGNbvKqqPrxIRaTBCcY/r/kC+c24tgJlNAUYB5SHhnFvnTTsWuKBzblXA6y1mtgNIB/aEoK4aSY6P0SGwIiIVhKK7qR2wMeD9Jq+tRsysPxADrAlofsDrhnrIzGKDK/PEUhNi2H+4hOKSYyefWUSkiQiLgWszawO8BNzgnCvbSv8a6A70A1KAX1Wx7C1mlmdmeQUFBbWuoezSHLt1roSISLlQhMRmoH3A+0yvrVrMLAl4F7jHOTenrN05t9WVOgw8T2m31nc45yY653Kdc7np6em1+gFAF/kTEalMKEJiHtDVzLLNLAYYDUytzoLe/G8BL1YcoPb2LjAzAy4Floag1iopJEREvivokHDOlQDjgenACuA159wyM7vfzC4BMLN+ZrYJ+AHwlJkt8xa/ChgCXF/Joa5/N7MlwBIgDfh9sLWeiEJCROS7QnF0E865acC0Cm2/DXg9j9JuqIrLvQy8XMVnfi8UtVWXQkJE5LvCYuA6HLRsFg3ALoWEiEg5hYQnKjKCjKRYNu/+xu9SRETChkIiQHZaAl/vPOB3GSIiYUMhESA7LZF1ujSHiEg5hUSA7LR4Cg8Ws0cn1ImIAAqJ42SnJQLw9c6DPlciIhIeFBIBstMSAIWEiEgZhUSADinxRJhCQkSkjEIiQExUBO1T4hUSIiIehUQFWakJCgkREY9CooLScyUO4pzzuxQREd8pJCrolJ5AUfFRduw/7HcpIiK+U0hUUHaE09oCdTmJiCgkKshKLQ2JdbsUEiIiCokK2rZsRkxUhAavRURQSHxHZISRlRqv7iYRERQSldLVYEVESikkKpGVlsCGwiKOHD3mdykiIr5SSFRiQHYKR4463lm4xe9SRER8pZCoxHmntCKnTRJ//XA1JdqbEJEmLCQhYWYjzGylmeWb2YRKpg8xsy/NrMTMrqwwbayZrfYeYwPa+5rZEu8zHzUzC0Wt1WFm3DW0K+t3FfG29iZEpAkLOiTMLBJ4HBgJ5ABXm1lOhdk2ANcDr1RYNgW4FxgA9AfuNbNkb/KTwDigq/cYEWytNTEsJ4OcNkk8pr0JEWnCQrEn0R/Id86tdc4VA1OAUYEzOOfWOecWAxW3thcAM5xzhc653cAMYISZtQGSnHNzXOlFlF4ELg1BrdVmZtw5tCvrdhVpbEJEmqxQhEQ7YGPA+01eWzDLtvNen/QzzewWM8szs7yCgoJqF10dw729CY1NiEhT1eAHrp1zE51zuc653PT09JB+duDexNRF2psQkaYnFCGxGWgf8D7Tawtm2c3e69p8ZkgNz8ng1DZJ/PXDfO1NiEiTE4qQmAd0NbNsM4sBRgNTq7nsdGC4mSV7A9bDgenOua3APjMb6B3VNAZ4JwS11piZcef5Xfl650HtTYhIkxN0SDjnSoDxlG7wVwCvOeeWmdn9ZnYJgJn1M7NNwA+Ap8xsmbdsIfA7SoNmHnC/1wbwY+AZIB9YA7wXbK21VbY38Zj2JkSkibHGdAe23Nxcl5eXVyef/f7Sbdz28nxuP7czv7zgFOrxtA0RkTplZvOdc7mVTWvwA9f1ZXhOBj/om8mTs9bw08kLOHTkqN8liYjUuSi/C2goIiKMP115Op1bJfLg+1+xsbCIiWNyyUiK87s0EZE6oz2JGjAzbjunM0/9qC+rdxxg1GOfsXTzXr/LEhGpMwqJWhjeozWv3zaICIMr/zabj1eF9iQ+EZFwoZCopZy2Sbw9fjDtk+P57TtLOXqs8RwAICJSRiERhFbN4/j58G6s31XEe0u3+l2OiEjIKSSCNDynNZ3SE3jiozU0psOJRURAIRG0iIjSwezlW/dpbEJEGh2FRAhc2qsdbVrE8cRHa/wuRUQkpBQSIRATFcEtQzrxxbpC5q0rPPkCIiINhEIiREb360BKQgxPfJTvdykiIiGjkAiRZjGR3Dg4i49WFrBsi06wE5HGQSERQtedmUVibBRPztLYhIg0DgqJEGrRLJrrzuzIu0u2srbggN/liIgETSERYjcOziYmMoKnPl7rdykiIkFTSIRYevNYftivPW8u2MTctbv8LkdEJCgKiTpwx/ld6ZASz/XPz+Oz/J1+lyMiUmsKiTqQlhjLlFvOpENKPDe+ME9nYotIg6WQqCPpzWOZfMtAOqcnMm5SHh8s3+53SSIiNaaQqEMpCTG8Mm4A3ds057aX5/O+rhQrIg1MSELCzEaY2UozyzezCZVMjzWzV73pc80sy2u/1swWBjyOmVkvb9os7zPLprUKRa31rWV8DC/fPIDTM1vwk1cWMHXRFr9LEhGptqBDwswigceBkUAOcLWZ5VSY7SZgt3OuC/AQ8CCAc+7vzrlezrlewHXA1865hQHLXVs23Tm3I9ha/ZIUF82LNw2gb8dk7pqygDfmb/K7JBGRagnFnkR/IN85t9Y5VwxMAUZVmGcUMMl7/TpwvplZhXmu9pZtlBJjo3jhhn4M7JTKL15fxKvzNvhdkojISYUiJNoBGwPeb/LaKp3HOVcC7AVSK8zzQ2Byhbbnva6m31QSKgCY2S1mlmdmeQUF4X0UUXxMFM9d348hXdP51RtLeGnOer9LEhE5obAYuDazAUCRc25pQPO1zrmewNne47rKlnXOTXTO5TrnctPT0+uh2uDERUcycUxfhp7ait+8vZTn/v213yWJiFQpFCGxGWgf8D7Ta6t0HjOLAloAgacjj6bCXoRzbrP3vB94hdJurUYhNiqSJ67ty4gerbn//5bzt491QUARCU+hCIl5QFczyzazGEo3+FMrzDMVGOu9vhL40Hk3hDazCOAqAsYjzCzKzNK819HARcBSGpGYqAj+ek1vLj6jLX987yv++N5XHDume2SLSHiJCvYDnHMlZjYemA5EAs8555aZ2f1AnnNuKvAs8JKZ5QOFlAZJmSHARudc4BXxYoHpXkBEAh8ATwdba7iJjozg4R/2Iikuir99vIbNe77hzz84ndioSL9LExEBwLw/6BuF3Nxcl5eX53cZNeac46lP1vLH976if1YKE8f0pWV8jN9liUgTYWbznXO5lU0Li4Hrps7MuO2czjx6dW8WbtzD5U/OZmNhkd9liYgoJMLJJWe05aWb+rPrQDGXPfEZizbu8bskEWniFBJhZkCnVN64fRDNYiIZPXEOM3RhQBHxkUIiDHVplcibtw+mW0Yit76Ux4ufr/O7JBFpohQSYarsUuPf696K376zjD9MW6FDZEWk3ikkwlh8TBRPXZfLmDM7MvGTtfx08gIOHTnqd1ki0oQEfZ6E1K3ICOP/XdKD9snxPDBtBdv3HeLpMbkkJ+gQWRGpe9qTaADMjHFDOvH4NX1YvHkvlz85m/W7Dvpdlog0AQqJBuTC09vwys0D2F1UzOVPzGbBht1+lyQijZxCooHJzUrhzdsHkRAbxdVPz2H6sm1+lyQijZhCogHqlJ7Imz8eRPfWSdz28nxe+EyXGxeRuqGQaKDSEmOZPG4gw07N4L5/Lte9s0WkTigkGrBmMZE8fm0f+mUl86vXF7Ni6z6/SxKRRkYh0cBFR0bw+LV9aB4Xxa0vzWdv0RG/SxKRRkQh0Qi0ah7Hkz/qy9a933Dnqwt0ZraIhIxCopHo2zGZey/uwayVBTz8wSq/yxGRRkIh0YhcO6ADV+Vm8uiH+fxLh8aKSAgoJBoRM+P+UadxemYL7n5tEWsKDvhdkog0cAqJRiYuOpInf9SXmKgIbn1pPgcOl/hdkog0YCEJCTMbYWYrzSzfzCZUMj3WzF71ps81syyvPcvMvjGzhd7jbwHL9DWzJd4yj5qZhaLWpqBdy2Y8dk1v1hYc4D/+sYjGdB9zEalfQYeEmUUCjwMjgRzgajPLqTDbTcBu51wX4CHgwYBpa5xzvbzHbQHtTwLjgK7eY0SwtTYlgzqn8euRp/Le0m08+fEav8sRkQYqFHsS/YF859xa51wxMAUYVWGeUcAk7/XrwPkn2jMwszZAknNujiv9M/hF4NIQ1Nqk3Hx2Nhef0ZY/T1/JJ6sK/C5HRBqgUIREO2BjwPtNXlul8zjnSoC9QKo3LdvMFpjZx2Z2dsD8m07ymQCY2S1mlmdmeQUF2hAGMjMevKIn3TKac8eUBWwsLPK7JBFpYPweuN4KdHDO9QbuBl4xs6SafIBzbqJzLtc5l5uenl4nRTZkpXe368uxY45bX5rPN8W6s52IVF8oQmIz0D7gfabXVuk8ZhYFtAB2OecOO+d2ATjn5gNrgG7e/Jkn+Uyppo6pCTwyujcrtu3jnreWaCBbRKotFCExD+hqZtlmFgOMBqZWmGcqMNZ7fSXwoXPOmVm6N/CNmXWidIB6rXNuK7DPzAZ6YxdjgHdCUGuTdV73VvxsaDfeXLCZSbPX+V2OiDQQQd/j2jlXYmbjgelAJPCcc26Zmd0P5DnnpgLPAi+ZWT5QSGmQAAwB7jezI8Ax4DbnXKE37cfAC0Az4D3vIUEYf14XFm/ay+/fXUFO2xb0z07xuyQRCXPWmLoecnNzXV5ent9lhLV9h45w6WOfse9QCVPHD6Zty2Z+lyQiPjOz+c653Mqm+T1wLfUsKS6ap67ry+EjR7lpUh4HdUa2iJyAQqIJ6prRnMeu7cOq7fu5Y/ICjurS4iJSBYVEE3VOt3TuuziHmV/t4Cd//5J1Ow/6XZKIhKGgB66l4bruzCz2HSrhrx+uZsaK7VzZJ5Ofnt+FzOR4v0sTkTChgWthx75DPDFrDa/M3YDD8cN+7Rl/Xldat4jzuzQRqQcnGrhWSEi5LXu+4bGP8nlt3kYiIoxrB3Tg9nM706q5wkKkMVNISI1sLCzi0ZmreXPBZqIjjbGDsrh1SGdSEmL8Lk1E6oBCQmrl650HeeSDVbyzaAvx0ZHceFY2N5/diRbNov0uTURCSCEhQVm9fT8Pf7Cad5dspXlcFOPO7sQNg7NoHqewEGkMFBISEsu37OOhD1YxY/l2WsZHc+uQzowd1JH4GB0kJ9KQKSQkpBZv2sNfZqxi1soC0hJjuKJPJoO6pNEvK1mBIdIAKSSkTsxfX8ijM/OZvWYnR446oiON3h2SGdw5jcFdUjmjfUuiI3W+pki4U0hInSoqLmHeut3Mzt/JZ2t2smzLPpyDhJhI+menMLhLGoM6p9G9dXMiIqq8a62I+OREIaG+AQlafEwU53RL55xupXcG3H2wmDlrd/HZmp3Mzt/FRytXAJCSEMOZnVPL9zQ6pMRzgludi0gYUEhIyCUnxDCyZxtG9mwDwNa93/BZ/q7yPY13F28FoF3LZgzqnMoNg7PJaVuju9aKSD1Rd5PUK+ccawoOMtvby/hszU4OHTnKL4afwrizO6k7SsQHGpOQsLX7YDG/fnMJ7y/bxsBOKfzlql66EZJIPdNNhyRsJSfE8OSP+vCnK05n8aa9jHj4E/65aIvfZYmIRyEhvjMzrurXnml3nE2n9ER+OnkBd7+6kP2HjvhdmkiTp5CQsJGVlsA/bjuTO87vytsLNzPykU/JW1fod1kiTVpIQsLMRpjZSjPLN7MJlUyPNbNXvelzzSzLax9mZvPNbIn3/L2AZWZ5n7nQe7QKRa0S3qIjI7h7WDf+cdsgIsy46qnP+d9/reTI0WN+lybSJAUdEmYWCTwOjARygKvNLKfCbDcBu51zXYCHgAe99p3Axc65nsBY4KUKy13rnOvlPXYEW6s0HH07JjPtzrO5vE8mf/0wnyufnM3XusWqSL0LxZ5EfyDfObfWOVcMTAFGVZhnFDDJe/06cL6ZmXNugXOubJRyGdDMzGJDUJM0AomxUfz5B2fwxLV9WLeriO8/8imTv9hAYzoiTyTchSIk2gEbA95v8toqncc5VwLsBVIrzHMF8KVz7nBA2/NeV9NvrIpTc83sFjPLM7O8goKCYH4OCVPf79mG9+86mz4dW/LrN5dw60vzKTxY7HdZIk1CWAxcm1kPSrugbg1ovtbrhjrbe1xX2bLOuYnOuVznXG56enrdFyu+aNOiGS/dOIB7vn8qs1YWcMHDn/DxKv1RIFLXQhESm4H2Ae8zvbZK5zGzKKAFsMt7nwm8BYxxzq0pW8A5t9l73g+8Qmm3ljRhERHGuCGdePsng0mOj2bsc19w39Rl7Nh/yO/SpAn7pvgo976ztNEesh2KkJgHdDWzbDOLAUYDUyvMM5XSgWmAK4EPnXPOzFoC7wITnHOflc1sZlFmlua9jgYuApaGoFZpBHLaJjF1/FlcPyiLF2avY+AfZnLds3N5Y/4mDhwu8bs8aWL+Pnc9kz5fz2Mf5ftdSp0IOiS8MYbxwHRgBfCac26Zmd1vZpd4sz0LpJpZPnA3UHaY7HigC/DbCoe6xgLTzWwxsJDSPZGng61VGo+46Ejuu6QHH9w9hB+f24Wvdx7k5/9YRO7vZzD+lS+ZuWK7DpuVenHMO5Di2LHGeUCFrt0kjYJzji837OatBZt5d/FWdhcdITk+mgtPb8OlvdrRt2OyLksudWLiJ2v4w7SvuPmsbP7roopH/zcMup+ENHpmRt+OKfTtmMJvL+rBp6sLeHvhFl6fv4mX52wgM7kZl/Zqx6W929KlVXO/y5VGxGjcf3woJKTRiYmK4PxTMzj/1AwOHC5h+tJtvL1wM0/Myuexj/Lp0TaJS3u145JebclIivO7XGkkGk+fzPEUEtKoJcZGcUXfTK7om8mO/Yf4v0VbeWfhZh6YtoI/vLei9KZHg7I5/9RW6o6SWin7tWlEPffHUUhIk9GqeRw3npXNjWdls7bgAG8v3MJbCzZx84t5nHdKOvdd0oOOqQl+lykSVsLiZDqR+tYpPZG7h3Xjw5+fy39deCrz1u1m2EOf8JcZqzh05Kjf5UkTceToMWbn76zVsvsPHeHLDbtDXNF3KSSkSYuOjODmszsx8+fnMPK01jw6czVD//IxM5Zv1zWipFrKuildLUYl/jx9Jdc8M7dWG/tbXpzP5U/MrvM/ahQSIkBGUhyPjO7N5HEDiY+JZNyLedw0KY/1u3TlWTmxspGs2vxNkb/jAAC7DtT8WmSLN+0BqPPzgRQSIgHO7JzKu3eczX9deCpz1+5SF5TUqW8HvWueMN/uwdQthYRIBWVdUB/+4tzyLqhhD33MB8u3+12aNDq1P6Kuvo7FU0iIVCGwCyouKpKbX8zjxhfmqQtKjhPM3kCZYPYG6nroTCEhchJndk5l2p3Hd0E9pC4o8QTzF31Q51iUD4YEUUA1KCREqqFiF9Qj6oKSCoLZzteGuptEwlBlXVB/ev8rv8sSH4XmTP1guqrqdldCISFSC2VdUFf378ATs9bwxKzGeS8Bqb7adBkF091UfnRTHXc36bIcIrUUHRnBA5eeRlFxCX96fyXNY6O47swsv8uSela+oa/FX/TBXEG2vi41ppAQCUJEhPHnH5zBwcNH+c07y0iMi+Ky3pl+lyX1yN/OJp0nIRL2oiMjeOya3gzqnMov/rGY6cu2+V2SNBBBdTd5z8fquL9JISESAnHRkTw9Jpee7Vrw01cW8O/VtbtomzRcwYxJ1EZ9jUkoJERCJCE2ihdu6Een9ATGvZjH/PV1f4VOCQNBXB6jbEyiduMZ1HrZmlBIiIRQy/gYXrypPxlJsdzw/Bcs37LP75KkjgU1JhHU0U21X7YmQhISZjbCzFaaWb6ZTahkeqyZvepNn2tmWQHTfu21rzSzC6r7mSLhqlXzOF6+eQAJsVGMeW4uawsO+F2S1AO/riwf9iFhZpHA48BIIAe42sxyKsx2E7DbOdcFeAh40Fs2BxgN9ABGAE+YWWQ1P1MkbGUmx/PyzQNwDn70zFw27/nG75KkjgQ1ruA91247X/uuqpoIxZ5EfyDfObfWOVcMTAFGVZhnFDDJe/06cL6VjrqMAqY45w47574G8r3Pq85nioS1zumJvHhTf/YfLuFHz8ylYP9hv0uSOhXE5b5rdanw0udj4b4nAbQDNga83+S1VTqPc64E2AuknmDZ6nwmAGZ2i5nlmVleQUFBED+GSOj1aNuCF27ox7a9h7ju2bnsLTrid0kSYuWDz751N4X/noSvnHMTnXO5zrnc9PR0v8sR+Y6+HVOYOKYvawsOcv0LX3DwcInfJUkIhaK7KZhlw35MAtgMtA94n+m1VTqPmUUBLYBdJ1i2Op8p0mCc3TWdR6/uzeJNexn3Yp4uMy5AsNduqv2yNRGKkJgHdDWzbDOLoXQgemqFeaYCY73XVwIfutJ9pKnAaO/op2ygK/BFNT9TpEEZcVpr/nTF6cxes4vbXp6voGgk6usv+qqE/cC1N8YwHpgOrABec84tM7P7zewSb7ZngVQzywfuBiZ4yy4DXgOWA+8DP3HOHa3qM4OtVcRvV/TN5I+X92TWygIFRSPx7QBy/Z4QV19jISG5wJ9zbhowrULbbwNeHwJ+UMWyDwAPVOczRRqD0f07ADDhzSXc9vJ8/vajvsRFR/pcldRW2b/doZJjNV42mEtrBBNONdHgB65FGqLR/TuU71Fc+bfZ5O/QCXcNVWxUaUj4dUCCrgIr0kiN7t+Bp8fksnn3N1z01095ec76Oj+cUerOgVqERDDjGQ3p6CYRqaVhORlMv2sI/bJS+K+3lzLuxTx2HtBJdw1L6Vb6WG3Oaiu/YVEtFg3iRLyaUEiI+KxVUhyTbujPby/K4ZPVOxnx8Kd8tHKH32VJDeWt383Ruj79uRLqbhJpAiIijBvPymbq+MGkJsRww/PzuG/qMh391AAE/iFf05D49gil2m/qNXAt0oR0b53EO+MHc8PgLF6YvY5LHvu3Ljce5gI30TXdYDeLKd0EP/rhas75n49quGzpgPl/vrmE0RM/r9GyNaGQEAkzcdGR3HtxDybd2J/dRUe49PHPeObTtbXr85Z69Y+8jby7eGu152/RLBqAjYXfsH5XER+vqv7158qW/XLDHuasLayzKw0rJETC1Dnd0nn/zrM555R0fv/uCsY89wXb9x3yuyypIHDn4TfvLOOXry+q9rLxMcefqrZ0894aLHv8uTXb9tbN74ZCQiSMpSbGMvG6vvzhsp7MX7+bCx7+hPeXbvO7LDmBqMjqb1ZjajDvyZetmz1NhYRImDMzrhnQgf+74yzaJ8dz28vz+dXri3U12TBR8ZIa0ZHVv7ZrRMTx89ZkADu6QkjU1fi1QkKkgeicnsgbtw/ix+d25rX5G7nw0U+Znb+TwyU6AspPFTfOURG136xu31f9c2Sio47/nt11dK+SkFy7SUTqR0xUBL8c0Z0h3dK5+9WFXPPMXKIjjS6tmpPTJomctkmlz22SaBEf7Xe5TVJUDfYkKu45vDRnPb+79LRqLVtxj+Wfi7YwLCej2t9dXQoJkQZoYKdUpv9sCLNWFrBsyz6Wb93Hx6t28MaXm8rnyUxudnxwtE2iXctm5WfqSuX2HzrC9/73Y3I7JjNhZHc6piaccP6KvTwVu4HqSsUxiaRmdbM5V0iINFDN46K5+Iy2XHxG2/K2HfsPsdwLjbLnGSu2l3eJJMVFeaHRojw8umUk1miwtbHbffAIBfsP897SbcxcsYPrB2cx/ntdSIqrfM+s4t5AZETtQ7hnuxbVnrfieEaX9MRaf++JKCREGpFWzeNodUoc557SqrytqLiEr7btPy48XvliPYeOlF7aOiUhhgt6ZDDytDac2Tm13v4SDldlJ8T9akR31hQc4OlP1/L+0m28Mm4AmcnxJ10+qgYhUXE844HLqtfVBFDxa8acmVXtZWtCISHSyMXHRNGnQzJ9OiSXtx095vh650GWbdnLzBU7mLpwC5O/2EjL+GiG52Tw/Z5tGNQ5jZiophcYZdvtNi3iuP3czozu154bX5jHD5+aw+RxA+mQeuKg6JBy8iD59ruOT4mE2Opvkq3CHbIr7lmEikJCpAmKjDC6tEqkS6tERvVqx6EjR/lkVQHTlmxl2pJtvJa3iaS4KIb3aM33e7ZmcJe08vsmNHZlexJlQze5WSm8Mm4gP3p2Lj+c+DmvjBtIdtq34xRlewNv3H4mbVs2o02LZjX+zr4dk7no9DZ0rkGXUVl9F/Zsw3ndW5145iAoJESEuOhIhvdozfAerTlccpRPV+1k2tKtTF+2jdfnb6J5XBTDTi3dwzira1qjvpOeKw+Jb/8yP61dC1652QuKpz5n8i0Dv7NBT0mIrXFAlAVMakIMNwzOrtWy2WkJXNk3s0bL1oRCQkSOExsVydCcDIbmZHC45Ciz83cxbclW/rV8O28u2ExibBRDT23FyJ5tOKdbeqMLjLKNb8Xem5y2SUweN5Brn5njdT0NoGtG81rdn7r8u7zn2lyWq+x7j4bzVWDNLMXMZpjZau85uYr5xnrzrDazsV5bvJm9a2ZfmdkyM/tjwPzXm1mBmS30HjcHU6eI1E5sVCTndW/F//zgDObdM5RJN/bnwp5tmLWqgFtfmk+/33/As//+2pf7KNSVsh+lYp8/wCmtmzPlloGYwTXPzGXfoSPloRLMiEBjvlT4BGCmc64rMNN7fxwzSwHuBQYA/YF7A8Lkz8657kBvYLCZjQxY9FXnXC/v8UyQdYpIkGKiIjinWzoPXnk68+4Zyks39advVjK/+7/lXPr4ZzW6OF04K9voVjUO3KVVc54Zk0vB/sM8++nX5e21Of2kbPtemw19+bJ1HNDBhsQoYJL3ehJwaSXzXADMcM4VOud2AzOAEc65IufcRwDOuWLgS6DuOtZEJGSiIyM4u2s6z1/fj8eu6c3WvYcY9fhn/GHaCoqKG/Y1pcr3DE6w1T+jfUtGntaaZz5dS+HB4vL2jYVFTHhjMfsPVe8SGWVdRsccfLVtH/e8taTae2XBdFXVRLAhkeGcK7t4+jagsnPC2wEbA95v8trKmVlL4GJK90bKXGFmi83sdTNrX1UBZnaLmeWZWV5BQfWvxS4iwTMzLjq9LTPvPoercjOZ+Mlahj/0CbMa8O1XKx7dVJW7h3XjmyNHefbfpXsThrG7qJgp8zby9Cdra/SdDvi64CB/n7vhuLPmq6Ouu/pOGhJm9oGZLa3kMSpwPlfaqVbjas0sCpgMPOqcK1uz/wSynHOnU7rnMamq5Z1zE51zuc653PT09Jp+vYiEQIv4aP778tN57dYziY2K4Prn53HH5AUU7K/+BevCxbcD1ydOia4ZzbmsdyZbvfs4mMHpmS25sGcbnvn319X62cu+yznHiNNac0ZmCx6esapat60NXLYunTQknHNDnXOnVfJ4B9huZm0AvOfK/nzYDATuCWR6bWUmAqudcw8HfOcu51zZGn4G6Fujn0pEfNE/O4Vpd57NXUO78v7SbQz9y8e8Nm9jnW/IQqmsC6g656bdNbTrdy609/Ph3ThccozHP8qv9ncecw4z41cjurNl7yFenrO+2suG9dFNwFRgrPd6LPBOJfNMB4abWbI3YD3ca8PMfg+0AO4KXKAseDyXACuCrFNE6klsVCR3De3GtDvP4pSM5vzyjcVc/fQc1hYc8Lu0aik/uqkaIdE+JZ5r+ncAvr2wX6f0RK7Kbc/f565nw66i6n1n6RVSGNQljbO7pvH4R/nsO+m4xrfjGXUp2JD4IzDMzFYDQ733mFmumT0D4JwrBH4HzPMe9zvnCs0sE7gHyAG+rHCo6x3eYbGLgDuA64OsU0TqWZdWpYeL/vflPVm2ZR8jHvmUR2euprjkmN+lnVBlJ9OdyC9HdOep6/rSukVcedtdQ7sSYcZDH6yq1ncFHt30ywu6s7voCM+cZFyjQRzd5HULne+c6+p1SxV67XnOuZsD5nvOOdfFezzvtW1yzplz7tSKh7o6537tnOvhnDvDOXeec+6rYOoUEX9ERBhX9+/AzJ+fw/CcDP4yYxUXPvopeesK/S6tSseqOSZRJiE2igt6tD6uLSMpjhsGZ/P2ws2s2LrvpJ8R2GPUM7MFF55e/XGNcD9PQkTkpFo1j+Oxa/rw3PW5FBUf5cq/fc5/vrWEvd/Uzd3UglG+JxHk59x+Tmeax0bxP9NXnuC7Sp9jo4/fFP9i+CkcLjnGYx+uPumydX2Zd4WEiNSb73XP4F8/G8JNZ2Uz5YsNDPzDTG55MY9/5G087nwDP5X9XV7dPYmqtIiP5vZzu/DhVzt4bd7GSucp+64Xbuh/XHt2WgI/7NeeV77YwMerKj+03+FonRTHHy7rGVSdJ6NrN4lIvUqIjeI3F+VwWe92vDpvIzOWb+dfy7cTYZDbMYVhORkMy8kgK+3Ed4SrK2V9/KG4gd8Ng7OYvWYnv3xjMbuLirn1nM7VXvY/hp/Cwg17uHnSPP73ql5cEnBzqfqkkBARX5zWrgWntWvB/aN6sHTzPmYs38a/lm/ngWkreGDaCrq2SiwPjDMyW9bZ/RIqqsnRTScTFx3JM2Nzufu1Rfz3e19ReLCYCSO7lw+Kn+i6T8kJMUy5dSDjJuVx55QF7CkqPu7GQs6FpsaTUUiIiK/MjJ6ZLeiZ2YK7h5/CxsIiZizfzozl23nqk7U8MWsNrZrHcv6pGQzPyeDMzql1euXZb8+TCM0WODYqkkdH9yY5PpqnPlnLroPF/PHynkRFRpR/V1VflRQXzaQb+/PTyQv47TvL2HmgmJ8N7YqZ4Qh+3KQ6FBIiElbap8Rz41nZ3HhWNnuKivlo5Q5mLN/O1IWbmfzFBhJiIhnSLZ1hORkM6JRKUlwUCTFRIdvTCMVVXSuKjDB+N+o0UhNieWTmavYUHeGR0b2qtWxcdCRPXtuH/3xrCY/OXE3hwcPce3GPEFZ3YgoJEQlbLeNjuKx3Jpf1zuTQkaN8vnYXM5Zv54Pl23lv6bbj5m0WHUlCbBSJsaXPpa+jvm2LiSI+YHpibGm4JMRG0TwuirTEWFITY769CmyIu7fMjJ8N60ZKQgz3/XMZPe6dTpx3VNPJzsmIiozgwStOJyUhlr99vIbJX2wkKsJIS4wNaY2Vfnedf4OISAjERUdy3imtOO+UVvx+1Gks3ryX5Vv2cfBwCQcOl3DwcAkHi0s4cPhoedv2fYe89tK2ouKTXxMpPqa0K6uuunLGDsqie+vmzFlbyIbCIlITY6q1nJkxYWR3cjsms3DjHjYUFnFqm6Q6qjLgexvSNVVOJjc31+Xl5fldhoiEqaPHHEXFJRw8fPTbYDlcwr5DR9h5oJidBw6z60AxJcccv7noVOJjmsbf0WY23zmXW9m0prEGREQoHRtoHhdN87hov0tpMHQynYiIVEkhISIiVVJIiIhIlRQSIiJSJYWEiIhUSSEhIiJVUkiIiEiVFBIiIlKlRnXGtZkVAOtruXgasDOE5TRmWlfVo/VUPVpP1VdX66qjcy69sgmNKiSCYWZ5VZ2WLsfTuqoerafq0XqqPj/WlbqbRESkSgoJERGpkkLiWxP9LqAB0bqqHq2n6tF6qr56X1cakxARkSppT0JERKqkkBARkSopJAAzG2FmK80s38wm+F2P38xsnZktMbOFZpbntaWY2QwzW+09J3vtZmaPeutusZn18bf6umVmz5nZDjNbGtBW43VjZmO9+Veb2Vg/fpa6VMV6us/MNnu/VwvN7PsB037traeVZnZBQHuj/r9pZu3N7CMzW25my8zsTq89fH6nnHNN+gFEAmuATkAMsAjI8bsun9fJOiCtQtufgAne6wnAg97r7wPvUXpL4IHAXL/rr+N1MwToAyyt7boBUoC13nOy9zrZ75+tHtbTfcAvKpk3x/t/Fwtke/8fI5vC/02gDdDHe90cWOWtj7D5ndKeBPQH8p1za51zxcAUYJTPNYWjUcAk7/Uk4NKA9hddqTlASzNr40N99cI59wlQWKG5puvmAmCGc67QObcbmAGMqPPi61EV66kqo4ApzrnDzrmvgXxK/182+v+bzrmtzrkvvdf7gRVAO8Lod0ohUfoPsjHg/SavrSlzwL/MbL6Z3eK1ZTjntnqvtwEZ3mutv5qvm6a8zsZ73STPlXWhoPUEgJllAb2BuYTR75RCQipzlnOuDzAS+ImZDQmc6Er3b3XsdCW0bk7oSaAz0AvYCvyvr9WEETNLBN4A7nLO7Quc5vfvlEICNgPtA95nem1NlnNus/e8A3iL0t3+7WXdSN7zDm92rb+ar5smuc6cc9udc0edc8eApyn9vYImvp7MLJrSgPi7c+5NrzlsfqcUEjAP6Gpm2WYWA4wGpvpck2/MLMHMmpe9BoYDSyldJ2VHTIwF3vFeTwXGeEddDAT2BuwmNxU1XTfTgeFmlux1uQz32hq1CmNVl1H6ewWl62m0mcWaWTbQFfiCJvB/08wMeBZY4Zz7S8Ck8Pmd8nt0PxwelB4xsIrSIynu8bsen9dFJ0qPIlkELCtbH0AqMBNYDXwApHjtBjzurbslQK7fP0Mdr5/JlHaVHKG03/em2qwb4EZKB2jzgRv8/rnqaT295K2Hxd7Grk3A/Pd462klMDKgvVH/3wTOorQraTGw0Ht8P5x+p3RZDhERqZK6m0REpEoKCRERqZJCQkREqqSQEBGRKikkRESkSgoJERGpkkJCRESq9P8Bqvd19Nf8p2kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 89.3180  # Value for C0\n",
    "K0 = -0.0010  # Value for K0\n",
    "K1 = 0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = -0.0204    # Value for b\n",
    "c = 2.2194    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    92.600000    92.387115    92.174230    91.961345    91.748459   \n",
      "351    92.387115    92.174230    91.961345    91.748459    91.535574   \n",
      "352    92.174230    91.961345    91.748459    91.535574    91.322689   \n",
      "353    91.961345    91.748459    91.535574    91.322689    91.109804   \n",
      "354    91.748459    91.535574    91.322689    91.109804    90.896919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    91.535574    91.322689    91.109804    90.896919    90.691597  ...   \n",
      "351    91.322689    91.109804    90.896919    90.691597    90.579552  ...   \n",
      "352    91.109804    90.896919    90.691597    90.579552    90.467507  ...   \n",
      "353    90.896919    90.691597    90.579552    90.467507    90.355462  ...   \n",
      "354    90.691597    90.579552    90.467507    90.355462    90.243417  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   80.261671    0.000263   80.252334    0.000263   80.242997    0.000263   \n",
      "351   80.252334    0.000263   80.242997    0.000263   80.233660    0.000262   \n",
      "352   80.242997    0.000263   80.233660    0.000262   80.224323    0.000262   \n",
      "353   80.233660    0.000262   80.224323    0.000262   80.214986    0.000262   \n",
      "354   80.224323    0.000262   80.214986    0.000262   80.205649    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   80.233660    0.000262   80.224323    0.000262  \n",
      "351   80.224323    0.000262   80.214986    0.000262  \n",
      "352   80.214986    0.000262   80.205649    0.000262  \n",
      "353   80.205649    0.000262   80.196312    0.000262  \n",
      "354   80.196312    0.000262   80.186975    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 1, 251) (1600, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 23ms/step - loss: 5642.5044 - val_loss: 4385.1162\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5575.1899 - val_loss: 4338.1787\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5520.5996 - val_loss: 4291.5005\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5466.1553 - val_loss: 4243.4883\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5408.6382 - val_loss: 4194.0269\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5351.0327 - val_loss: 4145.1445\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5294.3066 - val_loss: 4097.0693\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5238.3882 - val_loss: 4049.6465\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5183.1279 - val_loss: 4002.7844\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5128.4443 - val_loss: 3956.4265\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5074.2856 - val_loss: 3910.5435\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5020.6226 - val_loss: 3865.1125\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4967.4351 - val_loss: 3820.1196\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4914.7065 - val_loss: 3775.5527\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4862.4287 - val_loss: 3731.4038\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4810.5879 - val_loss: 3687.6641\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4759.1792 - val_loss: 3644.3276\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4708.1953 - val_loss: 3601.3906\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4657.6313 - val_loss: 3558.8464\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4607.4814 - val_loss: 3516.6919\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4557.7412 - val_loss: 3474.1978\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4493.0869 - val_loss: 3416.7214\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4436.3779 - val_loss: 3370.2200\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4381.9375 - val_loss: 3325.2007\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4328.9663 - val_loss: 3281.2625\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4277.0791 - val_loss: 3238.1665\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4226.0576 - val_loss: 3195.7788\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4175.7744 - val_loss: 3154.0161\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4126.1509 - val_loss: 3112.8242\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4077.1309 - val_loss: 3072.1658\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4028.6750 - val_loss: 3032.0098\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3980.7551 - val_loss: 2992.3352\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3933.3457 - val_loss: 2953.1243\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3886.4292 - val_loss: 2914.3625\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3839.9897 - val_loss: 2876.0364\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3794.0129 - val_loss: 2838.1362\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3748.4910 - val_loss: 2800.6528\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3703.4109 - val_loss: 2763.5776\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3658.7656 - val_loss: 2726.9050\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3614.5474 - val_loss: 2690.6265\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3570.7485 - val_loss: 2654.7371\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3527.3625 - val_loss: 2619.2317\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3484.3840 - val_loss: 2584.1047\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3441.8081 - val_loss: 2549.3511\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3399.6294 - val_loss: 2514.9680\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3357.8433 - val_loss: 2480.9495\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3316.4453 - val_loss: 2447.2930\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3275.4312 - val_loss: 2413.9939\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3234.7974 - val_loss: 2381.0488\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3194.5396 - val_loss: 2348.4546\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3154.6543 - val_loss: 2316.2085\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3115.1382 - val_loss: 2284.3054\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3075.9878 - val_loss: 2252.7449\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3037.2002 - val_loss: 2221.5220\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2998.7722 - val_loss: 2190.6345\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2960.7009 - val_loss: 2160.0801\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2922.9832 - val_loss: 2129.8552\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 2885.6157 - val_loss: 2099.9575\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2848.5959 - val_loss: 2070.3843\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2811.9219 - val_loss: 2041.1334\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2775.5908 - val_loss: 2012.2025\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2739.5994 - val_loss: 1983.5886\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2703.9458 - val_loss: 1955.2894\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2668.6274 - val_loss: 1927.3031\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2633.6411 - val_loss: 1899.6267\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2598.9849 - val_loss: 1872.2578\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2564.6572 - val_loss: 1845.1949\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2530.6553 - val_loss: 1818.4353\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2496.9766 - val_loss: 1791.9773\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2463.6189 - val_loss: 1765.8180\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2430.5798 - val_loss: 1739.9554\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2397.8577 - val_loss: 1714.3883\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2365.4497 - val_loss: 1689.1140\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2333.3552 - val_loss: 1664.1305\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2301.5708 - val_loss: 1639.4355\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2270.0947 - val_loss: 1615.0280\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2238.9246 - val_loss: 1590.9050\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2208.0596 - val_loss: 1567.0653\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2177.4961 - val_loss: 1543.5059\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2147.2336 - val_loss: 1520.2258\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2117.2688 - val_loss: 1497.2227\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 2087.6008 - val_loss: 1474.4948\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2058.2275 - val_loss: 1452.0402\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2029.1469 - val_loss: 1429.8572\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2000.3571 - val_loss: 1407.9441\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1971.8562 - val_loss: 1386.2990\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1943.6423 - val_loss: 1364.9193\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1915.7136 - val_loss: 1343.8042\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1888.0690 - val_loss: 1322.9518\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1860.7057 - val_loss: 1302.3593\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1833.6221 - val_loss: 1282.0261\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1806.8168 - val_loss: 1261.9504\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1780.2881 - val_loss: 1242.1301\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1754.0338 - val_loss: 1222.5641\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1728.0525 - val_loss: 1203.2493\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1702.3425 - val_loss: 1184.1848\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1676.9023 - val_loss: 1165.3691\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1651.7297 - val_loss: 1146.8010\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1626.8237 - val_loss: 1128.4775\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1602.1819 - val_loss: 1110.3983\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1577.8032 - val_loss: 1092.5605\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1553.6857 - val_loss: 1074.9631\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1529.8276 - val_loss: 1057.6046\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1506.2274 - val_loss: 1040.4830\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1482.8843 - val_loss: 1023.5973\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 1459.7952 - val_loss: 1006.9447\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1436.9592 - val_loss: 990.5238\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1414.3744 - val_loss: 974.3350\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1392.0400 - val_loss: 958.3744\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1369.9543 - val_loss: 942.6409\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1348.1152 - val_loss: 927.1338\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1326.5214 - val_loss: 911.8506\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1305.1711 - val_loss: 896.7902\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1284.0631 - val_loss: 881.9505\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1263.1956 - val_loss: 867.3312\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1242.5679 - val_loss: 852.9294\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1222.1771 - val_loss: 838.7440\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1202.0227 - val_loss: 824.7733\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1182.1028 - val_loss: 811.0167\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1162.4159 - val_loss: 797.4709\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1142.9604 - val_loss: 784.1362\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1123.7351 - val_loss: 771.0094\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1104.7380 - val_loss: 758.0898\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1085.9680 - val_loss: 745.3762\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1067.4236 - val_loss: 732.8668\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1049.1038 - val_loss: 720.5599\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1031.0062 - val_loss: 708.4538\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1013.1296 - val_loss: 696.5478\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 995.4728 - val_loss: 684.8395\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 978.0345 - val_loss: 673.3279\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 960.8130 - val_loss: 662.0114\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 943.8073 - val_loss: 650.8888\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 927.0150 - val_loss: 639.9580\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 910.4352 - val_loss: 629.2173\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 894.0661 - val_loss: 618.6656\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 877.9066 - val_loss: 608.3021\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 861.9554 - val_loss: 598.1243\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 846.2112 - val_loss: 588.1310\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 830.6722 - val_loss: 578.3209\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 815.3368 - val_loss: 568.6926\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 800.2044 - val_loss: 559.2441\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 785.2726 - val_loss: 549.9742\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 770.5405 - val_loss: 540.8815\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 756.0067 - val_loss: 531.9640\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 741.6696 - val_loss: 523.2214\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 727.5278 - val_loss: 514.6504\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 713.5795 - val_loss: 506.2510\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 699.8239 - val_loss: 498.0210\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 686.2591 - val_loss: 489.9588\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 672.8840 - val_loss: 482.0632\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 659.6973 - val_loss: 474.3334\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 646.6976 - val_loss: 466.7668\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 633.8826 - val_loss: 459.3625\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 621.2526 - val_loss: 452.1186\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 608.8047 - val_loss: 445.0344\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 596.5385 - val_loss: 438.1072\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 584.4518 - val_loss: 431.3368\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 572.5437 - val_loss: 424.7209\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 560.8129 - val_loss: 418.2579\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 549.2570 - val_loss: 411.9469\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 537.8756 - val_loss: 405.7856\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 526.6667 - val_loss: 399.7733\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 515.6295 - val_loss: 393.9080\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 504.7623 - val_loss: 388.1886\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 494.0637 - val_loss: 382.6128\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 483.5324 - val_loss: 377.1805\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 473.1670 - val_loss: 371.8887\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 462.9659 - val_loss: 366.7369\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 452.9278 - val_loss: 361.7227\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 443.0514 - val_loss: 356.8456\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 433.3349 - val_loss: 352.1033\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 423.7772 - val_loss: 347.4946\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 414.3767 - val_loss: 343.0176\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 405.1323 - val_loss: 338.6716\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 396.0429 - val_loss: 334.4549\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 387.1063 - val_loss: 330.3652\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 378.3218 - val_loss: 326.4016\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 369.6873 - val_loss: 322.5624\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 361.2021 - val_loss: 318.8463\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 352.8641 - val_loss: 315.2512\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 344.6721 - val_loss: 311.7759\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 336.6248 - val_loss: 308.4189\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 328.7207 - val_loss: 305.1788\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 320.9586 - val_loss: 302.0539\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 313.3368 - val_loss: 299.0425\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 305.8540 - val_loss: 296.1434\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 298.5091 - val_loss: 293.3548\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 291.3000 - val_loss: 290.6753\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 284.2261 - val_loss: 288.1034\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 277.2856 - val_loss: 285.6374\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 270.4771 - val_loss: 283.2759\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 263.7993 - val_loss: 281.0172\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 257.2502 - val_loss: 278.8598\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 250.8289 - val_loss: 276.8021\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 244.5338 - val_loss: 274.8427\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 238.3637 - val_loss: 272.9798\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 232.3168 - val_loss: 271.2121\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 226.3920 - val_loss: 269.5380\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 220.5880 - val_loss: 267.9559\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 214.9028 - val_loss: 266.4641\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 209.3357 - val_loss: 265.0612\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 203.8849 - val_loss: 263.7458\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 198.5486 - val_loss: 262.5160\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 193.3258 - val_loss: 261.3706\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 188.2154 - val_loss: 260.3077\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 183.2155 - val_loss: 259.3260\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 178.3248 - val_loss: 258.4240\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 173.5419 - val_loss: 257.5998\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 168.8654 - val_loss: 256.8522\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 164.2938 - val_loss: 256.1796\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 159.8257 - val_loss: 255.5804\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 155.4600 - val_loss: 255.0529\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 151.1947 - val_loss: 254.5957\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 147.0290 - val_loss: 254.2074\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 142.9612 - val_loss: 253.8862\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 138.9900 - val_loss: 253.6308\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 135.1136 - val_loss: 253.4396\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 131.3310 - val_loss: 253.3110\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 127.6406 - val_loss: 253.2435\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 124.0412 - val_loss: 253.2356\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 120.5310 - val_loss: 253.2859\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 117.1090 - val_loss: 253.3927\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 113.7741 - val_loss: 253.5547\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 110.5242 - val_loss: 253.7702\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 107.3583 - val_loss: 254.0378\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 104.2749 - val_loss: 254.3561\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 101.2728 - val_loss: 254.7235\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 98.3505 - val_loss: 255.1385\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 95.5066 - val_loss: 255.5999\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 92.7400 - val_loss: 256.1059\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 90.0490 - val_loss: 256.6552\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 87.4324 - val_loss: 257.2465\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 84.8887 - val_loss: 257.8782\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 82.4168 - val_loss: 258.5489\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 80.0153 - val_loss: 259.2572\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 77.6830 - val_loss: 260.0016\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 75.4184 - val_loss: 260.7810\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 73.2202 - val_loss: 261.5937\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 71.0872 - val_loss: 262.4385\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 69.0181 - val_loss: 263.3140\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 67.0114 - val_loss: 264.2188\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 65.0661 - val_loss: 265.1517\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 63.1807 - val_loss: 266.1113\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 61.3541 - val_loss: 267.0962\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 59.5851 - val_loss: 268.1051\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 57.8722 - val_loss: 269.1369\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 56.2145 - val_loss: 270.1904\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 54.6104 - val_loss: 271.2641\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 53.0590 - val_loss: 272.3568\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 51.5589 - val_loss: 273.4673\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 50.1090 - val_loss: 274.5946\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 48.7082 - val_loss: 275.7371\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 47.3552 - val_loss: 276.8941\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 46.0488 - val_loss: 278.0640\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 44.7881 - val_loss: 279.2460\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 43.5717 - val_loss: 280.4388\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 42.3986 - val_loss: 281.6414\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 41.2677 - val_loss: 282.8527\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 40.1778 - val_loss: 284.0717\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 39.1279 - val_loss: 285.2972\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 38.1169 - val_loss: 286.5282\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 37.1439 - val_loss: 287.7638\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 36.2077 - val_loss: 289.0030\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 35.3072 - val_loss: 290.2448\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 34.4416 - val_loss: 291.4882\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 33.6098 - val_loss: 292.7324\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 32.8108 - val_loss: 293.9766\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 32.0436 - val_loss: 295.2195\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 31.3074 - val_loss: 296.4608\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.6011 - val_loss: 297.6991\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 29.9239 - val_loss: 298.9341\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 29.2748 - val_loss: 300.1647\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 28.6530 - val_loss: 301.3903\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 28.0576 - val_loss: 302.6101\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 27.4876 - val_loss: 303.8232\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 26.9424 - val_loss: 305.0294\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 26.4210 - val_loss: 306.2278\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 25.9226 - val_loss: 307.4174\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 25.4465 - val_loss: 308.5982\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 24.9918 - val_loss: 309.7692\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 24.5578 - val_loss: 310.9301\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 24.1439 - val_loss: 312.0801\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.7492 - val_loss: 313.2187\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.3730 - val_loss: 314.3455\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.0147 - val_loss: 315.4598\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 22.6736 - val_loss: 316.5614\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.3491 - val_loss: 317.6500\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 22.0403 - val_loss: 318.7249\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.7469 - val_loss: 319.7857\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.4681 - val_loss: 320.8324\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.2034 - val_loss: 321.8644\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.9522 - val_loss: 322.8815\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.7138 - val_loss: 323.8830\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.4880 - val_loss: 324.8691\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.2739 - val_loss: 325.8397\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.0712 - val_loss: 326.7940\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.8794 - val_loss: 327.7319\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6979 - val_loss: 328.6539\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.5263 - val_loss: 329.5591\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 19.3642 - val_loss: 330.4477\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.2112 - val_loss: 331.3195\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.0667 - val_loss: 332.1745\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.9304 - val_loss: 333.0125\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 18.8020 - val_loss: 333.8336\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.6809 - val_loss: 334.6376\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.5670 - val_loss: 335.4242\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 18.4597 - val_loss: 336.1940\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 18.3589 - val_loss: 336.9469\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.2641 - val_loss: 337.6823\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 18.1750 - val_loss: 338.4013\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.0914 - val_loss: 339.1029\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 18.0130 - val_loss: 339.7876\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.9395 - val_loss: 340.4562\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 17.8705 - val_loss: 341.1072\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.8060 - val_loss: 341.7422\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.7456 - val_loss: 342.3610\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 17.6890 - val_loss: 342.9629\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.6362 - val_loss: 343.5491\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 17.5869 - val_loss: 344.1194\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.5407 - val_loss: 344.6738\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 17.4978 - val_loss: 345.2127\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.4576 - val_loss: 345.7361\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 17.4202 - val_loss: 346.2440\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.3854 - val_loss: 346.7372\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.3531 - val_loss: 347.2155\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.3229 - val_loss: 347.6794\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.2949 - val_loss: 348.1288\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.2689 - val_loss: 348.5641\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.2447 - val_loss: 348.9857\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.2223 - val_loss: 349.3937\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.2015 - val_loss: 349.7884\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.1822 - val_loss: 350.1697\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 17.1643 - val_loss: 350.5381\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 17.1478 - val_loss: 350.8944\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.1325 - val_loss: 351.2381\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 17.1185 - val_loss: 351.5703\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.1054 - val_loss: 351.8903\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0933 - val_loss: 352.1990\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0822 - val_loss: 352.4965\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0719 - val_loss: 352.7826\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 17.0625 - val_loss: 353.0586\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0538 - val_loss: 353.3236\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0458 - val_loss: 353.5789\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0385 - val_loss: 353.8241\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0317 - val_loss: 354.0600\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0255 - val_loss: 354.2869\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 17.0197 - val_loss: 354.5043\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0145 - val_loss: 354.7127\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0097 - val_loss: 354.9126\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0054 - val_loss: 355.1043\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0014 - val_loss: 355.2884\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9977 - val_loss: 355.4643\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 16.9944 - val_loss: 355.6331\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9913 - val_loss: 355.7940\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9885 - val_loss: 355.9484\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9860 - val_loss: 356.0958\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9837 - val_loss: 356.2365\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9816 - val_loss: 356.3709\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9797 - val_loss: 356.4994\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9780 - val_loss: 356.6217\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9765 - val_loss: 356.7383\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9751 - val_loss: 356.8495\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9738 - val_loss: 356.9554\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9727 - val_loss: 357.0561\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9717 - val_loss: 357.1524\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9708 - val_loss: 357.2436\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9700 - val_loss: 357.3304\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9693 - val_loss: 357.4131\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9687 - val_loss: 357.4918\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9681 - val_loss: 357.5660\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9677 - val_loss: 357.6361\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 16.9673 - val_loss: 357.7032\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 16.9669 - val_loss: 357.7665\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9666 - val_loss: 357.8264\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9664 - val_loss: 357.8833\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9662 - val_loss: 357.9372\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9661 - val_loss: 357.9883\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9660 - val_loss: 358.0365\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9659 - val_loss: 358.0822\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9659 - val_loss: 358.1253\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9658 - val_loss: 358.1656\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9659 - val_loss: 358.2038\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9659 - val_loss: 358.2402\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9660 - val_loss: 358.2737\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9661 - val_loss: 358.3058\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9662 - val_loss: 358.3355\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9663 - val_loss: 358.3641\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9665 - val_loss: 358.3911\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9667 - val_loss: 358.4160\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9668 - val_loss: 358.4393\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9670 - val_loss: 358.4613\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9672 - val_loss: 358.4820\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 16.9674 - val_loss: 358.5015\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9677 - val_loss: 358.5194\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9679 - val_loss: 358.5363\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9682 - val_loss: 358.5521\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9685 - val_loss: 358.5674\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9687 - val_loss: 358.5809\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9690 - val_loss: 358.5938\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9693 - val_loss: 358.6060\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9695 - val_loss: 358.6173\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9698 - val_loss: 358.6277\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9702 - val_loss: 358.6378\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9704 - val_loss: 358.6470\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9707 - val_loss: 358.6556\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9710 - val_loss: 358.6631\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9713 - val_loss: 358.6704\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9716 - val_loss: 358.6767\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 16.9720 - val_loss: 358.6830\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 16.9722 - val_loss: 358.6886\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9726 - val_loss: 358.6937\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9729 - val_loss: 358.6990\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9732 - val_loss: 358.7034\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9735 - val_loss: 358.7078\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 16.9738 - val_loss: 358.7114\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9742 - val_loss: 358.7148\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 16.9745 - val_loss: 358.7178\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9748 - val_loss: 358.7204\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9751 - val_loss: 358.7231\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9754 - val_loss: 358.7253\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 16.9758 - val_loss: 358.7278\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 16.9761 - val_loss: 358.7297\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9764 - val_loss: 358.7313\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9767 - val_loss: 358.7328\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9770 - val_loss: 358.7342\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9773 - val_loss: 358.7352\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9776 - val_loss: 358.7365\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9780 - val_loss: 358.7372\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9783 - val_loss: 358.7380\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9786 - val_loss: 358.7386\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9788 - val_loss: 358.7395\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9792 - val_loss: 358.7402\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9795 - val_loss: 358.7407\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9797 - val_loss: 358.7407\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9801 - val_loss: 358.7410\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 16.9803 - val_loss: 358.7411\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9806 - val_loss: 358.7411\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9810 - val_loss: 358.7413\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9812 - val_loss: 358.7413\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9815 - val_loss: 358.7411\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9818 - val_loss: 358.7409\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9821 - val_loss: 358.7407\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9823 - val_loss: 358.7405\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9826 - val_loss: 358.7402\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9829 - val_loss: 358.7400\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9831 - val_loss: 358.7394\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9834 - val_loss: 358.7389\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9837 - val_loss: 358.7388\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9839 - val_loss: 358.7384\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9842 - val_loss: 358.7380\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 16.9844 - val_loss: 358.7375\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9847 - val_loss: 358.7370\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9850 - val_loss: 358.7367\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9852 - val_loss: 358.7366\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9854 - val_loss: 358.7361\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9857 - val_loss: 358.7358\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9859 - val_loss: 358.7349\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9862 - val_loss: 358.7344\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9864 - val_loss: 358.7339\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9866 - val_loss: 358.7335\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9869 - val_loss: 358.7329\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9871 - val_loss: 358.7325\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9873 - val_loss: 358.7317\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9875 - val_loss: 358.7310\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 16.9877 - val_loss: 358.7305\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9880 - val_loss: 358.7303\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9882 - val_loss: 358.7299\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9883 - val_loss: 358.7294\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9886 - val_loss: 358.7290\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9888 - val_loss: 358.7285\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9889 - val_loss: 358.7280\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9892 - val_loss: 358.7275\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9893 - val_loss: 358.7266\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9895 - val_loss: 358.7263\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9897 - val_loss: 358.7255\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9899 - val_loss: 358.7253\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9901 - val_loss: 358.7247\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9903 - val_loss: 358.7241\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9904 - val_loss: 358.7238\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9906 - val_loss: 358.7233\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9908 - val_loss: 358.7224\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9910 - val_loss: 358.7220\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 16.9911 - val_loss: 358.7217\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9913 - val_loss: 358.7214\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 16.9915 - val_loss: 358.7211\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9916 - val_loss: 358.7209\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9918 - val_loss: 358.7204\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9919 - val_loss: 358.7200\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9921 - val_loss: 358.7199\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9922 - val_loss: 358.7194\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9924 - val_loss: 358.7189\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9925 - val_loss: 358.7184\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9927 - val_loss: 358.7181\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9928 - val_loss: 358.7178\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9929 - val_loss: 358.7173\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9931 - val_loss: 358.7173\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9932 - val_loss: 358.7168\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 16.9933 - val_loss: 358.7160\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9935 - val_loss: 358.7158\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.9936 - val_loss: 358.7156\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(89.3180, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0010, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(-0.0204, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.2194, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 378ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.87874650e+01, 6.87846639e+01, 6.87818628e+01, 6.87790616e+01,\n",
       "        6.87762605e+01, 6.87734594e+01, 6.87706583e+01, 6.87678571e+01,\n",
       "        6.87650560e+01, 6.87622549e+01, 6.87594538e+01, 6.87566527e+01,\n",
       "        6.87538515e+01, 6.87510504e+01, 6.87482493e+01, 6.87454482e+01,\n",
       "        6.87426471e+01, 6.87398459e+01, 6.87370448e+01, 6.87342437e+01,\n",
       "        6.87314426e+01, 6.87286415e+01, 6.87258403e+01, 6.87230392e+01,\n",
       "        6.87202381e+01, 6.87174370e+01, 6.87146358e+01, 6.87118347e+01,\n",
       "        6.87090336e+01, 6.87062325e+01, 6.87034314e+01, 6.87006303e+01,\n",
       "        6.86956583e+01, 6.86900560e+01, 6.86844538e+01, 6.86788515e+01,\n",
       "        6.86732493e+01, 6.86676471e+01, 6.86620448e+01, 6.86564426e+01,\n",
       "        6.86508403e+01, 6.86452381e+01, 6.86396359e+01, 6.86340336e+01,\n",
       "        6.86284314e+01, 6.86228291e+01, 6.86172269e+01, 7.18158473e+01,\n",
       "        7.17830742e+01, 7.17503011e+01, 7.17175280e+01, 7.16847549e+01,\n",
       "        7.16519818e+01, 7.16192087e+01, 7.15756536e+01, 7.15168301e+01,\n",
       "        7.14580065e+01, 7.13991830e+01, 7.13403595e+01, 7.12815360e+01,\n",
       "        7.12227124e+01, 7.11638889e+01, 7.11050654e+01, 7.10462418e+01,\n",
       "        7.09874183e+01, 7.09285948e+01, 7.08395425e+01, 7.07218954e+01,\n",
       "        7.06042484e+01, 7.04866013e+01, 7.03689543e+01, 7.02513072e+01,\n",
       "        7.01336601e+01, 7.76477127e+01, 4.82161460e-01, 5.73052470e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.34582450e-01,\n",
       "        6.13917084e+01, 0.00000000e+00, 0.00000000e+00, 1.04875565e-01,\n",
       "        1.88981742e-01, 5.35011351e-01, 7.28455633e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.43688333e-01, 1.69066891e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.29469955e-01, 2.20610276e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.02077842e-01, 1.87095612e-01, 3.30190659e-02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66.01446078, 66.00465686, 65.99485294, 65.98504902, 65.9752451 ,\n",
       "       65.96544118, 65.95563725, 65.94583333, 65.93602941, 65.92622549,\n",
       "       65.91642157, 65.90661765, 65.89681373, 65.8870098 , 65.87720588,\n",
       "       65.86740196, 65.85759804, 65.84779412, 65.8379902 , 65.82818627,\n",
       "       65.81838235, 65.80857843, 65.79877451, 65.78897059, 65.77916667,\n",
       "       65.76936275, 65.75955882, 65.7497549 , 65.73995098, 65.73014706,\n",
       "       65.72034314, 65.71053922, 65.70073529, 65.69093137, 65.68112745,\n",
       "       65.67132353, 65.66151961, 65.65171569, 65.64191176, 65.63210784,\n",
       "       65.62230392, 65.6125    , 65.60269608, 65.59289216, 65.58308824,\n",
       "       65.57328431, 65.56348039, 65.55367647, 65.54387255, 65.53406863,\n",
       "       65.52426471, 65.51446078, 65.50465686, 65.49485294, 65.48504902,\n",
       "       65.4752451 , 65.46544118, 65.45563725, 65.44583333, 65.43602941,\n",
       "       65.42622549, 65.41642157, 65.40661765, 65.39681373, 65.3870098 ,\n",
       "       65.37720588, 65.36740196, 65.35759804, 65.34779412, 65.3379902 ,\n",
       "       65.32818627, 65.31838235, 65.30857843, 65.29877451, 65.28897059,\n",
       "       65.27916667, 65.26936275, 65.25955882, 65.2497549 , 65.23995098,\n",
       "       65.23014706, 65.22034314, 65.21053922, 65.20073529, 65.19292205,\n",
       "       65.18527021, 65.17761836, 65.16996652, 65.16231468, 65.15466284,\n",
       "       65.147011  , 65.13935916, 65.13170732, 65.12405548, 65.11640363,\n",
       "       65.10875179, 65.10109995, 65.09344811, 65.08579627, 65.07814443])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.72384894382372\n",
      "19.282173789904896\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
