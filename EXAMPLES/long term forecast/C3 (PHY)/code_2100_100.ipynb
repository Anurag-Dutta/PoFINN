{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2195    68.910774\n",
       "2196    68.904489\n",
       "2197    68.898203\n",
       "2198    68.891918\n",
       "2199    68.885632\n",
       "Name: C3, Length: 2200, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_2100_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2095     0.000000\n",
       "2096     0.101646\n",
       "2097     0.000000\n",
       "2098     0.189380\n",
       "2099     0.220811\n",
       "Name: C3, Length: 2100, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2100)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlOElEQVR4nO3deXhc9X3v8fdX+y5Zi21ZtuM1gMEQjBO27GRhaVjStE+aNiUpudynWdp0eXpJc3ub+3QjSW+3m5SUljQ0TwilWS40EFLClhBWAcYGDHgDL5ItybZk2ZIsWfrdP+ZoPJJG0pxlZs6MPi8eP5o5c86c3xykzznzPb/zO+acQ0REiktJvhsgIiLRU7iLiBQhhbuISBFSuIuIFCGFu4hIESrLdwMAWltb3apVq/LdDBGRgvLss8/2Oefa0r0Wi3BftWoVnZ2d+W6GiEhBMbM3Zntt3rKMmX3TzHrM7MWUac1m9oCZ7fB+LvKmm5n9g5ntNLOtZrYpmo8gIiJ+ZFJz/xZw+bRpNwEPOufWAw96zwGuANZ7/24EbommmSIi4se84e6c+xlwZNrka4Dbvce3A9emTP83l/Ak0GRm7RG1VUREMhS0t8wS51y39/ggsMR73AHsS5lvvzdtBjO70cw6zayzt7c3YDNERCSd0F0hXWJwGt8D1DjnbnXObXbObW5rS3uyV0REAgoa7ocmyy3ezx5v+gFgRcp8y71pIiKSQ0HD/R7geu/x9cDdKdN/0+s1cxEwkFK+ERGRHMmkK+R3gSeAM8xsv5ndANwMvN/MdgDv854D3AfsBnYC/wx8OiutFhHJkX1HhvjZa4V3XnDei5icc782y0uXpZnXAZ8J2ygRkbh411cfZsLB6zdfle+m+KKxZURE5jBRoPczUriLiBQhhbuISBFSuIuIFCGFu4hIEVK4i4gUIYW7iEgRUriLiBQhhbuISBFSuIuIFCGFu4hIESrocH+56xhff3hnvpshIhI7BR3uT+4+zFd/8io7e47nuykiIrFS0OF+1bntmMGPtnbluykiIrFS0OG+pKGKC1c3858vdJEYbVhERKDAwx3gQ+ctY1fvCbZ3D+a7KSIisVHw4X7FOe2Ulxp/cd/LjIyN57s5IiKxUPDh3lxbwV99+Fx+sfMwn/vu84yNT+S7SSIieVfw4Q7wkQuW87+vPpsHXj7E79/1AgPDY/lukohIXs17D9VCcf0lqxgaHefL97/CI6/28MlLVvFbb19NU01FvpsmIpJzRXHkPum3372WH33u7Vy6tpV/eGgnl978EF+5/xWOnBjNd9NERHKqaI7cJ53T0cg3Pn4Brxw8xtce2sktj+7itsf2sLK5hrb6StrqK2mtS/zctHIRm9+0iJISy3ezRUQiVXThPunMpQ187WOb+HzPIN99eh8Hjg7Te/wkW/b10zt4kqHRRM+aJQ2VXHFOO1ed284FKxX0IlIcijbcJ61bXM+f/NKGGdMHhsd45NUe7tvWzR1P7+Vbj7/O0oYqLj9nKZefs5RNKxdRUVZUVSsRWUCKPtxn01hdzjVv6eCat3Rw/OQpHtx+iHu3ng76mopS3rqqmUvXtXDpulbOWtqgo3oRKRgLNtxT1VWWJYN+cGSMx3cd5vGdfTy2s4+/vK8XSPSnv3hNC5esa+HSta28qaUGM4W9iMSTwn2a+qpyPnj2Uj549lIADg6M8PiuPn6x8zCP7+rj3m3dAHQ0VbPpTYtY01rLmrZa1rTWsaq1hvqq8nw2X0QEULjPa2ljFR/etJwPb1qOc449fSf4xc5E2D+/9yg/2tpF6phlbfWVUwJ/dWstq9tqWdlcQ3mpavgikhsKdx/MjDVtdaxpq+PjF68CYGRsnDcOD7Gn7zi7+06wu/cEe/pO8JOXDnHkxL7ksqUlxsrmGla31rLGC/zVrbWsWFTDkoYqnbwVkUgp3EOqKi/ljKX1nLG0fsZr/UOj7O47wZ7eE+zuO84eL/x/sbOPk6emjoHTWlfJsqYqljZUsaypmvbGKpY2nn68pKFKR/4ikjGFexY11VSwaWUFm1YumjJ9YsLRfWyEPb0n6OofpmtgmIMDI3QNjLCn7wRP7DrM4MlTU5Yxg7a6Stobq2hvrOacjgYuXtvKucsbFfoiMoPCPQ9KSoyOpmo6mqpnnWdwZCwZ+AcHhunqH6F7YJjugRFeOzTI/S8dBF5Ldtm8eG0LF69p4ZyORkrVZVNkwQsV7mb2e8CnAAdsAz4JtAN3Ai3As8DHnXMa3MWn+qpy6qvKWb9kZrkH4MiJUZ7afZgndh/m8V2HufnHr3jLlXHh6mYuWtPCxWtb1D9fZIEKHO5m1gH8DrDBOTdsZncBHwWuBP7WOXenmX0DuAG4JZLWSlJzbQVXbGznio3tAPQMjvDk7iM8seswT+4+zE+39wDQVFPORasTQX/x2hbWL65T/3yRBSBsWaYMqDazMaAG6AbeC3zMe/124Eso3LNucX0VV5+3jKvPWwZA98AwT+w6nPi3+7BXxoHWugo2djSyqLaCxupymqoraKopp6mmPPG8poKm6sTz+qpylXhEClTgcHfOHTCzvwb2AsPAf5Eow/Q75ybPBu4HOtItb2Y3AjcCrFy5MmgzZBbtjdXJ/vkA+44MJYP+1YODvHboOAPDYxyfduI2lRnUV5YlAj9N+DdWp0yrKaepupzGmnKaayoo00lekbwKU5ZZBFwDrAb6gf8ALs90eefcrcCtAJs3b3bzzC4hrWiuYUVzDb/61hVTpo+NT3BseIz+4TH6h8YYGB6lfyjxuH94jIGhUQZSXt9/dJh+b9rEHP/XFtWU01qXGF65tb6S1rqKxFDLdZW01FXQVl9JR1M1zbUVKhMVkZe7jvH7d23he799CXWV/uLl6IlRKspKqPW5XFB/cNcLbOxo4BOXrva13MSE4+CxEZbN0SEiDsJsxfcBe5xzvQBm9gPgUqDJzMq8o/flwIHwzZRsKS8toaWukpa6Sl/LTUw4Bk+eYmBojP5hbwcwNEb/0Ch9x0fpO37S+zfKtv399B0fTfstobq8lOWLqr1/NaxoTvycfL6oplzhX0C+fP8rvHJwkGdeP8J7zljsa9nz/+wB2hureOILl/laru/4Sf7p0V3cdMVZvsqI339uP99/Dt/hfsuju/jqT17loT94F2va6nwte+fTe1nZUsMla1t9LRdEmHDfC1xkZjUkyjKXAZ3Aw8BHSPSYuR64O2wjJX5KSixZlllJTUbLDI+OJ0O/Z/AkXf3D7D86zP6jQ+w/Osxze/tn3P+2pqI0GfTLF1WzsrmGDcsaOKejkQaN4xM7497XubKA52q6B0Z8L/PFH27jJy8d4pK1rbznTH87lCAe29EHJMad8hvuN/1gGwCv33xV5O2aLkzN/Skz+x7wHHAKeJ5EmeVe4E4z+3Nv2m1RNFQKX3VFabI8NJuB4TEOpAR+avh3vn6EYyOnj/7XtNZyTkcj5y5vZGNHI2d3NPouBUi0Tk0krrwuzeG3rZEx72rvHK1ycgcW984Gof4SnHN/CvzptMm7gbeFeV9ZuCa/DWxY1pD29cPHT/Ji1zG27e9n24EBOl8/wj0vdAGJE8BrWms5d3lTMvQ3tDfkrIYr+Qm+5DpztENJ7sCKOdxFcq2lrpJ3vbmNd725LTmt7/hJth0YYNv+AbbuH+CJXYf54fOJUz0lBmvb6tjoHd2vbq2lvbGapY1VNFSVqZ4fsbyGe47WOe51JIj7xYEKdyl4rXWVvOeMxVNO4PUcG0kEvhf6P9/Rxw+em3puv7ailKXeWD2Jn1WnfzZUs6ypisZqndD1YzL4chnuE96Y2yU5+v80EfK8Qq4o3KUoLW6o4rKGKi47awkAzjl6Bk+y78gQ3QMjHBwYSfw8lhiv5xc7+zh0bGRG986q8pJE+DdMC//Gam8Qt6qi7875h//xAsOj41yxcSnvPXMxNRWzx8a4V7IoK8nddQ6nw33u+e5/8SDPvnFkzl41p8YnuOH2Tn75guXJCwJnzDOR251JUAp3WRDMjCUNiaGTZ3NqfILe4yenhr83WNvBgRGe2nOEQ8dGkn/ckyrKSpJBv6yxmvamxLeByRE8C/0bwH++0MXo+AT3buumqryEd795MVdsXMplZy2ZcQL71PjUEsmp8YmsX9CWaVnmvm3d3PNCFwPDY9z84XPTznNs5BSPvtbLYzv7KC+x5PAeqZJH7qXx/v+pcBfxlJWWeKE8+8UpExOOvhMnk+Hf3Z8I/y7v8VN7jnDw2EgycCZVl5fSXFtBdUUp1eWJf1UVpdSUl1JdUUqVN62m4vTzGm/eKm+eyef1VYmrhnN1zmBsfILfftda3vnmNu7b1s2PXzzI/S8dpKKshA3tDXQsqmZ5UzUdi6p55eAgkAjae7d285k7nmNFczVvaq5lWVMVHU013s9q1i2uY/EsO9sHtx/i8PFR1i6u46z2+rm/LWRYChobn8AM7urczxuHh9LOM+rdZ6G81PidO5/nuld7kq999NYn+LW3rWR4bBw4XZY5ODDC3VsO0Dt4kn95bA+fuGQV153fwXkrmth7eIgdPYO854zFOa/RK9xFfCgpMRbXV7G4vopzl6efZ3zC0Tt4kq6BYbq9oZq7+kfoHx5lZGyc4dFxhsfGGRge4+DAMMNj4wyPTjAyNs7Q6Kk5r/xNVVpiySEfFtVUsKimnMbqxM/JsYMmp09eJ+A3YMYnHBMucVOai9a0cNGaFr70obN5du9RfrztIK8dGuTlrmM88PKhZDBCokRyoD8RoOva6jg6NMYjr/bSM3hyyvsva6ziLSubeMuKpinTP//vWxj0ur2WlhhnLq1n08pFnL+yiUvXtU75BjaRcuS+78gQdzy9l40djbz3zMVUlZcm5xsbn2BDewPXnd/Bt598I+3nHRtPfIY/+uCZbO8+xr1bu5OvPbn7CE/uPpLyGRPb8kdbu/grb1RWgDue3su3Hn+dD523jGPDYzz6Wi/nLm/kL6/bOM/WjpbCXSRipSXGUq8+j89hk5xzjI5PMDI6kQj95M7gFMOjEwyNnuLYyCn6hxLDRBwdGvWGhhilq3+El7uO0T88xtDo+Iz3riovYU1rHeuX1LF+cR3rFtezfkkdb2qumbV0Mhl2qTeEKSkx3rqqmbeuak5Om/xG80+P7ua2x/ZM+UbxtY9tSnZHPXlqnO7+EQ70D7O9+xhb9vWzZV8/9207OGW94xOOD5/fwRUb29m6v5/n9/bzw+cP8O0n36C81PjIBSv49LvXsqK5JvktqcSM+188yC2P7AJgcX0l//1da/nY21ZSXVHK6LijoqyET71jDTe8fTWrv3AfV25cOmW9o97nbamr4Ku/ch4fPHspn/q3TgD++lfOo6m6PPl88jNOpNxEuaGqjMduei+3/XwPf//gjuT07oERPvGvT6fdxtmicBeJETOjsqyUyrJSGgl+Be6I982gf2iMIydG2XckUR7Y0XOcztePcveWruS85aXGmtY61i1O/EuEfz2rWmuSYVc+T3158hvNedOOwKerLCtlVWstq1pruXTd6UvwewdP8ta/+CkXrTm9w2ipq+D9G5bw/g2Jk+LjE47XDg3ynafe4K5n9vMfnfv45U3L2Xck8Q2hxAxHImi/8RsX8K3H9/BnP3qZWx7ZyX97xxqODY8l71VsZqxqmXrT+p+91sv+o8MAVHjTU88Llxi8b8MS/vK6jfzxD7fN+hkbqsr5vfe/mYde6WHbgQFWNtfwjd+4gKu/9tic2yZqCneRIlTl1eonyxcXr22Z8vqJk6fY1XucHYeOs9P7+VLXAPe92I1LqWFP3i2s0vcN3B0uw/ISQFt9JWvaammdY4yj0hLjrPYG/vzajXzmPev4p0d3c8fTe5PloNSa+zvWt3L5OUt5es8R/u9DO5Jlk7evmzqmS2obP3vHc8kroOe6dWVNRemsr6VKPR2yYVkDn33vOv7upztmXyBiCneRBai2soxzlzdx7vKmKdNHxsbZ3XuCHT2D7Oo5zo6e4zTVlM97RD4p3fG9n3O+k1k7346hvbGaL119Np9+91o+9LXHOHTsZNqukG9b3cy3b7iQ5/Ye5dZHd3NhyjeD6SejT004NnY00lRTzsbljd7nsZT5p7XVa2RqW+c6wf3pdyfCfUVzbkaTVLiLSFJVeSkbljXMOvxDNgXpS7K4oYo/+aUNfPaO54HZdwqbVi7iGx+/YN73u2hNM1+8asOc8/jtoDQ5f0VZCatba9nY0ejvDQLSHRVEJJZicV1AiCbku/UKdxHJinzegSfT/UJqG/2cIygECncRidyUOrSfY1g3+SP7SZtJq2zK46lLuGk/wX/JJpsU7iISmTDhFrYM4wj/bSEbpaDp7/hi10Cy+2Y2KdxFJJYyjVlf3wz8tiHc3mrmJGB37wne8ZWHg79vhhTuIpIV+axhBwn8XJSCcknhLiKRC1qHngzYXO0Y3DwryqTpU88vxIfCXUQiE6ZEEjYYnfO5U0izwrnaMPMipgxXk6ezrAp3EYmnDDMxm9mZ7r0zDeu0c+Uw5xXuIlJ0ggS++rmLiMzDuWAnKF2yn3tuzLeeTMpMcT0Rq3AXkchE3HPQF+f9l/H6Mp44+xpnLD5L98d8ULiLSCxlenI2m+GZtuaeg2WjoHAXESG/Y+Fkg8JdRLIiyAlKl27Aliy6d2s3X/jB1llf99vPPU4U7iISudTad6a19CiGEfATtJP18e8+vS+jNkyvp6dbV767P6ZSuItIZKLMMb8nWLNyBJ22n3vgRXNK4S4iBS39hUYB3igH5ZVcXq2qcBeR2IlL3/FsjjiZbQp3EYlc0Jt15DLU/d7Me/pL6Vqa7+6PqUKFu5k1mdn3zOwVM9tuZhebWbOZPWBmO7yfi6JqrIjEW5QXMfl9q2zU3NOHdYb97/N8W6awR+5/D9zvnDsTOA/YDtwEPOicWw886D0XEcmSdFeFxnM894K4iMnMGoF3ArcBOOdGnXP9wDXA7d5stwPXhmuiiBSi+cZKn3vZCBsSQmb93GPS2GnCHLmvBnqBfzWz583sX8ysFljinOv25jkILEm3sJndaGadZtbZ29sbohkiEjdTau5+btYRMifDBq2f8dwzfYdCHM+9DNgE3OKcOx84wbQSjEts6bRb2zl3q3Nus3Nuc1tbW4hmiEh8RBdkvvu5+yyrZPL+cwXzfPuRfPezCRPu+4H9zrmnvOffIxH2h8ysHcD72ROuiSIis4uqn3vmd1by/95RLOtX4HB3zh0E9pnZGd6ky4CXgXuA671p1wN3h2qhiBSkMBWSuFSxMwnjmJbcKQu5/OeA75hZBbAb+CSJHcZdZnYD8AbwqyHXISIFZsrYMr6WC7nekG8wdz/3+T9JnPq5hwp359wWYHOaly4L874iUpjClSymLuy3O6PfYM8orOda3zy7ojx3c9cVqiJS2NJeaRrgfTLdN4TJ7FwOZ6BwF5GsCFMhiUvf8Yxq7tlvRiAKdxHJKj/9vEP3cw+3+DzjuWeyfLDlskHhLiKRCxLS0zMw26EY9KKkSfP3cy/ssWVERJLyfeHOpCBXhWZaCsr3idJMKdxFJCty1c89m5f3R93PvSAuYhIRyYTPDo2h1pXdfu7hls81hbuIxELY8dyzYa42/K+7X2RsfGLehfNVe1e4i0hk8nmDiql3fwqwvM/5n3n9KI++Gt8RbRXuIpIVubplXpS7k5k9dua/RCou93udTuEuIlmVzREaZyyXxaDNrJ97HIpJCQp3EYlc4HBOXS4GZyejaIEuYhKRghdq3JWQIThlJMoAN+KIesSDfO+aFO4ikhW5Gh4m0iPj6SNTRnQjkNPLauAwESkSuQy07O5Q0n+OoPeLzTaFu4jExpSSe95acVqcTpD6pXAXkcgF6bUSZZBm8m0h27Gd76N4hbuIRCY10HLd+zuKkkwmI1MWyrG8wl1EYsXvjTryuUOZvs75gj+XOwaFu4jERmqw57usEZV8DcmgcBeRyAW6WUeOM3DKEX8Wutnk+2Sswl1EIjMloHN8H9Qo1jZjZMoC/vagcBeRrMnFuDJTjpBzsEOZUWaZUkqa+wPrZh0isiBNPTmZ/8PmKNqQr0+hcBeRyAU5fo4qBHM5CmXU7YiSwl1EIpN6pJv7fu7Bu1Amp03bxeQ7oMNQuItI1uTijkjkuJ/79M/k72beUbZkbgp3EYmNuA3CFUUbNJ67iCxsEaVgTr4tZCDfOyeFu4hELhsXBc27Tp/zp+sJM6Ofewx67ASlcBeR6ETQ5dz3idEpywZbp6/1zd7Nff5lc7izULiLSNaEGVclDsfMqc3P7NZ9mU3LhdDhbmalZva8mf3Ie77azJ4ys51m9u9mVhG+mSKyEEQzhID/NM3k20KoK2fzIIoj998Ftqc8/zLwt865dcBR4IYI1iEiBSSfFzFlvL4MxmqPw7eHoEKFu5ktB64C/sV7bsB7ge95s9wOXBtmHSJSOKbUvwMehwc9encu+DrDyMc6MxH2yP3vgD8CJrznLUC/c+6U93w/0JFuQTO70cw6zayzt7c3ZDNEJI7CHPlmWl2JYrz02eI5Xc19rtXNd9VrQVzEZGa/BPQ4554Nsrxz7lbn3Gbn3Oa2tragzRCRIhJFF8q4lFLy3c+9LMSylwJXm9mVQBXQAPw90GRmZd7R+3LgQPhmikghKYibdWTUhpSxcuJZfZlV4CN359wXnHPLnXOrgI8CDznnfh14GPiIN9v1wN2hWykiBSG1RBK8n3vQtecnfeMa+tno5/4/gN83s50kavC3ZWEdIlIAcnE0HsVFTLMtl7bmPkfhZ76rXnP55SRMWSbJOfcI8Ij3eDfwtijeV0QWrqAnSvNd644LXaEqIrEQh0yevkOJQ5uCUriLSBYE7/0duH+875HDoonumJbcFe4iEp2ZV3hm/9g3NaNzskPx3c99nhmyROEuIrERRc+TKHcooQY+y3PxX+EuIrGQ7zAsNgp3EYmcc/no5+5PJruSTOZZSP3cRWSBmnHwncODcUd2dyg27edc80ydmJ9vJAp3EYmN1BObGQ8cNj1SI8zSMCdr0w5vEKYxPincRSQW4lBxL6ayv8JdRCLniO8455Myum1eBrucuH5OhbuIRGZ6GObyQDjbN+sI+lny9WVA4S4isZF6YjPT/urTj8CjDNP0N7wO1q7ZpmWLwl1EYiEO9e65dijxLL7MTuEuIpFziaJ78GVzILJ9SUxTX+EuIpGZUSLJZT/3RNE94LLzzxO45p6nbyQKdxGJpcz7uQdbLmgbMn179XMXEfHk+1L+ONT9o6JwF5Gs8H9Fp3nLxaeInUnPmPi0diqFu4hEznmH4LkYzz25TvwF7ZSbecewf3xYCncRiUykfcwDzhjpeO7ppmV6LiDNjLkc1ljhLiKxke+STBGV3BXuIpIdzu/ZUZtcLvq2BJXJgbbvz5kjCncRidxk3OW694mfoE1tWjbzOV93mFK4i0h0stzHfC6TAR1pP/cQHyjfJR6Fu4jERpAj6GhviJ3d9ekiJhEpeAFL7rFSyBc1KdxFJHLJEkmQZSNYbyb83kJvttp5TM+nKtxFJDrR9jH3916T3Sjz0tc+3bIW/j3CULiLSGwEOQjO1QnU5FW3Idanm3WISMHzPbZMHOvbcWxThhTuIpI1Qfp4h7koyNfYMinJnck6Z625+1hnLgUOdzNbYWYPm9nLZvaSmf2uN73ZzB4wsx3ez0XRNVdECkEUwwj43i8k+7nnr+4/fWkozJt1nAL+wDm3AbgI+IyZbQBuAh50zq0HHvSei8gCEDrIAvVzj05m/dxDvH8O6zyBw9051+2ce857PAhsBzqAa4DbvdluB64N2UYRWQByGXyZmtJdMq59HmcRSc3dzFYB5wNPAUucc93eSweBJbMsc6OZdZpZZ29vbxTNEJEYCZqFuernnu91ZlvocDezOuD7wOedc8dSX3Nu9nugO+dudc5tds5tbmtrC9sMEYmTEBcxhRV0HPj5ZvFbyz/dz70ABw4zs3ISwf4d59wPvMmHzKzde70d6AnXRBEpFPksrMT0ADpvwvSWMeA2YLtz7m9SXroHuN57fD1wd/DmichCEqSXTTaH1E373uE70OREWYhlLwU+Dmwzsy3etD8GbgbuMrMbgDeAXw3VQhEpSH6DejJHw9Swg3bBzMc6sy1wuDvnHmP2/dBlQd9XRApfMu5CXaofcOFM73Ea3VvNvWwB9nMXEZkiX3cdgmh6reSz/VFTuItIbAS6WUcW8zh9yV036xCRBcz3zTomky9M/TvosvlYZ5Yp3EUka/LRsSTT5bJ+Sz2N5y4ixSYfR7ORDFYWQTviQuEuIpEJW/8OdLOOcKv0/ea6WYeIiA+TJZB89BuPa1/1MBTuIpI1YboWBu7mnuGC6erp0xdNfe63OZPvX4jjuYuIpJWXo+8sr7LQju0V7iISmdD36giQ0Fnt5x75+xXAzTpERObiN6gjGVsm4MJ+Fpsez3G9iYfCXUSyJlTPkhisM7V+77vmXsjjuYuIpBPTg9kpimgYmbQU7iISmXz0c49i2dkUcv4r3EUkK3I3zMvpCM7FOqd3tfS3rI+ZQ1K4i0jWhBpbJmASRrnOKK5GVT93ESkaBVByV81dRKQQZKNLYr56ukRB4S4iEUqpfwfIWueC948Pus7EcpkvOP2I31cfedXcRaQY+KmbR1XvjnI8m3B95jW2jIhIzhVyySUTCncRiVw+LskvhJO4uaRwF5HITKl/B4hbh/+QTj3+Djoapa++6jOW9VGv18BhIlIM/ETZjHFdcrDOedtg6R/7eTONLSMikkN+w7oQxstJpXAXkcjlJQezsNJCPumqcBeRyEypfwcJW+d8L5fa9TF4P/dgy4VdNpsU7iKSNX5KHzPmDTq2TLjBZWZ96nesmMnZQtXtQ1C4i4gUIYW7iEQvpqUKv0KXmfJI4S4ikZlS/w6wfKKfe9C+6kGXDL7OxLLxpHAXkcgdP3nKe+RjbJl5nme6XJie7nPeQ9VmzjVXsIcZ4yYKWQl3M7vczF41s51mdlM21iEi8fW57z7PHU/t9TUMwe6+E2zdP8Aze44GXm//0GjG86Y2bf/R4cDrDOrw8ZNZff+yqN/QzEqBrwPvB/YDz5jZPc65l6Nel4jEy/QwP3wi87B94/AQAJ+547lA6/6tb3X6mv+xnX3Jxx/+x8fTzjPfsfe9W7v4f1u6ks9f9z7DbH6+4/Q6L/jzn7J+cR133ngRLXWV8zfYp2wcub8N2Omc2+2cGwXuBK7JwnpEJGbKS3Nf6c3VOkvSlFlSgz2IHT3HufOZfaHeYzbZ2CodQGpr93vTpjCzG82s08w6e3t7s9AMEcm1De0NNFQlCgINVWX8z6vOynjZL31oA6UlRk1FKatba3nn+raMljtjaT1ntTckn193/oy4SeuRP3z3jGlXbmyf8rykxLj6vGWsaqnhwjXNAJzVXs+1b1k2Zb73nJFo601XnJmc9isXLOfKjUv59QtXJqf9469vmrHOT166KqP2+mVRD81pZh8BLnfOfcp7/nHgQufcZ2dbZvPmza6z099XKhGRhc7MnnXObU73WjaO3A8AK1KeL/emiYhIjmQj3J8B1pvZajOrAD4K3JOF9YiIyCwi7y3jnDtlZp8FfgKUAt90zr0U9XpERGR2kYc7gHPuPuC+bLy3iIjMT1eoiogUIYW7iEgRUriLiBQhhbuISBGK/CKmQI0w6wXeCLh4K9A371wLm7bR3LR95qdtNLd8bZ83OefSXsobi3APw8w6Z7tCSxK0jeam7TM/baO5xXH7qCwjIlKEFO4iIkWoGML91nw3oABoG81N22d+2kZzi932Kfiau4iIzFQMR+4iIjKNwl1EpAgVdLjrRtwJZva6mW0zsy1m1ulNazazB8xsh/dzkTfdzOwfvG221cxm3hqmCJjZN82sx8xeTJnme5uY2fXe/DvM7Pp8fJZsmGX7fMnMDni/R1vM7MqU177gbZ9XzeyDKdOL8m/QzFaY2cNm9rKZvWRmv+tNL5zfIedcQf4jMZzwLmANUAG8AGzId7vytC1eB1qnTfsKcJP3+Cbgy97jK4Efk7j370XAU/luf5a2yTuBTcCLQbcJ0Azs9n4u8h4vyvdny+L2+RLwh2nm3eD9fVUCq72/u9Ji/hsE2oFN3uN64DVvOxTM71AhH7nrRtxzuwa43Xt8O3BtyvR/cwlPAk1m1p5m+YLmnPsZcGTaZL/b5IPAA865I865o8ADwOVZb3wOzLJ9ZnMNcKdz7qRzbg+wk8TfX9H+DTrnup1zz3mPB4HtJO4FXTC/Q4Uc7hndiHuBcMB/mdmzZnajN22Jc67be3wQWOI9Xsjbze82WYjb6rNeWeGbkyUHFvj2MbNVwPnAUxTQ71Ahh7uc9nbn3CbgCuAzZvbO1Bdd4vuh+rym0DZJ6xZgLfAWoBv4P3ltTQyYWR3wfeDzzrljqa/F/XeokMNdN+L2OOcOeD97gB+S+Lp8aLLc4v3s8WZfyNvN7zZZUNvKOXfIOTfunJsA/pnE7xEs0O1jZuUkgv07zrkfeJML5neokMNdN+IGzKzWzOonHwMfAF4ksS0mz8xfD9ztPb4H+E3v7P5FwEDK18xi53eb/AT4gJkt8koUH/CmFaVp516uI/F7BInt81EzqzSz1cB64GmK+G/QzAy4DdjunPublJcK53co32elQ57RvpLEWexdwBfz3Z48bYM1JHopvAC8NLkdgBbgQWAH8FOg2ZtuwNe9bbYN2Jzvz5Cl7fJdEqWFMRJ1zhuCbBPgt0icQNwJfDLfnyvL2+fb3uffSiKs2lPm/6K3fV4FrkiZXpR/g8DbSZRctgJbvH9XFtLvkIYfEBEpQoVclhERkVko3EVEipDCXUSkCCncRUSKkMJdRKQIKdxFRIqQwl1EpAj9f+bzbqpDoQt5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 1, 251) (1650, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 2s 27ms/step - loss: 5875.4712 - val_loss: 3996.6584\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5783.0083 - val_loss: 3956.3628\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5718.7153 - val_loss: 3917.9009\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5653.3232 - val_loss: 3880.0781\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5580.1958 - val_loss: 3837.7720\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5506.8403 - val_loss: 3799.3901\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5440.4170 - val_loss: 3761.6758\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5375.3145 - val_loss: 3720.1230\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5297.6304 - val_loss: 3679.9890\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5228.8447 - val_loss: 3641.0891\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5161.7173 - val_loss: 3603.0747\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5096.0303 - val_loss: 3565.7505\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5031.4683 - val_loss: 3528.9995\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4967.8564 - val_loss: 3492.7576\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4905.0898 - val_loss: 3456.9827\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4843.0986 - val_loss: 3421.6475\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4781.8350 - val_loss: 3386.7319\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4721.2627 - val_loss: 3352.2200\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4661.3564 - val_loss: 3318.1001\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4602.0928 - val_loss: 3284.3621\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4543.4536 - val_loss: 3250.9973\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4485.4233 - val_loss: 3217.9995\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4427.9902 - val_loss: 3185.3613\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4371.1421 - val_loss: 3153.0767\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4314.8691 - val_loss: 3121.1416\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4259.1611 - val_loss: 3089.5515\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4204.0117 - val_loss: 3058.3013\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4149.4116 - val_loss: 3027.3870\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4095.3542 - val_loss: 2996.8049\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4041.8330 - val_loss: 2966.5520\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3988.8425 - val_loss: 2936.6238\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3936.3757 - val_loss: 2907.0186\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3884.4277 - val_loss: 2877.7314\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3832.9932 - val_loss: 2848.7612\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3782.0667 - val_loss: 2820.1040\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3731.6440 - val_loss: 2791.7568\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3681.7205 - val_loss: 2763.7175\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3632.2913 - val_loss: 2735.9834\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3583.3508 - val_loss: 2708.5513\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 3534.8965 - val_loss: 2681.4197\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3486.9243 - val_loss: 2654.5852\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3439.4294 - val_loss: 2628.0457\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3392.4087 - val_loss: 2601.7991\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3345.8577 - val_loss: 2575.8428\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3299.7720 - val_loss: 2550.1743\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3254.1482 - val_loss: 2524.7917\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3208.9836 - val_loss: 2499.6929\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3164.2744 - val_loss: 2474.8755\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3120.0159 - val_loss: 2450.3372\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3076.2058 - val_loss: 2426.0759\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3032.8398 - val_loss: 2402.0898\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2989.9167 - val_loss: 2378.3772\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2947.4302 - val_loss: 2354.9351\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2905.3789 - val_loss: 2331.7620\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2863.7598 - val_loss: 2308.8557\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2822.5686 - val_loss: 2286.2144\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2781.8022 - val_loss: 2263.8359\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2741.4587 - val_loss: 2241.7190\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2701.5349 - val_loss: 2219.8611\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2662.0266 - val_loss: 2198.2605\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2622.9321 - val_loss: 2176.9153\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2584.2476 - val_loss: 2155.8237\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2545.9709 - val_loss: 2134.9836\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2508.0981 - val_loss: 2114.3936\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2470.6274 - val_loss: 2094.0520\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2433.5557 - val_loss: 2073.9563\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2396.8794 - val_loss: 2054.1050\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2360.5964 - val_loss: 2034.4968\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2324.7046 - val_loss: 2015.1295\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 2289.1997 - val_loss: 1996.0015\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2254.0806 - val_loss: 1977.1108\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2219.3433 - val_loss: 1958.4561\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2184.9858 - val_loss: 1940.0354\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2151.0054 - val_loss: 1921.8473\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2117.3999 - val_loss: 1903.8898\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2084.1660 - val_loss: 1886.1614\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2051.3020 - val_loss: 1868.6606\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2018.8040 - val_loss: 1851.3854\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1986.6713 - val_loss: 1834.3348\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1954.8997 - val_loss: 1817.5066\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1923.4873 - val_loss: 1800.8990\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1892.4314 - val_loss: 1784.5110\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1861.7300 - val_loss: 1768.3406\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1831.3805 - val_loss: 1752.3866\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1801.3805 - val_loss: 1736.6464\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1771.7271 - val_loss: 1721.1201\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1742.4182 - val_loss: 1705.8047\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1713.4517 - val_loss: 1690.6995\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1684.8250 - val_loss: 1675.8019\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1656.5360 - val_loss: 1661.1121\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1628.5822 - val_loss: 1646.6271\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1600.9609 - val_loss: 1632.3462\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1573.6704 - val_loss: 1618.2671\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1546.7078 - val_loss: 1604.3892\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1520.0714 - val_loss: 1590.7101\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1493.7584 - val_loss: 1577.2290\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1467.7671 - val_loss: 1563.9443\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1442.0945 - val_loss: 1550.8542\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1416.7390 - val_loss: 1537.9573\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1391.6981 - val_loss: 1525.2521\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1366.9695 - val_loss: 1512.7377\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1342.5513 - val_loss: 1500.4120\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1318.4404 - val_loss: 1488.2738\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1294.6354 - val_loss: 1476.3213\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1271.1346 - val_loss: 1464.5536\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1247.9349 - val_loss: 1452.9690\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1225.0344 - val_loss: 1441.5659\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1202.4309 - val_loss: 1430.3431\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1180.1226 - val_loss: 1419.2992\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1158.1067 - val_loss: 1408.4329\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1136.3816 - val_loss: 1397.7422\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1114.9451 - val_loss: 1387.2262\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1093.7948 - val_loss: 1376.8832\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1072.9292 - val_loss: 1366.7119\n",
      "Epoch 115/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1052.3452 - val_loss: 1356.7109\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1032.0415 - val_loss: 1346.8790\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1012.0158 - val_loss: 1337.2144\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 992.2654 - val_loss: 1327.7157\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 972.7892 - val_loss: 1318.3820\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 953.5845 - val_loss: 1309.2113\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 934.6497 - val_loss: 1300.2026\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 915.9822 - val_loss: 1291.3546\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 897.5803 - val_loss: 1282.6653\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 879.4414 - val_loss: 1274.1340\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 861.5644 - val_loss: 1265.7595\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 843.9469 - val_loss: 1257.5394\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 826.5862 - val_loss: 1249.4730\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 809.4809 - val_loss: 1241.5590\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 792.6285 - val_loss: 1233.7954\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 776.0275 - val_loss: 1226.1814\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 759.6754 - val_loss: 1218.7156\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 743.5709 - val_loss: 1211.3964\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 727.7112 - val_loss: 1204.2225\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 712.0945 - val_loss: 1197.1924\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 696.7184 - val_loss: 1190.3051\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 681.5814 - val_loss: 1183.5587\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 666.6821 - val_loss: 1176.9525\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 652.0171 - val_loss: 1170.4843\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 637.5851 - val_loss: 1164.1532\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 623.3835 - val_loss: 1157.9579\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 609.4114 - val_loss: 1151.8967\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 595.6658 - val_loss: 1145.9685\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 582.1453 - val_loss: 1140.1716\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 568.8474 - val_loss: 1134.5052\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 555.7704 - val_loss: 1128.9675\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 542.9125 - val_loss: 1123.5573\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 530.2711 - val_loss: 1118.2728\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 517.8445 - val_loss: 1113.1132\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 505.6307 - val_loss: 1108.0767\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 493.6279 - val_loss: 1103.1624\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 481.8338 - val_loss: 1098.3682\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 470.2465 - val_loss: 1093.6935\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 458.8639 - val_loss: 1089.1366\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 447.6851 - val_loss: 1084.6962\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 436.7065 - val_loss: 1080.3706\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 425.9268 - val_loss: 1076.1587\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 415.3438 - val_loss: 1072.0591\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 404.9559 - val_loss: 1068.0703\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 394.7608 - val_loss: 1064.1910\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 384.7563 - val_loss: 1060.4199\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 374.9409 - val_loss: 1056.7554\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 365.3121 - val_loss: 1053.1965\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 355.8684 - val_loss: 1049.7411\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 346.6070 - val_loss: 1046.3885\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 337.5268 - val_loss: 1043.1371\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 328.6254 - val_loss: 1039.9855\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 319.9008 - val_loss: 1036.9323\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 311.3509 - val_loss: 1033.9760\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 302.9738 - val_loss: 1031.1152\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 294.7676 - val_loss: 1028.3488\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 286.7303 - val_loss: 1025.6754\n",
      "Epoch 172/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 278.8598 - val_loss: 1023.0934\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 271.1542 - val_loss: 1020.6013\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 263.6117 - val_loss: 1018.1981\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 256.2300 - val_loss: 1015.8821\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 249.0070 - val_loss: 1013.6522\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 241.9410 - val_loss: 1011.5067\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 235.0299 - val_loss: 1009.4443\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 228.2713 - val_loss: 1007.4636\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 221.6636 - val_loss: 1005.5635\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 215.2051 - val_loss: 1003.7419\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 208.8935 - val_loss: 1001.9984\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 202.7269 - val_loss: 1000.3310\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 196.7030 - val_loss: 998.7383\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 190.8203 - val_loss: 997.2191\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 185.0767 - val_loss: 995.7722\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 179.4701 - val_loss: 994.3958\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 173.9984 - val_loss: 993.0889\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 168.6597 - val_loss: 991.8497\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 163.4519 - val_loss: 990.6771\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 158.3732 - val_loss: 989.5699\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 153.4217 - val_loss: 988.5264\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 148.5954 - val_loss: 987.5455\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 143.8925 - val_loss: 986.6259\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 139.3108 - val_loss: 985.7659\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 134.8483 - val_loss: 984.9644\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 130.5033 - val_loss: 984.2199\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 126.2738 - val_loss: 983.5312\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 122.1578 - val_loss: 982.8971\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 118.1534 - val_loss: 982.3159\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 114.2586 - val_loss: 981.7866\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 110.4716 - val_loss: 981.3076\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 106.7906 - val_loss: 980.8779\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 103.2136 - val_loss: 980.4959\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 99.7386 - val_loss: 980.1604\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 96.3636 - val_loss: 979.8702\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 93.0871 - val_loss: 979.6240\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 89.9071 - val_loss: 979.4203\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 86.8215 - val_loss: 979.2584\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 83.8286 - val_loss: 979.1362\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 80.9265 - val_loss: 979.0531\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 78.1133 - val_loss: 979.0075\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 75.3877 - val_loss: 978.9984\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 72.7475 - val_loss: 979.0244\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 70.1909 - val_loss: 979.0844\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 67.7162 - val_loss: 979.1772\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 65.3216 - val_loss: 979.3015\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 63.0053 - val_loss: 979.4561\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 60.7655 - val_loss: 979.6401\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 58.6006 - val_loss: 979.8519\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 56.5088 - val_loss: 980.0906\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 54.4884 - val_loss: 980.3553\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 52.5377 - val_loss: 980.6444\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50.6551 - val_loss: 980.9572\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 48.8388 - val_loss: 981.2922\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 47.0873 - val_loss: 981.6487\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45.3990 - val_loss: 982.0256\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43.7721 - val_loss: 982.4216\n",
      "Epoch 229/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42.2052 - val_loss: 982.8358\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40.6966 - val_loss: 983.2672\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 39.2448 - val_loss: 983.7148\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 37.8483 - val_loss: 984.1776\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 36.5056 - val_loss: 984.6545\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 35.2150 - val_loss: 985.1447\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 33.9752 - val_loss: 985.6473\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 32.7847 - val_loss: 986.1614\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 31.6420 - val_loss: 986.6859\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 30.5458 - val_loss: 987.2200\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.4947 - val_loss: 987.7629\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 28.4872 - val_loss: 988.3137\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 27.5220 - val_loss: 988.8715\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 26.5979 - val_loss: 989.4357\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25.7134 - val_loss: 990.0053\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 24.8673 - val_loss: 990.5799\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 24.0584 - val_loss: 991.1583\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 23.2854 - val_loss: 991.7399\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 22.5471 - val_loss: 992.3242\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 21.8424 - val_loss: 992.9102\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 21.1698 - val_loss: 993.4976\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.5285 - val_loss: 994.0853\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 19.9173 - val_loss: 994.6733\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 19.3351 - val_loss: 995.2605\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7807 - val_loss: 995.8464\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 18.2533 - val_loss: 996.4305\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.7516 - val_loss: 997.0123\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.2747 - val_loss: 997.5912\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.8218 - val_loss: 998.1667\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.3918 - val_loss: 998.7385\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.9838 - val_loss: 999.3058\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.5969 - val_loss: 999.8688\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.2302 - val_loss: 1000.4262\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.8829 - val_loss: 1000.9784\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.5541 - val_loss: 1001.5244\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.2431 - val_loss: 1002.0645\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.9490 - val_loss: 1002.5978\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 13.6711 - val_loss: 1003.1243\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.4088 - val_loss: 1003.6436\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 13.1612 - val_loss: 1004.1553\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.9276 - val_loss: 1004.6595\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.7075 - val_loss: 1005.1559\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.5002 - val_loss: 1005.6439\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.3050 - val_loss: 1006.1237\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.1214 - val_loss: 1006.5948\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.9489 - val_loss: 1007.0574\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.7867 - val_loss: 1007.5111\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.6344 - val_loss: 1007.9557\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.4916 - val_loss: 1008.3915\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.3576 - val_loss: 1008.8181\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.2321 - val_loss: 1009.2354\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.1146 - val_loss: 1009.6432\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.0046 - val_loss: 1010.0419\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.9018 - val_loss: 1010.4313\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.8056 - val_loss: 1010.8111\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.7159 - val_loss: 1011.1815\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.6320 - val_loss: 1011.5426\n",
      "Epoch 286/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 10.5539 - val_loss: 1011.8942\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.4810 - val_loss: 1012.2366\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.4132 - val_loss: 1012.5696\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.3500 - val_loss: 1012.8932\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.2912 - val_loss: 1013.2079\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.2366 - val_loss: 1013.5131\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.1859 - val_loss: 1013.8094\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.1388 - val_loss: 1014.0970\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.0951 - val_loss: 1014.3755\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.0545 - val_loss: 1014.6454\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.0170 - val_loss: 1014.9066\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.9822 - val_loss: 1015.1590\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.9500 - val_loss: 1015.4034\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.9203 - val_loss: 1015.6392\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8928 - val_loss: 1015.8672\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8673 - val_loss: 1016.0870\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8439 - val_loss: 1016.2991\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8222 - val_loss: 1016.5036\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8023 - val_loss: 1016.7006\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7839 - val_loss: 1016.8901\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7670 - val_loss: 1017.0725\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7514 - val_loss: 1017.2478\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7371 - val_loss: 1017.4161\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7239 - val_loss: 1017.5779\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.7118 - val_loss: 1017.7332\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7007 - val_loss: 1017.8820\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6905 - val_loss: 1018.0246\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6811 - val_loss: 1018.1614\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6726 - val_loss: 1018.2921\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6647 - val_loss: 1018.4172\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 9.6575 - val_loss: 1018.5370\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6509 - val_loss: 1018.6512\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6449 - val_loss: 1018.7605\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6394 - val_loss: 1018.8647\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6343 - val_loss: 1018.9640\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6298 - val_loss: 1019.0587\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6255 - val_loss: 1019.1490\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6217 - val_loss: 1019.2347\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6183 - val_loss: 1019.3164\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6151 - val_loss: 1019.3940\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6122 - val_loss: 1019.4677\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6096 - val_loss: 1019.5377\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6072 - val_loss: 1019.6040\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6050 - val_loss: 1019.6669\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6031 - val_loss: 1019.7265\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6013 - val_loss: 1019.7828\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.5997 - val_loss: 1019.8361\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.5983 - val_loss: 1019.8865\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5970 - val_loss: 1019.9342\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5958 - val_loss: 1019.9788\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.5948 - val_loss: 1020.0216\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5939 - val_loss: 1020.0615\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5931 - val_loss: 1020.0991\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5923 - val_loss: 1020.1345\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5917 - val_loss: 1020.1678\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5912 - val_loss: 1020.1992\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5907 - val_loss: 1020.2286\n",
      "Epoch 343/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5902 - val_loss: 1020.2560\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5899 - val_loss: 1020.2819\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5896 - val_loss: 1020.3062\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.5894 - val_loss: 1020.3289\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5892 - val_loss: 1020.3499\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5891 - val_loss: 1020.3698\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 9.5890 - val_loss: 1020.3882\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5889 - val_loss: 1020.4054\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5888 - val_loss: 1020.4215\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5889 - val_loss: 1020.4363\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5889 - val_loss: 1020.4504\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5890 - val_loss: 1020.4633\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5891 - val_loss: 1020.4751\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5892 - val_loss: 1020.4861\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.5894 - val_loss: 1020.4964\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5895 - val_loss: 1020.5057\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5897 - val_loss: 1020.5143\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.5899 - val_loss: 1020.5223\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.5901 - val_loss: 1020.5297\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5904 - val_loss: 1020.5366\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5906 - val_loss: 1020.5426\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5909 - val_loss: 1020.5485\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5912 - val_loss: 1020.5536\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5915 - val_loss: 1020.5585\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5918 - val_loss: 1020.5626\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5921 - val_loss: 1020.5667\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5924 - val_loss: 1020.5702\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5927 - val_loss: 1020.5733\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5931 - val_loss: 1020.5762\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5934 - val_loss: 1020.5788\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5938 - val_loss: 1020.5810\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5941 - val_loss: 1020.5831\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5945 - val_loss: 1020.5850\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.5948 - val_loss: 1020.5865\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5952 - val_loss: 1020.5879\n",
      "Epoch 378/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 9.5956 - val_loss: 1020.5890\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.5960 - val_loss: 1020.5900\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5964 - val_loss: 1020.5910\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5968 - val_loss: 1020.5917\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5971 - val_loss: 1020.5923\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.5976 - val_loss: 1020.5925\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5980 - val_loss: 1020.5929\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5984 - val_loss: 1020.5932\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5988 - val_loss: 1020.5934\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5991 - val_loss: 1020.5933\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.5995 - val_loss: 1020.5931\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.5999 - val_loss: 1020.5930\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6004 - val_loss: 1020.5927\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6008 - val_loss: 1020.5925\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6012 - val_loss: 1020.5923\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6016 - val_loss: 1020.5920\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6020 - val_loss: 1020.5914\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6024 - val_loss: 1020.5909\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6028 - val_loss: 1020.5905\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6032 - val_loss: 1020.5900\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6036 - val_loss: 1020.5893\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6040 - val_loss: 1020.5888\n",
      "Epoch 400/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6044 - val_loss: 1020.5880\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6048 - val_loss: 1020.5875\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6052 - val_loss: 1020.5867\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6056 - val_loss: 1020.5860\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6060 - val_loss: 1020.5852\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6064 - val_loss: 1020.5845\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6068 - val_loss: 1020.5840\n",
      "Epoch 407/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6072 - val_loss: 1020.5831\n",
      "Epoch 408/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 9.6075 - val_loss: 1020.5824\n",
      "Epoch 409/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6079 - val_loss: 1020.5815\n",
      "Epoch 410/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6083 - val_loss: 1020.5807\n",
      "Epoch 411/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6087 - val_loss: 1020.5800\n",
      "Epoch 412/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6091 - val_loss: 1020.5793\n",
      "Epoch 413/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6095 - val_loss: 1020.5784\n",
      "Epoch 414/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6099 - val_loss: 1020.5776\n",
      "Epoch 415/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6102 - val_loss: 1020.5769\n",
      "Epoch 416/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6106 - val_loss: 1020.5762\n",
      "Epoch 417/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6110 - val_loss: 1020.5754\n",
      "Epoch 418/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6113 - val_loss: 1020.5744\n",
      "Epoch 419/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6117 - val_loss: 1020.5738\n",
      "Epoch 420/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6121 - val_loss: 1020.5731\n",
      "Epoch 421/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6124 - val_loss: 1020.5723\n",
      "Epoch 422/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6128 - val_loss: 1020.5716\n",
      "Epoch 423/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6131 - val_loss: 1020.5707\n",
      "Epoch 424/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6135 - val_loss: 1020.5700\n",
      "Epoch 425/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6138 - val_loss: 1020.5692\n",
      "Epoch 426/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6142 - val_loss: 1020.5684\n",
      "Epoch 427/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6145 - val_loss: 1020.5675\n",
      "Epoch 428/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6149 - val_loss: 1020.5668\n",
      "Epoch 429/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6152 - val_loss: 1020.5660\n",
      "Epoch 430/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6155 - val_loss: 1020.5654\n",
      "Epoch 431/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6159 - val_loss: 1020.5649\n",
      "Epoch 432/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6161 - val_loss: 1020.5639\n",
      "Epoch 433/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6165 - val_loss: 1020.5635\n",
      "Epoch 434/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6168 - val_loss: 1020.5627\n",
      "Epoch 435/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6171 - val_loss: 1020.5621\n",
      "Epoch 436/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6174 - val_loss: 1020.5613\n",
      "Epoch 437/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6177 - val_loss: 1020.5606\n",
      "Epoch 438/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6181 - val_loss: 1020.5601\n",
      "Epoch 439/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 9.6184 - val_loss: 1020.5593\n",
      "Epoch 440/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6186 - val_loss: 1020.5587\n",
      "Epoch 441/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6190 - val_loss: 1020.5580\n",
      "Epoch 442/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6192 - val_loss: 1020.5573\n",
      "Epoch 443/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6195 - val_loss: 1020.5568\n",
      "Epoch 444/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6198 - val_loss: 1020.5560\n",
      "Epoch 445/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.6201 - val_loss: 1020.5555\n",
      "Epoch 446/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6204 - val_loss: 1020.5550\n",
      "Epoch 447/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6207 - val_loss: 1020.5544\n",
      "Epoch 448/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6209 - val_loss: 1020.5536\n",
      "Epoch 449/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6212 - val_loss: 1020.5530\n",
      "Epoch 450/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6215 - val_loss: 1020.5524\n",
      "Epoch 451/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6217 - val_loss: 1020.5519\n",
      "Epoch 452/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6220 - val_loss: 1020.5512\n",
      "Epoch 453/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6223 - val_loss: 1020.5508\n",
      "Epoch 454/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6225 - val_loss: 1020.5501\n",
      "Epoch 455/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6227 - val_loss: 1020.5494\n",
      "Epoch 456/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6230 - val_loss: 1020.5490\n",
      "Epoch 457/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6232 - val_loss: 1020.5486\n",
      "Epoch 458/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6235 - val_loss: 1020.5480\n",
      "Epoch 459/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6237 - val_loss: 1020.5474\n",
      "Epoch 460/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6239 - val_loss: 1020.5468\n",
      "Epoch 461/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6242 - val_loss: 1020.5464\n",
      "Epoch 462/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6244 - val_loss: 1020.5458\n",
      "Epoch 463/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6246 - val_loss: 1020.5455\n",
      "Epoch 464/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6248 - val_loss: 1020.5448\n",
      "Epoch 465/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6251 - val_loss: 1020.5445\n",
      "Epoch 466/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6253 - val_loss: 1020.5440\n",
      "Epoch 467/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6255 - val_loss: 1020.5434\n",
      "Epoch 468/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6257 - val_loss: 1020.5430\n",
      "Epoch 469/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6259 - val_loss: 1020.5424\n",
      "Epoch 470/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 9.6261 - val_loss: 1020.5421\n",
      "Epoch 471/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6263 - val_loss: 1020.5417\n",
      "Epoch 472/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6265 - val_loss: 1020.5411\n",
      "Epoch 473/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6267 - val_loss: 1020.5407\n",
      "Epoch 474/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6269 - val_loss: 1020.5403\n",
      "Epoch 475/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6271 - val_loss: 1020.5399\n",
      "Epoch 476/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6273 - val_loss: 1020.5394\n",
      "Epoch 477/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6275 - val_loss: 1020.5389\n",
      "Epoch 478/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6277 - val_loss: 1020.5385\n",
      "Epoch 479/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6278 - val_loss: 1020.5381\n",
      "Epoch 480/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6280 - val_loss: 1020.5376\n",
      "Epoch 481/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6282 - val_loss: 1020.5374\n",
      "Epoch 482/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6284 - val_loss: 1020.5370\n",
      "Epoch 483/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6285 - val_loss: 1020.5367\n",
      "Epoch 484/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6287 - val_loss: 1020.5363\n",
      "Epoch 485/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6288 - val_loss: 1020.5360\n",
      "Epoch 486/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6290 - val_loss: 1020.5355\n",
      "Epoch 487/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6291 - val_loss: 1020.5352\n",
      "Epoch 488/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6293 - val_loss: 1020.5349\n",
      "Epoch 489/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6294 - val_loss: 1020.5345\n",
      "Epoch 490/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6296 - val_loss: 1020.5341\n",
      "Epoch 491/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6298 - val_loss: 1020.5339\n",
      "Epoch 492/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6299 - val_loss: 1020.5336\n",
      "Epoch 493/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6301 - val_loss: 1020.5331\n",
      "Epoch 494/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6301 - val_loss: 1020.5328\n",
      "Epoch 495/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6303 - val_loss: 1020.5326\n",
      "Epoch 496/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6304 - val_loss: 1020.5322\n",
      "Epoch 497/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6306 - val_loss: 1020.5320\n",
      "Epoch 498/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 9.6307 - val_loss: 1020.5317\n",
      "Epoch 499/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6308 - val_loss: 1020.5314\n",
      "Epoch 500/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.6310 - val_loss: 1020.5311\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 333ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.39838235e+01, 7.39418067e+01, 7.38997899e+01, 7.38577731e+01,\n",
       "        7.38157563e+01, 7.37317227e+01, 7.36224790e+01, 8.51383390e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.25208310e-01,\n",
       "        0.00000000e+00, 7.43370822e+01, 7.43152334e+01, 7.42872782e+01,\n",
       "        7.42452614e+01, 7.42032446e+01, 7.41612278e+01, 7.41192110e+01,\n",
       "        7.40771942e+01, 7.40351774e+01, 7.39931606e+01, 7.39511438e+01,\n",
       "        7.39091270e+01, 7.38671102e+01, 7.38250934e+01, 7.37559991e+01,\n",
       "        7.36467554e+01, 7.35375117e+01, 7.34282680e+01, 7.33190243e+01,\n",
       "        7.32097806e+01, 7.31005369e+01, 7.29912932e+01, 7.28820495e+01,\n",
       "        7.27728058e+01, 7.26635621e+01, 7.25543184e+01, 7.24704248e+01,\n",
       "        1.77041630e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.64978340e-01, 0.00000000e+00, 0.00000000e+00, 7.38764472e+01,\n",
       "        7.38344304e+01, 7.37802754e+01, 7.36710317e+01, 7.35617881e+01,\n",
       "        7.34525443e+01, 7.33433007e+01, 7.32340570e+01, 7.31248133e+01,\n",
       "        7.30155696e+01, 7.29063259e+01, 7.27970822e+01, 7.26878385e+01,\n",
       "        7.25785948e+01, 7.24834967e+01, 7.54567740e+01, 7.52197992e+01,\n",
       "        7.49828245e+01, 7.47458497e+01, 7.45458590e+01, 7.44803128e+01,\n",
       "        7.44147666e+01, 7.43492203e+01, 7.42686041e+01, 1.20782113e+00,\n",
       "        0.00000000e+00, 6.42200470e+01, 4.50416830e-01, 1.36045900e-01,\n",
       "        5.00575600e-01, 2.35461760e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.17919350e+01, 2.74588913e-01, 2.39897281e-01, 0.00000000e+00,\n",
       "        1.63825810e-01, 5.94637513e-01, 0.00000000e+00, 8.31045032e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.92393446e-01,\n",
       "        4.08036411e-01, 5.61039969e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.24612653e-01, 1.81440070e-01, 7.02173233e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.46985294, 69.46471755, 69.45958217, 69.45444678, 69.44931139,\n",
       "       69.444176  , 69.43904062, 69.43390523, 69.42876984, 69.42363445,\n",
       "       69.41849907, 69.41336368, 69.40822829, 69.4030929 , 69.39795752,\n",
       "       69.39282213, 69.38768674, 69.38255135, 69.37741597, 69.37228058,\n",
       "       69.36714519, 69.3620098 , 69.35687442, 69.35173903, 69.34660364,\n",
       "       69.34146825, 69.33633287, 69.33119748, 69.32606209, 69.3209267 ,\n",
       "       69.31579132, 69.31065593, 69.30552054, 69.30038515, 69.29418597,\n",
       "       69.28790053, 69.28161509, 69.27532964, 69.2690442 , 69.26275876,\n",
       "       69.25647332, 69.25018788, 69.24390244, 69.237617  , 69.23133156,\n",
       "       69.22504612, 69.21876068, 69.21247523, 69.20618979, 69.19990435,\n",
       "       69.19361891, 69.18733347, 69.18104803, 69.17476259, 69.16847715,\n",
       "       69.16219171, 69.15590626, 69.14962082, 69.14333538, 69.13704994,\n",
       "       69.1307645 , 69.12447906, 69.11819362, 69.11190818, 69.10562274,\n",
       "       69.0993373 , 69.09305185, 69.08676641, 69.08048097, 69.07419553,\n",
       "       69.06791009, 69.06162465, 69.05533921, 69.04905377, 69.04276833,\n",
       "       69.03648289, 69.03019744, 69.023912  , 69.01762656, 69.01134112,\n",
       "       69.00505568, 68.99877024, 68.9924848 , 68.98619936, 68.97991392,\n",
       "       68.97362848, 68.96734303, 68.96105759, 68.95477215, 68.94848671,\n",
       "       68.94220127, 68.93591583, 68.92963039, 68.92334495, 68.91705951,\n",
       "       68.91077407, 68.90448862, 68.89820318, 68.89191774, 68.8856323 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.724868516717\n",
      "30.343158031143695\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
