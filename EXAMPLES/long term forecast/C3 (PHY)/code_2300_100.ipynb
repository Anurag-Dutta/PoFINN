{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2395    67.653686\n",
       "2396    67.647400\n",
       "2397    67.641115\n",
       "2398    67.634830\n",
       "2399    67.628544\n",
       "Name: C3, Length: 2400, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_2300_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2295     0.566975\n",
       "2296     0.322637\n",
       "2297     0.000000\n",
       "2298     0.000000\n",
       "2299     0.000000\n",
       "Name: C3, Length: 2300, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2300)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1850, 1, 251) (1850, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 3s 23ms/step - loss: 5659.1748 - val_loss: 3655.5652\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5442.7974 - val_loss: 3512.1133\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5314.1509 - val_loss: 3436.0659\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5219.9043 - val_loss: 3377.1565\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 5137.1982 - val_loss: 3323.4797\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 5053.1978 - val_loss: 3268.0107\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4972.4194 - val_loss: 3216.3831\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4894.7090 - val_loss: 3166.8486\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4819.0996 - val_loss: 3118.6838\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4745.1353 - val_loss: 3071.6716\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4672.5586 - val_loss: 3025.6934\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4601.2153 - val_loss: 2980.8459\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4531.0010 - val_loss: 2936.2156\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4461.8398 - val_loss: 2892.8704\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4393.6753 - val_loss: 2850.3230\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4326.4644 - val_loss: 2808.5461\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4260.1704 - val_loss: 2767.5161\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4194.7637 - val_loss: 2727.2100\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4130.0278 - val_loss: 2676.9343\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4044.6226 - val_loss: 2632.1150\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 3974.0562 - val_loss: 2589.8430\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3906.0625 - val_loss: 2549.1877\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3840.0334 - val_loss: 2509.7627\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3775.5139 - val_loss: 2471.3699\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3712.2656 - val_loss: 2433.8979\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3650.1489 - val_loss: 2397.2756\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3589.0757 - val_loss: 2361.4548\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3528.9795 - val_loss: 2326.3972\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3469.8132 - val_loss: 2292.0750\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3411.5388 - val_loss: 2258.4639\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3354.1252 - val_loss: 2225.5444\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3297.5474 - val_loss: 2193.2991\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3241.7832 - val_loss: 2161.7129\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3186.8135 - val_loss: 2130.7727\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3132.6204 - val_loss: 2100.4656\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3079.1892 - val_loss: 2070.7805\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3026.5063 - val_loss: 2041.7072\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2974.5591 - val_loss: 2013.2354\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2923.3347 - val_loss: 1985.3564\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2872.8228 - val_loss: 1958.0616\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2823.0127 - val_loss: 1931.3423\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2773.8948 - val_loss: 1905.1902\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2725.4597 - val_loss: 1879.5981\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2677.6990 - val_loss: 1854.5588\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2630.6025 - val_loss: 1830.0648\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2584.1643 - val_loss: 1806.1086\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2538.3750 - val_loss: 1782.6846\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2493.2273 - val_loss: 1759.7855\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2448.7139 - val_loss: 1737.4050\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2404.8276 - val_loss: 1715.5371\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2361.5613 - val_loss: 1694.1753\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2318.9082 - val_loss: 1673.3135\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2276.8621 - val_loss: 1652.9462\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2235.4158 - val_loss: 1633.0669\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2194.5637 - val_loss: 1613.6708\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2154.2996 - val_loss: 1594.7510\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2114.6167 - val_loss: 1576.3032\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2075.5090 - val_loss: 1558.3217\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2036.9714 - val_loss: 1540.8000\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1998.9977 - val_loss: 1523.7334\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1961.5822 - val_loss: 1507.1174\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1924.7191 - val_loss: 1490.9454\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1888.4027 - val_loss: 1475.2129\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1852.6284 - val_loss: 1459.9147\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1817.3900 - val_loss: 1445.0454\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1782.6826 - val_loss: 1430.6007\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1748.5009 - val_loss: 1416.5750\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1714.8390 - val_loss: 1402.9631\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1681.6936 - val_loss: 1389.7610\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1649.0580 - val_loss: 1376.9631\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1616.9270 - val_loss: 1364.5647\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1585.2968 - val_loss: 1352.5607\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1554.1624 - val_loss: 1340.9467\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1523.5175 - val_loss: 1329.7179\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1493.3588 - val_loss: 1318.8694\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1463.6805 - val_loss: 1308.3967\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1434.4788 - val_loss: 1298.2948\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1405.7479 - val_loss: 1288.5593\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1377.4838 - val_loss: 1279.1854\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1349.6819 - val_loss: 1270.1689\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1322.3373 - val_loss: 1261.5045\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1295.4458 - val_loss: 1253.1882\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1269.0023 - val_loss: 1245.2152\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1243.0029 - val_loss: 1237.5811\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1217.4426 - val_loss: 1230.2812\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1192.3173 - val_loss: 1223.3113\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1167.6223 - val_loss: 1216.6665\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1143.3535 - val_loss: 1210.3431\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1119.5065 - val_loss: 1204.5591\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1092.6100 - val_loss: 1196.9415\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1063.9922 - val_loss: 1190.4927\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1037.0660 - val_loss: 1184.7085\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1011.5168 - val_loss: 1179.4579\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 986.9960 - val_loss: 1174.6675\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 963.3141 - val_loss: 1170.2937\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 940.3610 - val_loss: 1166.3068\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 918.0638 - val_loss: 1162.6857\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 896.3719 - val_loss: 1159.4124\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 875.2463 - val_loss: 1156.4731\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 854.6574 - val_loss: 1153.8556\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 834.5807 - val_loss: 1151.5487\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 814.9953 - val_loss: 1149.5428\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 795.8840 - val_loss: 1147.8291\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 777.2311 - val_loss: 1146.3990\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 759.0236 - val_loss: 1145.2450\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 741.2485 - val_loss: 1144.3594\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 723.8951 - val_loss: 1143.7351\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 706.9530 - val_loss: 1143.3655\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 690.4127 - val_loss: 1143.2438\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 674.2649 - val_loss: 1143.3636\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 658.5016 - val_loss: 1143.7189\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 643.1146 - val_loss: 1144.3036\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 628.0966 - val_loss: 1145.1117\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 613.4399 - val_loss: 1146.1373\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 599.1378 - val_loss: 1147.3746\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 585.1833 - val_loss: 1148.8184\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 571.5701 - val_loss: 1150.4631\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 558.2919 - val_loss: 1152.3029\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 545.3423 - val_loss: 1154.3325\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 532.7156 - val_loss: 1156.5468\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 520.4059 - val_loss: 1158.9404\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 508.4073 - val_loss: 1161.5081\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 496.7144 - val_loss: 1164.2446\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 485.3217 - val_loss: 1167.1451\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 474.2238 - val_loss: 1170.2042\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 463.4154 - val_loss: 1173.4170\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 452.8913 - val_loss: 1176.7784\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 442.6463 - val_loss: 1180.2836\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 432.6756 - val_loss: 1183.9276\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 422.9738 - val_loss: 1187.7054\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 413.5362 - val_loss: 1191.6125\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 404.3580 - val_loss: 1195.6439\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 395.4343 - val_loss: 1199.7948\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 386.7604 - val_loss: 1204.0603\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 378.3316 - val_loss: 1208.4358\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 370.1432 - val_loss: 1212.9169\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 362.1906 - val_loss: 1217.4985\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 354.4695 - val_loss: 1222.1764\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 346.9749 - val_loss: 1226.9457\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 339.7027 - val_loss: 1231.8019\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 332.6483 - val_loss: 1236.7404\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 325.8076 - val_loss: 1241.7571\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 319.1760 - val_loss: 1246.8472\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 312.7491 - val_loss: 1252.0066\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 306.5229 - val_loss: 1257.2307\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 300.4930 - val_loss: 1262.5150\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 294.6552 - val_loss: 1267.8553\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 289.0055 - val_loss: 1273.2479\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 283.5396 - val_loss: 1278.6884\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 278.2536 - val_loss: 1284.1720\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 273.1432 - val_loss: 1289.6951\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 268.2047 - val_loss: 1295.2537\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 263.4340 - val_loss: 1300.8431\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 258.8270 - val_loss: 1306.4603\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 254.3800 - val_loss: 1312.1013\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 250.0891 - val_loss: 1317.7610\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 245.9506 - val_loss: 1323.4368\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 241.9606 - val_loss: 1329.1249\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 238.1154 - val_loss: 1334.8204\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 234.4114 - val_loss: 1340.5214\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 230.8447 - val_loss: 1346.2230\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 227.4120 - val_loss: 1351.9218\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 224.1096 - val_loss: 1357.6147\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 220.9339 - val_loss: 1363.2982\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 217.8816 - val_loss: 1368.9689\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 214.9490 - val_loss: 1374.6235\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 212.1330 - val_loss: 1380.2587\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 209.4300 - val_loss: 1385.8721\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 206.8368 - val_loss: 1391.4598\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 204.3502 - val_loss: 1397.0189\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 201.9669 - val_loss: 1402.5468\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 199.6839 - val_loss: 1408.0406\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 197.4979 - val_loss: 1413.4977\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 195.4058 - val_loss: 1418.9146\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 193.4049 - val_loss: 1424.2897\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 191.4920 - val_loss: 1429.6199\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 189.6642 - val_loss: 1434.9031\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 187.9188 - val_loss: 1440.1368\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 186.2529 - val_loss: 1445.3184\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 184.6637 - val_loss: 1450.4464\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 183.1486 - val_loss: 1455.5184\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 181.7048 - val_loss: 1460.5327\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 180.3299 - val_loss: 1465.4867\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 179.0213 - val_loss: 1470.3793\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 177.7766 - val_loss: 1475.2081\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 176.5931 - val_loss: 1479.9723\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 175.4687 - val_loss: 1484.6694\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 174.4011 - val_loss: 1489.2987\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 173.3880 - val_loss: 1493.8590\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 172.4271 - val_loss: 1498.3481\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 171.5164 - val_loss: 1502.7653\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 170.6537 - val_loss: 1507.1095\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 169.8371 - val_loss: 1511.3798\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 169.0645 - val_loss: 1515.5760\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 168.3339 - val_loss: 1519.6962\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 167.6437 - val_loss: 1523.7402\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 166.9921 - val_loss: 1527.7068\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 166.3771 - val_loss: 1531.5967\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 165.7971 - val_loss: 1535.4080\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 165.2505 - val_loss: 1539.1414\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 164.7358 - val_loss: 1542.7965\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 164.2514 - val_loss: 1546.3723\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 163.7956 - val_loss: 1549.8698\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 163.3673 - val_loss: 1553.2880\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 162.9650 - val_loss: 1556.6279\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 162.5874 - val_loss: 1559.8885\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 162.2331 - val_loss: 1563.0709\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.9011 - val_loss: 1566.1760\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.5900 - val_loss: 1569.2020\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.2987 - val_loss: 1572.1511\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.0263 - val_loss: 1575.0233\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 160.7716 - val_loss: 1577.8191\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 160.5337 - val_loss: 1580.5392\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 160.3116 - val_loss: 1583.1841\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 160.1043 - val_loss: 1585.7545\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 159.9111 - val_loss: 1588.2517\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 159.7310 - val_loss: 1590.6755\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 159.5634 - val_loss: 1593.0286\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 159.4074 - val_loss: 1595.3094\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 159.2623 - val_loss: 1597.5215\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 159.1275 - val_loss: 1599.6641\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 159.0024 - val_loss: 1601.7400\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 158.8862 - val_loss: 1603.7482\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 158.7785 - val_loss: 1605.6909\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 158.6787 - val_loss: 1607.5687\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 158.5862 - val_loss: 1609.3846\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 158.5006 - val_loss: 1611.1372\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 158.4214 - val_loss: 1612.8293\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 158.3482 - val_loss: 1614.4620\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 158.2806 - val_loss: 1616.0370\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 158.2181 - val_loss: 1617.5544\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 158.1605 - val_loss: 1619.0160\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 158.1074 - val_loss: 1620.4240\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 158.0584 - val_loss: 1621.7786\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 158.0132 - val_loss: 1623.0814\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.9717 - val_loss: 1624.3337\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.9335 - val_loss: 1625.5374\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.8983 - val_loss: 1626.6932\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.8659 - val_loss: 1627.8031\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.8363 - val_loss: 1628.8669\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.8091 - val_loss: 1629.8878\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.7840 - val_loss: 1630.8658\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.7610 - val_loss: 1631.8031\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.7401 - val_loss: 1632.6998\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 157.7208 - val_loss: 1633.5574\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 157.7031 - val_loss: 1634.3784\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 157.6870 - val_loss: 1635.1637\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 157.6722 - val_loss: 1635.9138\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.6586 - val_loss: 1636.6298\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.6464 - val_loss: 1637.3126\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 157.6350 - val_loss: 1637.9648\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 157.6248 - val_loss: 1638.5868\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.6154 - val_loss: 1639.1797\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.6067 - val_loss: 1639.7438\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5990 - val_loss: 1640.2825\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5918 - val_loss: 1640.7946\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5853 - val_loss: 1641.2808\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5794 - val_loss: 1641.7433\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5741 - val_loss: 1642.1831\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5692 - val_loss: 1642.6013\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5648 - val_loss: 1642.9983\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5607 - val_loss: 1643.3746\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5571 - val_loss: 1643.7319\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5538 - val_loss: 1644.0704\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5508 - val_loss: 1644.3900\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5482 - val_loss: 1644.6942\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5457 - val_loss: 1644.9816\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5436 - val_loss: 1645.2537\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5416 - val_loss: 1645.5109\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5399 - val_loss: 1645.7543\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5383 - val_loss: 1645.9841\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5369 - val_loss: 1646.2013\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5357 - val_loss: 1646.4066\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 157.5346 - val_loss: 1646.6000\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 157.5337 - val_loss: 1646.7831\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5328 - val_loss: 1646.9547\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5321 - val_loss: 1647.1169\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 157.5314 - val_loss: 1647.2701\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5309 - val_loss: 1647.4138\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5305 - val_loss: 1647.5490\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5301 - val_loss: 1647.6769\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5298 - val_loss: 1647.7965\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5296 - val_loss: 1647.9088\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5294 - val_loss: 1648.0155\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5293 - val_loss: 1648.1149\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5292 - val_loss: 1648.2083\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5292 - val_loss: 1648.2957\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5292 - val_loss: 1648.3779\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5293 - val_loss: 1648.4551\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5293 - val_loss: 1648.5272\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5295 - val_loss: 1648.5952\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5296 - val_loss: 1648.6577\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5298 - val_loss: 1648.7173\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5300 - val_loss: 1648.7720\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5302 - val_loss: 1648.8239\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5305 - val_loss: 1648.8732\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5308 - val_loss: 1648.9182\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5310 - val_loss: 1648.9612\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5314 - val_loss: 1649.0009\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 157.5316 - val_loss: 1649.0371\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 157.5320 - val_loss: 1649.0719\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 157.5323 - val_loss: 1649.1040\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5326 - val_loss: 1649.1342\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5330 - val_loss: 1649.1621\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5333 - val_loss: 1649.1880\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5337 - val_loss: 1649.2129\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5340 - val_loss: 1649.2347\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5344 - val_loss: 1649.2559\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 157.5347 - val_loss: 1649.2747\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5352 - val_loss: 1649.2936\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5354 - val_loss: 1649.3104\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5359 - val_loss: 1649.3256\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 157.5362 - val_loss: 1649.3406\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5367 - val_loss: 1649.3539\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5370 - val_loss: 1649.3662\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5374 - val_loss: 1649.3782\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5378 - val_loss: 1649.3890\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 157.5382 - val_loss: 1649.3993\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 157.5385 - val_loss: 1649.4081\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5389 - val_loss: 1649.4169\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5392 - val_loss: 1649.4244\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5396 - val_loss: 1649.4314\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5400 - val_loss: 1649.4385\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5403 - val_loss: 1649.4442\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 157.5406 - val_loss: 1649.4495\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5410 - val_loss: 1649.4551\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5414 - val_loss: 1649.4598\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5417 - val_loss: 1649.4636\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5420 - val_loss: 1649.4686\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5424 - val_loss: 1649.4714\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5427 - val_loss: 1649.4745\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 157.5431 - val_loss: 1649.4789\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5434 - val_loss: 1649.4811\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5437 - val_loss: 1649.4836\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5440 - val_loss: 1649.4856\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5444 - val_loss: 1649.4873\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5446 - val_loss: 1649.4897\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5449 - val_loss: 1649.4919\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 157.5452 - val_loss: 1649.4934\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5455 - val_loss: 1649.4946\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5459 - val_loss: 1649.4965\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5461 - val_loss: 1649.4974\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5464 - val_loss: 1649.4991\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5466 - val_loss: 1649.4995\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5469 - val_loss: 1649.5009\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5472 - val_loss: 1649.5013\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5474 - val_loss: 1649.5026\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 157.5477 - val_loss: 1649.5031\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5480 - val_loss: 1649.5039\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5482 - val_loss: 1649.5040\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5485 - val_loss: 1649.5043\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5486 - val_loss: 1649.5044\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5489 - val_loss: 1649.5048\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5492 - val_loss: 1649.5045\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5494 - val_loss: 1649.5049\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5496 - val_loss: 1649.5049\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5498 - val_loss: 1649.5045\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5500 - val_loss: 1649.5051\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5502 - val_loss: 1649.5052\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 157.5504 - val_loss: 1649.5051\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5506 - val_loss: 1649.5048\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5508 - val_loss: 1649.5045\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5510 - val_loss: 1649.5043\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5512 - val_loss: 1649.5040\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5514 - val_loss: 1649.5039\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5515 - val_loss: 1649.5035\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5517 - val_loss: 1649.5034\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5519 - val_loss: 1649.5034\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5520 - val_loss: 1649.5034\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5523 - val_loss: 1649.5035\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5525 - val_loss: 1649.5034\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5526 - val_loss: 1649.5031\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5527 - val_loss: 1649.5027\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5529 - val_loss: 1649.5026\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5530 - val_loss: 1649.5026\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 157.5531 - val_loss: 1649.5021\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5533 - val_loss: 1649.5013\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5535 - val_loss: 1649.5021\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5536 - val_loss: 1649.5021\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5536 - val_loss: 1649.5007\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5539 - val_loss: 1649.5005\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5540 - val_loss: 1649.5004\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5541 - val_loss: 1649.5004\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5542 - val_loss: 1649.5001\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 157.5543 - val_loss: 1649.5000\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5544 - val_loss: 1649.4996\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5546 - val_loss: 1649.4995\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5547 - val_loss: 1649.4995\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5548 - val_loss: 1649.4991\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5549 - val_loss: 1649.4990\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5550 - val_loss: 1649.4991\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5551 - val_loss: 1649.4993\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5552 - val_loss: 1649.4987\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5553 - val_loss: 1649.4983\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5554 - val_loss: 1649.4977\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5555 - val_loss: 1649.4974\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5556 - val_loss: 1649.4971\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5557 - val_loss: 1649.4969\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5558 - val_loss: 1649.4966\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5558 - val_loss: 1649.4969\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5559 - val_loss: 1649.4968\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5560 - val_loss: 1649.4966\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5561 - val_loss: 1649.4965\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5561 - val_loss: 1649.4960\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5563 - val_loss: 1649.4960\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5563 - val_loss: 1649.4957\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5564 - val_loss: 1649.4956\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5565 - val_loss: 1649.4956\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5565 - val_loss: 1649.4952\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 157.5566 - val_loss: 1649.4946\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5567 - val_loss: 1649.4949\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5567 - val_loss: 1649.4944\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5569 - val_loss: 1649.4946\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5569 - val_loss: 1649.4948\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5570 - val_loss: 1649.4948\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5570 - val_loss: 1649.4952\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5570 - val_loss: 1649.4949\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5571 - val_loss: 1649.4948\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5572 - val_loss: 1649.4943\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5572 - val_loss: 1649.4946\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5573 - val_loss: 1649.4948\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5573 - val_loss: 1649.4938\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5574 - val_loss: 1649.4933\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5575 - val_loss: 1649.4935\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5575 - val_loss: 1649.4939\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5575 - val_loss: 1649.4935\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5576 - val_loss: 1649.4930\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5576 - val_loss: 1649.4930\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5576 - val_loss: 1649.4930\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5577 - val_loss: 1649.4930\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5577 - val_loss: 1649.4930\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5578 - val_loss: 1649.4930\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5578 - val_loss: 1649.4927\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5578 - val_loss: 1649.4922\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 157.5579 - val_loss: 1649.4919\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5579 - val_loss: 1649.4919\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5580 - val_loss: 1649.4916\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5580 - val_loss: 1649.4916\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5580 - val_loss: 1649.4907\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5580 - val_loss: 1649.4906\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5581 - val_loss: 1649.4906\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5582 - val_loss: 1649.4911\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5582 - val_loss: 1649.4913\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5582 - val_loss: 1649.4908\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5582 - val_loss: 1649.4908\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5582 - val_loss: 1649.4902\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5582 - val_loss: 1649.4895\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5583 - val_loss: 1649.4889\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5584 - val_loss: 1649.4890\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5583 - val_loss: 1649.4886\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5584 - val_loss: 1649.4884\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5584 - val_loss: 1649.4885\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5584 - val_loss: 1649.4882\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 157.5585 - val_loss: 1649.4882\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5585 - val_loss: 1649.4884\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5585 - val_loss: 1649.4884\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5586 - val_loss: 1649.4885\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 157.5586 - val_loss: 1649.4894\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5586 - val_loss: 1649.4897\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5587 - val_loss: 1649.4900\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5586 - val_loss: 1649.4899\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5586 - val_loss: 1649.4899\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5587 - val_loss: 1649.4895\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5587 - val_loss: 1649.4890\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5587 - val_loss: 1649.4891\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5587 - val_loss: 1649.4890\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5587 - val_loss: 1649.4878\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5588 - val_loss: 1649.4873\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5588 - val_loss: 1649.4872\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5588 - val_loss: 1649.4872\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5589 - val_loss: 1649.4872\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5589 - val_loss: 1649.4875\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5589 - val_loss: 1649.4884\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5589 - val_loss: 1649.4880\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5589 - val_loss: 1649.4878\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5589 - val_loss: 1649.4878\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5589 - val_loss: 1649.4880\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5589 - val_loss: 1649.4882\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 157.5589 - val_loss: 1649.4882\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 157.5589 - val_loss: 1649.4878\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 157.5589 - val_loss: 1649.4875\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5589 - val_loss: 1649.4865\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5589 - val_loss: 1649.4858\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5590 - val_loss: 1649.4856\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5590 - val_loss: 1649.4855\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 157.5590 - val_loss: 1649.4854\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5590 - val_loss: 1649.4847\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5590 - val_loss: 1649.4846\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5590 - val_loss: 1649.4840\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5591 - val_loss: 1649.4838\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5591 - val_loss: 1649.4836\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5591 - val_loss: 1649.4834\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5591 - val_loss: 1649.4834\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5592 - val_loss: 1649.4838\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5592 - val_loss: 1649.4847\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5592 - val_loss: 1649.4847\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 157.5592 - val_loss: 1649.4847\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5592 - val_loss: 1649.4850\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5592 - val_loss: 1649.4846\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.5592 - val_loss: 1649.4841\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 355ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.45021615e+01, 7.44366153e+01, 7.43710691e+01, 7.43055229e+01,\n",
       "        7.89629211e+01, 7.13987590e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.95861490e-01, 2.44051470e-01, 0.00000000e+00, 7.39923120e-01,\n",
       "        0.00000000e+00, 7.28577731e+01, 7.27485294e+01, 7.26392857e+01,\n",
       "        7.25300420e+01, 7.24573529e+01, 7.53514519e+01, 7.51144771e+01,\n",
       "        7.48775023e+01, 7.46405275e+01, 7.45167274e+01, 7.44511811e+01,\n",
       "        7.43856349e+01, 7.43200887e+01, 7.42125817e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.45434314e+01, 7.44778852e+01, 7.44123389e+01,\n",
       "        7.43467927e+01, 7.42639356e+01, 7.41378852e+01, 7.40118347e+01,\n",
       "        7.38857843e+01, 7.36953081e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.38458010e-02,\n",
       "        0.00000000e+00, 4.24088746e-01, 0.00000000e+00, 7.43346545e+01,\n",
       "        7.42405929e+01, 2.03825940e-01, 3.15012340e-01, 7.45579972e+01,\n",
       "        7.44924510e+01, 7.44269048e+01, 7.43613585e+01, 7.42919468e+01,\n",
       "        7.41658964e+01, 7.40398459e+01, 7.39137955e+01, 7.37681372e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.43225163e+01, 7.42172502e+01,\n",
       "        7.40911998e+01, 7.39651494e+01, 7.38390990e+01, 7.35739262e+01,\n",
       "        7.32461951e+01, 7.29184640e+01, 7.25907330e+01, 9.50655500e-02,\n",
       "        0.00000000e+00, 6.93809586e+01, 8.27442300e-02, 0.00000000e+00,\n",
       "        6.12963200e-01, 2.98626840e-01, 0.00000000e+00, 1.89379860e-01,\n",
       "        6.78012161e+01, 0.00000000e+00, 7.30226278e-01, 0.00000000e+00,\n",
       "        6.81534052e-01, 0.00000000e+00, 7.81680271e-02, 1.88618451e-01,\n",
       "        1.82531565e-01, 0.00000000e+00, 2.99296409e-01, 3.43640864e-01,\n",
       "        2.53875822e-01, 1.20558865e-01, 4.08220649e-01, 5.49755991e-01,\n",
       "        2.26634368e-01, 3.69677514e-01, 6.74163476e-02, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68.25080276, 68.24451732, 68.23823188, 68.23194644, 68.225661  ,\n",
       "       68.21937556, 68.21309011, 68.20680467, 68.20051923, 68.19423379,\n",
       "       68.18794835, 68.18166291, 68.17537747, 68.16909203, 68.16280659,\n",
       "       68.15652115, 68.1502357 , 68.14395026, 68.13766482, 68.13137938,\n",
       "       68.12509394, 68.1188085 , 68.11252306, 68.10623762, 68.09995218,\n",
       "       68.09366673, 68.08738129, 68.08109585, 68.07481041, 68.06852497,\n",
       "       68.06223953, 68.05595409, 68.04966865, 68.04338321, 68.03709777,\n",
       "       68.03081232, 68.02452688, 68.01824144, 68.011956  , 68.00567056,\n",
       "       67.99938512, 67.99309968, 67.98681424, 67.9805288 , 67.97424336,\n",
       "       67.96795791, 67.96167247, 67.95538703, 67.94910159, 67.94281615,\n",
       "       67.93653071, 67.93024527, 67.92395983, 67.91767439, 67.91138895,\n",
       "       67.9051035 , 67.89881806, 67.89253262, 67.88624718, 67.87996174,\n",
       "       67.8736763 , 67.86739086, 67.86110542, 67.85481998, 67.84853454,\n",
       "       67.84224909, 67.83596365, 67.82967821, 67.82339277, 67.81710733,\n",
       "       67.81082189, 67.80453645, 67.79825101, 67.79196557, 67.78568013,\n",
       "       67.77939468, 67.77310924, 67.7668238 , 67.76053836, 67.75425292,\n",
       "       67.74796748, 67.74168204, 67.7353966 , 67.72911116, 67.72282572,\n",
       "       67.71654027, 67.71025483, 67.70396939, 67.69768395, 67.69139851,\n",
       "       67.68511307, 67.67882763, 67.67254219, 67.66625675, 67.65997131,\n",
       "       67.65368586, 67.64740042, 67.64111498, 67.63482954, 67.6285441 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.05550449472461\n",
      "36.799128467654434\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
