{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "1895    70.578338\n",
       "1896    70.570868\n",
       "1897    70.563399\n",
       "1898    70.555929\n",
       "1899    70.548459\n",
       "Name: C3, Length: 1900, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_1800_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "1795     0.665693\n",
       "1796     0.000000\n",
       "1797     0.171254\n",
       "1798     0.000000\n",
       "1799     0.000000\n",
       "Name: C3, Length: 1800, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1800)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1350, 1, 251) (1350, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 2s 32ms/step - loss: 6041.6831 - val_loss: 4965.3530\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5967.4370 - val_loss: 4911.7412\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5917.8564 - val_loss: 4863.7417\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5869.2236 - val_loss: 4825.7080\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5825.9775 - val_loss: 4788.1489\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5783.2671 - val_loss: 4751.0488\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5741.0137 - val_loss: 4714.3223\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5699.1401 - val_loss: 4677.9180\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5657.5942 - val_loss: 4641.8022\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5616.3486 - val_loss: 4605.9531\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5575.3804 - val_loss: 4570.3579\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5534.6777 - val_loss: 4535.0044\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5494.2295 - val_loss: 4499.8862\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5454.0288 - val_loss: 4464.9980\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5414.0679 - val_loss: 4430.3335\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5374.3433 - val_loss: 4395.8892\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5334.8506 - val_loss: 4361.6621\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5295.5854 - val_loss: 4327.6499\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5256.5469 - val_loss: 4293.8486\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5217.7310 - val_loss: 4260.2554\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5179.1343 - val_loss: 4226.8716\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5140.7563 - val_loss: 4193.6919\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5102.5942 - val_loss: 4160.7158\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5064.6470 - val_loss: 4127.9419\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5024.2476 - val_loss: 4087.3811\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4976.9971 - val_loss: 4049.0811\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4933.2295 - val_loss: 4011.8621\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4890.7607 - val_loss: 3975.6921\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4849.3232 - val_loss: 3940.2925\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4808.6509 - val_loss: 3905.4888\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4768.5825 - val_loss: 3871.1731\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4729.0181 - val_loss: 3837.2798\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4689.8955 - val_loss: 3803.7642\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4651.1675 - val_loss: 3770.5928\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4612.8027 - val_loss: 3737.7412\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4574.7764 - val_loss: 3705.1924\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4537.0703 - val_loss: 3672.9297\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4499.6680 - val_loss: 3640.9429\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4462.5571 - val_loss: 3609.2207\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4425.7266 - val_loss: 3577.7546\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4389.1685 - val_loss: 3546.5381\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4352.8750 - val_loss: 3515.5654\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4316.8408 - val_loss: 3484.8301\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4281.0571 - val_loss: 3454.3286\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4245.5215 - val_loss: 3424.0554\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4210.2280 - val_loss: 3394.0068\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4175.1724 - val_loss: 3364.1804\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4140.3525 - val_loss: 3334.5718\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 4105.7632 - val_loss: 3305.1782\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4071.4023 - val_loss: 3275.9976\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4037.2656 - val_loss: 3247.0269\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4003.3523 - val_loss: 3218.2637\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3969.6584 - val_loss: 3189.7058\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3936.1824 - val_loss: 3161.3513\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3902.9209 - val_loss: 3133.1987\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3869.8730 - val_loss: 3105.2454\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3837.0366 - val_loss: 3077.4902\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3804.4094 - val_loss: 3049.9312\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3771.9897 - val_loss: 3022.5667\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3739.7761 - val_loss: 2995.3950\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3707.7664 - val_loss: 2968.4146\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3675.9587 - val_loss: 2941.6245\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3644.3533 - val_loss: 2915.0237\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3612.9473 - val_loss: 2888.6091\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3581.7388 - val_loss: 2862.3816\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 3550.7273 - val_loss: 2836.3381\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3519.9114 - val_loss: 2810.4788\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3489.2891 - val_loss: 2784.8020\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3458.8604 - val_loss: 2759.3059\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3428.6233 - val_loss: 2733.9900\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3398.5767 - val_loss: 2708.8540\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3368.7195 - val_loss: 2683.8945\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3339.0503 - val_loss: 2659.1133\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3309.5688 - val_loss: 2634.5071\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3280.2732 - val_loss: 2610.0767\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3251.1624 - val_loss: 2585.8193\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3222.2351 - val_loss: 2561.7354\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3193.4912 - val_loss: 2537.8235\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3164.9294 - val_loss: 2514.0825\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3136.5483 - val_loss: 2490.5115\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3108.3477 - val_loss: 2467.1101\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3080.3252 - val_loss: 2443.8770\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 3052.4812 - val_loss: 2420.8103\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3024.8147 - val_loss: 2397.9111\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2997.3237 - val_loss: 2375.1780\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2970.0093 - val_loss: 2352.6094\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2942.8687 - val_loss: 2330.2048\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2915.9016 - val_loss: 2307.9629\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2889.1077 - val_loss: 2285.8843\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2862.4856 - val_loss: 2263.9673\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2836.0349 - val_loss: 2242.2112\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2809.7551 - val_loss: 2220.6155\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 2783.6440 - val_loss: 2199.1785\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2757.7017 - val_loss: 2177.8999\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2731.9275 - val_loss: 2156.7798\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2706.3203 - val_loss: 2135.8164\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2680.8799 - val_loss: 2115.0098\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2655.6042 - val_loss: 2094.3577\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2630.4937 - val_loss: 2073.8611\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2605.5474 - val_loss: 2053.5183\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2580.7646 - val_loss: 2033.3292\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2556.1445 - val_loss: 2013.2928\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2531.6858 - val_loss: 1993.4083\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2507.3889 - val_loss: 1973.6754\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2483.2522 - val_loss: 1954.0930\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2459.2749 - val_loss: 1934.6608\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2435.4573 - val_loss: 1915.3772\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2411.7971 - val_loss: 1896.2429\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2388.2961 - val_loss: 1877.2566\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2364.9509 - val_loss: 1858.4178\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2341.7627 - val_loss: 1839.7252\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2318.7300 - val_loss: 1821.1783\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2295.8511 - val_loss: 1802.7775\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2273.1279 - val_loss: 1784.5206\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2250.5581 - val_loss: 1766.4080\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 2228.1409 - val_loss: 1748.4385\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2205.8762 - val_loss: 1730.6124\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2183.7632 - val_loss: 1712.9281\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2161.8013 - val_loss: 1695.3855\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2139.9895 - val_loss: 1677.9843\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2118.3279 - val_loss: 1660.7231\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2096.8159 - val_loss: 1643.6013\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2075.4519 - val_loss: 1626.6193\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2054.2368 - val_loss: 1609.7754\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2033.1683 - val_loss: 1593.0695\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2012.2463 - val_loss: 1576.5005\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1991.4713 - val_loss: 1560.0687\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1970.8412 - val_loss: 1543.7734\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1950.3564 - val_loss: 1527.6135\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1930.0161 - val_loss: 1511.5881\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1909.8195 - val_loss: 1495.6981\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1889.7661 - val_loss: 1479.9413\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1869.8556 - val_loss: 1464.3182\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1850.0869 - val_loss: 1448.8273\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1830.4592 - val_loss: 1433.4683\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1810.9728 - val_loss: 1418.2415\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1791.6267 - val_loss: 1403.1458\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1772.4210 - val_loss: 1388.1810\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1753.3539 - val_loss: 1373.3446\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1734.4252 - val_loss: 1358.6381\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1715.6346 - val_loss: 1344.0601\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1696.9813 - val_loss: 1329.6107\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1678.4656 - val_loss: 1315.2889\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1660.0865 - val_loss: 1301.0948\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1641.8430 - val_loss: 1287.0270\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1623.7351 - val_loss: 1273.0852\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1605.7617 - val_loss: 1259.2689\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1587.9229 - val_loss: 1245.5778\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1570.2177 - val_loss: 1232.0116\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1552.6461 - val_loss: 1218.5685\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1535.2067 - val_loss: 1205.2490\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1517.8994 - val_loss: 1192.0521\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1500.7234 - val_loss: 1178.9777\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1483.6792 - val_loss: 1166.0253\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1466.7650 - val_loss: 1153.1943\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1449.9813 - val_loss: 1140.4835\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1433.3268 - val_loss: 1127.8933\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1416.8014 - val_loss: 1115.4222\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1400.4042 - val_loss: 1103.0708\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1384.1350 - val_loss: 1090.8381\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1367.9933 - val_loss: 1078.7231\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1351.9785 - val_loss: 1066.7258\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1336.0900 - val_loss: 1054.8457\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1320.3270 - val_loss: 1043.0818\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1304.6901 - val_loss: 1031.4344\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1289.1776 - val_loss: 1019.9025\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1273.7902 - val_loss: 1008.4858\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1258.5269 - val_loss: 997.1843\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1243.3872 - val_loss: 985.9960\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1228.3700 - val_loss: 974.9221\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1213.4753 - val_loss: 963.9603\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1198.7023 - val_loss: 953.1110\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1184.0509 - val_loss: 942.3745\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1169.5210 - val_loss: 931.7495\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1155.1113 - val_loss: 921.2353\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1140.8217 - val_loss: 910.8312\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1126.6509 - val_loss: 900.5374\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1112.5995 - val_loss: 890.3531\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1098.6667 - val_loss: 880.2782\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 1084.8521 - val_loss: 870.3115\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1071.1550 - val_loss: 860.4532\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1057.5747 - val_loss: 850.7013\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1044.1107 - val_loss: 841.0573\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1030.7631 - val_loss: 831.5193\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1017.5309 - val_loss: 822.0876\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1004.4141 - val_loss: 812.7614\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 991.4117 - val_loss: 803.5398\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 978.5236 - val_loss: 794.4233\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 965.7491 - val_loss: 785.4106\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 953.0878 - val_loss: 776.5010\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 940.5390 - val_loss: 767.6947\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 928.1026 - val_loss: 758.9906\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 915.7773 - val_loss: 750.3883\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 903.5637 - val_loss: 741.8882\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 891.4609 - val_loss: 733.4883\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 879.4680 - val_loss: 725.1893\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 867.5856 - val_loss: 716.9906\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 855.8123 - val_loss: 708.8912\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 844.1479 - val_loss: 700.8906\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 832.5917 - val_loss: 692.9886\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 821.1437 - val_loss: 685.1847\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 809.8031 - val_loss: 677.4781\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 798.5692 - val_loss: 669.8684\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 787.4419 - val_loss: 662.3554\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 776.4204 - val_loss: 654.9382\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 765.5045 - val_loss: 647.6162\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 754.6935 - val_loss: 640.3896\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 743.9874 - val_loss: 633.2573\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 733.3849 - val_loss: 626.2184\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 722.8861 - val_loss: 619.2736\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 712.4904 - val_loss: 612.4213\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 702.1971 - val_loss: 605.6614\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 692.0062 - val_loss: 598.9933\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 681.9169 - val_loss: 592.4172\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 671.9291 - val_loss: 585.9316\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 662.0417 - val_loss: 579.5363\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 652.2548 - val_loss: 573.2310\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 642.5676 - val_loss: 567.0151\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 632.9796 - val_loss: 560.8883\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 623.4906 - val_loss: 554.8493\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 614.0997 - val_loss: 548.8985\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 604.8065 - val_loss: 543.0343\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 595.6107 - val_loss: 537.2573\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 586.5117 - val_loss: 531.5670\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 577.5095 - val_loss: 525.9618\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 568.6027 - val_loss: 520.4424\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 559.7918 - val_loss: 515.0072\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 551.0756 - val_loss: 509.6562\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 542.4536 - val_loss: 504.3889\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 533.9258 - val_loss: 499.2049\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 525.4914 - val_loss: 494.1035\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 517.1497 - val_loss: 489.0837\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 508.9008 - val_loss: 484.1458\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 500.7439 - val_loss: 479.2889\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 492.6783 - val_loss: 474.5122\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 484.7037 - val_loss: 469.8156\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 476.8197 - val_loss: 465.1985\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 469.0256 - val_loss: 460.6602\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 461.3211 - val_loss: 456.2000\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 453.7053 - val_loss: 451.8178\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 446.1784 - val_loss: 447.5126\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 438.7395 - val_loss: 443.2846\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 431.3878 - val_loss: 439.1322\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 424.1232 - val_loss: 435.0556\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 416.9452 - val_loss: 431.0540\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 409.8530 - val_loss: 427.1270\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 402.8463 - val_loss: 423.2739\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 395.9248 - val_loss: 419.4942\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 389.0879 - val_loss: 415.7877\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 382.3351 - val_loss: 412.1533\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 375.6656 - val_loss: 408.5907\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 369.0791 - val_loss: 405.0992\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 362.5752 - val_loss: 401.6785\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 356.1532 - val_loss: 398.3277\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 349.8126 - val_loss: 395.0466\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 343.5530 - val_loss: 391.8344\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 337.3740 - val_loss: 388.6909\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 331.2745 - val_loss: 385.6147\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 325.2543 - val_loss: 382.6058\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 319.3131 - val_loss: 379.6639\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 313.4502 - val_loss: 376.7880\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 307.6653 - val_loss: 373.9778\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 301.9579 - val_loss: 371.2324\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 296.3271 - val_loss: 368.5513\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 290.7724 - val_loss: 365.9343\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 285.2935 - val_loss: 363.3804\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 279.8897 - val_loss: 360.8892\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 274.5607 - val_loss: 358.4601\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 269.3058 - val_loss: 356.0923\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 264.1246 - val_loss: 353.7857\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 259.0165 - val_loss: 351.5393\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 253.9807 - val_loss: 349.3527\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 249.0170 - val_loss: 347.2252\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 244.1247 - val_loss: 345.1562\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 239.3034 - val_loss: 343.1453\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 234.5526 - val_loss: 341.1916\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 229.8716 - val_loss: 339.2949\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 225.2601 - val_loss: 337.4543\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 220.7172 - val_loss: 335.6694\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 216.2427 - val_loss: 333.9393\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 211.8356 - val_loss: 332.2636\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 207.4959 - val_loss: 330.6416\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 203.2225 - val_loss: 329.0730\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 199.0154 - val_loss: 327.5569\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 194.8740 - val_loss: 326.0928\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 190.7974 - val_loss: 324.6800\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 186.7853 - val_loss: 323.3181\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 182.8368 - val_loss: 322.0061\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 178.9518 - val_loss: 320.7437\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 175.1294 - val_loss: 319.5303\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 171.3693 - val_loss: 318.3652\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 167.6707 - val_loss: 317.2476\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 164.0332 - val_loss: 316.1773\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 160.4563 - val_loss: 315.1534\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 156.9395 - val_loss: 314.1754\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 153.4821 - val_loss: 313.2425\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 150.0833 - val_loss: 312.3542\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 146.7429 - val_loss: 311.5099\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 143.4602 - val_loss: 310.7091\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 140.2347 - val_loss: 309.9508\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 137.0656 - val_loss: 309.2346\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 133.9528 - val_loss: 308.5602\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 130.8954 - val_loss: 307.9265\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 127.8929 - val_loss: 307.3330\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 124.9446 - val_loss: 306.7792\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 122.0503 - val_loss: 306.2645\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 119.2092 - val_loss: 305.7880\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 116.4206 - val_loss: 305.3494\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 113.6842 - val_loss: 304.9478\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 110.9993 - val_loss: 304.5828\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 108.3654 - val_loss: 304.2536\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 105.7817 - val_loss: 303.9597\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 103.2479 - val_loss: 303.7004\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 100.7634 - val_loss: 303.4751\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 98.3276 - val_loss: 303.2833\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 95.9398 - val_loss: 303.1241\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 93.5996 - val_loss: 302.9971\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 91.3064 - val_loss: 302.9016\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 89.0595 - val_loss: 302.8370\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 86.8585 - val_loss: 302.8027\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 84.7027 - val_loss: 302.7980\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 82.5916 - val_loss: 302.8224\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 80.5247 - val_loss: 302.8752\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 78.5012 - val_loss: 302.9558\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 76.5207 - val_loss: 303.0636\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 74.5827 - val_loss: 303.1978\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 72.6867 - val_loss: 303.3582\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 70.8319 - val_loss: 303.5438\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 69.0178 - val_loss: 303.7542\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 67.2439 - val_loss: 303.9886\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 65.5095 - val_loss: 304.2467\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 63.8144 - val_loss: 304.5276\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 62.1577 - val_loss: 304.8309\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 60.5392 - val_loss: 305.1558\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 58.9580 - val_loss: 305.5020\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 57.4136 - val_loss: 305.8686\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 55.9055 - val_loss: 306.2552\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 54.4330 - val_loss: 306.6610\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 52.9958 - val_loss: 307.0858\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 51.5932 - val_loss: 307.5286\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 50.2249 - val_loss: 307.9890\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 48.8900 - val_loss: 308.4666\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 47.5880 - val_loss: 308.9605\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 46.3188 - val_loss: 309.4703\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 45.0814 - val_loss: 309.9954\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 43.8755 - val_loss: 310.5352\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 42.7004 - val_loss: 311.0893\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 41.5556 - val_loss: 311.6570\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 40.4407 - val_loss: 312.2378\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 39.3551 - val_loss: 312.8312\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 38.2983 - val_loss: 313.4365\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 37.2699 - val_loss: 314.0532\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 36.2692 - val_loss: 314.6810\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 35.2957 - val_loss: 315.3190\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 34.3490 - val_loss: 315.9670\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 33.4285 - val_loss: 316.6245\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 32.5336 - val_loss: 317.2906\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 31.6642 - val_loss: 317.9651\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 30.8194 - val_loss: 318.6476\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 29.9987 - val_loss: 319.3374\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 29.2019 - val_loss: 320.0340\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.4284 - val_loss: 320.7371\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 27.6775 - val_loss: 321.4460\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 26.9491 - val_loss: 322.1605\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.2425 - val_loss: 322.8797\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 25.5574 - val_loss: 323.6036\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 24.8931 - val_loss: 324.3316\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 24.2492 - val_loss: 325.0631\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 23.6254 - val_loss: 325.7979\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 23.0211 - val_loss: 326.5352\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.4360 - val_loss: 327.2751\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.8696 - val_loss: 328.0167\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.3214 - val_loss: 328.7598\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.7911 - val_loss: 329.5039\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.2781 - val_loss: 330.2488\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.7821 - val_loss: 330.9941\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.3026 - val_loss: 331.7392\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.8393 - val_loss: 332.4838\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.3918 - val_loss: 333.2278\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.9596 - val_loss: 333.9704\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.5423 - val_loss: 334.7116\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.1397 - val_loss: 335.4509\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.7512 - val_loss: 336.1878\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.3765 - val_loss: 336.9225\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0152 - val_loss: 337.6543\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.6670 - val_loss: 338.3826\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.3316 - val_loss: 339.1078\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.0085 - val_loss: 339.8292\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.6973 - val_loss: 340.5465\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 14.3979 - val_loss: 341.2596\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.1098 - val_loss: 341.9679\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.8327 - val_loss: 342.6715\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.5662 - val_loss: 343.3698\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 13.3101 - val_loss: 344.0632\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 13.0640 - val_loss: 344.7507\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 12.8277 - val_loss: 345.4326\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.6008 - val_loss: 346.1085\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.3830 - val_loss: 346.7782\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.1741 - val_loss: 347.4413\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 11.9737 - val_loss: 348.0979\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.7816 - val_loss: 348.7478\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.5975 - val_loss: 349.3909\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 11.4211 - val_loss: 350.0266\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.2522 - val_loss: 350.6554\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.0905 - val_loss: 351.2767\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.9358 - val_loss: 351.8903\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7878 - val_loss: 352.4961\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.6463 - val_loss: 353.0944\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.5111 - val_loss: 353.6846\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3819 - val_loss: 354.2668\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.2586 - val_loss: 354.8406\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 10.1409 - val_loss: 355.4064\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.0285 - val_loss: 355.9638\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.9214 - val_loss: 356.5131\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.8192 - val_loss: 357.0538\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.7218 - val_loss: 357.5861\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.6291 - val_loss: 358.1094\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.5407 - val_loss: 358.6247\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.4567 - val_loss: 359.1310\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.3766 - val_loss: 359.6286\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.3006 - val_loss: 360.1180\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.2282 - val_loss: 360.5983\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.1595 - val_loss: 361.0695\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.0943 - val_loss: 361.5326\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.0323 - val_loss: 361.9868\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.9734 - val_loss: 362.4325\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.9176 - val_loss: 362.8691\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.8647 - val_loss: 363.2971\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.8146 - val_loss: 363.7166\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.7670 - val_loss: 364.1275\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.7220 - val_loss: 364.5298\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.6794 - val_loss: 364.9235\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 8.6391 - val_loss: 365.3084\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 8.6010 - val_loss: 365.6850\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.5650 - val_loss: 366.0533\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.5310 - val_loss: 366.4135\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.4988 - val_loss: 366.7653\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.4684 - val_loss: 367.1088\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.4397 - val_loss: 367.4442\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.4127 - val_loss: 367.7715\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.3872 - val_loss: 368.0910\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.3632 - val_loss: 368.4022\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.3406 - val_loss: 368.7056\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.3193 - val_loss: 369.0015\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.2992 - val_loss: 369.2897\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.2803 - val_loss: 369.5707\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.2626 - val_loss: 369.8441\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.2459 - val_loss: 370.1105\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.2302 - val_loss: 370.3696\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.2154 - val_loss: 370.6214\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.2016 - val_loss: 370.8660\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1886 - val_loss: 371.1038\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1764 - val_loss: 371.3349\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1650 - val_loss: 371.5588\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1544 - val_loss: 371.7769\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1443 - val_loss: 371.9882\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 8.1349 - val_loss: 372.1933\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.1261 - val_loss: 372.3920\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.1179 - val_loss: 372.5852\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1102 - val_loss: 372.7719\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1030 - val_loss: 372.9531\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.0962 - val_loss: 373.1281\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0899 - val_loss: 373.2979\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0840 - val_loss: 373.4620\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0786 - val_loss: 373.6210\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0734 - val_loss: 373.7747\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.0686 - val_loss: 373.9230\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0642 - val_loss: 374.0664\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0600 - val_loss: 374.2050\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.0561 - val_loss: 374.3389\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.0525 - val_loss: 374.4680\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0491 - val_loss: 374.5927\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0460 - val_loss: 374.7125\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0431 - val_loss: 374.8282\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0404 - val_loss: 374.9396\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0378 - val_loss: 375.0469\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0355 - val_loss: 375.1504\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0333 - val_loss: 375.2498\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 8.0313 - val_loss: 375.3463\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0294 - val_loss: 375.4385\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0276 - val_loss: 375.5268\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0260 - val_loss: 375.6119\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0245 - val_loss: 375.6939\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0231 - val_loss: 375.7724\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0219 - val_loss: 375.8479\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0206 - val_loss: 375.9205\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.0195 - val_loss: 375.9900\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0185 - val_loss: 376.0566\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0175 - val_loss: 376.1201\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0167 - val_loss: 376.1819\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0159 - val_loss: 376.2401\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0151 - val_loss: 376.2962\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0144 - val_loss: 376.3495\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0138 - val_loss: 376.4008\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0132 - val_loss: 376.4497\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0127 - val_loss: 376.4964\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0122 - val_loss: 376.5408\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0118 - val_loss: 376.5839\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 8.0114 - val_loss: 376.6247\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0110 - val_loss: 376.6639\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 365ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73.90445845, 73.89045285, 73.87644725, 73.86244164, 73.84843604,\n",
       "        73.83443044, 73.82042484, 73.80641923, 73.78027544, 73.74386088,\n",
       "        73.70744631, 73.67103175, 73.63461718, 73.59820261, 73.56178805,\n",
       "        73.52537348, 73.48895892, 73.45254435, 73.41612979, 73.37971522,\n",
       "        73.34330065, 73.30688609, 73.27047152, 73.23405696, 73.19764239,\n",
       "        73.16122782, 73.12481326, 73.08839869, 73.05198413, 73.01556956,\n",
       "        72.979155  , 72.94274043, 72.90632586, 72.8699113 , 72.83349673,\n",
       "        72.79708217, 72.7606676 , 72.72425303, 72.68783847, 72.6514239 ,\n",
       "        72.61500934, 72.57859477, 72.54218021, 72.50576564, 72.48349673,\n",
       "        72.46388889, 72.44428105, 75.45677404, 75.37778245, 75.29879085,\n",
       "        75.21979925, 75.14080766, 75.06181606, 74.98282446, 74.90383287,\n",
       "        74.82484127, 74.74584967, 74.66685808, 74.58786648, 74.54585901,\n",
       "        74.52401027, 74.50216153, 74.48031279, 74.45846405, 74.43661531,\n",
       "        74.41476657, 74.39291783, 74.37106909, 74.34922035, 74.32737162,\n",
       "        74.30552288, 74.26860411, 74.2265873 , 78.96292114,  1.20782113,\n",
       "         0.15123923,  0.71398759,  0.        ,  0.17827012,  0.        ,\n",
       "        64.220047  ,  0.        ,  0.        ,  0.45041683,  0.63506269,\n",
       "         0.59586149,  0.1360459 ,  0.        ,  0.24405147,  0.5005756 ,\n",
       "         0.12205936,  0.        ,  0.23546176,  0.        ,  0.73992312,\n",
       "         0.        ,  0.29736304,  0.        ,  0.        ,  0.12922123]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71.25497199, 71.25030345, 71.24563492, 71.24096639, 71.23629785,\n",
       "       71.23162932, 71.22696078, 71.22229225, 71.21762372, 71.21295518,\n",
       "       71.20828665, 71.20361811, 71.19831933, 71.19084967, 71.18338002,\n",
       "       71.17591036, 71.16844071, 71.16097106, 71.1535014 , 71.14603175,\n",
       "       71.13856209, 71.13109244, 71.12362278, 71.11615313, 71.10868347,\n",
       "       71.10121382, 71.09374416, 71.08627451, 71.07880486, 71.0713352 ,\n",
       "       71.06386555, 71.05639589, 71.04892624, 71.04145658, 71.03398693,\n",
       "       71.02651727, 71.01904762, 71.01157796, 71.00410831, 70.99663866,\n",
       "       70.989169  , 70.98169935, 70.97422969, 70.96676004, 70.95929038,\n",
       "       70.95182073, 70.94435107, 70.93688142, 70.92941176, 70.92194211,\n",
       "       70.91447246, 70.9070028 , 70.89953315, 70.89206349, 70.88459384,\n",
       "       70.87712418, 70.86965453, 70.86218487, 70.85471522, 70.84724556,\n",
       "       70.83977591, 70.83230626, 70.8248366 , 70.81736695, 70.80989729,\n",
       "       70.80242764, 70.79495798, 70.78748833, 70.78001867, 70.77254902,\n",
       "       70.76507937, 70.75760971, 70.75014006, 70.7426704 , 70.73520075,\n",
       "       70.72773109, 70.72026144, 70.71279178, 70.70532213, 70.69785247,\n",
       "       70.69038282, 70.68291317, 70.67544351, 70.66797386, 70.6605042 ,\n",
       "       70.65303455, 70.64556489, 70.63809524, 70.63062558, 70.62315593,\n",
       "       70.61568627, 70.60821662, 70.60074697, 70.59327731, 70.58580766,\n",
       "       70.578338  , 70.57086835, 70.56339869, 70.55592904, 70.54845938])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.29449926346448\n",
      "19.734261158044465\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
