{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "2095    69.495530\n",
       "2096    69.490394\n",
       "2097    69.485259\n",
       "2098    69.480124\n",
       "2099    69.474988\n",
       "Name: C3, Length: 2100, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_2000_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "1995     0.000000\n",
       "1996     0.424089\n",
       "1997     0.489865\n",
       "1998     0.000000\n",
       "1999     0.000000\n",
       "Name: C3, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2000)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAknElEQVR4nO3de3gcV53m8e9P97tkWbJs+RLbiXOxA8GJgwMJmSEJIQRCwi5kwi0Gwnp5uAwwuzubWZ4dmH1mWRhgWBiyZMIkwbCBwGRgExaG3AiBsIkTOXEuthN8T2xLlnyRZOti3c7+0dVSq6WWVV3dXdWt9/M8erq7uqrrdEl669SpU6fMOYeIiBSWorALICIimadwFxEpQAp3EZECpHAXESlACncRkQJUEnYBAJqamtzy5cvDLoaISF7ZsmXLEedc83TvRSLcly9fTltbW9jFEBHJK2a2P9V7p22WMbO7zKzTzF5KmNZoZg+b2U7vcZ433czs22a2y8xeMLMLM/MVRETEj9m0uX8fuCZp2q3Ao865VcCj3muAdwCrvJ+NwHczU0wREfHjtOHunPsdcCxp8vXAJu/5JuCGhOk/cDFPAQ1mtihDZRURkVlKt7dMi3Ou3XveAbR4zxcDryXMd8CbNoWZbTSzNjNr6+rqSrMYIiIyncBdIV1scBrfA9Q45+5wzq1zzq1rbp72ZK+IiKQp3XA/HG9u8R47vekHgaUJ8y3xpomISA6lG+4PABu85xuA+xOm3+z1mrkE6ElovhERkRyZTVfIHwNPAueY2QEzuwX4CvA2M9sJXOW9BvgVsAfYBXwP+GRWSi0iEnFdJ07x65c6Qlv/aS9ics69P8VbV04zrwM+FbRQIiL5bsNdT7O9vZdtf/N2qstzf72oxpYREcmC1471AzAa0g2RFO4iIgVI4S4ikgVh38BU4S4ikkUW0noV7iIiWRRWDV7hLiKSBWHV2OMU7iIiWaA2dxGRAqY2dxERyRiFu4hIAVK4i4gUoLwO9x3tvdz22K6wiyEiEjl5He5P7j7K1x58hZ2HT4RdFBGRSVxIY8rE5XW4X3dBK8VFxs+f0/1AREQS5XW4N9eWc9lZTdy/9RBjY2H3KhURiY68DneA96xdzMHuAZ7ZdyzsooiIjDML9xrVvA/3q9e0UFNewt/+cgc9A8NhF0dEBFCbe2BVZSV866Y38HJHLzffuVkBLyKRElYNPu/DHeDK81r47gcvYnt7Lzff9fT4HVBEROaqggh3gKtWt3DbBy5kR3svf/r13/K5e59jR3tv2MUSEQlFwYQ7wNVrFvK7//RWPnbpch7efph3fOv3fPTup3l677HQ279ERHIp97fkzrKF9RV84Z2r+fRbV/HDp/Zx9x/2ceM/PklrfQXNdRU0VZfRVFPO/JoyWuoquPSsJs5aUBN2sUVEMqrgwj2uvqqUT1+xilsuW8l9zx7guf3HOdI3RHvPIC8e7OFo3xCjXt/4sxbU8PY1LVyzZhHnL64LvQuTiEhQBRvucZVlxXz4kjP48CVnTJo+NuY41DPAozs6eXBbB7c/vofbHtvN4oZKrl7TwttWt3DhsnlUlBaHVHIRyWdhNwQXfLinUlRkLJlXxYY3L2fDm5dzvG+IR3Yc5sFtHdyz+VXu/sM+ykqKWLu0gUtWzueSlfNZu6xBYS8ieWHOhnuyedVlvG/dUt63bil9p0Z4cvdRNu89ylN7jvEPv9nJtx7dqbAXkVkLu3FX4T6N6vISrlrdwlWrWwDoGRimbd8xntozNezfsKSBsxfWsHx+deynqZqljZWUlyj0ReYyNcvkgfrKUq48r4Urz5sa9s/sO84DWw/ROzgyPn+RQWtDpRf2VQnBX8XSxioFv4hkncI9Dclh75yju3+YvUf72H+0j71H+tl/tI99R/qmBL8ZtNZXsqJpcvAvbaxiYV0FdZUl6q0jIoEp3DPAzJhXXca86jIuXDZvyvvH+4bYd7Qv9nOk33vezy+eb58yFk5laTEL6ytoqStnYV0FC+srWVhX7k2rYFF9JU01ZZQUF9T1ZyIFK6wLKBXuORAP/rXTBH93/xB7j/Rx4PgAh3sH6egZpL13kMM9g7TtP87h3naGRyf/cRRZbCz7hXWxwD93UR3rVzSydlkDVWX6lYqIwj10DVVlrF02ffBDrD/+sf4hOnoGOdw7SLv32NEzSEfvILu7TvLIjsN820FJkfG6JfWsXzGf9SsauWj5POoqSnP8jUQkCgKFu5l9Hvg4sRPDLwIfBRYB9wLzgS3Ah51zQwHLOWcVFRlNNeU01ZRz/uL6aefpHRxmy/7jPL33GE/vPcadT+zh9sd3YwarF9XxxhWNrF/RyMXLG5lfU57jbyAiYUg73M1sMfDnwGrn3ICZ/RS4CbgW+KZz7l4zux24BfhuRkor06qrKOWt5yzgrecsAGBgaJTnXouF/eY9x/iRd1EWxIZaWL+i0Qv8+Sysrwix5CKFK+yxCoM2y5QAlWY2DFQB7cAVwAe89zcBX0LhnlOVZcW8+cwm3nxmEwBDI2O8eLCbzV7N/v6th7hn86sALGus4uyWWuorSxN+SqivKp00rc57VDdOEX/Cyvi0w905d9DMvg68CgwADxFrhul2zsX7/h0AFk+3vJltBDYCLFu2LN1iyCyUlRRx0RmNXHRGI5/8Uxgdc+xo7/XC/iivHhtg+6EeegaG6RsanfGzKkqLknYEE8Gf8qeqlHlVZZSqh4/MIWH3aA7SLDMPuB5YAXQD/wxcM9vlnXN3AHcArFu3LuyLueaU4iLj/MX1nL+4nlsuWzHpveHRMXoHhulJ+pluWs/AMAe7B9nRfoKegWFOnhpJscaY+spS5teU0VQdG3K5sbqM+TXlNNWUMd+btqC2nNaGSg3rMEf8+Y+fY/3KRj64/ozTz5yk79QIw6NjNFSVZaFk03vtWD8f+/4z/OjfXUJzrf/zV4d7B2mszk1FJ0izzFXAXudcF4CZ/Qy4FGgwsxKv9r4EOBi8mJIrpcVFzK8pT+vE68joGL2DI1N3Av1DHOsb5mjfKY6eHOLIyVPs6jzJ0b4hjvcPTds22VRTxuKGSlobKice58WeL26opKGqVBd7FYAHnj/EA88fSivc3/J3j3Gsb4h9X3mn72X3HenjZ88d5PNXrfL1d3TnE3vZ2XmSXzx/iI8lVYySJf9dnxgcZv2XH+WD65fx39/zOt9l9itIuL8KXGJmVcSaZa4E2oDHgPcS6zGzAbg/aCElP5QUF9FYHauRz9bI6BjH+4c51hcL/cO9gxw8PsChngEOHB/gj4dP8NgrnQwOj01arqqseFLwL5lXyTkttaxZXMfCugoF/xxwrC/9Tngfuftp9h3t56aLl9LaUDnr5eL3gCgp9v/3Fb9S/bGXO30vm44gbe6bzew+4FlgBHiOWDPLL4F7zexvvWl3ZqKgUphKiotori2nubacc6iddh7nHMf7hzl4fICD3bGfQ90D4zuBl7ybr8Q1VpexprWO1a11nN9az5rWOpbPr6aoSIEvMf3euaUin5WAES/ci338LcVr8KPexYjFaewY0hGot4xz7ovAF5Mm7wHeGORzRRKZ2fgRweuWTN/Xv+/UCC939LLtUC/bDvayrb2Hu57YO351b3VZMectqmNNax1rFscCf9WCWspKdJJ3LhrzErfI569/dCx2BFmcxpHhiLdsid+VpklXqEpBqC4vGe8RFDc0MsbOzhNsO9TL9kO9vHSwh/u2HGDTk/sBKCsuYlVLTSzwW+s5Y35VbAyf2gq16Re4ePOK35Ae9VoH/dTck9eZqwNIhbsUrLKSIta01rOmdaK2Pzbm2He0j22HennpUA/bD/XyyI5Oftp2YNKy5SVFtNRVxMbvqa+gpXZi8Lb4DmBBXbl69eQpL2d9h3S85p5Om/uod7SgmrtIFhQVGSuba1jZXMN1F7QCsTb9w72nONjdT0fPKTp6Y+P3xMfwefFANw/3Dk45qQswr6qUFm8At/iOIDaaZzkLamM7gsaqsjnR3j8yOsbGH26hvrKUt69p4fKzm2ccyC6s0RIhtpMHsNPcL6m7f4i/vn8bn7niLFa11DI83uY+OaB7+ofZ+MM2PnPFKi5bFbt40CVdvjQy6r+9PgiFu8x5ZsbC+ooZh2JwztE7ODJp0LbO3thjR0+sl8+O9l66Tp6a0gWurLiIBXXlLBoftnli+OaF9eUsrK9kQW153l/k1T0wzG9e7qTI4OfPHaS8pIi3rGrm6jUtXHVey5ReVGNJ22lsLBaHuQi/keSVp7Cj/QQPPH+I/7f7KPduXD9xUjSpOWff0T427z3G1k3P8L2b13H52c0Tb8ZPqKZxMjYIhbvILJjZ+BW3Z7dM36sHYrXXrpOnvFE8T9HRM0BH7ylvRM9Yz55HdhyechRgBvOry6guL6GipJiKsmIqS4uoLC2msqw4YVrsp6K0iArvvYlpxePTqsqKafCuDs7VkBFDI7Hv9N+uP5+VzdU8tO0wD23r4JEdhykyOHdhndd9tYJFDbEdWqINdz/N73ce4dyFtbQ2VNLaENsBxh/PWlBDU4rrL/Z0neT3O4+wbH5sOI3W+pm7w47O8qhhyGtk7xkY4r23P0l3f+z+C8kBPezNV1ZcxMd/0MYNb2gd/x1f950nuOWyFSxrrALI2VGcwl0kg0qKi1hUX8mi+tR9p51z9AwM094Tr/nHhnLuOjFI/9AoA0OjDI6MMTg0ypGTQwwOjzIwPBp7HIo9n2XFE4jdAKa+spQGb7ygiceyya8ry1jUUMGyxqq0jiLiAVdZOjG20RevW822Q708uK2Dlw72cOB4P0/vPTrp7mRxuzpPArFbVB7qHmDL/uNTbmbTWl/B65c0TOk1dcfv9nDvM6+Nv26qKeP1Sxp4/ZJ6LljawJvPnD9pJxdvEnI4OnsHuesP+zh3YS1XnLdg0jDZw94O6+vvu4BfvtDOQ9sPA7HrLBLFdwJfe9/reXh7J796sWP8vVeP9fPFB7aNv85RT0iFu0iumRkNVWU0VJVx3qI638s75xgedQwMj3LKC/4BL/gHh8cYHB7l5KmJK4W7+4e8x2G6B4bZd6Q/9npgaNrzCCVFxhnzq1jZXMOZzTWc2VzNmQtqOLOphvqq1PcHGK+9JnQvNZsY6iLRyVMjtHcP8LZv/m783EdlaTHXXdDKP7x/7fh8/UMjHOqOHfW80nGCFw708MKBbn69rWPS542MORbUlnPbBy9kR3svz78Wm++xVzpxDhbUlnPLZSv4wPpl1FaUjjeRAPzm5U5uf3w3ALXlJXzoTWfw0UuXs6C2Yvw7nbOwluvfsJhfv9TOJ/73s1PD3dsJNNdW8I0bL+CmfUt53+1PAvDxy1bwngsX8+9/uIUDxweoLMvNkZTCXSTPmBllJRYL0cpgN2MZHB6dCP7+IQ4cH2DPkZPs7uxjd9dJfvtK56Q7gTXVlLOyuXpS6J/VXENrQyVDI7H5ZlPrrykvYZXXfFIxw7UGVWUlnLWghrMW1PCWVRPt2D39w7zxy49wamRi51RaXMTFy2P3LeBNsWknBod5Zt8x7nxiL//jX1/mO4/t4uY3nTHpyCf+9PYPXcQvXjjEPz6+mzuf2Mt7L1rCorrYeZgy7ztVl0+OTOcc/2frQbpOnJo0X3LLy5rWeh783OWs+eKDXHpW02m3TyYo3EXmsHg7fYsXYuuT3h8ZHeO14wPs7jzJ7q74Tx+/enHy/X/LS2InjQHKSvy1O7ikx9moryrlbatb2H6od8b5aitKueLcFq44t4XnX+vm9sd3879+u3vaedcua+Ca8xey70gfd/x+D/e1HRhvbkneYcXLuudIH5//yfPj02e6KC5+CsDvVbHpUriLSEolxUWsaKpmRVM1V9EyPt05x7G+IfYc6UsI/j4aq8s5Z+Hsm5qST3r6ib3EZWdzfvSCpQ1890MXsbvrJFd+4/Hx5ZKXXd5UzZff8zo+d+Uq7vrDPl7u6B3fcSV3nYx3b/yTs5spLrLxk6bTfZPTdbvMNIW7iPhmZuOjh168vPH0C0TImc01fOm61XzpF9tnnG9BXQW3vuPcWX3mn128lGtft2j8dRQubs7vjrUiIp4oBGqUKNxFJFTxZpF0rlidaK8PfrWrn33DeJlTrHemz8rVhbkKdxGJDD+170xU1B3+dgxBjg5yfWShcBeROSfTI34mf1oURhRVuItIQQicp2ksH+LYZ6elcBeRUMWbRdLJSTfR+J1Tpzs/MGObe44Kq3AXkdAk17b99XMPvn7nnK/ad6pVzlSWsFpoFO4iUhD8XCSU7cCNQJO7wl1EBNK7gnQ2tf6w2uUV7iISrvF+7oE/ImdOt75cDzUwHYW7iIRmSpu7z/aMoKHu/H5GyuKlLnfyV9JFTCIiM5jatzz9ZTNturLoIiYRkRCkE7656taYDoW7iIQqE+PDpDMuTRBRvngpTuEuIqFJPvHot/IcNGSd8/ch8fK+/3tP8fxr3RPTwz9/OoXCXUTyUpAbfWQijX/27AFfH5/rHjQKdxGJhLCbOtKJ3rDLPBOFu4iEalJ7eZqV26hlrPq5i8icFrR1JGhvFefzE1KV19+NPjRwmIhISkHGUFc/99MwswYzu8/MXjazHWb2JjNrNLOHzWyn9zgvU4UVkcIVdvt1FG6wkUlBa+7fAn7tnDsXuADYAdwKPOqcWwU86r0WEZlWYqan21YdtR1D4suwdhpph7uZ1QOXA3cCOOeGnHPdwPXAJm+2TcANwYooIoUqaOwFDnXn7zMyct/WPBhbZgXQBdxtZs+Z2T+ZWTXQ4pxr9+bpAFqmW9jMNppZm5m1dXV1BSiGiMxJId/oA1IHdeIRSPwEaq7r70HCvQS4EPiuc24t0EdSE4yLfatpv75z7g7n3Drn3Lrm5uYAxRARCa6wWtyDhfsB4IBzbrP3+j5iYX/YzBYBeI+dwYooIoVsUjf3EPq5Z6Jr4kwjVOZdm7tzrgN4zczO8SZdCWwHHgA2eNM2APcHKqGIFKygwRd4bBmf82ciqHN17rck4PKfAe4xszJgD/BRYjuMn5rZLcB+4MaA6xARmWJKzxpf47lnpjad6hKo6T491zX4QOHunNsKrJvmrSuDfK6IzD25HrY3WYF1c9cVqiISrsn93NP8jAA7hkzsUqbeLjADHxqQwl1EQhN2BvrdJ2QitPOhn7uISGim1JYDLJuu1EE9dQX51M9dRCRjAnVnzMD6ozBMbyYp3EUkVInt5WG0VWeimURt7iIiiYKO5x4wmf2OBz/b4s40X9Ax6GdL4S4ieSkK47ln4kYf2aJwF5FICFQJz0yje4BFk4f8Tf1h33p0Jy8e6El/ZbOkcBeRUGViPPdMrT8bkr+Rc3Ddd57I8loV7iKSxwIP5x6wn3uqNv/E2cK67lbhLiKhCVJPj0I/dz9yPbaMwl1EIiFIL5JM9EAJlL3qCikiklo4/dyz23ASVs4r3EUkXAGyNdfjuSdHdarlo3C1q8JdREITpB16avfD9JfNJp1QFZE5LUgtPCNDCGRwWbW5i4gkiEIoZpra3EVkTgq7l4wfU/u553T1vijcRSQ0QS72mdrP3X8dOde39svlkYnCXUQiJL30853RCauJLxvo5K7N7uRuLvclCncRkQKkcBeRUIXdS8aPqRXyFGPLRODMsMJdREJj0zSPpLPsdK9nI3GdmewKGQUKdxGJjHQrvEHuqJSNHjeW8kXuKNxFRNI0q6ONkLpLKtxFJFSB2twzV4xZmW1begSa3BXuIhIeC9bTPZNFCRTIUQjzZAp3EYmMdDPS/8nYiTVlo8fNpJ2W2txFRPJLhEcfULiLSLhyPT5MELOthFuQ1qYMUbiLSGiC9HNPXMaR3oVDk/u5Z25s+ShQuItIZPi64UaQE6AJz7NRsS6Ifu5mVmxmz5nZ//VerzCzzWa2y8x+YmZlwYspIhI9hT7k72eBHQmvvwp80zl3FnAcuCUD6xCRAhXlgEw266OFCLTSBAp3M1sCvBP4J++1AVcA93mzbAJuCLIOEZkb0sv42FLOpZeniSdz1c99sv8J/CUw5r2eD3Q750a81weAxdMtaGYbzazNzNq6uroCFkNECoGfE5OBBvoKeCL3tJ8fgap72uFuZu8COp1zW9JZ3jl3h3NunXNuXXNzc7rFEBEJTa7v5ORHSYBlLwXebWbXAhVAHfAtoMHMSrza+xLgYPBiikihim48TpWqRp48NQrNNGnX3J1zf+WcW+KcWw7cBPzGOfdB4DHgvd5sG4D7A5dSRArS5GEA/Mf8xCIu8HjuhSYb/dz/M/AXZraLWBv8nVlYh4gUoJz1c09sc8/2eO4hCdIsM84591vgt97zPcAbM/G5IiJRFuWKv65QFZFQ5VPTSMqjhSm3/Au/7q5wF5HQBB0GIL6Mc2neQ5WJnUsm8zj8aFe4i0iE+AnFKAz0NZujjrD6vCvcRUQyLNsnbGdD4S4iIctM+IV5VWgUrkhNpnAXkdAEH8/dG1smzfUn9q3PZEBHIewV7iISGX56mURhoK/ZNLmozV1EpFCEX3FXuItIuMZvlReww3suupanWkcEurVPoXAXkdAEDcWJfu7pjwYfXzaj/dwjEPYKdxHJSxHIz0iPP6BwFxEJaMqQv6GUYjKFu4iEyiU9pisXgRqFLo6zpXAXkdAkh6Xfturxk7Fprt+5hLFl0vyM6SR26Qyr/V3hLiJ5KcjIi5katXE2O5WwRr1UuIuIBJS8s4hC443CXUSiIUAN1zly0v4RhS6Os6VwF5FQBRnfJeiFT4kDCKTTVJNq9YkfpTZ3EZlzwgq+PKqAp03hLiISUPJOKvEIRCdURWROC5KBjhz1c8+jKr/CXURClRjqvvu5B113wH7uqYb8VZu7iMxpQXIvCuO5R5nCXUQkoCjuKxTuIhIJQbo1OufSro2HdQPrbFO4i0ioEjPddz4HzGW/7f3J/fBn0889LAp3EQlPkPFhAjSGZHp0xyiEeTKFu4hIhkVhaGCFu4hEQljjuY93hYxi9TsAhbuIhCrsfu5+JJcv1eJR2E8o3EUkNIXTzz0CaZ4k7XA3s6Vm9piZbTezbWb2WW96o5k9bGY7vcd5mSuuiEj0RSHqg9TcR4D/4JxbDVwCfMrMVgO3Ao8651YBj3qvRURmFGSALefSbzMvzF7uAcLdOdfunHvWe34C2AEsBq4HNnmzbQJuCFhGESlgk8Zzz3Fjtd8LmJJLl+rCq0n3UPVbqAzJSJu7mS0H1gKbgRbnXLv3VgfQkmKZjWbWZmZtXV1dmSiGiOSZoFme7lWtmQ7cmb5HWEcGgcPdzGqAfwE+55zrTXzPxbb8tN/NOXeHc26dc25dc3Nz0GKIyBwThXbtVKJQtkDhbmalxIL9Hufcz7zJh81skff+IqAzWBFFZC4IMsaLw6UfqIHGpZleXneFtFij0p3ADufc3ye89QCwwXu+Abg//eKJyFyS60wM2s99Vsv4XyQjSgIseynwYeBFM9vqTfsvwFeAn5rZLcB+4MZAJRSRghU0+NKt62e6Zp38cVG42jXtcHfOPUHq382V6X6uiMhsRCA/ZyVvT6iKiGRC8H7uaS5LgCOICHeSV7iLSKgmhXrka+PTF3CmZpi87ucuIpKOoG3TQWr7mVg+yhTuIhIJfnM22I4h8ocIgSncRSQy0r3JhXMBl017XJroVv0V7iISqigHZLJU+4AoHgco3EUkNMH7uQfbMeTTjsUvhbuIRIPfq0UnLepzdMcoVrUzTOEuIpERxjnSIOPSzKa3TVg7EoW7iIQqn7ojpsrpGYf8Den7KdxFJDTBx3MPd/koU7iLSCT4PrmZsGPwPbpj4noDDnsQVQp3EYmMsC5Lyma7uNrcRWROinLtN1mqi53SvYAqmxTuIhKaoKGYD/sFnVAVkTnNf7v5xI4hyLg0QbI3yjsXhbuIREaQ9ulAywY8gphp3WpzF5E5KZ+GAIhey3pqCncRCU9YN1GNL54/+xXfFO4iEgn+283TXzhz/dyju3dQuItIZARp+w7Ubp5P7S2zpHAXkVBFuPI7RT6NJqlwF5G8pfHcU1O4i0hoJrd9+xyTPXHZAOO5Bwn4KO8aFO4iEhnh9XMPJorNNQp3EZFZiuIYMqko3EUkVIEu/1c/95QU7iISmslt3wGW9dvPPUAf+URR3jko3EUkMsIakz1om/lMzTVhNeUo3EVEZimdnUBY3S0V7iISriDNIuGtOmOfkC0lYRdAROau0THH/qP9QPDx3P00fwQZC37az4tgJ5qs1NzN7Boze8XMdpnZrdlYh4jkv2f2HafzxCnef8dTsQk+UvLE4DCjY46D3QNs2X887TIc6xua9bxFRRPlGxp1bDvUe9plwmpzz3jN3cyKgduAtwEHgGfM7AHn3PZMr0tECsOTe476XmbTk/sBuPQrvwFiRwF+3XDbH3zNX1cxEZk/fvpV3+tL9P0/7KVt/3G+ceMFlJcUB/qs6WSjWeaNwC7n3B4AM7sXuB5QuIvIzAL0LewfGpn1vKXF6TVa1JRPH5klRalr5+Ul06/rS7+IReL5i+v5xJ+cmVZ5ZpKNZpnFwGsJrw940yYxs41m1mZmbV1dXVkohohE3d0fuXj8+SUrG3n7+QtnvezPP/lmAF6/pB7AV0BevGIerfUV46+vOq9lVsuZGRvedMakaRcsqefM5pop8268fCXzq8v4s4uXjk/7r+9aPf68zNvBrF5UN+ty+2GZHmzezN4LXOOc+7j3+sPAeufcp1Mts27dOtfW1pbRcoiIFDoz2+KcWzfde9mouR8Elia8XuJNExGRHMlGuD8DrDKzFWZWBtwEPJCF9YiISAoZP6HqnBsxs08DDwLFwF3OuW2ZXo+IiKSWlYuYnHO/An6Vjc8WEZHT0/ADIiIFSOEuIlKAFO4iIgVI4S4iUoAyfhFTWoUw6wL2p7l4E3Akg8XJFJXLn6iWC6JbNpXLn0Is1xnOuebp3ohEuAdhZm2prtAKk8rlT1TLBdEtm8rlz1wrl5plREQKkMJdRKQAFUK43xF2AVJQufyJarkgumVTufyZU+XK+zZ3ERGZqhBq7iIikkThLiJSgPI63MO8EbeZLTWzx8xsu5ltM7PPetO/ZGYHzWyr93NtwjJ/5ZX1FTN7exbLts/MXvTW3+ZNazSzh81sp/c4z5tuZvZtr1wvmNmFWSrTOQnbZKuZ9ZrZ58LYXmZ2l5l1mtlLCdN8bx8z2+DNv9PMNmSpXF8zs5e9df/czBq86cvNbCBhu92esMxF3u9/l1f2QHdoTlEu37+3TP+/pijXTxLKtM/MtnrTc7m9UmVDbv/GnHN5+UNsOOHdwEqgDHgeWJ3D9S8CLvSe1wJ/BFYDXwL+4zTzr/bKWA6s8MpenKWy7QOakqb9HXCr9/xW4Kve82uBfwUMuATYnKPfXQdwRhjbC7gcuBB4Kd3tAzQCe7zHed7zeVko19VAiff8qwnlWp44X9LnPO2V1byyvyML5fL1e8vG/+t05Up6/xvAX4ewvVJlQ07/xvK55j5+I27n3BAQvxF3Tjjn2p1zz3rPTwA7mOZesQmuB+51zp1yzu0FdhH7DrlyPbDJe74JuCFh+g9czFNAg5ktynJZrgR2O+dmuio5a9vLOfc74Ng06/Ozfd4OPOycO+acOw48DFyT6XI55x5yzsXv/PwUsTubpeSVrc4595SLJcQPEr5Lxso1g1S/t4z/v85ULq/2fSPw45k+I0vbK1U25PRvLJ/DfVY34s4FM1sOrAU2e5M+7R1e3RU/9CK35XXAQ2a2xcw2etNanHPt3vMOIH5H4DC2401M/qcLe3uB/+0Txnb7GLEaXtwKM3vOzB43s7d40xZ7ZclFufz83nK9vd4CHHbO7UyYlvPtlZQNOf0by+dwjwQzqwH+Bficc64X+C5wJvAGoJ3YoWGuXeacuxB4B/ApM7s88U2vhhJKH1iL3Xrx3cA/e5OisL0mCXP7pGJmXwBGgHu8Se3AMufcWuAvgB+ZWV0OixS531uS9zO5ApHz7TVNNozLxd9YPod76DfiNrNSYr+8e5xzPwNwzh12zo0658aA7zHRlJCz8jrnDnqPncDPvTIcjje3eI+duS6X5x3As865w14ZQ99eHr/bJ2flM7OPAO8CPuiFAl6zx1Hv+RZi7dlne2VIbLrJSrnS+L3lcnuVAP8G+ElCeXO6vabLBnL8N5bP4R7qjbi9Nr07gR3Oub9PmJ7YXv0eIH4m/wHgJjMrN7MVwCpiJ3IyXa5qM6uNPyd2Qu4lb/3xs+0bgPsTynWzd8b+EqAn4dAxGybVqMLeXgn8bp8HgavNbJ7XJHG1Ny2jzOwa4C+Bdzvn+hOmN5tZsfd8JbHts8crW6+ZXeL9jd6c8F0yWS6/v7dc/r9eBbzsnBtvbsnl9kqVDeT6byzIWeGwf4idZf4jsb3wF3K87suIHVa9AGz1fq4Ffgi86E1/AFiUsMwXvLK+QsAz8jOUayWxngjPA9vi2wWYDzwK7AQeARq96Qbc5pXrRWBdFrdZNXAUqE+YlvPtRWzn0g4ME2vHvCWd7UOsDXyX9/PRLJVrF7F21/jf2O3evP/W+/1uBZ4Frkv4nHXEwnY38B28K9EzXC7fv7dM/79OVy5v+veBTyTNm8vtlSobcvo3puEHREQKUD43y4iISAoKdxGRAqRwFxEpQAp3EZECpHAXESlACncRkQKkcBcRKUD/H8d6bkvdoFmNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1550, 1, 251) (1550, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 28ms/step - loss: 5805.8081 - val_loss: 4279.4131\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5696.6289 - val_loss: 4222.2397\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5616.1646 - val_loss: 4165.7539\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5536.4902 - val_loss: 4109.9673\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5457.6777 - val_loss: 4054.8601\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5379.7197 - val_loss: 4000.4185\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5302.6050 - val_loss: 3946.6343\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5226.3237 - val_loss: 3893.4983\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5150.8667 - val_loss: 3841.0051\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5076.2280 - val_loss: 3789.1484\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5002.3994 - val_loss: 3737.9221\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4929.3716 - val_loss: 3687.3210\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4857.1426 - val_loss: 3637.3384\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4785.7017 - val_loss: 3587.9697\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4715.0449 - val_loss: 3539.2100\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4645.1636 - val_loss: 3491.0540\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4576.0542 - val_loss: 3443.4958\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 4507.7095 - val_loss: 3396.5315\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4440.1206 - val_loss: 3350.1550\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4373.2842 - val_loss: 3304.3621\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4307.1948 - val_loss: 3259.1475\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 4241.8438 - val_loss: 3214.5063\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4177.2275 - val_loss: 3170.4338\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4113.3394 - val_loss: 3126.9253\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4050.1731 - val_loss: 3083.9763\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3987.7217 - val_loss: 3041.5818\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3925.9834 - val_loss: 2999.7371\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3864.9480 - val_loss: 2958.4380\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3804.6128 - val_loss: 2917.6790\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3744.9714 - val_loss: 2877.4568\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3686.0178 - val_loss: 2837.7661\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3627.7458 - val_loss: 2798.6023\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3570.1528 - val_loss: 2759.9617\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3513.2297 - val_loss: 2721.8386\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3456.9739 - val_loss: 2684.2307\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 3401.3779 - val_loss: 2647.1316\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3346.4385 - val_loss: 2610.5383\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3292.1489 - val_loss: 2574.4460\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3238.5049 - val_loss: 2538.8503\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3185.5007 - val_loss: 2503.7476\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3133.1316 - val_loss: 2469.1335\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3081.3918 - val_loss: 2435.0037\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3030.2773 - val_loss: 2401.3540\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2979.7817 - val_loss: 2368.1804\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2929.9009 - val_loss: 2335.4790\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2880.6299 - val_loss: 2303.2456\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2831.9631 - val_loss: 2271.4763\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2783.8967 - val_loss: 2240.1665\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2736.4250 - val_loss: 2209.3130\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2689.5439 - val_loss: 2178.9119\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2643.2476 - val_loss: 2148.9585\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2597.5320 - val_loss: 2119.4497\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2552.3928 - val_loss: 2090.3813\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2507.8242 - val_loss: 2061.7495\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2463.8228 - val_loss: 2033.5510\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2420.3828 - val_loss: 2005.7815\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 2377.5000 - val_loss: 1978.4375\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2335.1707 - val_loss: 1951.5139\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2293.3892 - val_loss: 1925.0090\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2252.1511 - val_loss: 1898.9181\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2211.4521 - val_loss: 1873.2375\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2171.2888 - val_loss: 1847.9639\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2131.6550 - val_loss: 1823.0935\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2092.5474 - val_loss: 1798.6219\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2053.9609 - val_loss: 1774.5466\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2015.8917 - val_loss: 1750.8635\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1978.3353 - val_loss: 1727.5692\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1941.2877 - val_loss: 1704.6600\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1904.7439 - val_loss: 1682.1326\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1868.7000 - val_loss: 1659.9832\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1833.1520 - val_loss: 1638.2090\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1798.0966 - val_loss: 1616.8059\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1763.5282 - val_loss: 1595.7705\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1729.4425 - val_loss: 1575.0991\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1695.8357 - val_loss: 1554.7880\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1662.7039 - val_loss: 1534.8351\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1630.0427 - val_loss: 1515.2361\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1597.8486 - val_loss: 1495.9875\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1566.1172 - val_loss: 1477.0865\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1534.8446 - val_loss: 1458.5297\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1504.0271 - val_loss: 1440.3131\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1473.6597 - val_loss: 1422.4340\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1443.7393 - val_loss: 1404.8889\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1414.2614 - val_loss: 1387.6744\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1385.2228 - val_loss: 1370.7870\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1356.6188 - val_loss: 1354.2242\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1328.4454 - val_loss: 1337.9821\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1300.6991 - val_loss: 1322.0575\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1273.3765 - val_loss: 1306.4469\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1246.4729 - val_loss: 1291.1477\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1219.9844 - val_loss: 1276.1562\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1193.9082 - val_loss: 1261.4696\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1168.2393 - val_loss: 1247.0845\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1142.9750 - val_loss: 1232.9974\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1118.1106 - val_loss: 1219.2056\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1093.6427 - val_loss: 1205.7056\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1069.5671 - val_loss: 1192.4944\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1045.8807 - val_loss: 1179.5686\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1022.5797 - val_loss: 1166.9257\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 999.6600 - val_loss: 1154.5618\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 977.1183 - val_loss: 1142.4741\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 954.9506 - val_loss: 1130.6594\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 933.1535 - val_loss: 1119.1151\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 911.7228 - val_loss: 1107.8367\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 890.6550 - val_loss: 1096.8230\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 869.9470 - val_loss: 1086.0697\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 849.5950 - val_loss: 1075.5741\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 829.5951 - val_loss: 1065.3326\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 809.9437 - val_loss: 1055.3431\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 790.6376 - val_loss: 1045.6016\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 771.6727 - val_loss: 1036.1061\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 753.0456 - val_loss: 1026.8525\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 734.7526 - val_loss: 1017.8377\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 716.7904 - val_loss: 1009.0601\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 699.1556 - val_loss: 1000.5153\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 681.8441 - val_loss: 992.2005\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 664.8529 - val_loss: 984.1132\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 648.1782 - val_loss: 976.2497\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 631.8164 - val_loss: 968.6077\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 615.7641 - val_loss: 961.1837\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 600.0179 - val_loss: 953.9751\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 584.5745 - val_loss: 946.9786\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 569.4301 - val_loss: 940.1913\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 554.5812 - val_loss: 933.6104\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 540.0245 - val_loss: 927.2328\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 525.7568 - val_loss: 921.0555\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 511.7738 - val_loss: 915.0754\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 498.0730 - val_loss: 909.2902\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 484.6503 - val_loss: 903.6962\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 471.5027 - val_loss: 898.2907\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 458.6267 - val_loss: 893.0713\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 446.0191 - val_loss: 888.0343\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 433.6761 - val_loss: 883.1771\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 421.5945 - val_loss: 878.4969\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 409.7708 - val_loss: 873.9909\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 398.2021 - val_loss: 869.6556\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 386.8848 - val_loss: 865.4891\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 375.8155 - val_loss: 861.4875\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 364.9905 - val_loss: 857.6485\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 354.4069 - val_loss: 853.9694\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 344.0615 - val_loss: 850.4468\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 333.9510 - val_loss: 847.0782\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 324.0718 - val_loss: 843.8604\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 314.4203 - val_loss: 840.7913\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 304.9942 - val_loss: 837.8675\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 295.7892 - val_loss: 835.0861\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 286.8027 - val_loss: 832.4446\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 278.0315 - val_loss: 829.9402\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 269.4720 - val_loss: 827.5699\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 261.1212 - val_loss: 825.3309\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 252.9753 - val_loss: 823.2208\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 245.0320 - val_loss: 821.2365\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 237.2876 - val_loss: 819.3755\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 229.7390 - val_loss: 817.6347\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 222.3830 - val_loss: 816.0117\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 215.2163 - val_loss: 814.5036\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 208.2361 - val_loss: 813.1080\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 201.4390 - val_loss: 811.8219\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 194.8220 - val_loss: 810.6428\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 188.3820 - val_loss: 809.5679\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 182.1160 - val_loss: 808.5948\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 176.0208 - val_loss: 807.7205\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 170.0934 - val_loss: 806.9427\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 164.3309 - val_loss: 806.2589\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 158.7304 - val_loss: 805.6662\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 153.2885 - val_loss: 805.1622\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 148.0022 - val_loss: 804.7444\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 142.8685 - val_loss: 804.4101\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 137.8847 - val_loss: 804.1569\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 133.0481 - val_loss: 803.9824\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 128.3554 - val_loss: 803.8839\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 123.8035 - val_loss: 803.8591\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 119.3901 - val_loss: 803.9057\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 115.1120 - val_loss: 804.0212\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 110.9664 - val_loss: 804.2030\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 106.9506 - val_loss: 804.4488\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 103.0616 - val_loss: 804.7567\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 99.2967 - val_loss: 805.1238\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 95.6535 - val_loss: 805.5482\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 92.1290 - val_loss: 806.0273\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 88.7204 - val_loss: 806.5591\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 85.4252 - val_loss: 807.1414\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 82.2405 - val_loss: 807.7721\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 79.1639 - val_loss: 808.4487\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 76.1928 - val_loss: 809.1694\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 73.3244 - val_loss: 809.9321\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 70.5563 - val_loss: 810.7344\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 67.8863 - val_loss: 811.5744\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 65.3118 - val_loss: 812.4501\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 62.8301 - val_loss: 813.3596\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 60.4389 - val_loss: 814.3011\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 58.1357 - val_loss: 815.2720\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 55.9186 - val_loss: 816.2712\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 53.7846 - val_loss: 817.2967\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 51.7316 - val_loss: 818.3465\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 49.7574 - val_loss: 819.4188\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 47.8599 - val_loss: 820.5119\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 46.0367 - val_loss: 821.6239\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 44.2859 - val_loss: 822.7536\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 42.6051 - val_loss: 823.8986\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 40.9924 - val_loss: 825.0582\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 39.4455 - val_loss: 826.2303\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 37.9624 - val_loss: 827.4134\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 36.5412 - val_loss: 828.6063\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 35.1799 - val_loss: 829.8071\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 33.8767 - val_loss: 831.0147\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 32.6296 - val_loss: 832.2274\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 31.4368 - val_loss: 833.4442\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 30.2962 - val_loss: 834.6639\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 29.2064 - val_loss: 835.8849\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 28.1655 - val_loss: 837.1058\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 27.1717 - val_loss: 838.3261\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 26.2234 - val_loss: 839.5444\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 25.3189 - val_loss: 840.7591\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 24.4569 - val_loss: 841.9698\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 23.6355 - val_loss: 843.1749\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 22.8532 - val_loss: 844.3740\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 22.1087 - val_loss: 845.5657\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 21.4005 - val_loss: 846.7494\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 20.7270 - val_loss: 847.9238\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.0870 - val_loss: 849.0886\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 19.4791 - val_loss: 850.2429\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 18.9020 - val_loss: 851.3858\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 18.3544 - val_loss: 852.5167\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 17.8351 - val_loss: 853.6351\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 17.3429 - val_loss: 854.7398\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.8767 - val_loss: 855.8306\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.4353 - val_loss: 856.9069\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 16.0176 - val_loss: 857.9680\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 15.6226 - val_loss: 859.0138\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 15.2492 - val_loss: 860.0436\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 14.8965 - val_loss: 861.0573\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 14.5634 - val_loss: 862.0540\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 14.2491 - val_loss: 863.0338\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 13.9527 - val_loss: 863.9961\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 13.6732 - val_loss: 864.9404\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 13.4100 - val_loss: 865.8672\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 13.1622 - val_loss: 866.7753\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 12.9290 - val_loss: 867.6651\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 12.7098 - val_loss: 868.5365\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 12.5037 - val_loss: 869.3893\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 12.3100 - val_loss: 870.2232\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 12.1282 - val_loss: 871.0384\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 11.9576 - val_loss: 871.8349\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 11.7976 - val_loss: 872.6123\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 11.6475 - val_loss: 873.3708\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 11.5070 - val_loss: 874.1105\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 11.3755 - val_loss: 874.8312\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 11.2523 - val_loss: 875.5334\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 11.1372 - val_loss: 876.2169\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 11.0295 - val_loss: 876.8813\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.9289 - val_loss: 877.5276\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 10.8350 - val_loss: 878.1555\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 10.7474 - val_loss: 878.7657\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.6656 - val_loss: 879.3575\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.5893 - val_loss: 879.9321\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.5182 - val_loss: 880.4884\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.4520 - val_loss: 881.0280\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.3904 - val_loss: 881.5502\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.3330 - val_loss: 882.0555\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.2796 - val_loss: 882.5444\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.2300 - val_loss: 883.0170\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1839 - val_loss: 883.4738\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1410 - val_loss: 883.9147\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.1012 - val_loss: 884.3403\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 10.0642 - val_loss: 884.7506\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 10.0299 - val_loss: 885.1460\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.9981 - val_loss: 885.5268\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.9686 - val_loss: 885.8937\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.9413 - val_loss: 886.2466\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.9159 - val_loss: 886.5856\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.8925 - val_loss: 886.9117\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.8707 - val_loss: 887.2246\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.8506 - val_loss: 887.5256\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.8319 - val_loss: 887.8137\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.8147 - val_loss: 888.0905\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.7987 - val_loss: 888.3553\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.7840 - val_loss: 888.6091\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.7703 - val_loss: 888.8518\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.7577 - val_loss: 889.0844\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.7460 - val_loss: 889.3060\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 9.7352 - val_loss: 889.5181\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.7253 - val_loss: 889.7212\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.7161 - val_loss: 889.9141\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.7076 - val_loss: 890.0982\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6997 - val_loss: 890.2737\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6924 - val_loss: 890.4403\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6858 - val_loss: 890.5993\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6796 - val_loss: 890.7508\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6739 - val_loss: 890.8948\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6686 - val_loss: 891.0314\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6638 - val_loss: 891.1607\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6593 - val_loss: 891.2834\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6552 - val_loss: 891.4002\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6514 - val_loss: 891.5108\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6479 - val_loss: 891.6149\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6447 - val_loss: 891.7141\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6417 - val_loss: 891.8076\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6390 - val_loss: 891.8962\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6365 - val_loss: 891.9799\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6342 - val_loss: 892.0585\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6321 - val_loss: 892.1329\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6302 - val_loss: 892.2026\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6285 - val_loss: 892.2687\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6268 - val_loss: 892.3304\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6254 - val_loss: 892.3886\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6241 - val_loss: 892.4435\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 9.6228 - val_loss: 892.4946\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6218 - val_loss: 892.5428\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6208 - val_loss: 892.5881\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6199 - val_loss: 892.6304\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6191 - val_loss: 892.6700\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6184 - val_loss: 892.7068\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6178 - val_loss: 892.7415\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6172 - val_loss: 892.7738\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6167 - val_loss: 892.8036\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6163 - val_loss: 892.8315\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6159 - val_loss: 892.8574\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6157 - val_loss: 892.8818\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6154 - val_loss: 892.9039\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6152 - val_loss: 892.9250\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6150 - val_loss: 892.9448\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6149 - val_loss: 892.9625\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6148 - val_loss: 892.9790\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6148 - val_loss: 892.9938\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6148 - val_loss: 893.0081\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6149 - val_loss: 893.0212\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6149 - val_loss: 893.0327\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6150 - val_loss: 893.0438\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6151 - val_loss: 893.0535\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6153 - val_loss: 893.0628\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6155 - val_loss: 893.0713\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 9.6157 - val_loss: 893.0787\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6159 - val_loss: 893.0857\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6161 - val_loss: 893.0920\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6163 - val_loss: 893.0973\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6166 - val_loss: 893.1022\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6169 - val_loss: 893.1068\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6172 - val_loss: 893.1111\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6175 - val_loss: 893.1147\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6178 - val_loss: 893.1179\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6181 - val_loss: 893.1207\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6185 - val_loss: 893.1230\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6189 - val_loss: 893.1254\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6192 - val_loss: 893.1275\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6196 - val_loss: 893.1292\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6200 - val_loss: 893.1307\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6203 - val_loss: 893.1317\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6207 - val_loss: 893.1328\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6211 - val_loss: 893.1334\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6215 - val_loss: 893.1337\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6219 - val_loss: 893.1339\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6223 - val_loss: 893.1342\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6228 - val_loss: 893.1342\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6232 - val_loss: 893.1342\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6236 - val_loss: 893.1339\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 9.6240 - val_loss: 893.1335\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6245 - val_loss: 893.1332\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6249 - val_loss: 893.1326\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6253 - val_loss: 893.1317\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6258 - val_loss: 893.1312\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6262 - val_loss: 893.1299\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6266 - val_loss: 893.1292\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6270 - val_loss: 893.1282\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6275 - val_loss: 893.1272\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6279 - val_loss: 893.1265\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6284 - val_loss: 893.1251\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6288 - val_loss: 893.1242\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6292 - val_loss: 893.1229\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6297 - val_loss: 893.1219\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6302 - val_loss: 893.1205\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.6306 - val_loss: 893.1194\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.6311 - val_loss: 893.1179\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6315 - val_loss: 893.1172\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6319 - val_loss: 893.1156\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6324 - val_loss: 893.1147\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6328 - val_loss: 893.1131\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6332 - val_loss: 893.1118\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6337 - val_loss: 893.1105\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 9.6341 - val_loss: 893.1089\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6346 - val_loss: 893.1081\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6350 - val_loss: 893.1064\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6354 - val_loss: 893.1055\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6359 - val_loss: 893.1038\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6363 - val_loss: 893.1026\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6367 - val_loss: 893.1014\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6371 - val_loss: 893.1004\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6376 - val_loss: 893.0990\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.6380 - val_loss: 893.0978\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6384 - val_loss: 893.0966\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6388 - val_loss: 893.0950\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6392 - val_loss: 893.0939\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6396 - val_loss: 893.0925\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6401 - val_loss: 893.0916\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.6405 - val_loss: 893.0896\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6409 - val_loss: 893.0885\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6413 - val_loss: 893.0873\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6417 - val_loss: 893.0863\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6421 - val_loss: 893.0851\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6425 - val_loss: 893.0839\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 9.6429 - val_loss: 893.0826\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6432 - val_loss: 893.0812\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6437 - val_loss: 893.0800\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6441 - val_loss: 893.0786\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6444 - val_loss: 893.0778\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 9.6448 - val_loss: 893.0761\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6452 - val_loss: 893.0750\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6456 - val_loss: 893.0737\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6459 - val_loss: 893.0724\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6463 - val_loss: 893.0713\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.6467 - val_loss: 893.0702\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 9.6470 - val_loss: 893.0688\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6474 - val_loss: 893.0679\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6478 - val_loss: 893.0665\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6481 - val_loss: 893.0657\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6485 - val_loss: 893.0644\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6488 - val_loss: 893.0637\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6491 - val_loss: 893.0624\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6495 - val_loss: 893.0617\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6498 - val_loss: 893.0603\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6502 - val_loss: 893.0591\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 9.6505 - val_loss: 893.0580\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6508 - val_loss: 893.0571\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6512 - val_loss: 893.0554\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6515 - val_loss: 893.0546\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6518 - val_loss: 893.0536\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6522 - val_loss: 893.0524\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6524 - val_loss: 893.0516\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6528 - val_loss: 893.0506\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6531 - val_loss: 893.0500\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6534 - val_loss: 893.0494\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6537 - val_loss: 893.0482\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6540 - val_loss: 893.0474\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6543 - val_loss: 893.0464\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6546 - val_loss: 893.0455\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6548 - val_loss: 893.0446\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6551 - val_loss: 893.0435\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6554 - val_loss: 893.0430\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6557 - val_loss: 893.0418\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6560 - val_loss: 893.0410\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6562 - val_loss: 893.0402\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6565 - val_loss: 893.0391\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6568 - val_loss: 893.0385\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 9.6570 - val_loss: 893.0379\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6573 - val_loss: 893.0373\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6575 - val_loss: 893.0363\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6578 - val_loss: 893.0359\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6580 - val_loss: 893.0347\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6583 - val_loss: 893.0340\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6585 - val_loss: 893.0330\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6588 - val_loss: 893.0323\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6590 - val_loss: 893.0317\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6592 - val_loss: 893.0309\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6595 - val_loss: 893.0302\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6597 - val_loss: 893.0292\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6599 - val_loss: 893.0288\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6601 - val_loss: 893.0280\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6604 - val_loss: 893.0272\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6606 - val_loss: 893.0267\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6608 - val_loss: 893.0260\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6610 - val_loss: 893.0252\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6612 - val_loss: 893.0248\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6614 - val_loss: 893.0244\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6616 - val_loss: 893.0236\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6618 - val_loss: 893.0232\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 9.6620 - val_loss: 893.0222\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6622 - val_loss: 893.0219\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6624 - val_loss: 893.0212\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6625 - val_loss: 893.0204\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6628 - val_loss: 893.0201\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6629 - val_loss: 893.0197\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6631 - val_loss: 893.0187\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6632 - val_loss: 893.0178\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 9.6634 - val_loss: 893.0175\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6636 - val_loss: 893.0170\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6638 - val_loss: 893.0167\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6639 - val_loss: 893.0161\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6641 - val_loss: 893.0155\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6642 - val_loss: 893.0149\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6644 - val_loss: 893.0146\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6645 - val_loss: 893.0137\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6647 - val_loss: 893.0133\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6649 - val_loss: 893.0129\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6650 - val_loss: 893.0124\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6651 - val_loss: 893.0118\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6653 - val_loss: 893.0111\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 9.6655 - val_loss: 893.0106\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6656 - val_loss: 893.0106\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6657 - val_loss: 893.0103\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6659 - val_loss: 893.0101\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6659 - val_loss: 893.0095\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6661 - val_loss: 893.0093\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6662 - val_loss: 893.0085\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6663 - val_loss: 893.0081\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6665 - val_loss: 893.0079\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6666 - val_loss: 893.0076\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6667 - val_loss: 893.0071\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.6668 - val_loss: 893.0068\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6669 - val_loss: 893.0062\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.6671 - val_loss: 893.0059\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 373ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74.37835201, 74.35650327, 74.33465453, 74.31280579, 74.28260971,\n",
       "        74.2405929 , 74.1985761 ,  0.        ,  0.20382594,  0.        ,\n",
       "         0.25656152,  0.31501234,  0.        , 74.6317507 , 74.5579972 ,\n",
       "        74.53614846, 74.51429972, 74.49245098, 74.47060224, 74.4487535 ,\n",
       "        74.42690476, 74.40505602, 74.38320728, 74.36135854, 74.3395098 ,\n",
       "        74.31766106, 74.29194678, 74.24992997, 74.20791317, 74.16589636,\n",
       "        74.12387955, 74.08186275, 74.03984594, 73.99782913, 73.95581232,\n",
       "        73.91379552, 73.87177871, 73.8297619 , 73.76813725, 73.65889356,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , 74.32251634, 74.3006676 , 74.25926704,\n",
       "        74.21725023, 74.17523343, 74.13321662, 74.09119981, 74.04918301,\n",
       "        74.0071662 , 73.96514939, 73.92313259, 73.88111578, 73.83909897,\n",
       "        73.79241363, 73.68316993, 73.57392624, 73.46468254, 73.35543884,\n",
       "        73.24619514, 73.13695145, 73.02770775, 72.91846405, 72.80922035,\n",
       "        72.69997666, 72.59073296, 72.49003268, 78.38580322,  0.09506555,\n",
       "         0.35351771,  0.        ,  0.        ,  0.66569293,  0.        ,\n",
       "        69.38095856,  0.        ,  0.44140655,  0.08274423,  0.        ,\n",
       "         0.        ,  0.        ,  0.29105157,  0.68838817,  0.6129632 ,\n",
       "         0.33513257,  0.21309158,  0.29862684,  0.        ,  0.52793223,\n",
       "         0.        ,  0.10164601,  0.        ,  0.18937986,  0.22081141]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.98339169, 69.9782563 , 69.97312092, 69.96798553, 69.96285014,\n",
       "       69.95771475, 69.95257937, 69.94744398, 69.94230859, 69.9371732 ,\n",
       "       69.93203782, 69.92690243, 69.92176704, 69.91663165, 69.91149627,\n",
       "       69.90636088, 69.90122549, 69.8960901 , 69.89095472, 69.88581933,\n",
       "       69.88068394, 69.87554855, 69.87041317, 69.86527778, 69.86014239,\n",
       "       69.855007  , 69.84987162, 69.84473623, 69.83960084, 69.83446545,\n",
       "       69.82933007, 69.82419468, 69.81905929, 69.8139239 , 69.80878852,\n",
       "       69.80365313, 69.79851774, 69.79338235, 69.78824697, 69.78311158,\n",
       "       69.77797619, 69.7728408 , 69.76770542, 69.76257003, 69.75743464,\n",
       "       69.75229925, 69.74716387, 69.74202848, 69.73689309, 69.7317577 ,\n",
       "       69.72662232, 69.72148693, 69.71635154, 69.71121615, 69.70608077,\n",
       "       69.70094538, 69.69580999, 69.6906746 , 69.68553922, 69.68040383,\n",
       "       69.67526844, 69.67013305, 69.66499767, 69.65986228, 69.65472689,\n",
       "       69.6495915 , 69.64445612, 69.63932073, 69.63418534, 69.62904995,\n",
       "       69.62391457, 69.61877918, 69.61364379, 69.6085084 , 69.60337302,\n",
       "       69.59823763, 69.59310224, 69.58796685, 69.58283147, 69.57769608,\n",
       "       69.57256069, 69.5674253 , 69.56228992, 69.55715453, 69.55201914,\n",
       "       69.54688375, 69.54174837, 69.53661298, 69.53147759, 69.5263422 ,\n",
       "       69.52120682, 69.51607143, 69.51093604, 69.50580065, 69.50066527,\n",
       "       69.49552988, 69.49039449, 69.4852591 , 69.48012372, 69.47498833])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.96736911717379\n",
      "29.002218216822172\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
