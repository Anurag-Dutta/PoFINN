{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "1995    70.009069\n",
       "1996    70.003933\n",
       "1997    69.998798\n",
       "1998    69.993662\n",
       "1999    69.988527\n",
       "Name: C3, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c3_interpolated_1900_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       91.100000\n",
       "1       90.875910\n",
       "2       90.651821\n",
       "3       90.427731\n",
       "4       90.203641\n",
       "          ...    \n",
       "1895     0.000000\n",
       "1896     0.297363\n",
       "1897     0.000000\n",
       "1898     0.000000\n",
       "1899     0.129221\n",
       "Name: C3, Length: 1900, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1900)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.100000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.875910</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.651821</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.427731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.203641</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     91.100000  0.000298\n",
       "1     90.875910  0.000298\n",
       "2     90.651821  0.000297\n",
       "3     90.427731  0.000297\n",
       "4     90.203641  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 88.0403  # Value for C0\n",
    "K0 = -0.0012  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0120    # Value for b\n",
    "c = 2.0334    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    91.100000    90.875910    90.651821    90.427731    90.203641   \n",
      "351    90.875910    90.651821    90.427731    90.203641    89.979552   \n",
      "352    90.651821    90.427731    90.203641    89.979552    89.755462   \n",
      "353    90.427731    90.203641    89.979552    89.755462    89.531373   \n",
      "354    90.203641    89.979552    89.755462    89.531373    89.307283   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    89.979552    89.755462    89.531373    89.307283    89.094118  ...   \n",
      "351    89.755462    89.531373    89.307283    89.094118    89.015686  ...   \n",
      "352    89.531373    89.307283    89.094118    89.015686    88.937255  ...   \n",
      "353    89.307283    89.094118    89.015686    88.937255    88.858824  ...   \n",
      "354    89.094118    89.015686    88.937255    88.858824    88.780392  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   81.423343    0.000263   81.404669    0.000263   81.385994    0.000263   \n",
      "351   81.404669    0.000263   81.385994    0.000263   81.367320    0.000262   \n",
      "352   81.385994    0.000263   81.367320    0.000262   81.348646    0.000262   \n",
      "353   81.367320    0.000262   81.348646    0.000262   81.329972    0.000262   \n",
      "354   81.348646    0.000262   81.329972    0.000262   81.311298    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   81.367320    0.000262   81.348646    0.000262  \n",
      "351   81.348646    0.000262   81.329972    0.000262  \n",
      "352   81.329972    0.000262   81.311298    0.000262  \n",
      "353   81.311298    0.000262   81.292624    0.000262  \n",
      "354   81.292624    0.000262   81.273950    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1450, 1, 251) (1450, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 2s 24ms/step - loss: 5879.7529 - val_loss: 4564.9492\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5803.3662 - val_loss: 4513.7051\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5735.0078 - val_loss: 4449.1025\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5657.2910 - val_loss: 4396.0122\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5586.6514 - val_loss: 4330.2812\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5503.1768 - val_loss: 4269.5835\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5429.2520 - val_loss: 4212.3193\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5357.9766 - val_loss: 4156.5879\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 5288.3550 - val_loss: 4102.0527\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5220.0166 - val_loss: 4048.4810\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5152.7344 - val_loss: 3995.7383\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5086.3774 - val_loss: 3943.7427\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5020.8608 - val_loss: 3892.4397\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4956.1265 - val_loss: 3841.7913\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4892.1367 - val_loss: 3791.7690\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4828.8594 - val_loss: 3742.3503\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4766.2705 - val_loss: 3693.5186\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4704.3525 - val_loss: 3645.2590\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4643.0864 - val_loss: 3597.5591\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4582.4619 - val_loss: 3550.4082\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4522.4639 - val_loss: 3503.7979\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4463.0845 - val_loss: 3457.7183\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4404.3125 - val_loss: 3412.1626\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4346.1401 - val_loss: 3367.1238\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4288.5591 - val_loss: 3322.5959\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4231.5640 - val_loss: 3278.5723\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4175.1455 - val_loss: 3235.0469\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4119.2998 - val_loss: 3192.0154\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4064.0186 - val_loss: 3149.4717\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4009.2969 - val_loss: 3107.4116\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3955.1301 - val_loss: 3065.8301\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3901.5117 - val_loss: 3024.7227\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3848.4385 - val_loss: 2984.0854\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3795.9031 - val_loss: 2943.9128\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3743.9021 - val_loss: 2904.2021\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3692.4314 - val_loss: 2864.9482\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3641.4854 - val_loss: 2826.1479\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3591.0598 - val_loss: 2787.7961\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3541.1509 - val_loss: 2749.8894\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3491.7542 - val_loss: 2712.4246\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3442.8655 - val_loss: 2675.3933\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3394.4807 - val_loss: 2638.7781\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3339.5291 - val_loss: 2591.8308\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3282.0178 - val_loss: 2550.4553\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3228.5620 - val_loss: 2510.7236\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3176.9373 - val_loss: 2472.2524\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3126.6843 - val_loss: 2434.7563\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3077.5193 - val_loss: 2398.0742\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3029.2769 - val_loss: 2362.1091\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2981.8540 - val_loss: 2326.7949\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2935.1819 - val_loss: 2292.0876\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2889.2104 - val_loss: 2257.9529\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2843.9004 - val_loss: 2224.3645\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2799.2241 - val_loss: 2191.3005\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2755.1560 - val_loss: 2158.7449\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2711.6777 - val_loss: 2126.6819\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2668.7712 - val_loss: 2095.0991\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2626.4224 - val_loss: 2063.9858\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2584.6179 - val_loss: 2033.3313\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2543.3464 - val_loss: 2003.1272\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2502.5991 - val_loss: 1973.3651\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2462.3650 - val_loss: 1944.0381\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2422.6370 - val_loss: 1915.1388\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2383.4058 - val_loss: 1886.6613\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2344.6650 - val_loss: 1858.5991\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2306.4080 - val_loss: 1830.9470\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2268.6270 - val_loss: 1803.6990\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2231.3171 - val_loss: 1776.8507\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2194.4724 - val_loss: 1750.3966\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2158.0872 - val_loss: 1724.3323\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2122.1560 - val_loss: 1698.6539\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2086.6741 - val_loss: 1673.3555\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2051.6362 - val_loss: 1648.4347\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2017.0383 - val_loss: 1623.8862\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1982.8745 - val_loss: 1599.7059\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1949.1418 - val_loss: 1575.8905\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1915.8342 - val_loss: 1552.4362\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1882.9493 - val_loss: 1529.3390\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1850.4823 - val_loss: 1506.5958\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1818.4282 - val_loss: 1484.2021\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1786.7844 - val_loss: 1462.1552\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1755.5466 - val_loss: 1440.4514\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1724.7108 - val_loss: 1419.0873\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1694.2736 - val_loss: 1398.0599\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1664.2314 - val_loss: 1377.3658\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1634.5801 - val_loss: 1357.0015\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1605.3163 - val_loss: 1336.9637\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1576.4365 - val_loss: 1317.2495\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1547.9377 - val_loss: 1297.8564\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1519.8167 - val_loss: 1278.7804\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1492.0695 - val_loss: 1260.0195\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1464.6932 - val_loss: 1241.5701\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1437.6843 - val_loss: 1223.4286\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1411.0393 - val_loss: 1205.5928\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1384.7554 - val_loss: 1188.0596\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1358.8297 - val_loss: 1170.8265\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1333.2584 - val_loss: 1153.8900\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1308.0388 - val_loss: 1137.2471\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1283.1676 - val_loss: 1120.8959\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1258.6423 - val_loss: 1104.8336\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1234.4600 - val_loss: 1089.0565\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1210.6165 - val_loss: 1073.5624\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1187.1097 - val_loss: 1058.3485\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1163.9368 - val_loss: 1043.4117\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1141.0938 - val_loss: 1028.7496\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1118.5792 - val_loss: 1014.3601\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1096.3892 - val_loss: 1000.2397\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1074.5211 - val_loss: 986.3856\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1052.9724 - val_loss: 972.7959\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1031.7401 - val_loss: 959.4672\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1010.8211 - val_loss: 946.3971\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 990.2125 - val_loss: 933.5837\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 969.9120 - val_loss: 921.0232\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 949.9168 - val_loss: 908.7140\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 930.2235 - val_loss: 896.6528\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 910.8301 - val_loss: 884.8378\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 891.7333 - val_loss: 873.2656\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 872.9308 - val_loss: 861.9342\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 854.4197 - val_loss: 850.8408\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 836.1974 - val_loss: 839.9830\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 818.2612 - val_loss: 829.3582\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 800.6085 - val_loss: 818.9636\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 783.2360 - val_loss: 808.7975\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 766.1418 - val_loss: 798.8567\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 749.3230 - val_loss: 789.1385\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 732.7769 - val_loss: 779.6411\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 716.5013 - val_loss: 770.3618\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 700.4928 - val_loss: 761.2979\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 684.7495 - val_loss: 752.4464\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 669.2682 - val_loss: 743.8063\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 654.0466 - val_loss: 735.3740\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 639.0827 - val_loss: 727.1475\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 624.3732 - val_loss: 719.1240\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 609.9155 - val_loss: 711.3014\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 595.7075 - val_loss: 703.6773\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 581.7460 - val_loss: 696.2487\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 568.0292 - val_loss: 689.0140\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 554.5541 - val_loss: 681.9695\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 541.3181 - val_loss: 675.1141\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 528.3190 - val_loss: 668.4454\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 515.5542 - val_loss: 661.9598\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 503.0211 - val_loss: 655.6558\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 490.7170 - val_loss: 649.5309\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 478.6400 - val_loss: 643.5825\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 466.7871 - val_loss: 637.8082\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 455.1559 - val_loss: 632.2061\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 443.7442 - val_loss: 626.7732\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 432.5492 - val_loss: 621.5072\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 421.5681 - val_loss: 616.4059\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 410.7993 - val_loss: 611.4670\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 400.2398 - val_loss: 606.6882\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 389.8871 - val_loss: 602.0668\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 379.7392 - val_loss: 597.6006\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 369.7932 - val_loss: 593.2872\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 360.0464 - val_loss: 589.1245\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 350.4970 - val_loss: 585.1096\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 341.1423 - val_loss: 581.2410\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 331.9801 - val_loss: 577.5157\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 323.0078 - val_loss: 573.9315\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 314.2228 - val_loss: 570.4861\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 305.6229 - val_loss: 567.1776\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 297.2060 - val_loss: 564.0031\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 288.9694 - val_loss: 560.9606\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 280.9107 - val_loss: 558.0478\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 273.0276 - val_loss: 555.2623\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 265.3177 - val_loss: 552.6019\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 257.7785 - val_loss: 550.0641\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 250.4078 - val_loss: 547.6468\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 243.2030 - val_loss: 545.3478\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 236.1622 - val_loss: 543.1647\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 229.2828 - val_loss: 541.0955\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 222.5624 - val_loss: 539.1376\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 215.9989 - val_loss: 537.2890\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 209.5900 - val_loss: 535.5474\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 203.3329 - val_loss: 533.9105\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 197.2258 - val_loss: 532.3762\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 191.2663 - val_loss: 530.9422\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 185.4520 - val_loss: 529.6064\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 179.7807 - val_loss: 528.3667\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 174.2503 - val_loss: 527.2208\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 168.8585 - val_loss: 526.1664\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 163.6026 - val_loss: 525.2016\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 158.4811 - val_loss: 524.3240\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 153.4911 - val_loss: 523.5317\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 148.6307 - val_loss: 522.8225\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 143.8977 - val_loss: 522.1942\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 139.2897 - val_loss: 521.6448\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 134.8049 - val_loss: 521.1721\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 130.4408 - val_loss: 520.7744\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 126.1956 - val_loss: 520.4490\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 122.0667 - val_loss: 520.1943\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 118.0522 - val_loss: 520.0084\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 114.1502 - val_loss: 519.8888\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 110.3581 - val_loss: 519.8339\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 106.6738 - val_loss: 519.8414\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 103.0956 - val_loss: 519.9097\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 99.6213 - val_loss: 520.0364\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 96.2487 - val_loss: 520.2199\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 92.9761 - val_loss: 520.4583\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 89.8011 - val_loss: 520.7496\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 86.7217 - val_loss: 521.0918\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 83.7361 - val_loss: 521.4832\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 80.8424 - val_loss: 521.9218\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 78.0384 - val_loss: 522.4059\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 75.3222 - val_loss: 522.9336\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 72.6920 - val_loss: 523.5034\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 70.1456 - val_loss: 524.1130\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 67.6814 - val_loss: 524.7612\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 65.2974 - val_loss: 525.4460\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 62.9920 - val_loss: 526.1656\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 60.7630 - val_loss: 526.9185\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 58.6087 - val_loss: 527.7031\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 56.5272 - val_loss: 528.5177\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 54.5169 - val_loss: 529.3605\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 52.5760 - val_loss: 530.2302\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 50.7027 - val_loss: 531.1252\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 48.8952 - val_loss: 532.0439\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 47.1521 - val_loss: 532.9848\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 45.4715 - val_loss: 533.9462\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 43.8518 - val_loss: 534.9272\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 42.2913 - val_loss: 535.9258\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 40.7885 - val_loss: 536.9409\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 39.3416 - val_loss: 537.9713\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 37.9493 - val_loss: 539.0151\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 36.6100 - val_loss: 540.0715\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 35.3220 - val_loss: 541.1390\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 34.0840 - val_loss: 542.2166\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 32.8945 - val_loss: 543.3026\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.7521 - val_loss: 544.3960\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.6553 - val_loss: 545.4957\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.6027 - val_loss: 546.6005\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 28.5930 - val_loss: 547.7096\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 27.6247 - val_loss: 548.8214\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 26.6967 - val_loss: 549.9352\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 25.8075 - val_loss: 551.0495\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 24.9561 - val_loss: 552.1641\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 24.1409 - val_loss: 553.2775\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 23.3609 - val_loss: 554.3890\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 22.6149 - val_loss: 555.4975\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.9017 - val_loss: 556.6024\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.2201 - val_loss: 557.7026\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 20.5689 - val_loss: 558.7975\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9473 - val_loss: 559.8861\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.3540 - val_loss: 560.9678\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.7881 - val_loss: 562.0419\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 18.2486 - val_loss: 563.1078\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.7343 - val_loss: 564.1647\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.2444 - val_loss: 565.2120\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.7778 - val_loss: 566.2493\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 16.3338 - val_loss: 567.2755\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.9115 - val_loss: 568.2908\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 15.5098 - val_loss: 569.2941\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.1281 - val_loss: 570.2853\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.7655 - val_loss: 571.2637\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.4212 - val_loss: 572.2291\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 14.0943 - val_loss: 573.1808\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 13.7843 - val_loss: 574.1188\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 13.4904 - val_loss: 575.0425\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 13.2118 - val_loss: 575.9517\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 12.9479 - val_loss: 576.8461\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 12.6980 - val_loss: 577.7254\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 12.4615 - val_loss: 578.5895\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 12.2378 - val_loss: 579.4382\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 12.0262 - val_loss: 580.2714\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 11.8263 - val_loss: 581.0884\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11.6375 - val_loss: 581.8895\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11.4591 - val_loss: 582.6749\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11.2908 - val_loss: 583.4441\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11.1320 - val_loss: 584.1967\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10.9823 - val_loss: 584.9332\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10.8412 - val_loss: 585.6531\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 10.7083 - val_loss: 586.3569\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10.5831 - val_loss: 587.0442\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10.4654 - val_loss: 587.7152\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10.3545 - val_loss: 588.3704\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10.2503 - val_loss: 589.0092\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10.1523 - val_loss: 589.6315\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10.0603 - val_loss: 590.2380\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.9738 - val_loss: 590.8283\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.8927 - val_loss: 591.4029\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.8165 - val_loss: 591.9621\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.7451 - val_loss: 592.5052\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.6781 - val_loss: 593.0333\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.6153 - val_loss: 593.5461\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.5565 - val_loss: 594.0440\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.5013 - val_loss: 594.5267\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.4497 - val_loss: 594.9952\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.4014 - val_loss: 595.4492\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 9.3562 - val_loss: 595.8887\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.3139 - val_loss: 596.3144\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.2744 - val_loss: 596.7261\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.2374 - val_loss: 597.1246\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.2029 - val_loss: 597.5096\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.1706 - val_loss: 597.8820\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1405 - val_loss: 598.2410\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1123 - val_loss: 598.5880\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.0860 - val_loss: 598.9227\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.0614 - val_loss: 599.2452\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.0385 - val_loss: 599.5563\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.0171 - val_loss: 599.8555\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.9972 - val_loss: 600.1434\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 8.9786 - val_loss: 600.4208\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.9612 - val_loss: 600.6871\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.9451 - val_loss: 600.9433\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.9300 - val_loss: 601.1890\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.9160 - val_loss: 601.4255\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.9029 - val_loss: 601.6519\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.8907 - val_loss: 601.8694\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.8793 - val_loss: 602.0778\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.8687 - val_loss: 602.2773\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.8589 - val_loss: 602.4685\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.8497 - val_loss: 602.6513\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.8411 - val_loss: 602.8262\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.8331 - val_loss: 602.9935\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 8.8257 - val_loss: 603.1533\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.8187 - val_loss: 603.3058\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.8123 - val_loss: 603.4510\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.8063 - val_loss: 603.5895\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.8008 - val_loss: 603.7224\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7956 - val_loss: 603.8483\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7907 - val_loss: 603.9684\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7862 - val_loss: 604.0821\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7821 - val_loss: 604.1910\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7782 - val_loss: 604.2941\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7746 - val_loss: 604.3918\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7712 - val_loss: 604.4850\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7681 - val_loss: 604.5732\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7652 - val_loss: 604.6566\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7625 - val_loss: 604.7358\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7601 - val_loss: 604.8109\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7578 - val_loss: 604.8819\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7556 - val_loss: 604.9490\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7537 - val_loss: 605.0126\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7519 - val_loss: 605.0728\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7502 - val_loss: 605.1293\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7486 - val_loss: 605.1827\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7472 - val_loss: 605.2327\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7459 - val_loss: 605.2802\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7447 - val_loss: 605.3248\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7436 - val_loss: 605.3667\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7426 - val_loss: 605.4061\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7416 - val_loss: 605.4433\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7408 - val_loss: 605.4777\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7401 - val_loss: 605.5104\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 8.7393 - val_loss: 605.5409\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 8.7387 - val_loss: 605.5693\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7382 - val_loss: 605.5958\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7377 - val_loss: 605.6207\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7373 - val_loss: 605.6440\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7369 - val_loss: 605.6657\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7366 - val_loss: 605.6860\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7363 - val_loss: 605.7049\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7360 - val_loss: 605.7225\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7359 - val_loss: 605.7390\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7357 - val_loss: 605.7542\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7355 - val_loss: 605.7681\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7354 - val_loss: 605.7810\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7354 - val_loss: 605.7932\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7354 - val_loss: 605.8045\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7354 - val_loss: 605.8150\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7354 - val_loss: 605.8243\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7354 - val_loss: 605.8332\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7355 - val_loss: 605.8412\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7356 - val_loss: 605.8482\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7357 - val_loss: 605.8552\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7358 - val_loss: 605.8613\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7360 - val_loss: 605.8668\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7362 - val_loss: 605.8720\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7364 - val_loss: 605.8766\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7366 - val_loss: 605.8807\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7368 - val_loss: 605.8845\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7370 - val_loss: 605.8879\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 8.7372 - val_loss: 605.8909\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 8.7375 - val_loss: 605.8937\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7377 - val_loss: 605.8961\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7380 - val_loss: 605.8982\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7383 - val_loss: 605.9003\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7385 - val_loss: 605.9018\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7388 - val_loss: 605.9029\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7392 - val_loss: 605.9042\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7394 - val_loss: 605.9052\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7397 - val_loss: 605.9061\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7400 - val_loss: 605.9067\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7404 - val_loss: 605.9071\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7407 - val_loss: 605.9073\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7410 - val_loss: 605.9074\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7414 - val_loss: 605.9074\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7417 - val_loss: 605.9075\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7420 - val_loss: 605.9073\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7424 - val_loss: 605.9073\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7427 - val_loss: 605.9071\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7430 - val_loss: 605.9065\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7434 - val_loss: 605.9060\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7438 - val_loss: 605.9053\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7441 - val_loss: 605.9048\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7444 - val_loss: 605.9040\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7448 - val_loss: 605.9030\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7452 - val_loss: 605.9024\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 8.7455 - val_loss: 605.9016\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7459 - val_loss: 605.9006\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7463 - val_loss: 605.8998\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7466 - val_loss: 605.8991\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7470 - val_loss: 605.8981\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7473 - val_loss: 605.8970\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7477 - val_loss: 605.8959\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7481 - val_loss: 605.8948\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7484 - val_loss: 605.8938\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7488 - val_loss: 605.8928\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7491 - val_loss: 605.8918\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7495 - val_loss: 605.8909\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 8.7498 - val_loss: 605.8898\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7502 - val_loss: 605.8887\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7505 - val_loss: 605.8876\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7509 - val_loss: 605.8864\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7512 - val_loss: 605.8849\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7516 - val_loss: 605.8840\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7520 - val_loss: 605.8830\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7523 - val_loss: 605.8822\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7526 - val_loss: 605.8808\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7530 - val_loss: 605.8799\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7533 - val_loss: 605.8788\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 8.7537 - val_loss: 605.8779\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7540 - val_loss: 605.8765\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7544 - val_loss: 605.8754\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7547 - val_loss: 605.8741\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7551 - val_loss: 605.8733\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7554 - val_loss: 605.8720\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7557 - val_loss: 605.8709\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7561 - val_loss: 605.8699\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7564 - val_loss: 605.8690\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7567 - val_loss: 605.8679\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7570 - val_loss: 605.8668\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7574 - val_loss: 605.8657\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7577 - val_loss: 605.8646\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7580 - val_loss: 605.8635\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7583 - val_loss: 605.8624\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7587 - val_loss: 605.8616\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7590 - val_loss: 605.8605\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7593 - val_loss: 605.8594\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7596 - val_loss: 605.8581\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7599 - val_loss: 605.8573\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7602 - val_loss: 605.8562\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7605 - val_loss: 605.8553\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7608 - val_loss: 605.8541\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7612 - val_loss: 605.8533\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 8.7614 - val_loss: 605.8524\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7617 - val_loss: 605.8513\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7620 - val_loss: 605.8503\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7623 - val_loss: 605.8491\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7626 - val_loss: 605.8483\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7629 - val_loss: 605.8473\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7632 - val_loss: 605.8462\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7635 - val_loss: 605.8455\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7637 - val_loss: 605.8445\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7640 - val_loss: 605.8434\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7643 - val_loss: 605.8426\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7646 - val_loss: 605.8422\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7648 - val_loss: 605.8411\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7651 - val_loss: 605.8400\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7654 - val_loss: 605.8394\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7656 - val_loss: 605.8383\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7659 - val_loss: 605.8376\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7662 - val_loss: 605.8367\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7664 - val_loss: 605.8358\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7667 - val_loss: 605.8351\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7669 - val_loss: 605.8344\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 8.7671 - val_loss: 605.8334\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7674 - val_loss: 605.8329\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7676 - val_loss: 605.8321\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7679 - val_loss: 605.8312\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7681 - val_loss: 605.8304\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7683 - val_loss: 605.8297\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7686 - val_loss: 605.8291\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7688 - val_loss: 605.8284\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7690 - val_loss: 605.8276\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7692 - val_loss: 605.8270\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7695 - val_loss: 605.8260\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7697 - val_loss: 605.8251\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7699 - val_loss: 605.8245\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7701 - val_loss: 605.8238\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7703 - val_loss: 605.8229\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7705 - val_loss: 605.8221\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7708 - val_loss: 605.8215\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7709 - val_loss: 605.8210\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7711 - val_loss: 605.8201\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 8.7714 - val_loss: 605.8196\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7716 - val_loss: 605.8191\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 8.7717 - val_loss: 605.8184\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7719 - val_loss: 605.8176\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7721 - val_loss: 605.8168\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7723 - val_loss: 605.8163\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.7725 - val_loss: 605.8159\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7727 - val_loss: 605.8152\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7729 - val_loss: 605.8148\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7730 - val_loss: 605.8142\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7732 - val_loss: 605.8138\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7734 - val_loss: 605.8130\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7736 - val_loss: 605.8125\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7737 - val_loss: 605.8119\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.7739 - val_loss: 605.8114\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(88.0403, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0012, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0120, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.0334, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 339ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.28577731e+01, 7.28213585e+01, 7.27849440e+01, 7.27485294e+01,\n",
       "        7.27121149e+01, 7.26757003e+01, 7.26392857e+01, 7.26028711e+01,\n",
       "        7.25664566e+01, 7.25300420e+01, 7.24965686e+01, 7.24769608e+01,\n",
       "        7.24573529e+01, 7.55080299e+01, 7.54304435e+01, 7.53514519e+01,\n",
       "        7.52724603e+01, 7.51934687e+01, 7.51144771e+01, 7.50354855e+01,\n",
       "        7.49564939e+01, 7.48775023e+01, 7.47985107e+01, 7.47195191e+01,\n",
       "        7.46405275e+01, 7.45615360e+01, 7.45385761e+01, 7.45167274e+01,\n",
       "        7.44948786e+01, 7.44730299e+01, 7.44511811e+01, 7.44293324e+01,\n",
       "        7.44074837e+01, 7.43856349e+01, 7.43637862e+01, 7.43419374e+01,\n",
       "        7.43200887e+01, 7.42966153e+01, 7.42545985e+01, 7.42125817e+01,\n",
       "        3.16889050e-01, 0.00000000e+00, 0.00000000e+00, 3.13628440e-01,\n",
       "        9.75417440e-01, 0.00000000e+00, 0.00000000e+00, 7.45790896e+01,\n",
       "        7.45434314e+01, 7.45215826e+01, 7.44997339e+01, 7.44778852e+01,\n",
       "        7.44560364e+01, 7.44341877e+01, 7.44123389e+01, 7.43904902e+01,\n",
       "        7.43686415e+01, 7.43467927e+01, 7.43249440e+01, 7.43030952e+01,\n",
       "        7.42639356e+01, 7.42219188e+01, 7.41799020e+01, 7.41378852e+01,\n",
       "        7.40958684e+01, 7.40538515e+01, 7.40118347e+01, 7.39698179e+01,\n",
       "        7.39278011e+01, 7.38857843e+01, 7.38437675e+01, 7.38017507e+01,\n",
       "        7.36953081e+01, 7.86581497e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.32386131e+01, 0.00000000e+00, 1.42701268e-01, 2.18327343e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.05788219e-01, 0.00000000e+00, 5.38458005e-02, 6.89214468e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.24088746e-01, 4.89864558e-01, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70.54098973, 70.53352007, 70.52605042, 70.51858077, 70.51111111,\n",
       "       70.50364146, 70.4961718 , 70.48870215, 70.48123249, 70.47376284,\n",
       "       70.46629318, 70.45882353, 70.45135387, 70.44388422, 70.43641457,\n",
       "       70.42894491, 70.42147526, 70.4140056 , 70.40653595, 70.39935808,\n",
       "       70.39422269, 70.3890873 , 70.38395191, 70.37881653, 70.37368114,\n",
       "       70.36854575, 70.36341036, 70.35827498, 70.35313959, 70.3480042 ,\n",
       "       70.34286881, 70.33773343, 70.33259804, 70.32746265, 70.32232726,\n",
       "       70.31719188, 70.31205649, 70.3069211 , 70.30178571, 70.29665033,\n",
       "       70.29151494, 70.28637955, 70.28124416, 70.27610878, 70.27097339,\n",
       "       70.265838  , 70.26070261, 70.25556723, 70.25043184, 70.24529645,\n",
       "       70.24016106, 70.23502568, 70.22989029, 70.2247549 , 70.21961951,\n",
       "       70.21448413, 70.20934874, 70.20421335, 70.19907796, 70.19394258,\n",
       "       70.18880719, 70.1836718 , 70.17853641, 70.17340103, 70.16826564,\n",
       "       70.16313025, 70.15799486, 70.15285948, 70.14772409, 70.1425887 ,\n",
       "       70.13745331, 70.13231793, 70.12718254, 70.12204715, 70.11691176,\n",
       "       70.11177638, 70.10664099, 70.1015056 , 70.09637021, 70.09123483,\n",
       "       70.08609944, 70.08096405, 70.07582866, 70.07069328, 70.06555789,\n",
       "       70.0604225 , 70.05528711, 70.05015173, 70.04501634, 70.03988095,\n",
       "       70.03474556, 70.02961018, 70.02447479, 70.0193394 , 70.01420401,\n",
       "       70.00906863, 70.00393324, 69.99879785, 69.99366246, 69.98852708])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.77023589044184\n",
      "25.152666405682698\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
