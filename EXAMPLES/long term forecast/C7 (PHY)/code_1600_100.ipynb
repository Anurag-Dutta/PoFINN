{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "1695    68.709034\n",
       "1696    68.708100\n",
       "1697    68.707166\n",
       "1698    68.706232\n",
       "1699    68.705299\n",
       "Name: C7, Length: 1700, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c7_interpolated_1600_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "1595     0.508596\n",
       "1596     0.585035\n",
       "1597     0.000000\n",
       "1598     0.000000\n",
       "1599     0.000000\n",
       "Name: C7, Length: 1600, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1600)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.387115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.174230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.961345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.748459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     92.600000  0.000298\n",
       "1     92.387115  0.000298\n",
       "2     92.174230  0.000297\n",
       "3     91.961345  0.000297\n",
       "4     91.748459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 89.3180  # Value for C0\n",
    "K0 = -0.0010  # Value for K0\n",
    "K1 = 0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = -0.0204    # Value for b\n",
    "c = 2.2194    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    92.600000    92.387115    92.174230    91.961345    91.748459   \n",
      "351    92.387115    92.174230    91.961345    91.748459    91.535574   \n",
      "352    92.174230    91.961345    91.748459    91.535574    91.322689   \n",
      "353    91.961345    91.748459    91.535574    91.322689    91.109804   \n",
      "354    91.748459    91.535574    91.322689    91.109804    90.896919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    91.535574    91.322689    91.109804    90.896919    90.691597  ...   \n",
      "351    91.322689    91.109804    90.896919    90.691597    90.579552  ...   \n",
      "352    91.109804    90.896919    90.691597    90.579552    90.467507  ...   \n",
      "353    90.896919    90.691597    90.579552    90.467507    90.355462  ...   \n",
      "354    90.691597    90.579552    90.467507    90.355462    90.243417  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   80.261671    0.000263   80.252334    0.000263   80.242997    0.000263   \n",
      "351   80.252334    0.000263   80.242997    0.000263   80.233660    0.000262   \n",
      "352   80.242997    0.000263   80.233660    0.000262   80.224323    0.000262   \n",
      "353   80.233660    0.000262   80.224323    0.000262   80.214986    0.000262   \n",
      "354   80.224323    0.000262   80.214986    0.000262   80.205649    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   80.233660    0.000262   80.224323    0.000262  \n",
      "351   80.224323    0.000262   80.214986    0.000262  \n",
      "352   80.214986    0.000262   80.205649    0.000262  \n",
      "353   80.205649    0.000262   80.196312    0.000262  \n",
      "354   80.196312    0.000262   80.186975    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1150, 1, 251) (1150, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "15/15 [==============================] - 3s 67ms/step - loss: 5941.3999 - val_loss: 4912.1938\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5834.3130 - val_loss: 4846.8936\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5762.7896 - val_loss: 4781.4990\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 5691.5850 - val_loss: 4716.7109\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5621.0522 - val_loss: 4652.6001\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 5551.2212 - val_loss: 4589.1655\n",
      "Epoch 7/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5482.0786 - val_loss: 4526.3882\n",
      "Epoch 8/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5413.6113 - val_loss: 4464.2568\n",
      "Epoch 9/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 5345.8042 - val_loss: 4402.7612\n",
      "Epoch 10/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5278.6509 - val_loss: 4341.8940\n",
      "Epoch 11/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 5212.1392 - val_loss: 4281.6460\n",
      "Epoch 12/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 5146.2656 - val_loss: 4222.0132\n",
      "Epoch 13/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5081.0234 - val_loss: 4162.9883\n",
      "Epoch 14/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5016.4048 - val_loss: 4104.5669\n",
      "Epoch 15/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4952.4077 - val_loss: 4046.7437\n",
      "Epoch 16/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4889.0244 - val_loss: 3989.5142\n",
      "Epoch 17/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 4826.2510 - val_loss: 3932.8730\n",
      "Epoch 18/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4764.0835 - val_loss: 3876.8167\n",
      "Epoch 19/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4702.5156 - val_loss: 3821.3394\n",
      "Epoch 20/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4641.5449 - val_loss: 3766.4377\n",
      "Epoch 21/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4581.1665 - val_loss: 3712.1074\n",
      "Epoch 22/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4521.3750 - val_loss: 3658.3440\n",
      "Epoch 23/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4462.1665 - val_loss: 3605.1428\n",
      "Epoch 24/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4403.5381 - val_loss: 3552.5005\n",
      "Epoch 25/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4345.4839 - val_loss: 3500.4131\n",
      "Epoch 26/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4288.0010 - val_loss: 3448.8755\n",
      "Epoch 27/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4231.0854 - val_loss: 3397.8848\n",
      "Epoch 28/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4174.7319 - val_loss: 3347.4370\n",
      "Epoch 29/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4118.9385 - val_loss: 3297.5278\n",
      "Epoch 30/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 4063.6990 - val_loss: 3248.1533\n",
      "Epoch 31/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 4009.0120 - val_loss: 3199.3098\n",
      "Epoch 32/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3954.8716 - val_loss: 3150.9941\n",
      "Epoch 33/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3901.2742 - val_loss: 3103.2012\n",
      "Epoch 34/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3848.2170 - val_loss: 3055.9280\n",
      "Epoch 35/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3795.6956 - val_loss: 3009.1707\n",
      "Epoch 36/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3743.7065 - val_loss: 2962.9248\n",
      "Epoch 37/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 3692.2454 - val_loss: 2917.1880\n",
      "Epoch 38/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3641.3101 - val_loss: 2871.9561\n",
      "Epoch 39/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3590.8953 - val_loss: 2827.2251\n",
      "Epoch 40/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3540.9973 - val_loss: 2782.9924\n",
      "Epoch 41/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3491.6145 - val_loss: 2739.2532\n",
      "Epoch 42/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3442.7407 - val_loss: 2696.0054\n",
      "Epoch 43/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3394.3745 - val_loss: 2653.2424\n",
      "Epoch 44/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3346.5110 - val_loss: 2610.9646\n",
      "Epoch 45/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3299.1472 - val_loss: 2569.1660\n",
      "Epoch 46/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3252.2793 - val_loss: 2527.8438\n",
      "Epoch 47/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3205.9045 - val_loss: 2486.9941\n",
      "Epoch 48/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3160.0190 - val_loss: 2446.6145\n",
      "Epoch 49/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3114.6184 - val_loss: 2406.7002\n",
      "Epoch 50/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3069.7002 - val_loss: 2367.2483\n",
      "Epoch 51/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3025.2605 - val_loss: 2328.2563\n",
      "Epoch 52/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2981.2979 - val_loss: 2289.7202\n",
      "Epoch 53/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2937.8059 - val_loss: 2251.6362\n",
      "Epoch 54/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2894.7837 - val_loss: 2214.0020\n",
      "Epoch 55/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2852.2261 - val_loss: 2176.8132\n",
      "Epoch 56/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2810.1306 - val_loss: 2140.0671\n",
      "Epoch 57/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2768.4949 - val_loss: 2103.7603\n",
      "Epoch 58/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2727.3142 - val_loss: 2067.8889\n",
      "Epoch 59/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2686.5859 - val_loss: 2032.4512\n",
      "Epoch 60/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2646.3059 - val_loss: 1997.4423\n",
      "Epoch 61/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 2606.4729 - val_loss: 1962.8601\n",
      "Epoch 62/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2567.0815 - val_loss: 1928.7006\n",
      "Epoch 63/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2528.1299 - val_loss: 1894.9613\n",
      "Epoch 64/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2489.6145 - val_loss: 1861.6383\n",
      "Epoch 65/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2451.5327 - val_loss: 1828.7295\n",
      "Epoch 66/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2413.8804 - val_loss: 1796.2316\n",
      "Epoch 67/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2376.6548 - val_loss: 1764.1401\n",
      "Epoch 68/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2339.8535 - val_loss: 1732.4529\n",
      "Epoch 69/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2303.4729 - val_loss: 1701.1674\n",
      "Epoch 70/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2267.5090 - val_loss: 1670.2802\n",
      "Epoch 71/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2231.9597 - val_loss: 1639.7870\n",
      "Epoch 72/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2196.8225 - val_loss: 1609.6855\n",
      "Epoch 73/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2162.0933 - val_loss: 1579.9744\n",
      "Epoch 74/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2127.7695 - val_loss: 1550.6481\n",
      "Epoch 75/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2093.8479 - val_loss: 1521.7041\n",
      "Epoch 76/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2060.3259 - val_loss: 1493.1414\n",
      "Epoch 77/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2027.1998 - val_loss: 1464.9543\n",
      "Epoch 78/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1994.4673 - val_loss: 1437.1415\n",
      "Epoch 79/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1962.1248 - val_loss: 1409.6991\n",
      "Epoch 80/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1930.1703 - val_loss: 1382.6250\n",
      "Epoch 81/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1898.6001 - val_loss: 1355.9160\n",
      "Epoch 82/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1867.4119 - val_loss: 1329.5693\n",
      "Epoch 83/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1836.6022 - val_loss: 1303.5815\n",
      "Epoch 84/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1806.1682 - val_loss: 1277.9504\n",
      "Epoch 85/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1776.1077 - val_loss: 1252.6722\n",
      "Epoch 86/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1746.4167 - val_loss: 1227.7449\n",
      "Epoch 87/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1717.0934 - val_loss: 1203.1655\n",
      "Epoch 88/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1688.1343 - val_loss: 1178.9298\n",
      "Epoch 89/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1659.5363 - val_loss: 1155.0372\n",
      "Epoch 90/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1631.2976 - val_loss: 1131.4822\n",
      "Epoch 91/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1603.4143 - val_loss: 1108.2650\n",
      "Epoch 92/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1575.8848 - val_loss: 1085.3807\n",
      "Epoch 93/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1548.7052 - val_loss: 1062.8268\n",
      "Epoch 94/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1521.8737 - val_loss: 1040.6011\n",
      "Epoch 95/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1495.3862 - val_loss: 1018.7005\n",
      "Epoch 96/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1469.2415 - val_loss: 997.1220\n",
      "Epoch 97/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1443.4352 - val_loss: 975.8629\n",
      "Epoch 98/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1417.9661 - val_loss: 954.9206\n",
      "Epoch 99/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1392.8309 - val_loss: 934.2928\n",
      "Epoch 100/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1368.0266 - val_loss: 913.9762\n",
      "Epoch 101/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1343.5511 - val_loss: 893.9683\n",
      "Epoch 102/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1319.4008 - val_loss: 874.2657\n",
      "Epoch 103/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1295.5732 - val_loss: 854.8661\n",
      "Epoch 104/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1272.0665 - val_loss: 835.7678\n",
      "Epoch 105/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1248.8777 - val_loss: 816.9668\n",
      "Epoch 106/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1226.0035 - val_loss: 798.4603\n",
      "Epoch 107/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1203.4419 - val_loss: 780.2474\n",
      "Epoch 108/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1181.1902 - val_loss: 762.3237\n",
      "Epoch 109/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1159.2455 - val_loss: 744.6871\n",
      "Epoch 110/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1137.6051 - val_loss: 727.3345\n",
      "Epoch 111/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1116.2667 - val_loss: 710.2637\n",
      "Epoch 112/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1095.2274 - val_loss: 693.4725\n",
      "Epoch 113/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1074.4849 - val_loss: 676.9581\n",
      "Epoch 114/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1054.0365 - val_loss: 660.7173\n",
      "Epoch 115/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1033.8796 - val_loss: 644.7476\n",
      "Epoch 116/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1014.0124 - val_loss: 629.0470\n",
      "Epoch 117/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 994.4310 - val_loss: 613.6123\n",
      "Epoch 118/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 975.1332 - val_loss: 598.4410\n",
      "Epoch 119/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 956.1170 - val_loss: 583.5311\n",
      "Epoch 120/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 937.3795 - val_loss: 568.8795\n",
      "Epoch 121/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 918.9181 - val_loss: 554.4835\n",
      "Epoch 122/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 900.7307 - val_loss: 540.3409\n",
      "Epoch 123/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 882.8145 - val_loss: 526.4493\n",
      "Epoch 124/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 865.1671 - val_loss: 512.8051\n",
      "Epoch 125/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 847.7855 - val_loss: 499.4075\n",
      "Epoch 126/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 830.6675 - val_loss: 486.2526\n",
      "Epoch 127/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 813.8113 - val_loss: 473.3383\n",
      "Epoch 128/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 797.2138 - val_loss: 460.6622\n",
      "Epoch 129/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 780.8726 - val_loss: 448.2220\n",
      "Epoch 130/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 764.7850 - val_loss: 436.0148\n",
      "Epoch 131/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 748.9493 - val_loss: 424.0382\n",
      "Epoch 132/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 733.3622 - val_loss: 412.2902\n",
      "Epoch 133/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 718.0216 - val_loss: 400.7672\n",
      "Epoch 134/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 702.9253 - val_loss: 389.4681\n",
      "Epoch 135/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 688.0709 - val_loss: 378.3894\n",
      "Epoch 136/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 673.4556 - val_loss: 367.5294\n",
      "Epoch 137/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 659.0770 - val_loss: 356.8844\n",
      "Epoch 138/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 644.9331 - val_loss: 346.4535\n",
      "Epoch 139/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 631.0212 - val_loss: 336.2336\n",
      "Epoch 140/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 617.3389 - val_loss: 326.2222\n",
      "Epoch 141/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 603.8840 - val_loss: 316.4177\n",
      "Epoch 142/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 590.6544 - val_loss: 306.8161\n",
      "Epoch 143/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 577.6473 - val_loss: 297.4158\n",
      "Epoch 144/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 564.8604 - val_loss: 288.2151\n",
      "Epoch 145/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 552.2915 - val_loss: 279.2108\n",
      "Epoch 146/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 539.9381 - val_loss: 270.4012\n",
      "Epoch 147/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 527.7981 - val_loss: 261.7822\n",
      "Epoch 148/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 515.8685 - val_loss: 253.3533\n",
      "Epoch 149/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 504.1477 - val_loss: 245.1115\n",
      "Epoch 150/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 492.6334 - val_loss: 237.0549\n",
      "Epoch 151/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 481.3230 - val_loss: 229.1801\n",
      "Epoch 152/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 470.2142 - val_loss: 221.4858\n",
      "Epoch 153/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 459.3047 - val_loss: 213.9687\n",
      "Epoch 154/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 448.5925 - val_loss: 206.6275\n",
      "Epoch 155/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 438.0750 - val_loss: 199.4597\n",
      "Epoch 156/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 427.7501 - val_loss: 192.4624\n",
      "Epoch 157/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 417.6157 - val_loss: 185.6333\n",
      "Epoch 158/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 407.6694 - val_loss: 178.9709\n",
      "Epoch 159/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 397.9087 - val_loss: 172.4720\n",
      "Epoch 160/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 388.3318 - val_loss: 166.1349\n",
      "Epoch 161/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 378.9361 - val_loss: 159.9574\n",
      "Epoch 162/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 369.7196 - val_loss: 153.9373\n",
      "Epoch 163/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 360.6803 - val_loss: 148.0718\n",
      "Epoch 164/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 351.8157 - val_loss: 142.3589\n",
      "Epoch 165/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 343.1235 - val_loss: 136.7965\n",
      "Epoch 166/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 334.6021 - val_loss: 131.3826\n",
      "Epoch 167/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 326.2486 - val_loss: 126.1149\n",
      "Epoch 168/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 318.0613 - val_loss: 120.9910\n",
      "Epoch 169/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 310.0379 - val_loss: 116.0083\n",
      "Epoch 170/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 302.1763 - val_loss: 111.1654\n",
      "Epoch 171/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 294.4745 - val_loss: 106.4597\n",
      "Epoch 172/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 286.9297 - val_loss: 101.8889\n",
      "Epoch 173/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 279.5406 - val_loss: 97.4510\n",
      "Epoch 174/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 272.3046 - val_loss: 93.1443\n",
      "Epoch 175/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 265.2200 - val_loss: 88.9660\n",
      "Epoch 176/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 258.2842 - val_loss: 84.9143\n",
      "Epoch 177/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 251.4953 - val_loss: 80.9871\n",
      "Epoch 178/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 244.8515 - val_loss: 77.1820\n",
      "Epoch 179/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 238.3505 - val_loss: 73.4976\n",
      "Epoch 180/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 231.9902 - val_loss: 69.9307\n",
      "Epoch 181/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 225.7687 - val_loss: 66.4807\n",
      "Epoch 182/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 219.6840 - val_loss: 63.1443\n",
      "Epoch 183/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 213.7339 - val_loss: 59.9197\n",
      "Epoch 184/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 207.9164 - val_loss: 56.8055\n",
      "Epoch 185/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 202.2298 - val_loss: 53.7991\n",
      "Epoch 186/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 196.6721 - val_loss: 50.8984\n",
      "Epoch 187/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 191.2408 - val_loss: 48.1019\n",
      "Epoch 188/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 185.9343 - val_loss: 45.4072\n",
      "Epoch 189/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 180.7506 - val_loss: 42.8123\n",
      "Epoch 190/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 175.6877 - val_loss: 40.3157\n",
      "Epoch 191/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 170.7437 - val_loss: 37.9151\n",
      "Epoch 192/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 165.9169 - val_loss: 35.6086\n",
      "Epoch 193/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 161.2051 - val_loss: 33.3944\n",
      "Epoch 194/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 156.6066 - val_loss: 31.2702\n",
      "Epoch 195/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 152.1195 - val_loss: 29.2347\n",
      "Epoch 196/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 147.7417 - val_loss: 27.2857\n",
      "Epoch 197/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 143.4716 - val_loss: 25.4212\n",
      "Epoch 198/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 139.3072 - val_loss: 23.6396\n",
      "Epoch 199/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 135.2465 - val_loss: 21.9391\n",
      "Epoch 200/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 131.2882 - val_loss: 20.3175\n",
      "Epoch 201/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 127.4301 - val_loss: 18.7733\n",
      "Epoch 202/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 123.6704 - val_loss: 17.3047\n",
      "Epoch 203/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 120.0075 - val_loss: 15.9100\n",
      "Epoch 204/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 116.4395 - val_loss: 14.5872\n",
      "Epoch 205/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 112.9648 - val_loss: 13.3347\n",
      "Epoch 206/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 109.5816 - val_loss: 12.1508\n",
      "Epoch 207/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 106.2882 - val_loss: 11.0337\n",
      "Epoch 208/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 103.0828 - val_loss: 9.9819\n",
      "Epoch 209/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 99.9640 - val_loss: 8.9936\n",
      "Epoch 210/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 96.9299 - val_loss: 8.0670\n",
      "Epoch 211/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 93.9785 - val_loss: 7.2007\n",
      "Epoch 212/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 91.1086 - val_loss: 6.3928\n",
      "Epoch 213/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 88.3185 - val_loss: 5.6420\n",
      "Epoch 214/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 85.6066 - val_loss: 4.9466\n",
      "Epoch 215/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 82.9714 - val_loss: 4.3050\n",
      "Epoch 216/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 80.4109 - val_loss: 3.7157\n",
      "Epoch 217/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 77.9240 - val_loss: 3.1770\n",
      "Epoch 218/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 75.5089 - val_loss: 2.6876\n",
      "Epoch 219/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 73.1642 - val_loss: 2.2459\n",
      "Epoch 220/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 70.8882 - val_loss: 1.8505\n",
      "Epoch 221/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 68.6797 - val_loss: 1.5000\n",
      "Epoch 222/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 66.5372 - val_loss: 1.1928\n",
      "Epoch 223/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 64.4589 - val_loss: 0.9275\n",
      "Epoch 224/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 62.4436 - val_loss: 0.7028\n",
      "Epoch 225/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 60.4899 - val_loss: 0.5172\n",
      "Epoch 226/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 58.5962 - val_loss: 0.3695\n",
      "Epoch 227/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 56.7613 - val_loss: 0.2583\n",
      "Epoch 228/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 54.9838 - val_loss: 0.1823\n",
      "Epoch 229/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 53.2622 - val_loss: 0.1402\n",
      "Epoch 230/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 51.5954 - val_loss: 0.1306\n",
      "Epoch 231/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 49.9817 - val_loss: 0.1525\n",
      "Epoch 232/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 48.4201 - val_loss: 0.2045\n",
      "Epoch 233/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 46.9092 - val_loss: 0.2854\n",
      "Epoch 234/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 45.4480 - val_loss: 0.3940\n",
      "Epoch 235/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 44.0349 - val_loss: 0.5292\n",
      "Epoch 236/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 42.6688 - val_loss: 0.6899\n",
      "Epoch 237/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 41.3485 - val_loss: 0.8748\n",
      "Epoch 238/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 40.0728 - val_loss: 1.0830\n",
      "Epoch 239/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 38.8407 - val_loss: 1.3132\n",
      "Epoch 240/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 37.6507 - val_loss: 1.5645\n",
      "Epoch 241/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 36.5021 - val_loss: 1.8358\n",
      "Epoch 242/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 35.3934 - val_loss: 2.1261\n",
      "Epoch 243/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 34.3238 - val_loss: 2.4344\n",
      "Epoch 244/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 33.2919 - val_loss: 2.7598\n",
      "Epoch 245/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 32.2968 - val_loss: 3.1013\n",
      "Epoch 246/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 31.3376 - val_loss: 3.4579\n",
      "Epoch 247/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 30.4130 - val_loss: 3.8288\n",
      "Epoch 248/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 29.5222 - val_loss: 4.2130\n",
      "Epoch 249/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 28.6641 - val_loss: 4.6097\n",
      "Epoch 250/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 27.8379 - val_loss: 5.0181\n",
      "Epoch 251/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 27.0426 - val_loss: 5.4373\n",
      "Epoch 252/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 26.2772 - val_loss: 5.8666\n",
      "Epoch 253/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 25.5408 - val_loss: 6.3050\n",
      "Epoch 254/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 24.8327 - val_loss: 6.7518\n",
      "Epoch 255/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 24.1517 - val_loss: 7.2067\n",
      "Epoch 256/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 23.4971 - val_loss: 7.6683\n",
      "Epoch 257/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 22.8682 - val_loss: 8.1364\n",
      "Epoch 258/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 22.2641 - val_loss: 8.6102\n",
      "Epoch 259/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 21.6838 - val_loss: 9.0889\n",
      "Epoch 260/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 21.1268 - val_loss: 9.5719\n",
      "Epoch 261/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 20.5922 - val_loss: 10.0588\n",
      "Epoch 262/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 20.0793 - val_loss: 10.5488\n",
      "Epoch 263/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 19.5875 - val_loss: 11.0415\n",
      "Epoch 264/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 19.1157 - val_loss: 11.5362\n",
      "Epoch 265/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 18.6634 - val_loss: 12.0323\n",
      "Epoch 266/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 18.2301 - val_loss: 12.5296\n",
      "Epoch 267/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 17.8150 - val_loss: 13.0274\n",
      "Epoch 268/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 17.4174 - val_loss: 13.5251\n",
      "Epoch 269/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 17.0368 - val_loss: 14.0225\n",
      "Epoch 270/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 16.6725 - val_loss: 14.5190\n",
      "Epoch 271/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 16.3240 - val_loss: 15.0141\n",
      "Epoch 272/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 15.9907 - val_loss: 15.5077\n",
      "Epoch 273/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 15.6719 - val_loss: 15.9990\n",
      "Epoch 274/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 15.3672 - val_loss: 16.4879\n",
      "Epoch 275/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 15.0761 - val_loss: 16.9740\n",
      "Epoch 276/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 14.7980 - val_loss: 17.4570\n",
      "Epoch 277/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 14.5325 - val_loss: 17.9364\n",
      "Epoch 278/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 14.2790 - val_loss: 18.4123\n",
      "Epoch 279/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 14.0370 - val_loss: 18.8840\n",
      "Epoch 280/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 13.8061 - val_loss: 19.3514\n",
      "Epoch 281/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 13.5860 - val_loss: 19.8141\n",
      "Epoch 282/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 13.3760 - val_loss: 20.2722\n",
      "Epoch 283/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 13.1759 - val_loss: 20.7252\n",
      "Epoch 284/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 12.9852 - val_loss: 21.1729\n",
      "Epoch 285/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 12.8035 - val_loss: 21.6153\n",
      "Epoch 286/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 12.6304 - val_loss: 22.0521\n",
      "Epoch 287/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 12.4657 - val_loss: 22.4830\n",
      "Epoch 288/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 12.3089 - val_loss: 22.9078\n",
      "Epoch 289/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 12.1598 - val_loss: 23.3266\n",
      "Epoch 290/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 12.0179 - val_loss: 23.7392\n",
      "Epoch 291/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.8830 - val_loss: 24.1455\n",
      "Epoch 292/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.7547 - val_loss: 24.5454\n",
      "Epoch 293/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 11.6328 - val_loss: 24.9386\n",
      "Epoch 294/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.5170 - val_loss: 25.3255\n",
      "Epoch 295/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.4070 - val_loss: 25.7052\n",
      "Epoch 296/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.3025 - val_loss: 26.0784\n",
      "Epoch 297/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.2033 - val_loss: 26.4446\n",
      "Epoch 298/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 11.1092 - val_loss: 26.8042\n",
      "Epoch 299/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.0199 - val_loss: 27.1565\n",
      "Epoch 300/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.9352 - val_loss: 27.5018\n",
      "Epoch 301/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 10.8550 - val_loss: 27.8404\n",
      "Epoch 302/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.7788 - val_loss: 28.1720\n",
      "Epoch 303/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.7066 - val_loss: 28.4965\n",
      "Epoch 304/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 10.6382 - val_loss: 28.8139\n",
      "Epoch 305/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 10.5734 - val_loss: 29.1244\n",
      "Epoch 306/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 10.5121 - val_loss: 29.4281\n",
      "Epoch 307/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 10.4539 - val_loss: 29.7248\n",
      "Epoch 308/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 10.3989 - val_loss: 30.0148\n",
      "Epoch 309/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 10.3468 - val_loss: 30.2976\n",
      "Epoch 310/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 10.2975 - val_loss: 30.5737\n",
      "Epoch 311/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 10.2508 - val_loss: 30.8431\n",
      "Epoch 312/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 10.2067 - val_loss: 31.1059\n",
      "Epoch 313/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 10.1649 - val_loss: 31.3620\n",
      "Epoch 314/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 10.1254 - val_loss: 31.6116\n",
      "Epoch 315/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.0882 - val_loss: 31.8547\n",
      "Epoch 316/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.0528 - val_loss: 32.0910\n",
      "Epoch 317/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 10.0195 - val_loss: 32.3211\n",
      "Epoch 318/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.9880 - val_loss: 32.5452\n",
      "Epoch 319/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.9582 - val_loss: 32.7632\n",
      "Epoch 320/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.9300 - val_loss: 32.9743\n",
      "Epoch 321/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.9034 - val_loss: 33.1801\n",
      "Epoch 322/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.8783 - val_loss: 33.3799\n",
      "Epoch 323/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 9.8546 - val_loss: 33.5736\n",
      "Epoch 324/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 9.8322 - val_loss: 33.7619\n",
      "Epoch 325/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 9.8110 - val_loss: 33.9443\n",
      "Epoch 326/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.7910 - val_loss: 34.1211\n",
      "Epoch 327/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.7721 - val_loss: 34.2927\n",
      "Epoch 328/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.7543 - val_loss: 34.4588\n",
      "Epoch 329/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.7375 - val_loss: 34.6195\n",
      "Epoch 330/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.7216 - val_loss: 34.7751\n",
      "Epoch 331/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 9.7066 - val_loss: 34.9257\n",
      "Epoch 332/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 9.6925 - val_loss: 35.0717\n",
      "Epoch 333/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 9.6791 - val_loss: 35.2121\n",
      "Epoch 334/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 9.6665 - val_loss: 35.3485\n",
      "Epoch 335/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 9.6546 - val_loss: 35.4800\n",
      "Epoch 336/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 9.6434 - val_loss: 35.6074\n",
      "Epoch 337/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 9.6328 - val_loss: 35.7297\n",
      "Epoch 338/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 9.6228 - val_loss: 35.8482\n",
      "Epoch 339/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 9.6133 - val_loss: 35.9620\n",
      "Epoch 340/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.6045 - val_loss: 36.0722\n",
      "Epoch 341/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.5961 - val_loss: 36.1783\n",
      "Epoch 342/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.5881 - val_loss: 36.2804\n",
      "Epoch 343/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 9.5807 - val_loss: 36.3789\n",
      "Epoch 344/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 9.5736 - val_loss: 36.4737\n",
      "Epoch 345/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 9.5669 - val_loss: 36.5649\n",
      "Epoch 346/500\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 9.5606 - val_loss: 36.6526\n",
      "Epoch 347/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 9.5547 - val_loss: 36.7367\n",
      "Epoch 348/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 9.5491 - val_loss: 36.8181\n",
      "Epoch 349/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.5438 - val_loss: 36.8960\n",
      "Epoch 350/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.5388 - val_loss: 36.9710\n",
      "Epoch 351/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.5341 - val_loss: 37.0425\n",
      "Epoch 352/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 9.5297 - val_loss: 37.1115\n",
      "Epoch 353/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.5255 - val_loss: 37.1780\n",
      "Epoch 354/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.5215 - val_loss: 37.2414\n",
      "Epoch 355/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.5178 - val_loss: 37.3021\n",
      "Epoch 356/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.5142 - val_loss: 37.3603\n",
      "Epoch 357/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.5109 - val_loss: 37.4162\n",
      "Epoch 358/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.5078 - val_loss: 37.4695\n",
      "Epoch 359/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.5048 - val_loss: 37.5208\n",
      "Epoch 360/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.5021 - val_loss: 37.5696\n",
      "Epoch 361/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 9.4994 - val_loss: 37.6165\n",
      "Epoch 362/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4969 - val_loss: 37.6613\n",
      "Epoch 363/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 9.4946 - val_loss: 37.7039\n",
      "Epoch 364/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4924 - val_loss: 37.7448\n",
      "Epoch 365/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4903 - val_loss: 37.7836\n",
      "Epoch 366/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 9.4884 - val_loss: 37.8207\n",
      "Epoch 367/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4865 - val_loss: 37.8563\n",
      "Epoch 368/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4848 - val_loss: 37.8896\n",
      "Epoch 369/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4832 - val_loss: 37.9218\n",
      "Epoch 370/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4816 - val_loss: 37.9522\n",
      "Epoch 371/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4802 - val_loss: 37.9815\n",
      "Epoch 372/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4789 - val_loss: 38.0090\n",
      "Epoch 373/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4776 - val_loss: 38.0354\n",
      "Epoch 374/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 9.4765 - val_loss: 38.0604\n",
      "Epoch 375/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4753 - val_loss: 38.0841\n",
      "Epoch 376/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4743 - val_loss: 38.1070\n",
      "Epoch 377/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4734 - val_loss: 38.1286\n",
      "Epoch 378/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4724 - val_loss: 38.1489\n",
      "Epoch 379/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4716 - val_loss: 38.1683\n",
      "Epoch 380/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4708 - val_loss: 38.1866\n",
      "Epoch 381/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4700 - val_loss: 38.2039\n",
      "Epoch 382/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4694 - val_loss: 38.2203\n",
      "Epoch 383/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4688 - val_loss: 38.2359\n",
      "Epoch 384/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4681 - val_loss: 38.2507\n",
      "Epoch 385/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4676 - val_loss: 38.2649\n",
      "Epoch 386/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4671 - val_loss: 38.2780\n",
      "Epoch 387/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4666 - val_loss: 38.2902\n",
      "Epoch 388/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4662 - val_loss: 38.3021\n",
      "Epoch 389/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4658 - val_loss: 38.3132\n",
      "Epoch 390/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 9.4654 - val_loss: 38.3239\n",
      "Epoch 391/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4651 - val_loss: 38.3333\n",
      "Epoch 392/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 9.4648 - val_loss: 38.3429\n",
      "Epoch 393/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4645 - val_loss: 38.3516\n",
      "Epoch 394/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4643 - val_loss: 38.3598\n",
      "Epoch 395/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4641 - val_loss: 38.3675\n",
      "Epoch 396/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4638 - val_loss: 38.3748\n",
      "Epoch 397/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4637 - val_loss: 38.3820\n",
      "Epoch 398/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4635 - val_loss: 38.3883\n",
      "Epoch 399/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4634 - val_loss: 38.3944\n",
      "Epoch 400/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4633 - val_loss: 38.4000\n",
      "Epoch 401/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4632 - val_loss: 38.4057\n",
      "Epoch 402/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4631 - val_loss: 38.4104\n",
      "Epoch 403/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4631 - val_loss: 38.4150\n",
      "Epoch 404/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4630 - val_loss: 38.4193\n",
      "Epoch 405/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 9.4630 - val_loss: 38.4238\n",
      "Epoch 406/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4630 - val_loss: 38.4274\n",
      "Epoch 407/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4629 - val_loss: 38.4307\n",
      "Epoch 408/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4630 - val_loss: 38.4339\n",
      "Epoch 409/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4630 - val_loss: 38.4368\n",
      "Epoch 410/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4630 - val_loss: 38.4397\n",
      "Epoch 411/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4631 - val_loss: 38.4422\n",
      "Epoch 412/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4631 - val_loss: 38.4448\n",
      "Epoch 413/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4632 - val_loss: 38.4466\n",
      "Epoch 414/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4633 - val_loss: 38.4486\n",
      "Epoch 415/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4634 - val_loss: 38.4503\n",
      "Epoch 416/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4635 - val_loss: 38.4523\n",
      "Epoch 417/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4636 - val_loss: 38.4536\n",
      "Epoch 418/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4637 - val_loss: 38.4551\n",
      "Epoch 419/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4638 - val_loss: 38.4565\n",
      "Epoch 420/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4639 - val_loss: 38.4575\n",
      "Epoch 421/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4640 - val_loss: 38.4585\n",
      "Epoch 422/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 9.4642 - val_loss: 38.4599\n",
      "Epoch 423/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4643 - val_loss: 38.4605\n",
      "Epoch 424/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4644 - val_loss: 38.4613\n",
      "Epoch 425/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4646 - val_loss: 38.4618\n",
      "Epoch 426/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4648 - val_loss: 38.4627\n",
      "Epoch 427/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4649 - val_loss: 38.4632\n",
      "Epoch 428/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4651 - val_loss: 38.4638\n",
      "Epoch 429/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4652 - val_loss: 38.4641\n",
      "Epoch 430/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4654 - val_loss: 38.4644\n",
      "Epoch 431/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4655 - val_loss: 38.4647\n",
      "Epoch 432/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4657 - val_loss: 38.4651\n",
      "Epoch 433/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4659 - val_loss: 38.4653\n",
      "Epoch 434/500\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.4661 - val_loss: 38.4654\n",
      "Epoch 435/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4662 - val_loss: 38.4655\n",
      "Epoch 436/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4664 - val_loss: 38.4657\n",
      "Epoch 437/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4666 - val_loss: 38.4660\n",
      "Epoch 438/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4668 - val_loss: 38.4659\n",
      "Epoch 439/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4670 - val_loss: 38.4657\n",
      "Epoch 440/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4672 - val_loss: 38.4657\n",
      "Epoch 441/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 9.4674 - val_loss: 38.4656\n",
      "Epoch 442/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4675 - val_loss: 38.4654\n",
      "Epoch 443/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4677 - val_loss: 38.4654\n",
      "Epoch 444/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4679 - val_loss: 38.4653\n",
      "Epoch 445/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4681 - val_loss: 38.4653\n",
      "Epoch 446/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4683 - val_loss: 38.4653\n",
      "Epoch 447/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4685 - val_loss: 38.4651\n",
      "Epoch 448/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4687 - val_loss: 38.4651\n",
      "Epoch 449/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4688 - val_loss: 38.4646\n",
      "Epoch 450/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4691 - val_loss: 38.4645\n",
      "Epoch 451/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4693 - val_loss: 38.4642\n",
      "Epoch 452/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4695 - val_loss: 38.4638\n",
      "Epoch 453/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4697 - val_loss: 38.4636\n",
      "Epoch 454/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4698 - val_loss: 38.4632\n",
      "Epoch 455/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4701 - val_loss: 38.4629\n",
      "Epoch 456/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4703 - val_loss: 38.4624\n",
      "Epoch 457/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4705 - val_loss: 38.4620\n",
      "Epoch 458/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4707 - val_loss: 38.4618\n",
      "Epoch 459/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4709 - val_loss: 38.4615\n",
      "Epoch 460/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 9.4711 - val_loss: 38.4613\n",
      "Epoch 461/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4713 - val_loss: 38.4609\n",
      "Epoch 462/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4715 - val_loss: 38.4606\n",
      "Epoch 463/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4717 - val_loss: 38.4603\n",
      "Epoch 464/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4719 - val_loss: 38.4600\n",
      "Epoch 465/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4721 - val_loss: 38.4598\n",
      "Epoch 466/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4723 - val_loss: 38.4593\n",
      "Epoch 467/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4725 - val_loss: 38.4589\n",
      "Epoch 468/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4727 - val_loss: 38.4584\n",
      "Epoch 469/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4729 - val_loss: 38.4579\n",
      "Epoch 470/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4731 - val_loss: 38.4576\n",
      "Epoch 471/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4733 - val_loss: 38.4574\n",
      "Epoch 472/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4735 - val_loss: 38.4569\n",
      "Epoch 473/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4737 - val_loss: 38.4566\n",
      "Epoch 474/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4739 - val_loss: 38.4563\n",
      "Epoch 475/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4741 - val_loss: 38.4558\n",
      "Epoch 476/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4743 - val_loss: 38.4557\n",
      "Epoch 477/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4745 - val_loss: 38.4551\n",
      "Epoch 478/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4747 - val_loss: 38.4549\n",
      "Epoch 479/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 9.4749 - val_loss: 38.4544\n",
      "Epoch 480/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4751 - val_loss: 38.4538\n",
      "Epoch 481/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4753 - val_loss: 38.4535\n",
      "Epoch 482/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4755 - val_loss: 38.4532\n",
      "Epoch 483/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4757 - val_loss: 38.4530\n",
      "Epoch 484/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4759 - val_loss: 38.4526\n",
      "Epoch 485/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4761 - val_loss: 38.4522\n",
      "Epoch 486/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4763 - val_loss: 38.4520\n",
      "Epoch 487/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4765 - val_loss: 38.4517\n",
      "Epoch 488/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4767 - val_loss: 38.4512\n",
      "Epoch 489/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4768 - val_loss: 38.4507\n",
      "Epoch 490/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4771 - val_loss: 38.4505\n",
      "Epoch 491/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4772 - val_loss: 38.4501\n",
      "Epoch 492/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4774 - val_loss: 38.4498\n",
      "Epoch 493/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4776 - val_loss: 38.4492\n",
      "Epoch 494/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4779 - val_loss: 38.4491\n",
      "Epoch 495/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4780 - val_loss: 38.4488\n",
      "Epoch 496/500\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.4782 - val_loss: 38.4483\n",
      "Epoch 497/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 9.4784 - val_loss: 38.4481\n",
      "Epoch 498/500\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 9.4786 - val_loss: 38.4477\n",
      "Epoch 499/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 9.4788 - val_loss: 38.4474\n",
      "Epoch 500/500\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 9.4790 - val_loss: 38.4472\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(89.3180, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0010, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(-0.0204, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.2194, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 543ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.21052591e+01, 7.20629622e+01, 7.20206653e+01, 7.19869958e+01,\n",
       "        7.19760714e+01, 7.19651471e+01, 7.19542227e+01, 7.19432983e+01,\n",
       "        7.19323739e+01, 7.19214496e+01, 7.19105252e+01, 7.18996008e+01,\n",
       "        7.18886765e+01, 7.18777521e+01, 7.18668277e+01, 7.18559034e+01,\n",
       "        7.18449790e+01, 7.18340546e+01, 7.18231303e+01, 7.18122059e+01,\n",
       "        7.18012815e+01, 7.17903571e+01, 7.17794328e+01, 7.17685084e+01,\n",
       "        7.17575840e+01, 7.17466597e+01, 7.17357353e+01, 7.17248109e+01,\n",
       "        7.17138865e+01, 7.17029622e+01, 7.16920378e+01, 7.16811134e+01,\n",
       "        7.16701891e+01, 7.16592647e+01, 7.16483403e+01, 7.16374160e+01,\n",
       "        7.16264916e+01, 7.16155672e+01, 7.16046429e+01, 7.15887255e+01,\n",
       "        7.15691176e+01, 7.15495098e+01, 7.15299020e+01, 7.15102941e+01,\n",
       "        7.14906863e+01, 7.14710784e+01, 7.14514706e+01, 7.14318627e+01,\n",
       "        7.14122549e+01, 7.13926471e+01, 7.13730392e+01, 7.13534314e+01,\n",
       "        7.13338235e+01, 7.13142157e+01, 7.12946078e+01, 7.12750000e+01,\n",
       "        7.12553922e+01, 7.12357843e+01, 7.12161765e+01, 7.11965686e+01,\n",
       "        7.11769608e+01, 7.11573529e+01, 7.11377451e+01, 7.11181373e+01,\n",
       "        7.10985294e+01, 7.10789216e+01, 7.10593137e+01, 7.10397059e+01,\n",
       "        7.10200980e+01, 7.10004902e+01, 7.09808824e+01, 7.09612745e+01,\n",
       "        7.09416667e+01, 7.09220588e+01, 7.09024510e+01, 7.08656863e+01,\n",
       "        7.08264706e+01, 7.07872549e+01, 7.07480392e+01, 7.07088235e+01,\n",
       "        7.76552277e+01, 1.29356587e+00, 5.23304760e-01, 2.51280129e-01,\n",
       "        0.00000000e+00, 4.55971301e-01, 0.00000000e+00, 4.56666648e-01,\n",
       "        6.83388785e-02, 7.14449644e-01, 0.00000000e+00, 5.75651467e-01,\n",
       "        0.00000000e+00, 4.19966817e-01, 5.64365208e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68.79773576, 68.79680205, 68.79586835, 68.79493464, 68.79400093,\n",
       "       68.79306723, 68.79213352, 68.79119981, 68.79026611, 68.7893324 ,\n",
       "       68.78839869, 68.78746499, 68.78653128, 68.78559757, 68.78466387,\n",
       "       68.78373016, 68.78279645, 68.78186275, 68.78092904, 68.77999533,\n",
       "       68.77906162, 68.77812792, 68.77719421, 68.7762605 , 68.7753268 ,\n",
       "       68.77439309, 68.77345938, 68.77252568, 68.77159197, 68.77065826,\n",
       "       68.76972456, 68.76879085, 68.76785714, 68.76692344, 68.76598973,\n",
       "       68.76505602, 68.76412232, 68.76318861, 68.7622549 , 68.7613212 ,\n",
       "       68.76038749, 68.75945378, 68.75852007, 68.75758637, 68.75665266,\n",
       "       68.75571895, 68.75478525, 68.75385154, 68.75291783, 68.75198413,\n",
       "       68.75105042, 68.75011671, 68.74918301, 68.7482493 , 68.74731559,\n",
       "       68.74638189, 68.74544818, 68.74451447, 68.74358077, 68.74264706,\n",
       "       68.74171335, 68.74077965, 68.73984594, 68.73891223, 68.73797852,\n",
       "       68.73704482, 68.73611111, 68.7351774 , 68.7342437 , 68.73330999,\n",
       "       68.73237628, 68.73144258, 68.73050887, 68.72957516, 68.72864146,\n",
       "       68.72770775, 68.72677404, 68.72584034, 68.72490663, 68.72397292,\n",
       "       68.72303922, 68.72210551, 68.7211718 , 68.7202381 , 68.71930439,\n",
       "       68.71837068, 68.71743697, 68.71650327, 68.71556956, 68.71463585,\n",
       "       68.71370215, 68.71276844, 68.71183473, 68.71090103, 68.70996732,\n",
       "       68.70903361, 68.70809991, 68.7071662 , 68.70623249, 68.70529879])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.944891367889074\n",
      "15.279164544989607\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
