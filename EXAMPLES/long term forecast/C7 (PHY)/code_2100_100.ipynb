{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2195    64.726160\n",
       "2196    64.718508\n",
       "2197    64.710856\n",
       "2198    64.703204\n",
       "2199    64.695552\n",
       "Name: C7, Length: 2200, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c7_interpolated_2100_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2095     0.527806\n",
       "2096     0.609688\n",
       "2097     0.000000\n",
       "2098     0.000000\n",
       "2099     0.000000\n",
       "Name: C7, Length: 2100, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2100)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.387115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.174230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.961345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.748459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     92.600000  0.000298\n",
       "1     92.387115  0.000298\n",
       "2     92.174230  0.000297\n",
       "3     91.961345  0.000297\n",
       "4     91.748459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 89.3180  # Value for C0\n",
    "K0 = -0.0010  # Value for K0\n",
    "K1 = 0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = -0.0204    # Value for b\n",
    "c = 2.2194    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    92.600000    92.387115    92.174230    91.961345    91.748459   \n",
      "351    92.387115    92.174230    91.961345    91.748459    91.535574   \n",
      "352    92.174230    91.961345    91.748459    91.535574    91.322689   \n",
      "353    91.961345    91.748459    91.535574    91.322689    91.109804   \n",
      "354    91.748459    91.535574    91.322689    91.109804    90.896919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    91.535574    91.322689    91.109804    90.896919    90.691597  ...   \n",
      "351    91.322689    91.109804    90.896919    90.691597    90.579552  ...   \n",
      "352    91.109804    90.896919    90.691597    90.579552    90.467507  ...   \n",
      "353    90.896919    90.691597    90.579552    90.467507    90.355462  ...   \n",
      "354    90.691597    90.579552    90.467507    90.355462    90.243417  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   80.261671    0.000263   80.252334    0.000263   80.242997    0.000263   \n",
      "351   80.252334    0.000263   80.242997    0.000263   80.233660    0.000262   \n",
      "352   80.242997    0.000263   80.233660    0.000262   80.224323    0.000262   \n",
      "353   80.233660    0.000262   80.224323    0.000262   80.214986    0.000262   \n",
      "354   80.224323    0.000262   80.214986    0.000262   80.205649    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   80.233660    0.000262   80.224323    0.000262  \n",
      "351   80.224323    0.000262   80.214986    0.000262  \n",
      "352   80.214986    0.000262   80.205649    0.000262  \n",
      "353   80.205649    0.000262   80.196312    0.000262  \n",
      "354   80.196312    0.000262   80.186975    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 1, 251) (1650, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 2s 29ms/step - loss: 5708.0181 - val_loss: 3721.4072\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5635.1680 - val_loss: 3678.2966\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5570.1602 - val_loss: 3641.5171\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5505.6733 - val_loss: 3605.1289\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5441.7593 - val_loss: 3569.1187\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5378.4121 - val_loss: 3533.4785\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5315.6235 - val_loss: 3498.2024\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5253.3877 - val_loss: 3463.2871\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5191.6982 - val_loss: 3428.7288\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5130.5522 - val_loss: 3394.5242\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5069.9443 - val_loss: 3360.6704\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 5009.8716 - val_loss: 3327.1643\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4950.3276 - val_loss: 3294.0042\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4891.3110 - val_loss: 3261.1860\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4832.8164 - val_loss: 3228.7083\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4774.8398 - val_loss: 3196.5674\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4717.3794 - val_loss: 3164.7620\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4660.4312 - val_loss: 3133.2886\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4603.9902 - val_loss: 3102.1458\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4548.0532 - val_loss: 3071.3296\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4492.6172 - val_loss: 3040.8394\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4437.6782 - val_loss: 3010.6716\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4383.2339 - val_loss: 2980.8245\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4329.2812 - val_loss: 2951.2954\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4275.8149 - val_loss: 2922.0823\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4222.8306 - val_loss: 2893.1829\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4170.3291 - val_loss: 2864.5950\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4118.3047 - val_loss: 2836.3159\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4066.7539 - val_loss: 2808.3442\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4015.6731 - val_loss: 2780.6770\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3965.0610 - val_loss: 2753.3130\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3914.9136 - val_loss: 2726.2488\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3865.2261 - val_loss: 2699.4832\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3815.9980 - val_loss: 2673.0142\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3767.2239 - val_loss: 2646.8391\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3718.9033 - val_loss: 2620.9563\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3671.0310 - val_loss: 2595.3635\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3623.6052 - val_loss: 2570.0588\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3576.6223 - val_loss: 2545.0403\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3530.0796 - val_loss: 2520.3054\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3483.9734 - val_loss: 2495.8525\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3438.3022 - val_loss: 2471.6804\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3393.0620 - val_loss: 2447.7856\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3348.2500 - val_loss: 2424.1677\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3303.8645 - val_loss: 2400.8235\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3259.9019 - val_loss: 2377.7522\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3216.3584 - val_loss: 2354.9507\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3173.2332 - val_loss: 2332.4182\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3130.5225 - val_loss: 2310.1523\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3088.2231 - val_loss: 2288.1514\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3046.3333 - val_loss: 2266.4133\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3004.8501 - val_loss: 2244.9363\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2963.7695 - val_loss: 2223.7188\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 2923.0916 - val_loss: 2202.7588\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2882.8115 - val_loss: 2182.0547\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2842.9275 - val_loss: 2161.6042\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2803.4365 - val_loss: 2141.4065\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2764.3369 - val_loss: 2121.4590\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2725.6255 - val_loss: 2101.7603\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2687.2991 - val_loss: 2082.3086\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2649.3569 - val_loss: 2063.1021\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2611.7947 - val_loss: 2044.1392\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2574.6111 - val_loss: 2025.4182\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2537.8037 - val_loss: 2006.9377\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2501.3689 - val_loss: 1988.6957\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2465.3057 - val_loss: 1970.6902\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2429.6104 - val_loss: 1952.9199\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2394.2817 - val_loss: 1935.3835\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2359.3164 - val_loss: 1918.0792\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2324.7134 - val_loss: 1901.0049\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2290.4690 - val_loss: 1884.1593\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2256.5815 - val_loss: 1867.5409\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2223.0483 - val_loss: 1851.1483\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2189.8679 - val_loss: 1834.9790\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2157.0366 - val_loss: 1819.0327\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2124.5535 - val_loss: 1803.3066\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2092.4155 - val_loss: 1787.8000\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2060.6211 - val_loss: 1772.5112\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2029.1675 - val_loss: 1757.4382\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1998.0525 - val_loss: 1742.5796\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1967.2737 - val_loss: 1727.9343\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1936.8296 - val_loss: 1713.5006\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1906.7177 - val_loss: 1699.2767\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1876.9364 - val_loss: 1685.2616\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1847.4824 - val_loss: 1671.4532\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1818.3544 - val_loss: 1657.8502\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1789.5496 - val_loss: 1644.4515\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1761.0669 - val_loss: 1631.2552\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1732.9036 - val_loss: 1618.2599\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1705.0570 - val_loss: 1605.4640\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1677.5264 - val_loss: 1592.8665\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1650.3087 - val_loss: 1580.4655\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1623.4025 - val_loss: 1568.2595\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1596.8051 - val_loss: 1556.2476\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1570.5149 - val_loss: 1544.4279\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1544.5298 - val_loss: 1532.7991\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1518.8477 - val_loss: 1521.3594\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1493.4664 - val_loss: 1510.1078\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1468.3842 - val_loss: 1499.0431\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1443.5991 - val_loss: 1488.1631\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1419.1093 - val_loss: 1477.4668\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1394.9120 - val_loss: 1466.9529\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1371.0060 - val_loss: 1456.6201\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1347.3889 - val_loss: 1446.4667\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1324.0593 - val_loss: 1436.4912\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1301.0150 - val_loss: 1426.6924\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1278.2540 - val_loss: 1417.0692\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1255.7745 - val_loss: 1407.6196\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1233.5741 - val_loss: 1398.3428\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1211.6516 - val_loss: 1389.2369\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1190.0044 - val_loss: 1380.3011\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1168.6315 - val_loss: 1371.5333\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1147.5300 - val_loss: 1362.9326\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1126.6987 - val_loss: 1354.4977\n",
      "Epoch 115/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1106.1357 - val_loss: 1346.2269\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1085.8385 - val_loss: 1338.1189\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1065.8055 - val_loss: 1330.1727\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1046.0356 - val_loss: 1322.3864\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1026.5260 - val_loss: 1314.7589\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1007.2747 - val_loss: 1307.2888\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 988.2811 - val_loss: 1299.9749\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 969.5421 - val_loss: 1292.8152\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 951.0556 - val_loss: 1285.8091\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 932.8210 - val_loss: 1278.9550\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 914.8357 - val_loss: 1272.2511\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 897.0977 - val_loss: 1265.6968\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 879.6059 - val_loss: 1259.2903\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 862.3580 - val_loss: 1253.0302\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 845.3522 - val_loss: 1246.9153\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 828.5867 - val_loss: 1240.9443\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 812.0602 - val_loss: 1235.1156\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 795.7700 - val_loss: 1229.4281\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 779.7147 - val_loss: 1223.8802\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 763.8927 - val_loss: 1218.4709\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 748.3022 - val_loss: 1213.1987\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 732.9410 - val_loss: 1208.0619\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 717.8070 - val_loss: 1203.0593\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 702.8990 - val_loss: 1198.1897\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 688.2146 - val_loss: 1193.4517\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 673.7529 - val_loss: 1188.8439\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 659.5117 - val_loss: 1184.3651\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 645.4893 - val_loss: 1180.0134\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 631.6833 - val_loss: 1175.7882\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 618.0927 - val_loss: 1171.6875\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 604.7146 - val_loss: 1167.7103\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 591.5485 - val_loss: 1163.8551\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 578.5916 - val_loss: 1160.1202\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 565.8424 - val_loss: 1156.5051\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 553.2991 - val_loss: 1153.0077\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 540.9600 - val_loss: 1149.6266\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 528.8232 - val_loss: 1146.3608\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 516.8874 - val_loss: 1143.2089\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 505.1503 - val_loss: 1140.1694\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 493.6106 - val_loss: 1137.2410\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 482.2659 - val_loss: 1134.4221\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 471.1149 - val_loss: 1131.7117\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 460.1552 - val_loss: 1129.1079\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 449.3854 - val_loss: 1126.6096\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 438.8036 - val_loss: 1124.2156\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 428.4080 - val_loss: 1121.9243\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 418.1970 - val_loss: 1119.7344\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 408.1685 - val_loss: 1117.6443\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 398.3208 - val_loss: 1115.6527\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 388.6519 - val_loss: 1113.7584\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 379.1609 - val_loss: 1111.9598\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 369.8451 - val_loss: 1110.2557\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 360.7029 - val_loss: 1108.6447\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 351.7325 - val_loss: 1107.1250\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 342.9325 - val_loss: 1105.6956\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 334.3005 - val_loss: 1104.3550\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 325.8352 - val_loss: 1103.1016\n",
      "Epoch 172/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 317.5343 - val_loss: 1101.9342\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 309.3958 - val_loss: 1100.8514\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 301.4187 - val_loss: 1099.8519\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 293.6009 - val_loss: 1098.9338\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 285.9402 - val_loss: 1098.0963\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 278.4355 - val_loss: 1097.3376\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 271.0842 - val_loss: 1096.6565\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 263.8851 - val_loss: 1096.0514\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 256.8358 - val_loss: 1095.5210\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 249.9349 - val_loss: 1095.0640\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 243.1807 - val_loss: 1094.6787\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 236.5712 - val_loss: 1094.3639\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 230.1046 - val_loss: 1094.1182\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 223.7794 - val_loss: 1093.9399\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 217.5935 - val_loss: 1093.8279\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 211.5451 - val_loss: 1093.7809\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 205.6325 - val_loss: 1093.7971\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 199.8535 - val_loss: 1093.8752\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 194.2067 - val_loss: 1094.0140\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 188.6902 - val_loss: 1094.2119\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 183.3023 - val_loss: 1094.4679\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 178.0409 - val_loss: 1094.7798\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 172.9047 - val_loss: 1095.1469\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 167.8917 - val_loss: 1095.5674\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 163.0000 - val_loss: 1096.0400\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 158.2276 - val_loss: 1096.5636\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 153.5728 - val_loss: 1097.1364\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 149.0341 - val_loss: 1097.7573\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 144.6097 - val_loss: 1098.4247\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 140.2976 - val_loss: 1099.1371\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 136.0962 - val_loss: 1099.8938\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 132.0037 - val_loss: 1100.6926\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 128.0183 - val_loss: 1101.5330\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 124.1379 - val_loss: 1102.4125\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 120.3615 - val_loss: 1103.3308\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 116.6870 - val_loss: 1104.2860\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 113.1124 - val_loss: 1105.2769\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 109.6363 - val_loss: 1106.3021\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 106.2566 - val_loss: 1107.3605\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 102.9717 - val_loss: 1108.4503\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 99.7799 - val_loss: 1109.5709\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 96.6797 - val_loss: 1110.7202\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 93.6692 - val_loss: 1111.8975\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 90.7470 - val_loss: 1113.1012\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 87.9110 - val_loss: 1114.3301\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 85.1595 - val_loss: 1115.5830\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 82.4912 - val_loss: 1116.8584\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 79.9042 - val_loss: 1118.1553\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 77.3968 - val_loss: 1119.4725\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 74.9673 - val_loss: 1120.8085\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 72.6143 - val_loss: 1122.1625\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 70.3359 - val_loss: 1123.5330\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 68.1309 - val_loss: 1124.9187\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 65.9973 - val_loss: 1126.3186\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 63.9336 - val_loss: 1127.7316\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 61.9384 - val_loss: 1129.1560\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 60.0101 - val_loss: 1130.5918\n",
      "Epoch 229/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 58.1469 - val_loss: 1132.0369\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 56.3475 - val_loss: 1133.4905\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 54.6102 - val_loss: 1134.9517\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 52.9336 - val_loss: 1136.4189\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 51.3162 - val_loss: 1137.8917\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 49.7565 - val_loss: 1139.3689\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 48.2530 - val_loss: 1140.8489\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 46.8045 - val_loss: 1142.3312\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45.4093 - val_loss: 1143.8147\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44.0662 - val_loss: 1145.2985\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42.7735 - val_loss: 1146.7815\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41.5301 - val_loss: 1148.2632\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 40.3344 - val_loss: 1149.7423\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 39.1851 - val_loss: 1151.2179\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 38.0811 - val_loss: 1152.6892\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 37.0209 - val_loss: 1154.1556\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 36.0032 - val_loss: 1155.6160\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 35.0269 - val_loss: 1157.0698\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 34.0905 - val_loss: 1158.5159\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 33.1929 - val_loss: 1159.9536\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 32.3330 - val_loss: 1161.3824\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 31.5095 - val_loss: 1162.8013\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.7212 - val_loss: 1164.2101\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9670 - val_loss: 1165.6074\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.2459 - val_loss: 1166.9934\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 28.5565 - val_loss: 1168.3667\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 27.8980 - val_loss: 1169.7269\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 27.2692 - val_loss: 1171.0740\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 26.6690 - val_loss: 1172.4070\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 26.0965 - val_loss: 1173.7253\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25.5507 - val_loss: 1175.0281\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25.0306 - val_loss: 1176.3159\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 24.5352 - val_loss: 1177.5874\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 24.0637 - val_loss: 1178.8425\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.6150 - val_loss: 1180.0808\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.1883 - val_loss: 1181.3020\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 22.7827 - val_loss: 1182.5052\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 22.3976 - val_loss: 1183.6907\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 22.0319 - val_loss: 1184.8582\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.6849 - val_loss: 1186.0071\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.3558 - val_loss: 1187.1371\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.0439 - val_loss: 1188.2479\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 20.7485 - val_loss: 1189.3400\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 20.4688 - val_loss: 1190.4124\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.2041 - val_loss: 1191.4653\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.9537 - val_loss: 1192.4985\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.7171 - val_loss: 1193.5117\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.4937 - val_loss: 1194.5049\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.2828 - val_loss: 1195.4783\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.0837 - val_loss: 1196.4316\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8960 - val_loss: 1197.3647\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7191 - val_loss: 1198.2777\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.5525 - val_loss: 1199.1704\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.3956 - val_loss: 1200.0430\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.2481 - val_loss: 1200.8955\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.1094 - val_loss: 1201.7281\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 17.9791 - val_loss: 1202.5408\n",
      "Epoch 286/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 17.8567 - val_loss: 1203.3335\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 17.7418 - val_loss: 1204.1067\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 17.6340 - val_loss: 1204.8596\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 17.5330 - val_loss: 1205.5936\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.4383 - val_loss: 1206.3083\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.3497 - val_loss: 1207.0035\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.2667 - val_loss: 1207.6801\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.1891 - val_loss: 1208.3373\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 17.1166 - val_loss: 1208.9763\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 17.0489 - val_loss: 1209.5969\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 16.9856 - val_loss: 1210.1991\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.9265 - val_loss: 1210.7843\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.8715 - val_loss: 1211.3511\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.8202 - val_loss: 1211.9005\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.7724 - val_loss: 1212.4329\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.7278 - val_loss: 1212.9482\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.6864 - val_loss: 1213.4474\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.6479 - val_loss: 1213.9299\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.6120 - val_loss: 1214.3964\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.5788 - val_loss: 1214.8473\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.5479 - val_loss: 1215.2827\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.5192 - val_loss: 1215.7034\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.4926 - val_loss: 1216.1091\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.4680 - val_loss: 1216.5001\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.4451 - val_loss: 1216.8773\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.4239 - val_loss: 1217.2405\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.4043 - val_loss: 1217.5903\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.3862 - val_loss: 1217.9268\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.3694 - val_loss: 1218.2505\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.3539 - val_loss: 1218.5620\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.3396 - val_loss: 1218.8611\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.3263 - val_loss: 1219.1484\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.3142 - val_loss: 1219.4246\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.3029 - val_loss: 1219.6890\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 16.2924 - val_loss: 1219.9429\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2828 - val_loss: 1220.1862\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2740 - val_loss: 1220.4188\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2659 - val_loss: 1220.6421\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2584 - val_loss: 1220.8556\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2514 - val_loss: 1221.0596\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2451 - val_loss: 1221.2546\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2393 - val_loss: 1221.4412\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2339 - val_loss: 1221.6189\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2290 - val_loss: 1221.7891\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2244 - val_loss: 1221.9512\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2203 - val_loss: 1222.1055\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2165 - val_loss: 1222.2524\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2130 - val_loss: 1222.3926\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2098 - val_loss: 1222.5259\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2069 - val_loss: 1222.6527\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2042 - val_loss: 1222.7731\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2018 - val_loss: 1222.8872\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1996 - val_loss: 1222.9958\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1976 - val_loss: 1223.0989\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1958 - val_loss: 1223.1965\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1941 - val_loss: 1223.2891\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 16.1926 - val_loss: 1223.3766\n",
      "Epoch 343/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 16.1913 - val_loss: 1223.4598\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1901 - val_loss: 1223.5382\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1890 - val_loss: 1223.6125\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1880 - val_loss: 1223.6827\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1871 - val_loss: 1223.7489\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1864 - val_loss: 1223.8118\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1856 - val_loss: 1223.8706\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1851 - val_loss: 1223.9263\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1845 - val_loss: 1223.9785\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1841 - val_loss: 1224.0280\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1837 - val_loss: 1224.0746\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1834 - val_loss: 1224.1176\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1832 - val_loss: 1224.1588\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1830 - val_loss: 1224.1970\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1828 - val_loss: 1224.2334\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 16.1827 - val_loss: 1224.2675\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1827 - val_loss: 1224.2992\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1826 - val_loss: 1224.3290\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1827 - val_loss: 1224.3567\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1827 - val_loss: 1224.3828\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1828 - val_loss: 1224.4073\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1829 - val_loss: 1224.4302\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1830 - val_loss: 1224.4512\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1832 - val_loss: 1224.4708\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1834 - val_loss: 1224.4894\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1836 - val_loss: 1224.5062\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1838 - val_loss: 1224.5221\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1841 - val_loss: 1224.5370\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1843 - val_loss: 1224.5505\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1846 - val_loss: 1224.5634\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1849 - val_loss: 1224.5750\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1852 - val_loss: 1224.5856\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1855 - val_loss: 1224.5957\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1859 - val_loss: 1224.6047\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1862 - val_loss: 1224.6133\n",
      "Epoch 378/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1866 - val_loss: 1224.6212\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 16.1869 - val_loss: 1224.6281\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1873 - val_loss: 1224.6340\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1877 - val_loss: 1224.6404\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1881 - val_loss: 1224.6460\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1884 - val_loss: 1224.6509\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1889 - val_loss: 1224.6552\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1892 - val_loss: 1224.6591\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1897 - val_loss: 1224.6628\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1901 - val_loss: 1224.6658\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1905 - val_loss: 1224.6693\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1909 - val_loss: 1224.6719\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1913 - val_loss: 1224.6743\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1917 - val_loss: 1224.6764\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1921 - val_loss: 1224.6781\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1926 - val_loss: 1224.6797\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1930 - val_loss: 1224.6810\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1934 - val_loss: 1224.6824\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1938 - val_loss: 1224.6832\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1943 - val_loss: 1224.6840\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1947 - val_loss: 1224.6851\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1951 - val_loss: 1224.6853\n",
      "Epoch 400/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1955 - val_loss: 1224.6857\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 16.1959 - val_loss: 1224.6858\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1964 - val_loss: 1224.6860\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1968 - val_loss: 1224.6864\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1972 - val_loss: 1224.6860\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1976 - val_loss: 1224.6859\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1980 - val_loss: 1224.6859\n",
      "Epoch 407/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1984 - val_loss: 1224.6855\n",
      "Epoch 408/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1988 - val_loss: 1224.6853\n",
      "Epoch 409/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1992 - val_loss: 1224.6852\n",
      "Epoch 410/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.1996 - val_loss: 1224.6851\n",
      "Epoch 411/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2000 - val_loss: 1224.6843\n",
      "Epoch 412/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2004 - val_loss: 1224.6836\n",
      "Epoch 413/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2008 - val_loss: 1224.6830\n",
      "Epoch 414/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2012 - val_loss: 1224.6825\n",
      "Epoch 415/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2016 - val_loss: 1224.6819\n",
      "Epoch 416/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2019 - val_loss: 1224.6812\n",
      "Epoch 417/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2023 - val_loss: 1224.6805\n",
      "Epoch 418/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2027 - val_loss: 1224.6797\n",
      "Epoch 419/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2031 - val_loss: 1224.6790\n",
      "Epoch 420/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2034 - val_loss: 1224.6782\n",
      "Epoch 421/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2038 - val_loss: 1224.6779\n",
      "Epoch 422/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 16.2041 - val_loss: 1224.6770\n",
      "Epoch 423/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2045 - val_loss: 1224.6763\n",
      "Epoch 424/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2048 - val_loss: 1224.6750\n",
      "Epoch 425/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2052 - val_loss: 1224.6742\n",
      "Epoch 426/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2055 - val_loss: 1224.6735\n",
      "Epoch 427/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2058 - val_loss: 1224.6730\n",
      "Epoch 428/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2062 - val_loss: 1224.6719\n",
      "Epoch 429/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2066 - val_loss: 1224.6709\n",
      "Epoch 430/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2068 - val_loss: 1224.6703\n",
      "Epoch 431/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2072 - val_loss: 1224.6692\n",
      "Epoch 432/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2075 - val_loss: 1224.6682\n",
      "Epoch 433/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2078 - val_loss: 1224.6674\n",
      "Epoch 434/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2081 - val_loss: 1224.6665\n",
      "Epoch 435/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2085 - val_loss: 1224.6654\n",
      "Epoch 436/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2088 - val_loss: 1224.6646\n",
      "Epoch 437/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2090 - val_loss: 1224.6641\n",
      "Epoch 438/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2094 - val_loss: 1224.6632\n",
      "Epoch 439/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2097 - val_loss: 1224.6622\n",
      "Epoch 440/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2099 - val_loss: 1224.6616\n",
      "Epoch 441/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2102 - val_loss: 1224.6611\n",
      "Epoch 442/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2105 - val_loss: 1224.6604\n",
      "Epoch 443/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 16.2107 - val_loss: 1224.6594\n",
      "Epoch 444/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2110 - val_loss: 1224.6586\n",
      "Epoch 445/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2113 - val_loss: 1224.6580\n",
      "Epoch 446/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2116 - val_loss: 1224.6573\n",
      "Epoch 447/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2118 - val_loss: 1224.6562\n",
      "Epoch 448/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2121 - val_loss: 1224.6556\n",
      "Epoch 449/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2123 - val_loss: 1224.6548\n",
      "Epoch 450/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2126 - val_loss: 1224.6539\n",
      "Epoch 451/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2128 - val_loss: 1224.6536\n",
      "Epoch 452/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2131 - val_loss: 1224.6528\n",
      "Epoch 453/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2133 - val_loss: 1224.6522\n",
      "Epoch 454/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2135 - val_loss: 1224.6515\n",
      "Epoch 455/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2138 - val_loss: 1224.6511\n",
      "Epoch 456/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2140 - val_loss: 1224.6504\n",
      "Epoch 457/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 16.2142 - val_loss: 1224.6497\n",
      "Epoch 458/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 16.2145 - val_loss: 1224.6489\n",
      "Epoch 459/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2147 - val_loss: 1224.6487\n",
      "Epoch 460/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2149 - val_loss: 1224.6481\n",
      "Epoch 461/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2151 - val_loss: 1224.6475\n",
      "Epoch 462/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 16.2153 - val_loss: 1224.6469\n",
      "Epoch 463/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 16.2155 - val_loss: 1224.6465\n",
      "Epoch 464/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2157 - val_loss: 1224.6460\n",
      "Epoch 465/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2159 - val_loss: 1224.6459\n",
      "Epoch 466/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2161 - val_loss: 1224.6449\n",
      "Epoch 467/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2163 - val_loss: 1224.6445\n",
      "Epoch 468/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2165 - val_loss: 1224.6438\n",
      "Epoch 469/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2167 - val_loss: 1224.6436\n",
      "Epoch 470/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2168 - val_loss: 1224.6429\n",
      "Epoch 471/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2171 - val_loss: 1224.6426\n",
      "Epoch 472/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2172 - val_loss: 1224.6418\n",
      "Epoch 473/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2174 - val_loss: 1224.6415\n",
      "Epoch 474/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2175 - val_loss: 1224.6409\n",
      "Epoch 475/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2177 - val_loss: 1224.6400\n",
      "Epoch 476/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2179 - val_loss: 1224.6400\n",
      "Epoch 477/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2181 - val_loss: 1224.6396\n",
      "Epoch 478/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2182 - val_loss: 1224.6389\n",
      "Epoch 479/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2184 - val_loss: 1224.6383\n",
      "Epoch 480/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2185 - val_loss: 1224.6379\n",
      "Epoch 481/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2186 - val_loss: 1224.6371\n",
      "Epoch 482/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 16.2188 - val_loss: 1224.6368\n",
      "Epoch 483/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2190 - val_loss: 1224.6361\n",
      "Epoch 484/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2191 - val_loss: 1224.6359\n",
      "Epoch 485/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2193 - val_loss: 1224.6357\n",
      "Epoch 486/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2194 - val_loss: 1224.6355\n",
      "Epoch 487/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2195 - val_loss: 1224.6349\n",
      "Epoch 488/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2197 - val_loss: 1224.6344\n",
      "Epoch 489/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2198 - val_loss: 1224.6343\n",
      "Epoch 490/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2199 - val_loss: 1224.6340\n",
      "Epoch 491/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2201 - val_loss: 1224.6338\n",
      "Epoch 492/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2202 - val_loss: 1224.6337\n",
      "Epoch 493/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2203 - val_loss: 1224.6332\n",
      "Epoch 494/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2204 - val_loss: 1224.6328\n",
      "Epoch 495/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2206 - val_loss: 1224.6322\n",
      "Epoch 496/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2207 - val_loss: 1224.6320\n",
      "Epoch 497/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2208 - val_loss: 1224.6316\n",
      "Epoch 498/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2209 - val_loss: 1224.6312\n",
      "Epoch 499/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2210 - val_loss: 1224.6310\n",
      "Epoch 500/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 16.2211 - val_loss: 1224.6310\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(89.3180, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0010, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(-0.0204, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.2194, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 530ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.11573529e+01, 7.10985294e+01, 7.10397059e+01, 6.98808824e+01,\n",
       "        6.95210588e+01, 6.85264706e+01, 7.76552277e+01, 2.51280129e-01,\n",
       "        0.00000000e+00, 7.14449644e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.16556233e+01, 7.16228501e+01, 7.15821895e+01,\n",
       "        7.15233660e+01, 7.14645425e+01, 7.14057189e+01, 7.13468954e+01,\n",
       "        7.12880719e+01, 7.12296484e+01, 7.11704248e+01, 7.11116013e+01,\n",
       "        7.10532778e+01, 7.09939543e+01, 7.09351307e+01, 7.08526144e+01,\n",
       "        7.07359673e+01, 7.06173203e+01, 7.04996732e+01, 7.03820261e+01,\n",
       "        7.02643791e+01, 7.01467320e+01, 7.00290850e+01, 6.99114379e+01,\n",
       "        6.97937908e+01, 6.96761438e+01, 6.95614947e+01, 6.94704248e+01,\n",
       "        2.11114660e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.72564160e-02, 0.00000000e+00, 7.19315648e-01, 7.10070261e+01,\n",
       "        7.09482026e+01, 7.08787582e+01, 7.07611111e+01, 7.06434641e+01,\n",
       "        7.05258170e+01, 7.04081699e+01, 7.02905229e+01, 7.01728758e+01,\n",
       "        7.00552288e+01, 6.99375817e+01, 6.98199346e+01, 6.97022876e+01,\n",
       "        6.95846405e+01, 6.94834967e+01, 7.34305626e+01, 7.30498903e+01,\n",
       "        7.26692180e+01, 7.22885457e+01, 7.19687885e+01, 7.18704692e+01,\n",
       "        7.17721499e+01, 7.16738305e+01, 7.15560457e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.38740616e+01, 0.00000000e+00, 6.08911810e-01,\n",
       "        2.32701850e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.18126755e+01, 5.29752970e-02, 0.00000000e+00, 2.03491569e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.82741439e-01,\n",
       "        0.00000000e+00, 1.64696336e-01, 2.63578534e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.78146881e-01, 3.29186559e-01, 2.79348850e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.81616914e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65.52426471, 65.51446078, 65.50465686, 65.49485294, 65.48504902,\n",
       "       65.4752451 , 65.46544118, 65.45563725, 65.44583333, 65.43602941,\n",
       "       65.42622549, 65.41642157, 65.40661765, 65.39681373, 65.3870098 ,\n",
       "       65.37720588, 65.36740196, 65.35759804, 65.34779412, 65.3379902 ,\n",
       "       65.32818627, 65.31838235, 65.30857843, 65.29877451, 65.28897059,\n",
       "       65.27916667, 65.26936275, 65.25955882, 65.2497549 , 65.23995098,\n",
       "       65.23014706, 65.22034314, 65.21053922, 65.20073529, 65.19292205,\n",
       "       65.18527021, 65.17761836, 65.16996652, 65.16231468, 65.15466284,\n",
       "       65.147011  , 65.13935916, 65.13170732, 65.12405548, 65.11640363,\n",
       "       65.10875179, 65.10109995, 65.09344811, 65.08579627, 65.07814443,\n",
       "       65.07049259, 65.06284075, 65.0551889 , 65.04753706, 65.03988522,\n",
       "       65.03223338, 65.02458154, 65.0169297 , 65.00927786, 65.00162602,\n",
       "       64.99397418, 64.98632233, 64.97867049, 64.97101865, 64.96336681,\n",
       "       64.95571497, 64.94806313, 64.94041129, 64.93275945, 64.9251076 ,\n",
       "       64.91745576, 64.90980392, 64.90215208, 64.89450024, 64.8868484 ,\n",
       "       64.87919656, 64.87154472, 64.86389287, 64.85624103, 64.84858919,\n",
       "       64.84093735, 64.83328551, 64.82563367, 64.81798183, 64.81032999,\n",
       "       64.80267814, 64.7950263 , 64.78737446, 64.77972262, 64.77207078,\n",
       "       64.76441894, 64.7567671 , 64.74911526, 64.74146341, 64.73381157,\n",
       "       64.72615973, 64.71850789, 64.71085605, 64.70320421, 64.69555237])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.266857679589286\n",
      "29.473547891520138\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
