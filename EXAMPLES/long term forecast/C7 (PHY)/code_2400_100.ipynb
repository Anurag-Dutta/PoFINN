{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2495    62.430607\n",
       "2496    62.422956\n",
       "2497    62.415304\n",
       "2498    62.407652\n",
       "2499    62.400000\n",
       "Name: C7, Length: 2500, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c7_interpolated_2400_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2395     0.000000\n",
       "2396     0.005379\n",
       "2397     0.000000\n",
       "2398     0.631547\n",
       "2399     0.000000\n",
       "Name: C7, Length: 2400, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2400)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.387115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.174230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.961345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.748459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     92.600000  0.000298\n",
       "1     92.387115  0.000298\n",
       "2     92.174230  0.000297\n",
       "3     91.961345  0.000297\n",
       "4     91.748459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 89.3180  # Value for C0\n",
    "K0 = -0.0010  # Value for K0\n",
    "K1 = 0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = -0.0204    # Value for b\n",
    "c = 2.2194    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    92.600000    92.387115    92.174230    91.961345    91.748459   \n",
      "351    92.387115    92.174230    91.961345    91.748459    91.535574   \n",
      "352    92.174230    91.961345    91.748459    91.535574    91.322689   \n",
      "353    91.961345    91.748459    91.535574    91.322689    91.109804   \n",
      "354    91.748459    91.535574    91.322689    91.109804    90.896919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    91.535574    91.322689    91.109804    90.896919    90.691597  ...   \n",
      "351    91.322689    91.109804    90.896919    90.691597    90.579552  ...   \n",
      "352    91.109804    90.896919    90.691597    90.579552    90.467507  ...   \n",
      "353    90.896919    90.691597    90.579552    90.467507    90.355462  ...   \n",
      "354    90.691597    90.579552    90.467507    90.355462    90.243417  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   80.261671    0.000263   80.252334    0.000263   80.242997    0.000263   \n",
      "351   80.252334    0.000263   80.242997    0.000263   80.233660    0.000262   \n",
      "352   80.242997    0.000263   80.233660    0.000262   80.224323    0.000262   \n",
      "353   80.233660    0.000262   80.224323    0.000262   80.214986    0.000262   \n",
      "354   80.224323    0.000262   80.214986    0.000262   80.205649    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   80.233660    0.000262   80.224323    0.000262  \n",
      "351   80.224323    0.000262   80.214986    0.000262  \n",
      "352   80.214986    0.000262   80.205649    0.000262  \n",
      "353   80.205649    0.000262   80.196312    0.000262  \n",
      "354   80.196312    0.000262   80.186975    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1950, 1, 251) (1950, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "25/25 [==============================] - 2s 20ms/step - loss: 5387.0840 - val_loss: 3155.7671\n",
      "Epoch 2/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 5048.5874 - val_loss: 2976.1252\n",
      "Epoch 3/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4890.3774 - val_loss: 2889.4272\n",
      "Epoch 4/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4773.4492 - val_loss: 2821.2727\n",
      "Epoch 5/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4663.5879 - val_loss: 2756.6587\n",
      "Epoch 6/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4545.5283 - val_loss: 2686.1626\n",
      "Epoch 7/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 4437.4849 - val_loss: 2624.6794\n",
      "Epoch 8/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 4334.3149 - val_loss: 2565.6453\n",
      "Epoch 9/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 4234.2764 - val_loss: 2508.7009\n",
      "Epoch 10/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 4136.8774 - val_loss: 2453.6196\n",
      "Epoch 11/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4041.8267 - val_loss: 2400.2568\n",
      "Epoch 12/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3948.9377 - val_loss: 2348.5129\n",
      "Epoch 13/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3858.0806 - val_loss: 2298.3115\n",
      "Epoch 14/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3769.1533 - val_loss: 2249.5928\n",
      "Epoch 15/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3682.0776 - val_loss: 2202.3057\n",
      "Epoch 16/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3596.7898 - val_loss: 2156.4077\n",
      "Epoch 17/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3513.2329 - val_loss: 2111.8604\n",
      "Epoch 18/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3431.3606 - val_loss: 2068.6279\n",
      "Epoch 19/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3351.1309 - val_loss: 2026.3402\n",
      "Epoch 20/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3267.0186 - val_loss: 1980.5785\n",
      "Epoch 21/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3182.2358 - val_loss: 1937.8669\n",
      "Epoch 22/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3101.0950 - val_loss: 1897.2406\n",
      "Epoch 23/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3022.7185 - val_loss: 1858.3280\n",
      "Epoch 24/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2946.6006 - val_loss: 1820.9338\n",
      "Epoch 25/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2872.4741 - val_loss: 1784.9425\n",
      "Epoch 26/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2800.1797 - val_loss: 1750.2771\n",
      "Epoch 27/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2729.6106 - val_loss: 1716.8801\n",
      "Epoch 28/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2660.6868 - val_loss: 1684.7043\n",
      "Epoch 29/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2593.3447 - val_loss: 1653.7106\n",
      "Epoch 30/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2527.5327 - val_loss: 1623.8651\n",
      "Epoch 31/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2463.2058 - val_loss: 1595.1366\n",
      "Epoch 32/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2400.3267 - val_loss: 1567.4971\n",
      "Epoch 33/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2338.8577 - val_loss: 1540.9207\n",
      "Epoch 34/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2278.7688 - val_loss: 1515.3815\n",
      "Epoch 35/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2220.0288 - val_loss: 1490.8574\n",
      "Epoch 36/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2162.6108 - val_loss: 1467.3258\n",
      "Epoch 37/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2106.4880 - val_loss: 1444.7644\n",
      "Epoch 38/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2051.6360 - val_loss: 1423.1533\n",
      "Epoch 39/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1998.0302 - val_loss: 1402.4718\n",
      "Epoch 40/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1945.6486 - val_loss: 1382.7003\n",
      "Epoch 41/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1894.4688 - val_loss: 1363.8201\n",
      "Epoch 42/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1844.4696 - val_loss: 1345.8120\n",
      "Epoch 43/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1795.6295 - val_loss: 1328.6577\n",
      "Epoch 44/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1747.9287 - val_loss: 1312.3392\n",
      "Epoch 45/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1701.3480 - val_loss: 1296.8387\n",
      "Epoch 46/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1655.8674 - val_loss: 1282.1389\n",
      "Epoch 47/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1611.4688 - val_loss: 1268.2227\n",
      "Epoch 48/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1568.1333 - val_loss: 1255.0729\n",
      "Epoch 49/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1525.8427 - val_loss: 1242.6729\n",
      "Epoch 50/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1484.5793 - val_loss: 1231.0062\n",
      "Epoch 51/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1444.3257 - val_loss: 1220.0563\n",
      "Epoch 52/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1405.0642 - val_loss: 1209.8074\n",
      "Epoch 53/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1366.7783 - val_loss: 1200.2432\n",
      "Epoch 54/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1329.4507 - val_loss: 1191.3480\n",
      "Epoch 55/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1293.0651 - val_loss: 1183.1064\n",
      "Epoch 56/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1257.6055 - val_loss: 1175.5026\n",
      "Epoch 57/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1223.0547 - val_loss: 1168.5212\n",
      "Epoch 58/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1189.3982 - val_loss: 1162.1475\n",
      "Epoch 59/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1156.6194 - val_loss: 1156.3649\n",
      "Epoch 60/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1124.7026 - val_loss: 1150.6796\n",
      "Epoch 61/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1093.6364 - val_loss: 1146.5220\n",
      "Epoch 62/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1063.3947 - val_loss: 1142.4285\n",
      "Epoch 63/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1033.9727 - val_loss: 1138.8683\n",
      "Epoch 64/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1005.3525 - val_loss: 1135.8268\n",
      "Epoch 65/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 977.5187 - val_loss: 1133.2903\n",
      "Epoch 66/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 950.4575 - val_loss: 1131.2441\n",
      "Epoch 67/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 924.1534 - val_loss: 1129.6742\n",
      "Epoch 68/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 898.5927 - val_loss: 1128.5668\n",
      "Epoch 69/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 873.7612 - val_loss: 1127.9077\n",
      "Epoch 70/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 849.6442 - val_loss: 1127.6836\n",
      "Epoch 71/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 826.2280 - val_loss: 1127.8805\n",
      "Epoch 72/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 803.4990 - val_loss: 1128.4852\n",
      "Epoch 73/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 781.4435 - val_loss: 1129.4843\n",
      "Epoch 74/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 760.0479 - val_loss: 1130.8645\n",
      "Epoch 75/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 739.2980 - val_loss: 1132.6125\n",
      "Epoch 76/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 719.1813 - val_loss: 1134.7153\n",
      "Epoch 77/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 699.6842 - val_loss: 1137.1602\n",
      "Epoch 78/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 680.7938 - val_loss: 1139.9341\n",
      "Epoch 79/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 662.4968 - val_loss: 1143.0248\n",
      "Epoch 80/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 644.7806 - val_loss: 1146.4193\n",
      "Epoch 81/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 627.6324 - val_loss: 1150.1053\n",
      "Epoch 82/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 611.0397 - val_loss: 1154.0709\n",
      "Epoch 83/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 594.9896 - val_loss: 1158.3033\n",
      "Epoch 84/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 579.4703 - val_loss: 1162.7910\n",
      "Epoch 85/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 564.4693 - val_loss: 1167.5219\n",
      "Epoch 86/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 549.9744 - val_loss: 1172.4840\n",
      "Epoch 87/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 535.9735 - val_loss: 1177.6664\n",
      "Epoch 88/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 522.4550 - val_loss: 1183.0568\n",
      "Epoch 89/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 509.4070 - val_loss: 1188.6443\n",
      "Epoch 90/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 496.8179 - val_loss: 1194.4181\n",
      "Epoch 91/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 484.6763 - val_loss: 1200.3665\n",
      "Epoch 92/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 472.9708 - val_loss: 1206.4791\n",
      "Epoch 93/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 461.6898 - val_loss: 1212.7448\n",
      "Epoch 94/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 450.8229 - val_loss: 1219.1531\n",
      "Epoch 95/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 440.3586 - val_loss: 1225.6940\n",
      "Epoch 96/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 430.2863 - val_loss: 1232.3566\n",
      "Epoch 97/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 420.5952 - val_loss: 1239.1312\n",
      "Epoch 98/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 411.2750 - val_loss: 1245.9653\n",
      "Epoch 99/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 402.3149 - val_loss: 1253.0018\n",
      "Epoch 100/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 393.7049 - val_loss: 1260.0574\n",
      "Epoch 101/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 385.4350 - val_loss: 1267.1870\n",
      "Epoch 102/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 377.4949 - val_loss: 1274.3816\n",
      "Epoch 103/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 369.8752 - val_loss: 1281.6322\n",
      "Epoch 104/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 362.5658 - val_loss: 1288.9304\n",
      "Epoch 105/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 355.5574 - val_loss: 1296.2676\n",
      "Epoch 106/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 348.8406 - val_loss: 1303.6350\n",
      "Epoch 107/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 342.4062 - val_loss: 1311.0250\n",
      "Epoch 108/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 336.2454 - val_loss: 1318.4299\n",
      "Epoch 109/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 330.3487 - val_loss: 1325.8418\n",
      "Epoch 110/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 324.7080 - val_loss: 1333.2534\n",
      "Epoch 111/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 319.3144 - val_loss: 1340.6572\n",
      "Epoch 112/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 314.1596 - val_loss: 1348.0463\n",
      "Epoch 113/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 309.2354 - val_loss: 1355.4143\n",
      "Epoch 114/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 304.5335 - val_loss: 1362.7540\n",
      "Epoch 115/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 300.0464 - val_loss: 1370.0593\n",
      "Epoch 116/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 295.7660 - val_loss: 1377.3247\n",
      "Epoch 117/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 291.6848 - val_loss: 1384.5437\n",
      "Epoch 118/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 287.7955 - val_loss: 1391.7112\n",
      "Epoch 119/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 284.0908 - val_loss: 1398.8217\n",
      "Epoch 120/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 280.5636 - val_loss: 1405.8698\n",
      "Epoch 121/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 277.2072 - val_loss: 1412.8503\n",
      "Epoch 122/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 274.0147 - val_loss: 1419.7592\n",
      "Epoch 123/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 270.9797 - val_loss: 1426.5911\n",
      "Epoch 124/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 268.0958 - val_loss: 1433.3433\n",
      "Epoch 125/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 265.3568 - val_loss: 1440.0109\n",
      "Epoch 126/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 262.7564 - val_loss: 1446.5898\n",
      "Epoch 127/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 260.2892 - val_loss: 1453.0774\n",
      "Epoch 128/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 257.9493 - val_loss: 1459.4703\n",
      "Epoch 129/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 255.7311 - val_loss: 1465.7654\n",
      "Epoch 130/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 253.6293 - val_loss: 1471.9595\n",
      "Epoch 131/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 251.6387 - val_loss: 1478.0502\n",
      "Epoch 132/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 249.7544 - val_loss: 1484.0353\n",
      "Epoch 133/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 247.9715 - val_loss: 1489.9122\n",
      "Epoch 134/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 246.2855 - val_loss: 1495.6797\n",
      "Epoch 135/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 244.6912 - val_loss: 1501.3352\n",
      "Epoch 136/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 243.1850 - val_loss: 1506.8784\n",
      "Epoch 137/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 241.7623 - val_loss: 1512.3074\n",
      "Epoch 138/500\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 240.4191 - val_loss: 1517.6207\n",
      "Epoch 139/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 239.1514 - val_loss: 1522.8185\n",
      "Epoch 140/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 237.9556 - val_loss: 1527.8986\n",
      "Epoch 141/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 236.8280 - val_loss: 1532.8617\n",
      "Epoch 142/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 235.7652 - val_loss: 1537.7065\n",
      "Epoch 143/500\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 234.7637 - val_loss: 1542.4340\n",
      "Epoch 144/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 233.8205 - val_loss: 1547.0435\n",
      "Epoch 145/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 232.9324 - val_loss: 1551.5348\n",
      "Epoch 146/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 232.0966 - val_loss: 1555.9083\n",
      "Epoch 147/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 231.3101 - val_loss: 1560.1660\n",
      "Epoch 148/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 230.5703 - val_loss: 1564.3068\n",
      "Epoch 149/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 229.8746 - val_loss: 1568.3320\n",
      "Epoch 150/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 229.2208 - val_loss: 1572.2424\n",
      "Epoch 151/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 228.6064 - val_loss: 1576.0391\n",
      "Epoch 152/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 228.0291 - val_loss: 1579.7238\n",
      "Epoch 153/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 227.4868 - val_loss: 1583.2965\n",
      "Epoch 154/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 226.9777 - val_loss: 1586.7596\n",
      "Epoch 155/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 226.4997 - val_loss: 1590.1144\n",
      "Epoch 156/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 226.0510 - val_loss: 1593.3612\n",
      "Epoch 157/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 225.6301 - val_loss: 1596.5037\n",
      "Epoch 158/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 225.2351 - val_loss: 1599.5416\n",
      "Epoch 159/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 224.8644 - val_loss: 1602.4779\n",
      "Epoch 160/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 224.5169 - val_loss: 1605.3140\n",
      "Epoch 161/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 224.1909 - val_loss: 1608.0524\n",
      "Epoch 162/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 223.8853 - val_loss: 1610.6937\n",
      "Epoch 163/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 223.5988 - val_loss: 1613.2410\n",
      "Epoch 164/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 223.3300 - val_loss: 1615.6974\n",
      "Epoch 165/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 223.0781 - val_loss: 1618.0624\n",
      "Epoch 166/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 222.8421 - val_loss: 1620.3390\n",
      "Epoch 167/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 222.6208 - val_loss: 1622.5302\n",
      "Epoch 168/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 222.4133 - val_loss: 1624.6366\n",
      "Epoch 169/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 222.2190 - val_loss: 1626.6620\n",
      "Epoch 170/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 222.0367 - val_loss: 1628.6082\n",
      "Epoch 171/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 221.8660 - val_loss: 1630.4764\n",
      "Epoch 172/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 221.7059 - val_loss: 1632.2690\n",
      "Epoch 173/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 221.5559 - val_loss: 1633.9889\n",
      "Epoch 174/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 221.4153 - val_loss: 1635.6379\n",
      "Epoch 175/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 221.2835 - val_loss: 1637.2186\n",
      "Epoch 176/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 221.1599 - val_loss: 1638.7322\n",
      "Epoch 177/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 221.0442 - val_loss: 1640.1802\n",
      "Epoch 178/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 220.9357 - val_loss: 1641.5673\n",
      "Epoch 179/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 220.8338 - val_loss: 1642.8933\n",
      "Epoch 180/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 220.7384 - val_loss: 1644.1608\n",
      "Epoch 181/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 220.6490 - val_loss: 1645.3715\n",
      "Epoch 182/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 220.5651 - val_loss: 1646.5282\n",
      "Epoch 183/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 220.4864 - val_loss: 1647.6327\n",
      "Epoch 184/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 220.4127 - val_loss: 1648.6866\n",
      "Epoch 185/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 220.3434 - val_loss: 1649.6912\n",
      "Epoch 186/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 220.2786 - val_loss: 1650.6489\n",
      "Epoch 187/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 220.2178 - val_loss: 1651.5610\n",
      "Epoch 188/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 220.1608 - val_loss: 1652.4302\n",
      "Epoch 189/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 220.1072 - val_loss: 1653.2572\n",
      "Epoch 190/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 220.0571 - val_loss: 1654.0452\n",
      "Epoch 191/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 220.0099 - val_loss: 1654.7946\n",
      "Epoch 192/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.9658 - val_loss: 1655.5061\n",
      "Epoch 193/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.9244 - val_loss: 1656.1836\n",
      "Epoch 194/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.8855 - val_loss: 1656.8264\n",
      "Epoch 195/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.8491 - val_loss: 1657.4369\n",
      "Epoch 196/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.8148 - val_loss: 1658.0167\n",
      "Epoch 197/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.7829 - val_loss: 1658.5671\n",
      "Epoch 198/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.7527 - val_loss: 1659.0886\n",
      "Epoch 199/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.7245 - val_loss: 1659.5831\n",
      "Epoch 200/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.6981 - val_loss: 1660.0521\n",
      "Epoch 201/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.6733 - val_loss: 1660.4966\n",
      "Epoch 202/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.6500 - val_loss: 1660.9170\n",
      "Epoch 203/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 219.6282 - val_loss: 1661.3156\n",
      "Epoch 204/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.6078 - val_loss: 1661.6918\n",
      "Epoch 205/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.5888 - val_loss: 1662.0493\n",
      "Epoch 206/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.5707 - val_loss: 1662.3862\n",
      "Epoch 207/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.5540 - val_loss: 1662.7054\n",
      "Epoch 208/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.5383 - val_loss: 1663.0067\n",
      "Epoch 209/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.5235 - val_loss: 1663.2910\n",
      "Epoch 210/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.5097 - val_loss: 1663.5591\n",
      "Epoch 211/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4968 - val_loss: 1663.8129\n",
      "Epoch 212/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4848 - val_loss: 1664.0516\n",
      "Epoch 213/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4736 - val_loss: 1664.2778\n",
      "Epoch 214/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4630 - val_loss: 1664.4908\n",
      "Epoch 215/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4531 - val_loss: 1664.6920\n",
      "Epoch 216/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4439 - val_loss: 1664.8815\n",
      "Epoch 217/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4352 - val_loss: 1665.0588\n",
      "Epoch 218/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4272 - val_loss: 1665.2273\n",
      "Epoch 219/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4197 - val_loss: 1665.3851\n",
      "Epoch 220/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4127 - val_loss: 1665.5337\n",
      "Epoch 221/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4062 - val_loss: 1665.6736\n",
      "Epoch 222/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4002 - val_loss: 1665.8053\n",
      "Epoch 223/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3946 - val_loss: 1665.9293\n",
      "Epoch 224/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3893 - val_loss: 1666.0457\n",
      "Epoch 225/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3844 - val_loss: 1666.1556\n",
      "Epoch 226/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3799 - val_loss: 1666.2587\n",
      "Epoch 227/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3756 - val_loss: 1666.3541\n",
      "Epoch 228/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3717 - val_loss: 1666.4452\n",
      "Epoch 229/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3681 - val_loss: 1666.5314\n",
      "Epoch 230/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3647 - val_loss: 1666.6118\n",
      "Epoch 231/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3616 - val_loss: 1666.6864\n",
      "Epoch 232/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3587 - val_loss: 1666.7571\n",
      "Epoch 233/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3561 - val_loss: 1666.8234\n",
      "Epoch 234/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 219.3536 - val_loss: 1666.8854\n",
      "Epoch 235/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3514 - val_loss: 1666.9431\n",
      "Epoch 236/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3493 - val_loss: 1666.9978\n",
      "Epoch 237/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3473 - val_loss: 1667.0496\n",
      "Epoch 238/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3456 - val_loss: 1667.0962\n",
      "Epoch 239/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3439 - val_loss: 1667.1414\n",
      "Epoch 240/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3425 - val_loss: 1667.1832\n",
      "Epoch 241/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3411 - val_loss: 1667.2233\n",
      "Epoch 242/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3398 - val_loss: 1667.2594\n",
      "Epoch 243/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3388 - val_loss: 1667.2937\n",
      "Epoch 244/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3378 - val_loss: 1667.3257\n",
      "Epoch 245/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3369 - val_loss: 1667.3557\n",
      "Epoch 246/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3360 - val_loss: 1667.3843\n",
      "Epoch 247/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3353 - val_loss: 1667.4113\n",
      "Epoch 248/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3346 - val_loss: 1667.4358\n",
      "Epoch 249/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3340 - val_loss: 1667.4586\n",
      "Epoch 250/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3335 - val_loss: 1667.4801\n",
      "Epoch 251/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3330 - val_loss: 1667.5005\n",
      "Epoch 252/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3325 - val_loss: 1667.5188\n",
      "Epoch 253/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3322 - val_loss: 1667.5360\n",
      "Epoch 254/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3320 - val_loss: 1667.5533\n",
      "Epoch 255/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3317 - val_loss: 1667.5680\n",
      "Epoch 256/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3315 - val_loss: 1667.5826\n",
      "Epoch 257/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3312 - val_loss: 1667.5957\n",
      "Epoch 258/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3311 - val_loss: 1667.6080\n",
      "Epoch 259/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3310 - val_loss: 1667.6198\n",
      "Epoch 260/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3309 - val_loss: 1667.6300\n",
      "Epoch 261/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 219.3309 - val_loss: 1667.6400\n",
      "Epoch 262/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 219.3308 - val_loss: 1667.6495\n",
      "Epoch 263/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3308 - val_loss: 1667.6577\n",
      "Epoch 264/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3308 - val_loss: 1667.6656\n",
      "Epoch 265/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3308 - val_loss: 1667.6733\n",
      "Epoch 266/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3309 - val_loss: 1667.6804\n",
      "Epoch 267/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3310 - val_loss: 1667.6866\n",
      "Epoch 268/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3311 - val_loss: 1667.6917\n",
      "Epoch 269/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3311 - val_loss: 1667.6971\n",
      "Epoch 270/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 219.3313 - val_loss: 1667.7029\n",
      "Epoch 271/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3313 - val_loss: 1667.7068\n",
      "Epoch 272/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3316 - val_loss: 1667.7111\n",
      "Epoch 273/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3316 - val_loss: 1667.7148\n",
      "Epoch 274/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3318 - val_loss: 1667.7183\n",
      "Epoch 275/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3320 - val_loss: 1667.7212\n",
      "Epoch 276/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3322 - val_loss: 1667.7244\n",
      "Epoch 277/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3323 - val_loss: 1667.7274\n",
      "Epoch 278/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3326 - val_loss: 1667.7300\n",
      "Epoch 279/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3327 - val_loss: 1667.7321\n",
      "Epoch 280/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3328 - val_loss: 1667.7335\n",
      "Epoch 281/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3330 - val_loss: 1667.7358\n",
      "Epoch 282/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3333 - val_loss: 1667.7375\n",
      "Epoch 283/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3334 - val_loss: 1667.7391\n",
      "Epoch 284/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 219.3335 - val_loss: 1667.7396\n",
      "Epoch 285/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3337 - val_loss: 1667.7404\n",
      "Epoch 286/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3340 - val_loss: 1667.7417\n",
      "Epoch 287/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3341 - val_loss: 1667.7427\n",
      "Epoch 288/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3343 - val_loss: 1667.7429\n",
      "Epoch 289/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3345 - val_loss: 1667.7444\n",
      "Epoch 290/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3347 - val_loss: 1667.7444\n",
      "Epoch 291/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3349 - val_loss: 1667.7449\n",
      "Epoch 292/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3350 - val_loss: 1667.7445\n",
      "Epoch 293/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3353 - val_loss: 1667.7439\n",
      "Epoch 294/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3354 - val_loss: 1667.7434\n",
      "Epoch 295/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3357 - val_loss: 1667.7434\n",
      "Epoch 296/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3358 - val_loss: 1667.7429\n",
      "Epoch 297/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3360 - val_loss: 1667.7429\n",
      "Epoch 298/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3362 - val_loss: 1667.7433\n",
      "Epoch 299/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 219.3363 - val_loss: 1667.7422\n",
      "Epoch 300/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3365 - val_loss: 1667.7415\n",
      "Epoch 301/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3367 - val_loss: 1667.7407\n",
      "Epoch 302/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3367 - val_loss: 1667.7402\n",
      "Epoch 303/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3369 - val_loss: 1667.7394\n",
      "Epoch 304/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3371 - val_loss: 1667.7378\n",
      "Epoch 305/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3373 - val_loss: 1667.7366\n",
      "Epoch 306/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3375 - val_loss: 1667.7356\n",
      "Epoch 307/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 219.3376 - val_loss: 1667.7338\n",
      "Epoch 308/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3378 - val_loss: 1667.7322\n",
      "Epoch 309/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3380 - val_loss: 1667.7301\n",
      "Epoch 310/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3381 - val_loss: 1667.7284\n",
      "Epoch 311/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3383 - val_loss: 1667.7271\n",
      "Epoch 312/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3384 - val_loss: 1667.7253\n",
      "Epoch 313/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3385 - val_loss: 1667.7242\n",
      "Epoch 314/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3386 - val_loss: 1667.7214\n",
      "Epoch 315/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3388 - val_loss: 1667.7197\n",
      "Epoch 316/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3389 - val_loss: 1667.7181\n",
      "Epoch 317/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3390 - val_loss: 1667.7157\n",
      "Epoch 318/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3392 - val_loss: 1667.7145\n",
      "Epoch 319/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3392 - val_loss: 1667.7119\n",
      "Epoch 320/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3393 - val_loss: 1667.7086\n",
      "Epoch 321/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3395 - val_loss: 1667.7054\n",
      "Epoch 322/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3395 - val_loss: 1667.7020\n",
      "Epoch 323/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3398 - val_loss: 1667.6992\n",
      "Epoch 324/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3400 - val_loss: 1667.6968\n",
      "Epoch 325/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3400 - val_loss: 1667.6935\n",
      "Epoch 326/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3400 - val_loss: 1667.6895\n",
      "Epoch 327/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3402 - val_loss: 1667.6864\n",
      "Epoch 328/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3402 - val_loss: 1667.6819\n",
      "Epoch 329/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3403 - val_loss: 1667.6779\n",
      "Epoch 330/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3405 - val_loss: 1667.6737\n",
      "Epoch 331/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 219.3406 - val_loss: 1667.6696\n",
      "Epoch 332/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3406 - val_loss: 1667.6649\n",
      "Epoch 333/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3408 - val_loss: 1667.6605\n",
      "Epoch 334/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3408 - val_loss: 1667.6554\n",
      "Epoch 335/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3409 - val_loss: 1667.6505\n",
      "Epoch 336/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3409 - val_loss: 1667.6440\n",
      "Epoch 337/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3409 - val_loss: 1667.6370\n",
      "Epoch 338/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3410 - val_loss: 1667.6295\n",
      "Epoch 339/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3412 - val_loss: 1667.6226\n",
      "Epoch 340/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3413 - val_loss: 1667.6146\n",
      "Epoch 341/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3413 - val_loss: 1667.6056\n",
      "Epoch 342/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3414 - val_loss: 1667.5959\n",
      "Epoch 343/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3415 - val_loss: 1667.5862\n",
      "Epoch 344/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3416 - val_loss: 1667.5764\n",
      "Epoch 345/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3417 - val_loss: 1667.5654\n",
      "Epoch 346/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3417 - val_loss: 1667.5521\n",
      "Epoch 347/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3418 - val_loss: 1667.5375\n",
      "Epoch 348/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3418 - val_loss: 1667.5211\n",
      "Epoch 349/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3419 - val_loss: 1667.5032\n",
      "Epoch 350/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3419 - val_loss: 1667.4827\n",
      "Epoch 351/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3420 - val_loss: 1667.4589\n",
      "Epoch 352/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3420 - val_loss: 1667.4308\n",
      "Epoch 353/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3421 - val_loss: 1667.3976\n",
      "Epoch 354/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 219.3422 - val_loss: 1667.3577\n",
      "Epoch 355/500\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 219.3423 - val_loss: 1667.3070\n",
      "Epoch 356/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 219.3423 - val_loss: 1667.2415\n",
      "Epoch 357/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 219.3423 - val_loss: 1667.1517\n",
      "Epoch 358/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 219.3424 - val_loss: 1667.0225\n",
      "Epoch 359/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3424 - val_loss: 1666.8401\n",
      "Epoch 360/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3424 - val_loss: 1666.6188\n",
      "Epoch 361/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3434 - val_loss: 1660.9282\n",
      "Epoch 362/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3432 - val_loss: 1667.0355\n",
      "Epoch 363/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3417 - val_loss: 1666.9032\n",
      "Epoch 364/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3416 - val_loss: 1662.2205\n",
      "Epoch 365/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 211.5925 - val_loss: 1594.8848\n",
      "Epoch 366/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 225.6695 - val_loss: 1598.7329\n",
      "Epoch 367/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 225.1962 - val_loss: 1603.3433\n",
      "Epoch 368/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 224.6445 - val_loss: 1607.7305\n",
      "Epoch 369/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 224.1417 - val_loss: 1611.8336\n",
      "Epoch 370/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 223.6913 - val_loss: 1615.6670\n",
      "Epoch 371/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 223.2876 - val_loss: 1619.2439\n",
      "Epoch 372/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 222.9256 - val_loss: 1622.5829\n",
      "Epoch 373/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 222.6005 - val_loss: 1625.6987\n",
      "Epoch 374/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 222.3081 - val_loss: 1628.6051\n",
      "Epoch 375/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 222.0447 - val_loss: 1631.3159\n",
      "Epoch 376/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 221.8072 - val_loss: 1633.8434\n",
      "Epoch 377/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 221.5930 - val_loss: 1636.2009\n",
      "Epoch 378/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 221.3991 - val_loss: 1638.3979\n",
      "Epoch 379/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 221.2237 - val_loss: 1640.4453\n",
      "Epoch 380/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 221.0647 - val_loss: 1642.3539\n",
      "Epoch 381/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 220.9204 - val_loss: 1644.1312\n",
      "Epoch 382/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 220.7894 - val_loss: 1645.7880\n",
      "Epoch 383/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 220.6702 - val_loss: 1647.3314\n",
      "Epoch 384/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 220.5617 - val_loss: 1648.7676\n",
      "Epoch 385/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 220.4628 - val_loss: 1650.1066\n",
      "Epoch 386/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 220.3725 - val_loss: 1651.3519\n",
      "Epoch 387/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 220.2902 - val_loss: 1652.5128\n",
      "Epoch 388/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 220.2149 - val_loss: 1653.5927\n",
      "Epoch 389/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 220.1460 - val_loss: 1654.5977\n",
      "Epoch 390/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 220.0830 - val_loss: 1655.5344\n",
      "Epoch 391/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 220.0252 - val_loss: 1656.4062\n",
      "Epoch 392/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.9720 - val_loss: 1657.2183\n",
      "Epoch 393/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.9233 - val_loss: 1657.9730\n",
      "Epoch 394/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.8785 - val_loss: 1658.6764\n",
      "Epoch 395/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.8373 - val_loss: 1659.3293\n",
      "Epoch 396/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.7996 - val_loss: 1659.9391\n",
      "Epoch 397/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.7646 - val_loss: 1660.5050\n",
      "Epoch 398/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.7324 - val_loss: 1661.0314\n",
      "Epoch 399/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.7029 - val_loss: 1661.5214\n",
      "Epoch 400/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 219.6756 - val_loss: 1661.9771\n",
      "Epoch 401/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.6505 - val_loss: 1662.4006\n",
      "Epoch 402/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.6273 - val_loss: 1662.7966\n",
      "Epoch 403/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.6059 - val_loss: 1663.1638\n",
      "Epoch 404/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.5860 - val_loss: 1663.5048\n",
      "Epoch 405/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.5676 - val_loss: 1663.8217\n",
      "Epoch 406/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.5507 - val_loss: 1664.1174\n",
      "Epoch 407/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.5350 - val_loss: 1664.3915\n",
      "Epoch 408/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.5206 - val_loss: 1664.6481\n",
      "Epoch 409/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.5072 - val_loss: 1664.8867\n",
      "Epoch 410/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4946 - val_loss: 1665.1075\n",
      "Epoch 411/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4831 - val_loss: 1665.3142\n",
      "Epoch 412/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4725 - val_loss: 1665.5046\n",
      "Epoch 413/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4626 - val_loss: 1665.6829\n",
      "Epoch 414/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4535 - val_loss: 1665.8480\n",
      "Epoch 415/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4450 - val_loss: 1666.0021\n",
      "Epoch 416/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4372 - val_loss: 1666.1450\n",
      "Epoch 417/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4298 - val_loss: 1666.2778\n",
      "Epoch 418/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4232 - val_loss: 1666.4016\n",
      "Epoch 419/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4168 - val_loss: 1666.5167\n",
      "Epoch 420/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.4110 - val_loss: 1666.6240\n",
      "Epoch 421/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4055 - val_loss: 1666.7235\n",
      "Epoch 422/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.4006 - val_loss: 1666.8156\n",
      "Epoch 423/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3959 - val_loss: 1666.9021\n",
      "Epoch 424/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3916 - val_loss: 1666.9827\n",
      "Epoch 425/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3875 - val_loss: 1667.0560\n",
      "Epoch 426/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3839 - val_loss: 1667.1259\n",
      "Epoch 427/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3804 - val_loss: 1667.1902\n",
      "Epoch 428/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3772 - val_loss: 1667.2494\n",
      "Epoch 429/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3742 - val_loss: 1667.3048\n",
      "Epoch 430/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 219.3715 - val_loss: 1667.3567\n",
      "Epoch 431/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3689 - val_loss: 1667.4049\n",
      "Epoch 432/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3666 - val_loss: 1667.4487\n",
      "Epoch 433/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3643 - val_loss: 1667.4915\n",
      "Epoch 434/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3621 - val_loss: 1667.5297\n",
      "Epoch 435/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 219.3603 - val_loss: 1667.5654\n",
      "Epoch 436/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3587 - val_loss: 1667.5997\n",
      "Epoch 437/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3569 - val_loss: 1667.6301\n",
      "Epoch 438/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3553 - val_loss: 1667.6588\n",
      "Epoch 439/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3540 - val_loss: 1667.6860\n",
      "Epoch 440/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3527 - val_loss: 1667.7120\n",
      "Epoch 441/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3514 - val_loss: 1667.7343\n",
      "Epoch 442/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3503 - val_loss: 1667.7562\n",
      "Epoch 443/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3491 - val_loss: 1667.7755\n",
      "Epoch 444/500\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 219.3482 - val_loss: 1667.7949\n",
      "Epoch 445/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3474 - val_loss: 1667.8126\n",
      "Epoch 446/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3465 - val_loss: 1667.8290\n",
      "Epoch 447/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3457 - val_loss: 1667.8442\n",
      "Epoch 448/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3448 - val_loss: 1667.8575\n",
      "Epoch 449/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3442 - val_loss: 1667.8700\n",
      "Epoch 450/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3436 - val_loss: 1667.8826\n",
      "Epoch 451/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3430 - val_loss: 1667.8943\n",
      "Epoch 452/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3424 - val_loss: 1667.9045\n",
      "Epoch 453/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.3419 - val_loss: 1667.9139\n",
      "Epoch 454/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3414 - val_loss: 1667.9231\n",
      "Epoch 455/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3411 - val_loss: 1667.9304\n",
      "Epoch 456/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3407 - val_loss: 1667.9386\n",
      "Epoch 457/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3403 - val_loss: 1667.9460\n",
      "Epoch 458/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3400 - val_loss: 1667.9534\n",
      "Epoch 459/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3396 - val_loss: 1667.9590\n",
      "Epoch 460/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3393 - val_loss: 1667.9652\n",
      "Epoch 461/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3389 - val_loss: 1667.9701\n",
      "Epoch 462/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3387 - val_loss: 1667.9747\n",
      "Epoch 463/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3386 - val_loss: 1667.9806\n",
      "Epoch 464/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3383 - val_loss: 1667.9855\n",
      "Epoch 465/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3380 - val_loss: 1667.9888\n",
      "Epoch 466/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3378 - val_loss: 1667.9927\n",
      "Epoch 467/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3377 - val_loss: 1667.9968\n",
      "Epoch 468/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 219.3375 - val_loss: 1668.0001\n",
      "Epoch 469/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3373 - val_loss: 1668.0029\n",
      "Epoch 470/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3371 - val_loss: 1668.0051\n",
      "Epoch 471/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3371 - val_loss: 1668.0072\n",
      "Epoch 472/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3370 - val_loss: 1668.0093\n",
      "Epoch 473/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3369 - val_loss: 1668.0106\n",
      "Epoch 474/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3368 - val_loss: 1668.0127\n",
      "Epoch 475/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3368 - val_loss: 1668.0143\n",
      "Epoch 476/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3367 - val_loss: 1668.0153\n",
      "Epoch 477/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3366 - val_loss: 1668.0165\n",
      "Epoch 478/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3365 - val_loss: 1668.0179\n",
      "Epoch 479/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3365 - val_loss: 1668.0194\n",
      "Epoch 480/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3364 - val_loss: 1668.0209\n",
      "Epoch 481/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3364 - val_loss: 1668.0222\n",
      "Epoch 482/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3363 - val_loss: 1668.0236\n",
      "Epoch 483/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3362 - val_loss: 1668.0247\n",
      "Epoch 484/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3362 - val_loss: 1668.0267\n",
      "Epoch 485/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3361 - val_loss: 1668.0277\n",
      "Epoch 486/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3361 - val_loss: 1668.0292\n",
      "Epoch 487/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3360 - val_loss: 1668.0302\n",
      "Epoch 488/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 219.3359 - val_loss: 1668.0308\n",
      "Epoch 489/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3359 - val_loss: 1668.0317\n",
      "Epoch 490/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3359 - val_loss: 1668.0330\n",
      "Epoch 491/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3358 - val_loss: 1668.0338\n",
      "Epoch 492/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3358 - val_loss: 1668.0349\n",
      "Epoch 493/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3357 - val_loss: 1668.0359\n",
      "Epoch 494/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3357 - val_loss: 1668.0370\n",
      "Epoch 495/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3356 - val_loss: 1668.0385\n",
      "Epoch 496/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3356 - val_loss: 1668.0393\n",
      "Epoch 497/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.3355 - val_loss: 1668.0405\n",
      "Epoch 498/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3355 - val_loss: 1668.0414\n",
      "Epoch 499/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3355 - val_loss: 1668.0424\n",
      "Epoch 500/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 219.3354 - val_loss: 1668.0435\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(89.3180, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0010, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(-0.0204, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.2194, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 374ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.20490686e+01, 7.20314216e+01, 7.20137745e+01, 6.97612745e+01,\n",
       "        1.29356590e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.17175280e+01, 7.16192087e+01, 7.14580065e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.19542227e+01, 7.18559034e+01,\n",
       "        7.17575840e+01, 7.16592647e+01, 7.15299020e+01, 7.13534314e+01,\n",
       "        7.11769608e+01, 7.10004902e+01, 6.82656863e+01, 6.83389000e-02,\n",
       "        0.00000000e+00, 7.16001001e+01, 7.14253268e+01, 7.12498562e+01,\n",
       "        7.10723856e+01, 7.08918301e+01, 7.05398889e+01, 7.01859477e+01,\n",
       "        6.98330065e+01, 6.94900327e+01, 0.00000000e+00, 3.76206400e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.04031100e-01, 8.66873000e-01,\n",
       "        8.27256700e-01, 6.09688200e-01, 0.00000000e+00, 7.10397059e+01,\n",
       "        6.85264706e+01, 0.00000000e+00, 0.00000000e+00, 7.16228501e+01,\n",
       "        7.14645425e+01, 7.12880719e+01, 7.11116013e+01, 7.09351307e+01,\n",
       "        7.06173203e+01, 7.02643791e+01, 6.99114379e+01, 6.95614947e+01,\n",
       "        0.00000000e+00, 5.72564000e-02, 7.10070261e+01, 7.10761111e+01,\n",
       "        7.10408169e+01, 7.10055229e+01, 7.07022876e+01, 7.34305626e+01,\n",
       "        7.22885457e+01, 7.17721499e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.18126755e+01, 2.03491600e-01, 0.00000000e+00,\n",
       "        1.64696300e-01, 0.00000000e+00, 2.79348900e-01, 4.81617000e-01,\n",
       "        6.88145752e+01, 0.00000000e+00, 1.72625279e+00, 0.00000000e+00,\n",
       "        2.28045732e-01, 0.00000000e+00, 2.45720506e-01, 2.25578308e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.30577314e-03,\n",
       "        0.00000000e+00, 2.30525568e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.14231861e-01, 7.76045203e-01, 6.30600035e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63.15753228, 63.14988044, 63.1422286 , 63.13457676, 63.12692492,\n",
       "       63.11927308, 63.11162123, 63.10396939, 63.09631755, 63.08866571,\n",
       "       63.08101387, 63.07336203, 63.06571019, 63.05805835, 63.0504065 ,\n",
       "       63.04275466, 63.03510282, 63.02745098, 63.01979914, 63.0121473 ,\n",
       "       63.00449546, 62.99684362, 62.98919177, 62.98153993, 62.97388809,\n",
       "       62.96623625, 62.95858441, 62.95093257, 62.94328073, 62.93562889,\n",
       "       62.92797704, 62.9203252 , 62.91267336, 62.90502152, 62.89736968,\n",
       "       62.88971784, 62.882066  , 62.87441416, 62.86676231, 62.85911047,\n",
       "       62.85145863, 62.84380679, 62.83615495, 62.82850311, 62.82085127,\n",
       "       62.81319943, 62.80554758, 62.79789574, 62.7902439 , 62.78259206,\n",
       "       62.77494022, 62.76728838, 62.75963654, 62.7519847 , 62.74433286,\n",
       "       62.73668101, 62.72902917, 62.72137733, 62.71372549, 62.70607365,\n",
       "       62.69842181, 62.69076997, 62.68311813, 62.67546628, 62.66781444,\n",
       "       62.6601626 , 62.65251076, 62.64485892, 62.63720708, 62.62955524,\n",
       "       62.6219034 , 62.61425155, 62.60659971, 62.59894787, 62.59129603,\n",
       "       62.58364419, 62.57599235, 62.56834051, 62.56068867, 62.55303682,\n",
       "       62.54538498, 62.53773314, 62.5300813 , 62.52242946, 62.51477762,\n",
       "       62.50712578, 62.49947394, 62.49182209, 62.48417025, 62.47651841,\n",
       "       62.46886657, 62.46121473, 62.45356289, 62.44591105, 62.43825921,\n",
       "       62.43060736, 62.42295552, 62.41530368, 62.40765184, 62.4       ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.290691827044775\n",
      "37.5352355897514\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
