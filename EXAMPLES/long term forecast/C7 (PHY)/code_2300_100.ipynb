{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2395    63.195791\n",
       "2396    63.188140\n",
       "2397    63.180488\n",
       "2398    63.172836\n",
       "2399    63.165184\n",
       "Name: C7, Length: 2400, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c7_interpolated_2300_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2295     0.631547\n",
       "2296     0.000000\n",
       "2297     0.210530\n",
       "2298     0.000000\n",
       "2299     0.282563\n",
       "Name: C7, Length: 2300, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2300)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.387115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.174230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.961345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.748459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     92.600000  0.000298\n",
       "1     92.387115  0.000298\n",
       "2     92.174230  0.000297\n",
       "3     91.961345  0.000297\n",
       "4     91.748459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 89.3180  # Value for C0\n",
    "K0 = -0.0010  # Value for K0\n",
    "K1 = 0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = -0.0204    # Value for b\n",
    "c = 2.2194    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    92.600000    92.387115    92.174230    91.961345    91.748459   \n",
      "351    92.387115    92.174230    91.961345    91.748459    91.535574   \n",
      "352    92.174230    91.961345    91.748459    91.535574    91.322689   \n",
      "353    91.961345    91.748459    91.535574    91.322689    91.109804   \n",
      "354    91.748459    91.535574    91.322689    91.109804    90.896919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    91.535574    91.322689    91.109804    90.896919    90.691597  ...   \n",
      "351    91.322689    91.109804    90.896919    90.691597    90.579552  ...   \n",
      "352    91.109804    90.896919    90.691597    90.579552    90.467507  ...   \n",
      "353    90.896919    90.691597    90.579552    90.467507    90.355462  ...   \n",
      "354    90.691597    90.579552    90.467507    90.355462    90.243417  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   80.261671    0.000263   80.252334    0.000263   80.242997    0.000263   \n",
      "351   80.252334    0.000263   80.242997    0.000263   80.233660    0.000262   \n",
      "352   80.242997    0.000263   80.233660    0.000262   80.224323    0.000262   \n",
      "353   80.233660    0.000262   80.224323    0.000262   80.214986    0.000262   \n",
      "354   80.224323    0.000262   80.214986    0.000262   80.205649    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   80.233660    0.000262   80.224323    0.000262  \n",
      "351   80.224323    0.000262   80.214986    0.000262  \n",
      "352   80.214986    0.000262   80.205649    0.000262  \n",
      "353   80.205649    0.000262   80.196312    0.000262  \n",
      "354   80.196312    0.000262   80.186975    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1850, 1, 251) (1850, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 2s 22ms/step - loss: 5456.7168 - val_loss: 3333.1318\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 5164.6772 - val_loss: 3168.7791\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 5036.7222 - val_loss: 3094.9563\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 4931.6665 - val_loss: 3028.5239\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4830.6997 - val_loss: 2965.6833\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4733.0972 - val_loss: 2904.9795\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4638.0664 - val_loss: 2846.0479\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4545.1816 - val_loss: 2788.6875\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4454.2002 - val_loss: 2732.7737\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4364.9658 - val_loss: 2678.2205\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4277.3721 - val_loss: 2624.9668\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 4191.3403 - val_loss: 2572.9636\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4106.8110 - val_loss: 2522.1726\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4023.7339 - val_loss: 2472.5605\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3942.0686 - val_loss: 2424.0989\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3861.7825 - val_loss: 2376.7632\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3782.8425 - val_loss: 2330.5300\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3705.2227 - val_loss: 2285.3796\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3628.8977 - val_loss: 2241.2915\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3553.8459 - val_loss: 2198.2480\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3480.0457 - val_loss: 2156.2327\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3407.4771 - val_loss: 2115.2275\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3336.1208 - val_loss: 2075.2185\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3265.9604 - val_loss: 2036.1890\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3196.9788 - val_loss: 1998.1255\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3129.1587 - val_loss: 1961.0127\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3062.4849 - val_loss: 1924.8375\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2996.9412 - val_loss: 1889.5857\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2932.5142 - val_loss: 1855.2448\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2869.1877 - val_loss: 1821.8010\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2806.9492 - val_loss: 1789.2416\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2745.7834 - val_loss: 1757.5546\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2685.6780 - val_loss: 1726.7271\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2626.6187 - val_loss: 1696.7469\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2568.5933 - val_loss: 1667.6024\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2511.5874 - val_loss: 1639.2811\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2455.5908 - val_loss: 1611.7716\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2400.5891 - val_loss: 1585.0626\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2346.5708 - val_loss: 1559.1425\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2293.5232 - val_loss: 1533.9993\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2241.4351 - val_loss: 1509.6224\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2190.2947 - val_loss: 1486.0009\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2140.0901 - val_loss: 1463.1233\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2090.8098 - val_loss: 1440.9789\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2042.4424 - val_loss: 1419.5566\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1994.9767 - val_loss: 1398.8463\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1948.4011 - val_loss: 1378.8368\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1902.7061 - val_loss: 1359.5179\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1857.8789 - val_loss: 1340.8790\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1813.9098 - val_loss: 1322.9094\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1770.7877 - val_loss: 1305.5992\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1728.5022 - val_loss: 1288.9381\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1687.0428 - val_loss: 1272.9156\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1646.3992 - val_loss: 1257.5221\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1606.5604 - val_loss: 1242.7473\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1567.5167 - val_loss: 1228.5812\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1529.2578 - val_loss: 1215.0135\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1491.7737 - val_loss: 1202.0348\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1455.0542 - val_loss: 1189.6350\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1419.0894 - val_loss: 1177.8047\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1383.8693 - val_loss: 1166.5339\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1349.3845 - val_loss: 1155.8130\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1315.6249 - val_loss: 1145.6326\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1282.5809 - val_loss: 1135.9828\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1250.2433 - val_loss: 1126.8542\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1218.6019 - val_loss: 1118.2375\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1187.6475 - val_loss: 1110.1233\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1157.3710 - val_loss: 1102.5022\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1127.7627 - val_loss: 1095.3645\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1098.8132 - val_loss: 1088.7014\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1070.5138 - val_loss: 1082.5037\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1042.8549 - val_loss: 1076.7616\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1015.8271 - val_loss: 1071.4667\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 989.4217 - val_loss: 1066.6091\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 963.6301 - val_loss: 1062.1804\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 938.4426 - val_loss: 1058.1714\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 913.8506 - val_loss: 1054.5729\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 889.8455 - val_loss: 1051.3760\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 866.4177 - val_loss: 1048.5718\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 843.5591 - val_loss: 1046.1515\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 821.2608 - val_loss: 1044.1063\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 799.5140 - val_loss: 1042.4272\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 778.3102 - val_loss: 1041.1055\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 757.6410 - val_loss: 1040.1326\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 737.4972 - val_loss: 1039.4996\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 717.8712 - val_loss: 1039.1982\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 698.7540 - val_loss: 1039.2195\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 680.1373 - val_loss: 1039.5549\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 662.0129 - val_loss: 1040.1959\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 644.3723 - val_loss: 1041.1343\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 627.2072 - val_loss: 1042.3613\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 610.5095 - val_loss: 1043.8687\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 594.2711 - val_loss: 1045.6482\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 578.4840 - val_loss: 1047.6912\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 563.1395 - val_loss: 1049.9894\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 548.2302 - val_loss: 1052.5349\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 533.7480 - val_loss: 1055.3196\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 519.6848 - val_loss: 1058.3350\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 506.0327 - val_loss: 1061.5732\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 492.7840 - val_loss: 1065.0261\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 479.9309 - val_loss: 1068.6860\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 467.4654 - val_loss: 1072.5446\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 455.3800 - val_loss: 1076.5942\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 443.6671 - val_loss: 1080.8271\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 432.3191 - val_loss: 1085.2357\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 421.3284 - val_loss: 1089.8118\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 410.6874 - val_loss: 1094.5481\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 400.3889 - val_loss: 1099.4373\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 390.4255 - val_loss: 1104.4711\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 380.7896 - val_loss: 1109.6429\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 371.4742 - val_loss: 1114.9451\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 362.4721 - val_loss: 1120.3702\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 353.7760 - val_loss: 1125.9113\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 345.3788 - val_loss: 1131.5613\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 337.2735 - val_loss: 1137.3127\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 329.4532 - val_loss: 1143.1592\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 321.9110 - val_loss: 1149.0936\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 314.6400 - val_loss: 1155.1088\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 307.6335 - val_loss: 1161.1986\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 300.8847 - val_loss: 1167.3564\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 294.3871 - val_loss: 1173.5753\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 288.1340 - val_loss: 1179.8491\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 282.1188 - val_loss: 1186.1718\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 276.3355 - val_loss: 1192.5367\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 270.7775 - val_loss: 1198.9380\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 265.4385 - val_loss: 1205.3700\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 260.3123 - val_loss: 1211.8258\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 255.3931 - val_loss: 1218.3003\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 250.6747 - val_loss: 1224.7882\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 246.1510 - val_loss: 1231.2836\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 241.8163 - val_loss: 1237.7809\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 237.6650 - val_loss: 1244.2751\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 233.6910 - val_loss: 1250.7612\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 229.8890 - val_loss: 1257.2334\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 226.2534 - val_loss: 1263.6880\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 222.7789 - val_loss: 1270.1199\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 219.4599 - val_loss: 1276.5239\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 216.2914 - val_loss: 1282.8958\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 213.2683 - val_loss: 1289.2312\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 210.3856 - val_loss: 1295.5256\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 207.6382 - val_loss: 1301.7760\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 205.0214 - val_loss: 1307.9772\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 202.5304 - val_loss: 1314.1261\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 200.1605 - val_loss: 1320.2194\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 197.9072 - val_loss: 1326.2532\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 195.7659 - val_loss: 1332.2235\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 193.7328 - val_loss: 1338.1281\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 191.8031 - val_loss: 1343.9634\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 189.9729 - val_loss: 1349.7274\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 188.2381 - val_loss: 1355.4164\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 186.5947 - val_loss: 1361.0286\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 185.0390 - val_loss: 1366.5613\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 183.5672 - val_loss: 1372.0116\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 182.1758 - val_loss: 1377.3779\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 180.8611 - val_loss: 1382.6592\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 179.6199 - val_loss: 1387.8521\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 178.4486 - val_loss: 1392.9559\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 177.3441 - val_loss: 1397.9683\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 176.3036 - val_loss: 1402.8881\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 175.3238 - val_loss: 1407.7151\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 174.4017 - val_loss: 1412.4473\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 173.5345 - val_loss: 1417.0841\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 172.7198 - val_loss: 1421.6250\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 171.9546 - val_loss: 1426.0681\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 171.2367 - val_loss: 1430.4137\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 170.5633 - val_loss: 1434.6616\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 169.9324 - val_loss: 1438.8112\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 169.3416 - val_loss: 1442.8630\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 168.7888 - val_loss: 1446.8159\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 168.2718 - val_loss: 1450.6707\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 167.7887 - val_loss: 1454.4274\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 167.3376 - val_loss: 1458.0864\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 166.9166 - val_loss: 1461.6478\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 166.5242 - val_loss: 1465.1128\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 166.1584 - val_loss: 1468.4818\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 165.8178 - val_loss: 1471.7549\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 165.5009 - val_loss: 1474.9338\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 165.2063 - val_loss: 1478.0186\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 164.9325 - val_loss: 1481.0116\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 164.6783 - val_loss: 1483.9130\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 164.4423 - val_loss: 1486.7235\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 164.2236 - val_loss: 1489.4446\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 164.0209 - val_loss: 1492.0778\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 163.8333 - val_loss: 1494.6246\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 163.6595 - val_loss: 1497.0862\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 163.4989 - val_loss: 1499.4639\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 163.3505 - val_loss: 1501.7594\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 163.2133 - val_loss: 1503.9745\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 163.0867 - val_loss: 1506.1101\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 162.9700 - val_loss: 1508.1696\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 162.8623 - val_loss: 1510.1517\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 162.7631 - val_loss: 1512.0596\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 162.6718 - val_loss: 1513.8954\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 162.5878 - val_loss: 1515.6608\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 162.5105 - val_loss: 1517.3568\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 162.4395 - val_loss: 1518.9863\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 162.3742 - val_loss: 1520.5497\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 162.3143 - val_loss: 1522.0497\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 162.2593 - val_loss: 1523.4877\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 162.2088 - val_loss: 1524.8649\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 162.1626 - val_loss: 1526.1843\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 162.1202 - val_loss: 1527.4473\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 162.0815 - val_loss: 1528.6544\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 162.0459 - val_loss: 1529.8090\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 162.0134 - val_loss: 1530.9124\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.9837 - val_loss: 1531.9656\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.9565 - val_loss: 1532.9708\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.9317 - val_loss: 1533.9291\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.9090 - val_loss: 1534.8425\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 161.8882 - val_loss: 1535.7140\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.8694 - val_loss: 1536.5428\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.8521 - val_loss: 1537.3314\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.8364 - val_loss: 1538.0818\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.8221 - val_loss: 1538.7957\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.8090 - val_loss: 1539.4727\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7971 - val_loss: 1540.1161\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7863 - val_loss: 1540.7262\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7765 - val_loss: 1541.3049\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7676 - val_loss: 1541.8546\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7595 - val_loss: 1542.3741\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7521 - val_loss: 1542.8658\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7455 - val_loss: 1543.3322\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7394 - val_loss: 1543.7734\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7339 - val_loss: 1544.1893\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7290 - val_loss: 1544.5828\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7246 - val_loss: 1544.9542\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7206 - val_loss: 1545.3058\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7169 - val_loss: 1545.6364\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7138 - val_loss: 1545.9484\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7109 - val_loss: 1546.2427\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7082 - val_loss: 1546.5194\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7059 - val_loss: 1546.7799\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7040 - val_loss: 1547.0255\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7021 - val_loss: 1547.2559\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7005 - val_loss: 1547.4723\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6992 - val_loss: 1547.6757\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6980 - val_loss: 1547.8669\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 161.6969 - val_loss: 1548.0463\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.6961 - val_loss: 1548.2147\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.6954 - val_loss: 1548.3718\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.6949 - val_loss: 1548.5203\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6943 - val_loss: 1548.6588\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6939 - val_loss: 1548.7880\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6937 - val_loss: 1548.9089\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6935 - val_loss: 1549.0223\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.6935 - val_loss: 1549.1284\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6935 - val_loss: 1549.2275\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6935 - val_loss: 1549.3201\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6935 - val_loss: 1549.4059\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6938 - val_loss: 1549.4858\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6940 - val_loss: 1549.5602\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6943 - val_loss: 1549.6301\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6946 - val_loss: 1549.6949\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6950 - val_loss: 1549.7545\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6954 - val_loss: 1549.8110\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6958 - val_loss: 1549.8625\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6963 - val_loss: 1549.9105\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6968 - val_loss: 1549.9554\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6973 - val_loss: 1549.9973\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6979 - val_loss: 1550.0360\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6984 - val_loss: 1550.0719\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6990 - val_loss: 1550.1049\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.6996 - val_loss: 1550.1351\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7003 - val_loss: 1550.1641\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7009 - val_loss: 1550.1898\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7015 - val_loss: 1550.2135\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 161.7022 - val_loss: 1550.2360\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7028 - val_loss: 1550.2567\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7035 - val_loss: 1550.2759\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7041 - val_loss: 1550.2927\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7048 - val_loss: 1550.3096\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7055 - val_loss: 1550.3250\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7061 - val_loss: 1550.3381\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7068 - val_loss: 1550.3505\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7075 - val_loss: 1550.3619\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7081 - val_loss: 1550.3723\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7088 - val_loss: 1550.3823\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7094 - val_loss: 1550.3905\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7101 - val_loss: 1550.3987\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7108 - val_loss: 1550.4062\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7115 - val_loss: 1550.4132\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7120 - val_loss: 1550.4189\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7127 - val_loss: 1550.4253\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7133 - val_loss: 1550.4299\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7140 - val_loss: 1550.4352\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7145 - val_loss: 1550.4385\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7152 - val_loss: 1550.4424\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7158 - val_loss: 1550.4453\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7164 - val_loss: 1550.4478\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7170 - val_loss: 1550.4508\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7176 - val_loss: 1550.4537\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7181 - val_loss: 1550.4552\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7188 - val_loss: 1550.4572\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7193 - val_loss: 1550.4587\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 161.7198 - val_loss: 1550.4596\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7204 - val_loss: 1550.4612\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7209 - val_loss: 1550.4622\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7215 - val_loss: 1550.4629\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7220 - val_loss: 1550.4631\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7225 - val_loss: 1550.4631\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7231 - val_loss: 1550.4635\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7235 - val_loss: 1550.4642\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7241 - val_loss: 1550.4653\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7245 - val_loss: 1550.4653\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7250 - val_loss: 1550.4657\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7255 - val_loss: 1550.4653\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7260 - val_loss: 1550.4657\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7263 - val_loss: 1550.4656\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7268 - val_loss: 1550.4658\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7272 - val_loss: 1550.4653\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7276 - val_loss: 1550.4656\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7281 - val_loss: 1550.4658\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7285 - val_loss: 1550.4647\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7289 - val_loss: 1550.4639\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7294 - val_loss: 1550.4645\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7297 - val_loss: 1550.4645\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7301 - val_loss: 1550.4648\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7305 - val_loss: 1550.4648\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 161.7308 - val_loss: 1550.4631\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 161.7312 - val_loss: 1550.4631\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7316 - val_loss: 1550.4623\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7319 - val_loss: 1550.4618\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7323 - val_loss: 1550.4614\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7326 - val_loss: 1550.4614\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7329 - val_loss: 1550.4613\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7332 - val_loss: 1550.4603\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7335 - val_loss: 1550.4603\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7339 - val_loss: 1550.4601\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7342 - val_loss: 1550.4595\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7344 - val_loss: 1550.4586\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7348 - val_loss: 1550.4581\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7350 - val_loss: 1550.4578\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7353 - val_loss: 1550.4574\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7355 - val_loss: 1550.4569\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7358 - val_loss: 1550.4563\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7361 - val_loss: 1550.4561\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7363 - val_loss: 1550.4557\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7366 - val_loss: 1550.4552\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7368 - val_loss: 1550.4547\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7371 - val_loss: 1550.4547\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7373 - val_loss: 1550.4537\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7375 - val_loss: 1550.4535\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7377 - val_loss: 1550.4528\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7379 - val_loss: 1550.4517\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 161.7382 - val_loss: 1550.4513\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7384 - val_loss: 1550.4513\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7386 - val_loss: 1550.4512\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7388 - val_loss: 1550.4508\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7390 - val_loss: 1550.4502\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7392 - val_loss: 1550.4498\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7394 - val_loss: 1550.4493\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7396 - val_loss: 1550.4493\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7398 - val_loss: 1550.4493\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7399 - val_loss: 1550.4493\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7401 - val_loss: 1550.4493\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7403 - val_loss: 1550.4490\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7404 - val_loss: 1550.4484\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7406 - val_loss: 1550.4476\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7407 - val_loss: 1550.4467\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7409 - val_loss: 1550.4467\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7410 - val_loss: 1550.4458\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7412 - val_loss: 1550.4456\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7413 - val_loss: 1550.4453\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7414 - val_loss: 1550.4449\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7416 - val_loss: 1550.4449\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7417 - val_loss: 1550.4449\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7419 - val_loss: 1550.4446\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7420 - val_loss: 1550.4442\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7422 - val_loss: 1550.4440\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7423 - val_loss: 1550.4437\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7424 - val_loss: 1550.4434\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 161.7426 - val_loss: 1550.4436\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7426 - val_loss: 1550.4434\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7427 - val_loss: 1550.4431\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7429 - val_loss: 1550.4431\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7430 - val_loss: 1550.4431\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7430 - val_loss: 1550.4423\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7432 - val_loss: 1550.4420\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7433 - val_loss: 1550.4423\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7433 - val_loss: 1550.4418\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7435 - val_loss: 1550.4419\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7435 - val_loss: 1550.4423\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7436 - val_loss: 1550.4423\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7436 - val_loss: 1550.4414\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7438 - val_loss: 1550.4412\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7438 - val_loss: 1550.4404\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7440 - val_loss: 1550.4404\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 161.7440 - val_loss: 1550.4406\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7441 - val_loss: 1550.4407\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7442 - val_loss: 1550.4407\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7443 - val_loss: 1550.4406\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7443 - val_loss: 1550.4401\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7444 - val_loss: 1550.4398\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7445 - val_loss: 1550.4396\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7446 - val_loss: 1550.4397\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7446 - val_loss: 1550.4393\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 161.7447 - val_loss: 1550.4397\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7448 - val_loss: 1550.4402\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7448 - val_loss: 1550.4404\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7449 - val_loss: 1550.4401\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7448 - val_loss: 1550.4392\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7449 - val_loss: 1550.4382\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7450 - val_loss: 1550.4375\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7451 - val_loss: 1550.4371\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7452 - val_loss: 1550.4371\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7452 - val_loss: 1550.4371\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7452 - val_loss: 1550.4368\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7453 - val_loss: 1550.4362\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7453 - val_loss: 1550.4353\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7454 - val_loss: 1550.4354\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7455 - val_loss: 1550.4358\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7456 - val_loss: 1550.4362\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7456 - val_loss: 1550.4365\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7456 - val_loss: 1550.4365\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7456 - val_loss: 1550.4366\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7457 - val_loss: 1550.4365\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7457 - val_loss: 1550.4363\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7458 - val_loss: 1550.4366\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7459 - val_loss: 1550.4370\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 161.7459 - val_loss: 1550.4374\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7459 - val_loss: 1550.4374\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7460 - val_loss: 1550.4374\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7460 - val_loss: 1550.4370\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7460 - val_loss: 1550.4368\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7461 - val_loss: 1550.4370\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7461 - val_loss: 1550.4370\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7461 - val_loss: 1550.4365\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7462 - val_loss: 1550.4365\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7462 - val_loss: 1550.4365\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7462 - val_loss: 1550.4362\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7462 - val_loss: 1550.4357\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7462 - val_loss: 1550.4353\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7463 - val_loss: 1550.4352\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7464 - val_loss: 1550.4358\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7464 - val_loss: 1550.4365\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7464 - val_loss: 1550.4365\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7464 - val_loss: 1550.4368\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7464 - val_loss: 1550.4365\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7464 - val_loss: 1550.4365\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 161.7465 - val_loss: 1550.4365\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7465 - val_loss: 1550.4366\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7465 - val_loss: 1550.4366\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7465 - val_loss: 1550.4365\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7466 - val_loss: 1550.4366\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7466 - val_loss: 1550.4366\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7465 - val_loss: 1550.4365\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7466 - val_loss: 1550.4358\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7466 - val_loss: 1550.4348\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7466 - val_loss: 1550.4340\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7466 - val_loss: 1550.4332\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7467 - val_loss: 1550.4332\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7468 - val_loss: 1550.4340\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7468 - val_loss: 1550.4344\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7468 - val_loss: 1550.4352\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7468 - val_loss: 1550.4353\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7468 - val_loss: 1550.4353\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7468 - val_loss: 1550.4353\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7468 - val_loss: 1550.4353\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 161.7469 - val_loss: 1550.4362\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7469 - val_loss: 1550.4368\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7468 - val_loss: 1550.4371\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 161.7469 - val_loss: 1550.4371\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7469 - val_loss: 1550.4371\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 161.7469 - val_loss: 1550.4371\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7469 - val_loss: 1550.4371\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7469 - val_loss: 1550.4366\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7469 - val_loss: 1550.4365\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7469 - val_loss: 1550.4365\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7469 - val_loss: 1550.4368\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7469 - val_loss: 1550.4368\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7469 - val_loss: 1550.4368\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7470 - val_loss: 1550.4370\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7469 - val_loss: 1550.4370\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7469 - val_loss: 1550.4366\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7470 - val_loss: 1550.4365\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7470 - val_loss: 1550.4362\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7470 - val_loss: 1550.4358\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7470 - val_loss: 1550.4352\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7470 - val_loss: 1550.4352\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7470 - val_loss: 1550.4346\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7471 - val_loss: 1550.4346\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7472 - val_loss: 1550.4357\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 161.7471 - val_loss: 1550.4365\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7471 - val_loss: 1550.4366\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7471 - val_loss: 1550.4370\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7472 - val_loss: 1550.4379\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7471 - val_loss: 1550.4388\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7471 - val_loss: 1550.4392\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7471 - val_loss: 1550.4388\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7471 - val_loss: 1550.4385\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7471 - val_loss: 1550.4375\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7472 - val_loss: 1550.4375\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7472 - val_loss: 1550.4371\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7471 - val_loss: 1550.4370\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7471 - val_loss: 1550.4371\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7471 - val_loss: 1550.4368\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7471 - val_loss: 1550.4368\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7471 - val_loss: 1550.4363\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.7471 - val_loss: 1550.4360\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.7472 - val_loss: 1550.4360\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(89.3180, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0010, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(-0.0204, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.2194, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 384ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.19032423e+01, 7.18049230e+01, 7.17066036e+01, 7.16082843e+01,\n",
       "        7.80659332e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.91444740e-01, 7.80059100e-01, 2.19391550e-01, 0.00000000e+00,\n",
       "        1.01611876e+00, 6.98852941e+01, 6.97676471e+01, 6.96500000e+01,\n",
       "        6.95323529e+01, 6.94573529e+01, 7.32613749e+01, 7.28807026e+01,\n",
       "        7.25000304e+01, 7.21193581e+01, 7.21925091e+01, 7.21826772e+01,\n",
       "        7.21728452e+01, 7.21630133e+01, 7.21477614e+01, 0.00000000e+00,\n",
       "        5.85034800e-01, 7.20651471e+01, 7.20866828e+01, 7.20768508e+01,\n",
       "        7.20670189e+01, 7.20549510e+01, 7.20373039e+01, 7.20196569e+01,\n",
       "        7.20020098e+01, 6.83960784e+01, 4.56666600e-01, 0.00000000e+00,\n",
       "        1.45112400e-01, 6.53236000e-02, 4.21061900e-01, 0.00000000e+00,\n",
       "        8.90326600e-01, 0.00000000e+00, 3.71032900e-01, 7.16519818e+01,\n",
       "        7.15168301e+01, 6.30085400e-01, 1.53718980e-01, 7.19869958e+01,\n",
       "        7.18886765e+01, 7.17903571e+01, 7.16920378e+01, 7.15887255e+01,\n",
       "        7.14122549e+01, 7.12357843e+01, 7.10593137e+01, 6.86568630e+01,\n",
       "        4.55971300e-01, 5.64365200e-01, 7.16337745e+01, 7.14841503e+01,\n",
       "        7.13076797e+01, 7.11312092e+01, 7.09547386e+01, 7.06565360e+01,\n",
       "        7.03035948e+01, 6.99506536e+01, 6.95997112e+01, 4.95039800e-01,\n",
       "        1.99221300e-01, 6.25196266e+01, 0.00000000e+00, 5.95545900e-01,\n",
       "        6.70332000e-02, 0.00000000e+00, 5.27806300e-01, 0.00000000e+00,\n",
       "        6.91138000e+01, 0.00000000e+00, 6.29535317e-03, 0.00000000e+00,\n",
       "        1.96523532e-01, 0.00000000e+00, 3.01663652e-02, 0.00000000e+00,\n",
       "        1.05618306e-01, 0.00000000e+00, 0.00000000e+00, 6.12055302e-01,\n",
       "        1.10715187e+00, 0.00000000e+00, 0.00000000e+00, 5.51990986e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.36216462e-01, 4.61374968e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63.9227164 , 63.91506456, 63.90741272, 63.89976088, 63.89210904,\n",
       "       63.8844572 , 63.87680536, 63.86915352, 63.86150167, 63.85384983,\n",
       "       63.84619799, 63.83854615, 63.83089431, 63.82324247, 63.81559063,\n",
       "       63.80793879, 63.80028694, 63.7926351 , 63.78498326, 63.77733142,\n",
       "       63.76967958, 63.76202774, 63.7543759 , 63.74672406, 63.73907221,\n",
       "       63.73142037, 63.72376853, 63.71611669, 63.70846485, 63.70081301,\n",
       "       63.69316117, 63.68550933, 63.67785748, 63.67020564, 63.6625538 ,\n",
       "       63.65490196, 63.64725012, 63.63959828, 63.63194644, 63.6242946 ,\n",
       "       63.61664275, 63.60899091, 63.60133907, 63.59368723, 63.58603539,\n",
       "       63.57838355, 63.57073171, 63.56307987, 63.55542802, 63.54777618,\n",
       "       63.54012434, 63.5324725 , 63.52482066, 63.51716882, 63.50951698,\n",
       "       63.50186514, 63.4942133 , 63.48656145, 63.47890961, 63.47125777,\n",
       "       63.46360593, 63.45595409, 63.44830225, 63.44065041, 63.43299857,\n",
       "       63.42534672, 63.41769488, 63.41004304, 63.4023912 , 63.39473936,\n",
       "       63.38708752, 63.37943568, 63.37178384, 63.36413199, 63.35648015,\n",
       "       63.34882831, 63.34117647, 63.33352463, 63.32587279, 63.31822095,\n",
       "       63.31056911, 63.30291726, 63.29526542, 63.28761358, 63.27996174,\n",
       "       63.2723099 , 63.26465806, 63.25700622, 63.24935438, 63.24170253,\n",
       "       63.23405069, 63.22639885, 63.21874701, 63.21109517, 63.20344333,\n",
       "       63.19579149, 63.18813965, 63.1804878 , 63.17283596, 63.16518412])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.04150118020956\n",
      "35.43754702789227\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
