{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "1895    67.567507\n",
       "1896    67.556303\n",
       "1897    67.545098\n",
       "1898    67.533894\n",
       "1899    67.522689\n",
       "Name: C7, Length: 1900, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c7_interpolated_1800_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "1795     0.376206\n",
       "1796     0.000000\n",
       "1797     0.694525\n",
       "1798     0.164611\n",
       "1799     0.719316\n",
       "Name: C7, Length: 1800, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1800)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.387115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.174230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.961345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.748459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     92.600000  0.000298\n",
       "1     92.387115  0.000298\n",
       "2     92.174230  0.000297\n",
       "3     91.961345  0.000297\n",
       "4     91.748459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 89.3180  # Value for C0\n",
    "K0 = -0.0010  # Value for K0\n",
    "K1 = 0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = -0.0204    # Value for b\n",
    "c = 2.2194    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    92.600000    92.387115    92.174230    91.961345    91.748459   \n",
      "351    92.387115    92.174230    91.961345    91.748459    91.535574   \n",
      "352    92.174230    91.961345    91.748459    91.535574    91.322689   \n",
      "353    91.961345    91.748459    91.535574    91.322689    91.109804   \n",
      "354    91.748459    91.535574    91.322689    91.109804    90.896919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    91.535574    91.322689    91.109804    90.896919    90.691597  ...   \n",
      "351    91.322689    91.109804    90.896919    90.691597    90.579552  ...   \n",
      "352    91.109804    90.896919    90.691597    90.579552    90.467507  ...   \n",
      "353    90.896919    90.691597    90.579552    90.467507    90.355462  ...   \n",
      "354    90.691597    90.579552    90.467507    90.355462    90.243417  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   80.261671    0.000263   80.252334    0.000263   80.242997    0.000263   \n",
      "351   80.252334    0.000263   80.242997    0.000263   80.233660    0.000262   \n",
      "352   80.242997    0.000263   80.233660    0.000262   80.224323    0.000262   \n",
      "353   80.233660    0.000262   80.224323    0.000262   80.214986    0.000262   \n",
      "354   80.224323    0.000262   80.214986    0.000262   80.205649    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   80.233660    0.000262   80.224323    0.000262  \n",
      "351   80.224323    0.000262   80.214986    0.000262  \n",
      "352   80.214986    0.000262   80.205649    0.000262  \n",
      "353   80.205649    0.000262   80.196312    0.000262  \n",
      "354   80.196312    0.000262   80.186975    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1350, 1, 251) (1350, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 2s 29ms/step - loss: 5709.8076 - val_loss: 4425.9902\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5583.5962 - val_loss: 4346.7563\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5498.4873 - val_loss: 4278.9844\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5419.4023 - val_loss: 4212.1172\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5341.3257 - val_loss: 4146.1875\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5264.2285 - val_loss: 4081.1467\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5186.2207 - val_loss: 4009.2959\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5101.9639 - val_loss: 3942.5884\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5020.3862 - val_loss: 3870.9343\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4936.4697 - val_loss: 3793.2449\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4844.5625 - val_loss: 3723.3374\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4762.4321 - val_loss: 3655.1960\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4682.4438 - val_loss: 3588.8862\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4604.3350 - val_loss: 3524.0974\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4527.7935 - val_loss: 3460.6206\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4452.6201 - val_loss: 3398.3237\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4378.6885 - val_loss: 3337.1194\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4305.9097 - val_loss: 3276.9453\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4234.2236 - val_loss: 3217.7563\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4163.5791 - val_loss: 3159.5144\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4093.9417 - val_loss: 3102.1902\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4025.2778 - val_loss: 3045.7593\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 3957.5640 - val_loss: 2990.2002\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3890.7764 - val_loss: 2935.4946\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3824.8955 - val_loss: 2881.6252\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3759.9045 - val_loss: 2828.5776\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3695.7883 - val_loss: 2776.3391\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3632.5325 - val_loss: 2724.8960\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3570.1235 - val_loss: 2674.2373\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3508.5491 - val_loss: 2624.3511\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3447.7983 - val_loss: 2575.2283\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3387.8606 - val_loss: 2526.8582\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3328.7244 - val_loss: 2479.2310\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3270.3811 - val_loss: 2432.3389\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3212.8215 - val_loss: 2386.1719\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3156.0359 - val_loss: 2340.7222\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3100.0156 - val_loss: 2295.9805\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3044.7515 - val_loss: 2251.9399\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2990.2366 - val_loss: 2208.5928\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2936.4622 - val_loss: 2165.9297\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2883.4207 - val_loss: 2123.9456\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2831.1045 - val_loss: 2082.6304\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2779.5056 - val_loss: 2041.9796\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2728.6179 - val_loss: 2001.9838\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2678.4324 - val_loss: 1962.6384\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2628.9441 - val_loss: 1923.9349\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2580.1433 - val_loss: 1885.8661\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2532.0256 - val_loss: 1848.4268\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2484.5833 - val_loss: 1811.6091\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2437.8098 - val_loss: 1775.4067\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2391.6982 - val_loss: 1739.8138\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2346.2422 - val_loss: 1704.8237\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2301.4353 - val_loss: 1670.4292\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2257.2708 - val_loss: 1636.6254\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2213.7434 - val_loss: 1603.4059\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2170.8455 - val_loss: 1570.7629\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 2128.5723 - val_loss: 1538.6926\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2086.9170 - val_loss: 1507.1873\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2045.8732 - val_loss: 1476.2418\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 2005.4349 - val_loss: 1445.8503\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1965.5972 - val_loss: 1416.0061\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1926.3533 - val_loss: 1386.7042\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1887.6975 - val_loss: 1357.9380\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1849.6238 - val_loss: 1329.7021\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1812.1263 - val_loss: 1301.9910\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1775.2004 - val_loss: 1274.7983\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1738.8389 - val_loss: 1248.1194\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1703.0376 - val_loss: 1221.9480\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1667.7892 - val_loss: 1196.2783\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1633.0898 - val_loss: 1171.1049\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1598.9327 - val_loss: 1146.4226\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1565.3132 - val_loss: 1122.2257\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1532.2250 - val_loss: 1098.5083\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1499.6638 - val_loss: 1075.2660\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1467.6230 - val_loss: 1052.4930\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1436.0984 - val_loss: 1030.1835\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1405.0835 - val_loss: 1008.3320\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1374.5740 - val_loss: 986.9338\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1344.5636 - val_loss: 965.9833\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1315.0480 - val_loss: 945.4756\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1286.0219 - val_loss: 925.4050\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1257.4792 - val_loss: 905.7664\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1229.4158 - val_loss: 886.5547\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1201.8260 - val_loss: 867.7646\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1174.7051 - val_loss: 849.3914\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1148.0475 - val_loss: 831.4295\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1121.8489 - val_loss: 813.8737\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1096.1035 - val_loss: 796.7200\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1070.8069 - val_loss: 779.9621\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1045.9539 - val_loss: 763.5961\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1021.5389 - val_loss: 747.6150\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 997.5575 - val_loss: 732.0165\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 974.0054 - val_loss: 716.7934\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 950.8771 - val_loss: 701.9427\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 928.1680 - val_loss: 687.4574\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 905.8729 - val_loss: 673.3349\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 883.9879 - val_loss: 659.5681\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 862.5069 - val_loss: 646.1545\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 841.4257 - val_loss: 633.0861\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 820.7392 - val_loss: 620.3610\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 800.4436 - val_loss: 607.9733\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 780.5334 - val_loss: 595.9182\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 761.0045 - val_loss: 584.1909\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 741.8516 - val_loss: 572.7867\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 723.0708 - val_loss: 561.7020\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 704.6569 - val_loss: 550.9302\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 686.6055 - val_loss: 540.4682\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 668.9124 - val_loss: 530.3106\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 651.5726 - val_loss: 520.4523\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 634.5817 - val_loss: 510.8900\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 617.9350 - val_loss: 501.6180\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 601.6282 - val_loss: 492.6324\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 585.6567 - val_loss: 483.9282\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 570.0161 - val_loss: 475.5017\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 554.7023 - val_loss: 467.3474\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 539.7105 - val_loss: 459.4609\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 525.0363 - val_loss: 451.8383\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 510.6755 - val_loss: 444.4751\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 496.6237 - val_loss: 437.3663\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 482.8766 - val_loss: 430.5079\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 469.4300 - val_loss: 423.8959\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 456.2795 - val_loss: 417.5255\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 443.4210 - val_loss: 411.3922\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 430.8500 - val_loss: 405.4921\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 418.5626 - val_loss: 399.8208\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 406.5545 - val_loss: 394.3740\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 394.8212 - val_loss: 389.1471\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 383.3588 - val_loss: 384.1364\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 372.1631 - val_loss: 379.3374\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 361.2302 - val_loss: 374.7462\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 350.5560 - val_loss: 370.3586\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 340.1364 - val_loss: 366.1701\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 329.9669 - val_loss: 362.1772\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 320.0442 - val_loss: 358.3751\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 310.3636 - val_loss: 354.7601\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 300.9217 - val_loss: 351.3286\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 291.7145 - val_loss: 348.0760\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 282.7375 - val_loss: 344.9985\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 273.9877 - val_loss: 342.0923\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 265.4605 - val_loss: 339.3536\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 257.1526 - val_loss: 336.7779\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 249.0596 - val_loss: 334.3620\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 241.1782 - val_loss: 332.1018\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 233.5047 - val_loss: 329.9936\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 226.0350 - val_loss: 328.0335\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 218.7655 - val_loss: 326.2177\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 211.6923 - val_loss: 324.5428\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 204.8121 - val_loss: 323.0048\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 198.1211 - val_loss: 321.6002\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 191.6156 - val_loss: 320.3254\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 185.2924 - val_loss: 319.1767\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 179.1477 - val_loss: 318.1508\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 173.1779 - val_loss: 317.2439\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 167.3797 - val_loss: 316.4528\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 161.7495 - val_loss: 315.7738\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 156.2839 - val_loss: 315.2035\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 150.9797 - val_loss: 314.7389\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 145.8333 - val_loss: 314.3762\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 140.8414 - val_loss: 314.1123\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 136.0007 - val_loss: 313.9440\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 131.3080 - val_loss: 313.8680\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 126.7602 - val_loss: 313.8811\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 122.3538 - val_loss: 313.9803\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 118.0859 - val_loss: 314.1623\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 113.9532 - val_loss: 314.4241\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 109.9526 - val_loss: 314.7627\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 106.0812 - val_loss: 315.1751\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 102.3358 - val_loss: 315.6584\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 98.7135 - val_loss: 316.2097\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 95.2113 - val_loss: 316.8261\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 91.8263 - val_loss: 317.5049\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 88.5556 - val_loss: 318.2432\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 85.3963 - val_loss: 319.0382\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 82.3458 - val_loss: 319.8875\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 79.4011 - val_loss: 320.7884\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 76.5596 - val_loss: 321.7380\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 73.8186 - val_loss: 322.7341\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 71.1754 - val_loss: 323.7741\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 68.6273 - val_loss: 324.8556\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 66.1720 - val_loss: 325.9760\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 63.8066 - val_loss: 327.1332\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 61.5288 - val_loss: 328.3248\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 59.3363 - val_loss: 329.5484\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 57.2263 - val_loss: 330.8021\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 55.1968 - val_loss: 332.0834\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 53.2452 - val_loss: 333.3904\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 51.3693 - val_loss: 334.7211\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 49.5668 - val_loss: 336.0733\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 47.8355 - val_loss: 337.4451\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 46.1732 - val_loss: 338.8346\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 44.5780 - val_loss: 340.2396\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 43.0475 - val_loss: 341.6591\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 41.5797 - val_loss: 343.0906\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 40.1728 - val_loss: 344.5326\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 38.8246 - val_loss: 345.9832\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 37.5332 - val_loss: 347.4414\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 36.2968 - val_loss: 348.9053\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 35.1134 - val_loss: 350.3730\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.9814 - val_loss: 351.8436\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 32.8988 - val_loss: 353.3156\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.8641 - val_loss: 354.7871\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 30.8755 - val_loss: 356.2574\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.9315 - val_loss: 357.7246\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.0303 - val_loss: 359.1882\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 28.1703 - val_loss: 360.6468\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 27.3500 - val_loss: 362.0984\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 26.5682 - val_loss: 363.5431\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.8231 - val_loss: 364.9795\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 25.1133 - val_loss: 366.4065\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 24.4377 - val_loss: 367.8228\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.7948 - val_loss: 369.2280\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 23.1832 - val_loss: 370.6213\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 22.6017 - val_loss: 372.0018\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 22.0491 - val_loss: 373.3681\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.5244 - val_loss: 374.7203\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 21.0262 - val_loss: 376.0571\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.5535 - val_loss: 377.3785\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.1050 - val_loss: 378.6831\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.6800 - val_loss: 379.9708\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.2773 - val_loss: 381.2408\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.8959 - val_loss: 382.4928\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.5350 - val_loss: 383.7269\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.1934 - val_loss: 384.9417\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.8705 - val_loss: 386.1372\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.5652 - val_loss: 387.3136\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2768 - val_loss: 388.4697\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.0045 - val_loss: 389.6055\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.7476 - val_loss: 390.7210\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5052 - val_loss: 391.8158\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2768 - val_loss: 392.8904\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.0615 - val_loss: 393.9435\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.8587 - val_loss: 394.9757\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.6679 - val_loss: 395.9870\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 15.4883 - val_loss: 396.9766\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3195 - val_loss: 397.9447\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.1609 - val_loss: 398.8917\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.0119 - val_loss: 399.8175\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8720 - val_loss: 400.7224\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 14.7407 - val_loss: 401.6056\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.6177 - val_loss: 402.4680\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5023 - val_loss: 403.3090\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.3943 - val_loss: 404.1293\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.2931 - val_loss: 404.9287\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.1984 - val_loss: 405.7074\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.1098 - val_loss: 406.4654\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.0271 - val_loss: 407.2032\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 13.9498 - val_loss: 407.9215\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 13.8775 - val_loss: 408.6196\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.8101 - val_loss: 409.2981\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7472 - val_loss: 409.9573\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6886 - val_loss: 410.5970\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6340 - val_loss: 411.2182\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.5830 - val_loss: 411.8208\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.5357 - val_loss: 412.4048\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.4916 - val_loss: 412.9710\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.4506 - val_loss: 413.5193\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.4125 - val_loss: 414.0506\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3771 - val_loss: 414.5646\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3442 - val_loss: 415.0611\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3137 - val_loss: 415.5420\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.2854 - val_loss: 416.0063\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 13.2592 - val_loss: 416.4546\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.2349 - val_loss: 416.8875\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.2124 - val_loss: 417.3053\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1916 - val_loss: 417.7087\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1722 - val_loss: 418.0975\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1544 - val_loss: 418.4722\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1379 - val_loss: 418.8332\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1226 - val_loss: 419.1810\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1085 - val_loss: 419.5155\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0954 - val_loss: 419.8371\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0834 - val_loss: 420.1468\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0723 - val_loss: 420.4443\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0621 - val_loss: 420.7297\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0526 - val_loss: 421.0037\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 13.0439 - val_loss: 421.2665\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0359 - val_loss: 421.5188\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0286 - val_loss: 421.7611\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0218 - val_loss: 421.9929\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0155 - val_loss: 422.2148\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0098 - val_loss: 422.4279\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0045 - val_loss: 422.6311\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9996 - val_loss: 422.8256\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9951 - val_loss: 423.0117\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9910 - val_loss: 423.1896\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9873 - val_loss: 423.3596\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9838 - val_loss: 423.5216\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 12.9807 - val_loss: 423.6763\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9777 - val_loss: 423.8234\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9751 - val_loss: 423.9639\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9727 - val_loss: 424.0980\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9704 - val_loss: 424.2254\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9684 - val_loss: 424.3467\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9665 - val_loss: 424.4616\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9648 - val_loss: 424.5714\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9633 - val_loss: 424.6751\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9619 - val_loss: 424.7740\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.9606 - val_loss: 424.8678\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9595 - val_loss: 424.9567\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9584 - val_loss: 425.0411\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9574 - val_loss: 425.1206\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9566 - val_loss: 425.1962\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9558 - val_loss: 425.2678\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9552 - val_loss: 425.3357\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9545 - val_loss: 425.4001\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9540 - val_loss: 425.4604\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9535 - val_loss: 425.5179\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9530 - val_loss: 425.5717\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9527 - val_loss: 425.6224\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9524 - val_loss: 425.6703\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9521 - val_loss: 425.7160\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9519 - val_loss: 425.7588\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 12.9517 - val_loss: 425.7991\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9515 - val_loss: 425.8372\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9514 - val_loss: 425.8726\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9513 - val_loss: 425.9060\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9512 - val_loss: 425.9372\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9512 - val_loss: 425.9659\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9512 - val_loss: 425.9933\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9513 - val_loss: 426.0191\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9513 - val_loss: 426.0430\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9513 - val_loss: 426.0656\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9514 - val_loss: 426.0862\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9516 - val_loss: 426.1061\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9516 - val_loss: 426.1241\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9518 - val_loss: 426.1413\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9520 - val_loss: 426.1568\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9521 - val_loss: 426.1716\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9523 - val_loss: 426.1855\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9525 - val_loss: 426.1987\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9527 - val_loss: 426.2103\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9530 - val_loss: 426.2212\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9532 - val_loss: 426.2315\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9534 - val_loss: 426.2411\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9536 - val_loss: 426.2496\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9539 - val_loss: 426.2572\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9542 - val_loss: 426.2643\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9544 - val_loss: 426.2710\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9547 - val_loss: 426.2774\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9550 - val_loss: 426.2828\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9553 - val_loss: 426.2883\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9556 - val_loss: 426.2929\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9559 - val_loss: 426.2970\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 12.9562 - val_loss: 426.3010\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9566 - val_loss: 426.3045\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9569 - val_loss: 426.3077\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9572 - val_loss: 426.3106\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9575 - val_loss: 426.3132\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9578 - val_loss: 426.3148\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9582 - val_loss: 426.3172\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9586 - val_loss: 426.3185\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9589 - val_loss: 426.3205\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9593 - val_loss: 426.3220\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9596 - val_loss: 426.3236\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9599 - val_loss: 426.3245\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9603 - val_loss: 426.3250\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9607 - val_loss: 426.3253\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9610 - val_loss: 426.3261\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9614 - val_loss: 426.3263\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9617 - val_loss: 426.3264\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9621 - val_loss: 426.3267\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9625 - val_loss: 426.3266\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9629 - val_loss: 426.3267\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9632 - val_loss: 426.3261\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9636 - val_loss: 426.3258\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9639 - val_loss: 426.3256\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9643 - val_loss: 426.3252\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9647 - val_loss: 426.3250\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 12.9650 - val_loss: 426.3244\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9654 - val_loss: 426.3238\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9658 - val_loss: 426.3230\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9662 - val_loss: 426.3225\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.9665 - val_loss: 426.3217\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9669 - val_loss: 426.3208\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9673 - val_loss: 426.3199\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9677 - val_loss: 426.3190\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9681 - val_loss: 426.3182\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9684 - val_loss: 426.3174\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9688 - val_loss: 426.3164\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9692 - val_loss: 426.3155\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9696 - val_loss: 426.3147\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9699 - val_loss: 426.3138\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9703 - val_loss: 426.3130\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9707 - val_loss: 426.3119\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9710 - val_loss: 426.3106\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9714 - val_loss: 426.3094\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9718 - val_loss: 426.3080\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9722 - val_loss: 426.3072\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9725 - val_loss: 426.3064\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9729 - val_loss: 426.3055\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9733 - val_loss: 426.3044\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9737 - val_loss: 426.3036\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9740 - val_loss: 426.3028\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9744 - val_loss: 426.3018\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9747 - val_loss: 426.3006\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 12.9751 - val_loss: 426.2994\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9755 - val_loss: 426.2986\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9759 - val_loss: 426.2978\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9762 - val_loss: 426.2964\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9766 - val_loss: 426.2955\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9769 - val_loss: 426.2947\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9773 - val_loss: 426.2935\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9777 - val_loss: 426.2928\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9780 - val_loss: 426.2920\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9784 - val_loss: 426.2910\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9787 - val_loss: 426.2900\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9791 - val_loss: 426.2891\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9794 - val_loss: 426.2880\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9798 - val_loss: 426.2874\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9801 - val_loss: 426.2861\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 12.9805 - val_loss: 426.2854\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9808 - val_loss: 426.2845\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9812 - val_loss: 426.2836\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9815 - val_loss: 426.2822\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9818 - val_loss: 426.2813\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9822 - val_loss: 426.2805\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9825 - val_loss: 426.2794\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9829 - val_loss: 426.2783\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9832 - val_loss: 426.2773\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9835 - val_loss: 426.2766\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9838 - val_loss: 426.2755\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9842 - val_loss: 426.2748\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9845 - val_loss: 426.2739\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9848 - val_loss: 426.2731\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9851 - val_loss: 426.2721\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9854 - val_loss: 426.2712\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9858 - val_loss: 426.2702\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9861 - val_loss: 426.2694\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9864 - val_loss: 426.2685\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9867 - val_loss: 426.2674\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9870 - val_loss: 426.2664\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 12.9873 - val_loss: 426.2654\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9876 - val_loss: 426.2647\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9879 - val_loss: 426.2631\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9882 - val_loss: 426.2622\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9885 - val_loss: 426.2608\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9888 - val_loss: 426.2604\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9892 - val_loss: 426.2599\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9894 - val_loss: 426.2592\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9897 - val_loss: 426.2580\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9900 - val_loss: 426.2573\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9903 - val_loss: 426.2562\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9906 - val_loss: 426.2557\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9909 - val_loss: 426.2552\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9912 - val_loss: 426.2547\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9914 - val_loss: 426.2539\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9917 - val_loss: 426.2529\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9919 - val_loss: 426.2520\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9922 - val_loss: 426.2510\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9925 - val_loss: 426.2503\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9927 - val_loss: 426.2494\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 12.9930 - val_loss: 426.2484\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 12.9933 - val_loss: 426.2479\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9935 - val_loss: 426.2470\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9938 - val_loss: 426.2466\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9940 - val_loss: 426.2460\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9943 - val_loss: 426.2448\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9945 - val_loss: 426.2443\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9948 - val_loss: 426.2434\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9950 - val_loss: 426.2428\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9953 - val_loss: 426.2423\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9955 - val_loss: 426.2415\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9957 - val_loss: 426.2408\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9960 - val_loss: 426.2404\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9962 - val_loss: 426.2394\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9964 - val_loss: 426.2387\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9967 - val_loss: 426.2378\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9969 - val_loss: 426.2373\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9971 - val_loss: 426.2364\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9973 - val_loss: 426.2358\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9976 - val_loss: 426.2353\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9978 - val_loss: 426.2344\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9980 - val_loss: 426.2339\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9982 - val_loss: 426.2332\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 12.9984 - val_loss: 426.2329\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9986 - val_loss: 426.2324\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9988 - val_loss: 426.2318\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9991 - val_loss: 426.2315\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9992 - val_loss: 426.2310\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9994 - val_loss: 426.2303\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.9996 - val_loss: 426.2299\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 12.9998 - val_loss: 426.2287\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0000 - val_loss: 426.2284\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0002 - val_loss: 426.2281\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0004 - val_loss: 426.2273\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0006 - val_loss: 426.2268\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0008 - val_loss: 426.2264\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0010 - val_loss: 426.2262\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0011 - val_loss: 426.2252\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0013 - val_loss: 426.2247\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0015 - val_loss: 426.2245\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0016 - val_loss: 426.2235\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0018 - val_loss: 426.2229\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0020 - val_loss: 426.2227\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0021 - val_loss: 426.2218\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0023 - val_loss: 426.2214\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0025 - val_loss: 426.2209\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0027 - val_loss: 426.2209\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0028 - val_loss: 426.2205\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 13.0029 - val_loss: 426.2198\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(89.3180, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0010, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(-0.0204, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.2194, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 354ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71.04624183, 71.02663399, 71.00702614, 70.9874183 , 70.96781046,\n",
       "        70.94820261, 70.92859477, 70.90898693, 70.87875817, 70.83954248,\n",
       "        70.8003268 , 70.76111111, 70.72189542, 70.68267974, 70.64346405,\n",
       "        70.60424837, 70.56503268, 70.52581699, 70.48660131, 70.44738562,\n",
       "        70.40816993, 70.36895425, 70.32973856, 70.29052288, 70.25130719,\n",
       "        70.2120915 , 70.17287582, 70.13366013, 70.09444444, 70.05522876,\n",
       "        70.01601307, 69.97679739, 69.9375817 , 69.89836601, 69.85915033,\n",
       "        69.81993464, 69.78071895, 69.74150327, 69.70228758, 69.6630719 ,\n",
       "        69.62385621, 69.58464052, 69.54542484, 69.50620915, 69.48349673,\n",
       "        69.46388889, 69.44428105, 73.43056256, 73.3036718 , 73.17678105,\n",
       "        73.04989029, 72.92299953, 72.79610878, 72.66921802, 72.54232726,\n",
       "        72.41543651, 72.28854575, 72.161655  , 72.03476424, 71.96878852,\n",
       "        71.93601541, 71.9032423 , 71.87046919, 71.83769608, 71.80492297,\n",
       "        71.77214986, 71.73937675, 71.70660364, 71.67383053, 71.64105742,\n",
       "        71.60828431, 71.55604575, 71.49722222, 78.06593323,  0.        ,\n",
       "         0.4376162 ,  0.        ,  0.        ,  0.508596  ,  0.        ,\n",
       "        73.87406158,  0.34570295,  0.        ,  0.        ,  0.74722916,\n",
       "         0.49144474,  0.60891181,  0.        ,  0.7800591 ,  0.23270185,\n",
       "         0.4472878 ,  0.21939155,  0.        ,  0.15797441,  0.        ,\n",
       "         0.        ,  0.58262908,  1.01611876,  0.        ,  0.53402716]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68.5219888 , 68.52012138, 68.51825397, 68.51638655, 68.51451914,\n",
       "       68.51265173, 68.51078431, 68.5089169 , 68.50704949, 68.50518207,\n",
       "       68.50331466, 68.50144725, 68.49747899, 68.48627451, 68.47507003,\n",
       "       68.46386555, 68.45266106, 68.44145658, 68.4302521 , 68.41904762,\n",
       "       68.40784314, 68.39663866, 68.38543417, 68.37422969, 68.36302521,\n",
       "       68.35182073, 68.34061625, 68.32941176, 68.31820728, 68.3070028 ,\n",
       "       68.29579832, 68.28459384, 68.27338936, 68.26218487, 68.25098039,\n",
       "       68.23977591, 68.22857143, 68.21736695, 68.20616246, 68.19495798,\n",
       "       68.1837535 , 68.17254902, 68.16134454, 68.15014006, 68.13893557,\n",
       "       68.12773109, 68.11652661, 68.10532213, 68.09411765, 68.08291317,\n",
       "       68.07170868, 68.0605042 , 68.04929972, 68.03809524, 68.02689076,\n",
       "       68.01568627, 68.00448179, 67.99327731, 67.98207283, 67.97086835,\n",
       "       67.95966387, 67.94845938, 67.9372549 , 67.92605042, 67.91484594,\n",
       "       67.90364146, 67.89243697, 67.88123249, 67.87002801, 67.85882353,\n",
       "       67.84761905, 67.83641457, 67.82521008, 67.8140056 , 67.80280112,\n",
       "       67.79159664, 67.78039216, 67.76918768, 67.75798319, 67.74677871,\n",
       "       67.73557423, 67.72436975, 67.71316527, 67.70196078, 67.6907563 ,\n",
       "       67.67955182, 67.66834734, 67.65714286, 67.64593838, 67.63473389,\n",
       "       67.62352941, 67.61232493, 67.60112045, 67.58991597, 67.57871148,\n",
       "       67.567507  , 67.55630252, 67.54509804, 67.53389356, 67.52268908])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.806146616720376\n",
      "19.012435488899914\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
