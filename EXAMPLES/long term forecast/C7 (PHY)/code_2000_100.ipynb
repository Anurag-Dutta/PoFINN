{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "2095    65.573284\n",
       "2096    65.563480\n",
       "2097    65.553676\n",
       "2098    65.543873\n",
       "2099    65.534069\n",
       "Name: C7, Length: 2100, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c7_interpolated_2000_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92.600000\n",
       "1       92.387115\n",
       "2       92.174230\n",
       "3       91.961345\n",
       "4       91.748459\n",
       "          ...    \n",
       "1995     0.000000\n",
       "1996     0.000000\n",
       "1997     0.000000\n",
       "1998     0.000000\n",
       "1999     0.371033\n",
       "Name: C7, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2000)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.387115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.174230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.961345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.748459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     92.600000  0.000298\n",
       "1     92.387115  0.000298\n",
       "2     92.174230  0.000297\n",
       "3     91.961345  0.000297\n",
       "4     91.748459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 89.3180  # Value for C0\n",
    "K0 = -0.0010  # Value for K0\n",
    "K1 = 0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = -0.0204    # Value for b\n",
    "c = 2.2194    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    92.600000    92.387115    92.174230    91.961345    91.748459   \n",
      "351    92.387115    92.174230    91.961345    91.748459    91.535574   \n",
      "352    92.174230    91.961345    91.748459    91.535574    91.322689   \n",
      "353    91.961345    91.748459    91.535574    91.322689    91.109804   \n",
      "354    91.748459    91.535574    91.322689    91.109804    90.896919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    91.535574    91.322689    91.109804    90.896919    90.691597  ...   \n",
      "351    91.322689    91.109804    90.896919    90.691597    90.579552  ...   \n",
      "352    91.109804    90.896919    90.691597    90.579552    90.467507  ...   \n",
      "353    90.896919    90.691597    90.579552    90.467507    90.355462  ...   \n",
      "354    90.691597    90.579552    90.467507    90.355462    90.243417  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   80.261671    0.000263   80.252334    0.000263   80.242997    0.000263   \n",
      "351   80.252334    0.000263   80.242997    0.000263   80.233660    0.000262   \n",
      "352   80.242997    0.000263   80.233660    0.000262   80.224323    0.000262   \n",
      "353   80.233660    0.000262   80.224323    0.000262   80.214986    0.000262   \n",
      "354   80.224323    0.000262   80.214986    0.000262   80.205649    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   80.233660    0.000262   80.224323    0.000262  \n",
      "351   80.224323    0.000262   80.214986    0.000262  \n",
      "352   80.214986    0.000262   80.205649    0.000262  \n",
      "353   80.205649    0.000262   80.196312    0.000262  \n",
      "354   80.196312    0.000262   80.186975    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1550, 1, 251) (1550, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 2s 25ms/step - loss: 5686.1382 - val_loss: 4027.3867\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5616.0698 - val_loss: 3995.8594\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5570.2290 - val_loss: 3964.7693\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5524.5806 - val_loss: 3933.8787\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5479.1807 - val_loss: 3903.1812\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5434.0430 - val_loss: 3872.6763\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5389.1724 - val_loss: 3842.3584\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5344.5728 - val_loss: 3812.2065\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 5300.2417 - val_loss: 3782.0649\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5244.9111 - val_loss: 3737.1233\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5185.9116 - val_loss: 3691.4519\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5117.5620 - val_loss: 3654.2927\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5064.2651 - val_loss: 3618.4902\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5012.8267 - val_loss: 3583.9160\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4962.7847 - val_loss: 3550.2100\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4913.7559 - val_loss: 3517.1677\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4865.5264 - val_loss: 3484.6707\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4817.9678 - val_loss: 3452.6455\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4770.9946 - val_loss: 3421.0410\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4724.5527 - val_loss: 3389.8218\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4678.5977 - val_loss: 3358.9612\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4633.0981 - val_loss: 3328.4387\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4588.0312 - val_loss: 3298.2378\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4543.3765 - val_loss: 3268.3455\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4499.1167 - val_loss: 3238.7510\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4455.2402 - val_loss: 3209.4448\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4411.7344 - val_loss: 3180.4194\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4368.5903 - val_loss: 3151.6682\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4325.7998 - val_loss: 3123.1846\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4283.3540 - val_loss: 3094.9639\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4241.2476 - val_loss: 3067.0012\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4199.4751 - val_loss: 3039.2922\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4158.0298 - val_loss: 3011.8330\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4116.9082 - val_loss: 2984.6201\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4076.1045 - val_loss: 2957.6499\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4035.6157 - val_loss: 2930.9197\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3995.4368 - val_loss: 2904.4272\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3955.5649 - val_loss: 2878.1689\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3915.9976 - val_loss: 2852.1421\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3876.7302 - val_loss: 2826.3455\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3837.7598 - val_loss: 2800.7759\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3799.0847 - val_loss: 2775.4316\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3760.7012 - val_loss: 2750.3103\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3722.6072 - val_loss: 2725.4104\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3684.7991 - val_loss: 2700.7292\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3647.2759 - val_loss: 2676.2659\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3610.0354 - val_loss: 2652.0181\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3573.0747 - val_loss: 2627.9844\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3536.3904 - val_loss: 2604.1631\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3499.9834 - val_loss: 2580.5520\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3463.8491 - val_loss: 2557.1506\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3427.9866 - val_loss: 2533.9565\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3392.3936 - val_loss: 2510.9683\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3357.0686 - val_loss: 2488.1853\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3322.0093 - val_loss: 2465.6052\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3287.2146 - val_loss: 2443.2273\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3252.6821 - val_loss: 2421.0500\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3218.4111 - val_loss: 2399.0718\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3184.3982 - val_loss: 2377.2913\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3150.6431 - val_loss: 2355.7073\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3117.1440 - val_loss: 2334.3191\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 3083.8987 - val_loss: 2313.1245\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3050.9067 - val_loss: 2292.1233\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3018.1655 - val_loss: 2271.3137\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2985.6733 - val_loss: 2250.6943\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2953.4312 - val_loss: 2230.2644\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2921.4336 - val_loss: 2210.0229\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2889.6824 - val_loss: 2189.9683\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2858.1741 - val_loss: 2170.0996\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2826.9089 - val_loss: 2150.4158\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2795.8843 - val_loss: 2130.9153\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2765.0996 - val_loss: 2111.5979\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2734.5535 - val_loss: 2092.4622\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2704.2439 - val_loss: 2073.5068\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2674.1699 - val_loss: 2054.7310\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2644.3303 - val_loss: 2036.1339\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2614.7246 - val_loss: 2017.7141\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2585.3501 - val_loss: 1999.4706\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2556.2056 - val_loss: 1981.4025\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2527.2910 - val_loss: 1963.5090\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2498.6047 - val_loss: 1945.7893\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2470.1453 - val_loss: 1928.2417\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2441.9109 - val_loss: 1910.8660\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 2413.9011 - val_loss: 1893.6603\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2386.1145 - val_loss: 1876.6244\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2358.5500 - val_loss: 1859.7574\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2331.2068 - val_loss: 1843.0581\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2304.0825 - val_loss: 1826.5256\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2277.1772 - val_loss: 1810.1591\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2250.4900 - val_loss: 1793.9579\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2224.0183 - val_loss: 1777.9204\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2197.7625 - val_loss: 1762.0464\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2171.7205 - val_loss: 1746.3347\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2145.8916 - val_loss: 1730.7844\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2120.2749 - val_loss: 1715.3950\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2094.8696 - val_loss: 1700.1652\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2069.6733 - val_loss: 1685.0940\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2044.6860 - val_loss: 1670.1809\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2019.9062 - val_loss: 1655.4253\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1995.3339 - val_loss: 1640.8258\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1970.9669 - val_loss: 1626.3818\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1946.8047 - val_loss: 1612.0925\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1922.8459 - val_loss: 1597.9570\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1899.0891 - val_loss: 1583.9746\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1875.5347 - val_loss: 1570.1443\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1852.1804 - val_loss: 1556.4653\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1829.0260 - val_loss: 1542.9368\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1806.0702 - val_loss: 1529.5581\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1783.3116 - val_loss: 1516.3284\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1760.7504 - val_loss: 1503.2463\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1738.3843 - val_loss: 1490.3123\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1716.2129 - val_loss: 1477.5244\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1694.2355 - val_loss: 1464.8822\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1672.4510 - val_loss: 1452.3853\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1650.8577 - val_loss: 1440.0321\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1629.4556 - val_loss: 1427.8225\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1608.2434 - val_loss: 1415.7559\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1587.2209 - val_loss: 1403.8308\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1566.3860 - val_loss: 1392.0469\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1545.7384 - val_loss: 1380.4034\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1525.2769 - val_loss: 1368.8993\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1505.0009 - val_loss: 1357.5344\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1484.9094 - val_loss: 1346.3075\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1465.0021 - val_loss: 1335.2179\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1445.2766 - val_loss: 1324.2644\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1425.7333 - val_loss: 1313.4471\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1406.3708 - val_loss: 1302.7651\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1387.1890 - val_loss: 1292.2173\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1368.1855 - val_loss: 1281.8031\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1349.3610 - val_loss: 1271.5220\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1330.7133 - val_loss: 1261.3721\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1312.2418 - val_loss: 1251.3545\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1293.9464 - val_loss: 1241.4668\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1275.8254 - val_loss: 1231.7095\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1257.8788 - val_loss: 1222.0814\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1240.1050 - val_loss: 1212.5813\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1222.5029 - val_loss: 1203.2090\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1205.0725 - val_loss: 1193.9639\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1187.8130 - val_loss: 1184.8452\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1170.7225 - val_loss: 1175.8518\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1153.8008 - val_loss: 1166.9829\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1137.0474 - val_loss: 1158.2385\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1120.4607 - val_loss: 1149.6174\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1104.0404 - val_loss: 1141.1188\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1087.7859 - val_loss: 1132.7423\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1071.6952 - val_loss: 1124.4869\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1055.7688 - val_loss: 1116.3522\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1040.0050 - val_loss: 1108.3367\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1024.4031 - val_loss: 1100.4408\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1008.9629 - val_loss: 1092.6632\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 993.6835 - val_loss: 1085.0028\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 978.5631 - val_loss: 1077.4596\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 963.6015 - val_loss: 1070.0326\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 948.7979 - val_loss: 1062.7211\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 934.1513 - val_loss: 1055.5240\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 919.6611 - val_loss: 1048.4412\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 905.3262 - val_loss: 1041.4716\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 891.1462 - val_loss: 1034.6144\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 877.1201 - val_loss: 1027.8695\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 863.2469 - val_loss: 1021.2354\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 849.5256 - val_loss: 1014.7117\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 835.9559 - val_loss: 1008.2980\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 822.5368 - val_loss: 1001.9929\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 809.2673 - val_loss: 995.7963\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 796.1472 - val_loss: 989.7070\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 783.1747 - val_loss: 983.7250\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 770.3500 - val_loss: 977.8490\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 757.6719 - val_loss: 972.0784\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 745.1392 - val_loss: 966.4121\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 732.7513 - val_loss: 960.8500\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 720.5076 - val_loss: 955.3911\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 708.4072 - val_loss: 950.0347\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 696.4492 - val_loss: 944.7798\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 684.6328 - val_loss: 939.6263\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 672.9573 - val_loss: 934.5729\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 661.4218 - val_loss: 929.6191\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 650.0254 - val_loss: 924.7642\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 638.7675 - val_loss: 920.0073\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 627.6470 - val_loss: 915.3476\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 616.6631 - val_loss: 910.7847\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 605.8150 - val_loss: 906.3174\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 595.1022 - val_loss: 901.9454\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 584.5238 - val_loss: 897.6680\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 574.0787 - val_loss: 893.4839\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 563.7662 - val_loss: 889.3928\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 553.5853 - val_loss: 885.3937\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 543.5355 - val_loss: 881.4861\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 533.6157 - val_loss: 877.6691\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 523.8255 - val_loss: 873.9420\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 514.1638 - val_loss: 870.3043\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 504.6302 - val_loss: 866.7548\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 495.2231 - val_loss: 863.2930\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 485.9422 - val_loss: 859.9182\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 476.7868 - val_loss: 856.6293\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 467.7557 - val_loss: 853.4258\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 458.8478 - val_loss: 850.3068\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 450.0629 - val_loss: 847.2714\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 441.3992 - val_loss: 844.3190\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 432.8564 - val_loss: 841.4489\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 424.4341 - val_loss: 838.6603\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 416.1310 - val_loss: 835.9523\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 407.9467 - val_loss: 833.3243\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 399.8798 - val_loss: 830.7753\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 391.9297 - val_loss: 828.3046\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 384.0954 - val_loss: 825.9114\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 376.3766 - val_loss: 823.5950\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 368.7718 - val_loss: 821.3546\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 361.2804 - val_loss: 819.1893\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 353.9015 - val_loss: 817.0984\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 346.6343 - val_loss: 815.0809\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 339.4780 - val_loss: 813.1363\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 332.4315 - val_loss: 811.2635\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 325.4939 - val_loss: 809.4619\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 318.6649 - val_loss: 807.7307\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 311.9431 - val_loss: 806.0687\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 305.3277 - val_loss: 804.4755\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 298.8179 - val_loss: 802.9503\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 292.4128 - val_loss: 801.4921\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 286.1115 - val_loss: 800.1000\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 279.9132 - val_loss: 798.7733\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 273.8169 - val_loss: 797.5112\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 267.8218 - val_loss: 796.3128\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 261.9269 - val_loss: 795.1772\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 256.1317 - val_loss: 794.1038\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 250.4351 - val_loss: 793.0916\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 244.8359 - val_loss: 792.1398\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 239.3333 - val_loss: 791.2476\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 233.9269 - val_loss: 790.4139\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 228.6152 - val_loss: 789.6381\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 223.3977 - val_loss: 788.9193\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 218.2731 - val_loss: 788.2567\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 213.2408 - val_loss: 787.6494\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 208.2998 - val_loss: 787.0965\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 203.4495 - val_loss: 786.5971\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 198.6887 - val_loss: 786.1504\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 194.0165 - val_loss: 785.7557\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 189.4319 - val_loss: 785.4120\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 184.9341 - val_loss: 785.1183\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 180.5221 - val_loss: 784.8741\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 176.1949 - val_loss: 784.6782\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 171.9519 - val_loss: 784.5298\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 167.7920 - val_loss: 784.4281\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 163.7142 - val_loss: 784.3722\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 159.7178 - val_loss: 784.3613\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 155.8016 - val_loss: 784.3943\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 151.9649 - val_loss: 784.4706\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 148.2067 - val_loss: 784.5892\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 144.5261 - val_loss: 784.7495\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 140.9221 - val_loss: 784.9500\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 137.3939 - val_loss: 785.1904\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 133.9404 - val_loss: 785.4695\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 130.5609 - val_loss: 785.7867\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 127.2543 - val_loss: 786.1409\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 124.0195 - val_loss: 786.5314\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 120.8559 - val_loss: 786.9570\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 117.7624 - val_loss: 787.4173\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 114.7381 - val_loss: 787.9112\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 111.7820 - val_loss: 788.4377\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 108.8933 - val_loss: 788.9962\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 106.0709 - val_loss: 789.5856\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 103.3141 - val_loss: 790.2050\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 100.6218 - val_loss: 790.8539\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 97.9931 - val_loss: 791.5311\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 95.4272 - val_loss: 792.2358\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 92.9230 - val_loss: 792.9673\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 90.4797 - val_loss: 793.7244\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 88.0962 - val_loss: 794.5067\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 85.7718 - val_loss: 795.3130\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 83.5055 - val_loss: 796.1426\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 81.2963 - val_loss: 796.9946\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 79.1433 - val_loss: 797.8683\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 77.0458 - val_loss: 798.7626\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 75.0028 - val_loss: 799.6769\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 73.0131 - val_loss: 800.6102\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 71.0761 - val_loss: 801.5620\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 69.1907 - val_loss: 802.5311\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 67.3562 - val_loss: 803.5168\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 65.5718 - val_loss: 804.5183\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 63.8363 - val_loss: 805.5348\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 62.1491 - val_loss: 806.5656\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 60.5089 - val_loss: 807.6098\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 58.9151 - val_loss: 808.6668\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 57.3668 - val_loss: 809.7357\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 55.8631 - val_loss: 810.8154\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 54.4033 - val_loss: 811.9058\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 52.9862 - val_loss: 813.0055\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 51.6112 - val_loss: 814.1141\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 50.2775 - val_loss: 815.2308\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 48.9841 - val_loss: 816.3547\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 47.7302 - val_loss: 817.4855\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 46.5148 - val_loss: 818.6219\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 45.3374 - val_loss: 819.7637\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 44.1970 - val_loss: 820.9100\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 43.0927 - val_loss: 822.0601\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 42.0238 - val_loss: 823.2135\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 40.9895 - val_loss: 824.3690\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 39.9891 - val_loss: 825.5264\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 39.0217 - val_loss: 826.6851\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 38.0863 - val_loss: 827.8443\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 37.1826 - val_loss: 829.0033\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 36.3095 - val_loss: 830.1616\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 35.4662 - val_loss: 831.3188\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 34.6523 - val_loss: 832.4736\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 33.8668 - val_loss: 833.6262\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 33.1090 - val_loss: 834.7758\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 32.3782 - val_loss: 835.9214\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 31.6737 - val_loss: 837.0632\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 30.9948 - val_loss: 838.2001\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 30.3408 - val_loss: 839.3318\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 29.7109 - val_loss: 840.4578\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 29.1046 - val_loss: 841.5776\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 28.5212 - val_loss: 842.6905\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 27.9600 - val_loss: 843.7966\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 27.4203 - val_loss: 844.8946\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 26.9017 - val_loss: 845.9851\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 26.4032 - val_loss: 847.0670\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 25.9245 - val_loss: 848.1395\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 25.4650 - val_loss: 849.2029\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 25.0239 - val_loss: 850.2568\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 24.6007 - val_loss: 851.3008\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 24.1949 - val_loss: 852.3340\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.8060 - val_loss: 853.3568\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.4333 - val_loss: 854.3691\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 23.0760 - val_loss: 855.3691\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.7342 - val_loss: 856.3578\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 22.4070 - val_loss: 857.3349\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 22.0941 - val_loss: 858.3000\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.7946 - val_loss: 859.2522\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.5084 - val_loss: 860.1920\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 21.2349 - val_loss: 861.1185\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 20.9737 - val_loss: 862.0323\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.7243 - val_loss: 862.9330\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.4861 - val_loss: 863.8199\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.2591 - val_loss: 864.6934\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 20.0425 - val_loss: 865.5529\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.8361 - val_loss: 866.3988\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.6394 - val_loss: 867.2308\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.4520 - val_loss: 868.0488\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 19.2736 - val_loss: 868.8522\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 19.1038 - val_loss: 869.6415\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 18.9422 - val_loss: 870.4164\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.7886 - val_loss: 871.1770\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.6426 - val_loss: 871.9228\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.5040 - val_loss: 872.6545\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.3722 - val_loss: 873.3716\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.2471 - val_loss: 874.0744\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 18.1283 - val_loss: 874.7627\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 18.0157 - val_loss: 875.4365\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.9088 - val_loss: 876.0958\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 17.8075 - val_loss: 876.7407\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 17.7115 - val_loss: 877.3716\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 17.6206 - val_loss: 877.9879\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.5345 - val_loss: 878.5901\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 17.4530 - val_loss: 879.1782\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.3759 - val_loss: 879.7524\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.3030 - val_loss: 880.3125\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 17.2340 - val_loss: 880.8589\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.1688 - val_loss: 881.3915\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 17.1072 - val_loss: 881.9110\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 17.0489 - val_loss: 882.4167\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9940 - val_loss: 882.9098\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.9420 - val_loss: 883.3892\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.8930 - val_loss: 883.8557\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.8468 - val_loss: 884.3097\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.8032 - val_loss: 884.7507\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.7621 - val_loss: 885.1793\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.7233 - val_loss: 885.5961\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.6867 - val_loss: 886.0000\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.6524 - val_loss: 886.3925\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.6199 - val_loss: 886.7731\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.5894 - val_loss: 887.1420\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.5607 - val_loss: 887.4999\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.5337 - val_loss: 887.8469\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.5081 - val_loss: 888.1827\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.4842 - val_loss: 888.5079\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.4617 - val_loss: 888.8228\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.4404 - val_loss: 889.1273\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 16.4204 - val_loss: 889.4217\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.4017 - val_loss: 889.7064\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.3841 - val_loss: 889.9811\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.3675 - val_loss: 890.2466\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 16.3519 - val_loss: 890.5031\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.3372 - val_loss: 890.7500\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 16.3235 - val_loss: 890.9885\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.3106 - val_loss: 891.2186\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.2984 - val_loss: 891.4404\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.2870 - val_loss: 891.6539\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.2764 - val_loss: 891.8595\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.2662 - val_loss: 892.0573\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.2568 - val_loss: 892.2479\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.2479 - val_loss: 892.4308\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.2396 - val_loss: 892.6069\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.2319 - val_loss: 892.7763\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.2245 - val_loss: 892.9389\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.2176 - val_loss: 893.0950\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.2111 - val_loss: 893.2446\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.2050 - val_loss: 893.3880\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1994 - val_loss: 893.5259\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1940 - val_loss: 893.6578\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1891 - val_loss: 893.7847\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 16.1843 - val_loss: 893.9058\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1799 - val_loss: 894.0214\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1758 - val_loss: 894.1324\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1719 - val_loss: 894.2387\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1683 - val_loss: 894.3399\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1649 - val_loss: 894.4369\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1617 - val_loss: 894.5291\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1588 - val_loss: 894.6176\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1560 - val_loss: 894.7021\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1533 - val_loss: 894.7825\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1509 - val_loss: 894.8586\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1487 - val_loss: 894.9319\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1465 - val_loss: 895.0015\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1446 - val_loss: 895.0681\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1427 - val_loss: 895.1315\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1410 - val_loss: 895.1920\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1393 - val_loss: 895.2490\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1378 - val_loss: 895.3033\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1364 - val_loss: 895.3547\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1351 - val_loss: 895.4037\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1339 - val_loss: 895.4504\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 16.1328 - val_loss: 895.4949\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1318 - val_loss: 895.5369\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1308 - val_loss: 895.5767\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1299 - val_loss: 895.6147\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1291 - val_loss: 895.6505\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1284 - val_loss: 895.6844\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1276 - val_loss: 895.7167\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1270 - val_loss: 895.7468\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1265 - val_loss: 895.7755\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1259 - val_loss: 895.8027\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1254 - val_loss: 895.8282\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1250 - val_loss: 895.8526\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1246 - val_loss: 895.8754\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1243 - val_loss: 895.8974\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1239 - val_loss: 895.9175\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1236 - val_loss: 895.9368\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1233 - val_loss: 895.9544\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 16.1232 - val_loss: 895.9721\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1230 - val_loss: 895.9881\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 16.1228 - val_loss: 896.0028\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1227 - val_loss: 896.0173\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1226 - val_loss: 896.0305\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1225 - val_loss: 896.0427\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 16.1225 - val_loss: 896.0547\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1224 - val_loss: 896.0661\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1224 - val_loss: 896.0760\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1224 - val_loss: 896.0859\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1224 - val_loss: 896.0948\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1224 - val_loss: 896.1035\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1224 - val_loss: 896.1111\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1225 - val_loss: 896.1187\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1225 - val_loss: 896.1253\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1227 - val_loss: 896.1317\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1228 - val_loss: 896.1378\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1228 - val_loss: 896.1432\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1230 - val_loss: 896.1482\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1231 - val_loss: 896.1529\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1232 - val_loss: 896.1577\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1234 - val_loss: 896.1616\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1236 - val_loss: 896.1658\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1236 - val_loss: 896.1691\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1238 - val_loss: 896.1727\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 16.1239 - val_loss: 896.1757\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1241 - val_loss: 896.1787\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1242 - val_loss: 896.1813\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1245 - val_loss: 896.1837\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1246 - val_loss: 896.1860\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1247 - val_loss: 896.1877\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1250 - val_loss: 896.1897\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1252 - val_loss: 896.1915\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1254 - val_loss: 896.1931\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1255 - val_loss: 896.1946\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1257 - val_loss: 896.1960\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1259 - val_loss: 896.1972\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 16.1261 - val_loss: 896.1981\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1263 - val_loss: 896.1993\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1264 - val_loss: 896.2003\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1267 - val_loss: 896.2014\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1268 - val_loss: 896.2019\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1270 - val_loss: 896.2020\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1272 - val_loss: 896.2023\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1274 - val_loss: 896.2031\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1276 - val_loss: 896.2034\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1277 - val_loss: 896.2036\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1280 - val_loss: 896.2040\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 16.1281 - val_loss: 896.2040\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1284 - val_loss: 896.2044\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1285 - val_loss: 896.2047\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1287 - val_loss: 896.2047\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1289 - val_loss: 896.2047\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1291 - val_loss: 896.2047\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1293 - val_loss: 896.2047\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1294 - val_loss: 896.2048\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1296 - val_loss: 896.2047\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1298 - val_loss: 896.2047\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1299 - val_loss: 896.2047\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1301 - val_loss: 896.2045\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 16.1303 - val_loss: 896.2042\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 16.1305 - val_loss: 896.2037\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(89.3180, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0010, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(-0.0204, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.2194, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 353ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.17175280e+01, 7.16847549e+01, 7.16519818e+01, 7.16192087e+01,\n",
       "        7.15756536e+01, 7.15168301e+01, 7.14580065e+01, 2.33948890e-01,\n",
       "        6.30085410e-01, 0.00000000e+00, 0.00000000e+00, 1.53718980e-01,\n",
       "        0.00000000e+00, 7.21052591e+01, 7.19869958e+01, 7.19542227e+01,\n",
       "        7.19214496e+01, 7.18886765e+01, 7.18559034e+01, 7.18223130e+01,\n",
       "        7.17903571e+01, 7.17575840e+01, 7.17248109e+01, 7.16920378e+01,\n",
       "        7.16592647e+01, 7.16264916e+01, 7.15887255e+01, 7.15299020e+01,\n",
       "        7.14710784e+01, 7.14122549e+01, 7.13534314e+01, 7.12946078e+01,\n",
       "        7.12357843e+01, 7.11769608e+01, 7.11181373e+01, 7.10593137e+01,\n",
       "        7.10004902e+01, 6.96416667e+01, 6.86568630e+01, 6.82656863e+01,\n",
       "        5.23304760e-01, 4.55971301e-01, 6.83388790e-02, 5.75651467e-01,\n",
       "        5.64365208e-01, 0.00000000e+00, 0.00000000e+00, 7.16337745e+01,\n",
       "        7.16001001e+01, 7.15429739e+01, 7.14841503e+01, 7.14253268e+01,\n",
       "        7.13665033e+01, 7.13076797e+01, 7.12498562e+01, 7.11890327e+01,\n",
       "        7.11312092e+01, 7.10723856e+01, 7.10135621e+01, 7.09547386e+01,\n",
       "        7.08918301e+01, 7.07741830e+01, 7.06565360e+01, 7.05398889e+01,\n",
       "        7.04212418e+01, 7.03035948e+01, 7.01859477e+01, 7.00683006e+01,\n",
       "        6.99506536e+01, 6.98330065e+01, 6.97153595e+01, 6.95997112e+01,\n",
       "        6.94900327e+01, 7.72702789e+01, 4.95039791e-01, 0.00000000e+00,\n",
       "        4.84672904e-01, 1.99221283e-01, 3.76206368e-01, 1.64610699e-01,\n",
       "        6.25196266e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.95545948e-01, 1.04031064e-01,\n",
       "        0.00000000e+00, 6.70331866e-02, 8.66873026e-01, 7.09320724e-01,\n",
       "        0.00000000e+00, 8.27256680e-01, 0.00000000e+00, 5.27806342e-01,\n",
       "        6.09688163e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66.50465686, 66.49485294, 66.48504902, 66.4752451 , 66.46544118,\n",
       "       66.45563725, 66.44583333, 66.43602941, 66.42622549, 66.41642157,\n",
       "       66.40661765, 66.39681373, 66.3870098 , 66.37720588, 66.36740196,\n",
       "       66.35759804, 66.34779412, 66.3379902 , 66.32818627, 66.31838235,\n",
       "       66.30857843, 66.29877451, 66.28897059, 66.27916667, 66.26936275,\n",
       "       66.25955882, 66.2497549 , 66.23995098, 66.23014706, 66.22034314,\n",
       "       66.21053922, 66.20073529, 66.19093137, 66.18112745, 66.17132353,\n",
       "       66.16151961, 66.15171569, 66.14191176, 66.13210784, 66.12230392,\n",
       "       66.1125    , 66.10269608, 66.09289216, 66.08308824, 66.07328431,\n",
       "       66.06348039, 66.05367647, 66.04387255, 66.03406863, 66.02426471,\n",
       "       66.01446078, 66.00465686, 65.99485294, 65.98504902, 65.9752451 ,\n",
       "       65.96544118, 65.95563725, 65.94583333, 65.93602941, 65.92622549,\n",
       "       65.91642157, 65.90661765, 65.89681373, 65.8870098 , 65.87720588,\n",
       "       65.86740196, 65.85759804, 65.84779412, 65.8379902 , 65.82818627,\n",
       "       65.81838235, 65.80857843, 65.79877451, 65.78897059, 65.77916667,\n",
       "       65.76936275, 65.75955882, 65.7497549 , 65.73995098, 65.73014706,\n",
       "       65.72034314, 65.71053922, 65.70073529, 65.69093137, 65.68112745,\n",
       "       65.67132353, 65.66151961, 65.65171569, 65.64191176, 65.63210784,\n",
       "       65.62230392, 65.6125    , 65.60269608, 65.59289216, 65.58308824,\n",
       "       65.57328431, 65.56348039, 65.55367647, 65.54387255, 65.53406863])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.64813326176061\n",
      "28.050430864809538\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
