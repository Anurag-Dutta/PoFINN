{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2195    62.009237\n",
       "2196    62.001312\n",
       "2197    61.993387\n",
       "2198    61.985461\n",
       "2199    61.977536\n",
       "Name: C5, Length: 2200, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_2100_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2095     0.000000\n",
       "2096     0.000000\n",
       "2097     0.000000\n",
       "2098     0.000000\n",
       "2099     0.323002\n",
       "Name: C5, Length: 2100, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2100)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAyEElEQVR4nO3deXhU5fXA8e/JThISIIR9CZvse4hQEHFlccFd0Cq1tNSqtWrVH2ptra3W3bpQK25FtKJSF6wL4gIiAhJA9i2EHYRAWCQsIcn5/TE3yTBMSGbJTMKcz/PwZObOe+eeuST3zLvdV1QVY4wxkSsq3AEYY4wJL0sExhgT4SwRGGNMhLNEYIwxEc4SgTHGRLiYcAfgj4YNG2pGRka4wzDGmFpl4cKFu1U13XN7rUwEGRkZZGdnhzsMY4ypVURkk7ft1jRkjDERzhKBMcZEOEsExhgT4SwRGGNMhLNEYIwxES4oiUBEhonIGhHJEZHxXl4fLCKLRKRIRK5w295LROaKyAoRWSoiVwcjHmOMMVUXcCIQkWhgAjAc6AKMFpEuHsU2A78A/uOx/RBwvap2BYYB/xCReoHGZIwxpuqCUSPIAnJUNVdVC4EpwEj3Aqq6UVWXAiUe29eq6jrn8XZgF3DCZIdgmfTdRj5asr263t4YY2qlYCSC5sAWt+dbnW0+EZEsIA5YX8Hr40QkW0Sy8/Ly/Ap0yoItfPiDJQJjjHFXIzqLRaQpMBm4QVVLvJVR1Ymqmqmqmenp/lUa0uvGk3fwaACRGmPMqScYiWAb0NLteQtnW5WISArwMXCfqs4LQjwVSk+OZ/dPlgiMMcZdMBLBAqCDiLQRkThgFDCtKjs65d8HXlfVqUGI5aQa1o0j76ej2PKcxhhTLuBEoKpFwC3AdGAV8I6qrhCRB0XkYgAR6SciW4ErgRdFZIWz+1XAYOAXIvKD869XoDFVJD05nsLiEg4cLqquQxhjTK0TlLuPquonwCce2/7k9ngBriYjz/3eAN4IRgxVkV43HoC8g0dITYwN1WGNMaZGqxGdxaFSmgh2WT+BMcaUiahE0Ki0RmCJwBhjykRUIkhPTgAsERhjjLuISgQpdWKIi46yuQTGGOMmohKBiJBeN57dPxWGOxRjjKkxIioRADRMjrMagTHGuIm4RJBeN976CIwxxo0lAmOMiXARlwjaNExi98GjbNxdEO5QjDGmRoi4RDCyV3Oio4QpC7ZUXtgYYyJAxCWCxikJnN2pEVMXbqGwyOsdr40xJqJEXCIAuCarFbsPFvLFqp3hDsUYY8IuIhPB4NPSaZaawFvfbw53KMYYE3YRmQiio4Sr+rVk9rrdbMk/FO5wjDEmrCIyEQBcldmSKIE351utwBgT2SI2ETSrV4cR3Zvy0uxcZq3NC3c4xhgTNhGbCAAeubwHHRvX5aY3FrJi+/5wh2OMMWER0YkgOT6G127oR0qdWG54bQHb9h0Od0jGGBNyQUkEIjJMRNaISI6IjPfy+mARWSQiRSJyhcdrY0RknfNvTDDi8UXjlAReu6EfhwuL+eVrCzhw5FioQzDGmLAKOBGISDQwARgOdAFGi0gXj2KbgV8A//HYtwHwZ+B0IAv4s4jUDzQmX3VqksK/ruvL+ryD/PaNhTbRzBgTUYJRI8gCclQ1V1ULgSnASPcCqrpRVZcCnlfYocAMVc1X1b3ADGBYEGLy2cD2DXn08h7MydnDH95dwuHC4nCEYYwxIReMRNAccL9xz1ZnW1D3FZFxIpItItl5edUzyufyvi24e1hHPlqyneHPfMP3G/Kr5TjGGFOT1JrOYlWdqKqZqpqZnp5ebce5aUh73vp1f4pVuXriXP7y0QoOFRZV2/GMMSbcgpEItgEt3Z63cLZV977VZkC7ND77/WCu79+a1+ZsZPgzs612YIw5ZQUjESwAOohIGxGJA0YB06q473TgfBGp73QSn+9sC7uk+Bj+MrIbU8b1RxWueWmezTUwxpySAk4EqloE3ILrAr4KeEdVV4jIgyJyMYCI9BORrcCVwIsissLZNx/4K65ksgB40NlWY/Rvm8aHNw+kXmIcd767lGPFNqLIGHNqEVUNdww+y8zM1Ozs7JAe8/MVPzJu8kJuP/c0fn9uh5Ae2xhjgkFEFqpqpuf2WtNZHG7nd23CyF7NeO6rdazcfiDc4RhjTNBYIvDBAxd1dZqIllgTkTHmlGGJwAf1k+J46NJurNxxgBdmrg93OMYYExSWCHw01K2JaNUOayIyxtR+lgj88MBFXUmt42oisslmxpjazhKBH+onxfHwpd1Ysf0A5zw5i2lLtlMbR18ZYwxYIvDb+V2bMPXGAaQlx3HrW4u56sW5LN9mE86MMbWPJYIAZGY04MObB/HIZd3JzSvgoue/Zfx/l7L74NFwh2aMMVVmiSBA0VHCqKxWfH3XEMYObMPUhVs564mZvDw719Y1MMbUCpYIgiQlIZY/XtiFz24bTJ9W9fnbx6sY9sw3zFyzK9yhGWPMSVkiCLL2jZL59w39ePUXmajCL15bwNh/L2DD7oJwh2aMMV5ZIqgGIsLZnRoz/bbB3DuiE/M35DPsH9/w/uKt4Q7NGGNOYImgGsXFRDFucDu++sOZ9GpZj9vfXsID01bY7SmMMTWKJYIQaJSSwBu/Op2xg9rw7+82cu1L89n105Fwh2WMMYAlgpCJjY7i/gu78MyoXizdto+LnvuWhZv2hjssY4yxRBBqI3s15/2bBhIfE82oiXN5Y94mm5VsjAkrSwRh0LlpCh/dMoiB7Rvyxw+Wc/fUpRw5VhzusIwxEcoSQZikJsby6ph+3HpOB95duJUr/zWXbfsOhzssY0wECkoiEJFhIrJGRHJEZLyX1+NF5G3n9fkikuFsjxWRSSKyTERWicg9wYintoiKEu447zRevj6TjbsLuOi5b5mTszvcYRljIkzAiUBEooEJwHCgCzBaRLp4FBsL7FXV9sDTwKPO9iuBeFXtDvQFflOaJCLJuV0a8+EtA0lLiuO6V+bz4qz11m9gjAmZYNQIsoAcVc1V1UJgCjDSo8xIYJLzeCpwjogIoECSiMQAdYBCICJXe2mbnswHNw9keLem/P3T1dzyn8UUHLW1Dowx1S8YiaA5sMXt+VZnm9cyqloE7AfScCWFAmAHsBl4QlXzvR1ERMaJSLaIZOfl5QUh7JonKT6G56/pzT3DO/Hp8h1cMmEOuXkHwx2WMeYUF+7O4iygGGgGtAH+ICJtvRVU1Ymqmqmqmenp6aGMMaREhN+c2Y7JY09n98GjjHx+Dh/+sI0im41sjKkmwUgE24CWbs9bONu8lnGagVKBPcA1wGeqekxVdwFzgMwgxFTrDWzfkI9+N4iMhkn8fsoPZD38Jfe8t4w5ObstKRhjgiomCO+xAOggIm1wXfBH4brAu5sGjAHmAlcAX6mqishm4GxgsogkAf2BfwQhplNCi/qJvHfTz/hq9S7+t3QHH/6wjbe+30yDpDiGdm3ChT2acnqbBsREh7tiZ4ypzSQYo1NEZASuC3g08KqqPiQiDwLZqjpNRBKAyUBvIB8Ypaq5IpIMvIZrtJEAr6nq45UdLzMzU7OzswOOu7Y5cqyYmWt28fGyH/ly1U4OFRaTlhTH0G5NuKC7JQVjzMmJyEJVPaHVJSiJINQiNRG4O1xYzKy1rprCV6t3WVIwxlTKEsEp7HBhaU3hxKRwYfemnN42jegoCXeYxpgws0QQIbwlhQt7NOW50b1xTd0wxkSqihJBMDqLTQ1SJy6a4d2bMrx7Uw4XFvPCrPU8++U6ujZL5bdD2oU7PGNMDWSNyKewOnHR3H5uBy7s0ZTHpq9m1tpTcyKeMSYwlghOcSLCY1f0oGPjuvzuP4vYtKcg3CEZY2oYSwQRIDEuhonXZbpmLU9eyKFCu4eRMaacJYII0SotkedG92btzp+4a+pSu7upMaaMJYIIMvi0dO4e1omPl+7gxW9ywx2OMaaGsEQQYX4zuC0X9GjKY5+t5hvrPDbGYIkg4ogIj1/Rg9Ma1+V3by1m855D4Q7JGBNmlggiUGJcDC9e1xeAcZOzrfPYmAhniSBCtU5L4tnRvVmz8yfuts5jYyKaJYIIduZp6dw1tCP/W7qDl2Zb57ExkcoSQYT77ZntGNG9CY98uprZ66zz2JhIZIkgwrk6j3vSoZGr83hLvnUeGxNpLBEYkuJjmHh9X0pKlHE289iYiGOJwADlncerfzzAXe9a57ExkSQoiUBEhonIGhHJEZHxXl6PF5G3ndfni0iG22s9RGSuiKwQkWXOspYmDIZ0bMT4YZ34eNkOnvsqJ9zhGGNCJOBEICLRwARgOK61h0eLSBePYmOBvaraHngaeNTZNwZ4A7hRVbsCQ4BjgcZk/DducFsu692cp2as5bPlO8IdjjEmBIJRI8gCclQ1V1ULgSnASI8yI4FJzuOpwDniWi7rfGCpqi4BUNU9qlochJiMn0SEhy/rTq+W9bj97SWs3H4g3CEZY6pZMBJBc2CL2/OtzjavZVS1CNgPpAGnASoi00VkkYjcHYR4TIASYqOZeF1fUuvEcv2r8xn/36W8OX8Ty7bup7CoJNzhGWOCLNxLVcYAg4B+wCHgS2dNzS89C4rIOGAcQKtWrUIaZCRqlJLAq7/oxyOfreazFT8yZYEr18dFR9GpaV16tEilR/N6dG+RSodGycRE27gDY2qrYCSCbUBLt+ctnG3eymx1+gVSgT24ag/fqOpuABH5BOgDnJAIVHUiMBFci9cHIW5TiS7NUnj9l1moKlv3Hmbp1v0s3baPpVv28+Hi7bwxbzMACbFRdGmaQo8W9ejePJWeLVNp0zCZ6CgJ8ycwxlRFMBLBAqCDiLTBdcEfBVzjUWYaMAaYC1wBfKWqKiLTgbtFJBEoBM7E1ZlsahARoWWDRFo2SOSCHk0BKClRNu4pYNm2/Szdup9lW/fzTvYW/v3dRgCS4qLp2jyV4d2acP2ADEsKxtRgAScCVS0SkVuA6UA08KqqrhCRB4FsVZ0GvAJMFpEcIB9XskBV94rIU7iSiQKfqOrHgcZkql9UlNA2PZm26cmM7OXqEiouUdbnHXQSwz4Wbt7LXz5ayYc/bOeJK3vQvlHdMEdtjPFGauPEoczMTM3Ozg53GKYSqsq0Jdt5YNoKCgqLue3cDow7o631JxgTJk4fbKbndvuLNNVGRBjZqzmf334m53RqxGOfreGyF75jzY8/hTs0Y4wbSwSm2qXXjeeFn/dlwjV92Lr3MBc+N5vnvlzHsWIbimpMTWCJwITMBT2aMuP2wQzt2oQnZ6zlkglzbMKaMTWAJQITUmnJ8Tx/TR/+9fM+7DxwhIuf/5anZ6y1iWoRavqKH/l4ac2/lcmuA0eYPG8TO/YfDnco1cISgQmLYd2aMuP2M7mgR1Oe+XIdFz//Lcu37Q93WCbEJs/dxCvf1vzV8TbsLuD+D5aTm1cQ7lCqhSUCEzb1k+J4ZlRvXro+kz0FhYycMIcnpq/haJHdbipSKIrrtmO+C+W389Kxlf5EmrPrIDm7avYACUsEJuzO69KYGbcPZmSvZjz/dQ4XPfctS7fuC3dYJgRU/bu4frtuNwP+/hWfLAtNs5IGkAnu/2A597y3LKjxBJslAlMj1EuM46mrevHqLzI5cLiISybM4ZFPV9tqaac4VfCnQrB8u6sZ8Yct+3ze98f9R3yuTahTJxA/MoGifu0HUBSikXWWCEyNcnanxky/fTBX9G3Bv2at58zHZzJ53iYbanqKCuQiCf7VJu6auoSb31zk205OjcCfpKWKX4Eu3JRP+/s+5bv1u33f2UeWCEyNk1onlseu6MnUGweQkZbI/R8s57ynZvHRku2UlNS+mfCmYv5eJAO5IYI/+wbSR+Dvft/l7AFgTo4lAhPBMjMa8M5vBvDKmEziY6L53VuLGTlhDrPX5YU7NBMkfuaBcv4kET86qLWsRuBP01DNZ4nA1GgiwjmdG/PJ78/gySt7kl9QyHWvfM+1L8+zDuVTgZ99BBrA5dWfDuqyPgJ/spafnzGULBGYWiE6Sri8bwu+uvNM7r+wCyu3H+Di5+dw85uLyM07GO7wjJ/87SMo+4bu576+XpjLj+e7wPtBqj+LWCIwtUp8TDRjB7Xhm7vP4taz2/P1ml2c9/Q33Pv+MnYdOBLu8IyP/B01FNAx/bgwl/UR+Nmf4V+tJ3QsEZhaqW5CLHec35FZd53Fz09vxbvZWxj8+Nc89tlq9h8+Fu7wTBUpYWo28blG4H93caCfMRTnxxKBqdXS68bzl5Hd+PKOIQzt2oR/zlzPmY9/zcRv1nPkmM1QrulUA2w2CdGIo8BqBIE1f4WCJQJzSmiVlsgzo3rz8a2D6NmiHg9/spqznpjJOwu2hGxSjvFdOGoEfo1UCqiPwDqLjQmprs1SmfTLLN76dX8apSRw93+XMuyZ2Uxf8SO1cTW+U12g/yV+XV/96Sx2MkGUP8NHa8GvXVASgYgME5E1IpIjIuO9vB4vIm87r88XkQyP11uJyEERuTMY8RgzoF0aH9z0M/718z6UqPKbyQu5/IXvmJ+7J9yhGTeub8v+XFwDGD7qR2dxiVOp9LfT198b60GA8yyqKOBEICLRwARgONAFGC0iXTyKjQX2qmp74GngUY/XnwI+DTQWY9yJCMO6NeXz2wbzyGXd2b7vCFdPnMcv/72A1T/agjg1gmpAF7pQjeIp7yr274D+DjsNlWDUCLKAHFXNVdVCYAow0qPMSGCS83gqcI44KVJELgE2ACuCEIsxJ4iJjmJUVitm3jWE8cM7kb0xn+HPzOYP7yxh275Tc6GR2sLf9vOAm5T8HDXkf43A9/3KhKCDIRiJoDmwxe35Vmeb1zKqWgTsB9JEJBn4P+AvQYjDmJNKiI3mxjPbMfvusxk3uC0fLd3OWU/M5KGPV7K3oDDc4UUkVT/b3Z2f/t0N1HeB5B1/b7UdSuHuLH4AeFpVK50aKiLjRCRbRLLz8uxeM8Z/qYmx3DO8MzPvHMIlvZrxyrcbGPz41/xzZg6HC23IaSiVhKVpyI8JZYHcfTSAxXdCJRiJYBvQ0u15C2eb1zIiEgOkAnuA04HHRGQjcBtwr4jc4u0gqjpRVTNVNTM9PT0IYZtI16xeHR67oief3TaY09uk8dhnaxjyxNdM+X6zDTkNEb9n3QZy91H8OWYA6xH4WSOobfMIFgAdRKSNiMQBo4BpHmWmAWOcx1cAX6nLGaqaoaoZwD+Ah1X1+SDEZEyVnda4Li+PyeTdGwfQon4i499bxtB/fMOXq3aGO7RTXunl1V+husAGVCMI8DYatWLUkNPmfwswHVgFvKOqK0TkQRG52Cn2Cq4+gRzgDuCEIabGhFu/jAZMvXEAE6/rC8DYSdnc9e4SDh61VdKqi6qG/O6j4PtwzoBmFrv29HO/0IgJxpuo6ifAJx7b/uT2+AhwZSXv8UAwYjEmECLC+V2bMKRjI579ch3/nJnD/A35PH11T/q2bhDu8E5JoW4996uzOKC7nfqX7ErZvYaMCZO4mCjuHNqRd34zAEW58l9zefLzNbZkZpCF4+6j/ozrD2g9AmzUkDG1WmZGAz659Qwu69OC577K4fIXvmO9rX8QNIHeq9+fK7M/ncWBrEeAH8c77qAhYInAmErUTYjliSt78sK1fdicf4gLnp3N5Hmb7N5FQRCWUUN+rVDmEpbJb7YwjTE1x/DuTZl+22D6ZTTg/g+WM3ZSNnk/HQ13WLVawPfq9+uY/qxZHMh6BH7ehtrnPfxnicAYHzROSWDSDVk8cFEX5uTsZtg/vmHGShtm6i+/79Uf4HFD2cQT8PBR6yw2puaJihJ+MbAN//vdIBqnJPDr17O5572lFNgwU58pBDQZIGQL09h6BMYYbzo0rssHNw/kxjPbMWXBFi54djaLNu8Nd1i1S4D34QnZ4vVlo4b8HD5aw8cNWSIwJgBxMVGMH96Jt37dn2PFrmGmT89YG9HDTEtKqv6V2+/1CHzew3NfP+815OW1ym5H4m+tJ5RjEYIyocyYSNe/bRqf3nYGf/5wBc98uY5nv1pHap1YGiTGUT8pjgZJcTRIjKNBchxpSXHU93iclhxHYlzt/3P8Ycs+Lpkwh/aNkjmrYzqZGQ3IbF2ftOR4r+XVbUz/4cJi6sRF+3Q8v286V8l+qsrVL86je4tU7hrascJbTHy8dAc3/2cRz47uzcU9m5VtP1pUTHyM81kCrvVUv9r/m2dMDZGSEMvTV/fi4p7NWLxlH3sLCsk/VMjegkK25B9iyZZ95BcUUlTBN+aE2KiyZNEgKZ7m9RJo2zCZtulJtE1PpmX9OsRE1+xK/La9rvUd8n46yqTvNvHS7A0AtEtPYkjHRlw/oDWt05LKyru3n//8lfkUFpVwVb+WXNGnxUmTQnUvcVlcony/MZ/vN+Yza20el/Zu7ux3/J4bdrvmlNz61mIWbMjnwZFdeW3ORqYs2Mx7Nw0kOT6mwlrPryZlc1rjZO4e1slrDKFcmMYSgTFBdlanRpzVqZHX11SVn44WkX+wkD0FriSR7ySM/IJC9hwsZO+hQvYcPMrybfvJLyhf6iM2WmjVIJG26a7k0M4tSTRIigvVxzupEucK/d/fum7gt3zbftcFdUM+k77byKtzNnBe58aMHdSGrDYNysb0qyrDuzXh/cXbuP+D5Tz1+Rp+3r811w1oTaO6CRUer/TyeqiwyKcaVWU1gtJcfXanRszL3cPj09d43S8uxpWYR2e1ZPK8TWQ0TKJz07rk7DrI//13Kc+P7n1crQdg3c6fKFbli1U7+WLVTnq0qMewbk1cxy1RoqKOP0goOpotERgTQiJCSkIsKQmxZDRMqrT8vkOFrM8rIDfvILm7nZ95Bcxak0ehW9t0vcRY2jZ0JYVOTepycc9mNEqp+AJaXUq0vFM1ITba1TSU0YCbhsDOA0d4fe5G3py/mc9X7qRb8xQ25x+ib+v6iAi/OqMtYwe1YcHGvbw0O5fnv87hxVm5XNK7GfeO6Ey9xPJk5/5t+bv1u7npzUXccd5pXNe/daV9DlWpTZR+jsyM+lzSuzm3vrW4gnKun/df2IU9Bwv5+yerePfGAdw9rBOPfLqafq3rH1frKSou4YZ/L6BuQixR4tr/7qlL6NY8hcS4GMa9ns2vB7dlaNcmlQcZRJYIjKnB6iXG0bd1HH1b1z9ue1FxCdv2HSY3r4D1bknim7V5TF24lb9/uprzOjfm2v6tGNiu4QnfMqtL6UXW26pjjVMSuGtoJ245qwPvL97GC7NyAMjdXVBWRkTIatOArDYN2LC7gFe/3cCUBZvZkn+Y18dmEevRNCYCDZPj6dYslT99uAJVGPOzjJPHWIUJXu6f4+KezcoSgWcSKU0YUSI8fkVPznpyJq/O2cizo3oxc80uXpmzAXE7Wkx0FPeO6MxNby4C4Pwujfl6zS4mz93EH87vSH5BIa98uyHkiaBmNzgaY7yKiY6idVoSZ3VqxK/OaMvDl3ZnyrgBfH/fucy8cwi/GtSG7zfmc90r33PWkzP516z17DlY/bOgyy+MFZepExfNNae34u1xAwDI9Ehypdo0TOKvl3Tjkct6MDd3D3/930qv5U5rXJfXf5nFuZ0b8+D/VvJdzu6TxliV4aOen+N/vxvE0K6NaZJ6fC3LPWGkJsYypGM6a3/8CYALejRjS/5hNucfOq6Wcl6XxiTHu76Dt2qQSJ9W9Zm9bjdxMVEM7daERZv2cvBoUa1bmMYYU4NkNEzinhGdmXvP2TwzqheNUxJ45NPVDPj7V9z61mLm5e6ptvsklZykRuCpWb06rHpwGPeO6HzScpf3bcG4wW15fe4m3py/CTjxm3lUlPD01T1pl57ETf9ZxKY9BV7eyaUqE7zcv+kDdGueyovXZZb1CZSVKzk+YTw4shuf3XYGIsKZHcpXUnQ/XGx0FFPG9UfEFcfg09JZueMAuw8e5YwODSkqUeat31O+by1ZvN4YUwPFx0Qzsldz3vnNAGbcPphr+7di5ppdjJo4j3OfmsWr325g/6FjQT1meR9B1crXiYsmugrNVv83rBNDOqbz5w9XMC93j9cydRNieen6TMA1IuenI94/m/sEL1X1mhRLE1plF2HPxJccH1O2T6u0RNqW9gN5vE235qnEx0QhIgxq3xCAOTm76du6PnVio5m9Ls/uNWSMCa4Ojevy54u6Mv/ec3n8ih6k1Inlwf+tJOvhL/jDO0tYtHlvUGoJ5d+Qg/stNjpKeHZ0b1qnJfLbNxayxRmm6nmhbp2WxIRr+pC7u4Db3/6h4slt4upnuee9Zbwwa/0JL2sVmrgAiitJfGd2dNUKCotOnHRWOmKqW/NU6iXGMnvdbuJjounftgGz1528eSvYLBEYE0HqxEVzZWZL3r9pIB/fOogr+rbgs+U7uOyf3zHi2W+ZPG9Thd+kq8KXpiFfpSTE8vKYfhSXKB8t2V5huYHtG3L/BZ35YtUunpyx5oTXS1NDdJRwqLCYx6evYeaaXceVqernKJ2cVlHN4czTXIng+w353uMQVxwD2zd01QJUOaNDOrm7C8rmZIRCUBKBiAwTkTUikiMiJ6xHLCLxIvK28/p8Eclwtp8nIgtFZJnz8+xgxGOMqVzXZqk8dGl35t93Lg9d2g0B7v9gOac//CWPfLrar2ajsrb1avqK2aZhEhOu7VNpuTE/y2BUv5ZM+Ho9ny7bcfyLzjdxEeHRy3vQqUkKv5/yAzv2l194q9LpXVou+iTJon/bNAB2ebtduZZPUDujfUN2HjhKzq6DDD7N1VT0zbq8Sj5l8AT83yUi0cAEYDjQBRgtIl08io0F9qpqe+Bp4FFn+27gIlXtDowBJgcajzHGN8nxMVx7ems+vnUQH9w8kHM7N+bFb9ZzxmNfMeHrHA4VVv2uqqrV0zTk7owO6fRv61o/um6C9xHwIsKDI7vRs0Uqf/xgOXsLCstjpPwbfJ24aF64tg/Hiku44+0lZfG7z4c4mRI9+WdNiI3m3hGdmDw264TXXOsiuB73aFEPgLU7D9IuPZmGyfHsC3L/zckEI29nATmqmquqhcAUYKRHmZHAJOfxVOAcERFVXayqpXW8FUAdEfF+UxJjTLUSEXq1rMezo3vzya1nkNWmAY9PX8Pgx2by+tyNXtu5PVVn05C7v13SHeC4SWae4mKieOTyHuw/fIyHPllVtt1zpm9GwyTGD+/E3Nw9fO00EZ1sPoS7kirct2jc4Hac4TaCyF35/AKn89pZNKdXy3rlZWrJegTNgS1uz7c627yWUdUiYD+Q5lHmcmCRqnod7Cwi40QkW0Sy8/JCV2UyJhJ1bprCy2P68d/fDqBtehJ/+nAF5zw1k/cWbaX4JHcXrWqTSrBU1sHduWkK4wa3ZerCrcxx5hd4Gz56db+WtEtP4v4PVlBwtKjsM1b2ObSSGkFl+5YSj229Wqb69Z7+qhGdxSLSFVdz0W8qKqOqE1U1U1Uz09O9Z1djTHD1bd2At8f159839CMlIZY73lnCiGdmM2PlzoCGXQbKl7e/9ZwOZKQlcu/7yzhyrNi1v0eZ+JhoHrm8B9v2HeapGWvd+joqqRGUqN9Jzz0hlf4sPaM93WsEtWTN4m1AS7fnLZxtXsuISAyQCuxxnrcA3geuV9UTx3EZY8JKRBjSsREf3TKI50b3prC4hF+/ns3lL3zH3PXHj+mv6rDLUEqIjebhS7uzac8hnvlyXYUzdvtlNODn/Vvx2pwNLN68D6j42/6hwiLeX7yVY8UlAdQI3G91UT6vAcr7DEIlGIlgAdBBRNqISBwwCpjmUWYars5ggCuAr1RVRaQe8DEwXlXnBCEWY0w1iYoSLurZjM9vH8zfL+vO9n1HGP3SPK57ZT7Ltu4HTpyRW118ffeftW/IlX1bMPGb3BNu+eDu7mGdaFQ3gbunLgUqTmiz1+3m9reXMGnuJr/b8E82wzm1Tqx/b+qngBOB0+Z/CzAdWAW8o6orRORBEbnYKfYKkCYiOcAdQOkQ01uA9sCfROQH55/3+/caY2qE2OgoRme1YuZdQ7hvRGeWb9vPRc9/y81vLmLl9gNA9ScCf9w7ojP1nAtsSQXVgpSEWP56STcOO01IFX0O9xXoDhzxb63q0gll4D0h9GwRun6CoNx9VFU/AT7x2PYnt8dHgCu97Pc34G/BiMEYE1oJsdH8enBbRmW15KXZG3h5di6HCp02+JB1Fle9bP2kOP50URd+P+UH9h+ueGjmeV0a07NlPZZs2Vfh5wjarZqcA3h2FoOrf2bJ1v0kxFZ/V67dhtoYE5C6CbHccd5pjBnQms9X7uRYcQkJsb4tOekrfzujL+7ZjKPHSujYpO5Jy71+QxYvf5vLQOc+QJ5KaxT/uLpX2dBPX5T2BZTXCMqHj5YaldWSV+dsCMmiQ5YIjDFBkZYcz+isViE9pq/LOYoIV/VrWWm51MRY/nB+x0rL9WiRStv0ZJ9igPJv/mWjhjy2A1W6GV+w1Ijho8YY44tw90BUdeZxZUpHDZUNH/UytyAULBEYY2qtUC7e4u24gcwhcHeyuQKh+IyWCIwxtU64ByWVTZzz83t7WR+Bx+7u1/xQLEhTyhKBMabWCl+NwLcFeE7Y3/npOXzU22xtX/tB/GGJwBhT64Titgsn49nZG6z9j6sR+PfWfrFEYIyptcJUISj7lu737SU4vrO57G28fCDrIzDGGC9qTB9BgDWCUt7mEYTyM1oiMMYYH1V1vYLKnGwegeexqpMlAmNMrVXZegTVpcRjZrCvtAqjjkLZD2KJwBhjfFQ26idYNQKP9Qi8Has6WSIwxtRaYessDnj46PGRS9l6BG7brI/AGGMqFu7O4kD7CMqbhpyfZTUCL/MIQtD8ZYnAGFN7halKEHAfgfOzKp3FoWCJwBhT64Ty9gveBF4jKE0kx2cC6yMwxhgfheL2C96UeLbt+OjEGsGJb2R9BMYYcxLhvg11Kb/vPlpR/vI6kcC/Y/giKIlARIaJyBoRyRGR8V5ejxeRt53X54tIhttr9zjb14jI0GDEY4wx1Sng9QjKZiZ7rEfgVqRW3X1URKKBCcBwoAswWkS6eBQbC+xV1fbA08Cjzr5dgFFAV2AY8E/n/YwxplK1dz0Cj6UqPd7XW9nqFIwaQRaQo6q5qloITAFGepQZCUxyHk8FzhFXuhsJTFHVo6q6Achx3s8YYyoUzr7iL1buZMX2A644/F6PwPWzfEJZ6TwCt3sN+R+iz4KRCJoDW9yeb3W2eS2jqkXAfiCtivsCICLjRCRbRLLz8vKCELYxprZTIL+gMKTHvHPqEqYt2Q5UPSEt27qfF2et52hRsdfXS99mj5fPYvcacqOqE1U1U1Uz09PTwx2OMSZIzntqFhnjP2bBxvwq71P6Tfye95Zx1Ytzqys0r44VlXBWx3QmXNOH2OjKL6Gqyl1Tl/D3T1dz5FgJANmb9gKw//AxoDyhPPdVTtl+tW3U0DagpdvzFs42r2VEJAZIBfZUcV9jzClsfd5BALbkH/J53w6NktlbUMheH2sF7y/eyhvzNvl8PIBjxUqnpilc0KMp0VXoJPg2Zzerf/wJgLyfjrB4817W7nQ9P3ikqNL9a8s8ggVABxFpIyJxuDp/p3mUmQaMcR5fAXylrsawacAoZ1RRG6AD8H0QYjLG1BKl7eNVuaiW7+P6ec3prfj+vnOpnxTn0zFvf3sJf/xguU/7gOvbfWFxSZVqAqUOF5Y3B322/Ecu/ed3HDjiqgkUlXhMLHNTq+4+6rT53wJMB1YB76jqChF5UEQudoq9AqSJSA5wBzDe2XcF8A6wEvgMuFlVvTeiGWNOaf7M0o2LifIpgQAcKy4pe3zVi3OPu1BXvq/rwh0XXfVjusdXWOQ6drTnymQnebta00egqp+o6mmq2k5VH3K2/UlVpzmPj6jqlaraXlWzVDXXbd+HnP06quqnwYjHGFN7lF4DfaoRBHC8I8dcF/7OTVP4fkM+2/YdrvK+pUnkic/Xkus0aVXGPcEVOomk9LNGeSYEN6XbilW5bcpilm7dV+U4fVVrOouNMac2X7/Zg+vb8p3vLvGpvb+0w/a0xskAfiUCX0S5fa7S/csSgLP9ZJ/833M28MEP27niherrFI+ptnc2xpgqKP3mG+1L05Bb0S9W7SQprurzUAuOujpo26U7iWBv1RNBoVsiiImq2vdo989VmghKk57nPAJv1ucVAPDkVT2rHKevLBEYY8LK1SmqftUIAA4VFpPgQyJY/eMBRODsTo0Y0jGdNg2TqrxvaRs/QEwV+wnc88X3G1xDZE9oGvKyn/u2mXcOoWWDxCrH6StrGjLG1AhRfiSC4hKlsKiExNiqf6cd1q0pc/7vbLo1T6VHi3rUTYit8r6lncUAMVWM171GUDqM9Oent2ZY1yaMG9y2wv0aJsfzwEXld+vxN1FWhdUIjDHh5Vzfqnphde3iKnvIGfGT6EONAKBZvTo+lS/l3kdQ1Quzt5pDamIs/7qub9lzby1DUVFCvUTXsNiSah46ZDUCY0yN4M/w0YTYKN4e158RPZpWQ0QnOq5pyEsfwYrt+8kY/zHZx82SrvxzVTRn4GSL2geTJQJjTFhde3orwL8JZTFRwult02ju5zd8Xx1XI/DyTX9erisB/G/pjrJtVVlzuLIcWN1zCSwRGGPCakjHRgD4MFm3zP0frvBp+Gegjq8RnHj1Lh29VDoyCeCt78vvqzl2UBv6ZdQ/Yb+KLvTltSRrGjLGnMI6N6nLs6N706ZhcpX3cb8E7z90LPhBVcC9s9hbDSYp3tXtembH8htj/nSkPL6r+7Xk3Rt/dsJ+FfUBlOaBkmquEVhnsTEmrBqlJHBxz2Y+7ePePn/gSCgTgatG8McLOnu931DpBb1Tk5Sybe59HxVd8Cvq7C7tO7CmIWOM8ZCaGMtHtwxC5PhmmOpWOqFsQLs07687TUfxMeWXVvc+5ZIKJiaLCAPbp5HZur7HdtfP6l6lzGoExphaqWuzFNY/NMKv+Qf+Kq0RxFXQodG5aQq/O7s9qYnlcxPcRwSdbBjopBuyTphhXPrRqrtGYInAGFMrhTIBlCouUUSo8DbU3Zqn0q156nHb3K/tJ7ugx3h9T9fO1T2PwBKBMcZU0chezX3uz6hKH0FFxGoExhhT85zsBnHey5c/jo/1rVvWn0l2/rDOYmOMqUalF/Mnr+x53GiiqihNA3aLCWOMqcXK5wL4fjEPVdOQJQJjjKlGpTUCf67lteJeQyLSQERmiMg65+eJc6dd5cY4ZdaJyBhnW6KIfCwiq0VkhYg8EkgsxhhTE3V3RhG1rO/7egKl/RFVuV9RIAKtEYwHvlTVDsCXzvPjiEgD4M/A6UAW8Ge3hPGEqnYCegMDRWR4gPEYY0yNcv2A1nz6+zMqnIR2MuV9BMGNyVOgiWAkMMl5PAm4xEuZocAMVc1X1b3ADGCYqh5S1a8BVLUQWAS0CDAeY4ypUUSEzk196yR239elZtcIGqtq6f1WfwQaeynTHNji9nyrs62MiNQDLsJVq/BKRMaJSLaIZOfl5QUUtDHG1AZlaSDc8whE5AugiZeX7nN/oqoqIj6HKyIxwFvAs6qaW1E5VZ0ITATIzMys7r4TY4wJu0A6mn1RaSJQ1XMrek1EdopIU1XdISJNgV1eim0Dhrg9bwHMdHs+EVinqv+oSsDGGBMpyoaeVnMnQaBNQ9OAMc7jMcCHXspMB84XkfpOJ/H5zjZE5G9AKnBbgHEYY8wpJzQ9BIEngkeA80RkHXCu8xwRyRSRlwFUNR/4K7DA+fegquaLSAtczUtdgEUi8oOI/CrAeIwx5tRRG+41pKp7gHO8bM8GfuX2/FXgVY8yW6nKqs7GGBOhyvsIanbTkDHGmGoSqlFDlgiMMaaGKp9ZXL3HsURgjDE1VKiWqrREYIwxNVSolqq0RGCMMTVU/cQ4RnRvQlpyXLUex1YoM8aYGqptejL/vLZvtR/HagTGGBPhLBEYY0yEs0RgjDERzhKBMcZEOEsExhgT4SwRGGNMhLNEYIwxEc4SgTHGRDjR6p67XA1EJA/Y5OfuDYHdQQznVGPnp3J2jk7Ozk/lwnWOWqtquufGWpkIAiEi2aqaGe44aio7P5Wzc3Rydn4qV9POkTUNGWNMhLNEYIwxES4SE8HEcAdQw9n5qZydo5Oz81O5GnWOIq6PwBhjzPEisUZgjDHGjSUCY4yJcBGTCERkmIisEZEcERkf7njCSUQ2isgyEflBRLKdbQ1EZIaIrHN+1ne2i4g865y3pSLSJ7zRB5+IvCoiu0Rkuds2n8+HiIxxyq8TkTHh+CzVpYJz9ICIbHN+j34QkRFur93jnKM1IjLUbfsp+XcoIi1F5GsRWSkiK0Tk98722vF7pKqn/D8gGlgPtAXigCVAl3DHFcbzsRFo6LHtMWC883g88KjzeATwKSBAf2B+uOOvhvMxGOgDLPf3fAANgFznZ33ncf1wf7ZqPkcPAHd6KdvF+RuLB9o4f3vRp/LfIdAU6OM8rgusdc5Drfg9ipQaQRaQo6q5qloITAFGhjmmmmYkMMl5PAm4xG376+oyD6gnIk3DEF+1UdVvgHyPzb6ej6HADFXNV9W9wAxgWLUHHyIVnKOKjASmqOpRVd0A5OD6Gzxl/w5VdYeqLnIe/wSsAppTS36PIiURNAe2uD3f6myLVAp8LiILRWScs62xqu5wHv8INHYeR+q58/V8ROp5usVp2ni1tNmDCD9HIpIB9AbmU0t+jyIlEZjjDVLVPsBw4GYRGez+orrqqDau2GHno0IvAO2AXsAO4MmwRlMDiEgy8F/gNlU94P5aTf49ipREsA1o6fa8hbMtIqnqNufnLuB9XFX2naVNPs7PXU7xSD13vp6PiDtPqrpTVYtVtQR4CdfvEUToORKRWFxJ4E1Vfc/ZXCt+jyIlESwAOohIGxGJA0YB08IcU1iISJKI1C19DJwPLMd1PkpHKIwBPnQeTwOud0Y59Af2u1V1T2W+no/pwPkiUt9pIjnf2XbK8ugruhTX7xG4ztEoEYkXkTZAB+B7TuG/QxER4BVglao+5fZS7fg9Cndve6j+4eqlX4tr1MJ94Y4njOehLa7RGkuAFaXnAkgDvgTWAV8ADZztAkxwztsyIDPcn6EazslbuJo2juFqkx3rz/kAfomrYzQHuCHcnysE52iycw6W4rqwNXUrf59zjtYAw922n5J/h8AgXM0+S4EfnH8jasvvkd1iwhhjIlykNA0ZY4ypgCUCY4yJcJYIjDEmwlkiMMaYCGeJwBhjIpwlAmOMiXCWCIwxJsL9P7XEyKJjZ7ZCAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 1, 251) (1650, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 2s 26ms/step - loss: 5132.1611 - val_loss: 3331.8298\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4982.4907 - val_loss: 3261.5015\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4896.5322 - val_loss: 3208.9041\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4814.0615 - val_loss: 3157.1685\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4732.7046 - val_loss: 3106.2656\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4652.4414 - val_loss: 3056.1648\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4573.2432 - val_loss: 3006.8442\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4495.0850 - val_loss: 2958.2864\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4417.9512 - val_loss: 2910.3264\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4335.1880 - val_loss: 2857.1401\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 4253.8174 - val_loss: 2807.7080\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4175.1504 - val_loss: 2759.6455\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4098.2778 - val_loss: 2712.7136\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4022.8916 - val_loss: 2666.7678\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3948.8179 - val_loss: 2621.7249\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3875.9539 - val_loss: 2577.5342\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3804.2349 - val_loss: 2534.1592\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3733.6147 - val_loss: 2491.5737\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3664.0576 - val_loss: 2449.7566\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3595.5349 - val_loss: 2408.6895\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3528.0266 - val_loss: 2368.3579\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3461.5081 - val_loss: 2328.7488\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3395.9651 - val_loss: 2289.8486\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3331.3804 - val_loss: 2251.6479\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3267.7397 - val_loss: 2214.1355\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3205.0303 - val_loss: 2177.3018\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3143.2385 - val_loss: 2141.1375\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3082.3528 - val_loss: 2105.6335\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3022.3623 - val_loss: 2070.7825\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2963.2551 - val_loss: 2036.5748\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2905.0215 - val_loss: 2003.0031\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2847.6509 - val_loss: 1970.0591\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2791.1340 - val_loss: 1937.7358\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2735.4604 - val_loss: 1906.0254\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2680.6211 - val_loss: 1874.9213\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2626.6069 - val_loss: 1844.4155\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2573.4084 - val_loss: 1814.5013\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2521.0173 - val_loss: 1785.1716\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2469.4253 - val_loss: 1756.4200\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2418.6221 - val_loss: 1728.2390\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2368.6008 - val_loss: 1700.6227\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2319.3525 - val_loss: 1673.5645\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2270.8687 - val_loss: 1647.0566\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2223.1418 - val_loss: 1621.0944\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2176.1643 - val_loss: 1595.6700\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2129.9265 - val_loss: 1570.7784\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2084.4226 - val_loss: 1546.4120\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2039.6436 - val_loss: 1522.5659\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1995.5817 - val_loss: 1499.2330\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1952.2297 - val_loss: 1476.4077\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1909.5807 - val_loss: 1454.0841\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1867.6263 - val_loss: 1432.2552\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1826.3593 - val_loss: 1410.9164\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1785.7729 - val_loss: 1390.0605\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1745.8591 - val_loss: 1369.6830\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1706.6112 - val_loss: 1349.7766\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1668.0212 - val_loss: 1330.3370\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1630.0834 - val_loss: 1311.3574\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1592.7896 - val_loss: 1292.8322\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1556.1324 - val_loss: 1274.7557\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1520.1062 - val_loss: 1257.1227\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1484.7036 - val_loss: 1239.9276\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1449.9176 - val_loss: 1223.1641\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1415.7413 - val_loss: 1206.8271\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1382.1681 - val_loss: 1190.9113\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1349.1907 - val_loss: 1175.4109\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1316.8032 - val_loss: 1160.3204\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1284.9989 - val_loss: 1145.6346\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1253.7712 - val_loss: 1131.3481\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1223.1130 - val_loss: 1117.4554\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1193.0186 - val_loss: 1103.9512\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1163.4807 - val_loss: 1090.8302\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1134.4933 - val_loss: 1078.0869\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1106.0498 - val_loss: 1065.7163\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1078.1439 - val_loss: 1053.7128\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1050.7695 - val_loss: 1042.0714\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1023.9194 - val_loss: 1030.7866\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 997.5881 - val_loss: 1019.8540\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 971.7694 - val_loss: 1009.2674\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 946.4569 - val_loss: 999.0225\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 921.6445 - val_loss: 989.1138\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 897.3259 - val_loss: 979.5364\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 873.4954 - val_loss: 970.2850\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 850.1464 - val_loss: 961.3546\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 827.2732 - val_loss: 952.7401\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 804.8696 - val_loss: 944.4368\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 782.9297 - val_loss: 936.4392\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 761.4474 - val_loss: 928.7429\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 740.4167 - val_loss: 921.3422\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 719.8318 - val_loss: 914.2330\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 699.6868 - val_loss: 907.4097\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 679.9758 - val_loss: 900.8680\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 660.6932 - val_loss: 894.6027\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 641.8328 - val_loss: 888.6085\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 623.3891 - val_loss: 882.8813\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 605.3564 - val_loss: 877.4159\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 587.7286 - val_loss: 872.2076\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 570.5002 - val_loss: 867.2516\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 553.6655 - val_loss: 862.5430\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 537.2191 - val_loss: 858.0771\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 521.1549 - val_loss: 853.8494\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 505.4677 - val_loss: 849.8550\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 490.1518 - val_loss: 846.0892\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 475.2016 - val_loss: 842.5472\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 460.6116 - val_loss: 839.2245\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 446.3764 - val_loss: 836.1166\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 432.4903 - val_loss: 833.2188\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 418.9481 - val_loss: 830.5263\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 405.7441 - val_loss: 828.0347\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 392.8730 - val_loss: 825.7394\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 380.3297 - val_loss: 823.6360\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 368.1082 - val_loss: 821.7197\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 356.2039 - val_loss: 819.9864\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 344.6112 - val_loss: 818.4313\n",
      "Epoch 115/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 333.3247 - val_loss: 817.0503\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 322.3392 - val_loss: 815.8386\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 311.6497 - val_loss: 814.7921\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 301.2509 - val_loss: 813.9062\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 291.1376 - val_loss: 813.1770\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 281.3048 - val_loss: 812.5998\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 271.7472 - val_loss: 812.1703\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 262.4601 - val_loss: 811.8846\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 253.4380 - val_loss: 811.7379\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 244.6761 - val_loss: 811.7265\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 236.1695 - val_loss: 811.8460\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 227.9131 - val_loss: 812.0924\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 219.9021 - val_loss: 812.4615\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 212.1317 - val_loss: 812.9492\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 204.5968 - val_loss: 813.5515\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 197.2928 - val_loss: 814.2644\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 190.2150 - val_loss: 815.0839\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 183.3585 - val_loss: 816.0060\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 176.7187 - val_loss: 817.0269\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 170.2908 - val_loss: 818.1429\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 164.0702 - val_loss: 819.3498\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 158.0523 - val_loss: 820.6440\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 152.2327 - val_loss: 822.0219\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 146.6068 - val_loss: 823.4796\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 141.1702 - val_loss: 825.0134\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 135.9184 - val_loss: 826.6198\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 130.8472 - val_loss: 828.2953\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 125.9520 - val_loss: 830.0361\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 121.2286 - val_loss: 831.8390\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 116.6728 - val_loss: 833.7006\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 112.2802 - val_loss: 835.6171\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 108.0470 - val_loss: 837.5857\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 103.9688 - val_loss: 839.6028\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 100.0415 - val_loss: 841.6652\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 96.2614 - val_loss: 843.7696\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 92.6243 - val_loss: 845.9131\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 89.1264 - val_loss: 848.0925\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 85.7638 - val_loss: 850.3050\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 82.5325 - val_loss: 852.5474\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 79.4290 - val_loss: 854.8170\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 76.4496 - val_loss: 857.1106\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 73.5906 - val_loss: 859.4258\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 70.8483 - val_loss: 861.7596\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 68.2194 - val_loss: 864.1097\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 65.7002 - val_loss: 866.4730\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 63.2874 - val_loss: 868.8474\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 60.9775 - val_loss: 871.2299\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 58.7674 - val_loss: 873.6188\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 56.6538 - val_loss: 876.0112\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 54.6335 - val_loss: 878.4051\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 52.7032 - val_loss: 880.7981\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 50.8600 - val_loss: 883.1882\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 49.1010 - val_loss: 885.5728\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 47.4231 - val_loss: 887.9507\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 45.8234 - val_loss: 890.3199\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 44.2989 - val_loss: 892.6779\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42.8473 - val_loss: 895.0231\n",
      "Epoch 172/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 41.4656 - val_loss: 897.3541\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 40.1512 - val_loss: 899.6689\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 38.9015 - val_loss: 901.9658\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 37.7142 - val_loss: 904.2437\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 36.5865 - val_loss: 906.5007\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 35.5164 - val_loss: 908.7356\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 34.5013 - val_loss: 910.9470\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 33.5391 - val_loss: 913.1332\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 32.6275 - val_loss: 915.2939\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 31.7644 - val_loss: 917.4277\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 30.9476 - val_loss: 919.5328\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 30.1753 - val_loss: 921.6091\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.4453 - val_loss: 923.6554\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 28.7559 - val_loss: 925.6707\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 28.1052 - val_loss: 927.6542\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 27.4913 - val_loss: 929.6055\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 26.9126 - val_loss: 931.5233\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 26.3676 - val_loss: 933.4072\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 25.8544 - val_loss: 935.2568\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 25.3716 - val_loss: 937.0716\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 24.9176 - val_loss: 938.8513\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 24.4911 - val_loss: 940.5952\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 24.0906 - val_loss: 942.3029\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.7148 - val_loss: 943.9747\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 23.3624 - val_loss: 945.6097\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 23.0322 - val_loss: 947.2081\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 22.7230 - val_loss: 948.7698\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 22.4336 - val_loss: 950.2945\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 22.1630 - val_loss: 951.7828\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 21.9101 - val_loss: 953.2336\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 21.6739 - val_loss: 954.6481\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 21.4536 - val_loss: 956.0259\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 21.2480 - val_loss: 957.3671\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 21.0565 - val_loss: 958.6721\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.8781 - val_loss: 959.9410\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.7121 - val_loss: 961.1741\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.5576 - val_loss: 962.3716\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.4142 - val_loss: 963.5342\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.2809 - val_loss: 964.6613\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.1573 - val_loss: 965.7543\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 20.0426 - val_loss: 966.8135\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.9363 - val_loss: 967.8393\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 19.8379 - val_loss: 968.8321\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.7467 - val_loss: 969.7921\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.6625 - val_loss: 970.7199\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.5846 - val_loss: 971.6166\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.5126 - val_loss: 972.4819\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.4462 - val_loss: 973.3173\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 19.3849 - val_loss: 974.1224\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.3284 - val_loss: 974.8987\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.2764 - val_loss: 975.6461\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.2285 - val_loss: 976.3657\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.1844 - val_loss: 977.0580\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 19.1439 - val_loss: 977.7233\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 19.1067 - val_loss: 978.3627\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 19.0724 - val_loss: 978.9767\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 19.0410 - val_loss: 979.5663\n",
      "Epoch 229/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 19.0122 - val_loss: 980.1313\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 18.9858 - val_loss: 980.6735\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.9616 - val_loss: 981.1928\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.9394 - val_loss: 981.6895\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.9192 - val_loss: 982.1643\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.9006 - val_loss: 982.6188\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8837 - val_loss: 983.0530\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.8682 - val_loss: 983.4677\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8541 - val_loss: 983.8636\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8411 - val_loss: 984.2404\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8294 - val_loss: 984.6005\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8186 - val_loss: 984.9429\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8089 - val_loss: 985.2692\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8000 - val_loss: 985.5793\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7919 - val_loss: 985.8745\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7845 - val_loss: 986.1545\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7779 - val_loss: 986.4205\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7718 - val_loss: 986.6729\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7663 - val_loss: 986.9122\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7613 - val_loss: 987.1393\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7568 - val_loss: 987.3538\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7528 - val_loss: 987.5572\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7491 - val_loss: 987.7496\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7458 - val_loss: 987.9315\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7428 - val_loss: 988.1030\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7401 - val_loss: 988.2646\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7377 - val_loss: 988.4174\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 18.7356 - val_loss: 988.5612\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7337 - val_loss: 988.6966\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7320 - val_loss: 988.8239\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7305 - val_loss: 988.9438\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 18.7292 - val_loss: 989.0560\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7280 - val_loss: 989.1617\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7270 - val_loss: 989.2605\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7262 - val_loss: 989.3529\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7255 - val_loss: 989.4395\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7249 - val_loss: 989.5212\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7243 - val_loss: 989.5970\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7240 - val_loss: 989.6681\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7237 - val_loss: 989.7347\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7234 - val_loss: 989.7962\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7234 - val_loss: 989.8538\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7233 - val_loss: 989.9070\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7233 - val_loss: 989.9569\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7233 - val_loss: 990.0031\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7234 - val_loss: 990.0459\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7236 - val_loss: 990.0856\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7238 - val_loss: 990.1221\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7241 - val_loss: 990.1561\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7244 - val_loss: 990.1876\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7247 - val_loss: 990.2162\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 18.7251 - val_loss: 990.2430\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7256 - val_loss: 990.2678\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7260 - val_loss: 990.2902\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7265 - val_loss: 990.3108\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7270 - val_loss: 990.3295\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 18.7275 - val_loss: 990.3467\n",
      "Epoch 286/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7281 - val_loss: 990.3623\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7286 - val_loss: 990.3766\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7292 - val_loss: 990.3895\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7298 - val_loss: 990.4012\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7304 - val_loss: 990.4116\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7311 - val_loss: 990.4210\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7317 - val_loss: 990.4296\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7324 - val_loss: 990.4370\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7331 - val_loss: 990.4437\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7337 - val_loss: 990.4493\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7345 - val_loss: 990.4545\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7351 - val_loss: 990.4590\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7358 - val_loss: 990.4627\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7365 - val_loss: 990.4659\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7373 - val_loss: 990.4686\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 18.7381 - val_loss: 990.4715\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7387 - val_loss: 990.4732\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7395 - val_loss: 990.4746\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7402 - val_loss: 990.4753\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7410 - val_loss: 990.4760\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7418 - val_loss: 990.4767\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7425 - val_loss: 990.4767\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7432 - val_loss: 990.4768\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7440 - val_loss: 990.4764\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7447 - val_loss: 990.4758\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7455 - val_loss: 990.4750\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7462 - val_loss: 990.4738\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7470 - val_loss: 990.4727\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7477 - val_loss: 990.4715\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7484 - val_loss: 990.4694\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7492 - val_loss: 990.4678\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7500 - val_loss: 990.4660\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7507 - val_loss: 990.4641\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7514 - val_loss: 990.4623\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7522 - val_loss: 990.4600\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7529 - val_loss: 990.4581\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7537 - val_loss: 990.4559\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7544 - val_loss: 990.4538\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7551 - val_loss: 990.4515\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7558 - val_loss: 990.4492\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 18.7565 - val_loss: 990.4467\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 18.7573 - val_loss: 990.4443\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7580 - val_loss: 990.4417\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7587 - val_loss: 990.4394\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7594 - val_loss: 990.4370\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7601 - val_loss: 990.4346\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7607 - val_loss: 990.4315\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7615 - val_loss: 990.4294\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7621 - val_loss: 990.4267\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7628 - val_loss: 990.4241\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7635 - val_loss: 990.4222\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7642 - val_loss: 990.4195\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7648 - val_loss: 990.4171\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7655 - val_loss: 990.4147\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7662 - val_loss: 990.4127\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7668 - val_loss: 990.4100\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7674 - val_loss: 990.4077\n",
      "Epoch 343/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7681 - val_loss: 990.4052\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7687 - val_loss: 990.4028\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7694 - val_loss: 990.4009\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7699 - val_loss: 990.3985\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7706 - val_loss: 990.3961\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 18.7712 - val_loss: 990.3939\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7718 - val_loss: 990.3916\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7724 - val_loss: 990.3893\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7729 - val_loss: 990.3869\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7735 - val_loss: 990.3848\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7741 - val_loss: 990.3828\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7747 - val_loss: 990.3807\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7752 - val_loss: 990.3782\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7758 - val_loss: 990.3760\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7763 - val_loss: 990.3740\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7769 - val_loss: 990.3718\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7774 - val_loss: 990.3697\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7780 - val_loss: 990.3673\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7785 - val_loss: 990.3657\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7790 - val_loss: 990.3635\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7796 - val_loss: 990.3619\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7800 - val_loss: 990.3597\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7805 - val_loss: 990.3576\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7810 - val_loss: 990.3554\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7815 - val_loss: 990.3534\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 18.7820 - val_loss: 990.3514\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7825 - val_loss: 990.3496\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7829 - val_loss: 990.3481\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7834 - val_loss: 990.3460\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7839 - val_loss: 990.3441\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7843 - val_loss: 990.3425\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7848 - val_loss: 990.3405\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7852 - val_loss: 990.3389\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7857 - val_loss: 990.3371\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7861 - val_loss: 990.3357\n",
      "Epoch 378/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7865 - val_loss: 990.3339\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7869 - val_loss: 990.3320\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7874 - val_loss: 990.3307\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7878 - val_loss: 990.3290\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7881 - val_loss: 990.3276\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7886 - val_loss: 990.3259\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7889 - val_loss: 990.3245\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7893 - val_loss: 990.3228\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7897 - val_loss: 990.3217\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7900 - val_loss: 990.3203\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7905 - val_loss: 990.3190\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7908 - val_loss: 990.3175\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7911 - val_loss: 990.3160\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 18.7915 - val_loss: 990.3145\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7919 - val_loss: 990.3132\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7922 - val_loss: 990.3118\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.7925 - val_loss: 990.3106\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7928 - val_loss: 990.3093\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7932 - val_loss: 990.3079\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7935 - val_loss: 990.3068\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7938 - val_loss: 990.3055\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7941 - val_loss: 990.3046\n",
      "Epoch 400/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7944 - val_loss: 990.3036\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7947 - val_loss: 990.3021\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7950 - val_loss: 990.3010\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7953 - val_loss: 990.3002\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7956 - val_loss: 990.2991\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7958 - val_loss: 990.2979\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7961 - val_loss: 990.2969\n",
      "Epoch 407/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7964 - val_loss: 990.2959\n",
      "Epoch 408/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7966 - val_loss: 990.2947\n",
      "Epoch 409/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7969 - val_loss: 990.2938\n",
      "Epoch 410/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7972 - val_loss: 990.2927\n",
      "Epoch 411/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 18.7974 - val_loss: 990.2916\n",
      "Epoch 412/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7977 - val_loss: 990.2902\n",
      "Epoch 413/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7980 - val_loss: 990.2897\n",
      "Epoch 414/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7982 - val_loss: 990.2886\n",
      "Epoch 415/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7984 - val_loss: 990.2878\n",
      "Epoch 416/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7987 - val_loss: 990.2870\n",
      "Epoch 417/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7989 - val_loss: 990.2864\n",
      "Epoch 418/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7991 - val_loss: 990.2858\n",
      "Epoch 419/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7993 - val_loss: 990.2847\n",
      "Epoch 420/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7995 - val_loss: 990.2833\n",
      "Epoch 421/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7997 - val_loss: 990.2828\n",
      "Epoch 422/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.7999 - val_loss: 990.2819\n",
      "Epoch 423/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8001 - val_loss: 990.2807\n",
      "Epoch 424/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8004 - val_loss: 990.2804\n",
      "Epoch 425/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8005 - val_loss: 990.2794\n",
      "Epoch 426/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8007 - val_loss: 990.2785\n",
      "Epoch 427/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8009 - val_loss: 990.2783\n",
      "Epoch 428/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8011 - val_loss: 990.2773\n",
      "Epoch 429/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8013 - val_loss: 990.2764\n",
      "Epoch 430/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8015 - val_loss: 990.2756\n",
      "Epoch 431/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8016 - val_loss: 990.2751\n",
      "Epoch 432/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 18.8018 - val_loss: 990.2745\n",
      "Epoch 433/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.8020 - val_loss: 990.2739\n",
      "Epoch 434/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8022 - val_loss: 990.2735\n",
      "Epoch 435/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8023 - val_loss: 990.2723\n",
      "Epoch 436/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8025 - val_loss: 990.2721\n",
      "Epoch 437/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8027 - val_loss: 990.2717\n",
      "Epoch 438/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8028 - val_loss: 990.2710\n",
      "Epoch 439/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8029 - val_loss: 990.2704\n",
      "Epoch 440/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8031 - val_loss: 990.2697\n",
      "Epoch 441/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8033 - val_loss: 990.2691\n",
      "Epoch 442/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8034 - val_loss: 990.2686\n",
      "Epoch 443/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8036 - val_loss: 990.2682\n",
      "Epoch 444/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8037 - val_loss: 990.2676\n",
      "Epoch 445/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8038 - val_loss: 990.2673\n",
      "Epoch 446/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8039 - val_loss: 990.2663\n",
      "Epoch 447/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8041 - val_loss: 990.2655\n",
      "Epoch 448/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8042 - val_loss: 990.2651\n",
      "Epoch 449/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8043 - val_loss: 990.2646\n",
      "Epoch 450/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8044 - val_loss: 990.2641\n",
      "Epoch 451/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8045 - val_loss: 990.2636\n",
      "Epoch 452/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8047 - val_loss: 990.2629\n",
      "Epoch 453/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 18.8049 - val_loss: 990.2628\n",
      "Epoch 454/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 18.8049 - val_loss: 990.2620\n",
      "Epoch 455/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8050 - val_loss: 990.2615\n",
      "Epoch 456/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8051 - val_loss: 990.2613\n",
      "Epoch 457/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8053 - val_loss: 990.2610\n",
      "Epoch 458/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8053 - val_loss: 990.2607\n",
      "Epoch 459/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8055 - val_loss: 990.2607\n",
      "Epoch 460/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8056 - val_loss: 990.2603\n",
      "Epoch 461/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8056 - val_loss: 990.2598\n",
      "Epoch 462/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8058 - val_loss: 990.2591\n",
      "Epoch 463/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8058 - val_loss: 990.2584\n",
      "Epoch 464/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8060 - val_loss: 990.2579\n",
      "Epoch 465/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8061 - val_loss: 990.2579\n",
      "Epoch 466/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8061 - val_loss: 990.2573\n",
      "Epoch 467/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8062 - val_loss: 990.2569\n",
      "Epoch 468/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8063 - val_loss: 990.2565\n",
      "Epoch 469/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8064 - val_loss: 990.2563\n",
      "Epoch 470/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8065 - val_loss: 990.2562\n",
      "Epoch 471/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8066 - val_loss: 990.2559\n",
      "Epoch 472/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 18.8067 - val_loss: 990.2559\n",
      "Epoch 473/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8067 - val_loss: 990.2553\n",
      "Epoch 474/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8068 - val_loss: 990.2548\n",
      "Epoch 475/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8069 - val_loss: 990.2543\n",
      "Epoch 476/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8070 - val_loss: 990.2543\n",
      "Epoch 477/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8071 - val_loss: 990.2543\n",
      "Epoch 478/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8071 - val_loss: 990.2537\n",
      "Epoch 479/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8072 - val_loss: 990.2534\n",
      "Epoch 480/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8072 - val_loss: 990.2531\n",
      "Epoch 481/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8073 - val_loss: 990.2529\n",
      "Epoch 482/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8073 - val_loss: 990.2520\n",
      "Epoch 483/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8075 - val_loss: 990.2523\n",
      "Epoch 484/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8075 - val_loss: 990.2519\n",
      "Epoch 485/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8075 - val_loss: 990.2512\n",
      "Epoch 486/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8077 - val_loss: 990.2514\n",
      "Epoch 487/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8077 - val_loss: 990.2510\n",
      "Epoch 488/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8077 - val_loss: 990.2507\n",
      "Epoch 489/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8078 - val_loss: 990.2505\n",
      "Epoch 490/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8078 - val_loss: 990.2501\n",
      "Epoch 491/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.8079 - val_loss: 990.2496\n",
      "Epoch 492/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 18.8080 - val_loss: 990.2496\n",
      "Epoch 493/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8080 - val_loss: 990.2496\n",
      "Epoch 494/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8081 - val_loss: 990.2495\n",
      "Epoch 495/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8081 - val_loss: 990.2491\n",
      "Epoch 496/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8082 - val_loss: 990.2493\n",
      "Epoch 497/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8082 - val_loss: 990.2493\n",
      "Epoch 498/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8083 - val_loss: 990.2491\n",
      "Epoch 499/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8083 - val_loss: 990.2488\n",
      "Epoch 500/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 18.8083 - val_loss: 990.2482\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 367ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.86044118e+01, 6.85119748e+01, 6.84195378e+01, 6.83271008e+01,\n",
       "        6.82346639e+01, 6.81212185e+01, 6.79951681e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.79321930e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.93570495e+01, 6.93234360e+01, 6.92720121e+01,\n",
       "        6.91795752e+01, 6.90871382e+01, 6.89947012e+01, 6.89022642e+01,\n",
       "        6.88098273e+01, 6.87173903e+01, 6.86249533e+01, 6.85325163e+01,\n",
       "        6.84400794e+01, 6.83476424e+01, 6.82552054e+01, 6.81492297e+01,\n",
       "        6.80231793e+01, 6.78971289e+01, 6.77710784e+01, 6.76450280e+01,\n",
       "        6.75189776e+01, 6.73929272e+01, 6.72668767e+01, 6.71408263e+01,\n",
       "        6.70147759e+01, 6.68887255e+01, 6.67626751e+01, 6.66661998e+01,\n",
       "        0.00000000e+00, 2.91491540e-01, 9.92602700e-02, 7.78855440e-01,\n",
       "        0.00000000e+00, 1.66989040e-01, 0.00000000e+00, 6.83671839e+01,\n",
       "        6.82757470e+01, 6.81772409e+01, 6.80511905e+01, 6.79451401e+01,\n",
       "        6.77890896e+01, 6.76730392e+01, 6.75476988e+01, 6.74209384e+01,\n",
       "        6.72948880e+01, 6.71688375e+01, 6.70427871e+01, 6.69167367e+01,\n",
       "        6.67906863e+01, 6.66811391e+01, 6.98908030e+01, 6.98403828e+01,\n",
       "        6.97899627e+01, 6.97395425e+01, 6.96782446e+01, 6.95774043e+01,\n",
       "        6.94776564e+01, 6.93775724e+01, 6.92309290e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.34659462e+01, 0.00000000e+00, 8.26832712e-01,\n",
       "        9.94954300e-03, 6.24333203e-01, 2.44547352e-01, 0.00000000e+00,\n",
       "        5.88982048e+01, 0.00000000e+00, 0.00000000e+00, 1.35703892e-01,\n",
       "        4.81509626e-01, 0.00000000e+00, 3.07033718e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.97727555e-01, 3.51600379e-01, 2.67281473e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.87531620e-01, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([62.73161765, 62.72461485, 62.71761204, 62.71060924, 62.70360644,\n",
       "       62.69660364, 62.68960084, 62.68259804, 62.67559524, 62.66859244,\n",
       "       62.66158964, 62.65458683, 62.64758403, 62.64058123, 62.63357843,\n",
       "       62.62657563, 62.61957283, 62.61257003, 62.60556723, 62.59856443,\n",
       "       62.59156162, 62.58455882, 62.57755602, 62.57055322, 62.56355042,\n",
       "       62.55654762, 62.54954482, 62.54254202, 62.53553922, 62.52853641,\n",
       "       62.52153361, 62.51453081, 62.50752801, 62.50052521, 62.49266926,\n",
       "       62.48474414, 62.47681902, 62.4688939 , 62.46096878, 62.45304366,\n",
       "       62.44511854, 62.43719341, 62.42926829, 62.42134317, 62.41341805,\n",
       "       62.40549293, 62.39756781, 62.38964269, 62.38171757, 62.37379244,\n",
       "       62.36586732, 62.3579422 , 62.35001708, 62.34209196, 62.33416684,\n",
       "       62.32624172, 62.31831659, 62.31039147, 62.30246635, 62.29454123,\n",
       "       62.28661611, 62.27869099, 62.27076587, 62.26284075, 62.25491562,\n",
       "       62.2469905 , 62.23906538, 62.23114026, 62.22321514, 62.21529002,\n",
       "       62.2073649 , 62.19943978, 62.19151465, 62.18358953, 62.17566441,\n",
       "       62.16773929, 62.15981417, 62.15188905, 62.14396393, 62.13603881,\n",
       "       62.12811368, 62.12018856, 62.11226344, 62.10433832, 62.0964132 ,\n",
       "       62.08848808, 62.08056296, 62.07263784, 62.06471271, 62.05678759,\n",
       "       62.04886247, 62.04093735, 62.03301223, 62.02508711, 62.01716199,\n",
       "       62.00923687, 62.00131174, 61.99338662, 61.9854615 , 61.97753638])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.53060211770588\n",
      "28.23571309081738\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
