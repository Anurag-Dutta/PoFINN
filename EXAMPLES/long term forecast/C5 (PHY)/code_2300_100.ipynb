{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2395    60.424213\n",
       "2396    60.416287\n",
       "2397    60.408362\n",
       "2398    60.400437\n",
       "2399    60.392512\n",
       "Name: C5, Length: 2400, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_2300_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2295     0.000000\n",
       "2296     0.000000\n",
       "2297     0.000000\n",
       "2298     0.000000\n",
       "2299     0.000000\n",
       "Name: C5, Length: 2300, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2300)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1850, 1, 251) (1850, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 3s 26ms/step - loss: 4983.4658 - val_loss: 3048.3250\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4730.0933 - val_loss: 2900.4126\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4604.7812 - val_loss: 2828.6235\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4500.3911 - val_loss: 2766.1660\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4401.8403 - val_loss: 2706.4514\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4306.6343 - val_loss: 2648.8235\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4214.0088 - val_loss: 2592.9412\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4123.5571 - val_loss: 2538.6055\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4034.9321 - val_loss: 2481.1367\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3931.9878 - val_loss: 2422.0850\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3841.4084 - val_loss: 2368.9829\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3753.6648 - val_loss: 2317.8108\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3668.3083 - val_loss: 2268.2666\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3584.9763 - val_loss: 2220.1873\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3503.4702 - val_loss: 2173.4739\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3423.6682 - val_loss: 2128.0596\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3345.4827 - val_loss: 2083.8923\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3268.8501 - val_loss: 2040.9316\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3193.7183 - val_loss: 1999.1218\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3117.4500 - val_loss: 1954.4352\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3038.0793 - val_loss: 1911.5801\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2961.8494 - val_loss: 1870.5547\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2888.0527 - val_loss: 1831.1343\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2816.3230 - val_loss: 1793.1301\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2746.4155 - val_loss: 1756.4277\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2678.1792 - val_loss: 1720.9507\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2611.5120 - val_loss: 1686.6422\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2546.3391 - val_loss: 1653.4581\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2482.6040 - val_loss: 1621.3613\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2420.2559 - val_loss: 1590.3196\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2359.2551 - val_loss: 1560.3054\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2299.5667 - val_loss: 1531.2932\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2241.1580 - val_loss: 1503.2588\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2184.0012 - val_loss: 1476.1808\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2128.0684 - val_loss: 1450.0380\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2073.3364 - val_loss: 1424.8112\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2019.7803 - val_loss: 1400.4814\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1967.3798 - val_loss: 1377.0305\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1916.1128 - val_loss: 1354.4412\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1865.9598 - val_loss: 1332.6963\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1816.9015 - val_loss: 1311.7797\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1768.9191 - val_loss: 1291.6753\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1721.9951 - val_loss: 1272.3668\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1676.1110 - val_loss: 1253.8394\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1631.2504 - val_loss: 1236.0776\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1587.3961 - val_loss: 1219.0671\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1544.5327 - val_loss: 1202.7924\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1502.6432 - val_loss: 1187.2401\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1461.7129 - val_loss: 1172.3955\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1421.7255 - val_loss: 1158.2445\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1382.6663 - val_loss: 1144.7732\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1344.5204 - val_loss: 1131.9686\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1307.2734 - val_loss: 1119.8162\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1270.9100 - val_loss: 1108.3035\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1235.4166 - val_loss: 1097.4167\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1200.7794 - val_loss: 1087.1429\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1166.9839 - val_loss: 1077.4692\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1134.0165 - val_loss: 1068.3828\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1101.8636 - val_loss: 1059.8705\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1070.5122 - val_loss: 1051.9200\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1039.9482 - val_loss: 1044.5190\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1010.1589 - val_loss: 1037.6544\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 981.1317 - val_loss: 1031.3143\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 952.8530 - val_loss: 1025.4865\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 925.3104 - val_loss: 1020.1586\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 898.4910 - val_loss: 1015.3187\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 872.3826 - val_loss: 1010.9547\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 846.9725 - val_loss: 1007.0551\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 822.2485 - val_loss: 1003.6074\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 798.1981 - val_loss: 1000.6006\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 774.8096 - val_loss: 998.0226\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 752.0708 - val_loss: 995.8620\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 729.9697 - val_loss: 994.1072\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 708.4948 - val_loss: 992.7471\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 687.6337 - val_loss: 991.7704\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 667.3756 - val_loss: 991.1657\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 647.7083 - val_loss: 990.9219\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 628.6210 - val_loss: 991.0280\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 610.1019 - val_loss: 991.4730\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 592.1399 - val_loss: 992.2460\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 574.7236 - val_loss: 993.3365\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 557.8423 - val_loss: 994.7333\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 541.4847 - val_loss: 996.4262\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 525.6400 - val_loss: 998.4045\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 510.2977 - val_loss: 1000.6577\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 495.4466 - val_loss: 1003.1758\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 481.0766 - val_loss: 1005.9481\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 467.1770 - val_loss: 1008.9645\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 453.7372 - val_loss: 1012.2155\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 440.7467 - val_loss: 1015.6907\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 428.1958 - val_loss: 1019.3802\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 416.0740 - val_loss: 1023.2742\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 404.3716 - val_loss: 1027.3634\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 393.0780 - val_loss: 1031.6382\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 382.1840 - val_loss: 1036.0889\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 371.6793 - val_loss: 1040.7063\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 361.5547 - val_loss: 1045.4810\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 351.8006 - val_loss: 1050.4044\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 342.4071 - val_loss: 1055.4675\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 333.3653 - val_loss: 1060.6610\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 324.6657 - val_loss: 1065.9766\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 316.2993 - val_loss: 1071.4055\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 308.2572 - val_loss: 1076.9397\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 300.5302 - val_loss: 1082.5699\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 293.1097 - val_loss: 1088.2892\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 285.9868 - val_loss: 1094.0890\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 279.1531 - val_loss: 1099.9609\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 272.6002 - val_loss: 1105.8978\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 266.3196 - val_loss: 1111.8923\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 260.3032 - val_loss: 1117.9363\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 254.5427 - val_loss: 1124.0231\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 249.0304 - val_loss: 1130.1451\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 243.7584 - val_loss: 1136.2957\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 238.7189 - val_loss: 1142.4679\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 233.9043 - val_loss: 1148.6553\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 229.3072 - val_loss: 1154.8516\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 224.9202 - val_loss: 1161.0500\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 220.7362 - val_loss: 1167.2449\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 216.7480 - val_loss: 1173.4299\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 212.9488 - val_loss: 1179.5996\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 209.3318 - val_loss: 1185.7485\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 205.8903 - val_loss: 1191.8708\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 202.6179 - val_loss: 1197.9620\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 199.5080 - val_loss: 1204.0167\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 196.5547 - val_loss: 1210.0299\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 193.7516 - val_loss: 1215.9971\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 191.0930 - val_loss: 1221.9141\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 188.5729 - val_loss: 1227.7767\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 186.1857 - val_loss: 1233.5803\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 183.9260 - val_loss: 1239.3215\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 181.7884 - val_loss: 1244.9966\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 179.7677 - val_loss: 1250.6021\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 177.8586 - val_loss: 1256.1348\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 176.0564 - val_loss: 1261.5912\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 174.3561 - val_loss: 1266.9690\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 172.7533 - val_loss: 1272.2655\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 171.2433 - val_loss: 1277.4775\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 169.8219 - val_loss: 1282.6034\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 168.4847 - val_loss: 1287.6405\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 167.2278 - val_loss: 1292.5873\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 166.0470 - val_loss: 1297.4418\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 164.9388 - val_loss: 1302.2030\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 163.8991 - val_loss: 1306.8685\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 162.9248 - val_loss: 1311.4382\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 162.0123 - val_loss: 1315.9098\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 161.1582 - val_loss: 1320.2831\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 160.3596 - val_loss: 1324.5571\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 159.6134 - val_loss: 1328.7313\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 158.9166 - val_loss: 1332.8055\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 158.2665 - val_loss: 1336.7792\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.6604 - val_loss: 1340.6531\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 157.0956 - val_loss: 1344.4259\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 156.5699 - val_loss: 1348.0983\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 156.0810 - val_loss: 1351.6711\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 155.6265 - val_loss: 1355.1440\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 155.2045 - val_loss: 1358.5186\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.8127 - val_loss: 1361.7935\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.4494 - val_loss: 1364.9717\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 154.1127 - val_loss: 1368.0531\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 153.8010 - val_loss: 1371.0380\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 153.5126 - val_loss: 1373.9288\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 153.2460 - val_loss: 1376.7261\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 152.9996 - val_loss: 1379.4310\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 152.7722 - val_loss: 1382.0454\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 152.5623 - val_loss: 1384.5706\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 152.3689 - val_loss: 1387.0076\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 152.1907 - val_loss: 1389.3578\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 152.0266 - val_loss: 1391.6223\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 151.8758 - val_loss: 1393.8047\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 151.7370 - val_loss: 1395.9048\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 151.6097 - val_loss: 1397.9257\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 151.4927 - val_loss: 1399.8682\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 151.3853 - val_loss: 1401.7350\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 151.2869 - val_loss: 1403.5269\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 151.1968 - val_loss: 1405.2463\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 151.1142 - val_loss: 1406.8956\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 151.0386 - val_loss: 1408.4757\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.9695 - val_loss: 1409.9886\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.9063 - val_loss: 1411.4369\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.8486 - val_loss: 1412.8214\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.7959 - val_loss: 1414.1442\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.7478 - val_loss: 1415.4009\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.7037 - val_loss: 1414.5813\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.9407 - val_loss: 1417.8146\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.6896 - val_loss: 1419.2660\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.6272 - val_loss: 1420.4969\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.5842 - val_loss: 1421.6198\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.5491 - val_loss: 1422.6575\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.5193 - val_loss: 1423.6246\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 150.4931 - val_loss: 1424.5270\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.4702 - val_loss: 1425.3716\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.4500 - val_loss: 1426.1637\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.4319 - val_loss: 1426.9058\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.4159 - val_loss: 1427.6021\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.4017 - val_loss: 1428.2551\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3889 - val_loss: 1428.8684\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3775 - val_loss: 1429.4437\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3673 - val_loss: 1429.9832\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3582 - val_loss: 1430.4902\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3501 - val_loss: 1430.9651\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3428 - val_loss: 1431.4102\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3363 - val_loss: 1431.8274\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3306 - val_loss: 1432.2188\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3253 - val_loss: 1432.5848\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3207 - val_loss: 1432.9274\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3167 - val_loss: 1433.2490\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3129 - val_loss: 1433.5487\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3098 - val_loss: 1433.8284\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3069 - val_loss: 1434.0908\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3044 - val_loss: 1434.3354\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3023 - val_loss: 1434.5637\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3004 - val_loss: 1434.7767\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2987 - val_loss: 1434.9750\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2973 - val_loss: 1435.1594\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2962 - val_loss: 1435.3328\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2950 - val_loss: 1435.4922\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2944 - val_loss: 1435.6412\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 150.2936 - val_loss: 1435.7794\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.2931 - val_loss: 1435.9080\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2928 - val_loss: 1436.0276\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2925 - val_loss: 1436.1383\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.2924 - val_loss: 1436.2411\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2923 - val_loss: 1436.3357\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2924 - val_loss: 1436.4244\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2925 - val_loss: 1436.5065\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2927 - val_loss: 1436.5813\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2931 - val_loss: 1436.6505\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2934 - val_loss: 1436.7156\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2937 - val_loss: 1436.7739\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2942 - val_loss: 1436.8291\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2947 - val_loss: 1436.8790\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.2953 - val_loss: 1436.9259\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2959 - val_loss: 1436.9684\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2965 - val_loss: 1437.0071\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2972 - val_loss: 1437.0427\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2979 - val_loss: 1437.0763\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2985 - val_loss: 1437.1062\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.2993 - val_loss: 1437.1338\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3001 - val_loss: 1437.1593\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3008 - val_loss: 1437.1818\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3016 - val_loss: 1437.2034\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3024 - val_loss: 1437.2224\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3032 - val_loss: 1437.2399\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 150.3040 - val_loss: 1437.2561\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3048 - val_loss: 1437.2701\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3057 - val_loss: 1437.2831\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3065 - val_loss: 1437.2946\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3073 - val_loss: 1437.3060\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3081 - val_loss: 1437.3148\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3090 - val_loss: 1437.3236\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3098 - val_loss: 1437.3313\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3106 - val_loss: 1437.3376\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3115 - val_loss: 1437.3438\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3123 - val_loss: 1437.3489\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3132 - val_loss: 1437.3538\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3140 - val_loss: 1437.3578\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3148 - val_loss: 1437.3619\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3156 - val_loss: 1437.3649\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3165 - val_loss: 1437.3680\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3172 - val_loss: 1437.3696\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3180 - val_loss: 1437.3721\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3188 - val_loss: 1437.3737\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3195 - val_loss: 1437.3750\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3204 - val_loss: 1437.3760\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3212 - val_loss: 1437.3765\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3219 - val_loss: 1437.3768\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3226 - val_loss: 1437.3771\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3234 - val_loss: 1437.3772\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3240 - val_loss: 1437.3771\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3249 - val_loss: 1437.3771\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 150.3255 - val_loss: 1437.3768\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3262 - val_loss: 1437.3763\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3269 - val_loss: 1437.3757\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3275 - val_loss: 1437.3743\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3282 - val_loss: 1437.3733\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3290 - val_loss: 1437.3724\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 150.3296 - val_loss: 1437.3711\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3302 - val_loss: 1437.3701\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3309 - val_loss: 1437.3696\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3315 - val_loss: 1437.3680\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3321 - val_loss: 1437.3671\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3327 - val_loss: 1437.3661\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3333 - val_loss: 1437.3652\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3339 - val_loss: 1437.3647\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3344 - val_loss: 1437.3634\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3350 - val_loss: 1437.3612\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3356 - val_loss: 1437.3601\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3361 - val_loss: 1437.3591\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3367 - val_loss: 1437.3584\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3371 - val_loss: 1437.3574\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3376 - val_loss: 1437.3557\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3381 - val_loss: 1437.3542\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3387 - val_loss: 1437.3530\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3392 - val_loss: 1437.3524\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3396 - val_loss: 1437.3512\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 150.3401 - val_loss: 1437.3496\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3405 - val_loss: 1437.3485\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3410 - val_loss: 1437.3469\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 150.3415 - val_loss: 1437.3463\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3419 - val_loss: 1437.3456\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3423 - val_loss: 1437.3447\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3428 - val_loss: 1437.3430\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3431 - val_loss: 1437.3417\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3435 - val_loss: 1437.3406\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3439 - val_loss: 1437.3397\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3444 - val_loss: 1437.3389\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3447 - val_loss: 1437.3375\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3451 - val_loss: 1437.3363\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3455 - val_loss: 1437.3354\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3459 - val_loss: 1437.3351\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3461 - val_loss: 1437.3345\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3465 - val_loss: 1437.3333\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3468 - val_loss: 1437.3322\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3472 - val_loss: 1437.3311\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3475 - val_loss: 1437.3300\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3479 - val_loss: 1437.3292\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3482 - val_loss: 1437.3292\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3484 - val_loss: 1437.3282\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 150.3487 - val_loss: 1437.3271\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3490 - val_loss: 1437.3270\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3492 - val_loss: 1437.3253\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3495 - val_loss: 1437.3243\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3499 - val_loss: 1437.3240\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3501 - val_loss: 1437.3231\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3504 - val_loss: 1437.3230\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3506 - val_loss: 1437.3221\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3508 - val_loss: 1437.3206\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3511 - val_loss: 1437.3201\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3514 - val_loss: 1437.3198\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3516 - val_loss: 1437.3190\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3518 - val_loss: 1437.3176\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3521 - val_loss: 1437.3173\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3523 - val_loss: 1437.3169\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3525 - val_loss: 1437.3168\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3527 - val_loss: 1437.3164\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3529 - val_loss: 1437.3160\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3531 - val_loss: 1437.3154\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3533 - val_loss: 1437.3142\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3535 - val_loss: 1437.3140\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3537 - val_loss: 1437.3132\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3538 - val_loss: 1437.3118\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 150.3541 - val_loss: 1437.3120\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3542 - val_loss: 1437.3115\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3544 - val_loss: 1437.3107\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3546 - val_loss: 1437.3099\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3548 - val_loss: 1437.3099\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3549 - val_loss: 1437.3094\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3551 - val_loss: 1437.3091\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3552 - val_loss: 1437.3090\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3553 - val_loss: 1437.3088\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3555 - val_loss: 1437.3088\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3556 - val_loss: 1437.3081\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3558 - val_loss: 1437.3074\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3559 - val_loss: 1437.3071\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3560 - val_loss: 1437.3064\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3562 - val_loss: 1437.3058\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3563 - val_loss: 1437.3063\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3564 - val_loss: 1437.3054\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3566 - val_loss: 1437.3049\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3567 - val_loss: 1437.3044\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3568 - val_loss: 1437.3041\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3569 - val_loss: 1437.3041\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3570 - val_loss: 1437.3032\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 150.3571 - val_loss: 1437.3029\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3572 - val_loss: 1437.3025\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3573 - val_loss: 1437.3020\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3574 - val_loss: 1437.3014\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3576 - val_loss: 1437.3014\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3577 - val_loss: 1437.3016\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3577 - val_loss: 1437.3010\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3579 - val_loss: 1437.3005\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3580 - val_loss: 1437.3011\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3581 - val_loss: 1437.3014\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3582 - val_loss: 1437.3009\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3582 - val_loss: 1437.3005\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3583 - val_loss: 1437.3000\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3585 - val_loss: 1437.3002\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3585 - val_loss: 1437.3005\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3585 - val_loss: 1437.3000\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3586 - val_loss: 1437.2997\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3587 - val_loss: 1437.3005\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3587 - val_loss: 1437.3003\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3587 - val_loss: 1437.2992\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3588 - val_loss: 1437.2990\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3590 - val_loss: 1437.2987\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 150.3591 - val_loss: 1437.2990\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3591 - val_loss: 1437.2988\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3591 - val_loss: 1437.2987\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3592 - val_loss: 1437.2985\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3593 - val_loss: 1437.2990\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3593 - val_loss: 1437.2990\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3593 - val_loss: 1437.2980\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3594 - val_loss: 1437.2971\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3595 - val_loss: 1437.2968\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3596 - val_loss: 1437.2970\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3596 - val_loss: 1437.2968\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3596 - val_loss: 1437.2958\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3596 - val_loss: 1437.2950\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3597 - val_loss: 1437.2946\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3598 - val_loss: 1437.2948\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3598 - val_loss: 1437.2937\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3599 - val_loss: 1437.2939\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3599 - val_loss: 1437.2932\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3600 - val_loss: 1437.2928\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3600 - val_loss: 1437.2935\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3600 - val_loss: 1437.2931\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3601 - val_loss: 1437.2926\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 150.3602 - val_loss: 1437.2931\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3602 - val_loss: 1437.2935\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3602 - val_loss: 1437.2935\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 150.3602 - val_loss: 1437.2932\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3603 - val_loss: 1437.2939\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3603 - val_loss: 1437.2939\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3604 - val_loss: 1437.2941\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3604 - val_loss: 1437.2943\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3604 - val_loss: 1437.2939\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3604 - val_loss: 1437.2927\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3604 - val_loss: 1437.2921\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3605 - val_loss: 1437.2921\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3605 - val_loss: 1437.2922\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3606 - val_loss: 1437.2928\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3607 - val_loss: 1437.2936\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3607 - val_loss: 1437.2937\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 150.3607 - val_loss: 1437.2946\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3607 - val_loss: 1437.2946\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 150.3607 - val_loss: 1437.2944\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 150.3607 - val_loss: 1437.2939\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 150.3607 - val_loss: 1437.2935\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3608 - val_loss: 1437.2932\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3607 - val_loss: 1437.2926\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3608 - val_loss: 1437.2924\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3609 - val_loss: 1437.2926\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3609 - val_loss: 1437.2931\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3609 - val_loss: 1437.2928\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3609 - val_loss: 1437.2928\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3609 - val_loss: 1437.2927\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3609 - val_loss: 1437.2924\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3609 - val_loss: 1437.2921\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3609 - val_loss: 1437.2915\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3610 - val_loss: 1437.2915\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3610 - val_loss: 1437.2909\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3610 - val_loss: 1437.2904\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3610 - val_loss: 1437.2904\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3610 - val_loss: 1437.2904\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3611 - val_loss: 1437.2902\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3611 - val_loss: 1437.2900\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3611 - val_loss: 1437.2900\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 150.3611 - val_loss: 1437.2900\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3611 - val_loss: 1437.2899\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3612 - val_loss: 1437.2899\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3612 - val_loss: 1437.2902\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3613 - val_loss: 1437.2905\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3613 - val_loss: 1437.2910\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3613 - val_loss: 1437.2915\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3613 - val_loss: 1437.2917\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3613 - val_loss: 1437.2919\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3613 - val_loss: 1437.2922\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3613 - val_loss: 1437.2927\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3613 - val_loss: 1437.2931\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3613 - val_loss: 1437.2935\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3613 - val_loss: 1437.2937\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3613 - val_loss: 1437.2937\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3613 - val_loss: 1437.2937\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3613 - val_loss: 1437.2937\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3613 - val_loss: 1437.2936\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3613 - val_loss: 1437.2936\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3613 - val_loss: 1437.2928\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 150.3613 - val_loss: 1437.2926\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3614 - val_loss: 1437.2927\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3614 - val_loss: 1437.2928\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3614 - val_loss: 1437.2928\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3615 - val_loss: 1437.2931\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3615 - val_loss: 1437.2932\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3615 - val_loss: 1437.2932\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3615 - val_loss: 1437.2932\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 150.3615 - val_loss: 1437.2932\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3615 - val_loss: 1437.2932\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3615 - val_loss: 1437.2939\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3615 - val_loss: 1437.2944\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3615 - val_loss: 1437.2948\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3615 - val_loss: 1437.2948\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 150.3615 - val_loss: 1437.2948\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3615 - val_loss: 1437.2948\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3615 - val_loss: 1437.2946\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3615 - val_loss: 1437.2946\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3615 - val_loss: 1437.2946\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 150.3615 - val_loss: 1437.2939\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 150.3615 - val_loss: 1437.2937\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3615 - val_loss: 1437.2932\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 150.3615 - val_loss: 1437.2931\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 150.3615 - val_loss: 1437.2926\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3615 - val_loss: 1437.2922\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3615 - val_loss: 1437.2919\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3616 - val_loss: 1437.2915\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 150.3616 - val_loss: 1437.2919\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3616 - val_loss: 1437.2921\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 150.3616 - val_loss: 1437.2922\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3616 - val_loss: 1437.2927\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 150.3616 - val_loss: 1437.2932\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 150.3616 - val_loss: 1437.2936\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 552ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.96110177e+01, 6.95110177e+01, 6.94109337e+01, 6.93084967e+01,\n",
       "        7.52695465e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.03557104e-01, 2.64017493e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.71128151e+01, 6.69867647e+01, 6.68607143e+01,\n",
       "        6.67346639e+01, 6.66512605e+01, 6.98683940e+01, 6.98179739e+01,\n",
       "        6.97675537e+01, 6.97171335e+01, 6.96334267e+01, 6.95332586e+01,\n",
       "        6.94321746e+01, 6.93330906e+01, 6.91076797e+01, 4.68572617e-01,\n",
       "        0.00000000e+00, 6.96745098e+01, 6.95736695e+01, 6.94728291e+01,\n",
       "        6.93719888e+01, 6.92206583e+01, 6.89433473e+01, 6.86660364e+01,\n",
       "        6.83887255e+01, 6.80792017e+01, 5.82197547e-01, 4.10423160e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.45603120e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.09320723e-01, 0.00000000e+00, 6.93553315e+01,\n",
       "        6.91693044e+01, 0.00000000e+00, 3.39738905e-01, 6.96969188e+01,\n",
       "        6.95960784e+01, 6.94952381e+01, 6.93943978e+01, 6.92822829e+01,\n",
       "        6.90049720e+01, 6.87276611e+01, 6.84503501e+01, 6.81632353e+01,\n",
       "        3.67115810e-02, 0.00000000e+00, 6.93346405e+01, 6.91179505e+01,\n",
       "        6.88406396e+01, 6.85633287e+01, 6.82860177e+01, 6.79391457e+01,\n",
       "        6.75609944e+01, 6.71828431e+01, 6.68046919e+01, 3.06580420e-01,\n",
       "        1.20305598e+00, 5.48878555e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.25676775e-01, 1.03203046e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.91677628e+01, 6.06343150e-02, 5.37889898e-01, 4.87298191e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.38881373e-01, 0.00000000e+00,\n",
       "        2.06910044e-01, 5.32587528e-01, 1.77110225e-01, 3.33228946e-01,\n",
       "        1.22112654e-01, 1.94935471e-01, 5.05961895e-01, 6.96203351e-01,\n",
       "        3.58316749e-01, 0.00000000e+00, 5.09931087e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61.17709913, 61.16917401, 61.16124889, 61.15332377, 61.14539865,\n",
       "       61.13747353, 61.1295484 , 61.12162328, 61.11369816, 61.10577304,\n",
       "       61.09784792, 61.0899228 , 61.08199768, 61.07407256, 61.06614743,\n",
       "       61.05822231, 61.05029719, 61.04237207, 61.03444695, 61.02652183,\n",
       "       61.01859671, 61.01067159, 61.00274646, 60.99482134, 60.98689622,\n",
       "       60.9789711 , 60.97104598, 60.96312086, 60.95519574, 60.94727062,\n",
       "       60.93934549, 60.93142037, 60.92349525, 60.91557013, 60.90764501,\n",
       "       60.89971989, 60.89179477, 60.88386965, 60.87594452, 60.8680194 ,\n",
       "       60.86009428, 60.85216916, 60.84424404, 60.83631892, 60.8283938 ,\n",
       "       60.82046868, 60.81254355, 60.80461843, 60.79669331, 60.78876819,\n",
       "       60.78084307, 60.77291795, 60.76499283, 60.75706771, 60.74914258,\n",
       "       60.74121746, 60.73329234, 60.72536722, 60.7174421 , 60.70951698,\n",
       "       60.70159186, 60.69366673, 60.68574161, 60.67781649, 60.66989137,\n",
       "       60.66196625, 60.65404113, 60.64611601, 60.63819089, 60.63026576,\n",
       "       60.62234064, 60.61441552, 60.6064904 , 60.59856528, 60.59064016,\n",
       "       60.58271504, 60.57478992, 60.56686479, 60.55893967, 60.55101455,\n",
       "       60.54308943, 60.53516431, 60.52723919, 60.51931407, 60.51138895,\n",
       "       60.50346382, 60.4955387 , 60.48761358, 60.47968846, 60.47176334,\n",
       "       60.46383822, 60.4559131 , 60.44798798, 60.44006285, 60.43213773,\n",
       "       60.42421261, 60.41628749, 60.40836237, 60.40043725, 60.39251213])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.15843877866673\n",
      "34.253890626818254\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
