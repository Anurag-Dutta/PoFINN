{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2495    59.631700\n",
       "2496    59.623775\n",
       "2497    59.615850\n",
       "2498    59.607925\n",
       "2499    59.600000\n",
       "Name: C5, Length: 2500, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_2400_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2395     0.696203\n",
       "2396     0.358317\n",
       "2397     0.000000\n",
       "2398     0.509931\n",
       "2399     0.000000\n",
       "Name: C5, Length: 2400, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2400)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1950, 1, 251) (1950, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "25/25 [==============================] - 2s 20ms/step - loss: 4931.2734 - val_loss: 2894.0759\n",
      "Epoch 2/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 4663.9624 - val_loss: 2741.5171\n",
      "Epoch 3/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 4512.0488 - val_loss: 2655.3750\n",
      "Epoch 4/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4386.9443 - val_loss: 2583.1880\n",
      "Epoch 5/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 4274.4863 - val_loss: 2517.4941\n",
      "Epoch 6/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4166.3271 - val_loss: 2454.6042\n",
      "Epoch 7/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4061.5754 - val_loss: 2394.0510\n",
      "Epoch 8/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3959.6814 - val_loss: 2335.5828\n",
      "Epoch 9/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3860.3374 - val_loss: 2279.0447\n",
      "Epoch 10/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3763.3496 - val_loss: 2224.3311\n",
      "Epoch 11/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3668.5850 - val_loss: 2171.3630\n",
      "Epoch 12/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3575.9446 - val_loss: 2120.0771\n",
      "Epoch 13/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3485.3484 - val_loss: 2070.4204\n",
      "Epoch 14/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3396.7324 - val_loss: 2022.3477\n",
      "Epoch 15/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3310.0422 - val_loss: 1975.8083\n",
      "Epoch 16/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3225.2288 - val_loss: 1930.8723\n",
      "Epoch 17/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3142.2520 - val_loss: 1887.3145\n",
      "Epoch 18/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3061.0696 - val_loss: 1845.2201\n",
      "Epoch 19/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2981.6482 - val_loss: 1804.5118\n",
      "Epoch 20/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2903.9475 - val_loss: 1765.0881\n",
      "Epoch 21/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2827.8555 - val_loss: 1727.3588\n",
      "Epoch 22/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2753.6016 - val_loss: 1690.5015\n",
      "Epoch 23/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2680.7805 - val_loss: 1653.8024\n",
      "Epoch 24/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2609.6208 - val_loss: 1619.4149\n",
      "Epoch 25/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2540.2336 - val_loss: 1588.7162\n",
      "Epoch 26/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2472.2559 - val_loss: 1557.1671\n",
      "Epoch 27/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2405.8123 - val_loss: 1526.8223\n",
      "Epoch 28/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2340.8694 - val_loss: 1497.6578\n",
      "Epoch 29/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2277.4016 - val_loss: 1469.6511\n",
      "Epoch 30/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2215.3848 - val_loss: 1442.7792\n",
      "Epoch 31/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2154.7961 - val_loss: 1417.0193\n",
      "Epoch 32/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2095.6111 - val_loss: 1392.3499\n",
      "Epoch 33/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2037.8075 - val_loss: 1368.7490\n",
      "Epoch 34/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1981.3627 - val_loss: 1346.1956\n",
      "Epoch 35/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1926.2540 - val_loss: 1324.6680\n",
      "Epoch 36/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1872.4606 - val_loss: 1304.1455\n",
      "Epoch 37/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1819.9600 - val_loss: 1284.6072\n",
      "Epoch 38/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1768.7314 - val_loss: 1266.0323\n",
      "Epoch 39/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1718.7532 - val_loss: 1248.4009\n",
      "Epoch 40/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1670.0055 - val_loss: 1231.6924\n",
      "Epoch 41/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1622.4666 - val_loss: 1215.8870\n",
      "Epoch 42/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1576.1168 - val_loss: 1200.9651\n",
      "Epoch 43/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1530.9360 - val_loss: 1186.9069\n",
      "Epoch 44/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1486.9043 - val_loss: 1173.6924\n",
      "Epoch 45/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1444.0017 - val_loss: 1161.3035\n",
      "Epoch 46/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1402.2095 - val_loss: 1149.7198\n",
      "Epoch 47/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1361.5072 - val_loss: 1138.9231\n",
      "Epoch 48/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1321.8763 - val_loss: 1128.8947\n",
      "Epoch 49/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1283.2979 - val_loss: 1119.6154\n",
      "Epoch 50/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1245.7532 - val_loss: 1111.0667\n",
      "Epoch 51/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1209.2235 - val_loss: 1103.2306\n",
      "Epoch 52/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1173.6902 - val_loss: 1096.0889\n",
      "Epoch 53/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1139.1356 - val_loss: 1089.6232\n",
      "Epoch 54/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1105.5410 - val_loss: 1083.8157\n",
      "Epoch 55/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1072.8892 - val_loss: 1078.6486\n",
      "Epoch 56/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1041.1615 - val_loss: 1074.1044\n",
      "Epoch 57/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1010.3409 - val_loss: 1070.1653\n",
      "Epoch 58/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 980.4102 - val_loss: 1066.8141\n",
      "Epoch 59/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 951.3510 - val_loss: 1064.0337\n",
      "Epoch 60/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 923.1473 - val_loss: 1061.8068\n",
      "Epoch 61/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 895.7816 - val_loss: 1060.1167\n",
      "Epoch 62/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 869.2368 - val_loss: 1058.9464\n",
      "Epoch 63/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 843.4966 - val_loss: 1058.2794\n",
      "Epoch 64/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 818.5443 - val_loss: 1058.0990\n",
      "Epoch 65/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 794.3632 - val_loss: 1058.3892\n",
      "Epoch 66/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 770.9378 - val_loss: 1059.1333\n",
      "Epoch 67/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 748.2513 - val_loss: 1060.3157\n",
      "Epoch 68/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 726.2880 - val_loss: 1061.9203\n",
      "Epoch 69/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 705.0317 - val_loss: 1063.9313\n",
      "Epoch 70/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 684.4672 - val_loss: 1066.3334\n",
      "Epoch 71/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 664.5787 - val_loss: 1069.1107\n",
      "Epoch 72/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 645.3509 - val_loss: 1072.2483\n",
      "Epoch 73/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 626.7687 - val_loss: 1075.7310\n",
      "Epoch 74/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 608.8167 - val_loss: 1079.5438\n",
      "Epoch 75/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 591.4803 - val_loss: 1083.6722\n",
      "Epoch 76/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 574.7446 - val_loss: 1088.1014\n",
      "Epoch 77/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 558.5948 - val_loss: 1092.8170\n",
      "Epoch 78/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 543.0169 - val_loss: 1097.8049\n",
      "Epoch 79/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 527.9962 - val_loss: 1103.0509\n",
      "Epoch 80/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 513.5187 - val_loss: 1108.5415\n",
      "Epoch 81/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 499.5701 - val_loss: 1114.2625\n",
      "Epoch 82/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 486.1372 - val_loss: 1120.2009\n",
      "Epoch 83/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 473.2060 - val_loss: 1126.3431\n",
      "Epoch 84/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 460.7632 - val_loss: 1132.6766\n",
      "Epoch 85/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 448.7950 - val_loss: 1139.1882\n",
      "Epoch 86/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 437.2887 - val_loss: 1145.8649\n",
      "Epoch 87/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 426.2313 - val_loss: 1152.6948\n",
      "Epoch 88/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 415.6099 - val_loss: 1159.6664\n",
      "Epoch 89/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 405.4119 - val_loss: 1166.7665\n",
      "Epoch 90/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 395.6249 - val_loss: 1173.9838\n",
      "Epoch 91/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 386.2367 - val_loss: 1181.3070\n",
      "Epoch 92/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 377.2350 - val_loss: 1188.7250\n",
      "Epoch 93/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 368.6082 - val_loss: 1196.2264\n",
      "Epoch 94/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 360.3445 - val_loss: 1203.8004\n",
      "Epoch 95/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 352.4325 - val_loss: 1211.4371\n",
      "Epoch 96/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 344.8607 - val_loss: 1219.1261\n",
      "Epoch 97/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 337.6180 - val_loss: 1226.8569\n",
      "Epoch 98/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 330.6937 - val_loss: 1234.6205\n",
      "Epoch 99/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 324.0770 - val_loss: 1242.4072\n",
      "Epoch 100/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 317.7572 - val_loss: 1250.2076\n",
      "Epoch 101/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 311.7242 - val_loss: 1258.0132\n",
      "Epoch 102/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 305.9678 - val_loss: 1265.8152\n",
      "Epoch 103/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 300.4782 - val_loss: 1273.6053\n",
      "Epoch 104/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 295.2458 - val_loss: 1281.3756\n",
      "Epoch 105/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 290.2608 - val_loss: 1289.1182\n",
      "Epoch 106/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 285.5142 - val_loss: 1296.8256\n",
      "Epoch 107/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 280.9969 - val_loss: 1304.4905\n",
      "Epoch 108/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 276.7000 - val_loss: 1312.1067\n",
      "Epoch 109/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 272.6150 - val_loss: 1319.6670\n",
      "Epoch 110/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 268.7333 - val_loss: 1327.1652\n",
      "Epoch 111/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 265.0469 - val_loss: 1334.5950\n",
      "Epoch 112/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 261.5476 - val_loss: 1341.9515\n",
      "Epoch 113/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 258.2278 - val_loss: 1349.2280\n",
      "Epoch 114/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 255.0800 - val_loss: 1356.4213\n",
      "Epoch 115/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 252.0966 - val_loss: 1363.5250\n",
      "Epoch 116/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 249.2707 - val_loss: 1370.5347\n",
      "Epoch 117/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 246.5953 - val_loss: 1377.4465\n",
      "Epoch 118/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 244.0637 - val_loss: 1384.2566\n",
      "Epoch 119/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 241.6694 - val_loss: 1390.9615\n",
      "Epoch 120/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 239.4061 - val_loss: 1397.5574\n",
      "Epoch 121/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 237.2677 - val_loss: 1404.0403\n",
      "Epoch 122/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 235.2484 - val_loss: 1410.4094\n",
      "Epoch 123/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 233.3423 - val_loss: 1416.6599\n",
      "Epoch 124/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 231.5442 - val_loss: 1422.7911\n",
      "Epoch 125/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 229.8487 - val_loss: 1428.8005\n",
      "Epoch 126/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 228.2507 - val_loss: 1434.6862\n",
      "Epoch 127/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 226.7453 - val_loss: 1440.4467\n",
      "Epoch 128/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 225.3278 - val_loss: 1446.0804\n",
      "Epoch 129/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 223.9937 - val_loss: 1451.5867\n",
      "Epoch 130/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 222.7386 - val_loss: 1456.9642\n",
      "Epoch 131/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 221.5584 - val_loss: 1462.2131\n",
      "Epoch 132/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 220.4490 - val_loss: 1467.3320\n",
      "Epoch 133/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 219.4067 - val_loss: 1472.3218\n",
      "Epoch 134/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 218.4278 - val_loss: 1477.1814\n",
      "Epoch 135/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 217.5087 - val_loss: 1481.9122\n",
      "Epoch 136/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 216.6463 - val_loss: 1486.5127\n",
      "Epoch 137/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 215.8372 - val_loss: 1490.9852\n",
      "Epoch 138/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 215.0785 - val_loss: 1495.3300\n",
      "Epoch 139/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 214.3671 - val_loss: 1499.5482\n",
      "Epoch 140/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 213.7006 - val_loss: 1503.6403\n",
      "Epoch 141/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 213.0760 - val_loss: 1507.6086\n",
      "Epoch 142/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 212.4910 - val_loss: 1511.4520\n",
      "Epoch 143/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 211.9433 - val_loss: 1515.1747\n",
      "Epoch 144/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 211.4306 - val_loss: 1518.7770\n",
      "Epoch 145/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 210.9508 - val_loss: 1522.2607\n",
      "Epoch 146/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 210.5018 - val_loss: 1525.6279\n",
      "Epoch 147/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 210.0818 - val_loss: 1528.8800\n",
      "Epoch 148/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 209.6890 - val_loss: 1532.0195\n",
      "Epoch 149/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 209.3215 - val_loss: 1535.0482\n",
      "Epoch 150/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 208.9781 - val_loss: 1537.9689\n",
      "Epoch 151/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 208.6569 - val_loss: 1540.7817\n",
      "Epoch 152/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 208.3568 - val_loss: 1543.4908\n",
      "Epoch 153/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 208.0764 - val_loss: 1546.0979\n",
      "Epoch 154/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 207.8142 - val_loss: 1548.6062\n",
      "Epoch 155/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 207.5692 - val_loss: 1551.0167\n",
      "Epoch 156/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 207.3403 - val_loss: 1553.3330\n",
      "Epoch 157/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 207.1264 - val_loss: 1555.5569\n",
      "Epoch 158/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 206.9265 - val_loss: 1557.6907\n",
      "Epoch 159/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 206.7399 - val_loss: 1559.7371\n",
      "Epoch 160/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 206.5654 - val_loss: 1561.6987\n",
      "Epoch 161/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 206.4024 - val_loss: 1563.5784\n",
      "Epoch 162/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 206.2501 - val_loss: 1565.3776\n",
      "Epoch 163/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 206.1078 - val_loss: 1567.0995\n",
      "Epoch 164/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 205.9747 - val_loss: 1568.7461\n",
      "Epoch 165/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 205.8505 - val_loss: 1570.3203\n",
      "Epoch 166/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 205.7344 - val_loss: 1571.8245\n",
      "Epoch 167/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 205.6259 - val_loss: 1573.2604\n",
      "Epoch 168/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 205.5244 - val_loss: 1574.6310\n",
      "Epoch 169/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 205.4296 - val_loss: 1575.9374\n",
      "Epoch 170/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 205.3411 - val_loss: 1577.1830\n",
      "Epoch 171/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 205.2583 - val_loss: 1578.3707\n",
      "Epoch 172/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 205.1808 - val_loss: 1579.5013\n",
      "Epoch 173/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 205.1085 - val_loss: 1580.5780\n",
      "Epoch 174/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 205.0408 - val_loss: 1581.6011\n",
      "Epoch 175/500\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 204.9776 - val_loss: 1582.5750\n",
      "Epoch 176/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.9184 - val_loss: 1583.5013\n",
      "Epoch 177/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.8631 - val_loss: 1584.3802\n",
      "Epoch 178/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.8115 - val_loss: 1585.2153\n",
      "Epoch 179/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.7631 - val_loss: 1586.0072\n",
      "Epoch 180/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.7179 - val_loss: 1586.7592\n",
      "Epoch 181/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.6756 - val_loss: 1587.4718\n",
      "Epoch 182/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.6361 - val_loss: 1588.1476\n",
      "Epoch 183/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.5991 - val_loss: 1588.7874\n",
      "Epoch 184/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.5646 - val_loss: 1589.3933\n",
      "Epoch 185/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.5323 - val_loss: 1589.9662\n",
      "Epoch 186/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.5021 - val_loss: 1590.5085\n",
      "Epoch 187/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.4739 - val_loss: 1591.0215\n",
      "Epoch 188/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.4476 - val_loss: 1591.5065\n",
      "Epoch 189/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.4229 - val_loss: 1591.9641\n",
      "Epoch 190/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.3999 - val_loss: 1592.3965\n",
      "Epoch 191/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.3784 - val_loss: 1592.8047\n",
      "Epoch 192/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.3583 - val_loss: 1593.1897\n",
      "Epoch 193/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.3397 - val_loss: 1593.5529\n",
      "Epoch 194/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.3221 - val_loss: 1593.8954\n",
      "Epoch 195/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.3058 - val_loss: 1594.2183\n",
      "Epoch 196/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.2906 - val_loss: 1594.5227\n",
      "Epoch 197/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.2763 - val_loss: 1594.8088\n",
      "Epoch 198/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.2631 - val_loss: 1595.0780\n",
      "Epoch 199/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.2508 - val_loss: 1595.3319\n",
      "Epoch 200/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.2393 - val_loss: 1595.5707\n",
      "Epoch 201/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.2286 - val_loss: 1595.7952\n",
      "Epoch 202/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 204.2186 - val_loss: 1596.0057\n",
      "Epoch 203/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.2093 - val_loss: 1596.2045\n",
      "Epoch 204/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.2007 - val_loss: 1596.3905\n",
      "Epoch 205/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1926 - val_loss: 1596.5657\n",
      "Epoch 206/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1852 - val_loss: 1596.7296\n",
      "Epoch 207/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1782 - val_loss: 1596.8832\n",
      "Epoch 208/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1718 - val_loss: 1597.0265\n",
      "Epoch 209/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1660 - val_loss: 1597.1627\n",
      "Epoch 210/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1604 - val_loss: 1597.2893\n",
      "Epoch 211/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1553 - val_loss: 1597.4093\n",
      "Epoch 212/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1506 - val_loss: 1597.5200\n",
      "Epoch 213/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1462 - val_loss: 1597.6241\n",
      "Epoch 214/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1422 - val_loss: 1597.7218\n",
      "Epoch 215/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1385 - val_loss: 1597.8135\n",
      "Epoch 216/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1351 - val_loss: 1597.8987\n",
      "Epoch 217/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1319 - val_loss: 1597.9779\n",
      "Epoch 218/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1291 - val_loss: 1598.0529\n",
      "Epoch 219/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1264 - val_loss: 1598.1221\n",
      "Epoch 220/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1241 - val_loss: 1598.1879\n",
      "Epoch 221/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1218 - val_loss: 1598.2485\n",
      "Epoch 222/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1197 - val_loss: 1598.3064\n",
      "Epoch 223/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1179 - val_loss: 1598.3588\n",
      "Epoch 224/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1162 - val_loss: 1598.4083\n",
      "Epoch 225/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1147 - val_loss: 1598.4543\n",
      "Epoch 226/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1133 - val_loss: 1598.4973\n",
      "Epoch 227/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1121 - val_loss: 1598.5375\n",
      "Epoch 228/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1110 - val_loss: 1598.5750\n",
      "Epoch 229/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 204.1101 - val_loss: 1598.6101\n",
      "Epoch 230/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1091 - val_loss: 1598.6431\n",
      "Epoch 231/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1082 - val_loss: 1598.6731\n",
      "Epoch 232/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1076 - val_loss: 1598.7014\n",
      "Epoch 233/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1070 - val_loss: 1598.7280\n",
      "Epoch 234/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1065 - val_loss: 1598.7532\n",
      "Epoch 235/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1059 - val_loss: 1598.7756\n",
      "Epoch 236/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1056 - val_loss: 1598.7970\n",
      "Epoch 237/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1052 - val_loss: 1598.8170\n",
      "Epoch 238/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1049 - val_loss: 1598.8346\n",
      "Epoch 239/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1048 - val_loss: 1598.8523\n",
      "Epoch 240/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1046 - val_loss: 1598.8674\n",
      "Epoch 241/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1045 - val_loss: 1598.8831\n",
      "Epoch 242/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1044 - val_loss: 1598.8965\n",
      "Epoch 243/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1043 - val_loss: 1598.9089\n",
      "Epoch 244/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1043 - val_loss: 1598.9210\n",
      "Epoch 245/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1043 - val_loss: 1598.9323\n",
      "Epoch 246/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1043 - val_loss: 1598.9426\n",
      "Epoch 247/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1044 - val_loss: 1598.9519\n",
      "Epoch 248/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1045 - val_loss: 1598.9609\n",
      "Epoch 249/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1047 - val_loss: 1598.9694\n",
      "Epoch 250/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1047 - val_loss: 1598.9766\n",
      "Epoch 251/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1049 - val_loss: 1598.9835\n",
      "Epoch 252/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1051 - val_loss: 1598.9894\n",
      "Epoch 253/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1053 - val_loss: 1598.9957\n",
      "Epoch 254/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1055 - val_loss: 1599.0017\n",
      "Epoch 255/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1057 - val_loss: 1599.0060\n",
      "Epoch 256/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1059 - val_loss: 1599.0106\n",
      "Epoch 257/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1061 - val_loss: 1599.0150\n",
      "Epoch 258/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1064 - val_loss: 1599.0189\n",
      "Epoch 259/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1066 - val_loss: 1599.0222\n",
      "Epoch 260/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1069 - val_loss: 1599.0265\n",
      "Epoch 261/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1071 - val_loss: 1599.0293\n",
      "Epoch 262/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1074 - val_loss: 1599.0322\n",
      "Epoch 263/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1077 - val_loss: 1599.0353\n",
      "Epoch 264/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1080 - val_loss: 1599.0378\n",
      "Epoch 265/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1082 - val_loss: 1599.0400\n",
      "Epoch 266/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 204.1085 - val_loss: 1599.0426\n",
      "Epoch 267/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1087 - val_loss: 1599.0444\n",
      "Epoch 268/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1089 - val_loss: 1599.0465\n",
      "Epoch 269/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1092 - val_loss: 1599.0483\n",
      "Epoch 270/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1095 - val_loss: 1599.0503\n",
      "Epoch 271/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1097 - val_loss: 1599.0513\n",
      "Epoch 272/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1100 - val_loss: 1599.0526\n",
      "Epoch 273/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1102 - val_loss: 1599.0542\n",
      "Epoch 274/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1105 - val_loss: 1599.0549\n",
      "Epoch 275/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1107 - val_loss: 1599.0554\n",
      "Epoch 276/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1110 - val_loss: 1599.0569\n",
      "Epoch 277/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1113 - val_loss: 1599.0582\n",
      "Epoch 278/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1115 - val_loss: 1599.0594\n",
      "Epoch 279/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1117 - val_loss: 1599.0599\n",
      "Epoch 280/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 204.1119 - val_loss: 1599.0603\n",
      "Epoch 281/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 204.1122 - val_loss: 1599.0609\n",
      "Epoch 282/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1124 - val_loss: 1599.0614\n",
      "Epoch 283/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 204.1127 - val_loss: 1599.0629\n",
      "Epoch 284/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 204.1128 - val_loss: 1599.0625\n",
      "Epoch 285/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 204.1131 - val_loss: 1599.0631\n",
      "Epoch 286/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1133 - val_loss: 1599.0636\n",
      "Epoch 287/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1135 - val_loss: 1599.0638\n",
      "Epoch 288/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1138 - val_loss: 1599.0646\n",
      "Epoch 289/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1139 - val_loss: 1599.0646\n",
      "Epoch 290/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1142 - val_loss: 1599.0647\n",
      "Epoch 291/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1143 - val_loss: 1599.0652\n",
      "Epoch 292/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1145 - val_loss: 1599.0654\n",
      "Epoch 293/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1147 - val_loss: 1599.0657\n",
      "Epoch 294/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1149 - val_loss: 1599.0660\n",
      "Epoch 295/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1151 - val_loss: 1599.0662\n",
      "Epoch 296/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1152 - val_loss: 1599.0664\n",
      "Epoch 297/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1154 - val_loss: 1599.0662\n",
      "Epoch 298/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1156 - val_loss: 1599.0665\n",
      "Epoch 299/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1158 - val_loss: 1599.0670\n",
      "Epoch 300/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1159 - val_loss: 1599.0667\n",
      "Epoch 301/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1161 - val_loss: 1599.0665\n",
      "Epoch 302/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1163 - val_loss: 1599.0671\n",
      "Epoch 303/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1165 - val_loss: 1599.0671\n",
      "Epoch 304/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1166 - val_loss: 1599.0673\n",
      "Epoch 305/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1167 - val_loss: 1599.0670\n",
      "Epoch 306/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1169 - val_loss: 1599.0671\n",
      "Epoch 307/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1170 - val_loss: 1599.0670\n",
      "Epoch 308/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1172 - val_loss: 1599.0670\n",
      "Epoch 309/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 204.1174 - val_loss: 1599.0671\n",
      "Epoch 310/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1174 - val_loss: 1599.0670\n",
      "Epoch 311/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1176 - val_loss: 1599.0662\n",
      "Epoch 312/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1178 - val_loss: 1599.0670\n",
      "Epoch 313/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1179 - val_loss: 1599.0675\n",
      "Epoch 314/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1180 - val_loss: 1599.0675\n",
      "Epoch 315/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1181 - val_loss: 1599.0671\n",
      "Epoch 316/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1182 - val_loss: 1599.0667\n",
      "Epoch 317/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1183 - val_loss: 1599.0667\n",
      "Epoch 318/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1184 - val_loss: 1599.0667\n",
      "Epoch 319/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1185 - val_loss: 1599.0667\n",
      "Epoch 320/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1186 - val_loss: 1599.0667\n",
      "Epoch 321/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1188 - val_loss: 1599.0670\n",
      "Epoch 322/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1189 - val_loss: 1599.0675\n",
      "Epoch 323/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1190 - val_loss: 1599.0680\n",
      "Epoch 324/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1190 - val_loss: 1599.0682\n",
      "Epoch 325/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1191 - val_loss: 1599.0682\n",
      "Epoch 326/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1192 - val_loss: 1599.0682\n",
      "Epoch 327/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1192 - val_loss: 1599.0682\n",
      "Epoch 328/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1193 - val_loss: 1599.0677\n",
      "Epoch 329/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1195 - val_loss: 1599.0676\n",
      "Epoch 330/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1196 - val_loss: 1599.0677\n",
      "Epoch 331/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1197 - val_loss: 1599.0681\n",
      "Epoch 332/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1198 - val_loss: 1599.0682\n",
      "Epoch 333/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1198 - val_loss: 1599.0676\n",
      "Epoch 334/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1199 - val_loss: 1599.0677\n",
      "Epoch 335/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1200 - val_loss: 1599.0682\n",
      "Epoch 336/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1200 - val_loss: 1599.0685\n",
      "Epoch 337/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1201 - val_loss: 1599.0685\n",
      "Epoch 338/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1201 - val_loss: 1599.0690\n",
      "Epoch 339/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1202 - val_loss: 1599.0691\n",
      "Epoch 340/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1202 - val_loss: 1599.0691\n",
      "Epoch 341/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1203 - val_loss: 1599.0692\n",
      "Epoch 342/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1203 - val_loss: 1599.0693\n",
      "Epoch 343/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1204 - val_loss: 1599.0698\n",
      "Epoch 344/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1204 - val_loss: 1599.0692\n",
      "Epoch 345/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1205 - val_loss: 1599.0691\n",
      "Epoch 346/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1205 - val_loss: 1599.0690\n",
      "Epoch 347/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1206 - val_loss: 1599.0690\n",
      "Epoch 348/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1207 - val_loss: 1599.0690\n",
      "Epoch 349/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1208 - val_loss: 1599.0690\n",
      "Epoch 350/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1208 - val_loss: 1599.0690\n",
      "Epoch 351/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1208 - val_loss: 1599.0690\n",
      "Epoch 352/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1209 - val_loss: 1599.0687\n",
      "Epoch 353/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1210 - val_loss: 1599.0687\n",
      "Epoch 354/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1210 - val_loss: 1599.0682\n",
      "Epoch 355/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1211 - val_loss: 1599.0682\n",
      "Epoch 356/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1212 - val_loss: 1599.0692\n",
      "Epoch 357/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 204.1212 - val_loss: 1599.0693\n",
      "Epoch 358/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1212 - val_loss: 1599.0698\n",
      "Epoch 359/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1212 - val_loss: 1599.0698\n",
      "Epoch 360/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1212 - val_loss: 1599.0702\n",
      "Epoch 361/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1213 - val_loss: 1599.0698\n",
      "Epoch 362/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1213 - val_loss: 1599.0698\n",
      "Epoch 363/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1213 - val_loss: 1599.0697\n",
      "Epoch 364/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1213 - val_loss: 1599.0697\n",
      "Epoch 365/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1214 - val_loss: 1599.0693\n",
      "Epoch 366/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1215 - val_loss: 1599.0693\n",
      "Epoch 367/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1215 - val_loss: 1599.0693\n",
      "Epoch 368/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1215 - val_loss: 1599.0685\n",
      "Epoch 369/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1216 - val_loss: 1599.0685\n",
      "Epoch 370/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1217 - val_loss: 1599.0693\n",
      "Epoch 371/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1216 - val_loss: 1599.0693\n",
      "Epoch 372/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1217 - val_loss: 1599.0693\n",
      "Epoch 373/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1217 - val_loss: 1599.0693\n",
      "Epoch 374/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1217 - val_loss: 1599.0690\n",
      "Epoch 375/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1218 - val_loss: 1599.0693\n",
      "Epoch 376/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1218 - val_loss: 1599.0687\n",
      "Epoch 377/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1218 - val_loss: 1599.0687\n",
      "Epoch 378/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1218 - val_loss: 1599.0682\n",
      "Epoch 379/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 204.1219 - val_loss: 1599.0680\n",
      "Epoch 380/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1219 - val_loss: 1599.0682\n",
      "Epoch 381/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1219 - val_loss: 1599.0687\n",
      "Epoch 382/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1220 - val_loss: 1599.0687\n",
      "Epoch 383/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1219 - val_loss: 1599.0687\n",
      "Epoch 384/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1220 - val_loss: 1599.0687\n",
      "Epoch 385/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1220 - val_loss: 1599.0690\n",
      "Epoch 386/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1220 - val_loss: 1599.0690\n",
      "Epoch 387/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1220 - val_loss: 1599.0687\n",
      "Epoch 388/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1221 - val_loss: 1599.0685\n",
      "Epoch 389/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1221 - val_loss: 1599.0681\n",
      "Epoch 390/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1221 - val_loss: 1599.0680\n",
      "Epoch 391/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1222 - val_loss: 1599.0677\n",
      "Epoch 392/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1222 - val_loss: 1599.0676\n",
      "Epoch 393/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1222 - val_loss: 1599.0675\n",
      "Epoch 394/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1223 - val_loss: 1599.0677\n",
      "Epoch 395/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1223 - val_loss: 1599.0680\n",
      "Epoch 396/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1223 - val_loss: 1599.0682\n",
      "Epoch 397/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1223 - val_loss: 1599.0686\n",
      "Epoch 398/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1223 - val_loss: 1599.0691\n",
      "Epoch 399/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1223 - val_loss: 1599.0696\n",
      "Epoch 400/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1223 - val_loss: 1599.0698\n",
      "Epoch 401/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 204.1223 - val_loss: 1599.0702\n",
      "Epoch 402/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1223 - val_loss: 1599.0707\n",
      "Epoch 403/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1223 - val_loss: 1599.0712\n",
      "Epoch 404/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1223 - val_loss: 1599.0713\n",
      "Epoch 405/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1223 - val_loss: 1599.0719\n",
      "Epoch 406/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1223 - val_loss: 1599.0723\n",
      "Epoch 407/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1223 - val_loss: 1599.0721\n",
      "Epoch 408/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1223 - val_loss: 1599.0718\n",
      "Epoch 409/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1223 - val_loss: 1599.0715\n",
      "Epoch 410/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1223 - val_loss: 1599.0712\n",
      "Epoch 411/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1223 - val_loss: 1599.0708\n",
      "Epoch 412/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1223 - val_loss: 1599.0707\n",
      "Epoch 413/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1223 - val_loss: 1599.0706\n",
      "Epoch 414/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1224 - val_loss: 1599.0706\n",
      "Epoch 415/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1224 - val_loss: 1599.0706\n",
      "Epoch 416/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1224 - val_loss: 1599.0707\n",
      "Epoch 417/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1224 - val_loss: 1599.0708\n",
      "Epoch 418/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1224 - val_loss: 1599.0706\n",
      "Epoch 419/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1224 - val_loss: 1599.0703\n",
      "Epoch 420/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 204.1224 - val_loss: 1599.0702\n",
      "Epoch 421/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1225 - val_loss: 1599.0698\n",
      "Epoch 422/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1225 - val_loss: 1599.0698\n",
      "Epoch 423/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1225 - val_loss: 1599.0691\n",
      "Epoch 424/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1225 - val_loss: 1599.0691\n",
      "Epoch 425/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1225 - val_loss: 1599.0690\n",
      "Epoch 426/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1225 - val_loss: 1599.0687\n",
      "Epoch 427/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1225 - val_loss: 1599.0685\n",
      "Epoch 428/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1225 - val_loss: 1599.0675\n",
      "Epoch 429/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1226 - val_loss: 1599.0664\n",
      "Epoch 430/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1226 - val_loss: 1599.0657\n",
      "Epoch 431/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1227 - val_loss: 1599.0660\n",
      "Epoch 432/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0654\n",
      "Epoch 433/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0651\n",
      "Epoch 434/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0654\n",
      "Epoch 435/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0654\n",
      "Epoch 436/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1228 - val_loss: 1599.0649\n",
      "Epoch 437/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1228 - val_loss: 1599.0647\n",
      "Epoch 438/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1228 - val_loss: 1599.0647\n",
      "Epoch 439/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1228 - val_loss: 1599.0642\n",
      "Epoch 440/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1228 - val_loss: 1599.0635\n",
      "Epoch 441/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1229 - val_loss: 1599.0631\n",
      "Epoch 442/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1229 - val_loss: 1599.0631\n",
      "Epoch 443/500\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 204.1229 - val_loss: 1599.0634\n",
      "Epoch 444/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1229 - val_loss: 1599.0640\n",
      "Epoch 445/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1229 - val_loss: 1599.0642\n",
      "Epoch 446/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 204.1229 - val_loss: 1599.0647\n",
      "Epoch 447/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1229 - val_loss: 1599.0647\n",
      "Epoch 448/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1229 - val_loss: 1599.0647\n",
      "Epoch 449/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1229 - val_loss: 1599.0649\n",
      "Epoch 450/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1229 - val_loss: 1599.0649\n",
      "Epoch 451/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1229 - val_loss: 1599.0649\n",
      "Epoch 452/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1229 - val_loss: 1599.0652\n",
      "Epoch 453/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1229 - val_loss: 1599.0656\n",
      "Epoch 454/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1229 - val_loss: 1599.0656\n",
      "Epoch 455/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1229 - val_loss: 1599.0657\n",
      "Epoch 456/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1229 - val_loss: 1599.0660\n",
      "Epoch 457/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1228 - val_loss: 1599.0667\n",
      "Epoch 458/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1228 - val_loss: 1599.0673\n",
      "Epoch 459/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1228 - val_loss: 1599.0676\n",
      "Epoch 460/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1228 - val_loss: 1599.0681\n",
      "Epoch 461/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1228 - val_loss: 1599.0686\n",
      "Epoch 462/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1228 - val_loss: 1599.0693\n",
      "Epoch 463/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 204.1227 - val_loss: 1599.0702\n",
      "Epoch 464/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1228 - val_loss: 1599.0703\n",
      "Epoch 465/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0707\n",
      "Epoch 466/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0706\n",
      "Epoch 467/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0706\n",
      "Epoch 468/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0703\n",
      "Epoch 469/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0706\n",
      "Epoch 470/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 204.1227 - val_loss: 1599.0706\n",
      "Epoch 471/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0706\n",
      "Epoch 472/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0706\n",
      "Epoch 473/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0703\n",
      "Epoch 474/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0703\n",
      "Epoch 475/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0706\n",
      "Epoch 476/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0707\n",
      "Epoch 477/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0706\n",
      "Epoch 478/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0706\n",
      "Epoch 479/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0712\n",
      "Epoch 480/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0715\n",
      "Epoch 481/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1227 - val_loss: 1599.0717\n",
      "Epoch 482/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 204.1226 - val_loss: 1599.0717\n",
      "Epoch 483/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 204.1227 - val_loss: 1599.0717\n",
      "Epoch 484/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1227 - val_loss: 1599.0708\n",
      "Epoch 485/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1227 - val_loss: 1599.0715\n",
      "Epoch 486/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 204.1227 - val_loss: 1599.0713\n",
      "Epoch 487/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0715\n",
      "Epoch 488/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0717\n",
      "Epoch 489/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0715\n",
      "Epoch 490/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0718\n",
      "Epoch 491/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0717\n",
      "Epoch 492/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0717\n",
      "Epoch 493/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0717\n",
      "Epoch 494/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0715\n",
      "Epoch 495/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0715\n",
      "Epoch 496/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0715\n",
      "Epoch 497/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0715\n",
      "Epoch 498/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0715\n",
      "Epoch 499/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.1227 - val_loss: 1599.0715\n",
      "Epoch 500/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 204.1227 - val_loss: 1599.0715\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 505ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.91282213e+01, 6.88509104e+01, 6.85735994e+01, 6.82962885e+01,\n",
       "        7.49060364e+01, 1.22350466e+00, 3.47051203e-01, 3.40441880e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.58575761e-01,\n",
       "        0.00000000e+00, 6.94215415e+01, 6.93219701e+01, 6.90768674e+01,\n",
       "        0.00000000e+00, 1.03676066e-01, 6.96633053e+01, 6.95624650e+01,\n",
       "        6.94616247e+01, 6.93607843e+01, 6.91898459e+01, 6.89125350e+01,\n",
       "        6.86352241e+01, 6.83579132e+01, 6.80371849e+01, 7.12585807e-01,\n",
       "        2.52054334e-01, 6.93010271e+01, 6.90255135e+01, 6.87482026e+01,\n",
       "        6.84708917e+01, 6.81912465e+01, 6.78130952e+01, 6.74349440e+01,\n",
       "        6.70567927e+01, 6.66886088e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.57989764e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.23001921e-01, 6.84195378e+01,\n",
       "        6.81212185e+01, 0.00000000e+00, 0.00000000e+00, 6.93234360e+01,\n",
       "        6.90871382e+01, 6.88098273e+01, 6.85325163e+01, 6.82552054e+01,\n",
       "        6.78971289e+01, 6.75189776e+01, 6.71408263e+01, 6.67626751e+01,\n",
       "        2.91491540e-01, 0.00000000e+00, 6.83671839e+01, 6.80511905e+01,\n",
       "        6.76730392e+01, 6.72948880e+01, 6.69167367e+01, 6.98908030e+01,\n",
       "        6.97395425e+01, 6.94776564e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.24333203e-01, 5.88982048e+01, 1.35703892e-01, 3.07033718e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.67281473e-01, 1.87531620e-01,\n",
       "        6.90436859e+01, 8.22603524e-01, 3.25669110e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.25862324e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.64896485e-02, 0.00000000e+00, 6.78934038e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 8.19440722e-01, 0.00000000e+00,\n",
       "        1.38352978e+00, 1.21409142e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60.38458701, 60.37666188, 60.36873676, 60.36081164, 60.35288652,\n",
       "       60.3449614 , 60.33703628, 60.32911116, 60.32118604, 60.31326091,\n",
       "       60.30533579, 60.29741067, 60.28948555, 60.28156043, 60.27363531,\n",
       "       60.26571019, 60.25778507, 60.24985994, 60.24193482, 60.2340097 ,\n",
       "       60.22608458, 60.21815946, 60.21023434, 60.20230922, 60.1943841 ,\n",
       "       60.18645897, 60.17853385, 60.17060873, 60.16268361, 60.15475849,\n",
       "       60.14683337, 60.13890825, 60.13098312, 60.123058  , 60.11513288,\n",
       "       60.10720776, 60.09928264, 60.09135752, 60.0834324 , 60.07550728,\n",
       "       60.06758215, 60.05965703, 60.05173191, 60.04380679, 60.03588167,\n",
       "       60.02795655, 60.02003143, 60.01210631, 60.00418118, 59.99625606,\n",
       "       59.98833094, 59.98040582, 59.9724807 , 59.96455558, 59.95663046,\n",
       "       59.94870534, 59.94078021, 59.93285509, 59.92492997, 59.91700485,\n",
       "       59.90907973, 59.90115461, 59.89322949, 59.88530437, 59.87737924,\n",
       "       59.86945412, 59.861529  , 59.85360388, 59.84567876, 59.83775364,\n",
       "       59.82982852, 59.8219034 , 59.81397827, 59.80605315, 59.79812803,\n",
       "       59.79020291, 59.78227779, 59.77435267, 59.76642755, 59.75850243,\n",
       "       59.7505773 , 59.74265218, 59.73472706, 59.72680194, 59.71887682,\n",
       "       59.7109517 , 59.70302658, 59.69510146, 59.68717633, 59.67925121,\n",
       "       59.67132609, 59.66340097, 59.65547585, 59.64755073, 59.63962561,\n",
       "       59.63170049, 59.62377536, 59.61585024, 59.60792512, 59.6       ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.86413209565537\n",
      "35.59411786534154\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
