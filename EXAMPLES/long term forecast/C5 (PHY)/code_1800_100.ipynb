{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "1895    64.245215\n",
       "1896    64.234944\n",
       "1897    64.224673\n",
       "1898    64.214402\n",
       "1899    64.204132\n",
       "Name: C5, Length: 1900, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_1800_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "1795     0.000000\n",
       "1796     0.166989\n",
       "1797     0.209524\n",
       "1798     0.267838\n",
       "1799     0.000000\n",
       "Name: C5, Length: 1800, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1800)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1350, 1, 251) (1350, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 3s 32ms/step - loss: 5369.2651 - val_loss: 4159.4873\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5288.3052 - val_loss: 4106.9346\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5225.7446 - val_loss: 4053.8342\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5162.3345 - val_loss: 3996.2878\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5094.7393 - val_loss: 3941.5588\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5030.6533 - val_loss: 3887.6055\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4967.5361 - val_loss: 3834.5342\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4905.3291 - val_loss: 3782.2312\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4843.9165 - val_loss: 3730.6162\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 4783.2217 - val_loss: 3679.6394\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4723.1973 - val_loss: 3629.2683\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4663.8115 - val_loss: 3579.4802\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4605.0420 - val_loss: 3530.2590\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4546.8711 - val_loss: 3481.5913\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4489.2866 - val_loss: 3433.4666\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4432.2773 - val_loss: 3385.8757\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4375.8330 - val_loss: 3338.8108\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4319.9463 - val_loss: 3292.2651\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4264.6104 - val_loss: 3246.2319\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4209.8179 - val_loss: 3200.7068\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4155.5625 - val_loss: 3155.6824\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 4101.8398 - val_loss: 3111.1553\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4048.6445 - val_loss: 3067.1199\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3995.9705 - val_loss: 3023.5718\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3943.8135 - val_loss: 2980.5066\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3892.1694 - val_loss: 2937.9202\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3841.0332 - val_loss: 2895.8079\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3790.4009 - val_loss: 2854.1663\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3740.2681 - val_loss: 2812.9910\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3690.6323 - val_loss: 2772.2791\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3641.4871 - val_loss: 2732.0256\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3592.8306 - val_loss: 2692.2283\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3544.6575 - val_loss: 2652.8818\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3496.9653 - val_loss: 2613.9839\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3449.7502 - val_loss: 2575.5305\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3403.0085 - val_loss: 2537.5190\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3356.7361 - val_loss: 2499.9446\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3310.9302 - val_loss: 2462.8052\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3265.5869 - val_loss: 2426.0964\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3220.7024 - val_loss: 2389.8152\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3176.2747 - val_loss: 2353.9597\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3132.2993 - val_loss: 2318.5247\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3088.7112 - val_loss: 2279.2927\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3037.9292 - val_loss: 2239.8191\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2989.1062 - val_loss: 2201.0273\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2941.6899 - val_loss: 2163.5464\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2895.6624 - val_loss: 2127.1023\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2850.7236 - val_loss: 2091.5020\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2806.6824 - val_loss: 2056.6265\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2763.4214 - val_loss: 2022.4021\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2720.8635 - val_loss: 1988.7778\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 2678.9551 - val_loss: 1955.7155\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2637.6584 - val_loss: 1923.1886\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2596.9419 - val_loss: 1891.1744\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2556.7832 - val_loss: 1859.6561\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2517.1621 - val_loss: 1828.6171\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2478.0613 - val_loss: 1798.0454\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2439.4688 - val_loss: 1767.9309\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2401.3713 - val_loss: 1738.2612\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2363.7578 - val_loss: 1709.0308\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2326.6196 - val_loss: 1680.2291\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2289.9482 - val_loss: 1651.8501\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2253.7346 - val_loss: 1623.8870\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2217.9722 - val_loss: 1596.3328\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2182.6541 - val_loss: 1569.1827\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2147.7744 - val_loss: 1542.4304\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2113.3267 - val_loss: 1516.0713\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2079.3054 - val_loss: 1490.0994\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2045.7053 - val_loss: 1464.5115\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2012.5217 - val_loss: 1439.3011\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1979.7493 - val_loss: 1414.4655\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1947.3838 - val_loss: 1389.9998\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1915.4207 - val_loss: 1365.8997\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1883.8549 - val_loss: 1342.1616\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1852.6835 - val_loss: 1318.7810\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1821.9014 - val_loss: 1295.7550\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1791.5051 - val_loss: 1273.0791\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1761.4912 - val_loss: 1250.7500\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1731.8549 - val_loss: 1228.7644\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1702.5931 - val_loss: 1207.1183\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1673.7024 - val_loss: 1185.8091\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1645.1796 - val_loss: 1164.8328\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1617.0201 - val_loss: 1144.1857\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1589.2214 - val_loss: 1123.8656\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1561.7802 - val_loss: 1103.8690\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1534.6925 - val_loss: 1084.1923\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1507.9561 - val_loss: 1064.8326\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1481.5667 - val_loss: 1045.7871\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1455.5223 - val_loss: 1027.0525\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1429.8193 - val_loss: 1008.6259\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1404.4545 - val_loss: 990.5038\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1379.4247 - val_loss: 972.6839\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1354.7279 - val_loss: 955.1631\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1330.3595 - val_loss: 937.9385\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1306.3180 - val_loss: 921.0074\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1282.6001 - val_loss: 904.3665\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1259.2029 - val_loss: 888.0130\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1236.1230 - val_loss: 871.9446\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1213.3584 - val_loss: 856.1584\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1190.9062 - val_loss: 840.6514\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1168.7637 - val_loss: 825.4209\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1146.9275 - val_loss: 810.4637\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1125.3953 - val_loss: 795.7783\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1104.1647 - val_loss: 781.3613\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1083.2325 - val_loss: 767.2100\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1062.5964 - val_loss: 753.3218\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1042.2539 - val_loss: 739.6943\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1022.2018 - val_loss: 726.3239\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1002.4375 - val_loss: 713.2093\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 982.9589 - val_loss: 700.3475\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 963.7633 - val_loss: 687.7354\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 944.8482 - val_loss: 675.3708\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 926.2103 - val_loss: 663.2508\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 907.8479 - val_loss: 651.3734\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 889.7581 - val_loss: 639.7363\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 871.9391 - val_loss: 628.3361\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 854.3878 - val_loss: 617.1707\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 837.1014 - val_loss: 606.2374\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 820.0776 - val_loss: 595.5341\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 803.3146 - val_loss: 585.0579\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 786.8095 - val_loss: 574.8069\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 770.5593 - val_loss: 564.7778\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 754.5625 - val_loss: 554.9686\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 738.8161 - val_loss: 545.3763\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 723.3176 - val_loss: 535.9997\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 708.0651 - val_loss: 526.8353\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 693.0560 - val_loss: 517.8812\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 678.2881 - val_loss: 509.1343\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 663.7588 - val_loss: 500.5928\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 649.4654 - val_loss: 492.2543\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 635.4061 - val_loss: 484.1158\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 621.5781 - val_loss: 476.1756\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 607.9793 - val_loss: 468.4309\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 594.6073 - val_loss: 460.8795\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 581.4601 - val_loss: 453.5192\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 568.5355 - val_loss: 446.3473\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 555.8306 - val_loss: 439.3615\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 543.3434 - val_loss: 432.5594\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 531.0715 - val_loss: 425.9390\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 519.0128 - val_loss: 419.4976\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 507.1649 - val_loss: 413.2330\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 495.5254 - val_loss: 407.1428\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 484.0921 - val_loss: 401.2246\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 472.8630 - val_loss: 395.4764\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 461.8357 - val_loss: 389.8958\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 451.0079 - val_loss: 384.4803\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 440.3775 - val_loss: 379.2278\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 429.9422 - val_loss: 374.1358\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 419.6996 - val_loss: 369.2021\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 409.6477 - val_loss: 364.4244\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 399.7843 - val_loss: 359.8006\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 390.1071 - val_loss: 355.3283\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 380.6141 - val_loss: 351.0053\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 371.3029 - val_loss: 346.8295\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 362.1715 - val_loss: 342.7981\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 353.2177 - val_loss: 338.9098\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 344.4395 - val_loss: 335.1615\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 335.8343 - val_loss: 331.5513\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 327.4002 - val_loss: 328.0767\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 319.1349 - val_loss: 324.7362\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 311.0367 - val_loss: 321.5270\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 303.1031 - val_loss: 318.4470\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 295.3321 - val_loss: 315.4941\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 287.7215 - val_loss: 312.6663\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 280.2691 - val_loss: 309.9611\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 272.9730 - val_loss: 307.3763\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 265.8310 - val_loss: 304.9099\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 258.8414 - val_loss: 302.5600\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 252.0016 - val_loss: 300.3241\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 245.3098 - val_loss: 298.2003\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 238.7639 - val_loss: 296.1863\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 232.3618 - val_loss: 294.2802\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 226.1015 - val_loss: 292.4796\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 219.9810 - val_loss: 290.7826\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 213.9982 - val_loss: 289.1870\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 208.1510 - val_loss: 287.6909\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 202.4377 - val_loss: 286.2921\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 196.8560 - val_loss: 284.9886\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 191.4043 - val_loss: 283.7783\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 186.0802 - val_loss: 282.6593\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 180.8821 - val_loss: 281.6295\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 175.8078 - val_loss: 280.6868\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 170.8553 - val_loss: 279.8293\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 166.0225 - val_loss: 279.0549\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 161.3076 - val_loss: 278.3617\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 156.7088 - val_loss: 277.7477\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 152.2244 - val_loss: 277.2110\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 147.8522 - val_loss: 276.7498\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 143.5905 - val_loss: 276.3619\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 139.4372 - val_loss: 276.0455\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 135.3905 - val_loss: 275.7987\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 131.4485 - val_loss: 275.6197\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 127.6095 - val_loss: 275.5065\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 123.8717 - val_loss: 275.4572\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 120.2333 - val_loss: 275.4702\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 116.6919 - val_loss: 275.5434\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 113.2464 - val_loss: 275.6752\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 109.8949 - val_loss: 275.8637\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 106.6353 - val_loss: 276.1071\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 103.4663 - val_loss: 276.4037\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 100.3858 - val_loss: 276.7517\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 97.3924 - val_loss: 277.1494\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 94.4841 - val_loss: 277.5951\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 91.6594 - val_loss: 278.0870\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 88.9165 - val_loss: 278.6236\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 86.2537 - val_loss: 279.2032\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 83.6695 - val_loss: 279.8240\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 81.1619 - val_loss: 280.4846\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 78.7296 - val_loss: 281.1832\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 76.3709 - val_loss: 281.9184\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 74.0843 - val_loss: 282.6885\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 71.8679 - val_loss: 283.4921\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 69.7205 - val_loss: 284.3275\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 67.6405 - val_loss: 285.1933\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 65.6261 - val_loss: 286.0880\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 63.6762 - val_loss: 287.0103\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 61.7888 - val_loss: 287.9586\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 59.9629 - val_loss: 288.9314\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 58.1969 - val_loss: 289.9276\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 56.4891 - val_loss: 290.9455\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 54.8385 - val_loss: 291.9840\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 53.2434 - val_loss: 293.0417\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 51.7024 - val_loss: 294.1172\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 50.2142 - val_loss: 295.2093\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 48.7776 - val_loss: 296.3169\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 47.3911 - val_loss: 297.4384\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 46.0535 - val_loss: 298.5731\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 44.7634 - val_loss: 299.7195\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 43.5195 - val_loss: 300.8763\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 42.3207 - val_loss: 302.0428\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 41.1655 - val_loss: 303.2176\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 40.0530 - val_loss: 304.3996\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 38.9818 - val_loss: 305.5879\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 37.9507 - val_loss: 306.7812\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 36.9588 - val_loss: 307.9790\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 36.0046 - val_loss: 309.1798\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 35.0873 - val_loss: 310.3830\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 34.2055 - val_loss: 311.5876\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 33.3583 - val_loss: 312.7925\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 32.5448 - val_loss: 313.9970\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 31.7636 - val_loss: 315.2001\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 31.0141 - val_loss: 316.4011\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 30.2949 - val_loss: 317.5995\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 29.6052 - val_loss: 318.7939\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.9441 - val_loss: 319.9841\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 28.3106 - val_loss: 321.1688\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.7039 - val_loss: 322.3479\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 27.1228 - val_loss: 323.5206\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.5667 - val_loss: 324.6859\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 26.0347 - val_loss: 325.8435\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.5259 - val_loss: 326.9928\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 25.0395 - val_loss: 328.1330\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 24.5747 - val_loss: 329.2638\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 24.1308 - val_loss: 330.3848\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 23.7068 - val_loss: 331.4950\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 23.3023 - val_loss: 332.5943\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.9164 - val_loss: 333.6823\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 22.5484 - val_loss: 334.7583\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 22.1976 - val_loss: 335.8219\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.8635 - val_loss: 336.8729\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.5452 - val_loss: 337.9109\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.2423 - val_loss: 338.9358\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.9540 - val_loss: 339.9468\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.6798 - val_loss: 340.9438\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.4192 - val_loss: 341.9270\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 20.1715 - val_loss: 342.8954\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.9363 - val_loss: 343.8491\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.7130 - val_loss: 344.7881\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.5010 - val_loss: 345.7119\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.2999 - val_loss: 346.6205\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.1093 - val_loss: 347.5139\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.9287 - val_loss: 348.3918\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.7575 - val_loss: 349.2539\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.5955 - val_loss: 350.1000\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.4422 - val_loss: 350.9307\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 18.2971 - val_loss: 351.7453\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.1601 - val_loss: 352.5442\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.0305 - val_loss: 353.3273\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.9080 - val_loss: 354.0944\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.7924 - val_loss: 354.8456\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.6833 - val_loss: 355.5807\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.5804 - val_loss: 356.2999\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.4834 - val_loss: 357.0035\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.3920 - val_loss: 357.6916\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.3058 - val_loss: 358.3638\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.2246 - val_loss: 359.0199\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.1483 - val_loss: 359.6607\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.0766 - val_loss: 360.2865\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.0091 - val_loss: 360.8969\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.9457 - val_loss: 361.4923\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.8860 - val_loss: 362.0726\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.8300 - val_loss: 362.6377\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.7776 - val_loss: 363.1883\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.7283 - val_loss: 363.7242\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.6822 - val_loss: 364.2458\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.6389 - val_loss: 364.7531\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.5984 - val_loss: 365.2467\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.5604 - val_loss: 365.7260\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 16.5249 - val_loss: 366.1923\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.4916 - val_loss: 366.6448\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.4606 - val_loss: 367.0840\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.4315 - val_loss: 367.5103\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.4044 - val_loss: 367.9236\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3792 - val_loss: 368.3246\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3555 - val_loss: 368.7129\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3334 - val_loss: 369.0894\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.3129 - val_loss: 369.4541\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2937 - val_loss: 369.8071\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2758 - val_loss: 370.1484\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2592 - val_loss: 370.4785\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2437 - val_loss: 370.7979\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2293 - val_loss: 371.1065\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2159 - val_loss: 371.4047\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2034 - val_loss: 371.6926\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1918 - val_loss: 371.9704\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 16.1811 - val_loss: 372.2388\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1710 - val_loss: 372.4972\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1617 - val_loss: 372.7465\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1531 - val_loss: 372.9870\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1451 - val_loss: 373.2187\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1377 - val_loss: 373.4414\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1308 - val_loss: 373.6560\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1244 - val_loss: 373.8619\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1186 - val_loss: 374.0605\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1131 - val_loss: 374.2514\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1080 - val_loss: 374.4346\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1034 - val_loss: 374.6108\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0990 - val_loss: 374.7795\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0951 - val_loss: 374.9417\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0914 - val_loss: 375.0974\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0880 - val_loss: 375.2467\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0848 - val_loss: 375.3895\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0819 - val_loss: 375.5266\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0793 - val_loss: 375.6578\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0768 - val_loss: 375.7832\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.0745 - val_loss: 375.9035\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0724 - val_loss: 376.0182\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0705 - val_loss: 376.1280\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0688 - val_loss: 376.2331\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.0671 - val_loss: 376.3333\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0657 - val_loss: 376.4293\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0643 - val_loss: 376.5207\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0631 - val_loss: 376.6076\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0619 - val_loss: 376.6904\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0609 - val_loss: 376.7693\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0600 - val_loss: 376.8447\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0592 - val_loss: 376.9165\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0584 - val_loss: 376.9847\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0577 - val_loss: 377.0491\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.0571 - val_loss: 377.1110\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0565 - val_loss: 377.1695\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0560 - val_loss: 377.2251\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 16.0556 - val_loss: 377.2779\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0552 - val_loss: 377.3278\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0549 - val_loss: 377.3757\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0546 - val_loss: 377.4206\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0544 - val_loss: 377.4634\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0541 - val_loss: 377.5038\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0540 - val_loss: 377.5419\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0538 - val_loss: 377.5778\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0538 - val_loss: 377.6124\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0537 - val_loss: 377.6448\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0536 - val_loss: 377.6753\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0536 - val_loss: 377.7039\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0536 - val_loss: 377.7310\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0536 - val_loss: 377.7567\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0537 - val_loss: 377.7807\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0537 - val_loss: 377.8035\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0538 - val_loss: 377.8248\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0539 - val_loss: 377.8451\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 16.0540 - val_loss: 377.8637\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0542 - val_loss: 377.8818\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0543 - val_loss: 377.8984\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0545 - val_loss: 377.9142\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0547 - val_loss: 377.9288\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0549 - val_loss: 377.9423\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0551 - val_loss: 377.9556\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.0553 - val_loss: 377.9674\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.0555 - val_loss: 377.9786\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.0557 - val_loss: 377.9890\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.0559 - val_loss: 377.9987\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0562 - val_loss: 378.0076\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0565 - val_loss: 378.0161\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0567 - val_loss: 378.0239\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0570 - val_loss: 378.0311\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0573 - val_loss: 378.0376\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0576 - val_loss: 378.0439\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.0579 - val_loss: 378.0498\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0582 - val_loss: 378.0553\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0584 - val_loss: 378.0602\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0587 - val_loss: 378.0647\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0590 - val_loss: 378.0686\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0593 - val_loss: 378.0725\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0596 - val_loss: 378.0759\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0599 - val_loss: 378.0789\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0603 - val_loss: 378.0818\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0606 - val_loss: 378.0845\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0609 - val_loss: 378.0870\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0613 - val_loss: 378.0894\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0616 - val_loss: 378.0912\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0619 - val_loss: 378.0928\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0622 - val_loss: 378.0944\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0626 - val_loss: 378.0958\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 16.0629 - val_loss: 378.0971\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0632 - val_loss: 378.0979\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0636 - val_loss: 378.0986\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0639 - val_loss: 378.0994\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0642 - val_loss: 378.0997\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0646 - val_loss: 378.1000\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0649 - val_loss: 378.1002\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 16.0652 - val_loss: 378.1006\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0656 - val_loss: 378.1008\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0659 - val_loss: 378.1007\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0662 - val_loss: 378.1006\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0666 - val_loss: 378.1003\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0669 - val_loss: 378.0999\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0672 - val_loss: 378.0996\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0676 - val_loss: 378.0994\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0679 - val_loss: 378.0991\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0683 - val_loss: 378.0989\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0686 - val_loss: 378.0987\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0689 - val_loss: 378.0981\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0692 - val_loss: 378.0977\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0695 - val_loss: 378.0970\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0699 - val_loss: 378.0963\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0702 - val_loss: 378.0959\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 16.0705 - val_loss: 378.0951\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0709 - val_loss: 378.0945\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0712 - val_loss: 378.0935\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0715 - val_loss: 378.0930\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0718 - val_loss: 378.0919\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0722 - val_loss: 378.0915\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0724 - val_loss: 378.0906\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0728 - val_loss: 378.0898\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0731 - val_loss: 378.0891\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0734 - val_loss: 378.0879\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0737 - val_loss: 378.0872\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0740 - val_loss: 378.0863\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0744 - val_loss: 378.0860\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 16.0747 - val_loss: 378.0854\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.0750 - val_loss: 378.0845\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0753 - val_loss: 378.0839\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0755 - val_loss: 378.0828\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0759 - val_loss: 378.0823\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0761 - val_loss: 378.0815\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0764 - val_loss: 378.0809\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.0767 - val_loss: 378.0799\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.0770 - val_loss: 378.0789\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.0773 - val_loss: 378.0781\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0776 - val_loss: 378.0771\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0779 - val_loss: 378.0764\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.0782 - val_loss: 378.0757\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.0785 - val_loss: 378.0749\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0787 - val_loss: 378.0739\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0790 - val_loss: 378.0732\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0792 - val_loss: 378.0722\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0795 - val_loss: 378.0713\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0798 - val_loss: 378.0706\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0800 - val_loss: 378.0698\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0804 - val_loss: 378.0693\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0806 - val_loss: 378.0687\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0808 - val_loss: 378.0679\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0811 - val_loss: 378.0671\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0813 - val_loss: 378.0662\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0816 - val_loss: 378.0655\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 16.0818 - val_loss: 378.0646\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0821 - val_loss: 378.0640\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0824 - val_loss: 378.0633\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0826 - val_loss: 378.0626\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0828 - val_loss: 378.0619\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0830 - val_loss: 378.0608\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0833 - val_loss: 378.0602\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0836 - val_loss: 378.0596\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0838 - val_loss: 378.0592\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0840 - val_loss: 378.0582\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0842 - val_loss: 378.0576\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0845 - val_loss: 378.0569\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0847 - val_loss: 378.0563\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0849 - val_loss: 378.0557\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0851 - val_loss: 378.0547\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 16.0854 - val_loss: 378.0542\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0856 - val_loss: 378.0536\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0858 - val_loss: 378.0529\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0860 - val_loss: 378.0523\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0862 - val_loss: 378.0518\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0864 - val_loss: 378.0513\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0866 - val_loss: 378.0506\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0868 - val_loss: 378.0497\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0870 - val_loss: 378.0491\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0872 - val_loss: 378.0484\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0874 - val_loss: 378.0478\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0876 - val_loss: 378.0472\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0878 - val_loss: 378.0463\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 16.0880 - val_loss: 378.0461\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0882 - val_loss: 378.0458\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0883 - val_loss: 378.0451\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0885 - val_loss: 378.0444\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0887 - val_loss: 378.0437\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0889 - val_loss: 378.0433\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0891 - val_loss: 378.0423\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 362ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.84298086e+01, 6.83989963e+01, 6.83681839e+01, 6.83373716e+01,\n",
       "        6.83065593e+01, 6.82757470e+01, 6.82449346e+01, 6.82141223e+01,\n",
       "        6.81772409e+01, 6.81352241e+01, 6.80932073e+01, 6.80511905e+01,\n",
       "        6.80091737e+01, 6.79671569e+01, 6.79251401e+01, 6.78831232e+01,\n",
       "        6.78411064e+01, 6.77990896e+01, 6.77570728e+01, 6.77150560e+01,\n",
       "        6.76730392e+01, 6.76310224e+01, 6.75890056e+01, 6.75469888e+01,\n",
       "        6.75049720e+01, 6.74629552e+01, 6.74209384e+01, 6.73789216e+01,\n",
       "        6.73369048e+01, 6.72948880e+01, 6.72528712e+01, 6.72108543e+01,\n",
       "        6.71688375e+01, 6.71268207e+01, 6.70848039e+01, 6.70427871e+01,\n",
       "        6.70007703e+01, 6.69587535e+01, 6.69167367e+01, 6.68747199e+01,\n",
       "        6.68327031e+01, 6.67906863e+01, 6.67486695e+01, 6.67066527e+01,\n",
       "        6.66811391e+01, 6.66587302e+01, 6.66363212e+01, 6.98908030e+01,\n",
       "        6.98739963e+01, 6.98571895e+01, 6.98403828e+01, 6.98235761e+01,\n",
       "        6.98067694e+01, 6.97899627e+01, 6.97731559e+01, 6.97563492e+01,\n",
       "        6.97395425e+01, 6.97227358e+01, 6.97059290e+01, 6.96782446e+01,\n",
       "        6.96446312e+01, 6.96110177e+01, 6.95774043e+01, 6.95443791e+01,\n",
       "        6.95110177e+01, 6.94776564e+01, 6.94432951e+01, 6.94109337e+01,\n",
       "        6.93775724e+01, 6.93442110e+01, 6.93084967e+01, 6.92309290e+01,\n",
       "        6.91384921e+01, 7.52695465e+01, 0.00000000e+00, 5.29040690e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.34659462e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.08990288e-01, 0.00000000e+00, 8.26832712e-01, 4.36887413e-01,\n",
       "        2.03557104e-01, 9.94954258e-03, 0.00000000e+00, 2.64017493e-01,\n",
       "        6.24333203e-01, 1.99805155e-01, 0.00000000e+00, 2.44547352e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.39340758e-02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65.17696078, 65.17042484, 65.16388889, 65.15735294, 65.15081699,\n",
       "       65.14428105, 65.1377451 , 65.13120915, 65.1246732 , 65.11813725,\n",
       "       65.11160131, 65.10506536, 65.09768908, 65.0874183 , 65.07714753,\n",
       "       65.06687675, 65.05660598, 65.0463352 , 65.03606443, 65.02579365,\n",
       "       65.01552288, 65.0052521 , 64.99498133, 64.98471055, 64.97443978,\n",
       "       64.964169  , 64.95389823, 64.94362745, 64.93335668, 64.9230859 ,\n",
       "       64.91281513, 64.90254435, 64.89227358, 64.8820028 , 64.87173203,\n",
       "       64.86146125, 64.85119048, 64.8409197 , 64.83064893, 64.82037815,\n",
       "       64.81010738, 64.7998366 , 64.78956583, 64.77929505, 64.76902428,\n",
       "       64.7587535 , 64.74848273, 64.73821195, 64.72794118, 64.7176704 ,\n",
       "       64.70739963, 64.69712885, 64.68685808, 64.6765873 , 64.66631653,\n",
       "       64.65604575, 64.64577498, 64.6355042 , 64.62523343, 64.61496265,\n",
       "       64.60469188, 64.5944211 , 64.58415033, 64.57387955, 64.56360878,\n",
       "       64.553338  , 64.54306723, 64.53279645, 64.52252568, 64.5122549 ,\n",
       "       64.50198413, 64.49171335, 64.48144258, 64.4711718 , 64.46090103,\n",
       "       64.45063025, 64.44035948, 64.4300887 , 64.41981793, 64.40954715,\n",
       "       64.39927638, 64.3890056 , 64.37873483, 64.36846405, 64.35819328,\n",
       "       64.3479225 , 64.33765173, 64.32738095, 64.31711018, 64.3068394 ,\n",
       "       64.29656863, 64.28629785, 64.27602708, 64.2657563 , 64.25548553,\n",
       "       64.24521475, 64.23494398, 64.2246732 , 64.21440243, 64.20413165])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.26608130444668\n",
      "18.670770939655\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
