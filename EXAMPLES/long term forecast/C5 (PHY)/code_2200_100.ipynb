{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2295    61.216725\n",
       "2296    61.208800\n",
       "2297    61.200874\n",
       "2298    61.192949\n",
       "2299    61.185024\n",
       "Name: C5, Length: 2300, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_2200_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "2195     0.267281\n",
       "2196     0.000000\n",
       "2197     0.000000\n",
       "2198     0.187532\n",
       "2199     0.000000\n",
       "Name: C5, Length: 2200, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2200)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750, 1, 251) (1750, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/22 [==============================] - 2s 26ms/step - loss: 5081.5620 - val_loss: 3276.1453\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4901.1787 - val_loss: 3121.3779\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4806.1196 - val_loss: 3072.7192\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4736.7998 - val_loss: 3027.3110\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4669.0088 - val_loss: 2983.0276\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4602.4702 - val_loss: 2939.6248\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4536.9692 - val_loss: 2896.9924\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4472.3838 - val_loss: 2855.0674\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4408.6431 - val_loss: 2813.8123\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 4345.6978 - val_loss: 2773.1992\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4283.5176 - val_loss: 2733.2092\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4222.0771 - val_loss: 2693.8269\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4161.3574 - val_loss: 2655.0388\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 4101.3413 - val_loss: 2616.8345\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4042.0171 - val_loss: 2579.2043\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3983.3721 - val_loss: 2542.1396\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3925.3965 - val_loss: 2505.6333\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3868.0808 - val_loss: 2469.6775\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3811.4175 - val_loss: 2434.2656\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3755.3965 - val_loss: 2399.3918\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3700.0132 - val_loss: 2365.0496\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3645.2593 - val_loss: 2331.2332\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3591.1272 - val_loss: 2297.9370\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3537.6111 - val_loss: 2265.1558\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3484.7053 - val_loss: 2232.8840\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3432.4038 - val_loss: 2201.1167\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3380.7007 - val_loss: 2169.8496\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3329.5911 - val_loss: 2139.0767\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3279.0679 - val_loss: 2108.7935\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3229.1265 - val_loss: 2078.9951\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3179.7617 - val_loss: 2049.6780\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3130.9692 - val_loss: 2020.8365\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 3082.7424 - val_loss: 1992.4663\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3035.0774 - val_loss: 1964.5634\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2987.9695 - val_loss: 1937.1230\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2941.4131 - val_loss: 1910.1409\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2895.4033 - val_loss: 1883.6129\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2849.9365 - val_loss: 1857.5344\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2805.0076 - val_loss: 1831.9020\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2760.6116 - val_loss: 1806.7111\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2716.7449 - val_loss: 1781.9575\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2673.4021 - val_loss: 1757.6368\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2630.5793 - val_loss: 1733.7458\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2588.2722 - val_loss: 1710.2797\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2546.4763 - val_loss: 1687.2350\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2505.1877 - val_loss: 1664.6073\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2464.4021 - val_loss: 1642.3925\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2424.1145 - val_loss: 1620.5869\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2384.3223 - val_loss: 1599.1863\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2345.0205 - val_loss: 1578.1851\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2306.2051 - val_loss: 1557.5764\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2267.8721 - val_loss: 1537.3429\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2230.0176 - val_loss: 1517.1069\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2185.5415 - val_loss: 1492.2010\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2140.8071 - val_loss: 1469.8199\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2098.5225 - val_loss: 1448.6555\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2057.9456 - val_loss: 1428.3934\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2018.6193 - val_loss: 1408.8602\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1980.2966 - val_loss: 1389.9583\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1942.8368 - val_loss: 1371.6281\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1906.1500 - val_loss: 1353.8281\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1870.1736 - val_loss: 1336.5280\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1834.8611 - val_loss: 1319.7042\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1800.1787 - val_loss: 1303.3383\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1766.0973 - val_loss: 1287.4148\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1732.5946 - val_loss: 1271.9200\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1699.6515 - val_loss: 1256.8429\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1667.2512 - val_loss: 1242.1732\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1635.3788 - val_loss: 1227.9015\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1604.0217 - val_loss: 1214.0194\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1573.1697 - val_loss: 1200.5194\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1542.8109 - val_loss: 1187.3944\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1512.9363 - val_loss: 1174.6377\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1483.5371 - val_loss: 1162.2424\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1454.6056 - val_loss: 1150.2031\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1426.1335 - val_loss: 1138.5142\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1398.1146 - val_loss: 1127.1694\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1370.5406 - val_loss: 1116.1643\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1343.4064 - val_loss: 1105.4932\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1316.7053 - val_loss: 1095.1515\n",
      "Epoch 81/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1290.4316 - val_loss: 1085.1338\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1264.5791 - val_loss: 1075.4358\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1239.1427 - val_loss: 1066.0530\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1214.1168 - val_loss: 1056.9811\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1189.4967 - val_loss: 1048.2150\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1165.2771 - val_loss: 1039.7507\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1141.4532 - val_loss: 1031.5842\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1118.0203 - val_loss: 1023.7112\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1094.9736 - val_loss: 1016.1273\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1072.3091 - val_loss: 1008.8290\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1050.0216 - val_loss: 1001.8118\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1028.1072 - val_loss: 995.0720\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1006.5613 - val_loss: 988.6053\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 985.3800 - val_loss: 982.4082\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 964.5592 - val_loss: 976.4771\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 944.0943 - val_loss: 970.8074\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 923.9820 - val_loss: 965.3960\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 904.2177 - val_loss: 960.2388\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 884.7977 - val_loss: 955.3323\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 865.7181 - val_loss: 950.6726\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 846.9753 - val_loss: 946.2560\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 828.5652 - val_loss: 942.0792\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 810.4842 - val_loss: 938.1385\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 792.7288 - val_loss: 934.4296\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 775.2946 - val_loss: 930.9500\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 758.1788 - val_loss: 927.6953\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 741.3772 - val_loss: 924.6623\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 724.8863 - val_loss: 921.8474\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 708.7026 - val_loss: 919.2471\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 692.8226 - val_loss: 916.8577\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 677.2430 - val_loss: 914.6759\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 661.9600 - val_loss: 912.6981\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 646.9703 - val_loss: 910.9208\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 632.2700 - val_loss: 909.3408\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 617.8562 - val_loss: 907.9543\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 603.7253 - val_loss: 906.7581\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 589.8743 - val_loss: 905.7486\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 576.2991 - val_loss: 904.9225\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 562.9970 - val_loss: 904.2762\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 549.9643 - val_loss: 903.8065\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 537.1976 - val_loss: 903.5099\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 524.6935 - val_loss: 903.3831\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 512.4492 - val_loss: 903.4225\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 500.4611 - val_loss: 903.6248\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 488.7263 - val_loss: 903.9868\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 477.2413 - val_loss: 904.5050\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 466.0024 - val_loss: 905.1760\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 455.0070 - val_loss: 905.9965\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 444.2518 - val_loss: 906.9633\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 433.7331 - val_loss: 908.0729\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 423.4483 - val_loss: 909.3219\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 413.3940 - val_loss: 910.7072\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 403.5670 - val_loss: 912.2253\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 393.9639 - val_loss: 913.8731\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 384.5820 - val_loss: 915.6472\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 375.4182 - val_loss: 917.5441\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 366.4691 - val_loss: 919.5609\n",
      "Epoch 138/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 357.7317 - val_loss: 921.6939\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 349.2026 - val_loss: 923.9406\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 340.8790 - val_loss: 926.2968\n",
      "Epoch 141/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 332.7580 - val_loss: 928.7599\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 324.8362 - val_loss: 931.3264\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 317.1107 - val_loss: 933.9931\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 309.5784 - val_loss: 936.7571\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 302.2362 - val_loss: 939.6147\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 295.0810 - val_loss: 942.5631\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 288.1102 - val_loss: 945.5989\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 281.3206 - val_loss: 948.7191\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 274.7088 - val_loss: 951.9205\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 268.2722 - val_loss: 955.2000\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 262.0079 - val_loss: 958.5544\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 255.9128 - val_loss: 961.9808\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.9839 - val_loss: 965.4757\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 244.2187 - val_loss: 969.0364\n",
      "Epoch 155/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 238.6136 - val_loss: 972.6600\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 233.1661 - val_loss: 976.3428\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 227.8736 - val_loss: 980.0825\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 222.7328 - val_loss: 983.8757\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 217.7408 - val_loss: 987.7193\n",
      "Epoch 160/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 212.8951 - val_loss: 991.6108\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 208.1927 - val_loss: 995.5471\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 203.6307 - val_loss: 999.5253\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 199.2064 - val_loss: 1003.5424\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 194.9170 - val_loss: 1007.5956\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 190.7598 - val_loss: 1011.6823\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 186.7321 - val_loss: 1015.7991\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 182.8310 - val_loss: 1019.9437\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 179.0541 - val_loss: 1024.1135\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 175.3983 - val_loss: 1028.3055\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 171.8613 - val_loss: 1032.5171\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 168.4404 - val_loss: 1036.7452\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 165.1329 - val_loss: 1040.9879\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 161.9363 - val_loss: 1045.2423\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 158.8480 - val_loss: 1049.5056\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 155.8655 - val_loss: 1053.7755\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 152.9860 - val_loss: 1058.0497\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 150.2071 - val_loss: 1062.3260\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 147.5264 - val_loss: 1066.6012\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 144.9416 - val_loss: 1070.8738\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 142.4500 - val_loss: 1075.1405\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 140.0493 - val_loss: 1079.3999\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 137.7373 - val_loss: 1083.6493\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 135.5115 - val_loss: 1087.8866\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 133.3696 - val_loss: 1092.1099\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 131.3092 - val_loss: 1096.3169\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 129.3282 - val_loss: 1100.5054\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 127.4243 - val_loss: 1104.6733\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 125.5955 - val_loss: 1108.8191\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 123.8393 - val_loss: 1112.9406\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 122.1537 - val_loss: 1117.0359\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 120.5368 - val_loss: 1121.1035\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 118.9862 - val_loss: 1125.1415\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 117.5001 - val_loss: 1129.1479\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 116.0763 - val_loss: 1133.1218\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 114.7129 - val_loss: 1137.0610\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.4081 - val_loss: 1140.9640\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.1599 - val_loss: 1144.8287\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 110.9665 - val_loss: 1148.6554\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 109.8258 - val_loss: 1152.4413\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 108.7363 - val_loss: 1156.1857\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 107.6961 - val_loss: 1159.8870\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 106.7035 - val_loss: 1163.5443\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 105.7567 - val_loss: 1167.1561\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 104.8544 - val_loss: 1170.7219\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 103.9945 - val_loss: 1174.2400\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 103.1758 - val_loss: 1177.7096\n",
      "Epoch 207/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 102.3966 - val_loss: 1181.1301\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 101.6554 - val_loss: 1184.5009\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 100.9507 - val_loss: 1187.8203\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 100.2811 - val_loss: 1191.0885\n",
      "Epoch 211/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 99.6452 - val_loss: 1194.3046\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 99.0416 - val_loss: 1197.4675\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 98.4691 - val_loss: 1200.5770\n",
      "Epoch 214/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 97.9263 - val_loss: 1203.6327\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 97.4119 - val_loss: 1206.6343\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 96.9248 - val_loss: 1209.5811\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 96.4637 - val_loss: 1212.4723\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 96.0276 - val_loss: 1215.3092\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 95.6153 - val_loss: 1218.0895\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 95.2257 - val_loss: 1220.8145\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 94.8579 - val_loss: 1223.4836\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 94.5107 - val_loss: 1226.0972\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 94.1833 - val_loss: 1228.6544\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 93.8747 - val_loss: 1231.1565\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 93.5839 - val_loss: 1233.6023\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 93.3101 - val_loss: 1235.9928\n",
      "Epoch 227/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 93.0525 - val_loss: 1238.3281\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 92.8102 - val_loss: 1240.6077\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 92.5825 - val_loss: 1242.8322\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 92.3687 - val_loss: 1245.0027\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 92.1679 - val_loss: 1247.1185\n",
      "Epoch 232/500\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 91.9796 - val_loss: 1249.1802\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 91.8031 - val_loss: 1251.1893\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 91.6376 - val_loss: 1253.1454\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 91.4826 - val_loss: 1255.0491\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 91.3376 - val_loss: 1256.9004\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 91.2019 - val_loss: 1258.7006\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 91.0751 - val_loss: 1260.4503\n",
      "Epoch 239/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 90.9566 - val_loss: 1262.1495\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 90.8460 - val_loss: 1263.7997\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 90.7427 - val_loss: 1265.4015\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 90.6464 - val_loss: 1266.9543\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 90.5566 - val_loss: 1268.4606\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 90.4730 - val_loss: 1269.9198\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 90.3952 - val_loss: 1271.3336\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 90.3227 - val_loss: 1272.7021\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 90.2553 - val_loss: 1274.0267\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 90.1927 - val_loss: 1275.3074\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 90.1345 - val_loss: 1276.5458\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 90.0805 - val_loss: 1277.7426\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 90.0303 - val_loss: 1278.8992\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.9838 - val_loss: 1280.0153\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.9407 - val_loss: 1281.0922\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.9007 - val_loss: 1282.1312\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.8637 - val_loss: 1283.1323\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.8295 - val_loss: 1284.0977\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 89.7977 - val_loss: 1285.0265\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.7684 - val_loss: 1285.9215\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.7413 - val_loss: 1286.7825\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.7163 - val_loss: 1287.6107\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.6931 - val_loss: 1288.4062\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.6718 - val_loss: 1289.1713\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.6521 - val_loss: 1289.9058\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.6339 - val_loss: 1290.6111\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.6171 - val_loss: 1291.2875\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.6017 - val_loss: 1291.9362\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.5875 - val_loss: 1292.5587\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.5743 - val_loss: 1293.1544\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.5623 - val_loss: 1293.7256\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.5512 - val_loss: 1294.2720\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.5410 - val_loss: 1294.7953\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.5316 - val_loss: 1295.2959\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.5229 - val_loss: 1295.7738\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 89.5150 - val_loss: 1296.2299\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.5077 - val_loss: 1296.6660\n",
      "Epoch 276/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.5010 - val_loss: 1297.0823\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4949 - val_loss: 1297.4792\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4893 - val_loss: 1297.8582\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4841 - val_loss: 1298.2189\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 89.4795 - val_loss: 1298.5634\n",
      "Epoch 281/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4751 - val_loss: 1298.8907\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4711 - val_loss: 1299.2028\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4675 - val_loss: 1299.4989\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4642 - val_loss: 1299.7811\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4612 - val_loss: 1300.0494\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4584 - val_loss: 1300.3047\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4559 - val_loss: 1300.5463\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4536 - val_loss: 1300.7759\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4516 - val_loss: 1300.9943\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4497 - val_loss: 1301.2009\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4480 - val_loss: 1301.3965\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4465 - val_loss: 1301.5824\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4450 - val_loss: 1301.7576\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4438 - val_loss: 1301.9240\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4427 - val_loss: 1302.0811\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4417 - val_loss: 1302.2300\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4408 - val_loss: 1302.3706\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4400 - val_loss: 1302.5042\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4393 - val_loss: 1302.6294\n",
      "Epoch 300/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4386 - val_loss: 1302.7478\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4381 - val_loss: 1302.8595\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4377 - val_loss: 1302.9656\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4373 - val_loss: 1303.0652\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 89.4369 - val_loss: 1303.1586\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4366 - val_loss: 1303.2467\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4364 - val_loss: 1303.3296\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4362 - val_loss: 1303.4078\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4361 - val_loss: 1303.4812\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4360 - val_loss: 1303.5502\n",
      "Epoch 310/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4360 - val_loss: 1303.6150\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4360 - val_loss: 1303.6764\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4360 - val_loss: 1303.7334\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4360 - val_loss: 1303.7874\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4361 - val_loss: 1303.8378\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4362 - val_loss: 1303.8848\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4363 - val_loss: 1303.9291\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4365 - val_loss: 1303.9700\n",
      "Epoch 318/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4367 - val_loss: 1304.0089\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4368 - val_loss: 1304.0453\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4371 - val_loss: 1304.0793\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4373 - val_loss: 1304.1110\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4375 - val_loss: 1304.1412\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4377 - val_loss: 1304.1686\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4380 - val_loss: 1304.1943\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4383 - val_loss: 1304.2186\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4385 - val_loss: 1304.2408\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 89.4388 - val_loss: 1304.2617\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4391 - val_loss: 1304.2811\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4394 - val_loss: 1304.2985\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4398 - val_loss: 1304.3152\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4401 - val_loss: 1304.3307\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4403 - val_loss: 1304.3451\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4407 - val_loss: 1304.3580\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4410 - val_loss: 1304.3700\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4414 - val_loss: 1304.3815\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4417 - val_loss: 1304.3922\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4420 - val_loss: 1304.4020\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4424 - val_loss: 1304.4113\n",
      "Epoch 339/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4426 - val_loss: 1304.4189\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4430 - val_loss: 1304.4269\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4433 - val_loss: 1304.4341\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4437 - val_loss: 1304.4407\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4440 - val_loss: 1304.4469\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4443 - val_loss: 1304.4523\n",
      "Epoch 345/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4447 - val_loss: 1304.4573\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4450 - val_loss: 1304.4619\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4454 - val_loss: 1304.4664\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4456 - val_loss: 1304.4698\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4460 - val_loss: 1304.4733\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 89.4463 - val_loss: 1304.4766\n",
      "Epoch 351/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4466 - val_loss: 1304.4794\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4469 - val_loss: 1304.4816\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4473 - val_loss: 1304.4836\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4475 - val_loss: 1304.4857\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4479 - val_loss: 1304.4874\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4482 - val_loss: 1304.4888\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4485 - val_loss: 1304.4900\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4488 - val_loss: 1304.4908\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4491 - val_loss: 1304.4923\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 89.4494 - val_loss: 1304.4935\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 89.4497 - val_loss: 1304.4941\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 89.4500 - val_loss: 1304.4948\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4502 - val_loss: 1304.4952\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 89.4505 - val_loss: 1304.4955\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4508 - val_loss: 1304.4965\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4511 - val_loss: 1304.4967\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4513 - val_loss: 1304.4972\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 89.4516 - val_loss: 1304.4969\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 89.4519 - val_loss: 1304.4968\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 89.4522 - val_loss: 1304.4976\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 89.4524 - val_loss: 1304.4968\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4526 - val_loss: 1304.4966\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4529 - val_loss: 1304.4965\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4531 - val_loss: 1304.4962\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4533 - val_loss: 1304.4960\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4536 - val_loss: 1304.4955\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4538 - val_loss: 1304.4949\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4540 - val_loss: 1304.4945\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4543 - val_loss: 1304.4939\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4545 - val_loss: 1304.4939\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4547 - val_loss: 1304.4938\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4549 - val_loss: 1304.4932\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4551 - val_loss: 1304.4930\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4553 - val_loss: 1304.4927\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4555 - val_loss: 1304.4916\n",
      "Epoch 386/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4558 - val_loss: 1304.4912\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4560 - val_loss: 1304.4906\n",
      "Epoch 388/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4562 - val_loss: 1304.4906\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4563 - val_loss: 1304.4902\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4565 - val_loss: 1304.4900\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4567 - val_loss: 1304.4895\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 89.4569 - val_loss: 1304.4897\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4570 - val_loss: 1304.4885\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4573 - val_loss: 1304.4882\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4575 - val_loss: 1304.4879\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4576 - val_loss: 1304.4872\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4577 - val_loss: 1304.4862\n",
      "Epoch 398/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4579 - val_loss: 1304.4858\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 89.4580 - val_loss: 1304.4852\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4582 - val_loss: 1304.4845\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4584 - val_loss: 1304.4843\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4585 - val_loss: 1304.4839\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4587 - val_loss: 1304.4832\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4588 - val_loss: 1304.4825\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4590 - val_loss: 1304.4828\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4591 - val_loss: 1304.4825\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4592 - val_loss: 1304.4817\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4594 - val_loss: 1304.4813\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4595 - val_loss: 1304.4808\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4596 - val_loss: 1304.4805\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4597 - val_loss: 1304.4805\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4598 - val_loss: 1304.4797\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4599 - val_loss: 1304.4791\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 89.4601 - val_loss: 1304.4779\n",
      "Epoch 415/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4602 - val_loss: 1304.4769\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4603 - val_loss: 1304.4769\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4605 - val_loss: 1304.4769\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4606 - val_loss: 1304.4766\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4607 - val_loss: 1304.4766\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4608 - val_loss: 1304.4762\n",
      "Epoch 421/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4609 - val_loss: 1304.4762\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4610 - val_loss: 1304.4761\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4611 - val_loss: 1304.4756\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4612 - val_loss: 1304.4752\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4613 - val_loss: 1304.4753\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4613 - val_loss: 1304.4749\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4614 - val_loss: 1304.4742\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4616 - val_loss: 1304.4741\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4616 - val_loss: 1304.4738\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4618 - val_loss: 1304.4736\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4618 - val_loss: 1304.4736\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4619 - val_loss: 1304.4734\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4619 - val_loss: 1304.4725\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4620 - val_loss: 1304.4725\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 89.4621 - val_loss: 1304.4719\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4622 - val_loss: 1304.4716\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4623 - val_loss: 1304.4716\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4623 - val_loss: 1304.4709\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4624 - val_loss: 1304.4707\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4625 - val_loss: 1304.4709\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4625 - val_loss: 1304.4703\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4626 - val_loss: 1304.4698\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4627 - val_loss: 1304.4698\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4628 - val_loss: 1304.4695\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4629 - val_loss: 1304.4691\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4629 - val_loss: 1304.4686\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4630 - val_loss: 1304.4684\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4630 - val_loss: 1304.4681\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4631 - val_loss: 1304.4681\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4631 - val_loss: 1304.4678\n",
      "Epoch 451/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4632 - val_loss: 1304.4678\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4633 - val_loss: 1304.4675\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4633 - val_loss: 1304.4675\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4634 - val_loss: 1304.4674\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4634 - val_loss: 1304.4674\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 89.4634 - val_loss: 1304.4670\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4635 - val_loss: 1304.4670\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4636 - val_loss: 1304.4670\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4636 - val_loss: 1304.4673\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4636 - val_loss: 1304.4668\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4636 - val_loss: 1304.4663\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4637 - val_loss: 1304.4662\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4637 - val_loss: 1304.4659\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4638 - val_loss: 1304.4658\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4638 - val_loss: 1304.4657\n",
      "Epoch 466/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4639 - val_loss: 1304.4656\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4639 - val_loss: 1304.4650\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4640 - val_loss: 1304.4650\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4640 - val_loss: 1304.4650\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4641 - val_loss: 1304.4656\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4641 - val_loss: 1304.4655\n",
      "Epoch 472/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4641 - val_loss: 1304.4650\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4641 - val_loss: 1304.4646\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4641 - val_loss: 1304.4639\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 89.4642 - val_loss: 1304.4642\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 89.4643 - val_loss: 1304.4646\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 89.4643 - val_loss: 1304.4646\n",
      "Epoch 478/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 89.4643 - val_loss: 1304.4646\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 89.4643 - val_loss: 1304.4636\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 89.4644 - val_loss: 1304.4636\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 89.4644 - val_loss: 1304.4633\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 89.4644 - val_loss: 1304.4633\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 89.4645 - val_loss: 1304.4633\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 89.4644 - val_loss: 1304.4633\n",
      "Epoch 485/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 89.4645 - val_loss: 1304.4630\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4646 - val_loss: 1304.4630\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 89.4646 - val_loss: 1304.4634\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4646 - val_loss: 1304.4634\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4646 - val_loss: 1304.4633\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4646 - val_loss: 1304.4631\n",
      "Epoch 491/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 89.4647 - val_loss: 1304.4629\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4647 - val_loss: 1304.4626\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4647 - val_loss: 1304.4623\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4647 - val_loss: 1304.4620\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4647 - val_loss: 1304.4619\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4648 - val_loss: 1304.4615\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4648 - val_loss: 1304.4613\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.4648 - val_loss: 1304.4619\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4648 - val_loss: 1304.4612\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 89.4648 - val_loss: 1304.4607\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 372ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.73509104e+01, 6.72248599e+01, 6.70988095e+01, 6.69727591e+01,\n",
       "        6.68467087e+01, 6.67206583e+01, 6.66437909e+01, 0.00000000e+00,\n",
       "        1.32437230e-01, 1.37314040e-01, 0.00000000e+00, 2.63236790e-01,\n",
       "        2.09523500e-01, 6.84298086e+01, 6.83373716e+01, 6.82449346e+01,\n",
       "        6.81352241e+01, 6.80091737e+01, 6.79131232e+01, 6.77570728e+01,\n",
       "        6.76310224e+01, 6.75054972e+01, 6.73789216e+01, 6.72528712e+01,\n",
       "        6.71268207e+01, 6.70007703e+01, 6.68747199e+01, 6.67486695e+01,\n",
       "        6.66587302e+01, 6.98739963e+01, 6.98235761e+01, 6.97731559e+01,\n",
       "        6.97227358e+01, 6.96446312e+01, 6.95443791e+01, 6.94432951e+01,\n",
       "        6.93442110e+01, 6.91384921e+01, 5.29040690e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.08990288e-01, 4.36887413e-01, 0.00000000e+00,\n",
       "        1.99805155e-01, 0.00000000e+00, 1.39340760e-02, 6.70287815e+01,\n",
       "        6.69027311e+01, 6.67766807e+01, 6.66736695e+01, 6.98852007e+01,\n",
       "        6.98347806e+01, 6.97836040e+01, 6.97339402e+01, 6.96670402e+01,\n",
       "        6.95661998e+01, 6.94653595e+01, 6.93664519e+01, 6.92001167e+01,\n",
       "        7.40804970e-01, 0.00000000e+00, 6.97040616e+01, 6.96072829e+01,\n",
       "        6.95064426e+01, 6.94056022e+01, 6.93067619e+01, 6.90357843e+01,\n",
       "        6.87584734e+01, 6.84811625e+01, 6.82038515e+01, 0.00000000e+00,\n",
       "        6.37347620e-02, 5.86339149e+01, 9.36521947e-01, 0.00000000e+00,\n",
       "        6.61817640e-02, 0.00000000e+00, 5.43199718e-01, 4.57491755e-01,\n",
       "        6.72341232e+01, 0.00000000e+00, 6.92671001e-01, 0.00000000e+00,\n",
       "        8.96960720e-02, 0.00000000e+00, 6.56537831e-01, 0.00000000e+00,\n",
       "        1.34843394e-01, 0.00000000e+00, 1.07352018e+00, 1.11613326e-01,\n",
       "        0.00000000e+00, 3.57472718e-01, 1.43053502e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61.96961126, 61.96168614, 61.95376102, 61.9458359 , 61.93791077,\n",
       "       61.92998565, 61.92206053, 61.91413541, 61.90621029, 61.89828517,\n",
       "       61.89036005, 61.88243493, 61.8745098 , 61.86658468, 61.85865956,\n",
       "       61.85073444, 61.84280932, 61.8348842 , 61.82695908, 61.81903396,\n",
       "       61.81110883, 61.80318371, 61.79525859, 61.78733347, 61.77940835,\n",
       "       61.77148323, 61.76355811, 61.75563298, 61.74770786, 61.73978274,\n",
       "       61.73185762, 61.7239325 , 61.71600738, 61.70808226, 61.70015714,\n",
       "       61.69223201, 61.68430689, 61.67638177, 61.66845665, 61.66053153,\n",
       "       61.65260641, 61.64468129, 61.63675617, 61.62883104, 61.62090592,\n",
       "       61.6129808 , 61.60505568, 61.59713056, 61.58920544, 61.58128032,\n",
       "       61.5733552 , 61.56543007, 61.55750495, 61.54957983, 61.54165471,\n",
       "       61.53372959, 61.52580447, 61.51787935, 61.50995423, 61.5020291 ,\n",
       "       61.49410398, 61.48617886, 61.47825374, 61.47032862, 61.4624035 ,\n",
       "       61.45447838, 61.44655326, 61.43862813, 61.43070301, 61.42277789,\n",
       "       61.41485277, 61.40692765, 61.39900253, 61.39107741, 61.38315229,\n",
       "       61.37522716, 61.36730204, 61.35937692, 61.3514518 , 61.34352668,\n",
       "       61.33560156, 61.32767644, 61.31975132, 61.31182619, 61.30390107,\n",
       "       61.29597595, 61.28805083, 61.28012571, 61.27220059, 61.26427547,\n",
       "       61.25635035, 61.24842522, 61.2405001 , 61.23257498, 61.22464986,\n",
       "       61.21672474, 61.20879962, 61.2008745 , 61.19294937, 61.18502425])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.95483147913037\n",
      "30.655611874260465\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
