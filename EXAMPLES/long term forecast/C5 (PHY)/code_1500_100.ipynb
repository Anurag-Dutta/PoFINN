{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "1595    65.919234\n",
       "1596    65.911765\n",
       "1597    65.904295\n",
       "1598    65.899603\n",
       "1599    65.898669\n",
       "Name: C5, Length: 1600, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c5_interpolated_1500_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89.140000\n",
       "1       88.911429\n",
       "2       88.682857\n",
       "3       88.454286\n",
       "4       88.225714\n",
       "          ...    \n",
       "1495    66.666200\n",
       "1496    66.658730\n",
       "1497    66.651261\n",
       "1498    66.643791\n",
       "1499    66.636321\n",
       "Name: C5, Length: 1500, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1500)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.140000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.911429</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.682857</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.454286</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.225714</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     89.140000  0.000298\n",
       "1     88.911429  0.000298\n",
       "2     88.682857  0.000297\n",
       "3     88.454286  0.000297\n",
       "4     88.225714  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 86.8407  # Value for C0\n",
    "K0 = -0.0015  # Value for K0\n",
    "K1 = -0.0001  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0118    # Value for b\n",
    "c = 2.5775    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    89.140000    88.911429    88.682857    88.454286    88.225714   \n",
      "351    88.911429    88.682857    88.454286    88.225714    87.997143   \n",
      "352    88.682857    88.454286    88.225714    87.997143    87.768571   \n",
      "353    88.454286    88.225714    87.997143    87.768571    87.540000   \n",
      "354    88.225714    87.997143    87.768571    87.540000    87.311429   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.997143    87.768571    87.540000    87.311429    87.095798  ...   \n",
      "351    87.768571    87.540000    87.311429    87.095798    87.039776  ...   \n",
      "352    87.540000    87.311429    87.095798    87.039776    86.983754  ...   \n",
      "353    87.311429    87.095798    87.039776    86.983754    86.927731  ...   \n",
      "354    87.095798    87.039776    86.983754    86.927731    86.871709  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   79.161181    0.000263   79.132236    0.000263   79.103291    0.000263   \n",
      "351   79.132236    0.000263   79.103291    0.000263   79.074346    0.000262   \n",
      "352   79.103291    0.000263   79.074346    0.000262   79.045401    0.000262   \n",
      "353   79.074346    0.000262   79.045401    0.000262   79.016457    0.000262   \n",
      "354   79.045401    0.000262   79.016457    0.000262   78.987512    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   79.074346    0.000262   79.045401    0.000262  \n",
      "351   79.045401    0.000262   79.016457    0.000262  \n",
      "352   79.016457    0.000262   78.987512    0.000262  \n",
      "353   78.987512    0.000262   78.958567    0.000262  \n",
      "354   78.958567    0.000262   78.929622    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 1, 251) (1050, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "14/14 [==============================] - 3s 40ms/step - loss: 5644.9487 - val_loss: 4718.6875\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5586.4585 - val_loss: 4678.8770\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5542.9966 - val_loss: 4638.9897\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5499.6548 - val_loss: 4599.3623\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5456.6055 - val_loss: 4560.0269\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5413.8555 - val_loss: 4520.9746\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5371.3921 - val_loss: 4482.1934\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5329.2070 - val_loss: 4443.6748\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5287.2900 - val_loss: 4405.4116\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5245.6348 - val_loss: 4367.3994\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5204.2344 - val_loss: 4329.6357\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5163.0903 - val_loss: 4292.1157\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5122.1973 - val_loss: 4254.8379\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5081.5508 - val_loss: 4217.7983\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5041.1504 - val_loss: 4180.9976\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5000.9946 - val_loss: 4144.4316\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4961.0806 - val_loss: 4108.1006\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4921.4067 - val_loss: 4072.0015\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4881.9722 - val_loss: 4036.1345\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4842.7739 - val_loss: 4000.4958\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 4803.8125 - val_loss: 3965.0864\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4765.0859 - val_loss: 3929.9038\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4726.5918 - val_loss: 3894.9470\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4688.3291 - val_loss: 3860.2139\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4650.2979 - val_loss: 3825.7051\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4612.4956 - val_loss: 3791.4180\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4574.9219 - val_loss: 3757.3518\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4537.5762 - val_loss: 3723.5049\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4500.4546 - val_loss: 3689.8774\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4463.5581 - val_loss: 3656.4675\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4426.8862 - val_loss: 3623.2732\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4390.4360 - val_loss: 3590.2952\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4354.2080 - val_loss: 3557.5312\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4318.1992 - val_loss: 3524.9807\n",
      "Epoch 35/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4282.4111 - val_loss: 3492.6416\n",
      "Epoch 36/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4246.8403 - val_loss: 3460.5146\n",
      "Epoch 37/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4211.4863 - val_loss: 3428.5974\n",
      "Epoch 38/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4176.3486 - val_loss: 3396.8889\n",
      "Epoch 39/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4141.4263 - val_loss: 3365.3894\n",
      "Epoch 40/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4106.7183 - val_loss: 3334.0964\n",
      "Epoch 41/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4072.2227 - val_loss: 3303.0095\n",
      "Epoch 42/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4037.9404 - val_loss: 3272.1279\n",
      "Epoch 43/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4003.8677 - val_loss: 3241.4502\n",
      "Epoch 44/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3970.0054 - val_loss: 3210.9756\n",
      "Epoch 45/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3936.3523 - val_loss: 3180.7034\n",
      "Epoch 46/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3902.9067 - val_loss: 3150.6331\n",
      "Epoch 47/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3869.6699 - val_loss: 3120.7622\n",
      "Epoch 48/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3836.6382 - val_loss: 3091.0913\n",
      "Epoch 49/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3803.8115 - val_loss: 3061.6182\n",
      "Epoch 50/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3771.1892 - val_loss: 3032.3435\n",
      "Epoch 51/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3738.7708 - val_loss: 3003.2651\n",
      "Epoch 52/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3706.5547 - val_loss: 2974.3813\n",
      "Epoch 53/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3674.5393 - val_loss: 2945.6938\n",
      "Epoch 54/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3642.7251 - val_loss: 2917.1997\n",
      "Epoch 55/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3611.1106 - val_loss: 2888.8977\n",
      "Epoch 56/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3579.6946 - val_loss: 2860.7886\n",
      "Epoch 57/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3548.4768 - val_loss: 2832.8701\n",
      "Epoch 58/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3517.4556 - val_loss: 2805.1418\n",
      "Epoch 59/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3486.6299 - val_loss: 2777.6038\n",
      "Epoch 60/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3455.9998 - val_loss: 2750.2542\n",
      "Epoch 61/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3425.5637 - val_loss: 2723.0916\n",
      "Epoch 62/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3395.3218 - val_loss: 2696.1165\n",
      "Epoch 63/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3365.2712 - val_loss: 2669.3269\n",
      "Epoch 64/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 3335.4131 - val_loss: 2642.7217\n",
      "Epoch 65/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3305.7458 - val_loss: 2616.3013\n",
      "Epoch 66/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3276.2681 - val_loss: 2590.0649\n",
      "Epoch 67/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3246.9805 - val_loss: 2564.0105\n",
      "Epoch 68/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3217.8799 - val_loss: 2538.1375\n",
      "Epoch 69/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3188.9670 - val_loss: 2512.4458\n",
      "Epoch 70/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3160.2407 - val_loss: 2486.9343\n",
      "Epoch 71/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3131.6997 - val_loss: 2461.6016\n",
      "Epoch 72/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3103.3442 - val_loss: 2436.4475\n",
      "Epoch 73/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 3075.1726 - val_loss: 2411.4717\n",
      "Epoch 74/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 3047.1843 - val_loss: 2386.6709\n",
      "Epoch 75/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3019.3779 - val_loss: 2362.0471\n",
      "Epoch 76/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2991.7539 - val_loss: 2337.5984\n",
      "Epoch 77/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2964.3096 - val_loss: 2313.3237\n",
      "Epoch 78/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2937.0464 - val_loss: 2289.2236\n",
      "Epoch 79/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2909.9629 - val_loss: 2265.2964\n",
      "Epoch 80/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2873.9810 - val_loss: 2227.4597\n",
      "Epoch 81/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2837.9719 - val_loss: 2198.7871\n",
      "Epoch 82/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2806.0159 - val_loss: 2171.0735\n",
      "Epoch 83/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2775.1125 - val_loss: 2144.2266\n",
      "Epoch 84/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2745.0720 - val_loss: 2118.0527\n",
      "Epoch 85/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2715.7043 - val_loss: 2092.4197\n",
      "Epoch 86/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2686.8823 - val_loss: 2067.2400\n",
      "Epoch 87/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2658.5239 - val_loss: 2042.4543\n",
      "Epoch 88/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2630.5715 - val_loss: 2018.0212\n",
      "Epoch 89/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2602.9856 - val_loss: 1993.9121\n",
      "Epoch 90/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2575.7356 - val_loss: 1970.1034\n",
      "Epoch 91/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2548.7988 - val_loss: 1946.5773\n",
      "Epoch 92/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2522.1567 - val_loss: 1923.3199\n",
      "Epoch 93/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2495.7957 - val_loss: 1900.3184\n",
      "Epoch 94/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2469.7021 - val_loss: 1877.5637\n",
      "Epoch 95/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2443.8657 - val_loss: 1855.0470\n",
      "Epoch 96/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2418.2788 - val_loss: 1832.7617\n",
      "Epoch 97/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2392.9336 - val_loss: 1810.7002\n",
      "Epoch 98/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2367.8225 - val_loss: 1788.8574\n",
      "Epoch 99/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2342.9402 - val_loss: 1767.2294\n",
      "Epoch 100/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2318.2817 - val_loss: 1745.8103\n",
      "Epoch 101/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2293.8420 - val_loss: 1724.5969\n",
      "Epoch 102/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2269.6174 - val_loss: 1703.5850\n",
      "Epoch 103/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2245.6035 - val_loss: 1682.7716\n",
      "Epoch 104/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2221.7971 - val_loss: 1662.1542\n",
      "Epoch 105/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2198.1948 - val_loss: 1641.7283\n",
      "Epoch 106/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2174.7935 - val_loss: 1621.4933\n",
      "Epoch 107/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2151.5906 - val_loss: 1601.4452\n",
      "Epoch 108/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2128.5835 - val_loss: 1581.5828\n",
      "Epoch 109/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2105.7695 - val_loss: 1561.9027\n",
      "Epoch 110/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2083.1470 - val_loss: 1542.4034\n",
      "Epoch 111/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2060.7131 - val_loss: 1523.0826\n",
      "Epoch 112/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2038.4659 - val_loss: 1503.9397\n",
      "Epoch 113/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2012.9420 - val_loss: 1478.2074\n",
      "Epoch 114/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1984.4478 - val_loss: 1454.8486\n",
      "Epoch 115/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1957.7621 - val_loss: 1432.3629\n",
      "Epoch 116/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1932.0740 - val_loss: 1410.6938\n",
      "Epoch 117/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1907.2179 - val_loss: 1389.6635\n",
      "Epoch 118/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1883.0134 - val_loss: 1369.1472\n",
      "Epoch 119/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1859.3397 - val_loss: 1349.0627\n",
      "Epoch 120/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1836.1154 - val_loss: 1329.3552\n",
      "Epoch 121/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1813.2866 - val_loss: 1309.9860\n",
      "Epoch 122/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1790.8145 - val_loss: 1290.9269\n",
      "Epoch 123/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1768.6693 - val_loss: 1272.1556\n",
      "Epoch 124/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1746.8301 - val_loss: 1253.6556\n",
      "Epoch 125/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1725.2772 - val_loss: 1235.4122\n",
      "Epoch 126/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1703.9972 - val_loss: 1217.4148\n",
      "Epoch 127/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1682.9772 - val_loss: 1199.6526\n",
      "Epoch 128/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1662.2078 - val_loss: 1182.1189\n",
      "Epoch 129/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1641.6793 - val_loss: 1164.8053\n",
      "Epoch 130/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1621.3845 - val_loss: 1147.7051\n",
      "Epoch 131/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1601.3162 - val_loss: 1130.8138\n",
      "Epoch 132/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1581.4690 - val_loss: 1114.1261\n",
      "Epoch 133/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1561.8374 - val_loss: 1097.6364\n",
      "Epoch 134/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1542.4164 - val_loss: 1081.3423\n",
      "Epoch 135/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1523.2015 - val_loss: 1065.2385\n",
      "Epoch 136/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1504.1893 - val_loss: 1049.3229\n",
      "Epoch 137/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1485.3748 - val_loss: 1033.5908\n",
      "Epoch 138/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1466.7556 - val_loss: 1018.0400\n",
      "Epoch 139/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1448.3287 - val_loss: 1002.6682\n",
      "Epoch 140/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1430.0905 - val_loss: 987.4724\n",
      "Epoch 141/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1412.0386 - val_loss: 972.4493\n",
      "Epoch 142/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1394.1697 - val_loss: 957.5972\n",
      "Epoch 143/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1376.4818 - val_loss: 942.9142\n",
      "Epoch 144/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1358.9728 - val_loss: 928.3980\n",
      "Epoch 145/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1341.6404 - val_loss: 914.0468\n",
      "Epoch 146/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1324.4823 - val_loss: 899.8574\n",
      "Epoch 147/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1307.4961 - val_loss: 885.8292\n",
      "Epoch 148/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1290.6801 - val_loss: 871.9609\n",
      "Epoch 149/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1274.0331 - val_loss: 858.2491\n",
      "Epoch 150/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1257.5519 - val_loss: 844.6932\n",
      "Epoch 151/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1241.2360 - val_loss: 831.2915\n",
      "Epoch 152/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1225.0834 - val_loss: 818.0425\n",
      "Epoch 153/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1209.0922 - val_loss: 804.9445\n",
      "Epoch 154/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1193.2611 - val_loss: 791.9958\n",
      "Epoch 155/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1177.5884 - val_loss: 779.1967\n",
      "Epoch 156/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1162.0732 - val_loss: 766.5434\n",
      "Epoch 157/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1146.7136 - val_loss: 754.0360\n",
      "Epoch 158/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1131.5085 - val_loss: 741.6729\n",
      "Epoch 159/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1116.4559 - val_loss: 729.4525\n",
      "Epoch 160/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1101.5549 - val_loss: 717.3737\n",
      "Epoch 161/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1086.8044 - val_loss: 705.4359\n",
      "Epoch 162/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1072.2030 - val_loss: 693.6368\n",
      "Epoch 163/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1057.7494 - val_loss: 681.9767\n",
      "Epoch 164/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1043.4423 - val_loss: 670.4530\n",
      "Epoch 165/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1029.2806 - val_loss: 659.0650\n",
      "Epoch 166/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1015.2633 - val_loss: 647.8118\n",
      "Epoch 167/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1001.3890 - val_loss: 636.6921\n",
      "Epoch 168/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 987.6569 - val_loss: 620.7708\n",
      "Epoch 169/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 966.6590 - val_loss: 607.1303\n",
      "Epoch 170/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 949.4951 - val_loss: 593.5604\n",
      "Epoch 171/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 932.8654 - val_loss: 580.6232\n",
      "Epoch 172/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 916.9460 - val_loss: 568.2144\n",
      "Epoch 173/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 901.5958 - val_loss: 556.2255\n",
      "Epoch 174/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 886.7000 - val_loss: 544.5839\n",
      "Epoch 175/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 872.1830 - val_loss: 533.2414\n",
      "Epoch 176/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 857.9934 - val_loss: 522.1650\n",
      "Epoch 177/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 844.0961 - val_loss: 511.3297\n",
      "Epoch 178/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 830.4650 - val_loss: 500.7185\n",
      "Epoch 179/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 817.0801 - val_loss: 490.3169\n",
      "Epoch 180/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 803.9258 - val_loss: 480.1129\n",
      "Epoch 181/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 790.9895 - val_loss: 470.0983\n",
      "Epoch 182/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 778.2611 - val_loss: 460.2644\n",
      "Epoch 183/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 765.7319 - val_loss: 450.6049\n",
      "Epoch 184/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 753.3941 - val_loss: 441.1137\n",
      "Epoch 185/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 741.2409 - val_loss: 431.7854\n",
      "Epoch 186/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 729.2671 - val_loss: 422.6160\n",
      "Epoch 187/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 717.4677 - val_loss: 413.6014\n",
      "Epoch 188/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 705.8376 - val_loss: 404.7374\n",
      "Epoch 189/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 694.3729 - val_loss: 396.0209\n",
      "Epoch 190/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 683.0701 - val_loss: 387.4482\n",
      "Epoch 191/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 671.9254 - val_loss: 379.0180\n",
      "Epoch 192/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 660.9357 - val_loss: 370.7260\n",
      "Epoch 193/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 650.0983 - val_loss: 362.5707\n",
      "Epoch 194/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 639.4104 - val_loss: 354.5487\n",
      "Epoch 195/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 628.8692 - val_loss: 346.6583\n",
      "Epoch 196/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 618.4721 - val_loss: 338.8979\n",
      "Epoch 197/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 608.2172 - val_loss: 331.2646\n",
      "Epoch 198/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 598.1023 - val_loss: 323.7569\n",
      "Epoch 199/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 588.1246 - val_loss: 316.3727\n",
      "Epoch 200/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 578.2829 - val_loss: 309.1106\n",
      "Epoch 201/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 568.5751 - val_loss: 301.9688\n",
      "Epoch 202/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 558.9991 - val_loss: 294.9453\n",
      "Epoch 203/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 549.5535 - val_loss: 288.0390\n",
      "Epoch 204/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 540.2366 - val_loss: 281.2480\n",
      "Epoch 205/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 531.0466 - val_loss: 274.5708\n",
      "Epoch 206/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 521.9817 - val_loss: 268.0063\n",
      "Epoch 207/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 513.0409 - val_loss: 261.5529\n",
      "Epoch 208/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 504.2228 - val_loss: 255.2088\n",
      "Epoch 209/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 495.5249 - val_loss: 248.9736\n",
      "Epoch 210/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 486.9469 - val_loss: 242.8450\n",
      "Epoch 211/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 478.4868 - val_loss: 236.8223\n",
      "Epoch 212/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 470.1438 - val_loss: 230.9041\n",
      "Epoch 213/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 461.9160 - val_loss: 225.0889\n",
      "Epoch 214/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 453.8023 - val_loss: 219.3758\n",
      "Epoch 215/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 445.8019 - val_loss: 213.7638\n",
      "Epoch 216/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 437.9132 - val_loss: 208.2513\n",
      "Epoch 217/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 430.1348 - val_loss: 202.8373\n",
      "Epoch 218/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 422.4656 - val_loss: 197.5206\n",
      "Epoch 219/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 414.9050 - val_loss: 192.3004\n",
      "Epoch 220/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 407.4513 - val_loss: 187.1752\n",
      "Epoch 221/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 400.1036 - val_loss: 182.1440\n",
      "Epoch 222/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 392.8604 - val_loss: 177.2057\n",
      "Epoch 223/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 385.7209 - val_loss: 172.3598\n",
      "Epoch 224/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 378.6842 - val_loss: 167.6041\n",
      "Epoch 225/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 371.7490 - val_loss: 162.9389\n",
      "Epoch 226/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 364.9146 - val_loss: 158.3622\n",
      "Epoch 227/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 358.1794 - val_loss: 153.8732\n",
      "Epoch 228/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 351.5427 - val_loss: 149.4713\n",
      "Epoch 229/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 345.0037 - val_loss: 145.1552\n",
      "Epoch 230/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 338.5611 - val_loss: 140.9238\n",
      "Epoch 231/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 332.2140 - val_loss: 136.7763\n",
      "Epoch 232/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 325.9613 - val_loss: 132.7116\n",
      "Epoch 233/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 319.8020 - val_loss: 128.7289\n",
      "Epoch 234/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 313.7353 - val_loss: 124.8272\n",
      "Epoch 235/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 307.7603 - val_loss: 121.0053\n",
      "Epoch 236/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 301.8759 - val_loss: 117.2628\n",
      "Epoch 237/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 296.0811 - val_loss: 113.5979\n",
      "Epoch 238/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 290.3750 - val_loss: 110.0107\n",
      "Epoch 239/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 284.7570 - val_loss: 106.4995\n",
      "Epoch 240/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 279.2259 - val_loss: 103.0639\n",
      "Epoch 241/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 273.7808 - val_loss: 99.7025\n",
      "Epoch 242/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 268.4207 - val_loss: 96.4149\n",
      "Epoch 243/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 263.1451 - val_loss: 93.2001\n",
      "Epoch 244/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 257.9530 - val_loss: 90.0571\n",
      "Epoch 245/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 252.8434 - val_loss: 86.9848\n",
      "Epoch 246/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 247.8150 - val_loss: 83.9827\n",
      "Epoch 247/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 242.8676 - val_loss: 81.0495\n",
      "Epoch 248/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 238.0001 - val_loss: 78.1849\n",
      "Epoch 249/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 233.2117 - val_loss: 75.3876\n",
      "Epoch 250/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 228.5013 - val_loss: 72.6567\n",
      "Epoch 251/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 223.8684 - val_loss: 69.9916\n",
      "Epoch 252/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 219.3122 - val_loss: 67.3918\n",
      "Epoch 253/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 214.8312 - val_loss: 64.8554\n",
      "Epoch 254/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 210.4251 - val_loss: 62.3824\n",
      "Epoch 255/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 206.0931 - val_loss: 59.9716\n",
      "Epoch 256/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 201.8344 - val_loss: 57.6226\n",
      "Epoch 257/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 197.6479 - val_loss: 55.3341\n",
      "Epoch 258/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 193.5332 - val_loss: 53.1054\n",
      "Epoch 259/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 189.4890 - val_loss: 50.9359\n",
      "Epoch 260/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 185.5148 - val_loss: 48.8245\n",
      "Epoch 261/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 181.6098 - val_loss: 46.7705\n",
      "Epoch 262/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 177.7731 - val_loss: 44.7733\n",
      "Epoch 263/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 174.0041 - val_loss: 42.8316\n",
      "Epoch 264/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 170.3016 - val_loss: 40.9448\n",
      "Epoch 265/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 166.6650 - val_loss: 39.1125\n",
      "Epoch 266/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 163.0937 - val_loss: 37.3333\n",
      "Epoch 267/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 159.5868 - val_loss: 35.6069\n",
      "Epoch 268/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 156.1434 - val_loss: 33.9320\n",
      "Epoch 269/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 152.7630 - val_loss: 32.3084\n",
      "Epoch 270/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 149.4447 - val_loss: 30.7349\n",
      "Epoch 271/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 146.1877 - val_loss: 29.2110\n",
      "Epoch 272/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 142.9914 - val_loss: 27.7357\n",
      "Epoch 273/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 139.8547 - val_loss: 26.3084\n",
      "Epoch 274/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 136.7772 - val_loss: 24.9283\n",
      "Epoch 275/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 133.7579 - val_loss: 23.5944\n",
      "Epoch 276/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 130.7964 - val_loss: 22.3063\n",
      "Epoch 277/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 127.8915 - val_loss: 21.0631\n",
      "Epoch 278/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 125.0428 - val_loss: 19.8641\n",
      "Epoch 279/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 122.2496 - val_loss: 18.7083\n",
      "Epoch 280/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 119.5108 - val_loss: 17.5953\n",
      "Epoch 281/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 116.8262 - val_loss: 16.5243\n",
      "Epoch 282/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 114.1946 - val_loss: 15.4944\n",
      "Epoch 283/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 111.6155 - val_loss: 14.5051\n",
      "Epoch 284/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 109.0883 - val_loss: 13.5554\n",
      "Epoch 285/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 106.6120 - val_loss: 12.6448\n",
      "Epoch 286/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 104.1862 - val_loss: 11.7725\n",
      "Epoch 287/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 101.8100 - val_loss: 10.9378\n",
      "Epoch 288/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 99.4829 - val_loss: 10.1400\n",
      "Epoch 289/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 97.2041 - val_loss: 9.3785\n",
      "Epoch 290/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 94.9728 - val_loss: 8.6524\n",
      "Epoch 291/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 92.7882 - val_loss: 7.9610\n",
      "Epoch 292/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 90.6499 - val_loss: 7.3039\n",
      "Epoch 293/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 88.5573 - val_loss: 6.6801\n",
      "Epoch 294/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 86.5094 - val_loss: 6.0891\n",
      "Epoch 295/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 84.5058 - val_loss: 5.5302\n",
      "Epoch 296/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 82.5456 - val_loss: 5.0026\n",
      "Epoch 297/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 80.6282 - val_loss: 4.5058\n",
      "Epoch 298/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 78.7532 - val_loss: 4.0390\n",
      "Epoch 299/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 76.9195 - val_loss: 3.6017\n",
      "Epoch 300/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 75.1269 - val_loss: 3.1932\n",
      "Epoch 301/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 73.3746 - val_loss: 2.8128\n",
      "Epoch 302/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 71.6618 - val_loss: 2.4598\n",
      "Epoch 303/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 69.9880 - val_loss: 2.1338\n",
      "Epoch 304/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 68.3526 - val_loss: 1.8339\n",
      "Epoch 305/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 66.7548 - val_loss: 1.5596\n",
      "Epoch 306/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 65.1942 - val_loss: 1.3103\n",
      "Epoch 307/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 63.6701 - val_loss: 1.0853\n",
      "Epoch 308/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 62.1818 - val_loss: 0.8841\n",
      "Epoch 309/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 60.7288 - val_loss: 0.7061\n",
      "Epoch 310/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 59.3106 - val_loss: 0.5506\n",
      "Epoch 311/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 57.9263 - val_loss: 0.4171\n",
      "Epoch 312/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 56.5756 - val_loss: 0.3049\n",
      "Epoch 313/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 55.2579 - val_loss: 0.2136\n",
      "Epoch 314/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 53.9722 - val_loss: 0.1424\n",
      "Epoch 315/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 52.7184 - val_loss: 0.0909\n",
      "Epoch 316/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 51.4958 - val_loss: 0.0585\n",
      "Epoch 317/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 50.3037 - val_loss: 0.0446\n",
      "Epoch 318/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 49.1416 - val_loss: 0.0487\n",
      "Epoch 319/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 48.0090 - val_loss: 0.0703\n",
      "Epoch 320/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 46.9054 - val_loss: 0.1087\n",
      "Epoch 321/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 45.8302 - val_loss: 0.1636\n",
      "Epoch 322/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 44.7829 - val_loss: 0.2342\n",
      "Epoch 323/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 43.7629 - val_loss: 0.3202\n",
      "Epoch 324/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 42.7695 - val_loss: 0.4210\n",
      "Epoch 325/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 41.8023 - val_loss: 0.5361\n",
      "Epoch 326/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 40.8610 - val_loss: 0.6650\n",
      "Epoch 327/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 39.9449 - val_loss: 0.8073\n",
      "Epoch 328/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 39.0533 - val_loss: 0.9624\n",
      "Epoch 329/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 38.1860 - val_loss: 1.1298\n",
      "Epoch 330/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 37.3424 - val_loss: 1.3090\n",
      "Epoch 331/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 36.5220 - val_loss: 1.4998\n",
      "Epoch 332/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 35.7244 - val_loss: 1.7014\n",
      "Epoch 333/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 34.9489 - val_loss: 1.9136\n",
      "Epoch 334/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 34.1952 - val_loss: 2.1359\n",
      "Epoch 335/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 33.4628 - val_loss: 2.3677\n",
      "Epoch 336/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 32.7512 - val_loss: 2.6088\n",
      "Epoch 337/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 32.0599 - val_loss: 2.8586\n",
      "Epoch 338/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 31.3887 - val_loss: 3.1168\n",
      "Epoch 339/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 30.7369 - val_loss: 3.3829\n",
      "Epoch 340/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 30.1042 - val_loss: 3.6566\n",
      "Epoch 341/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 29.4900 - val_loss: 3.9374\n",
      "Epoch 342/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 28.8940 - val_loss: 4.2249\n",
      "Epoch 343/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 28.3158 - val_loss: 4.5189\n",
      "Epoch 344/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 27.7549 - val_loss: 4.8188\n",
      "Epoch 345/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 27.2110 - val_loss: 5.1245\n",
      "Epoch 346/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 26.6835 - val_loss: 5.4354\n",
      "Epoch 347/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 26.1721 - val_loss: 5.7511\n",
      "Epoch 348/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 25.6766 - val_loss: 6.0714\n",
      "Epoch 349/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 25.1964 - val_loss: 6.3961\n",
      "Epoch 350/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 24.7311 - val_loss: 6.7246\n",
      "Epoch 351/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 24.2805 - val_loss: 7.0568\n",
      "Epoch 352/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 23.8441 - val_loss: 7.3922\n",
      "Epoch 353/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.4215 - val_loss: 7.7306\n",
      "Epoch 354/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 23.0124 - val_loss: 8.0716\n",
      "Epoch 355/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 22.6165 - val_loss: 8.4151\n",
      "Epoch 356/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 22.2334 - val_loss: 8.7606\n",
      "Epoch 357/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 21.8628 - val_loss: 9.1079\n",
      "Epoch 358/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 21.5044 - val_loss: 9.4568\n",
      "Epoch 359/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 21.1577 - val_loss: 9.8070\n",
      "Epoch 360/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 20.8225 - val_loss: 10.1582\n",
      "Epoch 361/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 20.4986 - val_loss: 10.5101\n",
      "Epoch 362/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 20.1855 - val_loss: 10.8627\n",
      "Epoch 363/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 19.8830 - val_loss: 11.2156\n",
      "Epoch 364/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 19.5907 - val_loss: 11.5683\n",
      "Epoch 365/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 19.3085 - val_loss: 11.9209\n",
      "Epoch 366/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 19.0361 - val_loss: 12.2732\n",
      "Epoch 367/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 18.7730 - val_loss: 12.6249\n",
      "Epoch 368/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 18.5191 - val_loss: 12.9758\n",
      "Epoch 369/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 18.2740 - val_loss: 13.3258\n",
      "Epoch 370/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 18.0375 - val_loss: 13.6745\n",
      "Epoch 371/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 17.8095 - val_loss: 14.0219\n",
      "Epoch 372/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 17.5896 - val_loss: 14.3677\n",
      "Epoch 373/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 17.3776 - val_loss: 14.7119\n",
      "Epoch 374/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 17.1731 - val_loss: 15.0543\n",
      "Epoch 375/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 16.9761 - val_loss: 15.3946\n",
      "Epoch 376/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 16.7862 - val_loss: 15.7327\n",
      "Epoch 377/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 16.6033 - val_loss: 16.0687\n",
      "Epoch 378/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 16.4270 - val_loss: 16.4020\n",
      "Epoch 379/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 16.2574 - val_loss: 16.7328\n",
      "Epoch 380/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 16.0940 - val_loss: 17.0610\n",
      "Epoch 381/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 15.9367 - val_loss: 17.3862\n",
      "Epoch 382/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 15.7854 - val_loss: 17.7086\n",
      "Epoch 383/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 15.6397 - val_loss: 18.0279\n",
      "Epoch 384/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 15.4996 - val_loss: 18.3439\n",
      "Epoch 385/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 15.3648 - val_loss: 18.6569\n",
      "Epoch 386/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 15.2351 - val_loss: 18.9665\n",
      "Epoch 387/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 15.1106 - val_loss: 19.2726\n",
      "Epoch 388/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 14.9907 - val_loss: 19.5753\n",
      "Epoch 389/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 14.8755 - val_loss: 19.8744\n",
      "Epoch 390/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 14.7648 - val_loss: 20.1698\n",
      "Epoch 391/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 14.6585 - val_loss: 20.4614\n",
      "Epoch 392/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 14.5564 - val_loss: 20.7494\n",
      "Epoch 393/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 14.4582 - val_loss: 21.0337\n",
      "Epoch 394/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 14.3640 - val_loss: 21.3137\n",
      "Epoch 395/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 14.2735 - val_loss: 21.5901\n",
      "Epoch 396/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 14.1866 - val_loss: 21.8625\n",
      "Epoch 397/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 14.1032 - val_loss: 22.1310\n",
      "Epoch 398/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 14.0232 - val_loss: 22.3953\n",
      "Epoch 399/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 13.9464 - val_loss: 22.6553\n",
      "Epoch 400/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 13.8728 - val_loss: 22.9115\n",
      "Epoch 401/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 13.8022 - val_loss: 23.1635\n",
      "Epoch 402/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.7344 - val_loss: 23.4114\n",
      "Epoch 403/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 13.6695 - val_loss: 23.6550\n",
      "Epoch 404/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 13.6071 - val_loss: 23.8947\n",
      "Epoch 405/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 13.5474 - val_loss: 24.1300\n",
      "Epoch 406/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.4902 - val_loss: 24.3614\n",
      "Epoch 407/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 13.4353 - val_loss: 24.5882\n",
      "Epoch 408/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 13.3828 - val_loss: 24.8112\n",
      "Epoch 409/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.3324 - val_loss: 25.0299\n",
      "Epoch 410/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.2841 - val_loss: 25.2446\n",
      "Epoch 411/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.2379 - val_loss: 25.4551\n",
      "Epoch 412/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.1936 - val_loss: 25.6616\n",
      "Epoch 413/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 13.1511 - val_loss: 25.8638\n",
      "Epoch 414/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.1105 - val_loss: 26.0620\n",
      "Epoch 415/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 13.0716 - val_loss: 26.2560\n",
      "Epoch 416/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.0344 - val_loss: 26.4460\n",
      "Epoch 417/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.9988 - val_loss: 26.6321\n",
      "Epoch 418/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 12.9647 - val_loss: 26.8140\n",
      "Epoch 419/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.9320 - val_loss: 26.9921\n",
      "Epoch 420/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.9008 - val_loss: 27.1665\n",
      "Epoch 421/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.8708 - val_loss: 27.3366\n",
      "Epoch 422/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.8422 - val_loss: 27.5030\n",
      "Epoch 423/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.8148 - val_loss: 27.6656\n",
      "Epoch 424/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.7887 - val_loss: 27.8245\n",
      "Epoch 425/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.7636 - val_loss: 27.9796\n",
      "Epoch 426/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.7396 - val_loss: 28.1310\n",
      "Epoch 427/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.7166 - val_loss: 28.2789\n",
      "Epoch 428/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.6947 - val_loss: 28.4230\n",
      "Epoch 429/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.6737 - val_loss: 28.5638\n",
      "Epoch 430/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.6536 - val_loss: 28.7008\n",
      "Epoch 431/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.6344 - val_loss: 28.8344\n",
      "Epoch 432/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.6160 - val_loss: 28.9649\n",
      "Epoch 433/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.5984 - val_loss: 29.0918\n",
      "Epoch 434/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 12.5817 - val_loss: 29.2154\n",
      "Epoch 435/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.5656 - val_loss: 29.3359\n",
      "Epoch 436/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.5502 - val_loss: 29.4529\n",
      "Epoch 437/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.5355 - val_loss: 29.5669\n",
      "Epoch 438/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.5215 - val_loss: 29.6777\n",
      "Epoch 439/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.5081 - val_loss: 29.7856\n",
      "Epoch 440/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.4952 - val_loss: 29.8905\n",
      "Epoch 441/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.4829 - val_loss: 29.9924\n",
      "Epoch 442/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.4712 - val_loss: 30.0915\n",
      "Epoch 443/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.4600 - val_loss: 30.1876\n",
      "Epoch 444/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.4492 - val_loss: 30.2810\n",
      "Epoch 445/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.4390 - val_loss: 30.3718\n",
      "Epoch 446/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.4291 - val_loss: 30.4599\n",
      "Epoch 447/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.4198 - val_loss: 30.5452\n",
      "Epoch 448/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.4108 - val_loss: 30.6279\n",
      "Epoch 449/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.4022 - val_loss: 30.7082\n",
      "Epoch 450/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.3941 - val_loss: 30.7861\n",
      "Epoch 451/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.3862 - val_loss: 30.8616\n",
      "Epoch 452/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.3787 - val_loss: 30.9346\n",
      "Epoch 453/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 12.3716 - val_loss: 31.0055\n",
      "Epoch 454/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.3647 - val_loss: 31.0740\n",
      "Epoch 455/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.3582 - val_loss: 31.1404\n",
      "Epoch 456/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.3520 - val_loss: 31.2047\n",
      "Epoch 457/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.3460 - val_loss: 31.2668\n",
      "Epoch 458/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.3403 - val_loss: 31.3270\n",
      "Epoch 459/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.3348 - val_loss: 31.3851\n",
      "Epoch 460/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.3296 - val_loss: 31.4413\n",
      "Epoch 461/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.3246 - val_loss: 31.4955\n",
      "Epoch 462/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.3199 - val_loss: 31.5482\n",
      "Epoch 463/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.3153 - val_loss: 31.5988\n",
      "Epoch 464/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.3109 - val_loss: 31.6478\n",
      "Epoch 465/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.3068 - val_loss: 31.6951\n",
      "Epoch 466/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.3028 - val_loss: 31.7408\n",
      "Epoch 467/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.2990 - val_loss: 31.7847\n",
      "Epoch 468/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 12.2954 - val_loss: 31.8272\n",
      "Epoch 469/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.2919 - val_loss: 31.8681\n",
      "Epoch 470/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.2886 - val_loss: 31.9075\n",
      "Epoch 471/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.2855 - val_loss: 31.9455\n",
      "Epoch 472/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.2825 - val_loss: 31.9820\n",
      "Epoch 473/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.2796 - val_loss: 32.0174\n",
      "Epoch 474/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.2769 - val_loss: 32.0511\n",
      "Epoch 475/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.2743 - val_loss: 32.0837\n",
      "Epoch 476/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.2718 - val_loss: 32.1154\n",
      "Epoch 477/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.2694 - val_loss: 32.1455\n",
      "Epoch 478/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.2671 - val_loss: 32.1746\n",
      "Epoch 479/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 12.2650 - val_loss: 32.2024\n",
      "Epoch 480/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.2629 - val_loss: 32.2294\n",
      "Epoch 481/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.2609 - val_loss: 32.2551\n",
      "Epoch 482/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.2591 - val_loss: 32.2800\n",
      "Epoch 483/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.2573 - val_loss: 32.3038\n",
      "Epoch 484/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.2556 - val_loss: 32.3266\n",
      "Epoch 485/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 12.2540 - val_loss: 32.3485\n",
      "Epoch 486/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.2524 - val_loss: 32.3696\n",
      "Epoch 487/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.2510 - val_loss: 32.3897\n",
      "Epoch 488/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 12.2496 - val_loss: 32.4090\n",
      "Epoch 489/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 12.2483 - val_loss: 32.4275\n",
      "Epoch 490/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.2470 - val_loss: 32.4453\n",
      "Epoch 491/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.2458 - val_loss: 32.4623\n",
      "Epoch 492/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.2447 - val_loss: 32.4785\n",
      "Epoch 493/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.2436 - val_loss: 32.4940\n",
      "Epoch 494/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.2426 - val_loss: 32.5088\n",
      "Epoch 495/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.2417 - val_loss: 32.5232\n",
      "Epoch 496/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.2408 - val_loss: 32.5370\n",
      "Epoch 497/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.2399 - val_loss: 32.5499\n",
      "Epoch 498/500\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.2391 - val_loss: 32.5623\n",
      "Epoch 499/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 12.2383 - val_loss: 32.5742\n",
      "Epoch 500/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 12.2376 - val_loss: 32.5854\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(86.8407, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0015, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0001, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0118, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.5775, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 344ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.99190710e+01, 6.98964052e+01, 6.98908030e+01, 6.98852007e+01,\n",
       "        6.98795985e+01, 6.98739963e+01, 6.98683940e+01, 6.98627918e+01,\n",
       "        6.98571895e+01, 6.98515873e+01, 6.98459851e+01, 6.98403828e+01,\n",
       "        6.98347806e+01, 6.98291783e+01, 6.98235761e+01, 6.98179739e+01,\n",
       "        6.98123716e+01, 6.98067694e+01, 6.98011671e+01, 6.97955649e+01,\n",
       "        6.97899627e+01, 6.97843604e+01, 6.97787582e+01, 6.97731559e+01,\n",
       "        6.97675537e+01, 6.97619514e+01, 6.97563492e+01, 6.97507470e+01,\n",
       "        6.97451447e+01, 6.97395425e+01, 6.97339402e+01, 6.97283380e+01,\n",
       "        6.97227358e+01, 6.97171335e+01, 6.97115313e+01, 6.97059290e+01,\n",
       "        6.97003268e+01, 6.96894491e+01, 6.96782446e+01, 6.96670402e+01,\n",
       "        6.96558357e+01, 6.96446312e+01, 6.96334267e+01, 6.96222222e+01,\n",
       "        6.96110177e+01, 6.95998133e+01, 6.95886088e+01, 6.95774043e+01,\n",
       "        6.95661998e+01, 6.95549953e+01, 6.95437908e+01, 6.95325864e+01,\n",
       "        6.95213819e+01, 6.95101774e+01, 6.94989729e+01, 6.94877684e+01,\n",
       "        6.94765640e+01, 6.94653595e+01, 6.94541550e+01, 6.94429505e+01,\n",
       "        6.94317460e+01, 6.94205415e+01, 6.94093371e+01, 6.93981326e+01,\n",
       "        6.93869281e+01, 6.93757236e+01, 6.93645191e+01, 6.93533147e+01,\n",
       "        6.93421102e+01, 6.93309057e+01, 6.93197012e+01, 6.93084967e+01,\n",
       "        6.92925537e+01, 6.92617414e+01, 6.92309290e+01, 6.92001167e+01,\n",
       "        6.91693044e+01, 6.91384921e+01, 6.91076797e+01, 6.90768674e+01,\n",
       "        7.52695465e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.40804970e-01, 0.00000000e+00, 5.29040694e-02, 4.68572617e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.68220079e-01, 6.08990267e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.39738905e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.03676066e-01, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66.62885154, 66.62138189, 66.61391223, 66.60644258, 66.59897292,\n",
       "       66.59150327, 66.58403361, 66.57656396, 66.5690943 , 66.56162465,\n",
       "       66.554155  , 66.54668534, 66.53921569, 66.53174603, 66.52427638,\n",
       "       66.51680672, 66.50933707, 66.50186741, 66.49439776, 66.4869281 ,\n",
       "       66.47945845, 66.4719888 , 66.46451914, 66.45704949, 66.44957983,\n",
       "       66.44211018, 66.43464052, 66.42717087, 66.41970121, 66.41223156,\n",
       "       66.4047619 , 66.39729225, 66.3898226 , 66.38235294, 66.37488329,\n",
       "       66.36741363, 66.35994398, 66.35247432, 66.34500467, 66.33753501,\n",
       "       66.33006536, 66.3225957 , 66.31512605, 66.3076564 , 66.30018674,\n",
       "       66.29271709, 66.28524743, 66.27777778, 66.27030812, 66.26283847,\n",
       "       66.25536881, 66.24789916, 66.24042951, 66.23295985, 66.2254902 ,\n",
       "       66.21802054, 66.21055089, 66.20308123, 66.19561158, 66.18814192,\n",
       "       66.18067227, 66.17320261, 66.16573296, 66.15826331, 66.15079365,\n",
       "       66.143324  , 66.13585434, 66.12838469, 66.12091503, 66.11344538,\n",
       "       66.10597572, 66.09850607, 66.09103641, 66.08356676, 66.07609711,\n",
       "       66.06862745, 66.0611578 , 66.05368814, 66.04621849, 66.03874883,\n",
       "       66.03127918, 66.02380952, 66.01633987, 66.00887021, 66.00140056,\n",
       "       65.99393091, 65.98646125, 65.9789916 , 65.97152194, 65.96405229,\n",
       "       65.95658263, 65.94911298, 65.94164332, 65.93417367, 65.92670401,\n",
       "       65.91923436, 65.91176471, 65.90429505, 65.89960317, 65.89866947])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.860524568861226\n",
      "15.219885823056543\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
