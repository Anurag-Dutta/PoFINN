{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2495    45.239352\n",
       "2496    45.229514\n",
       "2497    45.219676\n",
       "2498    45.209838\n",
       "2499    45.200000\n",
       "Name: C6, Length: 2500, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_2400_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2395     0.208332\n",
       "2396     0.000000\n",
       "2397     0.125489\n",
       "2398     0.000000\n",
       "2399     0.068872\n",
       "Name: C6, Length: 2400, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2400)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD4CAYAAAANbUbJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAr+0lEQVR4nO3deXxV5b3v8c8vEyQkkNEQIJAgk4gDEBFFcG6dWrX1aFvb4tB662nVattrJ8/xvHrb2vbUU+vtsdc6H61jtahVq6I4IAaDzCBzgIQASRgThhDy3D/2wE6yk73W2uNa+/d+vTB7WMOzss13rf1bz3qWGGNQSinlbRnJboBSSqn407BXSqk0oGGvlFJpQMNeKaXSgIa9UkqlgaxErqy0tNRUVVUlcpVKKeV6ixYtajHGlEWzjISGfVVVFXV1dYlcpVJKuZ6IbI52GVrGUUqpNKBhr5RSaUDDXiml0oCGvVJKpQENe6WUSgMa9koplQY07JVSKg24IuxfWbqNJz+OupupUkqlLVeE/RsrtvNfb62l82hXspuilFKu5Iqw/8Ipw2ht72D+htZkN0UppVzJFWF/zvgyCgZm8fKSbcluilJKuZIrwn5gdiYXnTiUf67czqEjR5PdHKWUch1XhD3Al6eOoO1wJ/+zQE/UKqWUXa4J++mjSzhnfBl/fGcdrW2Hk90cpZRyFdeEPcDPLjmBAx1HuW/uumQ3RSmlXMVVYT+2vICvTRvJU7VbeG9tc7Kbo5RSrmEp7EXkdhFZKSIrRORpERkoItUiUisi60XkWRHJiXdjAW6/cByjSvKY/chCfvDcUna3dyRitUop5WoRw15EhgO3AjXGmElAJvAV4DfAfxljxgC7gRvj2dCA4kE5vHbrTL577vHMWdLIBfe+x5wljRhjErF6pZRyJatlnCwgV0SygDygCTgPeMH//uPAFTFvXR8GZmfyo89P4JVbzmJEcR63PbOE6x79hIbdBxLVBKWUcpWIYW+MaQT+E9iCL+T3AouAPcaYTv9kDcDwcPOLyE0iUicidc3Nsa2zn1AxmBdvPpN//8JEPqnfxYX3vs/DH27iaJce5SulVCgrZZwi4HKgGhgGDAIusroCY8yDxpgaY0xNWVlUN0cPKzNDuH5GNW/dcTZnHF/CL15dxdcfqmX73kMxX5dSSrmVlTLOBcAmY0yzMeYI8CIwAyj0l3UARgCNcWqjJcMLc3l4dg2/vepkljbs4aL73ufdNTuT2SSllEoZVsJ+CzBdRPJERIDzgVXAu8BV/mlmA3Pi00TrRISrayr5x60zGTYkl28/XscrS3U8HaWUslKzr8V3IvZTYLl/ngeBO4E7RGQ9UAI8HMd22lJdOohn/9d0powq4tZnFvPMwi3JbpJSSiWVJLLLYk1Njamrq0vY+g52HOU7Ty7ivbXN3HXZRG48qzph61ZKqVgRkUXGmJpoluGqK2jtys3J5MFvTuXiSUP5xaur+P2ba3TUTKVUWvJ02AMMyMrk/q9O5stTRnD/O+uZcc87/P7NNezYp711lFLpw9NlnFDGGD7a0Mqj8zcx97OdZIpw6ckVXD+jmlMrC5PSJqWUsiIWZZysyJN4g4gwY0wpM8aUsrm1ncc/2sxzdVuZs2Qbk0cWcv2Mai6eNJTsTM9/2VFKpaG0ObIPp+1wJy/UbeWxj+qpbz1A+eABfGP6KL46bSQl+QOS3TyllAJic2Sf1mEf0NVlmLd2J4/Or+eDdS3kZGVwxanDuH5GNSdUDE5285RSaU7LODGSkSGcN6Gc8yaUs27Hfh79qJ4XP23guboGpo8u5voZ1VxwQjmZGZLspiqllCN6ZN+HPQc6ePaTrTyxYDONew5SWZzL7DOq+JeaSobkZie7eUqpNKJlnAToPNrFW6t28Oj8ehbW7yIvJ5Orpo5g9plVHF+Wn+zmKaXSgIZ9gq1o3Muj8+t5Zek2Oo52cc74Mq47s4pZY8vI0BKPUipONOyTpHn/Yf5au4UnazfTvP8wo8sGcelJFZw9roxTKwvJ0u6bSqkY0rBPso7OLl5b3sRTtZtZtHk3XQYKBmYxc2wp54w7jrPHl1E+eGCym6mUcjntjZNkOVkZXDF5OFdMHs7eA0f4cH0L763dyXtrm3lt+XYAJgwt4Jzxx3HO+DKmjirSi7aUUkmhR/ZxYIzhs+37mbemmffW7qSufjedXYb8AVnMGFPC2eN84T+sMDfZTVVKuYCWcVxi/6EjfLSh1Rf+a3ayzX/LxAlDC/jllScxdVRRkluolEplGvYuZIxh/c425q1p5omP69m+9xD/dtlEvj59FL4bgSmlVHc6nr0LiQhjywv49qzRvPq9mcwcW8Zdc1byg+eWcrBDx9pXSsWHhn0SDcnL5qFv1nD7BeN4aUkjV/73fDa3tie7WUopD9KwT7KMDOG2C8byyHWn0bT3EJfd/yFzV+9IdrOUUh6jYZ8izh1/HK/echYji/O48fE67n1rLUe7Enc+RSnlbRr2KaSyOI+/3XwmV00dwR/nruOGxz5hz4GOZDdLKeUBGvYpZmB2Jr+76mR+eeUkFmxo5bL7P2RF495kN0sp5XIa9ilIRLj29FE8950zONpl+PIDH/F83dZkN0sp5WIa9ins1MpCXr3lLKaOKuJHLyzjpy8t53Cnds9UStmnYZ/iSvIH8MQN07j5nOP5a+0Wrv7zAlY37aOjsyvZTVNKuYgOhOYCWZkZ3HnRBE4ZUcgPn1/Kxfd9gAiUFwyksjiXEUV5jCjKpdL/c0RRHhWFA3XQNaVUkIa9i1w0aSgnjRjCgg2tNOw+wNZdB2nYfYCFm3YxZ8lBQntqZghUDMlleFFucEdw9vgyJlcW6rAMSqUhHRvHI44c7WL73kNs3X2ABv9OoGH3Qd/z3QfZvu8QxsDY4/K55rRKrpw8nJL8AclutlLKAh0ITVnWdriTV5du49m6rSzesofsTOGCE8q55rRKZo4tI1Nvq+hahzuP8tAHm/j2zNHkZKVO6e6x+Zu45KQKjvPYDXxa2g4zZ8k2bphRlbBvyToQmrIsf0AWX5k2kpf+dQZv3j6L2WdUUbtpF9c9+gkzf/MO9765hq27DiS7mcqBR+fX87t/ruGxjzZZnscYwxsrtnPkaHxO9G9qaefuV1Zx81OfWp6nq8vw+vImEnkAakXT3oMs2rwr+Pz2Z5fwi1dXsappXxJbZZ+GfRoaV17Azy+byMc/OZ//vnYKY8sLuP/d9cz63bt8/aFaXl66jUNHtIunW7Qf7gTg0BHrwf3ump1858lF/HHuOsvzrG7ax459hyxNG9iJ7Dt4xPLyn1hQz81Pfcrzixosz7N11wE2NLdZnt6Js383jy8/sCD4fLf/qvYul3WI0xO0aSwnK4NLTqrgkpMqaNxzkBfqGniubiu3Pr2Ywrxsrjh1OFdNHcG48oKUKg+o7rr8R8J2KnEtbb7A2rbHWngDwV5gm359qeU22alyNPl3JK1t1ocImfnbdwGovydym5zq2c05EPJu6+egYa8AGF6Yy20XjOWW88Ywf0MLz36ylb/WbuGxj+rJzBCGF+ZSVTqI6pI8RpUMorp0EFWlgxhRlKtdPJMs0AvLTv3YONhB+Oaz2CZ/IGbYapPvZ6qH6LGda4o3tAcNe9VNRoYwc2wZM8eWsbu9g3lrd7KxuZ1NLe1sbj3A4s272e8vGwBkZggjinKp8u8ARpXkUVU6iCmVRQzJy07ilqQPJyXuwDzxCiyD/UYFdkDvrWnmO2cfH+smRc0Y022H6rKs17BXfSsalMOVk0d0e80YQ2t7B5tb29nUcoD6lnY2tbazubWdRZt30+bfEQzMzuDKycP5xvQqJg4bnIzmp41AsNoJ7q44H0U72ZkE2rRgY2scWhS999Y2c87441zzDaQnDXtli4hQmj+A0vwBTB1V3O09YwwtbR1saG5jzpJGXlrcyNMLt3JaVRHfPKOKiyYN1ZJPHBwLVhvzYL+mbkegTb7rO4ylElOiOuHs3H+Iwtwc2+eh9h/yHci4tYyjf3kqZkSEsoIBTB9dwq+/dDK1P7mAn196Ajv2HeaWpxcz4553+MPba9lpsUeHsqarK5oj+/gEViAQd7V38Own1kZs7UpA2h852sW0X87lRy8sdbwMJyfEU4GGvYqbIXnZfGvmaOb98Bweve40Jg4bzB/eXseZ97zDLU8vpq5+V8r1qXYjJyUZpydorQoN7rrNuy3Nk4j/FwJ3f3tjxXbHyzBx3lHGi6UyjogUAg8BkwAD3ACsAZ4FqoB64GpjjLVPVaWVjAzh3AnHce6E49jU0s6TH2/mubqtvLJ0GxMrBjP7zFF88ZTh5OZkJrupruTsZKjvZ/xO0CZmnmQItNNdUW/9yP4+4A1jzATgFGA18GNgrjFmLDDX/1ypflWXDuKuyyZS+9Pz+dWVJ9FlDHf+bTnTfz2XX722mi2tehWvXc5Ohvpr9vFoEM7q74ko48SCCV5D0P9v74F5G/jzexsS0SRLIh7Zi8gQYBZwHYAxpgPoEJHLgXP8kz0OzAPujEcjlffk5WTxtdNH8tVplSzctIsnPt7Mwx9u4i8fbOS0qmIuO7mCiyYN5bgCb42rEg9OSjLxLkU4KckkIuujWcctTy/mcyeWB8tmkX7fv3njM4CU6UZqpYxTDTQDj4rIKcAi4Dag3BjT5J9mO1AebmYRuQm4CWDkyJFRN1h5i4hw+ugSTh9dwva9h3iubiuvLtvGv81Zyb+/vJLTq4u59ORhXDxpKKU6SmdYwfCxkfZOrnC1o8vRkX3s2xFrrW0dnu6NkwVMAR4wxkwG2ulRsjG+3XjYj8oY86AxpsYYU1NWVhZte5WHDR0ykFvPH8ubt5/Nm7fP4tbzxtK8/zB3/X0F0375Ntc+9DF/rd1Ca9vhZDc1pQS7UTqYN241e0dH9vFP+1hsrpf72TcADcaYWv/zF/CF/Q4RqTDGNIlIBbAzXo1U6WdceQHjLizg+xeMZc2O/fxjWROvLmvipy8t5645Kzjz+BIuPamCz584lKJBOclublIFj4hTqWbvZB4T+tha3/xk6LJYs081EcPeGLNdRLaKyHhjzBrgfGCV/99s4B7/zzlxbalKSyLChKGDmTB0MHdcOI7VTfv5x/JtvLqsiR+/uJyf/30FJ40YQnnBQEoLcigZNIDSggGUDsrx/cwfQEl+DgUDslz3x7m8YS93zVnBqZWFzBhTyrTqYobk9h6CwtFFVXE4Ol2/s41731rDDz83PuzJVmMM33q8jqlVRdx89vG9Po94n6Bds30/97/T/yifj83fxISKwdSMKuKuOSv41szRvaYJNLOufhfvdxzlq9PcUZ62egXtLcBTIpIDbASux1cCek5EbgQ2A1fHp4lK+YgIE4cNZuKwwfzwc+NZuW0fry5rYunWPWxobmNhfQe7D3SEPQmXk5VBmT/4fVcA51DivxK4NPia7/2ivJyUuJnLkq27WbJ1D0u27uGxj+rJEDhp+BDOOL6UM48voaaqiLycrJATtMLfFzcyb81OaqqKmT66mOPL8sPu5I6dZIzddtbV7+K15dt5f20LX5oyvNf7nV2GuZ/tZO5nO1m6dQ+/veoUaje2sm5nGzfNGh3228C2PQe55/XPuPmc4zmhIrphN578eDOvLmvqd5q7X1kFwLwfnsPTC7fy9MLeF4Rt918UeNszSwBY0biXH188gd3tR3hpcSPfO29MSvz/05OlsDfGLAHC3SXl/Ji2RimLRIRJw4cwafiQbq93Hu1iV3sHLW0dtLQdprX9MC37fY8Dr+3Yd4hV2/bR2n6YI0d7R0yGQPGg0J3AsR1DSX4OZSGPS/JzGJAVn+sDAm1b+LPz2djczkcbWlmwoYWHPtjIn9/bQHamMLmyiOWNe4PtfnFxI++vbebvS7YBUDIoh2nVxZxeXczpo0sYX15ARoZ0K0X86d31iMCssWVMrBhs60Rvt/b69yDDCgfyxILNvd7v9G9Paf4A5q7eyRfu/5AuY2jYfZC5q3f0Gr7g+88sZkNzO8sb9/LGyu3cddlEvn76SJ5YsJnJIws5eURh2HZ8tL6FxVv3cNOs0d2G5xhZnBd8HOk7xHtrmyNu7/DCXBr3HOSp2i007D4YnGfuZzv409emRJw/0XRsHOUpWZkZHDd4oKVb4Rlj2Hewk+a2w74dQ1tgp3Bsx9DadphPtxygpe0wBzrC39Bl8MCsbt8Mej4uK8ihLH8gw4tybR3xBW4AMigni+mjS5g+ugQuHMeBjk4+qd/NRxtaWLChlYP+G83k5fj+nE+pLOS+a06ldlMrtZt2UbtxF6/7rxgdkpvNaVXFNO45CPh2jr/75xoAfvvGGkoG5XDW2FJmji3j7HFllBX07gG179ARnvx4M6dVFVMzqij4zaHT394nv3U6v/rH6uAOJ6DD//53zh7N5JGF3PTEIlrbOxg8MIu1O9qCg+j5Phu6zV9dMoi7/r6C+etaeGPldnKyMvjPfzml2/Ib9xzkzheWsbppH63tHXywrpk/fW0KuTmZvLJ0W7fPr+cY9X9b1MCY4/IR8a37HxG+AQCU5OcEf4+hO4dlDXuD4+ynEg17lbZEhCF52QzJy2bMcfkRpz/Q0UlrWwfNITuGVv+Oodn/eN3ONhZsbGXPgd53aMrNzmTc0AImVhRwQsVgTqgYzIShBRQMDD8UdKf/SDkrs/sOIi8ni7PH+cIY4O1VO/jWE3UU5flOVAtQ5b/fwDWn+erJDbsPsNAf/LWbWqn3X7yWN8AXATeeVc2JwwbzwboWPljXzJwl28jJyuD6GVX86zljup0reH9tM799w7eDOKWykJ9dcgLTqouDO6e8nCz+4/JJvcI+sDPIzsxg6qhiTqks5J3PdlJZnMf//doUzv3PeX3+7u+95hTmr2/hV6/5+q5j4NanF3ebZt2O/Xy4viX4fPGWPdz81KfcMKOKO/+2vM9lA/zged9YOYGq1oEjnf1M7RPuW2Eq07BXyqK8nCzyirOoDCkH9OVIsJzk2xns2HuIz7bvZ3XTPl5fsb1bLbiyOJcThg4O7gAmVgymsjg3GJ7ZGf33kLZy34ARRXmMKMrjS1N8Q1bPX9/CtQ/VUlXi25aS/By+NGUEX5oygq4uw+rt+3jkw3oefH8jz32ylVvPHxtcVqDe/71zx/DCogau/n8LuHBiOcX+nU1WhgTHoAnY3NrOwk2++7j23HmB78rqx2+YxuxHFoZtf4YIN806nr98sInm/Yf59qxq3lixnQ3N7WGnz84U7v7iifzkxeXBdoXz8tJtvL782FF84HxP8/7I3XtXu+wetBr2SsVBdmYG5YMHUh6mnGSMYfu+Q6xu2sfqpv2satrH6qZ9vLV6RzBs8gdkMTA7k8wMsVVDt9pXPVx5JiAjQzhx2BB+f/UpXD+jil+/vpr/8J+4DHXF5OF899wxPDJ/Ew/M2xAsw2RnZnC4R5nkvrfX8eLiRt/7fey8BlgYcjjwq8jJzOTuL57INx4Ov3MAuKamkmcWbuGNlX0PevbAvA1hQ3vHPu9dy6Fhr1SCiQgVQ3KpGJLLeROOXXh+sOMoa3bs9+8EfP+mDiqMa1si7RsmDR/Ckzeezry1zVz/6Ce9dhK5OZl899wxXHNaJffPXUdLW0fY8xIdR7soGJjFpGFDmDyyMCbtnTm2+0WaPTclI0O4fkY13392CQA/uHAcv39rbbdpTq0sDIb9V6eNpKXtMG+t2uG4falMw16pFJGbk8mplYWcWlnoaH4nNySx8j1ARDh3/HGMKsljcmVh2G8PpfkD+I/LJ4XM03s5ZQUDePqm6cem6Wfanmvoa5sunFhOw+6DfbY9tIfPBRPLyR+YFfyWsvfgkW7LzcvJ5C/frGH6r+ayfd8hcrIyep3IdTMdz14pl3PSUbLnPOKSAXsD4ezk8oBAT5uAn764vNtzd/wGnNOwV0pZFnrEHfNvEHYbE1i2wytvdx/ocLhGd9KwVyqN2QnKVDjy7dncbm2ysCl2dlCpsL2xpGGvlMekakj11a5wJaSeOyGnZabe5SoL80RRKkplGvZKeYSTaoaDATMtsROqtpYbRTvD7zCO/dKsLNtdl1F1p2GvlMuFhpTVwHcamo5PaMY4JR3X92PaCnfRsFcqndlIv3gPEW1l+Ym8TW24bwJuruxo2CvlMfEOZaeBa6ddVvvZd/tWEzJXX+P1hz7tazv66//vZhr2SqWxaG5pGD3fWm31kImmZh/u4q3QspTX0r0HDXulPMJ3I2irh93RB1t/4djzPevtsrpuZ+87vU7ACzTslXI956lltyST7BOcia3Ze4uGvVIeE6+QCizX6VF6pHZF20Oo+w3Lw6/VUs1epNtPr9CwV0olpaQRvHgpzHt9XSnb+4SrsGbHfp6q7X0bxF7ri7Aeb0V7bxr2SqWxaKoi/YVjz/diXX7pedT9s5dW9HjfyjJi2aLUp2GvlEcYYxJwUZX91I5lpmrN3jkNe6Vcrldpw85olHbCUxzMg/UhGaIN13A1+/7WGXE7PJb2GvZKqaSMZx9cY5hE7nkSuK/ByaLto99tPR4L95407JVKY9H0f4/bN4gYiFfNPtldT6OhYa+URxhsDIQW15bE7+Sn1uyd07BXyuWiCSUn9XfHY+PEOT5DmxWs2fc3fYTtCNfP3s07AA17pTzGSahaKns4aIuVdVobeMz+ODp9LSNUuMD3apdMDXullCN2dip2zw1EPuru/rOv960sI/jcwvZozV4plRJsh2qc2hGvkk1Ca/YeO8LXsFfKK5zciCQB6Zmo8eFDL/g61s++75VG/PZg8TW30LBXyuV6BVo8E8nY/zbQ1/Riow4fr5uAh2ub147oAzTslVKW9NypxL6fvfUFRioThWtbpAuyvBryARr2SnmI28ant6v3aJgRQj+KdekQx0op1wuOTR+ntA/NyURFZrh+9v1O76Bm72Ya9kp5RCLuJ2swtke+jMV4Y/E6yRu2n73nYt5Hw14pl4tFNFkpWUR1pW7Ydfb/vN+2OLgHbc+XEnleOxVo2CvlIW6rwffF8pcHhzcet7KO8KNkupflsBeRTBFZLCKv+p9Xi0itiKwXkWdFJCd+zVRKxYOTm5HYdawEE78rbqGve9BGw1vH+naO7G8DVoc8/w3wX8aYMcBu4MZYNkwp5YydfutOMjEZR7fx6BkjEn6n0t+q3Bz/lsJeREYAlwIP+Z8LcB7wgn+Sx4Er4tA+pZRF0RzNWg0xJ+voa6TMYxdKORi4LdL7YfvZ2++b7yVWj+z/APxvoMv/vATYY4zp9D9vAIaHm1FEbhKROhGpa25ujqatSqkwEhVS8b4IKXRxsaouac3+mIhhLyKXATuNMYucrMAY86AxpsYYU1NWVuZkEUopq+xeVJWiNwNxdn6299g40fDagX6WhWlmAF8UkUuAgcBg4D6gUESy/Ef3I4DG+DVTKWWVlX7igWkcZaKFmZJxUZVdIoTdlv7am6rbYkXEI3tjzE+MMSOMMVXAV4B3jDHXAu8CV/knmw3MiVsrlVIRRVWzt5hiTmv2YdcZGAjNwjLshqyVfvZ9tceroulnfydwh4isx1fDfzg2TVJK2ZGokOq5HnsnVmNbL7K66v5+N+lWs7dSxgkyxswD5vkfbwSmxb5JSimnfF0JU/MINfJVr8cmcNL/30o/ezs7KK8d6esVtEqlMUehauH4NjQonUSm5RO0NrsEhW6vr5+9vWW6Of417JXyGGf3X00CGzckiUU3Tyfj6XiJhr1SHpGIenLoUb3lC7GIfRdPyzcviaKfvddo2CvlcqFHpPEMsGiPfCMeWYc8jrbXT0xq9h47Qathr1QacxSqNudxtI+wuA67y+5Vsw+zMRa+FLiShr1SHmPr3rCBG57EuGBtqQ4f/Gn9IrBoxOIWhm7eAWjYK6UcsXwhFrEvf1g92drfZFqzV0q5kjFORoG3uw7n89o5Oo/XePb2ava9p3Xz/kHDXqk0FsvhD6KVqBPNoesLuxo312r6oWGvlMfYO4KOVxvCP+42jZVaS3Bae6/3NW20d+Zy835Aw16pNBSLselt7VQSXCC3cmOUXk3y+FVVGvZKKcuiuY1hvLM0tM6v/ex707BXyiN8V6raiyM7kweCMhEH6YkIVV9ZJ8zrIe97iYa9Ui4XTUkm/v13rIwjH/gZ3aiXVoQuV7teKqU8r2c5w8lBbH87lZ7LDzu6pIN19lx+3yd/7a/DYwfyvWjYK6XiKlEH0IkYzz7RJ5pjScNeKY8wxn6w2s0u3zqcBV7y7msVXqTx7LVmr5RKKYm7LWHi5uu5E4pV8GrNXimV3hykqa0j9XC9XiT8Tzvr7qssE26ZevMSpVTaiXeuJSM3Yz6efbh1uPjbgIa9Uh4S/zBycs9aPxtBm5AuoRGGT4j1sM/JpmGvlGfYH5veTu+SwGITcnTbq2Yf++Dt8+g/5mtKDRr2SrlcNDkYCDxHi7A4k9B/P3snJ5itj2cvIa9FunmJV2PeR8NeqTQU7wpFoiog3e9bG9ueNl6Lfg17pTwkFc8fBgdCczBPPPU5nn1wggQ0IoE07JVKY04uwkpIyT4Rg6312WMn/utOBg17pTwimvq7pRuE9xxwzeKahPAngu1cqdpzkoiDq4XrZ29xHq/SsFfK5WJxgjYVxDJstWbfm4a9Ul5iMeXi3fMkXM+XuBw5R7FM6aubUPD9cAOhOV9fsmnYK5XG7F68ZCAhiZeIi6r67mfvtWN6Hw17pTwmXveT7TlNtEfq/d0RKlYDoXW78XmkvvnOVuEaGvZKeYSj+8O6tCyRiBKL18Jfw14pl4vHFajxEPn2hE5G3nS+Ib5+9v2NjdP7tUSUl+JFw14pD7Hdb94j63BC+9krpVwtXv3soXt/+WjHsw8swMrt/xwfwXfrZx9hbByPhnyAhr1SHhHv+nssTpLGSiJKLF7rlaNhr5TLRXVEmsAztBFHnUxCtva3+VZ6CbmJhr1SHmI1jAI5lqo9eCxvh7cOvuMqYtiLSKWIvCsiq0RkpYjc5n+9WETeEpF1/p9F8W+uUiqSRN1hydZNUmz2enEyTdj5uo1n72wZXmHlyL4T+IExZiIwHfiuiEwEfgzMNcaMBeb6nyulXMhqDsbyoD6qbpNhXov2G4fXbkPYU8SwN8Y0GWM+9T/eD6wGhgOXA4/7J3scuCJObVRKWeDkBKWdgIw2ClMxSvuv2adii52zVbMXkSpgMlALlBtjmvxvbQfK+5jnJhGpE5G65ubmaNqqlAqj292arAZ+4H6yjnYQ8Snah2ZrMk+E9hfyPZvlpv2B5bAXkXzgb8D3jTH7Qt8zvk8/7MdjjHnQGFNjjKkpKyuLqrFKqchSMX+iLrHYfD34vo3x7L3OUtiLSDa+oH/KGPOi/+UdIlLhf78C2BmfJiql4s36RVUh88RxnRG/cejYOLZZ6Y0jwMPAamPMvSFvvQzM9j+eDcyJffOUUikjyppFKpY8ou0l5CZZFqaZAXwDWC4iS/yv/RS4B3hORG4ENgNXx6WFSilLjLF/dOvkaNgr96DtS38Z33sYh9S8yXs4EcPeGPMhfW//+bFtjlLKrmjGr09UUFkJ7367Yvbxlq0x6j12pG6XXkGrlMfE6+YlsVhP93UGlhOm/m5xXjvz+NZl/T2vlXE07JVSlkXzTSAVBhbr+Q2j3372KdDeWNKwV8ojDPGt2QfH03FLkdqh/nsJ9ZzWPTsEDXulXM95CSZRd16ysp7uF1XFpl2hYey1I3W7NOyV8hxHRXsHs8SmK6aVpfR1s/PQ163sIPqt2cf4huqpRsNeKWVZVEfcNsIzXt83etXs+5nWY1mvYa+UssZrR7p96bdm32Pv4KZfiYa9Uh5hjIMKvMsuqrJbOkqXHZQVGvZKuZyT/uE971TlKBPtlGXChHcguK3U7nueUA57k/IIbRCx188+/MTu7YqkYa+USgh7OxRroRrtkXv//ey9RcNeKZU2oh62oee0LtojaNgr5SF2e8vYmf7YRVXxL2XErGYfg7aEcvMFZRr2SnmMpX7r/kPSQHg5uRLUzizhMtJeP/vAcvpJ20hD4BOhZt/zeZhpXZz1GvZKuZ1bKgkRR6i0sSHBHUXUG9/PePbRLjrFaNgrpSxLVBkjURdVhWNrp+OiXYKGvVJpLFXLEqnaz15r9kqplGGrlm5n1MseC7aVo+H62QdLMZGXFDzH0M/uKdIlZSJis1QUri+/e9New14pj3AyXHFfz+Mh8lG5jS6P0TUlqNsN1HtenBajdaQKDXulXM5NY6pbZf0I2ualWrE+MHfRr17DXikPiXdN2WASUreOVc3e0Vj//bynNXulVMqwE4h2atC9+6HHZz39rbvfmn2U/eyt0LBXSiWdreAODCxmuj+Pp97rkJD/RrssZ0J/Y3rzEqVUSvNKJrkxXN3UZA17pZQtieh+aLVmH8urcq3MpF0vlVIpId5h1K2rosP5LE3fYzus3CDdynj20dKavVIqZdi7qMpYnifasOzrJitOlhurYQpCR/Ds3c/eTUWayDTslfIIexdVJS7I3FiLt8pN26Zhr5TLJTpwbJdkLE4fuhmWa/Y2lmmVi/LbFg17pTzEfm3c+fKjHc/ejkDIR9fP3qsxbo2GvVIe42QgNCtBGG1Y9n1U7qhoHxP97h/C3bxET9AqpVwlTQ5y4z1ukJu+LWjYK+URbr+xiBWJCFc3nXS1Q8NeKZcLDUDbNfgootvWGDwW9kShR+F9Td5X//tw7/VeQbh2RWxWv+t3Ew17pTzGXgj757E4S1Q7Bxv97HutJwFjzVu5OYvW7JVS3ufC8ka8m+ymko+GvVJpKJqQsnt0G8tAjGXNvq9vKS7Kb1s07JXyCIO12njPeZyyXPox1tZj5aKqqPrZhy0X2dNzejftGDTslXK5QIg17D7gfyF+62rae4jfvPFZTJYVOEoP19zL/zS/+7S96v2+Fw4d6Qq+ZndHF+lq3HA7h/bDnbbWAfB83VY2tbTbni/Wogp7EblIRNaIyHoR+XGsGqWUsu8Pb69jQ3M7761pjjhthj/JurqsB2Tn0S42tx6w3a7nFzWwY++hXq8fdXC2M7NHAr+wqCH4+K45K3tNn5NlP+Iy+vnKcu1DtbaX96MXlvGF+z+0PV+sZTmdUUQygT8BFwINwCci8rIxZlWsGqeUsq/NwtFnbnYmAM98shXwHbFHsnLbPsdt2rb3EC3tHd1e+2vtFgDeXLUj4vyB/UJxfg7bLLS1078TC2xnQFbGsfDfsusAjXsOBp8f6PD93nJzfPN8vHFXxPVkZ2VAx9GI01n5TOItmiP7acB6Y8xGY0wH8AxweWyapZSKp8yM7kevH65rsT1PTqa9+Ojo7Or3/cG52X2+l53pW/eKRt8OZ+/BI5bWmZdzLOwH5WQxfmhB8Hlo0AM8+bFv5/Ph+si/i4A7LhxnedplDXssTxsP0YT9cGBryPMG/2vdiMhNIlInInXNzZG/Xiql7BlWmEvJoJzg88euP83SfDPHlgYf/+Erp0ac/oGvTw0+/uklE8jI6P/kwM8vPaHb8z9/fUq3589/5wwAfnH5iQAUD8rh1186qVv7vnb6SB69/jTycnxFiKe/PR2AiyYNBeDtO2Z1W2Zp/gBGFufxb5dNBKCsYADfnlnNi/96JpkZwtRRRZw1xrfdBQO7Fzb+58ZpAPyfKyYB8OA3pnLHheN49LrTmDR8cK/tyx+QxbWnj6L+nku54tRhANz9hYl8/JPze237sCEDOaGi9zISSeye1AjOKHIVcJEx5lv+598ATjfGfK+veWpqakxdXZ2j9SmlVLoSkUXGmJpolhHNkX0jUBnyfIT/NaWUUikmmrD/BBgrItUikgN8BXg5Ns1SSikVS4574xhjOkXke8A/gUzgEWNM775PSimlks5x2AMYY14DXotRW5RSSsWJXkGrlFJpQMNeKaXSgIa9UkqlAQ17pZRKA44vqnK0MpFmYLPD2UsB69cxe0s6bzuk9/an87ZDem9/6LaPMsaURbOwhIZ9NESkLtoryNwqnbcd0nv703nbIb23P9bbrmUcpZRKAxr2SimVBtwU9g8muwFJlM7bDum9/em87ZDe2x/TbXdNzV4ppZRzbjqyV0op5ZCGvVJKpQFXhH063NhcROpFZLmILBGROv9rxSLylois8/8s8r8uIvJH/+9jmYhM6X/pqUVEHhGRnSKyIuQ129sqIrP9068TkdnJ2BYn+tj+u0Wk0f/5LxGRS0Le+4l/+9eIyOdDXnfd34WIVIrIuyKySkRWisht/tc9//n3s+2J+eyNMSn9D9/wyRuA0UAOsBSYmOx2xWE764HSHq/9Fvix//GPgd/4H18CvA4IMB2oTXb7bW7rLGAKsMLptgLFwEb/zyL/46Jkb1sU23838MMw0070/z8/AKj2/y1kuvXvAqgApvgfFwBr/dvo+c+/n21PyGfvhiP7dL6x+eXA4/7HjwNXhLz+hPH5GCgUkYoktM8RY8z7wK4eL9vd1s8DbxljdhljdgNvARfFvfEx0Mf29+Vy4BljzGFjzCZgPb6/CVf+XRhjmowxn/of7wdW47t3tec//362vS8x/ezdEPaWbmzuAQZ4U0QWichN/tfKjTFN/sfbgXL/Yy/+Tuxuqxd/B9/zlyoeCZQx8PD2i0gVMBmoJc0+/x7bDgn47N0Q9uniLGPMFOBi4LsiMiv0TeP7XpcW/WTTaVtDPAAcD5wKNAG/T2pr4kxE8oG/Ad83xuwLfc/rn3+YbU/IZ++GsE+LG5sbYxr9P3cCL+H7qrYjUJ7x/9zpn9yLvxO72+qp34ExZocx5qgxpgv4C77PHzy4/SKSjS/snjLGvOh/OS0+/3DbnqjP3g1h7/kbm4vIIBEpCDwGPgeswLedgV4Gs4E5/scvA9/091SYDuwN+QrsVna39Z/A50SkyP+193P+11ypxzmXK/F9/uDb/q+IyAARqQbGAgtx6d+FiAjwMLDaGHNvyFue//z72vaEffbJPkNt8Sz2JfjOXG8Afpbs9sRh+0bjO6O+FFgZ2EagBJgLrAPeBor9rwvwJ//vYzlQk+xtsLm9T+P7unoEX73xRifbCtyA76TVeuD6ZG9XlNv/P/7tW+b/w60Imf5n/u1fA1wc8rrr/i6As/CVaJYBS/z/LkmHz7+fbU/IZ6/DJSilVBpwQxlHKaVUlDTslVIqDWjYK6VUGtCwV0qpNKBhr5RSaUDDXiml0oCGvVJKpYH/D4IW1HquqnbgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1950, 1, 251) (1950, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "25/25 [==============================] - 3s 29ms/step - loss: 3614.4070 - val_loss: 2019.4213\n",
      "Epoch 2/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3355.2456 - val_loss: 1894.1211\n",
      "Epoch 3/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3242.6035 - val_loss: 1830.6848\n",
      "Epoch 4/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3146.6794 - val_loss: 1773.4261\n",
      "Epoch 5/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3049.9714 - val_loss: 1719.6010\n",
      "Epoch 6/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2964.9324 - val_loss: 1671.5311\n",
      "Epoch 7/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2883.5146 - val_loss: 1625.6338\n",
      "Epoch 8/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2804.9033 - val_loss: 1581.6277\n",
      "Epoch 9/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2728.6487 - val_loss: 1539.3124\n",
      "Epoch 10/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 2654.4951 - val_loss: 1498.5616\n",
      "Epoch 11/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 2582.2810 - val_loss: 1459.2877\n",
      "Epoch 12/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 2511.8916 - val_loss: 1421.4232\n",
      "Epoch 13/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2443.2395 - val_loss: 1384.9138\n",
      "Epoch 14/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2376.2581 - val_loss: 1349.7145\n",
      "Epoch 15/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 2310.8896 - val_loss: 1315.7855\n",
      "Epoch 16/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2247.0859 - val_loss: 1283.0916\n",
      "Epoch 17/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2184.8044 - val_loss: 1251.6002\n",
      "Epoch 18/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 2124.0078 - val_loss: 1221.2820\n",
      "Epoch 19/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2064.6606 - val_loss: 1192.1093\n",
      "Epoch 20/500\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 2006.7303 - val_loss: 1164.0580\n",
      "Epoch 21/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 1950.1866 - val_loss: 1137.1205\n",
      "Epoch 22/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1895.0017 - val_loss: 1111.4852\n",
      "Epoch 23/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1841.6189 - val_loss: 1086.5822\n",
      "Epoch 24/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1788.6107 - val_loss: 1062.7744\n",
      "Epoch 25/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1737.3433 - val_loss: 1039.9661\n",
      "Epoch 26/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1687.3319 - val_loss: 1018.1357\n",
      "Epoch 27/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1638.5535 - val_loss: 997.2618\n",
      "Epoch 28/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1590.9857 - val_loss: 977.3235\n",
      "Epoch 29/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1544.6062 - val_loss: 958.3007\n",
      "Epoch 30/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1499.3926 - val_loss: 940.1724\n",
      "Epoch 31/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1455.3245 - val_loss: 922.9191\n",
      "Epoch 32/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1412.3810 - val_loss: 906.5211\n",
      "Epoch 33/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1370.5410 - val_loss: 890.9590\n",
      "Epoch 34/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1329.7849 - val_loss: 876.2138\n",
      "Epoch 35/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1290.0929 - val_loss: 862.2667\n",
      "Epoch 36/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1251.4457 - val_loss: 849.0988\n",
      "Epoch 37/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1213.8239 - val_loss: 836.6918\n",
      "Epoch 38/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1177.2084 - val_loss: 825.0276\n",
      "Epoch 39/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1141.5811 - val_loss: 814.0878\n",
      "Epoch 40/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1106.9226 - val_loss: 803.8550\n",
      "Epoch 41/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1073.2158 - val_loss: 794.3115\n",
      "Epoch 42/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1040.4421 - val_loss: 785.4396\n",
      "Epoch 43/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1008.5840 - val_loss: 777.2220\n",
      "Epoch 44/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 977.6238 - val_loss: 769.6421\n",
      "Epoch 45/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 947.5441 - val_loss: 762.6823\n",
      "Epoch 46/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 918.3282 - val_loss: 756.3260\n",
      "Epoch 47/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 889.9586 - val_loss: 750.5566\n",
      "Epoch 48/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 862.4185 - val_loss: 745.3578\n",
      "Epoch 49/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 835.6916 - val_loss: 740.7130\n",
      "Epoch 50/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 809.7613 - val_loss: 736.6061\n",
      "Epoch 51/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 784.6111 - val_loss: 733.0212\n",
      "Epoch 52/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 760.2255 - val_loss: 729.9423\n",
      "Epoch 53/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 736.5881 - val_loss: 727.3538\n",
      "Epoch 54/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 713.6830 - val_loss: 725.2403\n",
      "Epoch 55/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 691.4951 - val_loss: 723.5860\n",
      "Epoch 56/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 670.0084 - val_loss: 722.3760\n",
      "Epoch 57/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 649.2077 - val_loss: 721.5950\n",
      "Epoch 58/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 629.0781 - val_loss: 721.2281\n",
      "Epoch 59/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 609.6045 - val_loss: 721.2607\n",
      "Epoch 60/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 590.7721 - val_loss: 721.6780\n",
      "Epoch 61/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 572.5659 - val_loss: 722.4656\n",
      "Epoch 62/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 554.9717 - val_loss: 723.6091\n",
      "Epoch 63/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 537.9751 - val_loss: 725.0947\n",
      "Epoch 64/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 521.5619 - val_loss: 726.9080\n",
      "Epoch 65/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 505.7180 - val_loss: 729.0356\n",
      "Epoch 66/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 490.4293 - val_loss: 731.4637\n",
      "Epoch 67/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 475.6824 - val_loss: 734.1786\n",
      "Epoch 68/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 461.4635 - val_loss: 737.1675\n",
      "Epoch 69/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 447.7591 - val_loss: 740.4169\n",
      "Epoch 70/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 434.5561 - val_loss: 743.9139\n",
      "Epoch 71/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 421.8413 - val_loss: 747.6462\n",
      "Epoch 72/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 409.6018 - val_loss: 751.6009\n",
      "Epoch 73/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 397.8248 - val_loss: 755.7656\n",
      "Epoch 74/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 386.4977 - val_loss: 760.1283\n",
      "Epoch 75/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 375.6080 - val_loss: 764.6770\n",
      "Epoch 76/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 365.1433 - val_loss: 769.4001\n",
      "Epoch 77/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 355.0916 - val_loss: 774.2861\n",
      "Epoch 78/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 345.4411 - val_loss: 779.3279\n",
      "Epoch 79/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 336.1783 - val_loss: 784.4848\n",
      "Epoch 80/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 327.2961 - val_loss: 789.7909\n",
      "Epoch 81/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 318.7787 - val_loss: 795.2157\n",
      "Epoch 82/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 310.6164 - val_loss: 800.7489\n",
      "Epoch 83/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 302.7979 - val_loss: 806.3799\n",
      "Epoch 84/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 295.3125 - val_loss: 812.0989\n",
      "Epoch 85/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 288.1496 - val_loss: 817.8960\n",
      "Epoch 86/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 281.2984 - val_loss: 823.7618\n",
      "Epoch 87/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 274.7487 - val_loss: 829.6867\n",
      "Epoch 88/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 268.4904 - val_loss: 835.6624\n",
      "Epoch 89/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 262.5136 - val_loss: 841.6793\n",
      "Epoch 90/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 256.8086 - val_loss: 847.7291\n",
      "Epoch 91/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 251.3656 - val_loss: 853.8038\n",
      "Epoch 92/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 246.1754 - val_loss: 859.8953\n",
      "Epoch 93/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 241.2288 - val_loss: 865.9952\n",
      "Epoch 94/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 236.5168 - val_loss: 872.0968\n",
      "Epoch 95/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 232.0307 - val_loss: 878.1928\n",
      "Epoch 96/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 227.7619 - val_loss: 884.2755\n",
      "Epoch 97/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 223.7020 - val_loss: 890.3387\n",
      "Epoch 98/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 219.8428 - val_loss: 896.3759\n",
      "Epoch 99/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 216.1764 - val_loss: 902.3811\n",
      "Epoch 100/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 212.6951 - val_loss: 908.3476\n",
      "Epoch 101/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 209.3912 - val_loss: 914.2711\n",
      "Epoch 102/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 206.2574 - val_loss: 920.1450\n",
      "Epoch 103/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 203.2865 - val_loss: 925.9646\n",
      "Epoch 104/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 200.4716 - val_loss: 931.7255\n",
      "Epoch 105/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 197.8058 - val_loss: 937.4223\n",
      "Epoch 106/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 195.2828 - val_loss: 943.0514\n",
      "Epoch 107/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 192.8960 - val_loss: 948.6079\n",
      "Epoch 108/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 190.6393 - val_loss: 954.0889\n",
      "Epoch 109/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 188.5067 - val_loss: 959.4905\n",
      "Epoch 110/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 186.4925 - val_loss: 964.8096\n",
      "Epoch 111/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 184.5911 - val_loss: 970.0425\n",
      "Epoch 112/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 182.7971 - val_loss: 975.1875\n",
      "Epoch 113/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 181.1053 - val_loss: 980.2416\n",
      "Epoch 114/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 179.5107 - val_loss: 985.2018\n",
      "Epoch 115/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 178.0085 - val_loss: 990.0668\n",
      "Epoch 116/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 176.5939 - val_loss: 994.8345\n",
      "Epoch 117/500\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 175.2626 - val_loss: 999.5040\n",
      "Epoch 118/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 174.0101 - val_loss: 1004.0726\n",
      "Epoch 119/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 172.8326 - val_loss: 1008.5406\n",
      "Epoch 120/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 171.7257 - val_loss: 1012.9058\n",
      "Epoch 121/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 170.6860 - val_loss: 1017.1680\n",
      "Epoch 122/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 169.7098 - val_loss: 1021.3264\n",
      "Epoch 123/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 168.7934 - val_loss: 1025.3810\n",
      "Epoch 124/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 167.9335 - val_loss: 1029.3318\n",
      "Epoch 125/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 167.1272 - val_loss: 1033.1777\n",
      "Epoch 126/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 166.3713 - val_loss: 1036.9194\n",
      "Epoch 127/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 165.6629 - val_loss: 1040.5582\n",
      "Epoch 128/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 164.9993 - val_loss: 1044.0934\n",
      "Epoch 129/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 164.3778 - val_loss: 1047.5258\n",
      "Epoch 130/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 163.7960 - val_loss: 1050.8561\n",
      "Epoch 131/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 163.2516 - val_loss: 1054.0854\n",
      "Epoch 132/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 162.7422 - val_loss: 1057.2147\n",
      "Epoch 133/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 162.2658 - val_loss: 1060.2452\n",
      "Epoch 134/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 161.8203 - val_loss: 1063.1779\n",
      "Epoch 135/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 161.4038 - val_loss: 1066.0139\n",
      "Epoch 136/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 161.0146 - val_loss: 1068.7556\n",
      "Epoch 137/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 160.6509 - val_loss: 1071.4033\n",
      "Epoch 138/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 160.3111 - val_loss: 1073.9591\n",
      "Epoch 139/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 159.9938 - val_loss: 1076.4246\n",
      "Epoch 140/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 159.6974 - val_loss: 1078.8020\n",
      "Epoch 141/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 159.4206 - val_loss: 1081.0919\n",
      "Epoch 142/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 159.1622 - val_loss: 1083.2975\n",
      "Epoch 143/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 158.9210 - val_loss: 1085.4198\n",
      "Epoch 144/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 158.6957 - val_loss: 1087.4607\n",
      "Epoch 145/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 158.4856 - val_loss: 1089.4225\n",
      "Epoch 146/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 158.2894 - val_loss: 1091.3073\n",
      "Epoch 147/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 158.1062 - val_loss: 1093.1166\n",
      "Epoch 148/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 157.9353 - val_loss: 1094.8525\n",
      "Epoch 149/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 157.7758 - val_loss: 1096.5176\n",
      "Epoch 150/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 157.6269 - val_loss: 1098.1130\n",
      "Epoch 151/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 157.4880 - val_loss: 1099.6410\n",
      "Epoch 152/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 157.3584 - val_loss: 1101.1041\n",
      "Epoch 153/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 157.2373 - val_loss: 1102.5035\n",
      "Epoch 154/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 157.1244 - val_loss: 1103.8420\n",
      "Epoch 155/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 157.0190 - val_loss: 1105.1212\n",
      "Epoch 156/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 156.9206 - val_loss: 1106.3435\n",
      "Epoch 157/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 156.8286 - val_loss: 1107.5104\n",
      "Epoch 158/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 156.7428 - val_loss: 1108.6234\n",
      "Epoch 159/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 156.6627 - val_loss: 1109.6853\n",
      "Epoch 160/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 156.5880 - val_loss: 1110.6971\n",
      "Epoch 161/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 156.5181 - val_loss: 1111.6617\n",
      "Epoch 162/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 156.4529 - val_loss: 1112.5801\n",
      "Epoch 163/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 156.3919 - val_loss: 1113.4537\n",
      "Epoch 164/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 156.3350 - val_loss: 1114.2852\n",
      "Epoch 165/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 156.2818 - val_loss: 1115.0752\n",
      "Epoch 166/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 156.2322 - val_loss: 1115.8259\n",
      "Epoch 167/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 156.1858 - val_loss: 1116.5393\n",
      "Epoch 168/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 156.1424 - val_loss: 1117.2167\n",
      "Epoch 169/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 156.1019 - val_loss: 1117.8601\n",
      "Epoch 170/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 156.0641 - val_loss: 1118.4695\n",
      "Epoch 171/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 156.0287 - val_loss: 1119.0472\n",
      "Epoch 172/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.9957 - val_loss: 1119.5953\n",
      "Epoch 173/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.9648 - val_loss: 1120.1141\n",
      "Epoch 174/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.9360 - val_loss: 1120.6055\n",
      "Epoch 175/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.9091 - val_loss: 1121.0704\n",
      "Epoch 176/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.8839 - val_loss: 1121.5098\n",
      "Epoch 177/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.8604 - val_loss: 1121.9257\n",
      "Epoch 178/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.8385 - val_loss: 1122.3185\n",
      "Epoch 179/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.8179 - val_loss: 1122.6899\n",
      "Epoch 180/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.7988 - val_loss: 1123.0403\n",
      "Epoch 181/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 155.7809 - val_loss: 1123.3713\n",
      "Epoch 182/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.7642 - val_loss: 1123.6832\n",
      "Epoch 183/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.7487 - val_loss: 1123.9781\n",
      "Epoch 184/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 155.7341 - val_loss: 1124.2555\n",
      "Epoch 185/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.7206 - val_loss: 1124.5168\n",
      "Epoch 186/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.7079 - val_loss: 1124.7634\n",
      "Epoch 187/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.6962 - val_loss: 1124.9950\n",
      "Epoch 188/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 155.6852 - val_loss: 1125.2134\n",
      "Epoch 189/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 155.6750 - val_loss: 1125.4185\n",
      "Epoch 190/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.6655 - val_loss: 1125.6121\n",
      "Epoch 191/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.6567 - val_loss: 1125.7933\n",
      "Epoch 192/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.6484 - val_loss: 1125.9641\n",
      "Epoch 193/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.6407 - val_loss: 1126.1251\n",
      "Epoch 194/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.6335 - val_loss: 1126.2753\n",
      "Epoch 195/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.6270 - val_loss: 1126.4167\n",
      "Epoch 196/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.6208 - val_loss: 1126.5494\n",
      "Epoch 197/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.6151 - val_loss: 1126.6743\n",
      "Epoch 198/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 155.6098 - val_loss: 1126.7910\n",
      "Epoch 199/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 155.6049 - val_loss: 1126.9001\n",
      "Epoch 200/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.6003 - val_loss: 1127.0032\n",
      "Epoch 201/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5962 - val_loss: 1127.0986\n",
      "Epoch 202/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5923 - val_loss: 1127.1886\n",
      "Epoch 203/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5887 - val_loss: 1127.2728\n",
      "Epoch 204/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5854 - val_loss: 1127.3518\n",
      "Epoch 205/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5823 - val_loss: 1127.4252\n",
      "Epoch 206/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5795 - val_loss: 1127.4941\n",
      "Epoch 207/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5770 - val_loss: 1127.5582\n",
      "Epoch 208/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5746 - val_loss: 1127.6185\n",
      "Epoch 209/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5724 - val_loss: 1127.6746\n",
      "Epoch 210/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5705 - val_loss: 1127.7273\n",
      "Epoch 211/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5686 - val_loss: 1127.7765\n",
      "Epoch 212/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5670 - val_loss: 1127.8218\n",
      "Epoch 213/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5655 - val_loss: 1127.8645\n",
      "Epoch 214/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5641 - val_loss: 1127.9045\n",
      "Epoch 215/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5629 - val_loss: 1127.9414\n",
      "Epoch 216/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 155.5618 - val_loss: 1127.9756\n",
      "Epoch 217/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5608 - val_loss: 1128.0079\n",
      "Epoch 218/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5599 - val_loss: 1128.0381\n",
      "Epoch 219/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 155.5591 - val_loss: 1128.0660\n",
      "Epoch 220/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5584 - val_loss: 1128.0914\n",
      "Epoch 221/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5578 - val_loss: 1128.1157\n",
      "Epoch 222/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5572 - val_loss: 1128.1390\n",
      "Epoch 223/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5567 - val_loss: 1128.1593\n",
      "Epoch 224/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5563 - val_loss: 1128.1793\n",
      "Epoch 225/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 155.5559 - val_loss: 1128.1974\n",
      "Epoch 226/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 155.5556 - val_loss: 1128.2139\n",
      "Epoch 227/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5554 - val_loss: 1128.2291\n",
      "Epoch 228/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5552 - val_loss: 1128.2435\n",
      "Epoch 229/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5550 - val_loss: 1128.2570\n",
      "Epoch 230/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5549 - val_loss: 1128.2692\n",
      "Epoch 231/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5549 - val_loss: 1128.2806\n",
      "Epoch 232/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5548 - val_loss: 1128.2916\n",
      "Epoch 233/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5548 - val_loss: 1128.3016\n",
      "Epoch 234/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5548 - val_loss: 1128.3109\n",
      "Epoch 235/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5548 - val_loss: 1128.3196\n",
      "Epoch 236/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5549 - val_loss: 1128.3270\n",
      "Epoch 237/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5550 - val_loss: 1128.3345\n",
      "Epoch 238/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5551 - val_loss: 1128.3412\n",
      "Epoch 239/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5552 - val_loss: 1128.3470\n",
      "Epoch 240/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5553 - val_loss: 1128.3525\n",
      "Epoch 241/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5555 - val_loss: 1128.3572\n",
      "Epoch 242/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5557 - val_loss: 1128.3622\n",
      "Epoch 243/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5559 - val_loss: 1128.3667\n",
      "Epoch 244/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5560 - val_loss: 1128.3710\n",
      "Epoch 245/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5562 - val_loss: 1128.3745\n",
      "Epoch 246/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5564 - val_loss: 1128.3779\n",
      "Epoch 247/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5567 - val_loss: 1128.3812\n",
      "Epoch 248/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5568 - val_loss: 1128.3842\n",
      "Epoch 249/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5571 - val_loss: 1128.3865\n",
      "Epoch 250/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5573 - val_loss: 1128.3895\n",
      "Epoch 251/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 155.5575 - val_loss: 1128.3910\n",
      "Epoch 252/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5577 - val_loss: 1128.3931\n",
      "Epoch 253/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5580 - val_loss: 1128.3953\n",
      "Epoch 254/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5582 - val_loss: 1128.3964\n",
      "Epoch 255/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5585 - val_loss: 1128.3977\n",
      "Epoch 256/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5587 - val_loss: 1128.3992\n",
      "Epoch 257/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5589 - val_loss: 1128.4003\n",
      "Epoch 258/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5592 - val_loss: 1128.4016\n",
      "Epoch 259/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5594 - val_loss: 1128.4025\n",
      "Epoch 260/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5597 - val_loss: 1128.4036\n",
      "Epoch 261/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5599 - val_loss: 1128.4043\n",
      "Epoch 262/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5601 - val_loss: 1128.4049\n",
      "Epoch 263/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5603 - val_loss: 1128.4056\n",
      "Epoch 264/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5606 - val_loss: 1128.4064\n",
      "Epoch 265/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5608 - val_loss: 1128.4076\n",
      "Epoch 266/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 155.5610 - val_loss: 1128.4080\n",
      "Epoch 267/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5612 - val_loss: 1128.4082\n",
      "Epoch 268/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5614 - val_loss: 1128.4082\n",
      "Epoch 269/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5616 - val_loss: 1128.4083\n",
      "Epoch 270/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5619 - val_loss: 1128.4084\n",
      "Epoch 271/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5621 - val_loss: 1128.4087\n",
      "Epoch 272/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5623 - val_loss: 1128.4089\n",
      "Epoch 273/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5625 - val_loss: 1128.4089\n",
      "Epoch 274/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5627 - val_loss: 1127.7899\n",
      "Epoch 275/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 155.8324 - val_loss: 1127.8685\n",
      "Epoch 276/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.6398 - val_loss: 1127.9919\n",
      "Epoch 277/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.6175 - val_loss: 1128.0344\n",
      "Epoch 278/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.6097 - val_loss: 1128.0657\n",
      "Epoch 279/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.6050 - val_loss: 1128.0934\n",
      "Epoch 280/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.6014 - val_loss: 1128.1169\n",
      "Epoch 281/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5986 - val_loss: 1128.1387\n",
      "Epoch 282/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5964 - val_loss: 1128.1587\n",
      "Epoch 283/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5945 - val_loss: 1128.1764\n",
      "Epoch 284/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5928 - val_loss: 1128.1925\n",
      "Epoch 285/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5914 - val_loss: 1128.2074\n",
      "Epoch 286/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5902 - val_loss: 1128.2209\n",
      "Epoch 287/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5892 - val_loss: 1128.2335\n",
      "Epoch 288/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5881 - val_loss: 1128.2451\n",
      "Epoch 289/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5873 - val_loss: 1128.2552\n",
      "Epoch 290/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5865 - val_loss: 1128.2651\n",
      "Epoch 291/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5858 - val_loss: 1128.2739\n",
      "Epoch 292/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5852 - val_loss: 1128.2820\n",
      "Epoch 293/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5847 - val_loss: 1128.2894\n",
      "Epoch 294/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5841 - val_loss: 1128.2964\n",
      "Epoch 295/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5837 - val_loss: 1128.3031\n",
      "Epoch 296/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5832 - val_loss: 1128.3088\n",
      "Epoch 297/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5829 - val_loss: 1128.3142\n",
      "Epoch 298/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5825 - val_loss: 1128.3192\n",
      "Epoch 299/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5822 - val_loss: 1128.3242\n",
      "Epoch 300/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5819 - val_loss: 1128.3278\n",
      "Epoch 301/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5816 - val_loss: 1128.3324\n",
      "Epoch 302/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 155.5814 - val_loss: 1128.3353\n",
      "Epoch 303/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5812 - val_loss: 1128.3387\n",
      "Epoch 304/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5810 - val_loss: 1128.3416\n",
      "Epoch 305/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5809 - val_loss: 1128.3445\n",
      "Epoch 306/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 155.5807 - val_loss: 1128.3469\n",
      "Epoch 307/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5806 - val_loss: 1128.3496\n",
      "Epoch 308/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5805 - val_loss: 1128.3519\n",
      "Epoch 309/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5803 - val_loss: 1128.3536\n",
      "Epoch 310/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3557\n",
      "Epoch 311/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5801 - val_loss: 1128.3577\n",
      "Epoch 312/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5800 - val_loss: 1128.3593\n",
      "Epoch 313/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5799 - val_loss: 1128.3604\n",
      "Epoch 314/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5799 - val_loss: 1128.3621\n",
      "Epoch 315/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5798 - val_loss: 1128.3633\n",
      "Epoch 316/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5798 - val_loss: 1128.3644\n",
      "Epoch 317/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5797 - val_loss: 1128.3652\n",
      "Epoch 318/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5797 - val_loss: 1128.3665\n",
      "Epoch 319/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5796 - val_loss: 1128.3672\n",
      "Epoch 320/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5796 - val_loss: 1128.3679\n",
      "Epoch 321/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5796 - val_loss: 1128.3685\n",
      "Epoch 322/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3696\n",
      "Epoch 323/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3702\n",
      "Epoch 324/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3705\n",
      "Epoch 325/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3710\n",
      "Epoch 326/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3711\n",
      "Epoch 327/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3718\n",
      "Epoch 328/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5795 - val_loss: 1128.3722\n",
      "Epoch 329/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5794 - val_loss: 1128.3724\n",
      "Epoch 330/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3728\n",
      "Epoch 331/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 155.5795 - val_loss: 1128.3734\n",
      "Epoch 332/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3734\n",
      "Epoch 333/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3737\n",
      "Epoch 334/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3737\n",
      "Epoch 335/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3739\n",
      "Epoch 336/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3739\n",
      "Epoch 337/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3739\n",
      "Epoch 338/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3740\n",
      "Epoch 339/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5796 - val_loss: 1128.3744\n",
      "Epoch 340/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3745\n",
      "Epoch 341/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5795 - val_loss: 1128.3749\n",
      "Epoch 342/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5795 - val_loss: 1128.3751\n",
      "Epoch 343/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3751\n",
      "Epoch 344/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5795 - val_loss: 1128.3752\n",
      "Epoch 345/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5795 - val_loss: 1128.3754\n",
      "Epoch 346/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5796 - val_loss: 1128.3754\n",
      "Epoch 347/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5796 - val_loss: 1128.3755\n",
      "Epoch 348/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5796 - val_loss: 1128.3756\n",
      "Epoch 349/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5796 - val_loss: 1128.3756\n",
      "Epoch 350/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5796 - val_loss: 1128.3751\n",
      "Epoch 351/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5797 - val_loss: 1128.3751\n",
      "Epoch 352/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5797 - val_loss: 1128.3756\n",
      "Epoch 353/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5797 - val_loss: 1128.3759\n",
      "Epoch 354/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5797 - val_loss: 1128.3759\n",
      "Epoch 355/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5796 - val_loss: 1128.3756\n",
      "Epoch 356/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 155.5797 - val_loss: 1128.3759\n",
      "Epoch 357/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5797 - val_loss: 1128.3760\n",
      "Epoch 358/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5797 - val_loss: 1128.3763\n",
      "Epoch 359/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5797 - val_loss: 1128.3763\n",
      "Epoch 360/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5797 - val_loss: 1128.3766\n",
      "Epoch 361/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5797 - val_loss: 1128.3763\n",
      "Epoch 362/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5797 - val_loss: 1128.3763\n",
      "Epoch 363/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 155.5798 - val_loss: 1128.3763\n",
      "Epoch 364/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5798 - val_loss: 1128.3767\n",
      "Epoch 365/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5798 - val_loss: 1128.3767\n",
      "Epoch 366/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5798 - val_loss: 1128.3770\n",
      "Epoch 367/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5797 - val_loss: 1128.3767\n",
      "Epoch 368/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5798 - val_loss: 1128.3767\n",
      "Epoch 369/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5798 - val_loss: 1128.3765\n",
      "Epoch 370/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5798 - val_loss: 1128.3763\n",
      "Epoch 371/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5798 - val_loss: 1128.3763\n",
      "Epoch 372/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5798 - val_loss: 1128.3763\n",
      "Epoch 373/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5798 - val_loss: 1128.3763\n",
      "Epoch 374/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5798 - val_loss: 1128.3761\n",
      "Epoch 375/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5799 - val_loss: 1128.3763\n",
      "Epoch 376/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5799 - val_loss: 1128.3763\n",
      "Epoch 377/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5798 - val_loss: 1128.3763\n",
      "Epoch 378/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5799 - val_loss: 1128.3763\n",
      "Epoch 379/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5799 - val_loss: 1128.3763\n",
      "Epoch 380/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5799 - val_loss: 1128.3763\n",
      "Epoch 381/500\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 155.5799 - val_loss: 1128.3761\n",
      "Epoch 382/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5799 - val_loss: 1128.3760\n",
      "Epoch 383/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5799 - val_loss: 1128.3756\n",
      "Epoch 384/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5799 - val_loss: 1128.3754\n",
      "Epoch 385/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5799 - val_loss: 1128.3749\n",
      "Epoch 386/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3748\n",
      "Epoch 387/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3745\n",
      "Epoch 388/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3746\n",
      "Epoch 389/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3746\n",
      "Epoch 390/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3748\n",
      "Epoch 391/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5801 - val_loss: 1128.3749\n",
      "Epoch 392/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3756\n",
      "Epoch 393/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3756\n",
      "Epoch 394/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3762\n",
      "Epoch 395/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5800 - val_loss: 1128.3765\n",
      "Epoch 396/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3766\n",
      "Epoch 397/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3767\n",
      "Epoch 398/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5799 - val_loss: 1128.3767\n",
      "Epoch 399/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 155.5800 - val_loss: 1128.3770\n",
      "Epoch 400/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5800 - val_loss: 1128.3766\n",
      "Epoch 401/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3766\n",
      "Epoch 402/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3763\n",
      "Epoch 403/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3763\n",
      "Epoch 404/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3763\n",
      "Epoch 405/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3761\n",
      "Epoch 406/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 155.5800 - val_loss: 1128.3761\n",
      "Epoch 407/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5800 - val_loss: 1128.3761\n",
      "Epoch 408/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3761\n",
      "Epoch 409/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3759\n",
      "Epoch 410/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3759\n",
      "Epoch 411/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3756\n",
      "Epoch 412/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3751\n",
      "Epoch 413/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5800 - val_loss: 1128.3746\n",
      "Epoch 414/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3745\n",
      "Epoch 415/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5801 - val_loss: 1128.3744\n",
      "Epoch 416/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3744\n",
      "Epoch 417/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3743\n",
      "Epoch 418/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5801 - val_loss: 1128.3741\n",
      "Epoch 419/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3741\n",
      "Epoch 420/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3739\n",
      "Epoch 421/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3740\n",
      "Epoch 422/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3739\n",
      "Epoch 423/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3741\n",
      "Epoch 424/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3739\n",
      "Epoch 425/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3738\n",
      "Epoch 426/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3737\n",
      "Epoch 427/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3730\n",
      "Epoch 428/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3728\n",
      "Epoch 429/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 155.5802 - val_loss: 1128.3728\n",
      "Epoch 430/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3728\n",
      "Epoch 431/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3728\n",
      "Epoch 432/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5803 - val_loss: 1128.3728\n",
      "Epoch 433/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3729\n",
      "Epoch 434/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5803 - val_loss: 1128.3732\n",
      "Epoch 435/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3732\n",
      "Epoch 436/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3732\n",
      "Epoch 437/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3732\n",
      "Epoch 438/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3730\n",
      "Epoch 439/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3730\n",
      "Epoch 440/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3730\n",
      "Epoch 441/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3735\n",
      "Epoch 442/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3738\n",
      "Epoch 443/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3740\n",
      "Epoch 444/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3744\n",
      "Epoch 445/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3744\n",
      "Epoch 446/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3748\n",
      "Epoch 447/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3749\n",
      "Epoch 448/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3749\n",
      "Epoch 449/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3751\n",
      "Epoch 450/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3751\n",
      "Epoch 451/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 155.5802 - val_loss: 1128.3751\n",
      "Epoch 452/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 155.5802 - val_loss: 1128.3751\n",
      "Epoch 453/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3750\n",
      "Epoch 454/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3751\n",
      "Epoch 455/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3755\n",
      "Epoch 456/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5801 - val_loss: 1128.3756\n",
      "Epoch 457/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3756\n",
      "Epoch 458/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3756\n",
      "Epoch 459/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3756\n",
      "Epoch 460/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3759\n",
      "Epoch 461/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3761\n",
      "Epoch 462/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3761\n",
      "Epoch 463/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3761\n",
      "Epoch 464/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3761\n",
      "Epoch 465/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3760\n",
      "Epoch 466/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3760\n",
      "Epoch 467/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3760\n",
      "Epoch 468/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3760\n",
      "Epoch 469/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3759\n",
      "Epoch 470/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3759\n",
      "Epoch 471/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3757\n",
      "Epoch 472/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3757\n",
      "Epoch 473/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 155.5802 - val_loss: 1128.3760\n",
      "Epoch 474/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5802 - val_loss: 1128.3760\n",
      "Epoch 475/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3760\n",
      "Epoch 476/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3761\n",
      "Epoch 477/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3762\n",
      "Epoch 478/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3761\n",
      "Epoch 479/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3761\n",
      "Epoch 480/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5801 - val_loss: 1128.3761\n",
      "Epoch 481/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5801 - val_loss: 1128.3760\n",
      "Epoch 482/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3759\n",
      "Epoch 483/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5801 - val_loss: 1128.3757\n",
      "Epoch 484/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3756\n",
      "Epoch 485/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3755\n",
      "Epoch 486/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3751\n",
      "Epoch 487/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3750\n",
      "Epoch 488/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3744\n",
      "Epoch 489/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3741\n",
      "Epoch 490/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5801 - val_loss: 1128.3735\n",
      "Epoch 491/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3728\n",
      "Epoch 492/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 155.5801 - val_loss: 1128.3718\n",
      "Epoch 493/500\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 155.5801 - val_loss: 1128.3702\n",
      "Epoch 494/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 155.5801 - val_loss: 1128.3674\n",
      "Epoch 495/500\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 155.5801 - val_loss: 1128.3608\n",
      "Epoch 496/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3441\n",
      "Epoch 497/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5790 - val_loss: 1126.9435\n",
      "Epoch 498/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5801 - val_loss: 1128.3759\n",
      "Epoch 499/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 155.5802 - val_loss: 1128.3756\n",
      "Epoch 500/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 1128.3750\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 393ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.71292192e+01, 5.70097987e+01, 5.68904383e+01, 5.67732777e+01,\n",
       "        5.66571173e+01, 1.67232350e-01, 4.66377380e-01, 1.00476260e-01,\n",
       "        0.00000000e+00, 4.84586540e-01, 2.13533160e-01, 3.05208620e-01,\n",
       "        6.48720090e-01, 5.73506769e+01, 5.72246265e+01, 5.70985761e+01,\n",
       "        1.71529650e-01, 2.09573240e-01, 5.76541316e+01, 5.75280812e+01,\n",
       "        5.74020308e+01, 5.72757980e+01, 5.71599930e+01, 5.70427885e+01,\n",
       "        5.69291835e+01, 5.68175789e+01, 5.67059737e+01, 4.30057615e-01,\n",
       "        0.00000000e+00, 5.72012839e+01, 5.70752334e+01, 5.69491830e+01,\n",
       "        5.68231326e+01, 5.66935808e+01, 5.64162698e+01, 5.61389589e+01,\n",
       "        5.58616480e+01, 5.55900327e+01, 8.74598384e-01, 5.82692683e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.65390253e-01, 0.00000000e+00, 0.00000000e+00, 5.68423801e+01,\n",
       "        5.67307748e+01, 0.00000000e+00, 4.06541169e-01, 5.72292950e+01,\n",
       "        5.71032446e+01, 5.69771942e+01, 5.68511438e+01, 5.67250934e+01,\n",
       "        5.64778945e+01, 5.62005836e+01, 5.59232726e+01, 5.56459617e+01,\n",
       "        0.00000000e+00, 4.33232427e-01, 5.67764472e+01, 5.65908730e+01,\n",
       "        5.63135621e+01, 5.60362512e+01, 5.57589402e+01, 5.81770075e+01,\n",
       "        5.77988562e+01, 5.74207050e+01, 6.62716980e-01, 0.00000000e+00,\n",
       "        4.03643970e-01, 5.46661339e+01, 2.22946980e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.52457500e-01, 2.97570199e-01, 2.88791180e-01,\n",
       "        5.86462135e+01, 7.43730605e-01, 5.53930104e-01, 4.38755974e-02,\n",
       "        8.26496243e-01, 0.00000000e+00, 0.00000000e+00, 4.69095916e-01,\n",
       "        6.57174110e-01, 0.00000000e+00, 4.37279880e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.07519031e-01, 0.00000000e+00,\n",
       "        9.07415032e-01, 7.48401642e-01, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46.17397008, 46.16413199, 46.15429391, 46.14445583, 46.13461775,\n",
       "       46.12477967, 46.11494159, 46.1051035 , 46.09526542, 46.08542734,\n",
       "       46.07558926, 46.06575118, 46.0559131 , 46.04607502, 46.03623693,\n",
       "       46.02639885, 46.01656077, 46.00672269, 45.99688461, 45.98704653,\n",
       "       45.97720844, 45.96737036, 45.95753228, 45.9476942 , 45.93785612,\n",
       "       45.92801804, 45.91817995, 45.90834187, 45.89850379, 45.88866571,\n",
       "       45.87882763, 45.86898955, 45.85915147, 45.84931338, 45.8394753 ,\n",
       "       45.82963722, 45.81979914, 45.80996106, 45.80012298, 45.79028489,\n",
       "       45.78044681, 45.77060873, 45.76077065, 45.75093257, 45.74109449,\n",
       "       45.73125641, 45.72141832, 45.71158024, 45.70174216, 45.69190408,\n",
       "       45.682066  , 45.67222792, 45.66238983, 45.65255175, 45.64271367,\n",
       "       45.63287559, 45.62303751, 45.61319943, 45.60336134, 45.59352326,\n",
       "       45.58368518, 45.5738471 , 45.56400902, 45.55417094, 45.54433286,\n",
       "       45.53449477, 45.52465669, 45.51481861, 45.50498053, 45.49514245,\n",
       "       45.48530437, 45.47546628, 45.4656282 , 45.45579012, 45.44595204,\n",
       "       45.43611396, 45.42627588, 45.41643779, 45.40659971, 45.39676163,\n",
       "       45.38692355, 45.37708547, 45.36724739, 45.35740931, 45.34757122,\n",
       "       45.33773314, 45.32789506, 45.31805698, 45.3082189 , 45.29838082,\n",
       "       45.28854273, 45.27870465, 45.26886657, 45.25902849, 45.24919041,\n",
       "       45.23935233, 45.22951424, 45.21967616, 45.20983808, 45.2       ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.8630584434183\n",
      "29.20746175233353\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
