{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2395    46.223160\n",
       "2396    46.213322\n",
       "2397    46.203484\n",
       "2398    46.193646\n",
       "2399    46.183808\n",
       "Name: C6, Length: 2400, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_2300_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2295     0.000000\n",
       "2296     0.000000\n",
       "2297     0.114564\n",
       "2298     0.095454\n",
       "2299     0.000000\n",
       "Name: C6, Length: 2300, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2300)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1850, 1, 251) (1850, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 2s 21ms/step - loss: 3691.7686 - val_loss: 2158.3582\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3453.2605 - val_loss: 2004.9991\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3340.6487 - val_loss: 1950.0286\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3259.9641 - val_loss: 1897.5436\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3167.9419 - val_loss: 1842.7333\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3089.2878 - val_loss: 1795.7427\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3014.1643 - val_loss: 1750.6254\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2941.3142 - val_loss: 1707.1027\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2870.3811 - val_loss: 1665.0037\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2801.1577 - val_loss: 1624.2222\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2733.5110 - val_loss: 1584.6848\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2667.3511 - val_loss: 1546.3357\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2602.6084 - val_loss: 1509.1317\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2539.2285 - val_loss: 1473.0364\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2477.1687 - val_loss: 1438.0186\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2416.3896 - val_loss: 1404.0505\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2356.8599 - val_loss: 1371.1074\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2298.5500 - val_loss: 1339.1664\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2241.4338 - val_loss: 1308.2062\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2185.4866 - val_loss: 1278.2068\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2130.6865 - val_loss: 1249.1488\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2077.0120 - val_loss: 1221.0144\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2024.4436 - val_loss: 1193.7855\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1972.9617 - val_loss: 1166.1957\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1912.0784 - val_loss: 1138.4673\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1857.2404 - val_loss: 1112.8148\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1804.7527 - val_loss: 1088.3613\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1754.2289 - val_loss: 1064.9598\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1705.3093 - val_loss: 1042.5275\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1657.7998 - val_loss: 1021.0113\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1611.5828 - val_loss: 1000.3733\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1566.5778 - val_loss: 980.5837\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1522.7257 - val_loss: 961.6262\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1479.9860 - val_loss: 943.4034\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1438.3015 - val_loss: 926.0022\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1397.6577 - val_loss: 909.3574\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1358.0192 - val_loss: 893.4510\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1319.3601 - val_loss: 878.2657\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1281.6570 - val_loss: 863.7846\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1244.8875 - val_loss: 849.9916\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1209.0308 - val_loss: 836.8713\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1174.0680 - val_loss: 824.4083\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1139.9806 - val_loss: 812.5883\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1106.7507 - val_loss: 801.3962\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1074.3613 - val_loss: 790.8186\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1042.7965 - val_loss: 780.8408\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1012.0398 - val_loss: 771.4495\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 982.0760 - val_loss: 762.6311\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 952.8900 - val_loss: 754.3722\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 924.4672 - val_loss: 746.6598\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 896.7933 - val_loss: 739.4807\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 869.8542 - val_loss: 732.8224\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 843.6359 - val_loss: 726.6721\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 818.1248 - val_loss: 721.0170\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 793.3078 - val_loss: 715.8449\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 769.1715 - val_loss: 711.1440\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 745.7032 - val_loss: 706.9025\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 722.8901 - val_loss: 703.1154\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 700.7411 - val_loss: 699.7588\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 679.1768 - val_loss: 696.8425\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 658.2528 - val_loss: 694.3133\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 637.9358 - val_loss: 692.1835\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 618.2126 - val_loss: 690.4410\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 599.0714 - val_loss: 689.0749\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 580.5004 - val_loss: 688.0734\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 562.4882 - val_loss: 687.4257\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 545.0229 - val_loss: 687.1204\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 528.0934 - val_loss: 687.1465\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 511.6887 - val_loss: 687.4932\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 495.7976 - val_loss: 688.1495\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 480.4090 - val_loss: 689.1048\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 465.5120 - val_loss: 690.3484\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 451.0960 - val_loss: 691.8700\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 437.1504 - val_loss: 693.6590\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 423.6644 - val_loss: 695.7050\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 410.6279 - val_loss: 697.9980\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 398.0303 - val_loss: 700.5278\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 385.8616 - val_loss: 703.2845\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 374.1117 - val_loss: 706.2581\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 362.7704 - val_loss: 709.4388\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 351.8282 - val_loss: 712.8172\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 341.2748 - val_loss: 716.3835\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 331.1011 - val_loss: 720.1287\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 321.2972 - val_loss: 724.0429\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 311.8537 - val_loss: 728.1173\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 302.7613 - val_loss: 732.3430\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 294.0107 - val_loss: 736.7109\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 285.5929 - val_loss: 741.2122\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 277.4988 - val_loss: 745.8383\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 269.7198 - val_loss: 750.5806\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 262.2469 - val_loss: 755.4309\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 255.0713 - val_loss: 760.3809\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 248.1849 - val_loss: 765.4225\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 241.5788 - val_loss: 770.5476\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 235.2450 - val_loss: 775.7490\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 229.1753 - val_loss: 781.0184\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 223.3616 - val_loss: 786.3484\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 217.7962 - val_loss: 791.7320\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 212.4710 - val_loss: 797.1617\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 207.3785 - val_loss: 802.6312\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 202.5110 - val_loss: 808.1328\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 197.8613 - val_loss: 813.6605\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 193.4220 - val_loss: 819.2075\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 189.1859 - val_loss: 824.7672\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 185.1462 - val_loss: 830.3340\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 181.2959 - val_loss: 835.9019\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 177.6282 - val_loss: 841.4646\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 174.1366 - val_loss: 847.0170\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 170.8145 - val_loss: 852.5537\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 167.6557 - val_loss: 858.0689\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 164.6540 - val_loss: 863.5583\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 161.8033 - val_loss: 869.0167\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 159.0977 - val_loss: 874.4395\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 156.5315 - val_loss: 879.8220\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 154.0989 - val_loss: 885.1602\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 151.7946 - val_loss: 890.4502\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 149.6132 - val_loss: 895.6879\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 147.5495 - val_loss: 900.8689\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 145.5984 - val_loss: 905.9910\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 143.7549 - val_loss: 911.0500\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 142.0145 - val_loss: 916.0430\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 140.3723 - val_loss: 920.9667\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 138.8240 - val_loss: 925.8193\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 137.3650 - val_loss: 930.5973\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 135.9914 - val_loss: 935.2986\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 134.6988 - val_loss: 939.9213\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 133.4835 - val_loss: 944.4626\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 132.3416 - val_loss: 948.9219\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 131.2694 - val_loss: 953.2962\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 130.2634 - val_loss: 957.5851\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 129.3202 - val_loss: 961.7870\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 128.4364 - val_loss: 965.9006\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 127.6089 - val_loss: 969.9250\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 126.8349 - val_loss: 973.8591\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 126.1111 - val_loss: 977.7029\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 125.4349 - val_loss: 981.4553\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 124.8036 - val_loss: 985.1164\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 124.2147 - val_loss: 988.6851\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 123.6657 - val_loss: 992.1624\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 123.1542 - val_loss: 995.5480\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 122.6781 - val_loss: 998.8422\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 122.2352 - val_loss: 1002.0446\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 121.8235 - val_loss: 1005.1562\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 121.4410 - val_loss: 1008.1780\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 121.0860 - val_loss: 1011.1101\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 120.7566 - val_loss: 1013.9533\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 120.4513 - val_loss: 1016.7086\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 120.1685 - val_loss: 1019.3770\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 119.9066 - val_loss: 1021.9591\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 119.6644 - val_loss: 1024.4565\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 119.4404 - val_loss: 1026.8706\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 119.2335 - val_loss: 1029.2024\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 119.0424 - val_loss: 1031.4534\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 118.8660 - val_loss: 1033.6243\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 118.7034 - val_loss: 1035.7175\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 118.5535 - val_loss: 1037.7336\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 118.4155 - val_loss: 1039.6750\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 118.2884 - val_loss: 1041.5427\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 118.1714 - val_loss: 1043.3389\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 118.0639 - val_loss: 1045.0648\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 117.9651 - val_loss: 1046.7225\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 117.8743 - val_loss: 1048.3125\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 117.7909 - val_loss: 1049.8389\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 117.7144 - val_loss: 1051.3009\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 117.6442 - val_loss: 1052.7015\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 117.5798 - val_loss: 1054.0422\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 117.5209 - val_loss: 1055.3253\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 117.4668 - val_loss: 1056.5520\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 117.4173 - val_loss: 1057.7236\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 117.3721 - val_loss: 1058.8430\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 117.3306 - val_loss: 1059.9108\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 117.2927 - val_loss: 1060.9294\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 117.2580 - val_loss: 1061.9004\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 117.2263 - val_loss: 1062.8247\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 117.1974 - val_loss: 1063.7053\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 117.1709 - val_loss: 1064.5426\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 117.1468 - val_loss: 1065.3395\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 117.1247 - val_loss: 1066.0961\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 117.1045 - val_loss: 1066.8143\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 117.0862 - val_loss: 1067.4966\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 117.0695 - val_loss: 1068.1432\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 117.0542 - val_loss: 1068.7565\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 117.0403 - val_loss: 1069.3373\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 117.0276 - val_loss: 1069.8866\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 117.0161 - val_loss: 1070.4072\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 117.0056 - val_loss: 1070.8989\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 116.9960 - val_loss: 1071.3641\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9874 - val_loss: 1071.8033\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 116.9795 - val_loss: 1072.2185\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 116.9724 - val_loss: 1072.6094\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 116.9659 - val_loss: 1072.9774\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9600 - val_loss: 1073.3252\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9548 - val_loss: 1073.6520\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9499 - val_loss: 1073.9603\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9456 - val_loss: 1074.2495\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9417 - val_loss: 1074.5215\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 116.9383 - val_loss: 1074.7770\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 116.9352 - val_loss: 1075.0171\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 116.9323 - val_loss: 1075.2421\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 116.9299 - val_loss: 1075.4532\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9277 - val_loss: 1075.6511\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9257 - val_loss: 1075.8359\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9241 - val_loss: 1076.0096\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9225 - val_loss: 1076.1719\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9212 - val_loss: 1076.3236\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9201 - val_loss: 1076.4651\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9192 - val_loss: 1076.5974\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9184 - val_loss: 1076.7212\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9178 - val_loss: 1076.8358\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9173 - val_loss: 1076.9435\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9169 - val_loss: 1077.0430\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9166 - val_loss: 1077.1364\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9164 - val_loss: 1077.2223\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9164 - val_loss: 1077.3024\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9164 - val_loss: 1077.3772\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9165 - val_loss: 1077.4463\n",
      "Epoch 217/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9166 - val_loss: 1077.5103\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9168 - val_loss: 1077.5696\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9171 - val_loss: 1077.6243\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9174 - val_loss: 1077.6752\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9179 - val_loss: 1077.7225\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9182 - val_loss: 1077.7654\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9187 - val_loss: 1077.8055\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9192 - val_loss: 1077.8428\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 116.9198 - val_loss: 1077.8768\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9204 - val_loss: 1077.9075\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9210 - val_loss: 1077.9362\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9216 - val_loss: 1077.9631\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9222 - val_loss: 1077.9869\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9229 - val_loss: 1078.0092\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9236 - val_loss: 1078.0294\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9243 - val_loss: 1078.0480\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9250 - val_loss: 1078.0648\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9257 - val_loss: 1078.0800\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9265 - val_loss: 1078.0942\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9272 - val_loss: 1078.1067\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9279 - val_loss: 1078.1183\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9287 - val_loss: 1078.1287\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9294 - val_loss: 1078.1378\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9302 - val_loss: 1078.1465\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9309 - val_loss: 1078.1534\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9317 - val_loss: 1078.1606\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9324 - val_loss: 1078.1664\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9332 - val_loss: 1078.1718\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9339 - val_loss: 1078.1761\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9346 - val_loss: 1078.1808\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9354 - val_loss: 1078.1840\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9361 - val_loss: 1078.1869\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9369 - val_loss: 1078.1903\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9376 - val_loss: 1078.1920\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 116.9383 - val_loss: 1078.1934\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9390 - val_loss: 1078.1949\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9397 - val_loss: 1078.1958\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9404 - val_loss: 1078.1971\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9411 - val_loss: 1078.1978\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9418 - val_loss: 1078.1981\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9424 - val_loss: 1078.1981\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9431 - val_loss: 1078.1984\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9438 - val_loss: 1078.1981\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9444 - val_loss: 1078.1978\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9450 - val_loss: 1078.1969\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9457 - val_loss: 1078.1967\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9463 - val_loss: 1078.1959\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9469 - val_loss: 1078.1951\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9475 - val_loss: 1078.1938\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9481 - val_loss: 1078.1932\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9487 - val_loss: 1078.1918\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9493 - val_loss: 1078.1908\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9498 - val_loss: 1078.1893\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9504 - val_loss: 1078.1880\n",
      "Epoch 271/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9509 - val_loss: 1078.1871\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9514 - val_loss: 1078.1855\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9519 - val_loss: 1078.1841\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 116.9525 - val_loss: 1078.1823\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9530 - val_loss: 1078.1812\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 116.9535 - val_loss: 1078.1797\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 116.9540 - val_loss: 1078.1777\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 116.9545 - val_loss: 1078.1766\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9550 - val_loss: 1078.1757\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9555 - val_loss: 1078.1744\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9559 - val_loss: 1078.1727\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9563 - val_loss: 1078.1711\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9568 - val_loss: 1078.1699\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9572 - val_loss: 1078.1683\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9576 - val_loss: 1078.1663\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9581 - val_loss: 1078.1650\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9584 - val_loss: 1078.1635\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9589 - val_loss: 1078.1621\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9592 - val_loss: 1078.1606\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9596 - val_loss: 1078.1597\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9600 - val_loss: 1078.1586\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9604 - val_loss: 1078.1573\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9607 - val_loss: 1078.1559\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 116.9611 - val_loss: 1078.1548\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9614 - val_loss: 1078.1539\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 116.9617 - val_loss: 1078.1526\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 116.9621 - val_loss: 1078.1509\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9625 - val_loss: 1078.1505\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9628 - val_loss: 1078.1494\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9631 - val_loss: 1078.1482\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9633 - val_loss: 1078.1473\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9637 - val_loss: 1078.1456\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9640 - val_loss: 1078.1448\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9642 - val_loss: 1078.1439\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9645 - val_loss: 1078.1427\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9648 - val_loss: 1078.1421\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9651 - val_loss: 1078.1412\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9653 - val_loss: 1078.1405\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9656 - val_loss: 1078.1393\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9658 - val_loss: 1078.1373\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9661 - val_loss: 1078.1362\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9664 - val_loss: 1078.1359\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9666 - val_loss: 1078.1354\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9668 - val_loss: 1078.1344\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9670 - val_loss: 1078.1332\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9673 - val_loss: 1078.1321\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9675 - val_loss: 1078.1309\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9677 - val_loss: 1078.1304\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9679 - val_loss: 1078.1296\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9681 - val_loss: 1078.1290\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9682 - val_loss: 1078.1281\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9685 - val_loss: 1078.1266\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9686 - val_loss: 1078.1255\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9689 - val_loss: 1078.1250\n",
      "Epoch 325/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9691 - val_loss: 1078.1248\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9692 - val_loss: 1078.1245\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9694 - val_loss: 1078.1238\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9695 - val_loss: 1078.1224\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9697 - val_loss: 1078.1219\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9699 - val_loss: 1078.1213\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9701 - val_loss: 1078.1202\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 116.9702 - val_loss: 1078.1200\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 116.9704 - val_loss: 1078.1195\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9705 - val_loss: 1078.1188\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9707 - val_loss: 1078.1185\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9708 - val_loss: 1078.1177\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9709 - val_loss: 1078.1174\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9710 - val_loss: 1078.1169\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9711 - val_loss: 1078.1161\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9714 - val_loss: 1078.1156\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9714 - val_loss: 1078.1154\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9715 - val_loss: 1078.1143\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9716 - val_loss: 1078.1136\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9718 - val_loss: 1078.1128\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 116.9719 - val_loss: 1078.1127\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9721 - val_loss: 1078.1125\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9721 - val_loss: 1078.1119\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9723 - val_loss: 1078.1118\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9724 - val_loss: 1078.1117\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9725 - val_loss: 1078.1112\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9726 - val_loss: 1078.1112\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9727 - val_loss: 1078.1111\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9728 - val_loss: 1078.1106\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9728 - val_loss: 1078.1104\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9730 - val_loss: 1078.1105\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9730 - val_loss: 1078.1100\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9730 - val_loss: 1078.1088\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9732 - val_loss: 1078.1082\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9733 - val_loss: 1078.1079\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9733 - val_loss: 1078.1074\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9734 - val_loss: 1078.1074\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9736 - val_loss: 1078.1075\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9736 - val_loss: 1078.1072\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9736 - val_loss: 1078.1064\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9737 - val_loss: 1078.1060\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9738 - val_loss: 1078.1057\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9738 - val_loss: 1078.1053\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9739 - val_loss: 1078.1051\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9740 - val_loss: 1078.1052\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 116.9741 - val_loss: 1078.1050\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9742 - val_loss: 1078.1049\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 116.9742 - val_loss: 1078.1049\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9743 - val_loss: 1078.1050\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9743 - val_loss: 1078.1049\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9744 - val_loss: 1078.1047\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9744 - val_loss: 1078.1041\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9745 - val_loss: 1078.1039\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9746 - val_loss: 1078.1040\n",
      "Epoch 379/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9746 - val_loss: 1078.1039\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9747 - val_loss: 1078.1035\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9747 - val_loss: 1078.1031\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9747 - val_loss: 1078.1029\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9748 - val_loss: 1078.1024\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9748 - val_loss: 1078.1016\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9749 - val_loss: 1078.1011\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9749 - val_loss: 1078.1008\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9750 - val_loss: 1078.1008\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9750 - val_loss: 1078.1007\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9750 - val_loss: 1078.1005\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9750 - val_loss: 1078.1000\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9751 - val_loss: 1078.1000\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9751 - val_loss: 1078.0999\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 116.9752 - val_loss: 1078.0996\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9752 - val_loss: 1078.0994\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9753 - val_loss: 1078.0991\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9753 - val_loss: 1078.0986\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9753 - val_loss: 1078.0980\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9754 - val_loss: 1078.0975\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9754 - val_loss: 1078.0972\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9755 - val_loss: 1078.0970\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9755 - val_loss: 1078.0968\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9755 - val_loss: 1078.0963\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9756 - val_loss: 1078.0961\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9755 - val_loss: 1078.0961\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9756 - val_loss: 1078.0959\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9756 - val_loss: 1078.0957\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9757 - val_loss: 1078.0956\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9757 - val_loss: 1078.0956\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9757 - val_loss: 1078.0958\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9757 - val_loss: 1078.0959\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9758 - val_loss: 1078.0961\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9758 - val_loss: 1078.0963\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9759 - val_loss: 1078.0963\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9759 - val_loss: 1078.0964\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 116.9759 - val_loss: 1078.0969\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9759 - val_loss: 1078.0969\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9759 - val_loss: 1078.0967\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9759 - val_loss: 1078.0964\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9760 - val_loss: 1078.0963\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9760 - val_loss: 1078.0963\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9760 - val_loss: 1078.0963\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9760 - val_loss: 1078.0964\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9760 - val_loss: 1078.0962\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9760 - val_loss: 1078.0961\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9760 - val_loss: 1078.0961\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9760 - val_loss: 1078.0961\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9761 - val_loss: 1078.0959\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9761 - val_loss: 1078.0961\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9761 - val_loss: 1078.0963\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9761 - val_loss: 1078.0964\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9761 - val_loss: 1078.0963\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9761 - val_loss: 1078.0963\n",
      "Epoch 433/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9762 - val_loss: 1078.0964\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9762 - val_loss: 1078.0967\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9762 - val_loss: 1078.0963\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9762 - val_loss: 1078.0959\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9762 - val_loss: 1078.0961\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9763 - val_loss: 1078.0963\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 116.9763 - val_loss: 1078.0962\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9763 - val_loss: 1078.0962\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9763 - val_loss: 1078.0961\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9762 - val_loss: 1078.0959\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9763 - val_loss: 1078.0958\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9763 - val_loss: 1078.0958\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9763 - val_loss: 1078.0958\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9763 - val_loss: 1078.0958\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9763 - val_loss: 1078.0957\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9763 - val_loss: 1078.0956\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9763 - val_loss: 1078.0958\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9763 - val_loss: 1078.0958\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9763 - val_loss: 1078.0961\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9763 - val_loss: 1078.0961\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9763 - val_loss: 1078.0961\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9764 - val_loss: 1078.0961\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 116.9764 - val_loss: 1078.0958\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9764 - val_loss: 1078.0958\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9764 - val_loss: 1078.0959\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9764 - val_loss: 1078.0956\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9764 - val_loss: 1078.0952\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9764 - val_loss: 1078.0951\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 116.9764 - val_loss: 1078.0946\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9764 - val_loss: 1078.0945\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0942\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0941\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0940\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0940\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9765 - val_loss: 1078.0941\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0941\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9765 - val_loss: 1078.0942\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0942\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9765 - val_loss: 1078.0942\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0942\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9765 - val_loss: 1078.0942\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9765 - val_loss: 1078.0942\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0942\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0945\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9765 - val_loss: 1078.0947\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9765 - val_loss: 1078.0947\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9765 - val_loss: 1078.0952\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9765 - val_loss: 1078.0952\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 116.9765 - val_loss: 1078.0955\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9765 - val_loss: 1078.0952\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9766 - val_loss: 1078.0955\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0956\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0952\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0952\n",
      "Epoch 487/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0952\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 116.9765 - val_loss: 1078.0947\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 116.9765 - val_loss: 1078.0945\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0944\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9765 - val_loss: 1078.0941\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9766 - val_loss: 1078.0939\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 116.9766 - val_loss: 1078.0936\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9766 - val_loss: 1078.0933\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9766 - val_loss: 1078.0919\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9766 - val_loss: 1078.0917\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9766 - val_loss: 1078.0912\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9766 - val_loss: 1078.0909\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9766 - val_loss: 1078.0909\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 116.9766 - val_loss: 1078.0907\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 539ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.75887722e+01, 5.74627218e+01, 5.73366713e+01, 5.72106209e+01,\n",
       "        6.49527130e+01, 0.00000000e+00, 8.53142740e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.85162810e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.59027311e+01, 5.58102941e+01, 5.57178571e+01,\n",
       "        5.56254202e+01, 5.55576928e+01, 5.81209851e+01, 5.79949346e+01,\n",
       "        5.78688842e+01, 5.77428338e+01, 5.76167834e+01, 5.74937329e+01,\n",
       "        5.73706825e+01, 5.72476321e+01, 5.71245817e+01, 6.53977270e-01,\n",
       "        2.81776700e-01, 5.76671373e+01, 5.75420868e+01, 5.74150364e+01,\n",
       "        5.72899860e+01, 5.71693936e+01, 5.70495189e+01, 5.69301584e+01,\n",
       "        5.68119979e+01, 5.66958374e+01, 2.13815960e-01, 1.30032140e-01,\n",
       "        0.00000000e+00, 1.01369178e+00, 8.32572000e-03, 0.00000000e+00,\n",
       "        4.05764340e-01, 4.29300800e-02, 1.07817820e-01, 5.72664333e+01,\n",
       "        5.71405929e+01, 0.00000000e+00, 7.98189880e-01, 5.76961485e+01,\n",
       "        5.75700980e+01, 5.74440476e+01, 5.73179972e+01, 5.71941947e+01,\n",
       "        5.70799902e+01, 5.69683851e+01, 5.68547806e+01, 5.67431754e+01,\n",
       "        1.04408872e+00, 1.88607156e-01, 5.72433007e+01, 5.71172502e+01,\n",
       "        5.69911998e+01, 5.68651494e+01, 5.67390990e+01, 5.65087068e+01,\n",
       "        5.62139590e+01, 5.59540850e+01, 5.56776740e+01, 4.24146210e-02,\n",
       "        1.23838449e+00, 4.92067833e+01, 3.48570496e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.82187900e-02, 0.00000000e+00, 9.82906938e-01,\n",
       "        6.03367004e+01, 0.00000000e+00, 0.00000000e+00, 5.40004849e-01,\n",
       "        0.00000000e+00, 4.55412269e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.96149662e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.72441649e-01, 3.37595671e-01, 1.17851317e+00, 2.08332092e-01,\n",
       "        0.00000000e+00, 1.25488579e-01, 0.00000000e+00, 6.88723326e-02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47.15777823, 47.14794015, 47.13810207, 47.12826399, 47.11842591,\n",
       "       47.10858783, 47.09874974, 47.08891166, 47.07907358, 47.0692355 ,\n",
       "       47.05939742, 47.04955934, 47.03972125, 47.02988317, 47.02004509,\n",
       "       47.01020701, 47.00036893, 46.99053085, 46.98069276, 46.97085468,\n",
       "       46.9610166 , 46.95117852, 46.94134044, 46.93150236, 46.92166428,\n",
       "       46.91182619, 46.90198811, 46.89215003, 46.88231195, 46.87247387,\n",
       "       46.86263579, 46.8527977 , 46.84295962, 46.83312154, 46.82328346,\n",
       "       46.81344538, 46.8036073 , 46.79376922, 46.78393113, 46.77409305,\n",
       "       46.76425497, 46.75441689, 46.74457881, 46.73474073, 46.72490264,\n",
       "       46.71506456, 46.70522648, 46.6953884 , 46.68555032, 46.67571224,\n",
       "       46.66587415, 46.65603607, 46.64619799, 46.63635991, 46.62652183,\n",
       "       46.61668375, 46.60684567, 46.59700758, 46.5871695 , 46.57733142,\n",
       "       46.56749334, 46.55765526, 46.54781718, 46.53797909, 46.52814101,\n",
       "       46.51830293, 46.50846485, 46.49862677, 46.48878869, 46.4789506 ,\n",
       "       46.46911252, 46.45927444, 46.44943636, 46.43959828, 46.4297602 ,\n",
       "       46.41992212, 46.41008403, 46.40024595, 46.39040787, 46.38056979,\n",
       "       46.37073171, 46.36089363, 46.35105554, 46.34121746, 46.33137938,\n",
       "       46.3215413 , 46.31170322, 46.30186514, 46.29202705, 46.28218897,\n",
       "       46.27235089, 46.26251281, 46.25267473, 46.24283665, 46.23299857,\n",
       "       46.22316048, 46.2133224 , 46.20348432, 46.19364624, 46.18380816])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.57737864376223\n",
      "28.313775208846863\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
