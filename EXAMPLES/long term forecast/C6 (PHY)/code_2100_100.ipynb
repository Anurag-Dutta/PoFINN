{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2195    48.190777\n",
       "2196    48.180939\n",
       "2197    48.171101\n",
       "2198    48.161263\n",
       "2199    48.151424\n",
       "Name: C6, Length: 2200, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_2100_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2095     0.000000\n",
       "2096     0.000000\n",
       "2097     0.870156\n",
       "2098     0.982907\n",
       "2099     0.000000\n",
       "Name: C6, Length: 2100, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2100)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 1, 251) (1650, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 2s 32ms/step - loss: 3810.3906 - val_loss: 2373.2354\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3743.1780 - val_loss: 2336.9675\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3687.5105 - val_loss: 2304.5437\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3634.2395 - val_loss: 2272.8198\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3581.8882 - val_loss: 2241.6855\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3530.3274 - val_loss: 2211.0549\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3479.4614 - val_loss: 2180.8806\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3429.2351 - val_loss: 2151.1360\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3379.6167 - val_loss: 2121.8010\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3330.5837 - val_loss: 2092.8606\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 3282.1211 - val_loss: 2064.2971\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3234.2148 - val_loss: 2036.0687\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3185.1299 - val_loss: 1998.8528\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3122.2312 - val_loss: 1967.9482\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3070.9788 - val_loss: 1938.0061\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3021.2432 - val_loss: 1909.0189\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2972.7319 - val_loss: 1880.7634\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2925.1863 - val_loss: 1853.1160\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2878.4658 - val_loss: 1826.0066\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2832.4856 - val_loss: 1799.3918\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2787.1921 - val_loss: 1773.2410\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2742.5461 - val_loss: 1747.5319\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2698.5198 - val_loss: 1722.2479\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2655.0911 - val_loss: 1697.3754\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2612.2422 - val_loss: 1672.9031\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2569.9575 - val_loss: 1648.8212\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2528.2253 - val_loss: 1625.1216\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2487.0342 - val_loss: 1601.7970\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2446.3735 - val_loss: 1578.8402\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 2406.2356 - val_loss: 1556.2456\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2366.6118 - val_loss: 1534.0074\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 2327.4946 - val_loss: 1512.1201\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 2288.8774 - val_loss: 1490.5787\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2250.7532 - val_loss: 1469.3778\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2213.1162 - val_loss: 1448.5118\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2175.9600 - val_loss: 1427.9738\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2139.2791 - val_loss: 1407.7511\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2103.0696 - val_loss: 1387.7106\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2060.9946 - val_loss: 1361.1975\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2015.6713 - val_loss: 1338.6620\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1975.3757 - val_loss: 1317.2625\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1936.7683 - val_loss: 1296.7054\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1899.3895 - val_loss: 1276.8018\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1862.9767 - val_loss: 1257.4486\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1827.3837 - val_loss: 1238.5850\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1792.5206 - val_loss: 1220.1692\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1758.3252 - val_loss: 1202.1733\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1724.7545 - val_loss: 1184.5750\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1691.7743 - val_loss: 1167.3571\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1659.3583 - val_loss: 1150.5054\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1627.4852 - val_loss: 1134.0084\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1596.1367 - val_loss: 1117.8561\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1565.2979 - val_loss: 1102.0393\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1534.9546 - val_loss: 1086.5502\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1505.0952 - val_loss: 1071.3817\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1475.7092 - val_loss: 1056.5273\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1446.7874 - val_loss: 1041.9811\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1418.3195 - val_loss: 1027.7377\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1390.2991 - val_loss: 1013.7912\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1362.7175 - val_loss: 1000.1374\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1335.5675 - val_loss: 986.7713\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1308.8434 - val_loss: 973.6885\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1282.5377 - val_loss: 960.8846\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1256.6450 - val_loss: 948.3556\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1231.1593 - val_loss: 936.0975\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1206.0750 - val_loss: 924.1064\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1181.3868 - val_loss: 912.3790\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1157.0896 - val_loss: 900.9112\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1133.1785 - val_loss: 889.6994\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1109.6483 - val_loss: 878.7405\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1086.4946 - val_loss: 868.0309\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1063.7128 - val_loss: 857.5676\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1041.2983 - val_loss: 847.3470\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1019.2466 - val_loss: 837.3661\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 997.5539 - val_loss: 827.6219\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 976.2155 - val_loss: 818.1109\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 955.2274 - val_loss: 808.8302\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 934.5857 - val_loss: 799.7772\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 914.2863 - val_loss: 790.9484\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 894.3252 - val_loss: 782.3412\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 874.6987 - val_loss: 773.9529\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 855.4031 - val_loss: 765.7801\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 836.4344 - val_loss: 757.8206\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 817.7892 - val_loss: 750.0709\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 799.4636 - val_loss: 742.5288\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 781.4539 - val_loss: 735.1913\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 763.7567 - val_loss: 728.0557\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 746.3685 - val_loss: 721.1194\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 729.2855 - val_loss: 714.3793\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 712.5047 - val_loss: 707.8335\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 696.0223 - val_loss: 701.4787\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 679.8350 - val_loss: 695.3125\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 663.9394 - val_loss: 689.3322\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 648.3322 - val_loss: 683.5353\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 633.0100 - val_loss: 677.9192\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 617.9697 - val_loss: 672.4813\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 603.2077 - val_loss: 667.2193\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 588.7209 - val_loss: 662.1303\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 574.5062 - val_loss: 657.2119\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 560.5604 - val_loss: 652.4615\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 546.8802 - val_loss: 647.8770\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 533.4623 - val_loss: 643.4553\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 520.3038 - val_loss: 639.1945\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 507.4017 - val_loss: 635.0918\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 494.7523 - val_loss: 631.1447\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 482.3530 - val_loss: 627.3510\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 470.2007 - val_loss: 623.7081\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 458.2921 - val_loss: 620.2136\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 446.6244 - val_loss: 616.8651\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 435.1945 - val_loss: 613.6601\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 423.9992 - val_loss: 610.5964\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 413.0359 - val_loss: 607.6716\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 402.3012 - val_loss: 604.8831\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 391.7924 - val_loss: 602.2285\n",
      "Epoch 115/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 381.5065 - val_loss: 599.7057\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 371.4404 - val_loss: 597.3123\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 361.5914 - val_loss: 595.0457\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 351.9564 - val_loss: 592.9039\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 342.5326 - val_loss: 590.8845\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 333.3171 - val_loss: 588.9849\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 324.3069 - val_loss: 587.2029\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 315.4992 - val_loss: 585.5364\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 306.8911 - val_loss: 583.9830\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 298.4799 - val_loss: 582.5403\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 290.2628 - val_loss: 581.2062\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 282.2368 - val_loss: 579.9782\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 274.3990 - val_loss: 578.8542\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 266.7470 - val_loss: 577.8320\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 259.2776 - val_loss: 576.9092\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 251.9882 - val_loss: 576.0837\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 244.8762 - val_loss: 575.3531\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 237.9385 - val_loss: 574.7153\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 231.1727 - val_loss: 574.1682\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 224.5761 - val_loss: 573.7095\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 218.1457 - val_loss: 573.3369\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 211.8790 - val_loss: 573.0483\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 205.7734 - val_loss: 572.8416\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 199.8259 - val_loss: 572.7147\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 194.0340 - val_loss: 572.6652\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 188.3952 - val_loss: 572.6912\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 182.9068 - val_loss: 572.7905\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 177.5661 - val_loss: 572.9610\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 172.3704 - val_loss: 573.2006\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 167.3173 - val_loss: 573.5073\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 162.4043 - val_loss: 573.8788\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 157.6286 - val_loss: 574.3133\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 152.9876 - val_loss: 574.8086\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 148.4791 - val_loss: 575.3628\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 144.1004 - val_loss: 575.9738\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 139.8491 - val_loss: 576.6396\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 135.7226 - val_loss: 577.3582\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 131.7184 - val_loss: 578.1277\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 127.8341 - val_loss: 578.9461\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 124.0674 - val_loss: 579.8115\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 120.4157 - val_loss: 580.7221\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 116.8766 - val_loss: 581.6759\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 113.4478 - val_loss: 582.6708\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 110.1270 - val_loss: 583.7053\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 106.9117 - val_loss: 584.7775\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 103.7996 - val_loss: 585.8853\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 100.7885 - val_loss: 587.0272\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 97.8760 - val_loss: 588.2014\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 95.0600 - val_loss: 589.4059\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 92.3382 - val_loss: 590.6393\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 89.7083 - val_loss: 591.8998\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 87.1681 - val_loss: 593.1856\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 84.7156 - val_loss: 594.4949\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 82.3484 - val_loss: 595.8265\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 80.0646 - val_loss: 597.1785\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 77.8620 - val_loss: 598.5493\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 75.7386 - val_loss: 599.9374\n",
      "Epoch 172/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 73.6922 - val_loss: 601.3412\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 71.7209 - val_loss: 602.7594\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 69.8226 - val_loss: 604.1903\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 67.9953 - val_loss: 605.6324\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 66.2372 - val_loss: 607.0845\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 64.5464 - val_loss: 608.5451\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 62.9208 - val_loss: 610.0128\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 61.3586 - val_loss: 611.4862\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 59.8581 - val_loss: 612.9643\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 58.4173 - val_loss: 614.4454\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 57.0345 - val_loss: 615.9286\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 55.7080 - val_loss: 617.4125\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 54.4359 - val_loss: 618.8960\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 53.2166 - val_loss: 620.3779\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 52.0484 - val_loss: 621.8572\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 50.9298 - val_loss: 623.3326\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 49.8590 - val_loss: 624.8033\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 48.8346 - val_loss: 626.2682\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 47.8549 - val_loss: 627.7261\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 46.9185 - val_loss: 629.1762\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 46.0238 - val_loss: 630.6177\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45.1695 - val_loss: 632.0497\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44.3540 - val_loss: 633.4711\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43.5760 - val_loss: 634.8812\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42.8341 - val_loss: 636.2794\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42.1270 - val_loss: 637.6649\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 41.4535 - val_loss: 639.0367\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 40.8122 - val_loss: 640.3940\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 40.2019 - val_loss: 641.7369\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 39.6214 - val_loss: 643.0641\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 39.0696 - val_loss: 644.3755\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 38.5452 - val_loss: 645.6699\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 38.0472 - val_loss: 646.9475\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 37.5744 - val_loss: 648.2075\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 37.1260 - val_loss: 649.4493\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 36.7008 - val_loss: 650.6725\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 36.2977 - val_loss: 651.8770\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 35.9160 - val_loss: 653.0620\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 35.5546 - val_loss: 654.2277\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 35.2127 - val_loss: 655.3734\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 34.8894 - val_loss: 656.4992\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 34.5837 - val_loss: 657.6044\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 34.2950 - val_loss: 658.6891\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 34.0223 - val_loss: 659.7531\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 33.7651 - val_loss: 660.7964\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 33.5224 - val_loss: 661.8185\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 33.2936 - val_loss: 662.8196\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 33.0781 - val_loss: 663.7995\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 32.8752 - val_loss: 664.7581\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 32.6842 - val_loss: 665.6952\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 32.5046 - val_loss: 666.6116\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 32.3357 - val_loss: 667.5063\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 32.1771 - val_loss: 668.3799\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 32.0281 - val_loss: 669.2328\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 31.8882 - val_loss: 670.0641\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 31.7570 - val_loss: 670.8749\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 31.6339 - val_loss: 671.6648\n",
      "Epoch 229/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 31.5186 - val_loss: 672.4340\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 31.4106 - val_loss: 673.1828\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 31.3096 - val_loss: 673.9114\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 31.2150 - val_loss: 674.6196\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 31.1266 - val_loss: 675.3080\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 31.0439 - val_loss: 675.9769\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.9666 - val_loss: 676.6265\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.8945 - val_loss: 677.2566\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.8272 - val_loss: 677.8679\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.7644 - val_loss: 678.4606\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.7058 - val_loss: 679.0351\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.6513 - val_loss: 679.5914\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.6004 - val_loss: 680.1299\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.5531 - val_loss: 680.6512\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.5091 - val_loss: 681.1553\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.4680 - val_loss: 681.6427\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.4299 - val_loss: 682.1135\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.3945 - val_loss: 682.5681\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.3616 - val_loss: 683.0069\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.3310 - val_loss: 683.4302\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.3027 - val_loss: 683.8386\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 30.2764 - val_loss: 684.2322\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.2519 - val_loss: 684.6110\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.2293 - val_loss: 684.9762\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.2083 - val_loss: 685.3277\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.1888 - val_loss: 685.6656\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.1708 - val_loss: 685.9906\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.1542 - val_loss: 686.3029\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.1388 - val_loss: 686.6029\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 30.1245 - val_loss: 686.8911\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 30.1113 - val_loss: 687.1676\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0991 - val_loss: 687.4326\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0878 - val_loss: 687.6872\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0773 - val_loss: 687.9304\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0678 - val_loss: 688.1639\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0589 - val_loss: 688.3874\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0507 - val_loss: 688.6012\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0431 - val_loss: 688.8057\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0362 - val_loss: 689.0013\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.0297 - val_loss: 689.1880\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.0238 - val_loss: 689.3665\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0184 - val_loss: 689.5366\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.0133 - val_loss: 689.6990\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.0088 - val_loss: 689.8538\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.0045 - val_loss: 690.0015\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.0007 - val_loss: 690.1424\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9971 - val_loss: 690.2763\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9938 - val_loss: 690.4037\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 29.9908 - val_loss: 690.5251\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9881 - val_loss: 690.6406\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9856 - val_loss: 690.7503\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9833 - val_loss: 690.8542\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9813 - val_loss: 690.9533\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9794 - val_loss: 691.0472\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9777 - val_loss: 691.1365\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9761 - val_loss: 691.2209\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9748 - val_loss: 691.3010\n",
      "Epoch 286/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9735 - val_loss: 691.3768\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9724 - val_loss: 691.4484\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9714 - val_loss: 691.5164\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9704 - val_loss: 691.5807\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9697 - val_loss: 691.6414\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9689 - val_loss: 691.6987\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9684 - val_loss: 691.7529\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9678 - val_loss: 691.8038\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9674 - val_loss: 691.8519\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9670 - val_loss: 691.8975\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9667 - val_loss: 691.9403\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9665 - val_loss: 691.9806\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9663 - val_loss: 692.0189\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9661 - val_loss: 692.0546\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9660 - val_loss: 692.0880\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9660 - val_loss: 692.1195\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 29.9660 - val_loss: 692.1493\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 29.9660 - val_loss: 692.1769\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 29.9661 - val_loss: 692.2030\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 29.9662 - val_loss: 692.2272\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 29.9664 - val_loss: 692.2503\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 29.9665 - val_loss: 692.2717\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 29.9667 - val_loss: 692.2917\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9670 - val_loss: 692.3107\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9671 - val_loss: 692.3280\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9674 - val_loss: 692.3443\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9677 - val_loss: 692.3596\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9680 - val_loss: 692.3735\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9683 - val_loss: 692.3867\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9687 - val_loss: 692.3990\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9690 - val_loss: 692.4106\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9693 - val_loss: 692.4210\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9697 - val_loss: 692.4310\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9701 - val_loss: 692.4404\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9705 - val_loss: 692.4487\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9709 - val_loss: 692.4567\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9713 - val_loss: 692.4638\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9717 - val_loss: 692.4706\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9721 - val_loss: 692.4768\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9725 - val_loss: 692.4823\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 29.9729 - val_loss: 692.4874\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 29.9734 - val_loss: 692.4922\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 29.9738 - val_loss: 692.4965\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 29.9742 - val_loss: 692.5007\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 29.9747 - val_loss: 692.5040\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 29.9751 - val_loss: 692.5072\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 29.9755 - val_loss: 692.5101\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9760 - val_loss: 692.5130\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9764 - val_loss: 692.5154\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9769 - val_loss: 692.5176\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9773 - val_loss: 692.5194\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9777 - val_loss: 692.5210\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 29.9782 - val_loss: 692.5227\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9786 - val_loss: 692.5242\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 29.9790 - val_loss: 692.5255\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9795 - val_loss: 692.5264\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9799 - val_loss: 692.5272\n",
      "Epoch 343/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 29.9803 - val_loss: 692.5278\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9807 - val_loss: 692.5286\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9812 - val_loss: 692.5289\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9816 - val_loss: 692.5291\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9820 - val_loss: 692.5294\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9825 - val_loss: 692.5298\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9828 - val_loss: 692.5299\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9832 - val_loss: 692.5299\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9836 - val_loss: 692.5299\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9840 - val_loss: 692.5295\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9844 - val_loss: 692.5297\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9847 - val_loss: 692.5292\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9851 - val_loss: 692.5289\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9855 - val_loss: 692.5288\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9859 - val_loss: 692.5284\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9862 - val_loss: 692.5280\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9866 - val_loss: 692.5273\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 29.9870 - val_loss: 692.5267\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9873 - val_loss: 692.5264\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9877 - val_loss: 692.5260\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9880 - val_loss: 692.5254\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9884 - val_loss: 692.5248\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9887 - val_loss: 692.5242\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9890 - val_loss: 692.5233\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9894 - val_loss: 692.5228\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9897 - val_loss: 692.5221\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9900 - val_loss: 692.5214\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9903 - val_loss: 692.5205\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9906 - val_loss: 692.5195\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9909 - val_loss: 692.5189\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 29.9912 - val_loss: 692.5183\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9916 - val_loss: 692.5180\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 29.9918 - val_loss: 692.5173\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9921 - val_loss: 692.5164\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9924 - val_loss: 692.5159\n",
      "Epoch 378/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9927 - val_loss: 692.5153\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9929 - val_loss: 692.5145\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9932 - val_loss: 692.5139\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9935 - val_loss: 692.5135\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 29.9937 - val_loss: 692.5126\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9940 - val_loss: 692.5119\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9943 - val_loss: 692.5115\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9945 - val_loss: 692.5109\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9947 - val_loss: 692.5100\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9950 - val_loss: 692.5095\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9952 - val_loss: 692.5090\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9954 - val_loss: 692.5082\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9957 - val_loss: 692.5075\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9959 - val_loss: 692.5073\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9961 - val_loss: 692.5063\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9963 - val_loss: 692.5059\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9965 - val_loss: 692.5052\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9968 - val_loss: 692.5048\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9969 - val_loss: 692.5040\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9972 - val_loss: 692.5033\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9973 - val_loss: 692.5026\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9976 - val_loss: 692.5021\n",
      "Epoch 400/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9978 - val_loss: 692.5016\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9980 - val_loss: 692.5012\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9981 - val_loss: 692.5004\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 29.9983 - val_loss: 692.4999\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9985 - val_loss: 692.4995\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9986 - val_loss: 692.4987\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9989 - val_loss: 692.4984\n",
      "Epoch 407/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9990 - val_loss: 692.4979\n",
      "Epoch 408/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9992 - val_loss: 692.4976\n",
      "Epoch 409/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9994 - val_loss: 692.4972\n",
      "Epoch 410/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9996 - val_loss: 692.4971\n",
      "Epoch 411/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9997 - val_loss: 692.4965\n",
      "Epoch 412/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 29.9998 - val_loss: 692.4960\n",
      "Epoch 413/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 29.9999 - val_loss: 692.4955\n",
      "Epoch 414/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0001 - val_loss: 692.4951\n",
      "Epoch 415/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0002 - val_loss: 692.4946\n",
      "Epoch 416/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 30.0004 - val_loss: 692.4940\n",
      "Epoch 417/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0005 - val_loss: 692.4933\n",
      "Epoch 418/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0007 - val_loss: 692.4930\n",
      "Epoch 419/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0008 - val_loss: 692.4926\n",
      "Epoch 420/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0010 - val_loss: 692.4924\n",
      "Epoch 421/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.0011 - val_loss: 692.4919\n",
      "Epoch 422/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.0012 - val_loss: 692.4915\n",
      "Epoch 423/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0013 - val_loss: 692.4908\n",
      "Epoch 424/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 30.0015 - val_loss: 692.4906\n",
      "Epoch 425/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0016 - val_loss: 692.4904\n",
      "Epoch 426/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0017 - val_loss: 692.4902\n",
      "Epoch 427/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0019 - val_loss: 692.4902\n",
      "Epoch 428/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0019 - val_loss: 692.4897\n",
      "Epoch 429/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0020 - val_loss: 692.4893\n",
      "Epoch 430/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0022 - val_loss: 692.4887\n",
      "Epoch 431/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0023 - val_loss: 692.4885\n",
      "Epoch 432/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0024 - val_loss: 692.4883\n",
      "Epoch 433/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0025 - val_loss: 692.4879\n",
      "Epoch 434/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0026 - val_loss: 692.4874\n",
      "Epoch 435/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.0027 - val_loss: 692.4872\n",
      "Epoch 436/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 30.0028 - val_loss: 692.4869\n",
      "Epoch 437/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 30.0029 - val_loss: 692.4865\n",
      "Epoch 438/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0030 - val_loss: 692.4861\n",
      "Epoch 439/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0031 - val_loss: 692.4858\n",
      "Epoch 440/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0032 - val_loss: 692.4857\n",
      "Epoch 441/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0032 - val_loss: 692.4854\n",
      "Epoch 442/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0033 - val_loss: 692.4851\n",
      "Epoch 443/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 30.0034 - val_loss: 692.4846\n",
      "Epoch 444/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0035 - val_loss: 692.4845\n",
      "Epoch 445/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0036 - val_loss: 692.4842\n",
      "Epoch 446/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0037 - val_loss: 692.4841\n",
      "Epoch 447/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0038 - val_loss: 692.4839\n",
      "Epoch 448/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0038 - val_loss: 692.4836\n",
      "Epoch 449/500\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 30.0039 - val_loss: 692.4835\n",
      "Epoch 450/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0040 - val_loss: 692.4833\n",
      "Epoch 451/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 30.0041 - val_loss: 692.4832\n",
      "Epoch 452/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0041 - val_loss: 692.4829\n",
      "Epoch 453/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0042 - val_loss: 692.4826\n",
      "Epoch 454/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0043 - val_loss: 692.4827\n",
      "Epoch 455/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0044 - val_loss: 692.4825\n",
      "Epoch 456/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0044 - val_loss: 692.4824\n",
      "Epoch 457/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0044 - val_loss: 692.4821\n",
      "Epoch 458/500\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.0045 - val_loss: 692.4818\n",
      "Epoch 459/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0046 - val_loss: 692.4816\n",
      "Epoch 460/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0046 - val_loss: 692.4813\n",
      "Epoch 461/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0047 - val_loss: 692.4811\n",
      "Epoch 462/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0048 - val_loss: 692.4809\n",
      "Epoch 463/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0048 - val_loss: 692.4805\n",
      "Epoch 464/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0049 - val_loss: 692.4803\n",
      "Epoch 465/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0049 - val_loss: 692.4800\n",
      "Epoch 466/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0050 - val_loss: 692.4799\n",
      "Epoch 467/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0050 - val_loss: 692.4796\n",
      "Epoch 468/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0051 - val_loss: 692.4795\n",
      "Epoch 469/500\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 30.0051 - val_loss: 692.4792\n",
      "Epoch 470/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0052 - val_loss: 692.4791\n",
      "Epoch 471/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0052 - val_loss: 692.4790\n",
      "Epoch 472/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0053 - val_loss: 692.4788\n",
      "Epoch 473/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0054 - val_loss: 692.4786\n",
      "Epoch 474/500\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 30.0054 - val_loss: 692.4786\n",
      "Epoch 475/500\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 30.0054 - val_loss: 692.4785\n",
      "Epoch 476/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 30.0055 - val_loss: 692.4785\n",
      "Epoch 477/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0055 - val_loss: 692.4785\n",
      "Epoch 478/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0055 - val_loss: 692.4782\n",
      "Epoch 479/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0056 - val_loss: 692.4780\n",
      "Epoch 480/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0057 - val_loss: 692.4780\n",
      "Epoch 481/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 30.0057 - val_loss: 692.4780\n",
      "Epoch 482/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0057 - val_loss: 692.4775\n",
      "Epoch 483/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0057 - val_loss: 692.4774\n",
      "Epoch 484/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0058 - val_loss: 692.4772\n",
      "Epoch 485/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0058 - val_loss: 692.4771\n",
      "Epoch 486/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0059 - val_loss: 692.4770\n",
      "Epoch 487/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0059 - val_loss: 692.4769\n",
      "Epoch 488/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0059 - val_loss: 692.4767\n",
      "Epoch 489/500\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 30.0060 - val_loss: 692.4765\n",
      "Epoch 490/500\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 30.0060 - val_loss: 692.4765\n",
      "Epoch 491/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0060 - val_loss: 692.4763\n",
      "Epoch 492/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0060 - val_loss: 692.4762\n",
      "Epoch 493/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0061 - val_loss: 692.4763\n",
      "Epoch 494/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0061 - val_loss: 692.4763\n",
      "Epoch 495/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0062 - val_loss: 692.4763\n",
      "Epoch 496/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0062 - val_loss: 692.4763\n",
      "Epoch 497/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0062 - val_loss: 692.4761\n",
      "Epoch 498/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0062 - val_loss: 692.4760\n",
      "Epoch 499/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0063 - val_loss: 692.4760\n",
      "Epoch 500/500\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 30.0063 - val_loss: 692.4760\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 369ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.69167832e+01, 5.68795816e+01, 5.68423801e+01, 5.68051783e+01,\n",
       "        5.67679765e+01, 5.67307748e+01, 5.66935732e+01, 5.66563714e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.06541169e-01,\n",
       "        3.79659380e-02, 5.72713119e+01, 5.72292950e+01, 5.71872782e+01,\n",
       "        5.71452614e+01, 5.71032446e+01, 5.70612278e+01, 5.70192110e+01,\n",
       "        5.69771942e+01, 5.69351774e+01, 5.68931606e+01, 5.68511438e+01,\n",
       "        5.68091270e+01, 5.67671102e+01, 5.67250934e+01, 5.66627684e+01,\n",
       "        5.65703315e+01, 5.64778945e+01, 5.63854575e+01, 5.62930205e+01,\n",
       "        5.62005836e+01, 5.61081466e+01, 5.60157096e+01, 5.59232726e+01,\n",
       "        5.58308357e+01, 5.57383987e+01, 5.56459617e+01, 5.55704248e+01,\n",
       "        1.29810739e+00, 0.00000000e+00, 0.00000000e+00, 8.68838131e-01,\n",
       "        4.33232427e-01, 2.79132515e-01, 3.72437805e-01, 5.67764472e+01,\n",
       "        5.67344304e+01, 5.66833100e+01, 5.65908730e+01, 5.64984360e+01,\n",
       "        5.64059991e+01, 5.63135621e+01, 5.62211251e+01, 5.61286881e+01,\n",
       "        5.60362512e+01, 5.59438142e+01, 5.58513772e+01, 5.57589402e+01,\n",
       "        5.56665033e+01, 5.55834967e+01, 5.81770075e+01, 5.80509571e+01,\n",
       "        5.79249066e+01, 5.77988562e+01, 5.76728058e+01, 5.75467554e+01,\n",
       "        5.74207050e+01, 5.72946545e+01, 5.71686041e+01, 6.62716980e-01,\n",
       "        1.31916910e-01, 6.18013115e+01, 0.00000000e+00, 1.65983210e-01,\n",
       "        7.46340040e-01, 4.03643970e-01, 0.00000000e+00, 2.49747480e-01,\n",
       "        5.46661339e+01, 4.32004333e-01, 1.70246243e-01, 2.22946983e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.86664660e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.52457500e-01, 0.00000000e+00, 0.00000000e+00, 2.97570199e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.88791180e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49.24779412, 49.23425537, 49.22071662, 49.20717787, 49.19363912,\n",
       "       49.18010037, 49.16656162, 49.15302288, 49.13948413, 49.12594538,\n",
       "       49.11240663, 49.09886788, 49.08532913, 49.07179038, 49.05825163,\n",
       "       49.04471289, 49.03117414, 49.01763539, 49.00409664, 48.99055789,\n",
       "       48.97701914, 48.96348039, 48.94994164, 48.93640289, 48.92286415,\n",
       "       48.9093254 , 48.89578665, 48.8822479 , 48.86870915, 48.8551704 ,\n",
       "       48.84163165, 48.8280929 , 48.81455415, 48.80101541, 48.79089977,\n",
       "       48.78106169, 48.77122361, 48.76138553, 48.75154745, 48.74170937,\n",
       "       48.73187129, 48.7220332 , 48.71219512, 48.70235704, 48.69251896,\n",
       "       48.68268088, 48.6728428 , 48.66300471, 48.65316663, 48.64332855,\n",
       "       48.63349047, 48.62365239, 48.61381431, 48.60397622, 48.59413814,\n",
       "       48.58430006, 48.57446198, 48.5646239 , 48.55478582, 48.54494774,\n",
       "       48.53510965, 48.52527157, 48.51543349, 48.50559541, 48.49575733,\n",
       "       48.48591925, 48.47608116, 48.46624308, 48.456405  , 48.44656692,\n",
       "       48.43672884, 48.42689076, 48.41705267, 48.40721459, 48.39737651,\n",
       "       48.38753843, 48.37770035, 48.36786227, 48.35802419, 48.3481861 ,\n",
       "       48.33834802, 48.32850994, 48.31867186, 48.30883378, 48.2989957 ,\n",
       "       48.28915761, 48.27931953, 48.26948145, 48.25964337, 48.24980529,\n",
       "       48.23996721, 48.23012912, 48.22029104, 48.21045296, 48.20061488,\n",
       "       48.1907768 , 48.18093872, 48.17110064, 48.16126255, 48.15142447])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.78725738605847\n",
      "23.671481974173506\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
