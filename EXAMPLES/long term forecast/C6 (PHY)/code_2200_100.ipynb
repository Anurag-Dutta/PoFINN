{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2295    47.206969\n",
       "2296    47.197131\n",
       "2297    47.187292\n",
       "2298    47.177454\n",
       "2299    47.167616\n",
       "Name: C6, Length: 2300, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_2200_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "2195     0.297570\n",
       "2196     0.000000\n",
       "2197     0.000000\n",
       "2198     0.288791\n",
       "2199     0.000000\n",
       "Name: C6, Length: 2200, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(2200)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750, 1, 251) (1750, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/22 [==============================] - 3s 25ms/step - loss: 3647.3767 - val_loss: 2227.0488\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3446.7383 - val_loss: 2092.4167\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3296.6035 - val_loss: 2000.9207\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3198.7222 - val_loss: 1943.4084\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3111.9431 - val_loss: 1889.0154\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 3028.7629 - val_loss: 1836.9760\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2948.3523 - val_loss: 1786.8668\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2870.2463 - val_loss: 1738.4614\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2794.1802 - val_loss: 1691.6215\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2719.9883 - val_loss: 1646.2452\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2647.5566 - val_loss: 1602.1600\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2572.1313 - val_loss: 1555.1000\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2498.3374 - val_loss: 1511.3442\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2427.1506 - val_loss: 1469.4540\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 2358.2104 - val_loss: 1429.1720\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2291.2183 - val_loss: 1390.3514\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2225.9983 - val_loss: 1352.9003\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2162.4402 - val_loss: 1316.7540\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 2100.4644 - val_loss: 1281.8615\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 2040.0088 - val_loss: 1248.1814\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1981.0247 - val_loss: 1215.6776\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1923.4689 - val_loss: 1184.3175\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1867.3048 - val_loss: 1154.0726\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1812.4962 - val_loss: 1124.9160\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1759.0150 - val_loss: 1096.8209\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1706.8309 - val_loss: 1069.7629\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1655.9171 - val_loss: 1043.7200\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1606.2482 - val_loss: 1018.6686\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1557.7998 - val_loss: 994.5873\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1510.5477 - val_loss: 971.4556\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1464.4700 - val_loss: 949.2527\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1419.5437 - val_loss: 927.9581\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1375.7484 - val_loss: 907.5527\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1333.0625 - val_loss: 888.0168\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1291.4662 - val_loss: 869.3316\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1250.9390 - val_loss: 851.4786\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1211.4615 - val_loss: 834.4389\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1173.0148 - val_loss: 818.1948\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1135.5793 - val_loss: 802.7285\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1099.1370 - val_loss: 788.0222\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1063.6693 - val_loss: 774.0583\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1029.1583 - val_loss: 760.8198\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 995.5862 - val_loss: 748.2898\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 962.9354 - val_loss: 736.4509\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 931.1884 - val_loss: 725.2870\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 900.3281 - val_loss: 714.7814\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 870.3378 - val_loss: 704.9175\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 841.2004 - val_loss: 695.6794\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 812.8993 - val_loss: 687.0511\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 785.4186 - val_loss: 679.0168\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 758.7417 - val_loss: 671.5606\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 732.8528 - val_loss: 664.6669\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 707.7358 - val_loss: 658.3206\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 683.3751 - val_loss: 652.5061\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 659.7552 - val_loss: 647.2087\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 636.8606 - val_loss: 642.4131\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 614.6765 - val_loss: 638.1046\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 593.1871 - val_loss: 634.2686\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 572.3776 - val_loss: 630.8906\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 552.2338 - val_loss: 627.9562\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 532.7410 - val_loss: 625.4510\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 513.8842 - val_loss: 623.3615\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 495.6495 - val_loss: 621.6731\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 478.0225 - val_loss: 620.3724\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 460.9895 - val_loss: 619.4459\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 444.5364 - val_loss: 618.8798\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 428.6494 - val_loss: 618.6610\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 413.3150 - val_loss: 618.7764\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 398.5199 - val_loss: 619.2130\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 384.2509 - val_loss: 619.9578\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 370.4945 - val_loss: 620.9983\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 357.2380 - val_loss: 622.3220\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 344.4686 - val_loss: 623.9166\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 332.1735 - val_loss: 625.7700\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 320.3401 - val_loss: 627.8701\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 308.9564 - val_loss: 630.2051\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 298.0101 - val_loss: 632.7634\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 287.4890 - val_loss: 635.5338\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 277.3814 - val_loss: 638.5048\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 267.6754 - val_loss: 641.6653\n",
      "Epoch 81/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 258.3598 - val_loss: 645.0048\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 249.4227 - val_loss: 648.5121\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 240.8535 - val_loss: 652.1771\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 232.6407 - val_loss: 655.9897\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 224.7736 - val_loss: 659.9394\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 217.2415 - val_loss: 664.0167\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 210.0338 - val_loss: 668.2119\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 203.1402 - val_loss: 672.5157\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 196.5506 - val_loss: 676.9189\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 190.2550 - val_loss: 681.4130\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 184.2435 - val_loss: 685.9897\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 178.5064 - val_loss: 690.6415\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 173.0345 - val_loss: 695.3634\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 167.8184 - val_loss: 700.1588\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 162.8489 - val_loss: 705.3024\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 156.8107 - val_loss: 712.4254\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 150.8715 - val_loss: 718.6096\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 145.7644 - val_loss: 724.5542\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 141.1512 - val_loss: 730.3481\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 136.9209 - val_loss: 736.0375\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 133.0093 - val_loss: 741.6429\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 129.3758 - val_loss: 747.1755\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 125.9916 - val_loss: 752.6400\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 122.8344 - val_loss: 758.0377\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 119.8859 - val_loss: 763.3684\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 117.1309 - val_loss: 768.6314\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 114.5557 - val_loss: 773.8244\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 112.1484 - val_loss: 778.9459\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 109.8981 - val_loss: 783.9927\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 107.7950 - val_loss: 788.9637\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 105.8300 - val_loss: 793.8553\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 103.9945 - val_loss: 798.6660\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 102.2808 - val_loss: 803.3933\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 100.6813 - val_loss: 808.0355\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 99.1893 - val_loss: 812.5901\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 97.7982 - val_loss: 817.0555\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 96.5019 - val_loss: 821.4307\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 95.2947 - val_loss: 825.7141\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 94.1710 - val_loss: 829.9040\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 93.1257 - val_loss: 834.0002\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 92.1540 - val_loss: 838.0013\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 91.2512 - val_loss: 841.9068\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 90.4131 - val_loss: 845.7159\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 89.6355 - val_loss: 849.4290\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 88.9145 - val_loss: 853.0449\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 88.2464 - val_loss: 856.5643\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 87.6279 - val_loss: 859.9869\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 87.0557 - val_loss: 863.3137\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 86.5265 - val_loss: 866.5441\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 86.0377 - val_loss: 869.6794\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 85.5863 - val_loss: 872.7200\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 85.1699 - val_loss: 875.6671\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 84.7860 - val_loss: 878.5209\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 84.4323 - val_loss: 881.2832\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 84.1066 - val_loss: 883.9541\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 83.8071 - val_loss: 886.5361\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 83.5317 - val_loss: 889.0295\n",
      "Epoch 138/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 83.2787 - val_loss: 891.4359\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 83.0465 - val_loss: 893.7571\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.8334 - val_loss: 895.9944\n",
      "Epoch 141/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.6381 - val_loss: 898.1491\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.4592 - val_loss: 900.2238\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.2954 - val_loss: 902.2188\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 82.1456 - val_loss: 904.1369\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 82.0087 - val_loss: 905.9793\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 81.8835 - val_loss: 907.7489\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 81.7693 - val_loss: 909.4460\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 81.6650 - val_loss: 911.0729\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 81.5700 - val_loss: 912.6315\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 81.4833 - val_loss: 914.1244\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 81.4045 - val_loss: 915.5530\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 81.3327 - val_loss: 916.9188\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 81.2673 - val_loss: 918.2245\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 81.2080 - val_loss: 919.4707\n",
      "Epoch 155/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 81.1541 - val_loss: 920.6606\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 81.1050 - val_loss: 921.7953\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 81.0606 - val_loss: 922.8766\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 81.0203 - val_loss: 923.9070\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.9837 - val_loss: 924.8873\n",
      "Epoch 160/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 80.9506 - val_loss: 925.8207\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.9206 - val_loss: 926.7075\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.8933 - val_loss: 927.5499\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.8688 - val_loss: 928.3503\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.8466 - val_loss: 929.1092\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.8264 - val_loss: 929.8289\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.8083 - val_loss: 930.5112\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 80.7919 - val_loss: 931.1573\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 80.7771 - val_loss: 931.7685\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7637 - val_loss: 932.3472\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7517 - val_loss: 932.8932\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7409 - val_loss: 933.4094\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7311 - val_loss: 933.8968\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7223 - val_loss: 934.3563\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7145 - val_loss: 934.7897\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7074 - val_loss: 935.1979\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7011 - val_loss: 935.5823\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6954 - val_loss: 935.9439\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6903 - val_loss: 936.2836\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6858 - val_loss: 936.6031\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6818 - val_loss: 936.9028\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6782 - val_loss: 937.1843\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6750 - val_loss: 937.4483\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6722 - val_loss: 937.6956\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6697 - val_loss: 937.9266\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6676 - val_loss: 938.1434\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.6657 - val_loss: 938.3460\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 80.6641 - val_loss: 938.5350\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.6627 - val_loss: 938.7115\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.6615 - val_loss: 938.8766\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6605 - val_loss: 939.0303\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6597 - val_loss: 939.1732\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6590 - val_loss: 939.3065\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6585 - val_loss: 939.4305\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6582 - val_loss: 939.5457\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6579 - val_loss: 939.6526\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6578 - val_loss: 939.7518\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 80.6577 - val_loss: 939.8439\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6578 - val_loss: 939.9290\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6579 - val_loss: 940.0079\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6581 - val_loss: 940.0807\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6584 - val_loss: 940.1482\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6588 - val_loss: 940.2102\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6592 - val_loss: 940.2675\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6597 - val_loss: 940.3202\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6602 - val_loss: 940.3686\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6607 - val_loss: 940.4128\n",
      "Epoch 207/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6614 - val_loss: 940.4534\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6620 - val_loss: 940.4907\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6627 - val_loss: 940.5252\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6634 - val_loss: 940.5565\n",
      "Epoch 211/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6641 - val_loss: 940.5851\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6649 - val_loss: 940.6110\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6657 - val_loss: 940.6344\n",
      "Epoch 214/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6665 - val_loss: 940.6561\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6673 - val_loss: 940.6755\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6681 - val_loss: 940.6931\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6690 - val_loss: 940.7084\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6698 - val_loss: 940.7222\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6707 - val_loss: 940.7354\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6716 - val_loss: 940.7463\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6725 - val_loss: 940.7564\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6734 - val_loss: 940.7648\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6743 - val_loss: 940.7728\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6752 - val_loss: 940.7793\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6761 - val_loss: 940.7853\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 80.6770 - val_loss: 940.7902\n",
      "Epoch 227/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.6780 - val_loss: 940.7940\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6789 - val_loss: 940.7980\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6798 - val_loss: 940.8006\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6807 - val_loss: 940.8032\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6816 - val_loss: 940.8044\n",
      "Epoch 232/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6825 - val_loss: 940.8057\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6834 - val_loss: 940.8065\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6844 - val_loss: 940.8071\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6852 - val_loss: 940.8066\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6861 - val_loss: 940.8061\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6870 - val_loss: 940.8054\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6879 - val_loss: 940.8044\n",
      "Epoch 239/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6888 - val_loss: 940.8029\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6897 - val_loss: 940.8011\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6905 - val_loss: 940.7994\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6914 - val_loss: 940.7977\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6922 - val_loss: 940.7953\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 80.6931 - val_loss: 940.7930\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 80.6939 - val_loss: 940.7905\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6947 - val_loss: 940.7880\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6956 - val_loss: 940.7850\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6963 - val_loss: 940.7817\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 80.6972 - val_loss: 940.7785\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6980 - val_loss: 940.7755\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6988 - val_loss: 940.7720\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.6995 - val_loss: 940.7679\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 80.7003 - val_loss: 940.7647\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7010 - val_loss: 940.7607\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7018 - val_loss: 940.7568\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7026 - val_loss: 940.7527\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7033 - val_loss: 940.7486\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7040 - val_loss: 940.7444\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7047 - val_loss: 940.7390\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7054 - val_loss: 940.7339\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7062 - val_loss: 940.7280\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7068 - val_loss: 940.7220\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7075 - val_loss: 940.7148\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7082 - val_loss: 940.7058\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7088 - val_loss: 940.6841\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7095 - val_loss: 937.7353\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.9406 - val_loss: 938.3698\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7897 - val_loss: 938.7077\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7706 - val_loss: 938.9381\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7625 - val_loss: 939.1337\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7571 - val_loss: 939.3054\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7530 - val_loss: 939.4568\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7497 - val_loss: 939.5907\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7471 - val_loss: 939.7097\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7448 - val_loss: 939.8149\n",
      "Epoch 276/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 80.7430 - val_loss: 939.9088\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 80.7415 - val_loss: 939.9923\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7402 - val_loss: 940.0664\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7391 - val_loss: 940.1322\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7382 - val_loss: 940.1906\n",
      "Epoch 281/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7375 - val_loss: 940.2423\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7369 - val_loss: 940.2884\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 80.7364 - val_loss: 940.3299\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7360 - val_loss: 940.3660\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7357 - val_loss: 940.3987\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7354 - val_loss: 940.4276\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7353 - val_loss: 940.4525\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7351 - val_loss: 940.4752\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7350 - val_loss: 940.4949\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7350 - val_loss: 940.5123\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7350 - val_loss: 940.5278\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7351 - val_loss: 940.5411\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7351 - val_loss: 940.5536\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7352 - val_loss: 940.5639\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7354 - val_loss: 940.5737\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7355 - val_loss: 940.5817\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7357 - val_loss: 940.5887\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7359 - val_loss: 940.5951\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7360 - val_loss: 940.6005\n",
      "Epoch 300/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7362 - val_loss: 940.6053\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7364 - val_loss: 940.6097\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7366 - val_loss: 940.6136\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7368 - val_loss: 940.6163\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7370 - val_loss: 940.6190\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7372 - val_loss: 940.6213\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7374 - val_loss: 940.6229\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7377 - val_loss: 940.6245\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 80.7379 - val_loss: 940.6257\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7381 - val_loss: 940.6268\n",
      "Epoch 310/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7383 - val_loss: 940.6276\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7386 - val_loss: 940.6277\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7388 - val_loss: 940.6282\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7390 - val_loss: 940.6282\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7393 - val_loss: 940.6286\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7395 - val_loss: 940.6285\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7397 - val_loss: 940.6286\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7399 - val_loss: 940.6284\n",
      "Epoch 318/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7401 - val_loss: 940.6283\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7403 - val_loss: 940.6279\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7406 - val_loss: 940.6274\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7408 - val_loss: 940.6271\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7410 - val_loss: 940.6268\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7412 - val_loss: 940.6260\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7414 - val_loss: 940.6252\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7416 - val_loss: 940.6248\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7417 - val_loss: 940.6244\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7420 - val_loss: 940.6239\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7421 - val_loss: 940.6231\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7423 - val_loss: 940.6229\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7425 - val_loss: 940.6223\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 80.7427 - val_loss: 940.6216\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 80.7429 - val_loss: 940.6211\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7430 - val_loss: 940.6205\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7432 - val_loss: 940.6198\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7434 - val_loss: 940.6193\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7435 - val_loss: 940.6187\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7437 - val_loss: 940.6185\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7439 - val_loss: 940.6178\n",
      "Epoch 339/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7440 - val_loss: 940.6172\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 80.7442 - val_loss: 940.6166\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7443 - val_loss: 940.6160\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7445 - val_loss: 940.6154\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7446 - val_loss: 940.6144\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 80.7448 - val_loss: 940.6140\n",
      "Epoch 345/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7449 - val_loss: 940.6136\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7450 - val_loss: 940.6132\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 80.7451 - val_loss: 940.6127\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7453 - val_loss: 940.6121\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7455 - val_loss: 940.6121\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7456 - val_loss: 940.6115\n",
      "Epoch 351/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7456 - val_loss: 940.6105\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7458 - val_loss: 940.6099\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7459 - val_loss: 940.6096\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7460 - val_loss: 940.6093\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 80.7461 - val_loss: 940.6091\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 80.7462 - val_loss: 940.6084\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7464 - val_loss: 940.6082\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7465 - val_loss: 940.6074\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7466 - val_loss: 940.6070\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7467 - val_loss: 940.6064\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7468 - val_loss: 940.6064\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7469 - val_loss: 940.6055\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7470 - val_loss: 940.6048\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 80.7471 - val_loss: 940.6045\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 80.7472 - val_loss: 940.6038\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7473 - val_loss: 940.6036\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7474 - val_loss: 940.6036\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7475 - val_loss: 940.6031\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7475 - val_loss: 940.6026\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7476 - val_loss: 940.6022\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7477 - val_loss: 940.6016\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7478 - val_loss: 940.6008\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7478 - val_loss: 940.6005\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7479 - val_loss: 940.6001\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7480 - val_loss: 940.5997\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7481 - val_loss: 940.5992\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 80.7482 - val_loss: 940.5991\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7483 - val_loss: 940.5989\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7483 - val_loss: 940.5986\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7484 - val_loss: 940.5983\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7485 - val_loss: 940.5980\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7485 - val_loss: 940.5980\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7486 - val_loss: 940.5978\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7486 - val_loss: 940.5976\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7487 - val_loss: 940.5974\n",
      "Epoch 386/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7488 - val_loss: 940.5970\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7488 - val_loss: 940.5967\n",
      "Epoch 388/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7489 - val_loss: 940.5963\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7490 - val_loss: 940.5963\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7490 - val_loss: 940.5960\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7491 - val_loss: 940.5959\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7491 - val_loss: 940.5953\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7492 - val_loss: 940.5953\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 80.7492 - val_loss: 940.5951\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7492 - val_loss: 940.5948\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7493 - val_loss: 940.5945\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7493 - val_loss: 940.5940\n",
      "Epoch 398/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 80.7494 - val_loss: 940.5936\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7495 - val_loss: 940.5936\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7495 - val_loss: 940.5935\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7495 - val_loss: 940.5935\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7496 - val_loss: 940.5934\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7496 - val_loss: 940.5935\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7497 - val_loss: 940.5934\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7497 - val_loss: 940.5932\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7497 - val_loss: 940.5927\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7497 - val_loss: 940.5925\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7498 - val_loss: 940.5925\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7499 - val_loss: 940.5923\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7499 - val_loss: 940.5920\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7499 - val_loss: 940.5916\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7500 - val_loss: 940.5916\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7500 - val_loss: 940.5914\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7500 - val_loss: 940.5914\n",
      "Epoch 415/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7500 - val_loss: 940.5911\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7501 - val_loss: 940.5909\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7501 - val_loss: 940.5909\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7502 - val_loss: 940.5911\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 80.7502 - val_loss: 940.5907\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7502 - val_loss: 940.5905\n",
      "Epoch 421/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7502 - val_loss: 940.5903\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7503 - val_loss: 940.5901\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7503 - val_loss: 940.5900\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7503 - val_loss: 940.5895\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7503 - val_loss: 940.5895\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7504 - val_loss: 940.5893\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7504 - val_loss: 940.5889\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 80.7504 - val_loss: 940.5886\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7505 - val_loss: 940.5884\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7505 - val_loss: 940.5882\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7505 - val_loss: 940.5880\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7505 - val_loss: 940.5878\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7505 - val_loss: 940.5878\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7506 - val_loss: 940.5878\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7506 - val_loss: 940.5878\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7506 - val_loss: 940.5878\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7506 - val_loss: 940.5877\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7506 - val_loss: 940.5877\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 80.7507 - val_loss: 940.5872\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 80.7507 - val_loss: 940.5872\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7507 - val_loss: 940.5868\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7507 - val_loss: 940.5867\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7507 - val_loss: 940.5864\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7508 - val_loss: 940.5862\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 80.7508 - val_loss: 940.5862\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 80.7508 - val_loss: 940.5864\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 80.7508 - val_loss: 940.5864\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7508 - val_loss: 940.5864\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7509 - val_loss: 940.5867\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7508 - val_loss: 940.5864\n",
      "Epoch 451/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7509 - val_loss: 940.5866\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7509 - val_loss: 940.5861\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7509 - val_loss: 940.5859\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7509 - val_loss: 940.5860\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7510 - val_loss: 940.5860\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7510 - val_loss: 940.5861\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7510 - val_loss: 940.5862\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7510 - val_loss: 940.5862\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 80.7510 - val_loss: 940.5856\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7510 - val_loss: 940.5857\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7510 - val_loss: 940.5855\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7510 - val_loss: 940.5853\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7510 - val_loss: 940.5852\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7511 - val_loss: 940.5852\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7511 - val_loss: 940.5850\n",
      "Epoch 466/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7511 - val_loss: 940.5852\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7511 - val_loss: 940.5852\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7511 - val_loss: 940.5850\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7511 - val_loss: 940.5850\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7511 - val_loss: 940.5850\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7511 - val_loss: 940.5850\n",
      "Epoch 472/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7511 - val_loss: 940.5850\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7511 - val_loss: 940.5850\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7511 - val_loss: 940.5850\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7511 - val_loss: 940.5850\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7511 - val_loss: 940.5847\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7512 - val_loss: 940.5847\n",
      "Epoch 478/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7512 - val_loss: 940.5845\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 80.7512 - val_loss: 940.5844\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7512 - val_loss: 940.5843\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7512 - val_loss: 940.5843\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 80.7512 - val_loss: 940.5843\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 80.7512 - val_loss: 940.5839\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 80.7512 - val_loss: 940.5837\n",
      "Epoch 485/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7512 - val_loss: 940.5837\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7512 - val_loss: 940.5837\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7512 - val_loss: 940.5837\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7512 - val_loss: 940.5837\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7513 - val_loss: 940.5841\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7513 - val_loss: 940.5841\n",
      "Epoch 491/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7513 - val_loss: 940.5842\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7513 - val_loss: 940.5842\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7513 - val_loss: 940.5841\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7513 - val_loss: 940.5839\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7513 - val_loss: 940.5839\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7513 - val_loss: 940.5837\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 80.7513 - val_loss: 940.5834\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 80.7513 - val_loss: 940.5829\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7513 - val_loss: 940.5828\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 80.7513 - val_loss: 940.5827\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 397ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.60773343e+01, 5.59848973e+01, 5.58924603e+01, 5.58000233e+01,\n",
       "        5.57075864e+01, 5.56151494e+01, 5.55508170e+01, 0.00000000e+00,\n",
       "        6.38354957e-01, 0.00000000e+00, 0.00000000e+00, 3.15409720e-01,\n",
       "        0.00000000e+00, 5.68044584e+01, 5.67624416e+01, 5.67204248e+01,\n",
       "        5.66524977e+01, 5.65600607e+01, 5.64676237e+01, 5.63751867e+01,\n",
       "        5.62827498e+01, 5.61903128e+01, 5.60978758e+01, 5.60054388e+01,\n",
       "        5.59130019e+01, 5.58205649e+01, 5.57281279e+01, 5.56356909e+01,\n",
       "        5.55638889e+01, 5.81349907e+01, 5.80089402e+01, 5.78828898e+01,\n",
       "        5.77568394e+01, 5.76307890e+01, 5.75047386e+01, 5.73786881e+01,\n",
       "        5.72526377e+01, 5.71265873e+01, 1.04276955e+00, 0.00000000e+00,\n",
       "        1.29682300e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.19310090e-01, 1.29750100e-01, 5.58411064e+01,\n",
       "        5.57486695e+01, 5.56562325e+01, 5.55769608e+01, 5.81630019e+01,\n",
       "        5.80369514e+01, 5.79109001e+01, 5.77848506e+01, 5.76588002e+01,\n",
       "        5.75347498e+01, 5.74116993e+01, 5.72886489e+01, 5.71655985e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.77101541e+01, 5.75841036e+01,\n",
       "        5.74570532e+01, 5.73300200e+01, 5.72095952e+01, 5.70892391e+01,\n",
       "        5.69700786e+01, 5.68507181e+01, 5.67345576e+01, 6.44609833e+01,\n",
       "        1.92497360e-01, 6.27657661e+01, 1.11946177e+00, 0.00000000e+00,\n",
       "        7.11524000e-03, 1.33132815e+00, 1.37562310e-01, 5.36103840e-01,\n",
       "        5.99574661e+01, 0.00000000e+00, 0.00000000e+00, 1.90725774e-01,\n",
       "        0.00000000e+00, 3.75996977e-01, 0.00000000e+00, 5.94399154e-01,\n",
       "        0.00000000e+00, 3.11569512e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.34181972e-02, 0.00000000e+00, 1.02772510e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.14563927e-01, 9.54535902e-02, 0.00000000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48.14158639, 48.13174831, 48.12191023, 48.11207215, 48.10223406,\n",
       "       48.09239598, 48.0825579 , 48.07271982, 48.06288174, 48.05304366,\n",
       "       48.04320557, 48.03336749, 48.02352941, 48.01369133, 48.00385325,\n",
       "       47.99401517, 47.98417709, 47.974339  , 47.96450092, 47.95466284,\n",
       "       47.94482476, 47.93498668, 47.9251486 , 47.91531051, 47.90547243,\n",
       "       47.89563435, 47.88579627, 47.87595819, 47.86612011, 47.85628203,\n",
       "       47.84644394, 47.83660586, 47.82676778, 47.8169297 , 47.80709162,\n",
       "       47.79725354, 47.78741545, 47.77757737, 47.76773929, 47.75790121,\n",
       "       47.74806313, 47.73822505, 47.72838696, 47.71854888, 47.7087108 ,\n",
       "       47.69887272, 47.68903464, 47.67919656, 47.66935848, 47.65952039,\n",
       "       47.64968231, 47.63984423, 47.63000615, 47.62016807, 47.61032999,\n",
       "       47.6004919 , 47.59065382, 47.58081574, 47.57097766, 47.56113958,\n",
       "       47.5513015 , 47.54146341, 47.53162533, 47.52178725, 47.51194917,\n",
       "       47.50211109, 47.49227301, 47.48243493, 47.47259684, 47.46275876,\n",
       "       47.45292068, 47.4430826 , 47.43324452, 47.42340644, 47.41356835,\n",
       "       47.40373027, 47.39389219, 47.38405411, 47.37421603, 47.36437795,\n",
       "       47.35453986, 47.34470178, 47.3348637 , 47.32502562, 47.31518754,\n",
       "       47.30534946, 47.29551138, 47.28567329, 47.27583521, 47.26599713,\n",
       "       47.25615905, 47.24632097, 47.23648289, 47.2266448 , 47.21680672,\n",
       "       47.20696864, 47.19713056, 47.18729248, 47.1774544 , 47.16761631])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.82661885793422\n",
      "25.63722487586837\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
