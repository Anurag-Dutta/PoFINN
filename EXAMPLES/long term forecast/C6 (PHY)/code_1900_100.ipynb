{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "1995    50.669363\n",
       "1996    50.655824\n",
       "1997    50.642285\n",
       "1998    50.628746\n",
       "1999    50.615208\n",
       "Name: C6, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c6_interpolated_1900_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84.600000\n",
       "1       84.431933\n",
       "2       84.263866\n",
       "3       84.095798\n",
       "4       83.927731\n",
       "          ...    \n",
       "1895     0.000000\n",
       "1896     0.419310\n",
       "1897     0.000000\n",
       "1898     0.249747\n",
       "1899     0.129750\n",
       "Name: C6, Length: 1900, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1900)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.431933</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.263866</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.095798</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.927731</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     84.600000  0.000298\n",
       "1     84.431933  0.000298\n",
       "2     84.263866  0.000297\n",
       "3     84.095798  0.000297\n",
       "4     83.927731  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 82.7524  # Value for C0\n",
    "K0 = -0.0031  # Value for K0\n",
    "K1 = -0.0003  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0171    # Value for b\n",
    "c = 3.0230    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    84.600000    84.431933    84.263866    84.095798    83.927731   \n",
      "351    84.431933    84.263866    84.095798    83.927731    83.759664   \n",
      "352    84.263866    84.095798    83.927731    83.759664    83.591597   \n",
      "353    84.095798    83.927731    83.759664    83.591597    83.423529   \n",
      "354    83.927731    83.759664    83.591597    83.423529    83.255462   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    83.759664    83.591597    83.423529    83.255462    83.092437  ...   \n",
      "351    83.591597    83.423529    83.255462    83.092437    82.991597  ...   \n",
      "352    83.423529    83.255462    83.092437    82.991597    82.890756  ...   \n",
      "353    83.255462    83.092437    82.991597    82.890756    82.789916  ...   \n",
      "354    83.092437    82.991597    82.890756    82.789916    82.689076  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   70.003688    0.000263   69.960738    0.000263   69.917787    0.000263   \n",
      "351   69.960738    0.000263   69.917787    0.000263   69.874837    0.000262   \n",
      "352   69.917787    0.000263   69.874837    0.000262   69.831886    0.000262   \n",
      "353   69.874837    0.000262   69.831886    0.000262   69.788936    0.000262   \n",
      "354   69.831886    0.000262   69.788936    0.000262   69.745985    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   69.874837    0.000262   69.831886    0.000262  \n",
      "351   69.831886    0.000262   69.788936    0.000262  \n",
      "352   69.788936    0.000262   69.745985    0.000262  \n",
      "353   69.745985    0.000262   69.703035    0.000262  \n",
      "354   69.703035    0.000262   69.660084    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1450, 1, 251) (1450, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 2s 29ms/step - loss: 3866.5991 - val_loss: 2686.8833\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3779.3484 - val_loss: 2646.9656\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3726.8850 - val_loss: 2606.9880\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3674.5562 - val_loss: 2567.3999\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3622.6943 - val_loss: 2528.2678\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3571.3511 - val_loss: 2489.6042\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3520.5403 - val_loss: 2451.4116\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3470.2629 - val_loss: 2413.6887\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 3420.5188 - val_loss: 2376.4348\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3371.3062 - val_loss: 2339.6465\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3322.6228 - val_loss: 2303.3218\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3274.4646 - val_loss: 2267.4570\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3226.8298 - val_loss: 2232.0488\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3179.7136 - val_loss: 2197.0933\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3133.1135 - val_loss: 2162.5884\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3087.0251 - val_loss: 2128.5293\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3041.4451 - val_loss: 2094.9133\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2996.3691 - val_loss: 2061.7366\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2951.7944 - val_loss: 2028.9952\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2907.7161 - val_loss: 1996.2802\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2861.5623 - val_loss: 1960.7311\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2813.2795 - val_loss: 1925.8401\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2766.3203 - val_loss: 1892.0502\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2720.6243 - val_loss: 1859.1334\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2675.9282 - val_loss: 1826.9435\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2632.0730 - val_loss: 1795.3950\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2588.9639 - val_loss: 1764.4343\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2546.5408 - val_loss: 1734.0245\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2504.7590 - val_loss: 1704.1388\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2463.5881 - val_loss: 1674.7567\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2423.0044 - val_loss: 1645.8612\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2382.9880 - val_loss: 1617.4390\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2343.5217 - val_loss: 1589.4784\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 2304.5930 - val_loss: 1561.9697\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2266.1897 - val_loss: 1534.9031\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2228.3013 - val_loss: 1508.2716\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2190.9180 - val_loss: 1482.0671\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 2154.0317 - val_loss: 1456.2836\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 2117.6348 - val_loss: 1430.9144\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 2081.7197 - val_loss: 1405.9535\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2046.2798 - val_loss: 1381.3956\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2011.3082 - val_loss: 1357.2355\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1976.7998 - val_loss: 1333.4678\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1942.7489 - val_loss: 1310.0875\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1909.1494 - val_loss: 1287.0909\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1875.9958 - val_loss: 1264.4728\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1843.2844 - val_loss: 1242.2286\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1811.0090 - val_loss: 1220.3545\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1779.1647 - val_loss: 1198.8461\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1747.7484 - val_loss: 1177.6995\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1716.7544 - val_loss: 1156.9104\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1686.1786 - val_loss: 1136.4753\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1656.0170 - val_loss: 1116.3905\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1626.2649 - val_loss: 1096.6517\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1596.9187 - val_loss: 1077.2554\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1567.9738 - val_loss: 1058.1981\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1539.4266 - val_loss: 1039.4758\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1511.2729 - val_loss: 1021.0859\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1483.5099 - val_loss: 1003.0234\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1456.1323 - val_loss: 985.2864\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1429.1375 - val_loss: 967.8704\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1402.5208 - val_loss: 950.7722\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1376.2791 - val_loss: 933.9890\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1350.4094 - val_loss: 917.5167\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1324.9072 - val_loss: 901.3531\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 1299.7697 - val_loss: 885.4939\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1274.9929 - val_loss: 869.9363\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1250.5736 - val_loss: 854.6771\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1226.5081 - val_loss: 839.7129\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1202.7933 - val_loss: 825.0408\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1179.4258 - val_loss: 810.6577\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1156.4020 - val_loss: 796.5600\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1133.7189 - val_loss: 782.7452\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1111.3728 - val_loss: 769.2102\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1089.3612 - val_loss: 755.9515\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1067.6807 - val_loss: 742.9665\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1046.3274 - val_loss: 730.2518\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1025.2983 - val_loss: 717.8049\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1004.5914 - val_loss: 705.6225\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 984.2024 - val_loss: 693.7017\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 964.1284 - val_loss: 682.0397\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 944.3668 - val_loss: 670.6335\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 924.9139 - val_loss: 659.4801\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 905.7669 - val_loss: 648.5769\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 886.9230 - val_loss: 637.9205\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 868.3788 - val_loss: 627.5085\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 850.1315 - val_loss: 617.3375\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 832.1779 - val_loss: 607.4054\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 814.5153 - val_loss: 597.7089\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 797.1409 - val_loss: 588.2452\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 780.0514 - val_loss: 579.0117\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 763.2440 - val_loss: 570.0054\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 746.7160 - val_loss: 561.2239\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 730.4644 - val_loss: 552.6641\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 714.4861 - val_loss: 544.3228\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 698.7781 - val_loss: 536.1980\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 683.3378 - val_loss: 528.2866\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 668.1625 - val_loss: 520.5859\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 653.2495 - val_loss: 513.0934\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 638.5957 - val_loss: 505.8062\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 624.1987 - val_loss: 498.7218\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 610.0551 - val_loss: 491.8373\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 596.1623 - val_loss: 485.1499\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 582.5176 - val_loss: 478.6572\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 569.1183 - val_loss: 472.3564\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 555.9618 - val_loss: 466.2451\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 543.0454 - val_loss: 460.3203\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 530.3661 - val_loss: 454.5793\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 517.9212 - val_loss: 449.0199\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 505.7080 - val_loss: 443.6391\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 493.7240 - val_loss: 438.4347\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 481.9666 - val_loss: 433.4038\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 470.4330 - val_loss: 428.5439\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 459.1206 - val_loss: 423.8523\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 448.0266 - val_loss: 419.3266\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 437.1485 - val_loss: 414.9641\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 426.4837 - val_loss: 410.7624\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 416.0298 - val_loss: 406.7188\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 405.7837 - val_loss: 402.8306\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 395.7429 - val_loss: 399.0956\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 385.9052 - val_loss: 395.5112\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 376.2676 - val_loss: 392.0748\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 366.8278 - val_loss: 388.7839\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 357.5830 - val_loss: 385.6360\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 348.5310 - val_loss: 382.6286\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 339.6689 - val_loss: 379.7593\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 330.9946 - val_loss: 377.0254\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 322.5053 - val_loss: 374.4247\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 314.1985 - val_loss: 371.9549\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 306.0717 - val_loss: 369.6132\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 298.1225 - val_loss: 367.3971\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 290.3484 - val_loss: 365.3044\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 282.7469 - val_loss: 363.3327\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 275.3155 - val_loss: 361.4794\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 268.0518 - val_loss: 359.7424\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 260.9534 - val_loss: 358.1190\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 254.0179 - val_loss: 356.6070\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 247.2428 - val_loss: 355.2039\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 240.6257 - val_loss: 353.9076\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 234.1642 - val_loss: 352.7154\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 227.8559 - val_loss: 351.6254\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 221.6985 - val_loss: 350.6348\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 215.6896 - val_loss: 349.7417\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 209.8269 - val_loss: 348.9435\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 204.1080 - val_loss: 348.2381\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 198.5307 - val_loss: 347.6232\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 193.0927 - val_loss: 347.0966\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 187.7914 - val_loss: 346.6558\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 182.6248 - val_loss: 346.2988\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 177.5905 - val_loss: 346.0234\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 172.6864 - val_loss: 345.8272\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 167.9099 - val_loss: 345.7082\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 163.2587 - val_loss: 345.6641\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 158.7309 - val_loss: 345.6928\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 154.3245 - val_loss: 345.7922\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 150.0367 - val_loss: 345.9602\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 145.8659 - val_loss: 346.1945\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 141.8097 - val_loss: 346.4932\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 137.8658 - val_loss: 346.8541\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 134.0321 - val_loss: 347.2752\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 130.3066 - val_loss: 347.7544\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126.6873 - val_loss: 348.2899\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 123.1719 - val_loss: 348.8794\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 119.7585 - val_loss: 349.5211\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 116.4447 - val_loss: 350.2129\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 113.2288 - val_loss: 350.9530\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 110.1085 - val_loss: 351.7395\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 107.0821 - val_loss: 352.5704\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 104.1474 - val_loss: 353.4439\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 101.3024 - val_loss: 354.3579\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 98.5454 - val_loss: 355.3109\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 95.8743 - val_loss: 356.3010\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 93.2870 - val_loss: 357.3263\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 90.7818 - val_loss: 358.3850\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 88.3569 - val_loss: 359.4756\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 86.0103 - val_loss: 360.5962\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 83.7400 - val_loss: 361.7453\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 81.5444 - val_loss: 362.9210\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 79.4218 - val_loss: 364.1217\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 77.3704 - val_loss: 365.3459\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 75.3883 - val_loss: 366.5920\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 73.4738 - val_loss: 367.8582\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 71.6252 - val_loss: 369.1433\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 69.8410 - val_loss: 370.4456\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 68.1193 - val_loss: 371.7638\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 66.4586 - val_loss: 373.0962\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 64.8571 - val_loss: 374.4415\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 63.3133 - val_loss: 375.7984\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 61.8257 - val_loss: 377.1656\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 60.3926 - val_loss: 378.5415\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 59.0125 - val_loss: 379.9251\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 57.6840 - val_loss: 381.3149\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 56.4056 - val_loss: 382.7097\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 55.1758 - val_loss: 384.1083\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 53.9933 - val_loss: 385.5097\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 52.8565 - val_loss: 386.9127\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 51.7640 - val_loss: 388.3160\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 50.7147 - val_loss: 389.7184\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 49.7071 - val_loss: 391.1192\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 48.7399 - val_loss: 392.5173\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 47.8118 - val_loss: 393.9117\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 46.9215 - val_loss: 395.3014\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 46.0680 - val_loss: 396.6855\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 45.2499 - val_loss: 398.0630\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 44.4660 - val_loss: 399.4331\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 43.7153 - val_loss: 400.7953\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 42.9965 - val_loss: 402.1484\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 42.3085 - val_loss: 403.4919\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 41.6504 - val_loss: 404.8246\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 41.0211 - val_loss: 406.1462\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 40.4195 - val_loss: 407.4562\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 39.8445 - val_loss: 408.7537\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 39.2953 - val_loss: 410.0380\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 38.7710 - val_loss: 411.3085\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 38.2705 - val_loss: 412.5649\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 37.7929 - val_loss: 413.8066\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 37.3375 - val_loss: 415.0331\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 36.9032 - val_loss: 416.2439\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 36.4894 - val_loss: 417.4386\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 36.0951 - val_loss: 418.6169\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 35.7196 - val_loss: 419.7781\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 35.3623 - val_loss: 420.9221\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 35.0222 - val_loss: 422.0487\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 34.6987 - val_loss: 423.1574\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 34.3910 - val_loss: 424.2484\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 34.0986 - val_loss: 425.3209\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.8207 - val_loss: 426.3748\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.5568 - val_loss: 427.4100\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 33.3062 - val_loss: 428.4265\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 33.0684 - val_loss: 429.4239\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 32.8427 - val_loss: 430.4022\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 32.6286 - val_loss: 431.3613\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 32.4258 - val_loss: 432.3011\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 32.2334 - val_loss: 433.2215\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 32.0512 - val_loss: 434.1230\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.8786 - val_loss: 435.0049\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.7151 - val_loss: 435.8678\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.5604 - val_loss: 436.7112\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.4139 - val_loss: 437.5353\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 31.2755 - val_loss: 438.3401\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 31.1445 - val_loss: 439.1263\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 31.0207 - val_loss: 439.8933\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.9037 - val_loss: 440.6419\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.7931 - val_loss: 441.3717\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.6886 - val_loss: 442.0827\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.5900 - val_loss: 442.7754\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 30.4969 - val_loss: 443.4499\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 30.4090 - val_loss: 444.1063\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.3261 - val_loss: 444.7450\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.2479 - val_loss: 445.3662\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 30.1740 - val_loss: 445.9698\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 30.1045 - val_loss: 446.5564\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 30.0390 - val_loss: 447.1263\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.9771 - val_loss: 447.6792\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.9188 - val_loss: 448.2156\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.8639 - val_loss: 448.7363\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.8122 - val_loss: 449.2409\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.7635 - val_loss: 449.7298\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.7177 - val_loss: 450.2034\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.6744 - val_loss: 450.6621\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.6338 - val_loss: 451.1061\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5955 - val_loss: 451.5353\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5595 - val_loss: 451.9507\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.5256 - val_loss: 452.3521\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.4937 - val_loss: 452.7394\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.4637 - val_loss: 453.1139\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.4355 - val_loss: 453.4751\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.4089 - val_loss: 453.8240\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.3840 - val_loss: 454.1605\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 29.3605 - val_loss: 454.4847\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.3384 - val_loss: 454.7977\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.3176 - val_loss: 455.0985\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.2981 - val_loss: 455.3887\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.2797 - val_loss: 455.6677\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.2624 - val_loss: 455.9360\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.2462 - val_loss: 456.1942\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.2309 - val_loss: 456.4424\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.2166 - val_loss: 456.6810\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.2031 - val_loss: 456.9101\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.1904 - val_loss: 457.1300\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.1785 - val_loss: 457.3413\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 29.1673 - val_loss: 457.5438\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.1567 - val_loss: 457.7378\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.1469 - val_loss: 457.9240\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.1376 - val_loss: 458.1023\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.1288 - val_loss: 458.2731\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.1206 - val_loss: 458.4366\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.1130 - val_loss: 458.5931\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.1057 - val_loss: 458.7428\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0990 - val_loss: 458.8859\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0926 - val_loss: 459.0223\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0866 - val_loss: 459.1529\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0810 - val_loss: 459.2778\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0757 - val_loss: 459.3965\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0709 - val_loss: 459.5102\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0662 - val_loss: 459.6184\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0619 - val_loss: 459.7216\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0579 - val_loss: 459.8198\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0541 - val_loss: 459.9138\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0505 - val_loss: 460.0028\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0472 - val_loss: 460.0876\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0441 - val_loss: 460.1685\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0412 - val_loss: 460.2453\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0385 - val_loss: 460.3181\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0360 - val_loss: 460.3878\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0337 - val_loss: 460.4533\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0315 - val_loss: 460.5158\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0295 - val_loss: 460.5748\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 29.0276 - val_loss: 460.6308\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0259 - val_loss: 460.6841\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0242 - val_loss: 460.7344\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0228 - val_loss: 460.7821\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.0214 - val_loss: 460.8274\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0202 - val_loss: 460.8702\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0189 - val_loss: 460.9108\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0179 - val_loss: 460.9487\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0169 - val_loss: 460.9848\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0161 - val_loss: 461.0191\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0152 - val_loss: 461.0514\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0145 - val_loss: 461.0814\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.0138 - val_loss: 461.1099\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0133 - val_loss: 461.1371\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0127 - val_loss: 461.1625\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0123 - val_loss: 461.1866\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0118 - val_loss: 461.2088\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0115 - val_loss: 461.2299\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.0112 - val_loss: 461.2498\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0109 - val_loss: 461.2687\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0107 - val_loss: 461.2862\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0105 - val_loss: 461.3029\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0104 - val_loss: 461.3181\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0103 - val_loss: 461.3328\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0102 - val_loss: 461.3463\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0102 - val_loss: 461.3589\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0102 - val_loss: 461.3710\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0102 - val_loss: 461.3819\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0103 - val_loss: 461.3925\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0104 - val_loss: 461.4023\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0105 - val_loss: 461.4110\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0106 - val_loss: 461.4195\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0107 - val_loss: 461.4273\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0109 - val_loss: 461.4347\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0111 - val_loss: 461.4413\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 29.0113 - val_loss: 461.4475\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0115 - val_loss: 461.4533\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0117 - val_loss: 461.4585\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0120 - val_loss: 461.4633\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0122 - val_loss: 461.4683\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0125 - val_loss: 461.4726\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0127 - val_loss: 461.4764\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0130 - val_loss: 461.4799\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0133 - val_loss: 461.4833\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0136 - val_loss: 461.4863\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0139 - val_loss: 461.4889\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0142 - val_loss: 461.4915\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0145 - val_loss: 461.4936\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0148 - val_loss: 461.4958\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0151 - val_loss: 461.4973\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0155 - val_loss: 461.4994\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0158 - val_loss: 461.5005\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0162 - val_loss: 461.5020\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0165 - val_loss: 461.5032\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0168 - val_loss: 461.5044\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0171 - val_loss: 461.5054\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0175 - val_loss: 461.5059\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0178 - val_loss: 461.5067\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0181 - val_loss: 461.5071\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0185 - val_loss: 461.5075\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0188 - val_loss: 461.5075\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0192 - val_loss: 461.5077\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0196 - val_loss: 461.5084\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0199 - val_loss: 461.5085\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0202 - val_loss: 461.5085\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0206 - val_loss: 461.5086\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0209 - val_loss: 461.5085\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0212 - val_loss: 461.5085\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0215 - val_loss: 461.5082\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0218 - val_loss: 461.5079\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 29.0222 - val_loss: 461.5079\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0225 - val_loss: 461.5073\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0228 - val_loss: 461.5069\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0231 - val_loss: 461.5066\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0234 - val_loss: 461.5058\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0238 - val_loss: 461.5053\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0241 - val_loss: 461.5049\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0244 - val_loss: 461.5043\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0247 - val_loss: 461.5037\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0250 - val_loss: 461.5034\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0253 - val_loss: 461.5030\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0256 - val_loss: 461.5023\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0259 - val_loss: 461.5017\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0262 - val_loss: 461.5011\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0265 - val_loss: 461.5006\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0268 - val_loss: 461.4999\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0271 - val_loss: 461.4995\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0273 - val_loss: 461.4989\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0276 - val_loss: 461.4983\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0279 - val_loss: 461.4981\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0281 - val_loss: 461.4974\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 29.0284 - val_loss: 461.4969\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0287 - val_loss: 461.4962\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0290 - val_loss: 461.4958\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0292 - val_loss: 461.4956\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0294 - val_loss: 461.4951\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0297 - val_loss: 461.4946\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0299 - val_loss: 461.4941\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0301 - val_loss: 461.4932\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0304 - val_loss: 461.4926\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0306 - val_loss: 461.4920\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0309 - val_loss: 461.4913\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0311 - val_loss: 461.4907\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0313 - val_loss: 461.4902\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0315 - val_loss: 461.4895\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0317 - val_loss: 461.4891\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0320 - val_loss: 461.4883\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0322 - val_loss: 461.4879\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0324 - val_loss: 461.4872\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0326 - val_loss: 461.4865\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0328 - val_loss: 461.4861\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0330 - val_loss: 461.4856\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0332 - val_loss: 461.4850\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0334 - val_loss: 461.4846\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 29.0336 - val_loss: 461.4842\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0338 - val_loss: 461.4834\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0340 - val_loss: 461.4830\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0342 - val_loss: 461.4830\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0343 - val_loss: 461.4828\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0345 - val_loss: 461.4818\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0347 - val_loss: 461.4815\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0348 - val_loss: 461.4809\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0350 - val_loss: 461.4806\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0352 - val_loss: 461.4802\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0354 - val_loss: 461.4794\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0355 - val_loss: 461.4792\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0357 - val_loss: 461.4788\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0358 - val_loss: 461.4782\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0360 - val_loss: 461.4778\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0361 - val_loss: 461.4771\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0363 - val_loss: 461.4766\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0365 - val_loss: 461.4761\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0366 - val_loss: 461.4759\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0367 - val_loss: 461.4756\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0369 - val_loss: 461.4752\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 29.0370 - val_loss: 461.4749\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0372 - val_loss: 461.4746\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0373 - val_loss: 461.4742\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0374 - val_loss: 461.4740\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0375 - val_loss: 461.4737\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0376 - val_loss: 461.4733\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0378 - val_loss: 461.4730\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0379 - val_loss: 461.4728\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0381 - val_loss: 461.4725\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0381 - val_loss: 461.4719\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0383 - val_loss: 461.4716\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0384 - val_loss: 461.4716\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0385 - val_loss: 461.4713\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0386 - val_loss: 461.4713\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0387 - val_loss: 461.4708\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.0388 - val_loss: 461.4705\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.0389 - val_loss: 461.4702\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0390 - val_loss: 461.4702\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 29.0391 - val_loss: 461.4699\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0392 - val_loss: 461.4694\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0393 - val_loss: 461.4693\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0394 - val_loss: 461.4691\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 29.0395 - val_loss: 461.4686\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.0396 - val_loss: 461.4683\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0397 - val_loss: 461.4683\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0398 - val_loss: 461.4678\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0399 - val_loss: 461.4677\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0400 - val_loss: 461.4677\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0400 - val_loss: 461.4675\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 29.0401 - val_loss: 461.4672\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.0402 - val_loss: 461.4669\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 29.0403 - val_loss: 461.4668\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 29.0404 - val_loss: 461.4664\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0405 - val_loss: 461.4665\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0405 - val_loss: 461.4663\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0406 - val_loss: 461.4661\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0406 - val_loss: 461.4656\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.0407 - val_loss: 461.4656\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0408 - val_loss: 461.4655\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0409 - val_loss: 461.4655\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0409 - val_loss: 461.4650\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.0410 - val_loss: 461.4650\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0411 - val_loss: 461.4650\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0411 - val_loss: 461.4643\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0412 - val_loss: 461.4643\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0412 - val_loss: 461.4641\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0413 - val_loss: 461.4639\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0414 - val_loss: 461.4638\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0414 - val_loss: 461.4635\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0415 - val_loss: 461.4632\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0416 - val_loss: 461.4630\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0416 - val_loss: 461.4625\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 29.0417 - val_loss: 461.4624\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0417 - val_loss: 461.4620\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0418 - val_loss: 461.4615\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0419 - val_loss: 461.4613\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.0419 - val_loss: 461.4613\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(82.7524, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0031, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0003, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0171, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(3.0230, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 339ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.59027311e+01, 5.58719188e+01, 5.58411064e+01, 5.58102941e+01,\n",
       "        5.57794818e+01, 5.57486695e+01, 5.57178571e+01, 5.56870448e+01,\n",
       "        5.56562325e+01, 5.56254202e+01, 5.55965686e+01, 5.55769608e+01,\n",
       "        5.55573529e+01, 5.82200747e+01, 5.81630019e+01, 5.81209851e+01,\n",
       "        5.80789683e+01, 5.80369514e+01, 5.79949346e+01, 5.79529178e+01,\n",
       "        5.79109010e+01, 5.78688842e+01, 5.78268674e+01, 5.77848506e+01,\n",
       "        5.77428338e+01, 5.77008170e+01, 5.76588002e+01, 5.76167834e+01,\n",
       "        5.75747666e+01, 5.75327498e+01, 5.74907330e+01, 5.74487162e+01,\n",
       "        5.74066993e+01, 5.73646825e+01, 5.73226657e+01, 5.72806489e+01,\n",
       "        5.72386321e+01, 5.71966153e+01, 5.71545985e+01, 5.71125817e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.53977270e-01, 2.47898160e-01,\n",
       "        0.00000000e+00, 2.81776700e-01, 0.00000000e+00, 5.77101541e+01,\n",
       "        5.76671373e+01, 5.76261205e+01, 5.75841036e+01, 5.75420868e+01,\n",
       "        5.75000700e+01, 5.74580532e+01, 5.74160364e+01, 5.73740196e+01,\n",
       "        5.73300200e+01, 5.72909860e+01, 5.72497969e+01, 5.72085952e+01,\n",
       "        5.71663936e+01, 5.71321919e+01, 5.70923908e+01, 5.70551891e+01,\n",
       "        5.70179874e+01, 5.69807857e+01, 5.69415840e+01, 5.69043827e+01,\n",
       "        5.68671811e+01, 5.68299795e+01, 5.67927777e+01, 5.67555760e+01,\n",
       "        5.67183743e+01, 5.66811726e+01, 6.44609833e+01, 2.13815957e-01,\n",
       "        1.67232350e-01, 1.92497358e-01, 1.30032137e-01, 4.66377378e-01,\n",
       "        6.27657661e+01, 0.00000000e+00, 1.00476265e-01, 1.11946177e+00,\n",
       "        1.01369178e+00, 0.00000000e+00, 0.00000000e+00, 8.32571834e-03,\n",
       "        4.84586537e-01, 7.11524487e-03, 0.00000000e+00, 2.13533163e-01,\n",
       "        1.33132815e+00, 4.05764341e-01, 3.05208623e-01, 1.37562305e-01,\n",
       "        4.29300815e-02, 6.48720086e-01, 5.36103845e-01, 1.07817821e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51.99960317, 51.98373016, 51.96785714, 51.95198413, 51.93611111,\n",
       "       51.9202381 , 51.90436508, 51.88849206, 51.87261905, 51.85674603,\n",
       "       51.84087302, 51.825     , 51.80912698, 51.79325397, 51.77738095,\n",
       "       51.76150794, 51.74563492, 51.7297619 , 51.71388889, 51.69830766,\n",
       "       51.68476891, 51.67123016, 51.65769141, 51.64415266, 51.63061391,\n",
       "       51.61707516, 51.60353641, 51.58999767, 51.57645892, 51.56292017,\n",
       "       51.54938142, 51.53584267, 51.52230392, 51.50876517, 51.49522642,\n",
       "       51.48168768, 51.46814893, 51.45461018, 51.44107143, 51.42753268,\n",
       "       51.41399393, 51.40045518, 51.38691643, 51.37337768, 51.35983894,\n",
       "       51.34630019, 51.33276144, 51.31922269, 51.30568394, 51.29214519,\n",
       "       51.27860644, 51.26506769, 51.25152894, 51.2379902 , 51.22445145,\n",
       "       51.2109127 , 51.19737395, 51.1838352 , 51.17029645, 51.1567577 ,\n",
       "       51.14321895, 51.12968021, 51.11614146, 51.10260271, 51.08906396,\n",
       "       51.07552521, 51.06198646, 51.04844771, 51.03490896, 51.02137021,\n",
       "       51.00783147, 50.99429272, 50.98075397, 50.96721522, 50.95367647,\n",
       "       50.94013772, 50.92659897, 50.91306022, 50.89952148, 50.88598273,\n",
       "       50.87244398, 50.85890523, 50.84536648, 50.83182773, 50.81828898,\n",
       "       50.80475023, 50.79121148, 50.77767274, 50.76413399, 50.75059524,\n",
       "       50.73705649, 50.72351774, 50.70997899, 50.69644024, 50.68290149,\n",
       "       50.66936275, 50.655824  , 50.64228525, 50.6287465 , 50.61520775])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.62612513303302\n",
      "19.7086844997184\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
