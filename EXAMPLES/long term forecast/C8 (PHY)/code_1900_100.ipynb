{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGKeZ2gyuoQ"
   },
   "source": [
    "_Importing Required Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-6LN-zXiLcM",
    "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "By_d9uXpaFvZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from hampel import hampel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOjBMFayuoR"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5QqIY_GyuoR"
   },
   "source": [
    "The `capa_intermittency.dat` feeds the model with the dynamics of the Capacitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9dV4a8yfyuoR"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('capa_intermittency.dat')\n",
    "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
    "training_set = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7easoxByuoR"
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnyolJTyuoR"
   },
   "source": [
    "_Calculating the value of_ $\\frac{dx}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmIbVfIvyuoR",
    "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1        0.000298\n",
      "2        0.000298\n",
      "3        0.000297\n",
      "4        0.000297\n",
      "5        0.000297\n",
      "           ...   \n",
      "9996     0.000018\n",
      "9997     0.000018\n",
      "9998     0.000018\n",
      "9999     0.000018\n",
      "10000    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "t_diff = 1\n",
    "print(training_set.max())\n",
    "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2eVeeoxyuoS"
   },
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0J-NKyIEyuoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "1995    59.309069\n",
       "1996    59.303933\n",
       "1997    59.298798\n",
       "1998    59.293662\n",
       "1999    59.288527\n",
       "Name: C8, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"c8_interpolated_1900_100.csv\")\n",
    "training_set = data.iloc[:, 1]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CbNUhJ74UqF",
    "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       88.200000\n",
       "1       87.987115\n",
       "2       87.774230\n",
       "3       87.561345\n",
       "4       87.348459\n",
       "          ...    \n",
       "1895     0.000000\n",
       "1896     0.203692\n",
       "1897     0.000000\n",
       "1898     0.000000\n",
       "1899     0.000000\n",
       "Name: C8, Length: 1900, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = training_set.tail(100)\n",
    "test\n",
    "training_set = training_set.head(1900)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0TwTcq0yuoS",
    "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000298\n",
      "1       0.000298\n",
      "2       0.000297\n",
      "3       0.000297\n",
      "4       0.000297\n",
      "          ...   \n",
      "9995    0.000018\n",
      "9996    0.000018\n",
      "9997    0.000018\n",
      "9998    0.000018\n",
      "9999    0.000018\n",
      "Name: 0, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training_set = training_set.reset_index(drop=True)\n",
    "gradient_t = gradient_t.reset_index(drop=True)\n",
    "print(gradient_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O2biznZQyuoS"
   },
   "outputs": [],
   "source": [
    "df = pd.concat((training_set, gradient_t), axis=1)\n",
    "df.columns = ['y_t', 'grad_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "sk_a5v3tyuoS",
    "outputId": "17563625-e550-45ae-faab-fafa353e44da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_t</th>\n",
       "      <th>grad_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.200000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.987115</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.774230</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87.561345</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.348459</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_t    grad_t\n",
       "0     88.200000  0.000298\n",
       "1     87.987115  0.000298\n",
       "2     87.774230  0.000297\n",
       "3     87.561345  0.000297\n",
       "4     87.348459  0.000297\n",
       "...         ...       ...\n",
       "9995        NaN  0.000018\n",
       "9996        NaN  0.000018\n",
       "9997        NaN  0.000018\n",
       "9998        NaN  0.000018\n",
       "9999        NaN  0.000018\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5esyHu5aFvg"
   },
   "source": [
    "## Plot of the External Forcing from Chaotic Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hGnE43tOh-4p",
    "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAiH0lEQVR4nO3deXxcZ33v8c9PmyVZ+2JbluxI3pKYxI4T4+wOECCBpFnYCqXEhIRwabkXaHtpWu6LG+4tBdoLZS0UQiCUXLYQSCBJwc2+2tjxlsRx5DWWbNmyZS3WYm1P/5ij8cgZ2zNzZjmj+b7zUmbmaM7MoyPrO8/85nmeY845REQk++RlugEiIpIYBbiISJZSgIuIZCkFuIhIllKAi4hkqYJ0PlldXZ1rbm5O51OKiGS99evXH3LO1Z+4Pa0B3tzczLp169L5lCIiWc/M9kTbrhKKiEiWUoCLiGQpBbiISJZSgIuIZCkFuIhIllKAi4hkKQW4iEiWyooA/93mfdyzJuowSBGRnJUVAf7wlg6++odXGRkbz3RTREQCIysC/IZljRzuH+ap1s5MN0VEJDCyIsCvWFRPdWkh973QnummiIgERlYEeFFBHtcumc3qlw/QNzSS6eaIiARCVgQ4wI3nN3JsdJx/Wd2KzuMpIpJFAb5sThUfuugM7npmF//40FaFuIjkvLQuJ+uHmfF/rn8DeQbff2oXY+Pwv645m7w8y3TTREQyImsCHEIhfsd1byAvz7jrmV2s2XWYz1x9FisX1mGmIBeR3JI1JZQJZsbnrl3M1/70PHoGR1h111o+eOcaNu3tznTTRETSKusCHEIhfsOyRh756yv433+ymG0dfVz/7Wf4i3vWs/1gX6abJyKSFpbODwOXL1/uUnFKtaPHRvn+kzu586md9A+P0VRdwoUttVw4r4aLWmqZU1OiEouIZC0zW++cW/667VMhwCccOnqMBzbuY+2uLtbu7qKrfxiAWRXFvOeCJj7xlgUUF+an7PlFRFIhJwI80vi4Y3vnUdbs6uLJVztZ/fIB5tVP55/evYTlzTVpaYOISDLkXICf6MlXO/m7+7awr2eQVRc38z+vOpPp07JqEI6I5KiTBXhWfoiZiJWL6vnDp1dy00Vn8KNnd3PV157k6dZDmW6WiEjCYuqBm9mngVsBB2wBbgYagJ8BtcB64EPOueFTPU4me+CR/ri7i7+9dzM7D/VzdkMFly2o5ZIFdaxorlGvXEQCJ+ESipk1Ak8Di51zg2b2C+Ah4J3Afc65n5nZd4FNzrnvnOqxghLgAEMjY9z97G4e23aQF/Z0Mzw2TkGesWxuFZcuqOPSBXWcN6eKwvyceZMiIgHlN8CfB5YCvcBvgG8C9wCznHOjZnYxcIdz7qpTPVaQAjzS4PAY6/Z08cz2wzy74xBb2ntwDkqL8lnRUsOl8+u4ZEEtZ8+q0NR9EUm7kwX4aesFzrl2M/t/wGvAIPAHQiWTbufcqHe3NqAxie1Nq5KifC5fWM/lC+sB6BkY4bmdh3lm+yGe2XGIx7dtBaBmehEXz6/l0vl1XLagjrm1pZlstojkuNMGuJlVA9cDLUA38Evg6lifwMxuA24DmDt3bkKNTLfK0kKuPmcWV58zC4COnqFwmD+7/TAPbt4PQHNtKSsX1XPFonoumler+rmIpFUsJZT3Alc7527xbt8EXAy8lylSQomHc46dh/p5uvUQT77ayXM7DzMwPEZhvvHG5hquWFTPykX1nDWrXLM/RSQp/NTALwTuAt5IqITyI2AdsBL4VcSHmJudc/96qseaCgF+omOjY6zffYQnXu3kiVc7eaUjtBbLzIpprFwYCvPLF9ZRVVqU4ZaKSLbyNZHHzD4P/CkwCmwgNKSwkdAwwhpv2587546d6nGmYoCfqKNniCdbQ2H+dOshegZHyDNY0lQV7p0vmllGeXFhppsqIlki52diZsLYuGNTWzdPbOvkydZONu7tZuJwl00roKGymFmVxd5lCbPDt0uYVVlMRXGByjAiogAPgiP9wzy/8zCvdQ2wv2eIjp4h9vcOsb97kM6jxzjxV1FalE9DRKBPBP6c6lIunl+rMeoiOSLhYYSSPNXTi3jHuQ1RvzcyNs7BvmN09Ayyv2eI/d1DoZDvDd1+ZvshDvQOMe6FfFN1CX/xpgW8+4JGphVohUWRXKQeeBYZHRun8+gxNrf18J3Hd7BxbzcNlcV8/E3zed/yOVoqV2SKUgllinHO8VTrIb7xSCvr9hxhRvk0PnbFfP5sxVxKihTkIlOJAnyKcs7x3M7DfOORVp7f2UVdWREfvXwef37RGZpYJDJFKMBzwNpdXXzz0Vaeaj1EdWkht14+j5suPkNDFkWynAI8h7zw2hG++Ugrj23rpKK4gI9c1sLNl7RQWaogF8lGCvActKWth2882srqlw9QPq2AVZc0c8tlLVRP16xQkWyiAM9hL+/r5VuPtfLwix2UFObzoYvP4KOXz6OubFqmmyYiMVCAC68e6ONbj27nt5v3UZSfR0vddCpLCqkqLaSqpIiq6d5laSFVJYVUlhZSXVoU/n5xYZ5mhopkgAJcwnZ0HuXfn9tDe/cgPQMjdA8O0z0wQvfACMNj4yfdr6ggj6qJwC8toqqkkNlVJaxoqeGNzTXUl6tHL5IKCnA5LeccQyPjHBnwAn1w2Av4kfDt7v7jgd8zOMKewwMMjowBMK9+Ohe21LCipYYVLbU0VpVk+CeSbDWRS9n4ji8VbddUejktM6OkKJ+SohJmxxi+I2PjvNjew9pdXazd1cXvNu/np2v3AtBYVRIR6DW01E3Pyj9ISb9//v02/vXxHbR+4R0JrfkzPu44OjxKRQaG0N7xwEvc/dwedn/pmpQ/lwJcfCnMz2PZ3GqWza3mY1fMZ2zcsa2jj7W7DrN2dxdPtnZy34Z2AOrLp7GipSYc6otmlOscoxLVD5/ZDcDw6HhCAf7Fh7fy/ad28eLnr6IsgQlto2Pj7O8ZYk5N/KdNvPu5PXHvkygFuCRVfp6xeHYFi2dX8OFLW8JnMJrooa/ZefyUdJUlhbyxuYYLzqhmbk0pDVWhFRfry6ZRoJUWc9qYV4bIT/AF/jcb9wEwcGw0oQD/hwe38qNnd7P2s1cyo7w4oTakgwJcUsrMmF9fxvz6Mj6wInRO1L1dA+FAX7u7i//cemDSPnkGM8qLw4E+q6IktKxu1fG102eUT9NyulOY38/m/Nahn2rtBKB3cJQZ5b6aklIKcEm7OTWlzKkp5d0XNAHQMzDCvp7B0ProPUPs95bU7egZYltHH49v62RgeGzSY+RZqCQzq7KEhorQOunzZ5SxtKmSM2eVa4ndLDfuc2zF2Li/HvzE8we9wqcAl4yrLA2NOT+7oSLq951z9A6N0tEzNCnoJ9ZO3955lKdaO+n3Qr4oP4+zGspZ0lTJkqYqljRVsnBGecJ/zJJ+4z574H4D2O8LQLoowCXwzIzKkkIqSwo5c1b097POOdqODLK5rYfN7d1s3tvD/Rv28ZPnXwOgpDCfcxorwoG+pKmK5tpSjYoJKL+jm8d9llAm9s8L+L8PBbhMCWYWLs1csyR01qPxcceuw/1sbutm094eNrd185Pn93BsNDRZqaK4gCVNVZzbVMlSL9QbKosV6lPAxAtAor9Kv/sDNN/+IBs/9zaqSlO39pACXKasvLzjH6DeuCxUbx8ZG6f1wNFQqLf1sKW9m+8/uZNR7y1zXdk0r4deyVKvt16rNWOyzpjPInqyeuA7Ovu54AwFuEhSFObnhYc5vn9FaNvQyBhb9/eGyi9toZ76Y9sOhnthjVUlk+rp5zZVZmSCiMRuIoATLcWoBi6SJYoL88OTkSYcPTbKS+2hQN/U1s3mth4efrEj/P15ddO9MK9iaVMlb5hdqVPZBYj/GnroMtjxrQAXiapsWgEXzqvlwnm14W3dA8PhHvqmth6e39kVnjCSn2csnFEW7qkvbapi/ozplBbpT2x4dJzfbGznopZa5tbGP7MxEX5HsYTHoceQ4Ad6hzh6bJT59WW+njMR+tclEqOq0iJWLqpn5aL68LaDvUNs8kJ9c1sPq18+wC/WtYW/X11aSGN1CY1VJTRWlXrXi8PXq0sLp/yHps/sOMRn7t0MwIUtNdy4rJF3nNtAZcnpy1AJl0B8D0OMff8vPLiV1S8f4Ce3XsgFZ1SffockUoCL+DCjopi3LS7mbYtnApOHM+4+3M++7kHauwfZ2dnPU62HXjchqaQwPxzws6tKaJoIe+9yZkVx4OuwpzPk/cwfWDGHNTu7uP2+LXzugZd469kzuOG8Rt505gyKCk4+q3Z0bJzfbNzHsrlVMfdyw/mbYI6Px7F/39AIgyNj3PzDtfz8Yxcn9oQJUoCLJFHkcMYTOefoHhihvXuQtiOD4XBvPxK63NLeQ1f/8KR98vOMWRXFNFaX0BQR7I3VocBvrCqhuDDYtfeJNeZvvXwe/3jjuWxu6+HXG9r57aZ9PLSlg6rSQq5d0sCNyxo5f271696R/HH3Ef7ml5sAOKexghvOa+TaJbOZVZm6NUrG4xjFMjLmOKO2lGMj49x019qUtSkaBbhImpgZ1dOLqJ5exDmNlVHvMzA8yr7uoYhgHwgH/JpdXezfOPi6aeZ1ZUXHQ73yeMjXlk2jZnoRNaVFlBcXZGzlx2Fv3H1RfuiMTkvnVLF0ThWfveZsnm49xK83tHPv+jZ+8vxrzK0p5YZljZP2Hx0P7f+BFXN4aV8v//DgVr7w0FYunlfLdUtns3JR/SmXPx4eHeffntjBwpllXLqgjvIYRhDFU0IZHhunobKY/3v9Obzv356Leb9kUICLBEhpUQELZpSxYEb0UsHo2DgdvUPhUG8/Msi+nlCP/pWOPh7ZejA8USlSfp5R7Z0ir2Z66KvaC/eq0sLwTNeq0qLwafYqSwqT0rsfGQuF4YllksL8PN581gzefNYM+oZG+P1LB/jNhna++Whr+D4uoobx7vOb+OK7atjZeZT7N+7j/o3t3H7fFiA01PONzaGRROfPnVyH3tTWzVdWvwqEptYvmlkeGnU0pypcljnxxe3EGvruQ/1UTy+KWrcfHh2noqSQhTPL+dHNK7j+28/Ee4gSpgAXySIF+Xk0VZfSVB19NIdzjsP9w+zvHuJw/zGODAzT1T/Ckf5hDvcPc6R/mK6BYbYfPMqRgWGODIycctLLtIK8SYFeWVJIeXEhFcUFlBcXUl5cQEWJdxnl9rSCPEa8EsqpVo8sLy7kPRc08Z4LmjjQO8Squ9bySkef9zNNvu+8+jI+/bZFfOqtC9m6v481uw6zdlcXz+44HB4VFD4euHA55DNXn8nQyDgb93bz4OZ9/HTta95zF7CkqZKzZlVw5qxyzpxZztDIuLc/7Ow8ylu+8gQAc2tKecPs0P3OmlXOWbMqODY6TlF+6AVg6ZwqrlnSEF4yOdUU4CJTiJlRVzaNuhhnj46PO/qOjdIbcdq8Hu96z6D3FXHe1PbuIfqG+ugbGqVvaOS0qwYW5eeFa+AF+bGVcGZWFHPjska++PArp/1ZJyZl3eytPb+vZ4gNrx3hf/x0w+vadl5TFZcsqAv/3DsP9bPhtSNs3BsaQXTPmj3h4I7UMzgCwHVLZzMyNs7W/b38x0sdk15YZkfU4xee5N1TKijARXJYXt7xhcLm1MS3r3OO/uEx+oZG6B0MBXrf0Ci9QyP0DkXcHhwJ9dwTOLFCpNONtjQzb7hmCZ19x/j8b18OtTPKffPyLFyqeu/yOUBo9uXergFe6ejjjgdeoqN3aNI+N57fyJvPnAGEPqtoPXCUbR19vHqgjzefNcPXz5YoBbiIJMTMKJtWQNm0AhqifybrWxrPuU5+ntFcN53muul09Q/z97/ectL7lhYVhD+MzSSd0kREAieyt+0nwye9ACQwCMe5+J/f0jgBXwEuIlOO3wiNVq4J4nQqBbiIZInEIjSdZZh0iynAzazKzO41s1fMbKuZXWxmNWa22sxavcv0LgIgIlNeELI3yC8AsfbAvw78h3PuLGApsBW4HXjEObcQeMS7LSLiW2Qd2c8Z6ieXwOPvwbsEXkLSuTbZaQPczCqBlcAPAJxzw865buB64G7vbncDN6SmiSIi8YlcTyWhED7NYwZFLD3wFqAT+KGZbTCzO81sOjDTOTcx3agDmBltZzO7zczWmdm6zs7O5LRaRHJOAPMz42IJ8ALgfOA7zrllQD8nlEtc6D1O1Jc559z3nHPLnXPL6+vro91FRCQq5xLpP0/ef0LiLwDxtSCdrzOxBHgb0OacW+PdvpdQoB8wswYA7/JgapooIrnGb287Wb31yPJ7EN8AnDbAnXMdwF4zO9PbdCXwMvAAsMrbtgq4PyUtFBHBR4Am0IXPlnJNrFPp/ztwj5kVATuBmwmF/y/M7BZgD/C+1DRRRCRzgjyMMKYAd85tBJZH+daVSW2NiEgEF/6fj/096epUB2oYoYhItonMUF8fgkY+ZgDLKgpwEckK6RyHnc4FqfxQgItIoPkbSHhcoi8AAS6BK8BFJLj8foDof/+IceQx9srT+U5BAS4igRMtBOOKxcip9ImEeHZUUBTgIiKnEuRhhApwEQkul7wADeIoEr8U4CISOMnKWuf9l/D+kVPpA/gCoAAXkawQT4D6PqWaz/3TRQEuIjkh0VD2c0KJVFOAi0hgOVxgPkQMYq9cAS4igRP9rPAJRGgSPwSNldZCERHxwf964pGnZAsuBbiIBFqyAjSIo0j8UoCLSGAlo/yRtB50AF8AFOAiEjjRzwof/+P4De9EXkDSuZKhAlxEppzoIRp7sE5aTzzARXAFuIgEWlDGYQdxjXAFuIgEVjKiOygvAKmgABeRwEnWmtq+1wNPYC0VjQMXEfEktJx3tIlA8aylErxqSVQKcBGRGAQx1BXgIhJYk05plmCATt0KuAJcRAIoWb3dyPp1Ig/pHHG/AqSzo64AF5FAS2wyjT/RF9MKHgW4iExtU7iGogAXkcCKzN5MTKRJoIKSVgpwEQmcpJ0Tc9I5LeOZSp94CzQOXEQkLP4+cCpCNFmTi5JJAS4iWSHxYYT+iiBBnomvABeRwEpmeCY2jDCB3r+WkxWRnBZ5SjMfIZ7orn6n4qeLAlxEppzIXnCQSyB+KcBFJCtkqgfst4aeSgpwEQmsZIZnuk7JpmGEIpLTJp3SzMfjJPNkDgEsgcce4GaWb2YbzOx33u0WM1tjZtvN7OdmVpS6ZopIrotrdEfEXX2f1CG4FZS4euCfBLZG3P4y8C/OuQXAEeCWZDZMRCSZgnhOS79iCnAzawKuAe70bhvwFuBe7y53AzekoH0iksucz2GESex9Z/Mwwq8BnwHGvdu1QLdzbtS73QY0RtvRzG4zs3Vmtq6zs9NPW0UkR/gNS7819CBOm4/mtAFuZtcCB51z6xN5Aufc95xzy51zy+vr6xN5CBGRDA4jDK6CGO5zKXCdmb0TKAYqgK8DVWZW4PXCm4D21DVTRMSfLOlUx+W0PXDn3N8555qcc83A+4FHnXMfBB4D3uPdbRVwf8paKSI5KbQedyb7wJNXJI9FOssvfsaB/y3wV2a2nVBN/AfJaZKI5Dq/I0Zs0loqiSxIdVwyx5InWywllDDn3OPA4971ncCK5DdJROT1pmAFxDfNxBQRiUEQa+gKcBEJLJeEceD+puLHv086c14BLiKB43c9br8hGvlcwa2AK8BFJEckc3JQUCjARSTQgjKIMIgU4CISWL5PSIxLsI6deA1F64GLSE6LnoGxJ2PUGnogiyD+KMBFRGIQxAWuFOAiEmj+Z0Imvn+AJ2ECCnARCTC/63EnGsCThxHG9yAaBy4iOc33kD+f48ijPqa/3VNCAS4ikqUU4CIypfmaip/gMMR0UYCLSGDFvxr3KfZP01T8bFkPXEQkJXyvB56CinUARxEqwEUk2HyfWT45zQgkBbiIZIVMTKTxu5xtqinARSSw/E7iidw/nrKKn6n4WgtFRHJbCsaBT0UKcBEJNN8rEk7hGroCXEQCa9JUep+Pla6p+JpKLyI5LVkhmHjv+fUtCGJZRgEuIoHmvwQS5CKIPwpwEZGTCE2lD+4LgAJcRLJC1qwmqKn0IpLLkjVpJxnrgQeZAlxEAi2hkSARCaxhhCIiGeZ7gas0ntEnXRTgIhJYmQrQaFkf6wuAxoGLSE6LDEGf8zD9NSTgFOAiMuUk7wUg2GUUBbiIZAX/I0OCd5IIvxTgIhJYmZpF6WcYo5aTFZGcFhmCfmZChk7I4LuI4nP/1FGAi8iUE/WEDMGrgPimABcROYlJy9kG8AXgtAFuZnPM7DEze9nMXjKzT3rba8xstZm1epfVqW+uiOSSTM2i9JPV6fywM5Ye+Cjw1865xcBFwF+a2WLgduAR59xC4BHvtoiIb5Nq4Insn8QQzephhM65/c65F7zrfcBWoBG4Hrjbu9vdwA0paqOISMZXI0zs+VOb/nHVwM2sGVgGrAFmOuf2e9/qAGaeZJ/bzGydma3r7Oz001YRkbQK+skgYg5wMysDfgV8yjnXG/k9FxqnE/Undc59zzm33Dm3vL6+3ldjRSS3uPD/EtzfJbqa4QltSHDfVIspwM2skFB43+Ocu8/bfMDMGrzvNwAHU9NEEck1qVh5MFlrjAdJLKNQDPgBsNU599WIbz0ArPKurwLuT37zRERCMh3AibyopPoD0IIY7nMp8CFgi5lt9Lb9PfAl4BdmdguwB3hfSlooIpIhQR6BAjEEuHPuaU7+Ae6VyW2OiMhxzjlfHyQ6Ett/8lT+OPeN+9kSp5mYIhI4UWvY8ewf47Z4BLGErgAXETmJoC+DpQAXkUDzPZ0+kWGEEf31II8FV4CLSGAl82w66SqBBG4cuIhIpsUTjKkI0QCWwBXgIiIn4/dkEKkehqgAF5FAy8hJiX0MI0wnBbiIBNakGrbPmZCpmJ4f9X4BWw9cRCSt/E+bD0bF2v/5OE9NAS4iU5qfCD3pMqsBoQAXkUDLRA3aV/9dwwhFRCCy/5tIVcX53H+yYJRlIinARSRwpsq6JZpKLyI5ze9Udj8fJIbO6BPcKrgCXESyQjo71dFGwcQ+jDB9FOAiEliZWMgqmyjARSRw/NawI3fPZIZrKr2I5LTM9qKD3YVXgItIdvDbK49nNUMfT5/Oky8rwEUksILd/808BbiIBM7kM+IksP+ksxL7a4ufEk6qz+ajABeRnJBIaWPyGX0CMjsoggJcRLJCOpdp9ZPVGgcuIkJyxoH7nsnpZ38NIxSRXDOpB5xAiierFxz0D1EV4CKSFZI5uef0940yld7f06eEAlxEJInS+VmnAlxEAisZ9etMrqei5WRFJOf4XcskWi84oRNCTBpGmEBDUkwBLiJZIb3LyabxyXxQgIvIlOa3jBFvCUU1cBERJs6I42//ZElkIpGWkxWRnBO9hh17gEbdP6EADvZIcAW4iMgJsqQErgAXkeBKRgfY9zDCOO+fzjVbFOAiEkARy8n6Oat85COm8YQQE4ZGxvj4T9az+1C/vyc/iQI/O5vZ1cDXgXzgTufcl5LSKhERoL17MHw9kanwN3z7mYSeNy8vtP/YuL/u+zcebWVzWw8Dw2Pc/ZEVvh4rmoQD3MzygW8DbwPagD+a2QPOuZeT1TgRyU1tRwYA+OiP1yW0v98ZnOXFoWj8szvXxL1vUcHxwsbmth4AugeGfbXnZPyUUFYA251zO51zw8DPgOuT0ywRyWWHjvoLvMHh8ddtmwjlWEwvev19GyqLY9p3VpT7bWrr4bXDAzE/f6z8BHgjsDfidpu3bRIzu83M1pnZus7OTh9PJyK54uNXzJ90+8OXNFNVWhjz/pfMr+XKs2aEb1+zpIHSKKF8MnNrSnnr2TPDt7/0rnMpyI8tLs9rquLWy1ombWuoLJ7UM08WS/QDAjN7D3C1c+5W7/aHgAudc5842T7Lly9369Yl9pZIRCRXmdl659zyE7f7eUloB+ZE3G7ytomISBr4CfA/AgvNrMXMioD3Aw8kp1kiInI6CY9Ccc6NmtkngN8TGkZ4l3PupaS1TERETsnXOHDn3EPAQ0lqi4iIxEEzMUVEspQCXEQkSynARUSylAJcRCRLJTyRJ6EnM+sE9iS4ex1wKInNSTa1zx+1zx+1z78gt/EM51z9iRvTGuB+mNm6aDORgkLt80ft80ft8y8b2ngilVBERLKUAlxEJEtlU4B/L9MNOA21zx+1zx+1z79saOMkWVMDFxGRybKpBy4iIhEU4CIiWSorAtzMrjazbWa23cxuz8DzzzGzx8zsZTN7ycw+6W2/w8zazWyj9/XOiH3+zmvvNjO7Kk3t3G1mW7y2rPO21ZjZajNr9S6rve1mZt/w2rjZzM5PcdvOjDhOG82s18w+lcljaGZ3mdlBM3sxYlvcx8vMVnn3bzWzVSlu3z+b2SteG35tZlXe9mYzG4w4jt+N2OcC79/Fdu9n8Hl+9lO2L+7fZ6r+vk/Svp9HtG23mW30tqf9+CWFcy7QX4SWqt0BzAOKgE3A4jS3oQE437teDrwKLAbuAP4myv0Xe+2cBrR47c9PQzt3A3UnbPsn4Hbv+u3Al73r7wQeJnSy74uANWn+nXYAZ2TyGAIrgfOBFxM9XkANsNO7rPauV6ewfW8HCrzrX45oX3Pk/U54nLVem837Gd6RwvbF9ftM5d93tPad8P2vAJ/L1PFLxlc29MAzfvJk59x+59wL3vU+YCtRzv8Z4XrgZ865Y865XcB2Qj9HJlwP3O1dvxu4IWL7j13I80CVmTWkqU1XAjucc6ealZvyY+icexLoivK88Ryvq4DVzrku59wRYDVwdara55z7g3Nu1Lv5PKEzYZ2U18YK59zzLpRGP474mZLevlM42e8zZX/fp2qf14t+H/DTUz1GKo9fMmRDgMd08uR0MbNmYBmwxtv0Ce/t7F0Tb7fJXJsd8AczW29mt3nbZjrn9nvXO4CJM7Vm8ri+n8l/OEE6hvEer0wex48Q6hFOaDGzDWb2hJld7m1r9NqUzvbF8/vM1PG7HDjgnGuN2BaU4xezbAjwwDCzMuBXwKecc73Ad4D5wHnAfkJvyTLpMufc+cA7gL80s5WR3/R6EBkdN2qh0+9dB/zS2xS0YxgWhON1Mmb2WWAUuMfbtB+Y65xbBvwV8P/NrCIDTQvs7/MEH2ByJyIoxy8u2RDggTh5spkVEgrve5xz9wE45w4458acc+PA9zn+Fj8jbXbOtXuXB4Ffe+05MFEa8S4PZrKNhF5cXnDOHfDaGqhjSPzHK+3tNLMPA9cCH/ReZPBKE4e96+sJ1ZUXeW2JLLOktH0J/D4zcfwKgHcBP49odyCOX7yyIcAzfvJkr172A2Crc+6rEdsja8Y3AhOfdj8AvN/MpplZC7CQ0AchqWzjdDMrn7hO6MOuF722TIyMWAXcH9HGm7zRFRcBPRGlg1Sa1PMJ0jGMeN54jtfvgbebWbVXLni7ty0lzOxq4DPAdc65gYjt9WaW712fR+h47fTa2GtmF3n/jm+K+JlS0b54f5+Z+Pt+K/CKcy5cGgnK8Ytbpj9FjeWL0AiAVwm9Kn42A89/GaG30puBjd7XO4F/B7Z42x8AGiL2+azX3m2k4VNrQp/ib/K+Xpo4TkAt8AjQCvwnUONtN+DbXhu3AMvT0MbpwGGgMmJbxo4hoReS/cAIodrmLYkcL0K16O3e180pbt92QjXjiX+H3/Xu+27v974ReAH4k4jHWU4oSHcA38KbgZ2i9sX9+0zV33e09nnbfwT8txPum/bjl4wvTaUXEclS2VBCERGRKBTgIiJZSgEuIpKlFOAiIllKAS4ikqUU4CIiWUoBLiKSpf4LQuu9hujp7aQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "ym4xWUUxaFvg",
    "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c0 = 85.7336  # Value for C0\n",
    "K0 = -0.0020  # Value for K0\n",
    "K1 = 0.0002  # Value for K1\n",
    "a = 0.0000    # Value for a\n",
    "b = 0.0125    # Value for b\n",
    "c = 2.3008    # Value for c\n",
    "\n",
    "L = np.minimum(c0, (df.iloc[:, 1] - (df.iloc[:, 0] * (K0 - K1 * (9 * a * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c)**2 + 4 * b * np.log(df.iloc[:, 0] / c0) / (K0 - K1 * c) + c)))))\n",
    "L.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VyEywnwaFvh"
   },
   "source": [
    "## Preprocessing the data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6V9dXqzdaFvh"
   },
   "outputs": [],
   "source": [
    "# split a sequence into samples\n",
    "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n_in, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n_out)\n",
    "    for i in range(0, n_out):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "      else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "       agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrzSrT1HnyfH",
    "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-350)  var1(t-349)  var1(t-348)  var1(t-347)  var1(t-346)  \\\n",
      "350    88.200000    87.987115    87.774230    87.561345    87.348459   \n",
      "351    87.987115    87.774230    87.561345    87.348459    87.135574   \n",
      "352    87.774230    87.561345    87.348459    87.135574    86.922689   \n",
      "353    87.561345    87.348459    87.135574    86.922689    86.709804   \n",
      "354    87.348459    87.135574    86.922689    86.709804    86.496919   \n",
      "\n",
      "     var1(t-345)  var1(t-344)  var1(t-343)  var1(t-342)  var1(t-341)  ...  \\\n",
      "350    87.135574    86.922689    86.709804    86.496919    86.294538  ...   \n",
      "351    86.922689    86.709804    86.496919    86.294538    86.221709  ...   \n",
      "352    86.709804    86.496919    86.294538    86.221709    86.148880  ...   \n",
      "353    86.496919    86.294538    86.221709    86.148880    86.076050  ...   \n",
      "354    86.294538    86.221709    86.148880    86.076050    86.003221  ...   \n",
      "\n",
      "     var1(t+95)  var2(t+95)  var1(t+96)  var2(t+96)  var1(t+97)  var2(t+97)  \\\n",
      "350   76.094351    0.000263   76.058870    0.000263   76.023389    0.000263   \n",
      "351   76.058870    0.000263   76.023389    0.000263   75.987909    0.000262   \n",
      "352   76.023389    0.000263   75.987909    0.000262   75.952428    0.000262   \n",
      "353   75.987909    0.000262   75.952428    0.000262   75.916947    0.000262   \n",
      "354   75.952428    0.000262   75.916947    0.000262   75.881466    0.000262   \n",
      "\n",
      "     var1(t+98)  var2(t+98)  var1(t+99)  var2(t+99)  \n",
      "350   75.987909    0.000262   75.952428    0.000262  \n",
      "351   75.952428    0.000262   75.916947    0.000262  \n",
      "352   75.916947    0.000262   75.881466    0.000262  \n",
      "353   75.881466    0.000262   75.845985    0.000262  \n",
      "354   75.845985    0.000262   75.810504    0.000262  \n",
      "\n",
      "[5 rows x 551 columns]\n",
      "Index(['var1(t-350)', 'var1(t-349)', 'var1(t-348)', 'var1(t-347)',\n",
      "       'var1(t-346)', 'var1(t-345)', 'var1(t-344)', 'var1(t-343)',\n",
      "       'var1(t-342)', 'var1(t-341)',\n",
      "       ...\n",
      "       'var1(t+95)', 'var2(t+95)', 'var1(t+96)', 'var2(t+96)', 'var1(t+97)',\n",
      "       'var2(t+97)', 'var1(t+98)', 'var2(t+98)', 'var1(t+99)', 'var2(t+99)'],\n",
      "      dtype='object', length=551)\n"
     ]
    }
   ],
   "source": [
    "data = Supervised(df.values, n_in = 350, n_out = 100)\n",
    "\n",
    "\n",
    "cols_to_drop = []\n",
    "for i in range(2, 351):\n",
    "    cols_to_drop.extend([f'var2(t-{i})'])\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AfPf60oy6Pe4"
   },
   "outputs": [],
   "source": [
    "train = np.array(data[0:len(data)-1])\n",
    "forecast = np.array(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WSAafzI37KiT"
   },
   "outputs": [],
   "source": [
    "trainy = train[:,-300:]\n",
    "trainX = train[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2SrOqVJA7f50"
   },
   "outputs": [],
   "source": [
    "forecasty = forecast[:,-300:]\n",
    "forecastX = forecast[:,:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qno_k8Nw7saY",
    "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1450, 1, 251) (1450, 300) (1, 1, 251)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
    "print(trainX.shape, trainy.shape, forecastX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Jp2DvNuNFx",
    "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 3s 27ms/step - loss: 4898.6084 - val_loss: 3577.7429\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 4825.3564 - val_loss: 3528.4194\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4769.2749 - val_loss: 3480.0632\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4704.4478 - val_loss: 3426.8406\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4640.5225 - val_loss: 3381.8621\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4582.8721 - val_loss: 3337.7908\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4526.9160 - val_loss: 3294.9578\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4472.3335 - val_loss: 3253.1028\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4418.8066 - val_loss: 3212.0195\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4366.1250 - val_loss: 3171.5894\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4314.1689 - val_loss: 3131.7395\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4262.8613 - val_loss: 3092.4238\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4212.1523 - val_loss: 3053.6082\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4162.0054 - val_loss: 3015.2690\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4112.3950 - val_loss: 2977.3877\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4063.2979 - val_loss: 2939.9500\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4014.7004 - val_loss: 2902.9431\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3966.5884 - val_loss: 2866.3577\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3918.9495 - val_loss: 2830.1848\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3871.7737 - val_loss: 2794.4167\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3825.0535 - val_loss: 2759.0471\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3778.7805 - val_loss: 2724.0698\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3732.9492 - val_loss: 2689.4792\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3687.5522 - val_loss: 2655.2703\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3642.5837 - val_loss: 2621.4385\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3598.0396 - val_loss: 2587.9788\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3553.9141 - val_loss: 2554.8882\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3510.2031 - val_loss: 2522.1609\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3466.9016 - val_loss: 2489.7930\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3424.0066 - val_loss: 2457.7747\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 3381.5134 - val_loss: 2416.9075\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3324.4971 - val_loss: 2380.5703\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3276.2673 - val_loss: 2345.0874\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3229.5432 - val_loss: 2310.8643\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3184.2161 - val_loss: 2277.5879\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3139.9397 - val_loss: 2245.0615\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3096.5107 - val_loss: 2213.1724\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3053.8083 - val_loss: 2181.8489\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3011.7559 - val_loss: 2151.0432\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2970.2988 - val_loss: 2120.7224\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2929.3999 - val_loss: 2090.8596\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2889.0286 - val_loss: 2061.4348\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2849.1616 - val_loss: 2032.4324\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2809.7800 - val_loss: 2003.8379\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2770.8682 - val_loss: 1975.6405\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2732.4124 - val_loss: 1947.8300\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2694.4014 - val_loss: 1920.3983\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2656.8254 - val_loss: 1893.3373\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2619.6743 - val_loss: 1866.6394\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2582.9414 - val_loss: 1840.3000\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2546.6187 - val_loss: 1814.3123\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2510.6995 - val_loss: 1788.6713\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2475.1775 - val_loss: 1763.3718\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2440.0476 - val_loss: 1738.4094\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2405.3044 - val_loss: 1713.7795\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2370.9424 - val_loss: 1689.4784\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2336.9568 - val_loss: 1665.5015\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2303.3440 - val_loss: 1641.8461\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2270.0989 - val_loss: 1618.5076\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2237.2183 - val_loss: 1595.4833\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 2204.6975 - val_loss: 1572.7694\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2172.5330 - val_loss: 1550.3627\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2140.7217 - val_loss: 1528.2605\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2109.2590 - val_loss: 1506.4596\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2078.1428 - val_loss: 1484.9569\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2047.3690 - val_loss: 1463.7494\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2016.9347 - val_loss: 1442.8346\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1986.8370 - val_loss: 1422.2100\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1957.0724 - val_loss: 1401.8724\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1927.6385 - val_loss: 1381.8198\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1898.5326 - val_loss: 1362.0492\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1869.7515 - val_loss: 1342.5582\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1841.2925 - val_loss: 1323.3442\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1813.1528 - val_loss: 1304.4047\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1785.3295 - val_loss: 1285.7378\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1757.8207 - val_loss: 1267.3407\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1730.6229 - val_loss: 1249.2109\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1703.7347 - val_loss: 1231.3469\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1677.1528 - val_loss: 1213.7452\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1650.8749 - val_loss: 1196.4049\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1624.8988 - val_loss: 1179.3225\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1599.2219 - val_loss: 1162.4968\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1573.8423 - val_loss: 1145.9252\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1548.7571 - val_loss: 1129.6053\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1523.9646 - val_loss: 1113.5360\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1499.4619 - val_loss: 1097.7142\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1475.2474 - val_loss: 1082.1379\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1451.3185 - val_loss: 1066.8054\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1427.6725 - val_loss: 1051.7145\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1404.3082 - val_loss: 1036.8628\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1381.2227 - val_loss: 1022.2484\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1358.4141 - val_loss: 1007.8699\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1335.8807 - val_loss: 993.7245\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1313.6198 - val_loss: 979.8109\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1291.6293 - val_loss: 966.1265\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1269.9075 - val_loss: 952.6697\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1248.4520 - val_loss: 939.4386\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1227.2612 - val_loss: 926.4313\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1206.3331 - val_loss: 913.6454\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1185.6649 - val_loss: 901.0797\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1165.2557 - val_loss: 888.7318\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1145.1031 - val_loss: 876.6002\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1125.2045 - val_loss: 864.6822\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1105.5587 - val_loss: 852.9767\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1086.1635 - val_loss: 841.4819\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1067.0172 - val_loss: 830.1956\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1048.1177 - val_loss: 819.1160\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1029.4630 - val_loss: 808.2413\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1011.0514 - val_loss: 797.5695\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 992.8809 - val_loss: 787.0991\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 974.9493 - val_loss: 776.8279\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 957.2555 - val_loss: 766.7544\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 939.7968 - val_loss: 756.8766\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 922.5721 - val_loss: 747.1929\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 905.5789 - val_loss: 737.7012\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 888.8160 - val_loss: 728.4003\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 872.2810 - val_loss: 719.2878\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 855.9725 - val_loss: 710.3618\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 839.8884 - val_loss: 701.6213\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 824.0269 - val_loss: 693.0638\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 808.3862 - val_loss: 684.6878\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 792.9647 - val_loss: 676.4915\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 777.7607 - val_loss: 668.4736\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 762.7721 - val_loss: 660.6312\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 747.9973 - val_loss: 652.9640\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 733.4344 - val_loss: 645.4692\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 719.0818 - val_loss: 638.1453\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 704.9378 - val_loss: 630.9908\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 691.0007 - val_loss: 624.0039\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 677.2681 - val_loss: 617.1825\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 663.7391 - val_loss: 610.5253\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 650.4115 - val_loss: 604.0305\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 637.2836 - val_loss: 597.6964\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 624.3540 - val_loss: 591.5209\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 611.6206 - val_loss: 585.5029\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 599.0820 - val_loss: 579.6400\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 586.7363 - val_loss: 573.9310\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 574.5814 - val_loss: 568.3740\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 562.6161 - val_loss: 562.9669\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 550.8387 - val_loss: 557.7086\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 539.2473 - val_loss: 552.5972\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 527.8404 - val_loss: 547.6312\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 516.6161 - val_loss: 542.8084\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 505.5728 - val_loss: 538.1275\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 494.7090 - val_loss: 533.5863\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 484.0225 - val_loss: 529.1838\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 473.5122 - val_loss: 524.9180\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 463.1764 - val_loss: 520.7870\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 453.0129 - val_loss: 516.7893\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 443.0205 - val_loss: 512.9232\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 433.1971 - val_loss: 509.1869\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 423.5413 - val_loss: 505.5787\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 414.0514 - val_loss: 502.0971\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 404.7261 - val_loss: 498.7402\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 395.5633 - val_loss: 495.5066\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 386.5613 - val_loss: 492.3943\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 377.7188 - val_loss: 489.4017\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 369.0338 - val_loss: 486.5270\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 360.5047 - val_loss: 483.7689\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 352.1300 - val_loss: 481.1253\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 343.9080 - val_loss: 478.5949\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 335.8372 - val_loss: 476.1758\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 327.9159 - val_loss: 473.8662\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 320.1422 - val_loss: 471.6647\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 312.5148 - val_loss: 469.5695\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 305.0319 - val_loss: 467.5788\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 297.6918 - val_loss: 465.6911\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 290.4930 - val_loss: 463.9048\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 283.4338 - val_loss: 462.2180\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 276.5128 - val_loss: 460.6292\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 269.7279 - val_loss: 459.1366\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 263.0781 - val_loss: 457.7388\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 256.5613 - val_loss: 456.4338\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 250.1758 - val_loss: 455.2203\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 243.9204 - val_loss: 454.0963\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 237.7932 - val_loss: 453.0603\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 231.7926 - val_loss: 452.1107\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 225.9174 - val_loss: 451.2458\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 220.1658 - val_loss: 450.4641\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 214.5362 - val_loss: 449.7638\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 209.0270 - val_loss: 449.1433\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 203.6366 - val_loss: 448.6009\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 198.3630 - val_loss: 448.1351\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 193.2050 - val_loss: 447.7442\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 188.1611 - val_loss: 447.4266\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 183.2294 - val_loss: 447.1808\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 178.4088 - val_loss: 447.0049\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 173.6976 - val_loss: 446.8976\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 169.0939 - val_loss: 446.8571\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 164.5964 - val_loss: 446.8820\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 160.2037 - val_loss: 446.9705\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 155.9141 - val_loss: 447.1211\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 151.7259 - val_loss: 447.3323\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 147.6376 - val_loss: 447.6025\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 143.6476 - val_loss: 447.9300\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 139.7547 - val_loss: 448.3134\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 135.9574 - val_loss: 448.7511\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 132.2539 - val_loss: 449.2415\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 128.6428 - val_loss: 449.7831\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125.1226 - val_loss: 450.3745\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 121.6918 - val_loss: 451.0140\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 118.3489 - val_loss: 451.7003\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 115.0923 - val_loss: 452.4316\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 111.9208 - val_loss: 453.2066\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 108.8326 - val_loss: 454.0239\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 105.8264 - val_loss: 454.8818\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 102.9008 - val_loss: 455.7789\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 100.0541 - val_loss: 456.7140\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 97.2852 - val_loss: 457.6853\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 94.5925 - val_loss: 458.6917\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 91.9746 - val_loss: 459.7316\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 89.4300 - val_loss: 460.8036\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 86.9573 - val_loss: 461.9063\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 84.5552 - val_loss: 463.0385\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 82.2222 - val_loss: 464.1986\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 79.9572 - val_loss: 465.3852\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 77.7586 - val_loss: 466.5973\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 75.6251 - val_loss: 467.8333\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 73.5554 - val_loss: 469.0920\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 71.5480 - val_loss: 470.3721\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 69.6018 - val_loss: 471.6722\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 67.7153 - val_loss: 472.9913\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 65.8872 - val_loss: 474.3278\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 64.1163 - val_loss: 475.6808\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 62.4013 - val_loss: 477.0489\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 60.7410 - val_loss: 478.4310\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 59.1339 - val_loss: 479.8258\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 57.5792 - val_loss: 481.2324\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 56.0752 - val_loss: 482.6494\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 54.6210 - val_loss: 484.0757\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 53.2152 - val_loss: 485.5103\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51.8569 - val_loss: 486.9521\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50.5446 - val_loss: 488.3998\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 49.2773 - val_loss: 489.8528\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 48.0538 - val_loss: 491.3099\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 46.8732 - val_loss: 492.7699\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 45.7340 - val_loss: 494.2319\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 44.6355 - val_loss: 495.6948\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 43.5764 - val_loss: 497.1581\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 42.5556 - val_loss: 498.6206\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 41.5720 - val_loss: 500.0815\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 40.6248 - val_loss: 501.5396\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 39.7128 - val_loss: 502.9944\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 38.8351 - val_loss: 504.4449\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 37.9906 - val_loss: 505.8903\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 37.1784 - val_loss: 507.3301\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 36.3975 - val_loss: 508.7629\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 35.6471 - val_loss: 510.1887\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 34.9261 - val_loss: 511.6064\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 34.2336 - val_loss: 513.0152\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 33.5688 - val_loss: 514.4147\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 32.9308 - val_loss: 515.8041\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 32.3188 - val_loss: 517.1827\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 31.7318 - val_loss: 518.5500\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 31.1692 - val_loss: 519.9056\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 30.6300 - val_loss: 521.2486\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 30.1135 - val_loss: 522.5787\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.6190 - val_loss: 523.8954\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 29.1455 - val_loss: 525.1981\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 28.6926 - val_loss: 526.4863\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 28.2594 - val_loss: 527.7597\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 27.8452 - val_loss: 529.0181\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 27.4492 - val_loss: 530.2607\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 27.0709 - val_loss: 531.4874\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 26.7097 - val_loss: 532.6976\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 26.3648 - val_loss: 533.8911\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 26.0357 - val_loss: 535.0680\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 25.7217 - val_loss: 536.2275\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 25.4223 - val_loss: 537.3691\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 25.1370 - val_loss: 538.4933\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 24.8650 - val_loss: 539.5995\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 24.6060 - val_loss: 540.6874\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 24.3594 - val_loss: 541.7576\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 24.1246 - val_loss: 542.8085\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 23.9013 - val_loss: 543.8414\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 23.6889 - val_loss: 544.8555\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 23.4869 - val_loss: 545.8505\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 23.2950 - val_loss: 546.8271\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 23.1126 - val_loss: 547.7847\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.9394 - val_loss: 548.7231\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 22.7750 - val_loss: 549.6428\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.6189 - val_loss: 550.5433\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.4709 - val_loss: 551.4250\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.3304 - val_loss: 552.2878\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.1973 - val_loss: 553.1315\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 22.0712 - val_loss: 553.9564\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 21.9516 - val_loss: 554.7629\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.8384 - val_loss: 555.5507\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.7311 - val_loss: 556.3200\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 21.6297 - val_loss: 557.0704\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.5337 - val_loss: 557.8031\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.4428 - val_loss: 558.5174\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.3569 - val_loss: 559.2137\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.2757 - val_loss: 559.8922\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.1989 - val_loss: 560.5530\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.1264 - val_loss: 561.1965\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.0578 - val_loss: 561.8228\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.9931 - val_loss: 562.4320\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.9320 - val_loss: 563.0241\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.8743 - val_loss: 563.5999\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.8199 - val_loss: 564.1589\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.7685 - val_loss: 564.7023\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.7200 - val_loss: 565.2296\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.6743 - val_loss: 565.7411\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.6312 - val_loss: 566.2377\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5906 - val_loss: 566.7186\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5523 - val_loss: 567.1852\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.5162 - val_loss: 567.6369\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4821 - val_loss: 568.0743\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4501 - val_loss: 568.4977\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.4199 - val_loss: 568.9075\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.3914 - val_loss: 569.3035\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.3647 - val_loss: 569.6864\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.3395 - val_loss: 570.0567\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.3157 - val_loss: 570.4139\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.2933 - val_loss: 570.7588\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.2723 - val_loss: 571.0918\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.2525 - val_loss: 571.4130\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 20.2338 - val_loss: 571.7225\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 20.2163 - val_loss: 572.0213\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.1998 - val_loss: 572.3090\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.1842 - val_loss: 572.5859\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.1696 - val_loss: 572.8524\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.1558 - val_loss: 573.1090\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.1429 - val_loss: 573.3560\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.1307 - val_loss: 573.5931\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.1193 - val_loss: 573.8209\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.1085 - val_loss: 574.0397\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0984 - val_loss: 574.2500\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0888 - val_loss: 574.4518\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0799 - val_loss: 574.6451\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0715 - val_loss: 574.8306\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0636 - val_loss: 575.0084\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0562 - val_loss: 575.1790\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 20.0492 - val_loss: 575.3419\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0426 - val_loss: 575.4979\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0364 - val_loss: 575.6476\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0306 - val_loss: 575.7904\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0252 - val_loss: 575.9271\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0201 - val_loss: 576.0577\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0153 - val_loss: 576.1824\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0108 - val_loss: 576.3014\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0066 - val_loss: 576.4151\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.0026 - val_loss: 576.5236\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9989 - val_loss: 576.6270\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9954 - val_loss: 576.7254\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9922 - val_loss: 576.8190\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9891 - val_loss: 576.9088\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 19.9862 - val_loss: 576.9937\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9836 - val_loss: 577.0743\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9811 - val_loss: 577.1512\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9788 - val_loss: 577.2245\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9766 - val_loss: 577.2941\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9745 - val_loss: 577.3599\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9727 - val_loss: 577.4222\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9709 - val_loss: 577.4814\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9693 - val_loss: 577.5379\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9678 - val_loss: 577.5915\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9664 - val_loss: 577.6417\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9651 - val_loss: 577.6896\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9639 - val_loss: 577.7349\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9627 - val_loss: 577.7778\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.9617 - val_loss: 577.8182\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9608 - val_loss: 577.8567\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9600 - val_loss: 577.8930\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9592 - val_loss: 577.9272\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9585 - val_loss: 577.9597\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9578 - val_loss: 577.9905\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9572 - val_loss: 578.0190\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9566 - val_loss: 578.0462\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9561 - val_loss: 578.0717\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9557 - val_loss: 578.0955\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9554 - val_loss: 578.1180\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9550 - val_loss: 578.1392\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9547 - val_loss: 578.1590\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9545 - val_loss: 578.1776\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 19.9543 - val_loss: 578.1948\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9541 - val_loss: 578.2113\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9540 - val_loss: 578.2265\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9539 - val_loss: 578.2409\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 19.9538 - val_loss: 578.2545\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9538 - val_loss: 578.2672\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9538 - val_loss: 578.2787\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9538 - val_loss: 578.2897\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9538 - val_loss: 578.3000\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9538 - val_loss: 578.3094\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9539 - val_loss: 578.3180\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9540 - val_loss: 578.3264\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9541 - val_loss: 578.3339\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 19.9542 - val_loss: 578.3408\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9544 - val_loss: 578.3473\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9545 - val_loss: 578.3536\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9547 - val_loss: 578.3591\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9549 - val_loss: 578.3642\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9551 - val_loss: 578.3690\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9553 - val_loss: 578.3734\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9555 - val_loss: 578.3773\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9557 - val_loss: 578.3809\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9560 - val_loss: 578.3846\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9561 - val_loss: 578.3875\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9564 - val_loss: 578.3905\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.9567 - val_loss: 578.3932\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 19.9569 - val_loss: 578.3954\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9572 - val_loss: 578.3978\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9574 - val_loss: 578.3998\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9577 - val_loss: 578.4015\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9580 - val_loss: 578.4029\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9582 - val_loss: 578.4042\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9585 - val_loss: 578.4054\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9588 - val_loss: 578.4065\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9591 - val_loss: 578.4072\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9594 - val_loss: 578.4077\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9597 - val_loss: 578.4086\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9599 - val_loss: 578.4092\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.9602 - val_loss: 578.4097\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9605 - val_loss: 578.4098\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9608 - val_loss: 578.4102\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9611 - val_loss: 578.4106\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9614 - val_loss: 578.4105\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.9617 - val_loss: 578.4108\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9620 - val_loss: 578.4109\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9622 - val_loss: 578.4106\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9625 - val_loss: 578.4105\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9628 - val_loss: 578.4105\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9631 - val_loss: 578.4100\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9633 - val_loss: 578.4096\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9637 - val_loss: 578.4094\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 19.9639 - val_loss: 578.4093\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9642 - val_loss: 578.4086\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9645 - val_loss: 578.4083\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9647 - val_loss: 578.4077\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9650 - val_loss: 578.4070\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9653 - val_loss: 578.4065\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9656 - val_loss: 578.4061\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9658 - val_loss: 578.4056\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9661 - val_loss: 578.4052\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9663 - val_loss: 578.4047\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9666 - val_loss: 578.4041\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9668 - val_loss: 578.4033\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 19.9671 - val_loss: 578.4028\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9674 - val_loss: 578.4023\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9676 - val_loss: 578.4019\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9678 - val_loss: 578.4010\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9681 - val_loss: 578.4001\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9683 - val_loss: 578.3996\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9685 - val_loss: 578.3988\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9688 - val_loss: 578.3984\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9690 - val_loss: 578.3976\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9692 - val_loss: 578.3972\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9695 - val_loss: 578.3964\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9697 - val_loss: 578.3957\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 19.9699 - val_loss: 578.3950\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 19.9701 - val_loss: 578.3945\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9703 - val_loss: 578.3939\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9705 - val_loss: 578.3930\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9708 - val_loss: 578.3922\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9710 - val_loss: 578.3917\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9712 - val_loss: 578.3913\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9714 - val_loss: 578.3907\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9716 - val_loss: 578.3903\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9718 - val_loss: 578.3895\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9720 - val_loss: 578.3890\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9721 - val_loss: 578.3882\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9724 - val_loss: 578.3879\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 19.9725 - val_loss: 578.3874\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9727 - val_loss: 578.3867\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9729 - val_loss: 578.3860\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9731 - val_loss: 578.3851\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9733 - val_loss: 578.3849\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9734 - val_loss: 578.3845\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9736 - val_loss: 578.3838\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9738 - val_loss: 578.3834\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9739 - val_loss: 578.3828\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9741 - val_loss: 578.3824\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9742 - val_loss: 578.3817\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9744 - val_loss: 578.3813\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.9746 - val_loss: 578.3809\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9747 - val_loss: 578.3802\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9749 - val_loss: 578.3801\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9750 - val_loss: 578.3795\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9752 - val_loss: 578.3790\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9753 - val_loss: 578.3785\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9755 - val_loss: 578.3780\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9756 - val_loss: 578.3777\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9757 - val_loss: 578.3774\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9759 - val_loss: 578.3770\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9760 - val_loss: 578.3764\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.9761 - val_loss: 578.3760\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9762 - val_loss: 578.3754\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9764 - val_loss: 578.3751\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9765 - val_loss: 578.3747\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9767 - val_loss: 578.3743\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9768 - val_loss: 578.3741\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9769 - val_loss: 578.3740\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9770 - val_loss: 578.3738\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9771 - val_loss: 578.3734\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 19.9772 - val_loss: 578.3728\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9773 - val_loss: 578.3724\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 19.9775 - val_loss: 578.3720\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.9775 - val_loss: 578.3716\n"
     ]
    }
   ],
   "source": [
    "C0 = tf.Variable(85.7336, name=\"C0\", trainable=True, dtype=tf.float32)\n",
    "K0 = tf.Variable(-0.0020, name=\"K0\", trainable=True, dtype=tf.float32)\n",
    "K1 = tf.Variable(-0.0002, name=\"K1\", trainable=True, dtype=tf.float32)\n",
    "a = tf.Variable(0.0000, name=\"a\", trainable=True, dtype=tf.float32)\n",
    "b = tf.Variable(0.0125, name=\"b\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(2.3008, name=\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "splitr = 0.8\n",
    "\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
    "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
    "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
    "    epsilon = 1\n",
    "    squared_difference3 = tf.square(\n",
    "        y_pred[:, 1] - (\n",
    "            y_pred[:, 0] * (\n",
    "                K0 - K1 * (\n",
    "                    9 * a * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c)**2 +\n",
    "                    4 * b * tf.math.log((y_pred[:, 0] + epsilon) / C0) / (K0 - K1 * c) + c\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(60))\n",
    "model.compile(loss=loss_fn, optimizer='adam')\n",
    "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJL101rPyuoT",
    "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 376ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast_without_mc = forecastX\n",
    "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
    "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9dQELcJ8wbp",
    "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 251)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS2kyIKG1Kbr",
    "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 251)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0u6VIzaDyuoT"
   },
   "outputs": [],
   "source": [
    "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
    "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUEcw0LX07oU",
    "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat_without_mc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "31OWVbSh_305"
   },
   "outputs": [],
   "source": [
    "fforecast = inv_yhat_without_mc[:,-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BlpGH2FOAiRF"
   },
   "outputs": [],
   "source": [
    "final_forecast = fforecast[:,0:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fforecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CXkgkj_LBk_t"
   },
   "outputs": [],
   "source": [
    "# code to replace all negative value with 0\n",
    "final_forecast[final_forecast<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.40100840e+01, 6.39988795e+01, 6.39876751e+01, 6.39764706e+01,\n",
       "        6.39652661e+01, 6.39540616e+01, 6.39428571e+01, 6.39316527e+01,\n",
       "        6.39204482e+01, 6.39092437e+01, 6.38941176e+01, 6.38605042e+01,\n",
       "        6.38268908e+01, 6.67665616e+01, 6.66797035e+01, 6.65998716e+01,\n",
       "        6.65200397e+01, 6.64402077e+01, 6.63603758e+01, 6.62805439e+01,\n",
       "        6.62007119e+01, 6.61208800e+01, 6.60404810e+01, 6.59612161e+01,\n",
       "        6.58813842e+01, 6.58015523e+01, 6.57258403e+01, 6.56502101e+01,\n",
       "        6.55745798e+01, 6.54998496e+01, 6.54233193e+01, 6.53476891e+01,\n",
       "        6.52720588e+01, 6.51964286e+01, 6.51207983e+01, 6.50451681e+01,\n",
       "        6.49695378e+01, 6.48959384e+01, 6.48455182e+01, 6.47950980e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.53829455e-01, 4.76361140e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.58192927e+01,\n",
       "        6.57426471e+01, 6.56670168e+01, 6.55913865e+01, 6.55157563e+01,\n",
       "        6.54401261e+01, 6.53644958e+01, 6.52888655e+01, 6.52132353e+01,\n",
       "        6.51376050e+01, 6.50619748e+01, 6.49863445e+01, 6.49107143e+01,\n",
       "        6.48567227e+01, 6.48063025e+01, 6.47558823e+01, 6.47054622e+01,\n",
       "        6.46540420e+01, 6.46036219e+01, 6.45534202e+01, 6.45037815e+01,\n",
       "        6.44533613e+01, 6.44029412e+01, 6.43525210e+01, 6.43021008e+01,\n",
       "        6.42677871e+01, 7.15446396e+01, 5.04386365e-01, 0.00000000e+00,\n",
       "        6.63190544e-01, 4.41821933e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.89203835e+01, 0.00000000e+00, 0.00000000e+00, 8.30763102e-01,\n",
       "        1.08063862e-01, 2.16340378e-01, 0.00000000e+00, 6.88362777e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.29114306e-01, 4.67840314e-01,\n",
       "        0.00000000e+00, 2.10966527e-01, 0.00000000e+00, 1.29907712e-01,\n",
       "        4.51612353e-01, 6.28426298e-02, 1.36335313e-01, 6.50943160e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "test = np.array(test)\n",
    "final_forecast = np.array(final_forecast.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59.96435574, 59.95035014, 59.93634454, 59.92233894, 59.90833333,\n",
       "       59.89432773, 59.88032213, 59.86631653, 59.85231092, 59.83830532,\n",
       "       59.82429972, 59.81029412, 59.79628852, 59.78228291, 59.76827731,\n",
       "       59.75427171, 59.74026611, 59.7262605 , 59.7122549 , 59.69935808,\n",
       "       59.69422269, 59.6890873 , 59.68395191, 59.67881653, 59.67368114,\n",
       "       59.66854575, 59.66341036, 59.65827498, 59.65313959, 59.6480042 ,\n",
       "       59.64286881, 59.63773343, 59.63259804, 59.62746265, 59.62232726,\n",
       "       59.61719188, 59.61205649, 59.6069211 , 59.60178571, 59.59665033,\n",
       "       59.59151494, 59.58637955, 59.58124416, 59.57610878, 59.57097339,\n",
       "       59.565838  , 59.56070261, 59.55556723, 59.55043184, 59.54529645,\n",
       "       59.54016106, 59.53502568, 59.52989029, 59.5247549 , 59.51961951,\n",
       "       59.51448413, 59.50934874, 59.50421335, 59.49907796, 59.49394258,\n",
       "       59.48880719, 59.4836718 , 59.47853641, 59.47340103, 59.46826564,\n",
       "       59.46313025, 59.45799486, 59.45285948, 59.44772409, 59.4425887 ,\n",
       "       59.43745331, 59.43231793, 59.42718254, 59.42204715, 59.41691176,\n",
       "       59.41177638, 59.40664099, 59.4015056 , 59.39637021, 59.39123483,\n",
       "       59.38609944, 59.38096405, 59.37582866, 59.37069328, 59.36555789,\n",
       "       59.3604225 , 59.35528711, 59.35015173, 59.34501634, 59.33988095,\n",
       "       59.33474556, 59.32961018, 59.32447479, 59.3193394 , 59.31420401,\n",
       "       59.30906863, 59.30393324, 59.29879785, 59.29366246, 59.28852708])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.82634952610873\n",
      "22.759512045609267\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "rsme = math.sqrt(MSE)\n",
    "print(rsme)  \n",
    "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
    "mae = MAE\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
